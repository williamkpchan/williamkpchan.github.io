<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" target=_blank>
<style type="text/css" target=_blank>a {text-decoration: none}</style>
</head>
<body bgcolor="#000000" text="#109030" leftmargin="10" topmargin="10" marginwidth="100" link="#00CCCC" vlink="#CC66CC" alink="#FFFF00" target=_blank>
<FONT size=3>

<h1 class="post-title">A primer on web scraping with R</h1>
<center>
<img src="https://predictiveheuristics.files.wordpress.com/2014/10/scraping-figure.png"><br>
The basic HTML scraping workflow using R<br>
</center>

<p>However, vast amounts of unstructured data, probably spread over hundreds of webpages, can pose a challenge, as it is very time-consuming and error prone to collect such data by hand. If you have identified online data as an appropriate resource for our project, it might be a good decision to automate the data collection and tidying procedure, especially if we plan to update databases regularly, if the collection task is non-trivial in terms of scope and complexity, and if we want others to be able to replicate our data collection process. We are used to automate the data preparation and analysis part of quantitative analyses with statistical software like Stata or R, but automation is also possible for the data collection part if the data of interest are available on the Web. In fact, over the past few years many people in the R community <a href="http://cran.r-project.org/web/views/WebTechnologies.html">have worked hard</a> to make R a very flexible tool to collect web data and communicate with web services. For us as substantively oriented researchers, this is extraordinarily valuable because R has become one of the most popular software packages in the profession, so it’s good news that R provides these capabilities as well.</p>
<p>So what are the main techniques to scrape data from the Web? Essentially, classical web scraping from HTML pages with R is a six-step process (see also the figure on the right). First, we have to identify the desired information and locate it within an HTML document. HTML source code is highly hierarchical, but interesting data are often layouted as news headlines, tables or lists, and it is possible to address the markup which is used to structure and layout content for display in a browser. Second, we have to download the documents which contain the information of interest. This can be one HTML page or hundreds of them. R is capable of doing this for us in an automated manner. Next, we import the HTML code into R using HTML parsing software which is implemented in R and store the bunch of documents in a list or some other useful data structure. In order to extract the information—certain lines of text, numbers stored in tables, etc.—from the documents, we exploit the markup nature of HTML and the fact that it is essentially XML-based and construct XPath queries. XPath is a little language of its own which allows assessing structured information from XML-style documents, asking R, e.g., to “return all bold formatted headlines which are in the politics section of this online newspaper frontpage.” Finally, we have to merge and tidy all extracted raw data and debug our code to keep it robust in future scraping tasks.</p>
<p>In practice, there are some pitfalls in more sophisticated scenarios (e.g., when we are interested in data from dynamic webpages), but essentially there is nothing that cannot be done with R in terms of tapping web resources. At Duke Michael Ward and Kyle Beardsley gave me the opportunity to demonstrate in two sessions what’s possible with R in their methods workshop. This is hardly enough time to become an expert in web scraping, so I decided to give a broad overview of the technologies and tools which are currently available. I demonstrated the basics of the following topics:</p>
<ol>
<li>How to scrape static content from HTML code using
<ul>
<li>the fabulous <a href="http://cran.r-project.org/web/packages/XML/index.html">XML</a> package to parse XML and HTML code,</li>
<li>the <a href="http://www.w3schools.com/xpath/">XPath</a> query language to extract well-chosen content from the document tree</li>
<li><a href="http://selectorgadget.com/">SelectorGadget</a> and the Browser Inspector tools as convenient instruments for constructing XPath queries, and</li>
<li><a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html">regular expressions</a> to <a href="https://www.youtube.com/watch?v=WOdjCb4LwQY">scrape data from a website as if it were merely text</a>.</li>
</ul>
</li>
<li>How to scrape dynamic content from AJAX-enriched webpages with <a href="http://docs.seleniumhq.org/projects/webdriver/">Selenium WebDriver</a> and the <a href="http://cran.r-project.org/web/packages/RSelenium/">RSelenium package</a>.</li>
<li>How to tap REST web services and access the popular Twitter APIs using the <a href="http://cran.r-project.org/web/packages/twitteR/">twitteR</a> and the <a href="http://cran.r-project.org/web/packages/streamR/">streamR</a> package.</li>
</ol>
<p>The scripts of both scraping sessions can be found <a href="https://github.com/simonmunzert/rscraping-intro-duke">here (session 1)</a> and <a href="https://github.com/simonmunzert/rscraping-intro-duke-2">here (session 2)</a>. The slides of the first session are <a href="https://predictiveheuristics.files.wordpress.com/2014/10/slides-intro-scraping.pdf">here</a>.</p>
<p>If you want to learn more about how to scrape web data with R, there is a book coming out in January 2015 in which colleagues of mine and me compiled useful fundamentals and many practical web scraping and text mining applications. During the past few years the market for books on data science/mining has emerged quickly. What is surprisingly often missing in these introductions though is how data for data science applications are actually acquired. In this sense our book serves as a preparatory step for data analyses but also provides guidance on how to manage available information and keep it up to date. We planned to make it accessible to autodidacts with no or only little knowledge about web technologies. For more information on the book click <a href="http://r-datacollection.com">here</a>.</p>
