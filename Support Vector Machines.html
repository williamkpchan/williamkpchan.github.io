<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" target=_blank>
<style type="text/css" target=_blank>a {text-decoration: none}</style>
</head>
<body bgcolor="#000000" text="#109030" leftmargin="10" topmargin="10" marginwidth="150" link="#00CCCC" vlink="#CC66CC" alink="#FFFF00" target=_blank>
<FONT size=3>

<h3>
Using Support Vector Machines as Flower Finders</h3>

<div>
Nature field guides are filled with pictures of plants and animals that teach us what to look for and how to name what we see. For example, a flower finder might display pictures of different iris species, such as the illustrations in the plot below. You have in hand your own specimen from your garden, and you carefully compare it to each of the pictures until you find a good-enough match. The&nbsp;<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">pictures come from Wikipedia</a>, but the data used to create the plot are from <a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/iris.html">the R dataset iris</a>: sepal and petal length and width measured on 150 flowers equally divided across three species.</div>
<div class="separator" style="clear: both; text-align: left;">
<br /></div>
I have lifted the code directly from the <a href="http://www.inside-r.org/node/57517">svm function in the R package e1071</a>.<br />
<div style="overflow: auto;">
<div class="geshifilter">
<pre class="r geshifilter-R" style="font-family: monospace;"><a href="http://inside-r.org/r-doc/base/library"><span style="color: #003399; font-weight: bold;">library</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/packages/cran/e1071">e1071</a><span style="color: #009900;">)</span>
<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399; font-weight: bold;">data</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #009900;">)</span>
<a href="http://inside-r.org/r-doc/base/attach"><span style="color: #003399; font-weight: bold;">attach</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #009900;">)</span>
&nbsp;
<span style="color: #666666; font-style: italic;">## classification mode</span>
<span style="color: #666666; font-style: italic;"># default with factor response:</span>
model &lt;- svm<span style="color: #009900;">(</span>Species ~ .<span style="color: #339933;">,</span> <a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399; font-weight: bold;">data</span></a> = <a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #009900;">)</span>
&nbsp;
<span style="color: #666666; font-style: italic;"># alternatively the traditional interface:</span>
x &lt;- <a href="http://inside-r.org/r-doc/base/subset"><span style="color: #003399; font-weight: bold;">subset</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #339933;">,</span> select = -Species<span style="color: #009900;">)</span>
y &lt;- Species
model &lt;- svm<span style="color: #009900;">(</span>x<span style="color: #339933;">,</span> y<span style="color: #009900;">)</span> 
&nbsp;
<a href="http://inside-r.org/r-doc/base/print"><span style="color: #003399; font-weight: bold;">print</span></a><span style="color: #009900;">(</span>model<span style="color: #009900;">)</span>
<a href="http://inside-r.org/r-doc/base/summary"><span style="color: #003399; font-weight: bold;">summary</span></a><span style="color: #009900;">(</span>model<span style="color: #009900;">)</span>
&nbsp;
<span style="color: #666666; font-style: italic;"># test with train data</span>
pred &lt;- <a href="http://inside-r.org/r-doc/stats/predict"><span style="color: #003399; font-weight: bold;">predict</span></a><span style="color: #009900;">(</span>model<span style="color: #339933;">,</span> x<span style="color: #009900;">)</span>
<span style="color: #666666; font-style: italic;"># (same as:)</span>
pred &lt;- <a href="http://inside-r.org/r-doc/stats/fitted"><span style="color: #003399; font-weight: bold;">fitted</span></a><span style="color: #009900;">(</span>model<span style="color: #009900;">)</span>
&nbsp;
<span style="color: #666666; font-style: italic;"># Check accuracy:</span>
<a href="http://inside-r.org/r-doc/base/table"><span style="color: #003399; font-weight: bold;">table</span></a><span style="color: #009900;">(</span>pred<span style="color: #339933;">,</span> y<span style="color: #009900;">)</span>
&nbsp;
<span style="color: #666666; font-style: italic;"># compute decision values and probabilities:</span>
pred &lt;- <a href="http://inside-r.org/r-doc/stats/predict"><span style="color: #003399; font-weight: bold;">predict</span></a><span style="color: #009900;">(</span>model<span style="color: #339933;">,</span> x<span style="color: #339933;">,</span> decision.values = <span style="color: black; font-weight: bold;">TRUE</span><span style="color: #009900;">)</span>
<a href="http://inside-r.org/r-doc/base/attr"><span style="color: #003399; font-weight: bold;">attr</span></a><span style="color: #009900;">(</span>pred<span style="color: #339933;">,</span> <span style="color: blue;">"decision.values"</span><span style="color: #009900;">)</span><span style="color: #009900;">[</span><span style="color: #cc66cc;">1</span>:<span style="color: #cc66cc;">4</span><span style="color: #339933;">,</span><span style="color: #009900;">]</span>
&nbsp;
<span style="color: #666666; font-style: italic;"># visualize (classes by color, SV by crosses):</span>
<a href="http://inside-r.org/r-doc/graphics/plot"><span style="color: #003399; font-weight: bold;">plot</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/stats/cmdscale"><span style="color: #003399; font-weight: bold;">cmdscale</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/stats/dist"><span style="color: #003399; font-weight: bold;">dist</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #009900;">[</span><span style="color: #339933;">,</span>-<span style="color: #cc66cc;">5</span><span style="color: #009900;">]</span><span style="color: #009900;">)</span><span style="color: #009900;">)</span><span style="color: #339933;">,</span>
     <a href="http://inside-r.org/r-doc/base/col"><span style="color: #003399; font-weight: bold;">col</span></a> = <a href="http://inside-r.org/r-doc/base/as.integer"><span style="color: #003399; font-weight: bold;">as.integer</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399; font-weight: bold;">iris</span></a><span style="color: #009900;">[</span><span style="color: #339933;">,</span><span style="color: #cc66cc;">5</span><span style="color: #009900;">]</span><span style="color: #009900;">)</span><span style="color: #339933;">,</span>
     pch = <a href="http://inside-r.org/r-doc/base/c"><span style="color: #003399; font-weight: bold;">c</span></a><span style="color: #009900;">(</span><span style="color: blue;">"o"</span><span style="color: #339933;">,</span><span style="color: blue;">"+"</span><span style="color: #009900;">)</span><span style="color: #009900;">[</span><span style="color: #cc66cc;">1</span>:<span style="color: #cc66cc;">150</span> %in% model$index + <span style="color: #cc66cc;">1</span><span style="color: #009900;">]</span><span style="color: #009900;">)</span></pre>
</div>
</div>
<a href="http://www.inside-r.org/pretty-r" title="Created by Pretty R at inside-R.org">Created by Pretty R at inside-R.org</a><br />
<br />
We will focus on the last block of R code that generates the metric multidimensional scaling (MDS) of the distances separating the 150 flowers calculated from sepal and petal length and width (i.e., <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/dist.html">the dist function</a> applied to the first four columns of the iris data). Species plays no role in the MDS with the flowers positioned in a two-dimensional space in order to reproduce the pairwise Euclidean distances. However, species is projected onto the plot using color, and the observations acting as support vectors are indicated with plus signs (+).<br />
<br />
The setosa flowers are represented by black circles and black plus signs. These points are separated along the first dimension from the versicolor species in red and virginica in green. The second dimension, on the other hand, seems to reflect some within-species sources of differences that do not differentiate among the three iris types.<br />
<br />
We should recall that the dist function calculates pairwise distances in the original space without any kernel transformation. The support vectors, on the other hand, were identified from the svm function using a radial kernel and then projected back onto the original observation space. Of course, we can change the kernel, which defaults to "radial" as in this example from the R package. A linear kernel may do just as well with the iris data, as you can see by adding kernel="linear" to the svm function in the above code.<br />
<br />

<a href="https://1.bp.blogspot.com/-_p05w09FNec/V0R3nVsTeYI/AAAAAAAAAZ4/3hM61FuoUhoUDt0Gtz0HnAOl5z8date4wCKgB/s1600/iris%2Bmds%2Bplot.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img src="https://1.bp.blogspot.com/-_p05w09FNec/V0R3nVsTeYI/AAAAAAAAAZ4/3hM61FuoUhoUDt0Gtz0HnAOl5z8date4wCKgB/s640/iris%2Bmds%2Bplot.jpg"></a>
<br />
It appears that we do not need all 150 flowers in order to identify the iris species. We know this because the svm function correctly classifies over 97% of the flowers with 51 support vectors (also called "landmarks" as noted in my last post&nbsp;<a href="http://joelcadwell.blogspot.com/2016/05/the-kernel-trick-in-support-vector.html">Seeing Similarity in More Intricate Dimensions</a>). The majority of the +'s are located between the two species with the greatest overlap. I have included the pictures so that the similarity of the red and green categories is obvious. This is where there will be confusion, and this is where the only misclassifications occur. If your iris is a setosa, your identification task is relatively easy and over quickly. But suppose that your iris resembles those in the cluster of red and green pluses between versicolor and virginica. This is where the finer distinctions are being made.<br />
<br />
By design, this analysis was kept brief to draw an analogy between support vector machines and finder guides that we have all used to identify unknown plants and animals in the wild. Hopefully, it was a useful comparison that will help you understand how we classify new observations by measuring their distances in a kernel metric from a more limited set of support vectors (a type of global positioning with a minimal number of landmarks or exemplars as satellites).<br />
<br />
When you are ready with your own data, you can view the videos from Chapter 9 of <a href="http://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/">An Introduction to Statistical Learning with Applications in R</a> to get a more complete outline of all the steps involved. My intent was simply to disrupt the feature mindset that relies on the cumulative contributions of separate attributes (e.g., the relative impact of each independent variable in a prediction equation). As objects become more complex, we stop seeing individual aspects and begin to bundle features into types or categories. We immediately recognize the object by its feature configuration, and these exemplars or landmarks become the new basis for our support vector representation.<br />
