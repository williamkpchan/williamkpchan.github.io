<base target="_blank"><html><head><title>statologyContents 6</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://williamkpchan.github.io/lazyload.min.js"></script>
<script src='https://williamkpchan.github.io/mainscript.js'></script>
<script src="https://williamkpchan.github.io/commonfunctions.js"></script>
<script>
  var showTopicNumber = true;
  var topicEnd = "<br>";
  var bookid = "statologyContents 6"
  var markerName = "h2, h3"
</script>
<style>
body{width:70%;margin-left: 15%; font-size:20px;}
h1, h2 {color: gold;}
strong {color: orange;}
b {color: brown;}
img {max-width:60%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>statologyContents 6</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a><br><br>
<div id="toc"></div></center><br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br></div>
<pre><br><br>
<h2><span class="orange">How to Find the F Critical Value in R</span></h2>
When you conduct an F test, you will get an F statistic as a result. To determine if the results of the F test are statistically significant, you can compare the F statistic to an <b>F critical value</b>. If the F statistic is greater than the F critical value, then the results of the test are statistically significant.
The F critical value can be found by using an  F distribution table  or by using statistical software.
To find the F critical value, you need:
A significance level (common choices are 0.01, 0.05, and 0.10)
Numerator degrees of freedom
Denominator degrees of freedom
Using these three values, you can determine the F critical value to be compared with the F statistic.
<h3>How to Find the F Critical Value in R</h3>
To find the F critical value in R, you can use the qf() function, which uses the following syntax:
<b>qf(p, df1, df2. lower.tail=TRUE)</b>
where:
<b>p: </b>The significance level to use
<b>df1</b>: The numerator degrees of freedom
<b>df2</b>: The denominator degrees of freedom
<b>lower.tail: </b>If TRUE, the probability to the left of <b>p </b>in the F distribution is returned. If FALSE, the probability to the right is returned. Default is TRUE.
This function returns the critical value from the F distribution based on the significance level, numerator degrees of freedom, and denominator degrees of freedom provided.
For example, suppose we would like to find the F critical value for a significance level of 0.05, numerator degrees of freedom = 6, and denominator degrees of freedom = 8. 
<b>#find F critical value
qf(p=.05, df1=6, df2=8, lower.tail=FALSE)
[1] 3.58058</b>
The F critical value for a significance level of 0.05, numerator degrees of freedom = 6, and denominator degrees of freedom = 8 is <b>3.58058</b>.
Thus, if we’re conducting some type of F test then we can compare the F test statistic to <b>3.58058</b>. If the F statistic is greater than 3.58058, then the results of the test are statistically significant.
Note that smaller values of alpha will lead to larger F critical values. For example, consider the F critical value for a significance level of <b>0.01</b>, numerator degrees of freedom = 6, and denominator degrees of freedom = 8. 
<b>#find F critical value
qf(p=.01, df1=6, df2=8, lower.tail=FALSE)
[1] 6.370681</b>
And consider the F critical value with the exact same degrees of freedom for the numerator and denominator, but with a significance level of <b>0.005</b>:
<b>#find F critical value
qf(p=.005, df1=6, df2=8, lower.tail=FALSE)
[1] 7.951992</b>
<i>You can find more R tutorials  here .</i>
<h2><span class="orange">F Distribution Calculator</span></h2>
<label for="df1">Degrees of freedom 1 (numerator)</label>
<input type="number" id="df1" min="0" value="4">
<label for="df2">Degrees of freedom 2 (denominator)</label>
<input type="number" id="df2" min="0" value="6">
<label for="f">F-value</label>
<input type="number" id="f" name="f" min="0" value="2">
<label for="prob">Probability Level</label>
<input type="number" id="prob" name="prob" min="0" value=".05" step=".01">
<input type="button" id="button" onclick="fPVALUE()" value="Calculate p-value">
<input type="button" id="button" onclick="fCRITICALVALUE()" value="Calculate F-value">
<script>
function fPVALUE() {
//get input values
var df1 = document.getElementById('df1').value*1;
var df2 = document.getElementById('df2').value*1;
var f = document.getElementById('f').value*1;
var prob = document.getElementById('prob').value;
//assign probabilities to variable names
var exactProb = 1-jStat.centralF.cdf(f, df1, df2);
//output probabilities
document.getElementsByName('prob')[0].value = exactProb.toFixed(5);
}
function fCRITICALVALUE() {
//get input values
var df1 = document.getElementById('df1').value*1;
var df2 = document.getElementById('df2').value*1;
var f = document.getElementById('f').value*1;
var prob = document.getElementById('prob').value;
//assign probabilities to variable names
var exactF = jStat.centralF.inv((1-prob), df1, df2);
//output probabilities
document.getElementsByName('f')[0].value = exactF.toFixed(5);
}
</script>
<h2><span class="orange">F Distribution Table</span></h2>
F Table for<b> α = 0.10 </b>(Click to zoom in)
  
F Table for<b> α = 0.05 </b>(Click to zoom in)
  
F Table for<b> α = 0.025 </b>(Click to zoom in)
  
F Table for<b> α = 0.01 </b>(Click to zoom in)
  
F Table for<b> α = 0.001 </b>(Click to zoom in)
  
<footer>
<imghttps://secure.gravatar.com/avatar/53eb699db6b966aaeedae88ddbade361?s=68&d=mm&r=g"><b>Nkululeko Fuyane</b> <span>says:
<!-- .comment-author -->
 <time datetime="2020-04-14T04:11:20-04:00">April 14, 2020 at 4:11 am</time> 
<!-- .comment-metadata -->
</footer><!-- .comment-meta -->
If Df2 is greater than 120, what do you?
<!-- .comment-content -->
 Reply </article>
<footer>
<imghttps://secure.gravatar.com/avatar/958f66fbe89e80753a8c8a0492bf5cc8?s=68&d=mm&r=g"><b>admin</b> <span>says:
<!-- .comment-author -->
 <time datetime="2020-04-14T08:31:02-04:00">April 14, 2020 at 8:31 am</time> 
<!-- .comment-metadata -->
</footer><!-- .comment-meta -->
Use the F distribution calculator instead:  https://www.statology.org/f-distribution-calculator/ 
<!-- .comment-content -->
 Reply </article>
<h2><span class="orange">F-Test for Equal Variances Calculator</span></h2>
An <b>F-test</b> is used to test whether two population variances are equal..
To perform an F-test for two samples, simply enter a list of values for each sample in the boxes below, then click the “Calculate” button:
<b>Sample 1:</b>
<textarea id="x" rows="5" cols="40">13, 15, 15, 16, 16, 16, 17, 18, 18, 19, 20, 21</textarea>
<b>Sample 2:</b>
<textarea id="y" rows="5" cols="40">15, 15, 16, 18, 19, 19, 19, 20, 21, 23, 23, 24</textarea>
<input type="button" id="button" onclick="calc()" value="Calculate">
F-Value: 1.77011
P-Value: 0.35774
<script>
function calc() {
//get input data
var x = document.getElementById('x').value.split(',').map(Number);
var y = document.getElementById('y').value.split(',').map(Number);
var var1 = Math.pow(math.std(x), 2)
var var2 = Math.pow(math.std(y), 2)
var n1 = x.length-1;
var n2 = y.length-1;
var f = Math.max(var1,var2) / Math.min(var1,var2);
var p = (1-jStat.centralF.cdf(f, Math.max(n1,n2), Math.min(n1,n2)))*2
document.getElementById('f').innerHTML = f.toFixed(5);
document.getElementById('p').innerHTML = p.toFixed(5);
  
} //end calc function
</script>
<h2><span class="orange">F-Test in Google Sheets (Step-by-Step)</span></h2>
The <b>F-test</b> is used to determine whether or not two population variances are equal.
The F-test uses the following null and alternative hypotheses:
H<sub>0</sub>: The population variances are equal (σ<sub>1</sub><sup>2</sup> = σ<sub>2</sub><sup>2</sup>)
H<sub>A</sub>: The population variances are not equal (σ<sub>1</sub><sup>2</sup> ≠ σ<sub>2</sub><sup>2</sup>)
If the  p-value  of the test is less than some significance level (e.g. α = .05) then we can reject the null hypothesis and conclude that the population variances are not equal.
The following step-by-step example shows how to perform the F-test in Google Sheets.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the data values for two samples:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/fsheets1.png">
<b>Note:</b> The sample sizes do not have to be equal between the two groups to perform the F-test.
<h3>Step 2: Perform the F-Test</h3>
Next, we will use the <b>=FTEST(sample1, sample2)</b> function to perform the F-test:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/fsheets2.png">
The p-value of the test turns out to be <b>.0367</b>.
Since this p-value is less than α = .05, we will reject the null hypothesis.
This means we have sufficient evidence to say that the variances between the two populations that the samples came from are not equal.
<b>Note:</b> The p-value returned by the <b>FTEST()</b> function represents the two-tailed p-value.
Thus, if you were performing a one-tailed test (H<sub>A</sub>: σ<sub>1</sub><sup>2</sup> &lt; σ<sub>2</sub><sup>2</sup>  or  H<sub>A</sub>: σ<sub>1</sub><sup>2</sup> > σ<sub>2</sub><sup>2</sup>) then you could simply multiply the resulting p-value by two to get the one-tailed p-value.
<h2><span class="orange">How to Perform an F-Test in R</span></h2>
An <b>F-test </b>is used to test whether two population variances are equal. The null and alternative hypotheses for the test are as follows:
<b>H<sub>0</sub>:</b> σ<sub>1</sub><sup>2</sup> = σ<sub>2</sub><sup>2</sup> (the population variances are equal)
<b>H<sub>1</sub>:</b> σ<sub>1</sub><sup>2</sup> ≠ σ<sub>2</sub><sup>2</sup> (the population variances are <em>not</em> equal)
To perform an F-test in R, we can use the function <b>var.test() </b>with one of the following syntaxes:
<b>Method 1: </b>var.test(x, y, alternative = “two.sided”)
<b>Method 2: </b>var.test(values ~ groups, data, alternative = “two.sided”)
Note that <em>alternative </em>indicates the alternative hypothesis to use. The default is “two.sided” but you can specify it to be “left” or “right” instead.
This tutorial explains how to perform an F-test in R using both methods.
<h3>Method 1: F-Test in R</h3>
The following code shows how to perform an F-test using the first method:
<b>#define the two groups
x &lt;- c(18, 19, 22, 25, 27, 28, 41, 45, 51, 55)
y &lt;- c(14, 15, 15, 17, 18, 22, 25, 25, 27, 34)
#perform an F-test to determine in the variances are equal
var.test(x, y)
F test to compare two variances
data:  x and y
F = 4.3871, num df = 9, denom df = 9, p-value = 0.03825
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
  1.089699 17.662528
sample estimates:
ratio of variances 
          4.387122 
</b>
The F test statistic is <b>4.3871 </b>and the corresponding p-value is <b>0.03825</b>. Since this p-value is less than .05, we would reject the null hypothesis. This means we have sufficient evidence to say that the two population variances are <em>not </em>equal.
<h3>Method 2: F-Test in R</h3>
The following code shows how to perform an F-test using the first method:
<b>#define the two groups
data &lt;- data.frame(values=c(18, 19, 22, 25, 27, 28, 41, 45, 51, 55,            14, 15, 15, 17, 18, 22, 25, 25, 27, 34),   group=rep(c('A', 'B'), each=10))
#perform an F-test to determine in the variances are equal
var.test(values~group, data=data)
F test to compare two variances
data:  x and y
F = 4.3871, num df = 9, denom df = 9, p-value = 0.03825
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
  1.089699 17.662528
sample estimates:
ratio of variances 
          4.387122 
</b>
Once again the F test statistic is <b>4.3871 </b>and the corresponding p-value is <b>0.03825</b>. Since this  p-value  is less than .05, we would reject the null hypothesis.
This means we have sufficient evidence to say that the two population variances are <em>not </em>equal.
<b>Related</b>: Perform an F-test using this free  F-Test for Equal Variances Calculator .
<h3>When to Use the F-Test</h3>
The F-test is typically used to answer one of the following questions:
<b>1.</b> Do two samples come from populations with equal variances?
<b>2.</b> Does a new treatment or process reduce the variability of some current treatment or process?
<h2><span class="orange">How to Perform an F-Test in Python</span></h2>
An <b>F-test </b>is used to test whether two population variances are equal. The null and alternative hypotheses for the test are as follows:
<b>H<sub>0</sub>:</b> σ<sub>1</sub><sup>2</sup> = σ<sub>2</sub><sup>2</sup> (the population variances are equal)
<b>H<sub>1</sub>:</b> σ<sub>1</sub><sup>2</sup> ≠ σ<sub>2</sub><sup>2</sup> (the population variances are <em>not</em> equal)
This tutorial explains how to perform an F-test in Python.
<h3>Example: F-Test in Python</h3>
Suppose we have the following two samples:
<b>x = [18, 19, 22, 25, 27, 28, 41, 45, 51, 55]</b>
<b>y = [14, 15, 15, 17, 18, 22, 25, 25, 27, 34]</b>
We can use the following function to perform an F-test to determine if the two populations these samples came from have equal variances:
<b>import numpy as np
#define F-test function
def f_test(x, y):
    x = np.array(x)
    y = np.array(y)
    f = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic 
    dfn = x.size-1 #define degrees of freedom numerator 
    dfd = y.size-1 #define degrees of freedom denominator 
    p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic 
    return f, p
#perform F-test
f_test(x, y)
(4.38712, 0.019127)
</b>
The F test statistic is <b>4.38712 </b>and the corresponding p-value is <b>0.019127</b>. Since this p-value is less than .05, we would reject the null hypothesis. This means we have sufficient evidence to say that the two population variances are <em>not </em>equal.
<h3>Notes</h3>
The F test statistic is calculated as s<sub>1</sub><sup>2</sup> / s<sub>2</sub><sup>2</sup>. By default,  numpy.var  calculates the population variance. To calculate the sample variance, we need to specify <b>ddof=1</b>.
The p-value corresponds to 1 – cdf of the F distribution with numerator degrees of freedom = n<sub>1</sub>-1 and denominator degrees of freedom = n<sub>2</sub>-1.
This function only works when the first sample variance is larger than the second sample variance. Thus, define the two samples in such a way that they work with the function.
<h3>When to Use the F-Test</h3>
The F-test is typically used to answer one of the following questions:
<b>1.</b> Do two samples come from populations with equal variances?
<b>2.</b> Does a new treatment or process reduce the variability of some current treatment or process?
<b>Related: </b> How to Perform an F-Test in R 
<h2><span class="orange">F-Test vs. T-Test: What’s the Difference?</span></h2>
Two statistical tests that students often get mixed up are the <b>F-Test </b>and the <b>T-Test</b>. This tutorial explains the difference between the two tests.
<h3>F-Test: The Basics</h3>
An <b>F-test </b>is used to test whether two population variances are equal. The null and alternative hypotheses for the test are as follows:
<b>H<sub>0</sub>:</b> σ<sub>1</sub><sup>2</sup> = σ<sub>2</sub><sup>2</sup> (the population variances are equal)
<b>H<sub>1</sub>:</b> σ<sub>1</sub><sup>2</sup> ≠ σ<sub>2</sub><sup>2</sup> (the population variances are <em>not</em> equal)
The F test statistic is calculated as s<sub>1</sub><sup>2</sup> / s<sub>2</sub><sup>2</sup>.
If the p-value of the test statistic is less than some significance level (common choices are 0.10, 0.05, and 0.01), then the null hypothesis is rejected.
<b>Example: F-Test for Equal Variances</b>
A researcher wants to know if the variance in height between two species of plants is the same. To test this, she collects a random sample of 20 plants from each population and calculates the sample variance for each sample.
The F test statistic turns out to be 4.38712 and the corresponding p-value is 0.0191. Since this p-value is less than .05, she rejects the null hypothesis of the F-Test. This means she has sufficient evidence to say that the variance in height between the two plant species is <em>not </em>equal.
<h3>T-Test: The Basics</h3>
A <b>two sample t-test</b> is used to test whether or not the means of two populations are equal.
A two-sample t-test always uses the following null hypothesis:
<b>H<sub>0</sub>:</b> μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
The alternative hypothesis can be either two-tailed, left-tailed, or right-tailed:
<b>H<sub>1</sub> (two-tailed): </b>μ<b><sub>1</sub></b> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>H<sub>1</sub> (left-tailed): </b>μ<sub>1</sub> &lt; μ<sub>2</sub> (population 1 mean is less than population 2 mean)
<b>H<sub>1</sub> (right-tailed): </b>μ<b><sub>1</sub></b>> μ<sub>2</sub> (population 1 mean is greater than population 2 mean)
The test statistic is calculated as:
<b>Test statistic:</b> (x<sub>1</sub> – x<sub>2</sub>)  /  s<sub>p</sub>(√1/n<sub>1</sub> + 1/n<sub>2</sub>)
where x<sub>1</sub> and x<sub>2</sub> are the sample means, n<sub>1 </sub>and n<sub>2 </sub>are the sample sizes, and where s<sub>p</sub> is calculated as:
<b>s<sub>p</sub></b> = √ (n<sub>1</sub>-1)s<sub>1</sub><sup>2</sup> +  (n<sub>2</sub>-1)s<sub>2</sub><sup>2</sup> /  (n<sub>1</sub>+n<sub>2</sub>-2)
where s<sub>1</sub><sup>2</sup> and s<sub>2</sub><sup>2</sup> are the sample variances.
If the p-value that corresponds to the test statistic t with (n<sub>1</sub>+n<sub>2</sub>-1) degrees of freedom is less than your chosen significance level (common choices are 0.10, 0.05, and 0.01) then you can reject the null hypothesis.
<b>Example: Two Sample t-test</b>
A researcher wants to know if the mean height between two species of plants is equal. To test this, she collects a random sample of 20 plants from each population and calculates the sample mean for each sample.
The t test statistic turns out to be 1.251 and the corresponding p-value is 0.2148. Since this p-value is not less than .05, she fails to reject the null hypothesis of the T-Test. This means she does not have sufficient evidence to say that the mean heights between these two plant species is different.
<h2>F-Test vs. T-Test: When to Use Each</h2>
We typically use an<b> F-test</b> to answer the following questions:
Do two samples come from populations with equal variances?
Does a new treatment or process reduce the variability of some current treatment or process?
And we typically use a <b>T-test</b> to answer the following questions:
Are two population means equal? (We use a  two sample t-test  to answer this)
Is one population mean equal to a certain value? (We use a  one sample t-test  to answer this)
<h2><span class="orange">How to Calculate F1 Score in Python (Including Example)</span></h2>
When using  classification models  in machine learning, a common metric that we use to assess the quality of the model is the <b>F1 Score</b>.
This metric is calculated as:
<b>F1 Score</b> = 2 * (Precision * Recall) / (Precision + Recall)
where:
<b>Precision</b>: Correct positive predictions relative to total positive predictions
<b>Recall</b>: Correct positive predictions relative to total actual positives
For example, suppose we use a logistic regression model to predict whether or not 400 different college basketball players get drafted into the NBA.
The following confusion matrix summarizes the predictions made by the model:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/fscore1.png">
Here is how to calculate the F1 score of the model:
Precision = True Positive / (True Positive + False Positive) = 120/ (120+70) = <b>.63157</b>
Recall = True Positive / (True Positive + False Negative) = 120 / (120+40) = <b>.75</b>
F1 Score = 2 * (.63157 * .75) / (.63157 + .75) = .<b>6857</b>
The following example shows how to calculate the F1 score for this exact model in Python.
<h3>Example: Calculating F1 Score in Python</h3>
The following code shows how to use the <b>f1_score()</b> function from the <b>sklearn</b> package in Python to calculate the F1 score for a given array of predicted values and actual values.
<b>import numpy as np
from sklearn.metrics import f1_score
#define array of actual classes
actual = np.repeat([1, 0], repeats=[160, 240])
#define array of predicted classes
pred = np.repeat([1, 0, 1, 0], repeats=[120, 40, 70, 170])
#calculate F1 score
f1_score(actual, pred)
0.6857142857142857
</b>
We can see that the F1 score is <b>0.6857</b>. This matches the value that we calculated earlier by hand.
<b>Note</b>: You can find the complete documentation for the <b>f1_score()</b> function  here .
<h3>Notes on Using F1 Scores</h3>
If you use F1 score to compare several models, the model with the highest F1 score represents the model that is best able to classify observations into classes.
For example, if you fit another logistic regression model to the data and that model has an F1 score of 0.75, that model would be considered better since it has a higher F1 score.
<h2><span class="orange">How to Calculate F1 Score in R (Including Example)</span></h2>
When using  classification models  in machine learning, a common metric that we use to assess the quality of the model is the <b>F1 Score</b>.
This metric is calculated as:
<b>F1 Score</b> = 2 * (Precision * Recall) / (Precision + Recall)
where:
<b>Precision</b>: Correct positive predictions relative to total positive predictions
<b>Recall</b>: Correct positive predictions relative to total actual positives
For example, suppose we use a logistic regression model to predict whether or not 400 different college basketball players get drafted into the NBA.
The following confusion matrix summarizes the predictions made by the model:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/fscore1.png">
Here is how to calculate the F1 score of the model:
Precision = True Positive / (True Positive + False Positive) = 120/ (120+70) = <b>.63157</b>
Recall = True Positive / (True Positive + False Negative) = 120 / (120+40) = <b>.75</b>
F1 Score = 2 * (.63157 * .75) / (.63157 + .75) = .<b>6857</b>
The following example shows how to calculate the F1 score for this exact model in R.
<h3>Example: Calculating F1 Score in R</h3>
The following code shows how to use the <b>confusionMatrix()</b> function from the <b>caret</b> package in R to calculate the F1 score (and other metrics) for a given logistic regression model:
<b>library(caret)
#define vectors of actual values and predicted values
actual &lt;- factor(rep(c(1, 0), times=c(160, 240)))
pred &lt;- factor(rep(c(1, 0, 1, 0), times=c(120, 40, 70, 170)))
#create confusion matrix and calculate metrics related to confusion matrix
confusionMatrix(pred, actual, mode = "everything", positive="1")
          Reference
Prediction   0   1
         0 170  40
         1  70 120                          
               Accuracy : 0.725            95% CI : (0.6784, 0.7682)
    No Information Rate : 0.6             
    P-Value [Acc > NIR] : 1.176e-07                                   Kappa : 0.4444                                    
 Mcnemar's Test P-Value : 0.005692                                  
            Sensitivity : 0.7500          
            Specificity : 0.7083          
         Pos Pred Value : 0.6316          
         Neg Pred Value : 0.8095          
              Precision : 0.6316           Recall : 0.7500               F1 : 0.6857          
             Prevalence : 0.4000          
         Detection Rate : 0.3000          
   Detection Prevalence : 0.4750          
      Balanced Accuracy : 0.7292                                    
       'Positive' Class : 1    </b>
We can see that the F1 score is <b>0.6857</b>. This matches the value that we calculated earlier by hand.
<b>Note</b>: We must specify <b>mode = “everything”</b> in order to get the F1 score to be displayed in the output.
If you use F1 score to compare several models, the model with the highest F1 score represents the model that is best able to classify observations into classes.
For example, if you fit another logistic regression model to the data and that model has an F1 score of 0.85, that model would be considered better since it has a higher F1 score.
<h2><span class="orange">F1 Score vs. Accuracy: Which Should You Use?</span></h2>
When using  classification models  in machine learning, two metrics we often use to assess the quality of the model are <b>F1 Score</b> and <b>Accuracy</b>.
For both metrics, the higher the value the better a model is able to classify observations into classes. 
However, each metric is calculated using a different formula and there are pros and cons to using each.
The following example shows how to calculate each metric in practice.
<h3>Example: Calculating F1 Score & Accuracy</h3>
Suppose we use a logistic regression model to predict whether or not 400 different college basketball players get drafted into the NBA.
The following confusion matrix summarizes the predictions made by the model:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/fscore1.png">
Here is how to calculate various metrics for the confusion matrix:
<b>Precision:</b> Correct positive predictions relative to total positive predictions
Precision = True Positive / (True Positive + False Positive)
Precision = 120 / (120 + 70)
Precision = <b>0.63</b>
<b>Recall:</b> Correct positive predictions relative to total actual positives
Recall = True Positive / (True Positive + False Negative)
Recall = 120 / (120 + 40)
Recall = <b>0.75</b>
<b>Accuracy:</b> Percentage of all correctly classified observations
Accuracy = (True Positive + True Negative) / (Total Sample Size)
Accuracy = (120 + 170) / (400)
Accuracy = <b>0.725</b>
<b>F1 Score:</b> Harmonic mean of precision and recall
F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
F1 Score = 2 * (0.63 * 0.75) / (0.63 + 0.75)
F1 Score = <b>0.685</b>
<h3>When to Use F1 Score vs. Accuracy</h3>
There are pros and cons to using F1 score and accuracy.
<b>Accuracy</b>:
<b>Pro</b>: Easy to interpret. If we say that a model is 90% accurate, we know that it correctly classified 90% of observations.
<b>Con</b>: Does not take into account how the data is distributed. For example, suppose 90% of all players do not get drafted into the NBA. If we have a model that simply predicts every player to not get drafted, the model would correctly predict the outcome for 90% of the players. This value seems high, but the model is actually unable to correctly predict any player who gets drafted.
<b>F1 Score</b>:
<b>Pro</b>: Takes into account how the data is distributed. For example, if the data is highly imbalanced (e.g. 90% of all players do not get drafted and 10% do get drafted) then F1 score will provide a better assessment of model performance.
<b>Con</b>: Harder to interpret. The F1 score is a blend of the precision and recall of the model, which makes it a bit harder to interpret.
As a rule of thumb:
We often use <b>accuracy</b> when the classes are balanced and there is no major downside to predicting false negatives.
We often use <b>F1 score</b> when the classes are imbalanced and there is a serious downside to predicting false negatives.
For example, if we use a logistic regression model to predict whether or not someone has cancer, false negatives are really bad (e.g. predicting that someone does not have cancer when they actually do) so F1 score will penalize models that have too many false negatives more than accuracy will.
<h2><span class="orange">What is Face Validity? (Definition & Examples)</span></h2>
The term <b>face validity</b> refers to the extent to which a test appears to measure what it claims to measure based on face value.
For example, a researcher may create a questionnaire that aims to measure depression levels in individuals. A colleague may then look over the questions and deem the questionnaire to be valid purely on face value.
In other words, on its surface the questionnaire seems to be constructed in such a way that it’s a good tool to use to measure depression levels.
Face validity is the most informal and subjective way to measure the validity of a test.
<h3>How to Measure Face Validity</h3>
In practice, we often measure face validity by asking multiple people to rate the validity of a test using a Likert scale.
For example, the potential responses could be:
<b>1. </b>The test is completely appropriate for measuring a certain construct.
<b>2. </b>The test is mostly appropriate.
<b>3.</b> The test is somewhat appropriate.
<b>4. </b>The test is neither appropriate nor inappropriate.
<b>5.</b> The test is somewhat inappropriate.
<b>6.</b> The test is mostly inappropriate.
<b>7.</b> The test is completely inappropriate.
There are three potential groups of people who could provide ratings for the face validity of a test:
<b>1. People who take the test.</b>
Individuals who actually take the test could provide ratings on face validity.
<b>2. People who work with the test in some way.</b>
Employers, university staff, coaching staff, or other individuals who work with the test in some way could provide ratings on face validity.
<b>3. Members of the general public who are interested in the test.</b>
Parents, teachers, school board members, city council members, etc. who are all interested in the test could provide ratings on face validity.
A test is considered to have high face validity if there is a high level of agreement among raters.
For example, if most raters say that the test or questionnaire is highly appropriate for measuring a certain construct then we would say that the test has high face validity.
<h3>Why Use Face Validity?</h3>
Face validity is a highly informal way to measure validity, but it can be useful for quickly ruling out sub-par research practices and techniques.
For example, if a questionnaire that aims to measure depression included questions such as:
“What is your favorite color?”
“What is your political party affiliation?”
Then we could quickly say that the questionnaire does not have face validity and likely doesn’t do a good job of measuring depression levels since the questions are irrelevant.
Thus, face validity offers a quick way to provide feedback on a test, questionnaire, or exam that doesn’t appear to measure the thing that it sets out to measure.
If a test <em>does</em> have face validity, we would likely go on to verify that it has more rigorous forms of validity like criterion validity, content validity, etc.
<h3>Other Types of Validity</h3>
The following tutorials provide brief explanations of other types of validity measurements:
 What is Criterion Validity? 
 What is Content Validity? 
 What is Concurrent Validity? 
 What is Predictive Validity? 
<h2><span class="orange">The Difference Between facet_wrap() and facet_grid() in R</span></h2>
The <b>facet_grid()</b> and <b>facet_wrap()</b> functions from the ggplot2 package can both be used to produce a grid of plots.
Here’s the main difference between the two functions:
The <b>facet_grid()</b> function will produce a grid of plots for each combination of variables that you specify, even if some plots are empty.
The <b>facet_wrap()</b> function will only produce plots for the combinations of variables that have values, which means <b>it won’t produce any empty plots</b>.
The following two examples illustrate the difference between these two functions, using the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'F', 'G', 'G', 'G', 'G'), points=c(8, 14, 20, 22, 25, 29, 30, 31), assists=c(10, 5, 5, 3, 8, 6, 9, 12))
#view data frame
df
  team position points assists
1    A        G      8      10
2    A        G     14       5
3    A        F     20       5
4    A        F     22       3
5    B        G     25       8
6    B        G     29       6
7    B        G     30       9
8    B        G     31      12</b>
<h3>Example 1: Use facet_grid() Function</h3>
The following code shows how to use <b>facet_grid()</b> to create a grid that displays a scatterplot of assists vs. points for each combination of team and position:
<b>library(ggplot2)
ggplot(df, aes(assists, points)) +
  geom_point() +
  facet_grid(position~team)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/facetgrid1.jpg"444">
Notice that a scatterplot is produced for every combination of <b>team</b> and <b>position</b>, even though no values exist in the original data frame for a team value of <b>B</b> and a position value of <b>F</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/facetgrid2.jpg"478">
This is how <b>facet_grid()</b> works: It will produce a plot for every combination of the variables that you specify, even if some plots are empty.
<h3>Example 2: Use facet_wrap() Function</h3>
The following code shows how to use <b>facet_wrap()</b> to create a grid that displays a scatterplot of assists vs. points for each combination of team and position that exists:
<b>library(ggplot2)
ggplot(df, aes(assists, points)) +
  geom_point() +
  facet_wrap(position~team)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/facetgrid3.jpg"457">
Notice that a scatterplot is only produced for the combinations of <b>team</b> and <b>position</b> that exist in the original data frame.
This means that no plot is created for the combination of team <b>B</b> and position <b>F</b> because no values exist in the original data frame for this particular combination.
This is how <b>facet_wrap()</b> works: It will never produce an empty plot.
<b>Note</b>: Refer to the ggplot2 documentation for a complete guide to the  facet_grid()  and  facet_wrap()  functions.
<h2><span class="orange">How to Use facet_wrap in R (With Examples)</span></h2>
The <b>facet_wrap()</b> function can be used to produce multi-panel plots in ggplot2.
This function uses the following basic syntax:
<b>library(ggplot2)
ggplot(df, aes(x_var, y_var)) +
  geom_point() +
  facet_wrap(vars(category_var))
</b>
The following examples show how to use this function with the built-in <b>mpg</b> dataset in R:
<b>#view first six rows of <em>mpg</em> dataset
head(mpg)
manufacturer  model  displ  year  cyl     trans  drvcty  hwy  fl  class
audi         a4    1.8  1999    4auto(l5)      f18    29   pcompact
audi         a4    1.8  1999    4manual(m5)    f21    29   pcompact
audi         a4    2.0  2008    4manual(m6)    f20    31   pcompact
audi         a4    2.0  2008    4auto(av)      f21    30   pcompact
audi         a4    2.8  1999    6auto(l5)      f16    26   pcompact
audi         a4    2.8  1999    6manual(m5)    f18    26   pcompact
</b>
<h3>Example 1: Basic facet_wrap() Function</h3>
The following code shows how to create several scatterplots in ggplot2 using <b>displ</b> as the x-axis variable, <b>hwy</b> as the y-axis variable, and <b>class</b> as the grouping variable:
<b>ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  facet_wrap(vars(class))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/facet1.png">
<h3>Example 2: Use Custom Labels</h3>
The following code shows how to use the <b>facet_wrap()</b> function with custom labels for the plot titles:
<b>#define custom labels
plot_names &lt;- c('2seater' = "2 Seater",
                'compact' = "Compact Vehicle",
                'midsize' = "Midsize Vehicle",
                'minivan' = "Minivan",
                'pickup' = "Pickup Truck",
                'subcompact' = "Subcompact Vehicle",
                'suv' = "Sport Utility Vehicle")
#use facet_wrap with custom plot labels
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  facet_wrap(vars(class), labeller = as_labeller(plot_names))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/facet2.png">
<h3>Example 3: Use Custom Scales</h3>
The following code shows how to use the <b>facet_wrap()</b> function with custom scales for each individual plot:
<b>#use facet_wrap with custom scales
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  facet_wrap(vars(class), scales='free')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/facet3.png">
<h3>Example 4: Use Custom Order</h3>
The following code shows how to use the <b>facet_wrap()</b> function with a custom order for the individual plots:
<b>#define order for plots
mpg &lt;- within(mpg, class &lt;- factor(class, levels=c('compact', '2seater', 'suv',                                   'subcompact', 'pickup',                                   'minivan', 'midsize')))
#use facet_wrap with custom order
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  facet_wrap(vars(class))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/facet4.png">
Notice that the plots appear in the exact order that we specified.
<h2><span class="orange">How to Convert Factor to Numeric in R (With Examples)</span></h2>
We can use the following syntax to convert a factor vector to a numeric vector in R:
<b>numeric_vector &lt;- as.numeric(as.character(factor_vector))
</b>
We must first convert the factor vector to a character vector, then to a numeric vector. This ensures that the numeric vector contains the actual numeric values instead of the factor levels.
This tutorial provides several examples of how to use this function in practice.
<h3>Example 1: Convert a Vector from Factor to Numeric</h3>
The following code shows how to convert a factor vector to a numeric vector:
<b>#define factor vector
factor_vector &lt;- factor(c(1, 5, 7, 8))
#convert factor vector to numeric vector
numeric_vector &lt;- as.numeric(as.character(factor_vector))
#view class
class(numeric_vector)
[1] "numeric"
</b>
<h3>Example 2: Convert a Column from Factor to Numeric</h3>
The following code shows how to convert a specific column in a data frame from factor to numeric:
<b>#create data frame
df &lt;- data.frame(a = factor(c(1, 5, 7, 8)), b = c(28, 34, 35, 36))
#convert column 'a' from factor to numeric
df$a &lt;- as.numeric(as.character(df$a))
#view new data frame
df
  a  b
1 1 28
2 5 34
3 7 35
4 8 36
#confirm class of numeric vector
class(df$a)
[1] "numeric"
</b>
<h3>Example 3: Convert Several Columns from Factor to Numeric</h3>
The following code shows how to convert all factor columns in a data frame from factor to numeric:
<b>#create data frame
df &lt;- data.frame(a = factor(c(1, 5, 7, 8)), b = factor(c(2, 3, 4, 5)), c = c('A', 'B', 'C', 'D'), d = c(45, 56, 54, 57))
#display classes of each column
sapply(df, class)
       a           b           c           d 
"factor"    "factor" "character"   "numeric" 
#identify all factor columns
x &lt;- sapply(df, is.factor)
#convert all factor columns to numeric
df[ , x] &lt;- as.data.frame(apply(df[ , x], 2, as.numeric))
#display classes of each column
sapply(df, class)
        a           b           c           d 
"numeric"   "numeric" "character"   "numeric" </b>
This code made the following changes to the data frame columns:
<b>Column a:</b> From factor to numeric
<b>Column b:</b> From factor to numeric
<b>Column c:</b> Unchanged (since it was a character)
<b>Column d:</b> Unchanged (since it was already numeric)
By using the  apply()  and  sapply()  functions, we were able to convert only the factor columns to numeric columns and leave all other columns unchanged.
<h2><span class="orange">What is a Factorial ANOVA? (Definition & Example)</span></h2>
A <b>factorial ANOVA</b> is any ANOVA (“analysis of variance”) that uses two or more independent factors and a single response variable. 
This type of ANOVA should be used whenever you’d like to understand how two or more factors affect a  response variable  and whether or not there is an interaction effect between the factors on the response variable.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/factorialANOVA1.png">
This tutorial provides several examples of situations where a factorial ANOVA may be used along with a step-by-step example of how to perform a factorial ANOVA.
<b>Note:</b> A  two-way ANOVA  is a type of factorial ANOVA.
<h2>Examples of Using a Factorial ANOVA</h2>
A factorial ANOVA could be used in each of the following situations.
<b>Example 1: Plant Growth</b>
A botanist wants to understand how sunlight exposure and watering frequency affect plant growth. She plants 100 seeds and lets them grow for three months under different conditions for sunlight exposure and watering frequency. After three months, she records the height of each plant.
In this case, she has the following variables:
<b>Response variable: </b>plant growth
<b>Factors: </b>sunlight exposure, watering frequency
And she would like to answer the following questions:
Does sunlight exposure affect plant growth?
Does watering frequency affect plant growth?
Is there an interaction effect between sunlight exposure and watering frequency?
She could use a factorial ANOVA for this analysis because she wants to understand how two factors affect a single response variable.
<b>Example 2: Exam Scores</b>
A professor wants to understand how class time and teaching method affect exam scores. He uses two different teaching methods and two different teaching times (early morning and early afternoon) and records the average exam scores of each student at the end of the semester.
In this case, he has the following variables:
<b>Response variable: </b>exam score
<b>Factors: </b>teaching method, teaching time
And he would like to answer the following questions:
Does teaching method affect exam scores?
Does teaching time affect exam scores?
Is there an interaction effect between teaching method and teach time?
He could use a factorial ANOVA for this analysis because he wants to understand how two factors affect a single response variable.
<b>Example 3: Annual Income</b>
An economist collects data to understand how education level (high school diploma, college degree, graduate degree), marital status (single, divorced, married), and region (North, East, South, West) affect annual income.
In this case, he has the following variables:
<b>Response variable: </b>annual income
<b>Factors: </b>education level, marital status, region
And he would like to answer the following questions:
Does education level affect income?
Does marital status affect income?
Does region affect income?
Is there an interaction effect between these three independent factors?
He could use a factorial ANOVA for this analysis because he wants to understand how three factors affect a single response variable.
<h2>Step-by-Step Example of a Factorial ANOVA</h2>
A botanist wants to know if sunlight exposure and watering frequency affect plant growth. She plants 40 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant.
The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova1.png">
We can see that five plants were grown under each combination of conditions.
For example, there were five plants grown with daily watering and no sunlight and their heights after two months were 4.8 inches, 4.4 inches, 3.2 inches, 3.9 inches, and 4.4 inches:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova2.png">
The botanist uses this data to perform a  factorial ANOVA in Excel  and ends up with the following output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova6-1.jpg"626">
The last table shows the result of the factorial ANOVA:
The p-value for the interaction between watering  frequency and sunlight exposure was <b>0.310898</b>. This is not statistically significant at alpha level 0.05.
The p-value for watering frequency was <b>0.975975</b>. This is not statistically significant at alpha level 0.05.
The p-value for sunlight exposure was <b>3.9E-8 (0.000000039)</b>. This is statistically significant at alpha level 0.05.
We can conclude that sunlight exposure is the only factor that has a statistically significant effect on plant growth.
We can also conclude that there is no interaction effect between sunlight exposure and watering frequency and that watering frequency does not have a statistically significant effect on plant growth.
<h2>Additional Resources</h2>
The following tutorials provide additional information about ANOVA models:
 An Introduction to the One-Way ANOVA 
 An Introduction to the Two-Way ANOVA 
 An Introduction to the Repeated Measures ANOVA 
 The Differences Between ANOVA, ANCOVA, MANOVA, and MANCOVA 
<h2><span class="orange">What is the Family-wise Error Rate?</span></h2>
In a  hypothesis test , there is always a type I error rate that tells us the probability of rejecting a null hypothesis that is actually true. In other words, it’s the probability of getting a “false positive”, i.e. when we claim there is a statistically significant effect, but there actually isn’t.
When we perform one hypothesis test, the type I error rate is equal to the significance level (α), which is commonly chosen to be 0.01, 0.05, or 0.10. However, when we conduct multiple hypothesis tests at once, the probability of getting a false positive increases.
For example, imagine that we roll a 20-sided dice. The probability that the dice lands on a “1” is just 5%. But if we roll two of these dice at once, the probability that one of the dice will land on a “1” increases to 9.75%. If we roll five dice at once, the probability increases to 22.6%. 
The more dice we roll, the higher the probability that one of the dice will land on a 1. Similarly, if we conduct several hypothesis tests at once using a significance level of .05, the probability that we get a false positive increases to beyond 0.05.
<h3>How to Estimate the Family-wise Error Rate</h3>
The formula to estimate the family-wise error rate is as follows:
<b>Family-wise error rate = 1 – (1-α)<sup>n</sup></b>
where:
<b>α:</b> The significance level for a single hypothesis test
<b>n:</b> The total number of tests
For example, suppose we conduct 5 different comparisons using an alpha level of α = .05. The family-wise error rate would be calculated as:
Family-wise error rate = 1 – (1-α)<sup>c  </sup>= 1 – (1-.05)<sup>5 </sup>= <b>0.2262</b>.
In other words, the probability of getting a type I error on at least one of the hypothesis tests is over 22%!
<h3>How to Control the Family-wise Error Rate</h3>
There are several methods that can be used to control the family-wise error rate, including:
<b>1. The Bonferroni Correction.</b>
Adjust the α value used to assess significance such that:
<b>α<sub>new</sub></b> = α<sub>old </sub>/ n
For example, if we conduct 5 different comparisons using an alpha level of α = .05, then using the Bonferroni Correction our new alpha level would be:
α<sub>new</sub> = α<sub>old </sub>/ n = .05 / 5 = <b>.01</b>.
<b>2. The Sidak Correction.</b>
Adjust the α value used to assess significance such that:
<b>α<sub>new</sub></b> = 1 – (1-α<sub>old</sub>)<sup>1/n</sup>
For example, if we conduct 5 different comparisons using an alpha level of α = .05, then using the Sidak Correction our new alpha level would be:
α<sub>new</sub> = 1 – (1-α<sub>old</sub>)<sup>1/n</sup> = 1 – (1-.05)<sup>1/5</sup> = <b>.010206</b>.
<b>3. The Bonferroni-Holm Correction.</b>
This procedure works as follows:
<ol>
Use the Bonferroni Correction to calculate α<sub>new</sub> = α<sub>old </sub>/ n.
Perform each hypothesis test and order the p-values from all tests from smallest to largest.
If the first p-value is greater than or equal to α<sub>new</sub>, stop the procedure. No p-values are significant.
If the first p-value is less than α<sub>new</sub>, then it is significant. Now compare the second p-value to α<sub>new</sub>. If it’s greater than or equal to α<sub>new</sub>, stop the procedure. No further p-values are significant.
</ol>
By using one of these corrections to the significance level, we can dramatically reduce the probability of committing a type I error among a family of hypothesis tests.
<h2><span class="orange">How to Use fig.add_subplot in Matplotlib</span></h2>
You can use the following basic syntax to create subplots in Matplotlib:
<b>import matplotlib.pyplot as plt
#define figure
fig = plt.figure()
#add first subplot in layout that has 3 rows and 2 columns
fig.add_subplot(321)
#add fifth subplot in layout that has 3 rows and 2 columns
fig.add_subplot(325)
...</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Add Subplots with Even Layout</h3>
The following code shows how to create six subplots in a layout that has 3 rows and 2 columns:
<b>import matplotlib.pyplot as plt
#define figure
fig = plt.figure()
#add subplots
fig.add_subplot(321).set_title('321')
fig.add_subplot(322).set_title('322')
fig.add_subplot(323).set_title('323')
fig.add_subplot(324).set_title('324')
fig.add_subplot(325).set_title('325')
fig.add_subplot(326).set_title('326')
#display plots
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/fig1.png">
Notice that the result is six subplots displayed in a layout that has 3 rows and 2 columns.
<h3>Example 2: Add Subplots with Uneven Layout</h3>
The following code shows how to create four subplots in the following manner:
Three of the plots are created in a grid with 3 rows and 2 columns.
The fourth plot is created in a grid with 1 row and 2 columns.
<b>import matplotlib.pyplot as plt
#define figure
fig = plt.figure()
#add subplots
fig.add_subplot(321).set_title('321')
fig.add_subplot(323).set_title('323')
fig.add_subplot(325).set_title('325')
fig.add_subplot(122).set_title('122')
#display plots
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/fig2.png">
The end result is three subplots displayed in a 3×2 grid while the last subplot is displayed in a 1×2 grid.
<h2><span class="orange">How to Use file.path() Function in R (With Example)</span></h2>
The <b>file.path()</b> function in base R offers a convenient way to define a file path.
This function uses the following basic syntax:
<b>file.path(“C:”, “Users”, “bob”, “Data_Science_Documents”, fsep=”\\”)</b>
The following example shows how to use this function in practice.
<h2>Example: How to Use file.path() Function in R</h2>
Suppose I would like to set the following directory as my working directory in R:
C:\Users\bob\Data_Science_Documents
I can use the following syntax with the <b>file.path()</b> function to do so:
<b>#define file path
path &lt;- file.path("C:", "Users", "bob", "Data_Science_Documents", fsep="\\")
#view file path
path
[1] "C:\\Users\\bob\\Data_Science_Documents"
#set path as working directory
setwd(path)
</b>
The working directory is now set to the following location:
C:\Users\bob\Data_Science_Documents
I can confirm this by using the <b>getwd()</b> function to get the current working directory:
<b>#get path of current working directory
getwd()
[1] "C:/Users/bob/Data_Science_Documents"
</b>
It’s worth noting that you could also manually type out the slashes in the file path location to set the working directory.
However, the <b>file.path()</b> function offers an easier way to define a file path with fewer characters.
The<b> file.path()</b> function also offers more readable code and is a function included in base R, so you don’t have to load any external packages to use it.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Check if a Package is Installed in R 
 How to Check if a Directory Exists in R 
 How to Load Multiple Packages in R 
<h2><span class="orange">How to Fill NA Values for Multiple Columns in Pandas</span></h2>
The pandas  fillna()  function is useful for filling in missing values in columns of a pandas DataFrame.
This tutorial provides several examples of how to use this function to fill in missing values for multiple columns of the following pandas DataFrame:
<b>import pandas as pd
import numpy as np
#create DataFrame
df = pd.DataFrame({'team': ['A', np.nan, 'B', 'B', 'B', 'C', 'C', 'C'],   'points': [25, np.nan, 15, np.nan, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, np.nan, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#view DataFrame
print(df)
  team  points  assists  rebounds
0    A    25.0      5.0        11
1  NaN     NaN      7.0         8
2    B    15.0      7.0        10
3    B     NaN      9.0         6
4    B    19.0     12.0         6
5    C    23.0      9.0         5
6    C    25.0      NaN         9
7    C    29.0      4.0        12
</b>
<h3>Example 1: Fill in Missing Values of All Columns</h3>
The following code shows how to fill in missing values with a zero for <em>all</em> columns in the DataFrame:
<b>#replace all missing values with zero
df.fillna(value=0, inplace=True)
#view DataFrame
print(df) 
  team  points  assists  rebounds
0    A    25.0      5.0        11
1    0     0.0      7.0         8
2    B    15.0      7.0        10
3    B     0.0      9.0         6
4    B    19.0     12.0         6
5    C    23.0      9.0         5
6    C    25.0      0.0         9
7    C    29.0      4.0        12</b>
<h3>Example 2: Fill in Missing Values of Multiple Columns</h3>
The following code shows how to fill in missing values with a zero for just the points and assists columns in the DataFrame:
<b>#replace missing values in points and assists columns with zero
df[['points', 'assists']] = df[['points', 'assists']].fillna(value=0)
#view DataFrame
print(df) 
  team  points  assists  rebounds
0    A    25.0      5.0        11
1  NaN     0.0      7.0         8
2    B    15.0      7.0        10
3    B     0.0      9.0         6
4    B    19.0     12.0         6
5    C    23.0      9.0         5
6    C    25.0      0.0         9
7    C    29.0      4.0        12
</b>
<h3>Example 3: Fill in Missing Values of Multiple Columns with Different Values</h3>
The following code shows how to fill in missing values in three different columns with three different values:
<b>#replace missing values in three columns with three different values
df.fillna({'team':'Unknown', 'points': 0, 'assists': 'zero'}, inplace=True)
#view DataFrame
print(df)
      team  points assists  rebounds
0        A    25.0       5        11
1  Unknown     0.0       7         8
2        B    15.0       7        10
3        B     0.0       9         6
4        B    19.0      12         6
5        C    23.0       9         5
6        C    25.0    zero         9
7        C    29.0       4        12
</b>
Notice that each of the missing values in the three columns were replaced with some unique value.
<h2><span class="orange">How to Filter a data.table in R (With Examples)</span></h2>
You can use the following methods to filter the rows of a data.table in R:
<b>Method 1: Filter for Rows Based on One Condition</b>
<b>dt[col1 == 'A', ]
</b>
<b>Method 2: Filter for Rows that Contain Value in List</b>
<b>dt[col1 %in% c('A', 'C'), ]
</b>
<b>Method 3: Filter for Rows where One of Several Conditions is Met</b>
<b>dt[col1 == 'A' | col2 &lt; 10, ]
</b>
<b>Method 4: Filter for Rows where Multiple Conditions are Met</b>
<b>dt[col1 == 'A' & col2 &lt; 10, ]</b>
The following examples show how to use each method in practice with the following data.table in R:
<b>library(data.table)
#create data table
dt &lt;- data.table(team=c('A', 'A', 'A', 'B', 'C'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data table
dt
   team points assists rebounds
1:    A     99      33       30
2:    A     90      28       28
3:    A     86      31       24
4:    B     88      39       24
5:    C     95      34       28</b>
<h2>Example 1: Filter for Rows Based on One Condition</h2>
The following code shows how to filter for only the rows where the value in the <b>team</b> column is equal to ‘A’:
<b>#filter for rows where team is A</b>
<b>dt[team == 'A', ]
   team points assists rebounds
1:    A     99      33       30
2:    A     90      28       28
3:    A     86      31       24
</b>
<h2>Example 2: Filter for Rows that Contain Value in List</h2>
The following code shows how to filter for only the rows where the value in the <b>team</b> column is equal to ‘A’ or ‘C’:
<b>#filter for rows where team is A or C
dt[team %in% c('A', 'C'), ]
   team points assists rebounds
1:    A     99      33       30
2:    A     90      28       28
3:    A     86      31       24
4:    C     95      34       28
</b>
<b>Related:</b>  How to Use %in% Operator in R (With Examples) 
<h2>Example 3: Filter for Rows where One of Several Conditions is Met</h2>
The following code shows how to filter for only the rows where the value in the <b>team</b> column is equal to ‘A’ <em>or</em> the value in the <b>points</b> column is less than 90:
<b>#filter for rows where team is A or points &lt; 90
dt[team == 'A' | points &lt; 90, ]
   team points assists rebounds
1:    A     99      33       30
2:    A     90      28       28
3:    A     86      31       24
4:    B     88      39       24</b>
<b>Note</b>: The <b>|</b> operator stands for “OR” in R.
<h2>Example 4: Filter for Rows where Multiple Conditions are Met</h2>
The following code shows how to filter for only the rows where the value in the <b>team</b> column is equal to ‘A’ <i>and </i>the value in the <b>points</b> column is less than 90:
<b>#filter for rows where team is A and points &lt; 90
dt[team == 'A' & points &lt; 90, ]
   team points assists rebounds
1:    A     86      31       24</b>
<b>Note</b>: The <b>& </b>operator stands for “AND” in R.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter a Vector in R 
 How to Remove Rows with Any Zeros in R 
 How to Remove Empty Rows from Data Frame in R 
<h2><span class="orange">How to Filter Data Horizontally in Excel (With Example)</span></h2>
You can use the following syntax to filter cells that are arranged horizontally in Excel:
<b>=FILTER(B1:G4, B2:G2 = "value")
</b>
This particular formula will return the columns in the range<b> B1:G4</b> where the cells in the range<b> B2:G2</b> are equal to “value.”
The following examples show how to use this syntax with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/hor1.jpg"561">
<h2>Example 1: Filter Data Horizontally Based on String</h2>
We can type the following formula into cell <b>B8 </b>to filter the data to only show columns where the value in the <b>Conference</b> row is equal to “West”:
<b>=FILTER(B1:G4, B2:G2 = "West")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/hor2-1.jpg">
Notice that only the columns that contain “West” in the <b>Conference</b> row are returned.
<h2>Example 2: Filter Data Horizontally Based on Numeric Value</h2>
We can type the following formula into cell <b>B8 </b>to filter the data to only show columns where the value in the <b>Points</b> row is greater than 100:
<b>=FILTER(B1:G4, B3:G3 > 100)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/hor3-1.jpg"616">
Notice that only the columns with a value greater than 100 in the <b>Points </b>row are returned.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: How to Delete Rows with Specific Text 
 Excel: How to Check if Cell Contains Partial Text 
 Excel: How to Check if Cell Contains Text from List 
<h2><span class="orange">How to Filter a Pandas DataFrame by Column Values</span></h2>
The simplest way to filter a pandas DataFrame by column values is to use the  query  function.
This tutorial provides several examples of how to use this function in practice with the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'B', 'B', 'C'],   'points': [25, 12, 15, 14, 19],   'assists': [5, 7, 7, 9, 12],   'rebounds': [11, 8, 10, 6, 6]})
#view DataFrame 
df
        teampointsassistsrebounds
0A25511
1A1278
2B15710
3B1496
4C19126</b>
<h3>Example 1: Filter Based on One Column</h3>
The following code shows how to filter the rows of the DataFrame based on a single value in the “points” column:
<b>df.query('points == 15')
     team   points    assists  rebounds
2    B      15        7        10
</b>
<h3>Example 2: Filter Based on Multiple Columns</h3>
The following code shows how to filter the rows of the DataFrame based on several values in different columns:
<b>#return rows where points is equal to 15 or 14
df.query('points == 15 | points == 14')
     team   points    assists  rebounds
2    B      15        7        10
3    B      14        9         6
#return rows where points is greater than 13 and rebounds is greater than 6
df.query('points > 13 & points > 6')
     team   points    assists  rebounds
0    A      25        5        11
2    B      15        7        10
</b>
<h3>Example 3: Filter Based on Values in a List</h3>
The following code shows how to filter the rows of the DataFrame based on values in a list
<b>#define list of values
value_list = [12, 19, 25]
#return rows where points is in the list of values
df.query('points in @value_list')
     team  points   assists    rebounds
0    A      25        5        11
1    A      12        7         8
4    C      19       12         6
#return rows where points is <em>not</em> in the list of values
df.query('points not in @value_list') 
     team   points    assists  rebounds
2    B      15        7        10
3    B      14        9         6
</b>
<h2><span class="orange">How to Filter Rows in R</span></h2>
Often you may be interested in subsetting a data frame based on certain conditions in R. Fortunately this is easy to do using the  filter()  function from the  dplyr  package.
<b>library(dplyr)</b>
This tutorial explains several examples of how to use this function in practice using the built-in dplyr dataset called <b>starwars</b>:
<b>#view first six rows of starwars dataset
head(starwars)
# A tibble: 6 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 Luke~    172    77 blond      fair       blue            19   male   Tatooine 
2 C-3PO    167    75 &lt;NA>       gold       yellow         112   &lt;NA>   Tatooine 
3 R2-D2     96    32 &lt;NA>       white, bl~ red             33   &lt;NA>   Naboo    
4 Dart~    202   136 none       white      yellow          41.9 male   Tatooine 
5 Leia~    150    49 brown      light      brown           19   female Alderaan 
6 Owen~    178   120 brown, gr~ light      blue            52   male   Tatooine 
# ... with 4 more variables: species , films , vehicles ,
#   starships 
</b>
<h3>Example 1: Filter Rows Equal to Some Value</h3>
The following code shows how to filter the dataset for rows where the variable ‘species’ is equal to Droid.
<b>starwars %>% filter(species == 'Droid')
# A tibble: 5 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 C-3PO    167    75        gold       yellow           112    Tatooine 
2 R2-D2     96    32        white, bl~ red               33    Naboo    
3 R5-D4     97    32        white, red red               NA    Tatooine 
4 IG-88    200   140 none       metal      red               15 none        
5 BB8       NA    NA none       none       black             NA none        
# ... with 4 more variables: species , films , vehicles ,
#   starships 
</b>
We can see that 5 rows in the dataset met this condition, as indicated by <em>#A tibble: 5 x 13</em>.
<h3>Example 2: Filter Rows Using ‘And’</h3>
We can also filter for rows where the species is Droid <b>and </b>the eye color is red:
<b>starwars %>% filter(species == 'Droid' & eye_color == 'red')
# A tibble: 3 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 R2-D2     96    32 &lt;NA>       white, bl~ red               33 &lt;NA>  Naboo    
2 R5-D4     97    32 &lt;NA>       white, red red               NA &lt;NA>  Tatooine 
3 IG-88    200   140 none       metal      red               15 none  &lt;NA>      
# ... with 4 more variables: species , films , vehicles ,
#   starships 
</b>
We can see that 3 rows in the dataset met this condition.
<h3>Example 3: Filter Rows Using ‘Or’</h3>
We can also filter for rows where the species is Droid <b>or </b>the eye color is red:
<b>starwars %>% filter(species == 'Droid' | eye_color == 'red')
# A tibble: 7 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 C-3PO    167    75 &lt;NA>       gold       yellow           112 &lt;NA>   Tatooine 
2 R2-D2     96    32 &lt;NA>       white, bl~ red               33 &lt;NA>   Naboo    
3 R5-D4     97    32 &lt;NA>       white, red red               NA &lt;NA>   Tatooine 
4 IG-88    200   140 none       metal      red               15 none   &lt;NA>     
5 Bossk    190   113 none       green      red               53 male   Trandosha
6 Nute~    191    90 none       mottled g~ red               NA male   Cato Nei~
7 BB8       NA    NA none       none       black             NA none   &lt;NA>     
# ... with 4 more variables: species , films , vehicles ,
#   starships  
</b>
We can see that 7 rows in the dataset met this condition.
<h3>Example 4: Filter Rows with Values in a List</h3>
We can also filter for rows where the eye color is in a list of colors:
<b>starwars %>% filter(eye_color %in% c('blue', 'yellow', 'red'))
# A tibble: 35 x 13
   name  height  mass hair_color skin_color eye_color birth_year gender               
 1 Luke~    172    77 blond      fair       blue            19   male  
 2 C-3PO    167    75 &lt;NA>       gold       yellow         112   &lt;NA> 
 3 R2-D2     96    32 &lt;NA>       white, bl~ red             33   &lt;NA>  
 4 Dart~    202   136 none       white      yellow          41.9 male  
 5 Owen~    178   120 brown, gr~ light      blue            52   male  
 6 Beru~    165    75 brown      light      blue            47   female
 7 R5-D4     97    32 &lt;NA>       white, red red             NA   &lt;NA> 
 8 Anak~    188    84 blond      fair       blue            41.9 male  
 9 Wilh~    180    NA auburn, g~ fair       blue            64   male  
10 Chew~    228   112 brown      unknown    blue           200   male  
# ... with 25 more rows, and 5 more variables: homeworld , species ,
#   films , vehicles , starships  
</b>
We can see that 35 rows in the dataset had an eye color of blue, yellow, or red.
<b>Related: </b> How to Use %in% Operator in R (With Examples) 
<h3>Example 5: Filter Rows Using Less Than or Greater Than</h3>
We can also filter rows using less than or greater than operations on numeric variables:
<b>#find rows where height is greater than 250
starwars %>% filter(height > 250)
# A tibble: 1 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 Yara~    264    NA none       white      yellow            NA male   Quermia  
# ... with 4 more variables: species , films , vehicles ,
#   starships   
#find rows where height is between 200 and 220
starwars %>% filter(height > 200 & height &lt; 220)
# A tibble: 5 x 13
  name  height  mass hair_color skin_color eye_color birth_year gender homeworld                   
1 Dart~    202   136 none       white      yellow          41.9 male   Tatooine 
2 Rugo~    206    NA none       green      orange          NA   male   Naboo    
3 Taun~    213    NA none       grey       black           NA   female Kamino   
4 Grie~    216   159 none       brown, wh~ green, y~       NA   male   Kalee    
5 Tion~    206    80 none       grey       black           NA   male   Utapau   
# ... with 4 more variables: species , films , vehicles ,
#   starships 
#find rows where height is above the average height
starwars %>% filter(height > mean(height, na.rm = TRUE))
# A tibble: 51 x 13
   name  height  mass hair_color skin_color eye_color birth_year gender               
 1 Dart~    202   136 none       white      yellow          41.9 male  
 2 Owen~    178   120 brown, gr~ light      blue            52   male  
 3 Bigg~    183    84 black      light      brown           24   male  
 4 Obi-~    182    77 auburn, w~ fair       blue-gray       57   male  
 5 Anak~    188    84 blond      fair       blue            41.9 male  
 6 Wilh~    180    NA auburn, g~ fair       blue            64   male  
 7 Chew~    228   112 brown      unknown    blue           200   male  
 8 Han ~    180    80 brown      fair       brown           29   male  
 9 Jabb~    175  1358 &lt;NA>       green-tan~ orange         600   herma~
10 Jek ~    180   110 brown      fair       blue            NA   male  
# ... with 41 more rows, and 5 more variables: homeworld , species ,
#   films , vehicles , starships 
</b>
<em>You can find the complete documentation for the <b>filter()</b> function  here .</em>
<h2><span class="orange">How to Filter Rows that Contain a Certain String Using dplyr</span></h2>
Often you may want to filter rows in a data frame in R that contain a certain string. Fortunately this is easy to do using the <b>filter() </b>function from the  dplyr  package and the <b>grepl() </b>function in Base R.
This tutorial shows several examples of how to use these functions in practice using the following data frame:
<b>#create data frame
df &lt;- data.frame(player = c('P Guard', 'S Guard', 'S Forward', 'P Forward', 'Center'), points = c(12, 15, 19, 22, 32), rebounds = c(5, 7, 7, 12, 11))
#view data frame
df
     player points rebounds
1   P Guard     12        5
2   S Guard     15        7
3 S Forward     19        7
4 P Forward     22       12
5    Center     32       11
</b>
<h3>Example 1: Filter Rows that Contain a Certain String</h3>
The following code shows how to filter rows that contain a certain string:
<b>#load dplyr package
library(dplyr)
#filter rows that contain the string 'Guard' in the player column
df %>% filter(grepl('Guard', player))
   player points rebounds
1 P Guard     12        5
2 S Guard     15        7</b>
<b>Related: </b> Comparing grep() vs. grepl() in R: What’s the Difference? 
<h3>Example 2: Filter Rows that Contain at Least One String</h3>
The following code shows how to filter rows that contain ‘Guard’ or ‘Forward’ in the player column:
<b>#filter rows that contain 'Guard' or 'Forward' in the player column
df %>% filter(grepl('Guard|Forward', player))
     player points rebounds
1   P Guard     12        5
2   S Guard     15        7
3 S Forward     19        7
4 P Forward     22       12</b>
The following code shows how to filter rows that contain ‘P’ or ‘Center’ in the player column:
<b>#filter rows that contain 'P' or 'Center' in the player column
df %>% filter(grepl('P|Center', player))
     player points rebounds
1   P Guard     12        5
2 P Forward     22       12
3    Center     32       11</b>
<h3>Example 3: Filter Out Rows that Contain a Certain String</h3>
The following code shows how to filter out (i.e. remove) rows that contain ‘Guard’ in the player column:
<b>#filter out rows that contain 'Guard' in the player column
df %>% filter(!grepl('Guard', player))
     player points rebounds
1 S Forward     19        7
2 P Forward     22       12
3    Center     32       11</b>
The following code shows how to filter out (i.e. remove) rows that contain ‘Guard’ or ‘Center’ in the player column:
<b>#filter out rows that contain 'Guard' or 'Center' in the player column
df %>% filter(!grepl('Guard|Center', player))
     player points rebounds
1 S Forward     19        7
2 P Forward     22       12</b>
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">How to Filter a Vector in R (4 Examples)</span></h2>
You can use the following methods to filter a vector in R:
<b>Method 1: Filter for Elements Equal to Some Value</b>
<b>#filter for elements equal to 8
x[x == 8]
</b>
<b>Method 2: Filter for Elements Based on One Condition</b>
<b>#filter for elements less than 8
x[x &lt; 8]</b>
<b>Method 3: Filter for Elements Based on Multiple Conditions</b>
<b>#filter for elements less than 8 <em>or</em> greater than 12
x[(x &lt; 8) | (x > 12)]</b>
<b>Method 4: Filter for Elements in List</b>
<b>#filter for elements equal to 2, 6, or 12
x[x %in% c(2, 6, 12)]</b>
The following examples show how to use each method in practice.
<h2>Example 1: Filter for Elements Equal to Some Value</h2>
The following code shows how to filter a vector in R for elements that are <b>equal</b> to 8:
<b>#create vector
x &lt;- c(1, 2, 2, 4, 6, 8, 8, 8, 12, 15)
#filter for elements equal to 8
x[x == 8]
[1] 8 8 8
</b>
We can just as easily filter for elements that are <b>not equal</b> to 8:
<b>#create vector
x &lt;- c(1, 2, 2, 4, 6, 8, 8, 8, 12, 15)
#filter for elements not equal to 8
x[x != 8]
[1]  1  2  2  4  6 12 15
</b>
<h2>Example 2: Filter for Elements Based on One Condition</h2>
The following code shows how to filter a vector in R for elements that are <b>less than</b> 8:
<b>#create vector
x &lt;- c(1, 2, 2, 4, 6, 8, 8, 8, 12, 15)
#filter for elements less than 8
x[x &lt; 8]
[1] 1 2 2 4 6
</b>
<h2>Example 3: Filter for Elements Based on Multiple Conditions</h2>
The following code shows how to filter a vector in R for elements that are <b>less than</b> 8 or <b>greater than</b> 12:
<b>#create vector
x &lt;- c(1, 2, 2, 4, 6, 8, 8, 8, 12, 15)
#filter for elements less than 8
x[(x &lt; 8) | (x > 12)]
[1]  1  2  2  4  6 15</b>
<h2>Example 4: Filter for Elements in List</h2>
The following code shows how to filter a vector in R for elements that are equal to values in a list:
<b>#create vector
x &lt;- c(1, 2, 2, 4, 6, 8, 8, 8, 12, 15)
#filter for elements equal to 2, 6, or 12
x[x %in% c(2, 6, 12)]
[1]  2  2  6 12
</b>
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Delete Data Frames in R 
 How to Delete Multiple Columns in R 
 How to Append Values to a Vector Using a Loop in R 
<h2><span class="orange">How to Find Area to the Left of Z-Score (With Examples)</span></h2>
In statistics, a  z-score  tells us how many standard deviations away a given value lies from a population mean.
We use the following formula to calculate a z-score for a given value:
<b>z = (x – μ) / σ</b>
where:
<b>x</b>: Individual data value
<b>μ</b>: Mean of population
<b>σ</b>: Standard deviation of population
To find the area under a normal distribution that lies to the left of a given z-score, we can use one of two methods:
<b>1.</b> Use the  z table .
<b>2.</b> Use the  Area to the Left of Z-Score Calculator .
The following examples show how to use each of these methods in practice.
<h3>Example 1: Area to the Left of Negative Z-Score</h3>
The weight of a certain species of turtles is normally distributed with mean μ = 300 pounds and standard deviation σ = 15 pounds. Approximately what percentage of turtles weigh less than 284 pounds?
The z-score for a weight of 284 pounds would be calculated as z = (284 – 300)  / 15 = <b>-1.07</b>
We can use one of two methods to find the area to the left of this z-score:
<b>Method 1: Use z table.</b>
To find the area to the left of the z-score, we can simply look up the value <b>-1.07 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arealeft2.png">
The area to the left of z = -1.07 is <b>0.1423</b>.
Applied to our scenario, this means approximately <b>14.23% </b>of turtles weight less than 284 pounds.
<b>Method 2: Use Area to the Left of Z-Score Calculator</b>
We can also use the  Area to the Left of Z-Score Calculator  to find that the area to the left of z = -1.07 is <b>0.1423</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arealeft3.png">
<h3>Example 2: Area to the Left of Positive Z-Score</h3>
The scores on a certain exam are normally distributed with mean μ = 85 and standard deviation σ = 8. Approximately what percentage of students score less than 87 on the exam?
The z-score for an exam score of 87 would be calculated as z = (87 – 85)  / 8 = <b>0.25</b>
We can use one of two methods to find the area to the left of this z-score:
<b>Method 1: Use z table.</b>
To find the area to the left of the z-score, we can simply look up the value <b>0.25 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable1.png">
The area to the left of z = 0.25 is <b>0.5987</b>. Applied to our scenario, this means approximately <b>59.87% </b>of students score less than 87 on this exam.
<b>Method 2: Use Area to the Left of Z-Score Calculator</b>
We can also use the  Area to the Left of Z-Score Calculator  to find that the area to the left of z = 0.25 is <b>0.5987</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arealeft1.png">
<h2><span class="orange">How to Find Area to the Right of Z-Score (With Examples)</span></h2>
In statistics, a  z-score  tells us how many standard deviations away a given value lies from a population mean.
We use the following formula to calculate a z-score for a given value:
<b>z = (x – μ) / σ</b>
where:
<b>x</b>: Individual data value
<b>μ</b>: Mean of population
<b>σ</b>: Standard deviation of population
To find the area under a normal distribution that lies to the right of a given z-score, we can use one of two methods:
<b>1.</b> Use the  z table .
<b>2.</b> Use the  Area to the Right of Z-Score Calculator .
The following examples show how to use each of these methods in practice.
<h3>Example 1: Area to the Right of Negative Z-Score</h3>
The weight of a certain species of dolphins is normally distributed with mean μ = 300 pounds and standard deviation σ = 15 pounds. Approximately what percentage of dolphins weigh more than 284 pounds?
The z-score for a weight of 284 pounds would be calculated as z = (284 – 300)  / 15 = <b>-1.07</b>
We can use one of two methods to find the area to the right of this z-score:
<b>Method 1: Use z table.</b>
To find the area to the right of the z-score, we can simply look up the value <b>-1.07 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arealeft2.png">
This represents the area to the left of z = -1.07. Thus, the area to the right is calculated as 1 – 0.1423 =  is <b>0.8577</b>.
Applied to our scenario, this means approximately <b>85.77% </b>of dolphins weight more than 284 pounds.
<b>Method 2: Use Area to the Right of Z-Score Calculator</b>
We can also use the  Area to the Right of Z-Score Calculator  to find that the area to the right of z = -1.07 is <b>0.8577</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arearight1.png">
<h3>Example 2: Area to the Right of Positive Z-Score</h3>
The scores on a certain exam are normally distributed with mean μ = 85 and standard deviation σ = 8. Approximately what percentage of students score greater than 87 on the exam?
The z-score for an exam score of 87 would be calculated as z = (87 – 85)  / 8 = <b>0.25</b>
We can use one of two methods to find the area to the right of this z-score:
<b>Method 1: Use z table.</b>
To find the area to the right of the z-score, we can simply look up the value <b>0.25 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable1.png">
The represents the area to the left of z = 0.25. Thus, the area to the right is calculated as 1 – 0.5987 = <b>0.4013</b>. Applied to our scenario, this means approximately <b>40.13% </b>of students score greater than 87 on this exam.
<b>Method 2: Use Area to the Right of Z-Score Calculator</b>
We can also use the  Area to the Right of Z-Score Calculator  to find that the area to the right of z = 0.25 is <b>0.4013</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/arearight2.png">
<h2><span class="orange">How to Find the Median of a Box Plot (With Examples)</span></h2>
A <b>box plot</b> is a type of plot that displays the five number summary of a dataset, which includes:
The minimum value
The first quartile (the 25th percentile)
The median value
The third quartile (the 75th percentile)
The maximum value
To make a box plot, we first draw a box from the first to the third quartile.
Then we draw a vertical line at the median.
Lastly, we draw “whiskers” from the quartiles to the minimum and maximum value.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/iqr_box3.png">
To find the <b>median </b>of a box plot, we simply need to identify the value located at the vertical line inside of the box.
The following examples show how to find the median of a box plot in practice.
<h2>Example 1: Exam Scores</h2>
The following box plot shows the distribution of scores on a certain college exam.
What is the median of the exam scores?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox2.jpg"466">
To find the median, we need to identify the vertical line inside the box.
We can then find what value lines up with this vertical line on the number line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/medianbox1.jpg"499">
The median of the exam scores is about <b>76</b>.
<h2>Example 2: Points Scored</h2>
The following box plot shows the distribution of points scored by basketball players in a certain league. 
What is the median of the distribution?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox3.jpg"453">
To find the median, we need to identify the vertical line inside the box.
We can then find what value lines up with this vertical line on the number line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/medianbox2.jpg">
The median of the distribution is about <b>21</b>.
<h2>Example 3: Comparing Plant Heights</h2>
The following box plots show the distribution of heights for two different plant species: Red and Blue. 
Which distribution has a higher median value?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox4.jpg">
The median of the red box plot is about 28.
The median of the blue box plot is about 21.
Thus, the red plant species has a higher median value.
<h2>Additional Resources</h2>
The following tutorials provide additional information about box plots:
 Box Plot Generator 
 How to Compare Box Plots 
 How to Identify Skewness in Box Plots 
 How to Find the Interquartile Range of a Box Plot 
<h2><span class="orange">How to Find Multiple Values in Excel (With Example)</span></h2>
You can use the following formula to find multiple values in Excel:
<b>=INDEX($A$1:$B$12,SMALL(IF($A$1:$A$12=$F$1,ROW($A$1:$A$12)),ROW(1:1)),2)
</b>
This particular formula finds all of the values in the range <b>B1:B12</b> where the corresponding value in the range <b>A1:A12</b> is equal to the value in cell <b>F1</b>.
The following example shows how to use this formula in practice.
<h2>Example: Find Multiple Values in Excel</h2>
Suppose we have the following dataset in Excel that shows which employees sold various products at some company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/findmult1.jpg"481">
Now suppose we would like to find all of the products sold by Mike.
To do so, we can type his name in cell <b>D2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/findmult2.jpg"510">
Then we can type the following formula into cell <b>E2</b>:
<b>=INDEX($A$1:$B$12,SMALL(IF($A$1:$A$12=$D$2,ROW($A$1:$A$12)),ROW(1:1)),2)</b>
This will return the first product sold by Mike:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/findmult3.jpg"534">
We can then autofill this formula down to the remaining cells in column E to find all products sold by Mike:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/findmult4.jpg"494">
We can now see all four products sold by Mike:
Oranges
Kiwis
Apples
Bananas
We can look at the original data in columns A and B to confirm that Mike indeed sold all four of these products.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Count Number of Occurrences in Excel 
 How to Count Frequency of Text in Excel 
 How to Calculate Relative Frequency in Excel 
<h2><span class="orange">How to Find Outliers Using the Interquartile Range</span></h2>
An <b>outlier</b> is an  observation  that lies abnormally far away from other values in a dataset. Outliers can be problematic because they can affect the results of an analysis.
One common way to find outliers in a dataset is to use the <b>interquartile range</b>.
The interquartile range, often abbreviated IQR, is the difference between the 25th percentile (Q1) and the 75th percentile (Q3) in a dataset. It measures the spread of the middle 50% of values.
One popular method is to declare an observation to be an outlier if it has a value 1.5 times greater than the IQR or 1.5 times less than the IQR.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier1.png">
This tutorial provides a step-by-step example of how to find outliers in a dataset using this method.
<h3>Step 1: Create the Data</h3>
Suppose we have the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier2.png">
<h3>Step 2: Identify the First and Third Quartile</h3>
The first quartile turns out to be <b>5</b> and the third quartile turns out to be <b>20.75</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier3.png">
Thus, the interquartile range turns out to be 20.75 -5 = <b>15.75</b>.
<h3>Step 3: Find the Lower and Upper Limits</h3>
The lower limit is calculated as:
Lower limit = Q1 – 1.5*IQR = 5 – 1.5*15.75 = <b>-18.625</b>
And the upper limited is calculated as:
Upper limit = Q3 + 1.5*IQR = 20.75 + 1.5*15.75 = <b>44.375</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier4.png">
<h3>Step 4: Identify the Outliers</h3>
The only observation in the dataset with a value less than the lower limit or greater than the upper limit is <b>46</b>. Thus, this is the only outlier in this dataset.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier5.png">
<b>Note:</b> You can use this  Outlier Boundary Calculator  to automatically find the upper and lower boundaries for outliers in a given dataset.
<h3>How to Find Outliers in Practice</h3>
The following tutorials explain how to find outliers using the interquartile range in different statistical software:
 How to Find Outliers in Excel 
 How to Find Outliers in R 
 How to Find Outliers in Python 
 How to Find Outliers in SPSS 
<h2><span class="orange">How to Find Percentage of Two Numbers in Excel</span></h2>
You can use the following formula to calculate the percentage change between two numbers:
<b>Percentage Change: (New Value – Old Value) / Old Value</b>
In Excel, you can type the following formula:
<b>=(C2-B2)/B2
</b>
This particular formula finds the percentage change between the values in cell <b>B2</b> and <b>C2</b> in which the new value is in cell <b>C2</b> and the old value is in cell <b>B2</b>.
The following example shows how to use this formula in practice.
<h2>Example: Find Percentage of Two Numbers in Excel</h2>
Suppose we have the following dataset in Excel that shows the points scored in two different years by various basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percbetween1.jpg"495">
Now suppose we would like to calculate the percentage change between year 1 and year 2 for each player.
To do so, we can type the following formula into cell D2:
<b>=(C2-B2)/B2
</b>
Once we press <b>Enter</b>, the percentage change for the first player will be shown:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percbetween2.jpg"446">
A value of <b>0.25</b> tells us that the value for points increased by <b>25%</b> for Andy between year 1 and year 2.
We can manually verify this is correct by calculating the percentage change by hand:
Percentage Change: (New Value – Old Value) / Old Value
Percentage Change: (15 – 12) / 12
Percentage Change: 0.25
We can then drag and fill this formula down to each remaining cell in column D:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percbetween3.jpg"471">
A positive value in the<b> % Change</b> column indicates that the points value increased between the first and second year.
Conversely, a negative value indicates that the points value decreased between the first and second year.
Note that we can also format these values as percentages by highlighting the cell range <b>D2:D11</b> and then clicking the<b> %</b> icon on the Home tab:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percbetween4.jpg"672">
Each of the percentages will now be displayed as a percentage instead of a decimal:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percbetween5.jpg">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate a Weighted Percentage in Excel 
 How to Multiply Column by a Percentage in Excel 
 How to Calculate Percentile Rank in Excel 
<h2><span class="orange">How to Find Probability from a Z-Score (With Examples)</span></h2>
The easiest way to find the probability from a z-score is to simply look up the probability that corresponds to the z-score in the  z table .
This tutorial explains how to use the z table to find the following probabilities:
The probability of a value being less than a certain z-score.
The probability of a value being greater than a certain z-score.
The probability of a value being between two certain z-scores.
Let’s jump in!
<h2>Example 1: Probability Less Than a Certain Z-Score</h2>
Suppose we would like to find the probability that a value in a given distribution has a z-score less than <b>z = 0.25</b>.
To find this probability, we need to look up 0.25 in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable1.png">
The probability that a value in a given distribution has a z-score less than <b>z = 0.25</b> is approximately <b>0.5987</b>.
<b>Note</b>: This could also be written as <b>59.87%</b> in percentage terms.
<h2>Example 2: Probability Greater Than a Certain Z-Score</h2>
Suppose we would like to find the probability that a value in a given distribution has a z-score greater than <b>z = -0.5</b>.
To find this probability, we need to look up -0.5 in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/g1.png">
The probability that corresponds to a z-score of -0.5 is .3085.
However, since we want to know the probability that a value in a given distribution has a z-score <em>greater </em>than -0.5, we need to subtract this probability from 1.
Thus, the probability that a value in a given distribution has a z-score greater than -0.5 is: 1 – .3085 = <b>0.6915</b>.
<h2>Example 3: Probability Between Two Z-Scores</h2>
Suppose we would like to find the probability that a value in a given distribution has a z-score between <b>z = 0.4</b> and<b> z = 1</b>.
First, we will look up the value <b>0.4 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable3.png">
Then, we will look up the value <b>1 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable4.png">
Then we will subtract the smaller value from the larger value: <b>0.8413 – 0.6554 = 0.1859</b>.
Thus, the probability that a value in a given distribution has a z-score between z = 0.4 and z = 1 is approximately <b>0.1859</b>.
<h2>Additional Resources</h2>
The following tutorials provide additional information about z-scores:
 5 Examples of Using Z-Scores in Real Life 
 How to Convert Z-Scores to Raw Scores 
 How to Find Z-Scores Given Area 
<h2><span class="orange">How to Find Probability Given a Mean and Standard Deviation</span></h2>
We can use the following process to find the probability that a normally distributed  random variable  <em>X</em> takes on a certain value, given a mean and standard deviation:
<b>Step 1: Find the z-score.</b>
A z-score tells you how many standard deviations away an individual data value falls from the mean. It is calculated as:
<b>z-score = (x – μ) / σ</b>
where:
<b>x: </b>individual data value
<b>μ: </b>population mean
<b>σ: </b>population standard deviation
<b>Step 2: Find the probability that corresponds to the z-score.</b>
Once we’ve calculated the z-score, we can look up the probability that corresponds to it in the  z table .
The following examples show how to use this process in different scenarios.
<h3>Example 1: Probability Less Than a Certain Value</h3>
The scores on a certain test are normally distributed with mean μ = 82 and standard deviation σ = 8. What is the probability that a given student scores less than 84 on the test?
<b>Step 1: Find the z-score.</b>
First, we will find the z-score associated with a score of 84:
z-score = (x – μ) /  σ = (84 – 82) / 8 = 2 / 8 = <b>0.25</b>
<b>Step 2: Use the z-table to find the corresponding probability.</b>
Next, we will look up the value <b>0.25 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable1.png">
The probability that a given student scores less than 84 is approximately <b>59.87%</b>.
<h3>Example 2: Probability Greater Than a Certain Value</h3>
The height of a certain species of penguin is normally distributed with a mean of μ = 30 inches and a standard deviation of σ = 4 inches. If we randomly select a penguin, what is the probability that it is greater than 28 inches tall?
<b>Step 1: Find the z-score.</b>
First, we will find the z-score associated with a height of 28 inches.
z-score = (x – μ) /  σ = (28 – 30) / 4 = -2 / 4 = <b>-.5</b>
<b>Step 2: Use the z-table to find the corresponding probability.</b>
Next, we will look up the value <b>-0.5 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/g1.png">
The value that corresponds to a z-score of -0.5 is .3085. This represents the probability that a penguin is less than 28 inches tall.
However, since we want to know the probability that a penguin will have a height greater than 28 inches, we need to subtract this probability from 1.
Thus, the probability that a penguin will have a height greater than 28 inches is: 1 – .3085 = <b>0.6915</b>.
<h3>Example 3: Probability Between Two Values</h3>
The weight of a certain species of turtle is normally distributed with a mean of μ = 400 pounds and a standard deviation of σ = 25 pounds. If we randomly select a turtle, what is the probability that it weighs between 410 and 425 pounds?
<b>Step 1: Find the z-scores.</b>
First, we will find the z-scores associated with 410 pounds and 425 pounds
z-score of 410 = (x – μ) /  σ = (410 – 400) / 25 = 10 / 25 = <b>0.4</b>
z-score of 425 = (x – μ) /  σ = (425 – 400) / 25 = 25 / 25 = <b>1</b>
<b>Step 2: Use the z-table to find the corresponding probability.</b>
First, we will look up the value <b>0.4 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable3.png">
Then, we will look up the value <b>1 </b>in the  z-table :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/ztable4.png">
Then we will subtract the smaller value from the larger value: <b>0.8413 – 0.6554 = 0.1859</b>.
Thus, the probability that a randomly selected turtle weighs between 410 pounds and 425 pounds is <b>18.59%</b>.
<h2><span class="orange">How to Find Quartiles in Even and Odd Length Datasets</span></h2>
<b>Quartiles</b> are values that split up a dataset into four equal parts.
To find the first and third quartile for a dataset with an <b>even</b> number of values, use the following steps:
Identify the median value (the average of the two middle values)
Split dataset in half at the median
Q<sub>1</sub> is the median value in the lower half of the dataset (not including median)
Q<sub>3</sub> is the median value in the upper half of the dataset (not including median)
To find the first and third quartile for a dataset with an <b>odd</b> number of values, use the following steps:
Identify the median value (the middle value)
Split dataset in half at the median
Q<sub>1</sub> is the median value in the lower half of the dataset (not including median)
Q<sub>3</sub> is the median value in the upper half of the dataset (not including median)
The following examples show how to calculate quartiles for both types of datasets.
<b>Note</b>: When calculating quartiles, some formulas do include the median value. As noted by  Wikipedia , there is actually no universal agreement on how to calculate quartiles for discrete distributions. The formulas shared here are used by TI-84 calculators, which is why we have chosen to use them.
<h2>Example 1: Calculate Quartiles for Even Length Dataset</h2>
Suppose we have the following dataset with ten values:
Data: 3, 3, 6, 8, 10, 14, 16, 16, 19, 24
The median value is the average of the middle two values, which is (10 + 14) / 2 = 12.
We will not include this median value when calculating the quartiles.
The first quartile is the median of the lower half of values, which turns out to be <b>6</b>:
Q<sub>1</sub> = 3, 3, <b>6</b>, 8, 10
The third quartile is the median of the upper half of values, which turns out to be <b>16</b>:
Q<sub>3</sub> = 14, 16, <b>16</b>, 19, 24
Thus, the first and third quartiles for this dataset are 6 and 16, respectively.
<h2>Example 2: Calculate Quartiles for Odd Length Dataset</h2>
Suppose we have the following dataset with nine values:
Data: 3, 3, 6, 8, 10, 14, 16, 16, 19
The median value is the value located directly in the middle: 10.
We will not include this median value when calculating the quartiles.
The first quartile is the median of the lower half of values. Since there are two values in the middle, we will take the average which turns out to be (3 + 6) / 2 = <b>4.5</b>:
Q<sub>1</sub> = 3, <b>3</b>, <b>6</b>, 8
The third quartile is the median of the upper half of values. Since there are two values in the middle, we will take the average which turns out to be (16 + 16) / 2 = <b>16</b>:
Q<sub>3</sub> = 14, <b>16</b>, <b>16</b>, 19
Thus, the first and third quartiles for this dataset are 4.5 and 16, respectively.
<h2>Additional Resources</h2>
The following tutorials explain how to find the quartiles of a dataset using different statistical software:
 How to Calculate Quartiles in Excel 
 How to Calculate Quartiles in R 
 How to Calculate Quartiles in SAS 
<h2><span class="orange">How to Find Quartiles Using Mean & Standard Deviation</span></h2>
You can use the following formulas to find the first (Q<sub>1</sub>) and third (Q<sub>3</sub>) quartiles of a normally distributed dataset:
<b>Q<sub>1</sub></b> = μ – (.675)σ
<b>Q<sub>3</sub></b> = μ + (.675)σ
Recall that <b>μ</b> represents the population mean and <b>σ</b> represents the population standard deviation.
Also recall that the first quartile represents the 25th percentile of a dataset and the third quartile represents the 75th percentile of a dataset.
The following examples show how to use these formulas in practice.
<h3>Example 1: Find Quartiles Using Mean & Standard Deviation</h3>
Suppose we have a normally distributed dataset with μ = 300 and σ = 45.
We can use the following formulas to calculate the first and third quartiles of the dataset:
<b>Q<sub>1</sub></b> = μ – (.675)σ = 300 – (.675)*45 = <b>269.625</b>
<b>Q<sub>3</sub></b> = μ + (.675)σ = 300 + (.675)*45 = <b>330.375</b>
We interpret this to mean that 25% of all values in the dataset fall below 269.625 and 75% of all values in the dataset fall below 330.375.
Using these numbers, we could also calculate the interquartile range to be:
IQR = Q<sub>3</sub> – Q<sub>1</sub>
IQR = 330.375 – 269.265
IQR = 61.11
This represents the spread of the middle 50% of values in the dataset.
<h3>Example 2: Find Quartiles Using Mean & Standard Deviation</h3>
Suppose we have a normally distributed dataset with μ = 50 and σ = 2.
We can use the following formulas to calculate the first and third quartiles of the dataset:
<b>Q<sub>1</sub></b> = μ – (.675)σ = 50 – (.675)*2 = <b>48.65</b>
<b>Q<sub>3</sub></b> = μ + (.675)σ = 50 + (.675)*2 = <b>51.35</b>
We interpret this to mean that 25% of all values in the dataset fall below 48.65 and 75% of all values in the dataset fall below 51.35.
Using these numbers, we could also calculate the interquartile range to be:
IQR = Q<sub>3</sub> – Q<sub>1</sub>
IQR = 51.35 – 48.65
IQR = 2.7
This represents the spread of the middle 50% of values in the dataset.
<h2><span class="orange">How to Find the Range of a Box Plot (With Examples)</span></h2>
A <b>box plot</b> is a type of plot that displays the five number summary of a dataset, which includes:
The minimum value
The first quartile (the 25th percentile)
The median value
The third quartile (the 75th percentile)
The maximum value
To make a box plot, we draw a box from the first to the third quartile. Then we draw a vertical line at the median. Lastly, we draw “whiskers” from the quartiles to the minimum and maximum value.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/iqr_box3.png">
The <b>range</b> of a box plot is the difference between the maximum and minimum value.
Range = Maximum – Minimum
To find the range of a given box plot, we can simply subtract the value located at the lower whisker from the value located at the upper whisker.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox1.jpg"436">
The following examples show how to find the range of a box plot in practice.
<h3>Example 1: Exam Scores</h3>
The following box plot shows the distribution of scores on a certain college exam. What is the range of the exam scores?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox2.jpg"466">
We can find the following values on the box plot to answer this:
Range = Maximum – Minimum
Range = 95 – 60
Range = 35
The range of the exam scores is <b>35</b>.
<h3>Example 2: Points Scored</h3>
The following box plot shows the distribution of points scored by basketball players in a certain league. What is the range of the distribution?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox3.jpg"453">
We can find the following values on the box plot to answer this:
Range = Maximum – Minimum
Range = 35 – 5
Range = 30
The range of the distribution is <b>30</b>.
<h3>Example 3: Comparing Plant Heights</h3>
The following box plots show the distribution of heights for two different plant species: Red and Blue. Which distribution has a larger range?
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/rangebox4.jpg"533">
First, let’s find the range of the red box plot:
Range = Maximum – Minimum
Range = 35 – 10
Range = 25
Next, let’s find the range of the blue box plot:
Range = Maximum – Minimum
Range = 40 – 5
Range = 35
The range for the Blue species is larger.
<h2><span class="orange">How to Quickly Find Regression Equation in Excel</span></h2>
You can use the <b>LINEST</b> function to quickly find a regression equation in Excel.
This function uses the following basic syntax:
<b>LINEST(known_y's, known_x's)
</b>
where:
<b>known_y’s</b>: A column of values for the response variable
<b>known_x’s</b>: One or more columns of values for the predictor variables
The following examples show how to use this function to find a regression equation for a  simple linear regression model  and a  multiple linear regression model .
<h3>Example 1: Find Equation for Simple Linear Regression</h3>
Suppose we have the following dataset that contains one predictor variable (x) and one response variable (y):
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/equation1.jpg"462">
We can type the following formula into cell <b>D1</b> to calculate the simple linear regression equation for this dataset:
<b>=LINEST(A2:A15, B2:B15)
</b>
Once we press <b>ENTER</b>, the coefficients for the simple linear regression model will be shown:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/equation2.jpg"489">
Here’s how to interpret the output:
The coefficient for the intercept is <b>3.115589</b>
The coefficient for the slope is <b>0.479072</b>
Using these values, we can write the equation for this simple regression model:
<b>y = 3.115589 + 0.478072(x)</b>
<b>Note</b>: To find the p-values for the coefficients, the r-squared value of the model, and other metrics, you should use the Regression function from the Data Analysis ToolPak. This  tutorial  explains how to do so.
<h3>Example 2: Find Equation for Multiple Linear Regression</h3>
Suppose we have the following dataset that contains two predictor variables (x1 and x2) and one response variable (y):
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/equation3.jpg"456">
We can type the following formula into cell <b>E1</b> to calculate the multiple linear regression equation for this dataset:
<b>=LINEST(A2:A15, B2:C15)
</b>
Once we press <b>ENTER</b>, the coefficients for the multiple linear regression model will be shown:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/equation4.jpg"518">
Here’s how to interpret the output:
The coefficient for the intercept is <b>1.471205</b>
The coefficient for x1 is <b>0.047243</b>
The coefficient for x2 is <b>0.406344</b>
Using these values, we can write the equation for this multiple regression model:
<b>y = 1.471205 + 0.047243(x1) + 0.406344(x2)</b>
<b>Note</b>: To find the p-values for the coefficients, the r-squared value of the model, and other metrics for a multiple linear regression model in Excel, you should use the Regression function from the Data Analysis ToolPak. This  tutorial  explains how to do so.
<h2><span class="orange">How to Find Z-Scores Given Area (With Examples)</span></h2>
There are three ways to find the z-score that corresponds to a given area under a normal distribution curve
<b>1.</b> Use the  z-table .
<b>2.</b> Use the  Percentile to Z-Score Calculator .
<b>3.</b> Use the  invNorm() Function on a TI-84 Calculator .
The following examples show how to use each of these methods to find the z-score that corresponds to a given area under a normal distribution curve.
<h3>Example 1: Find Z-Score Given Area to the Left</h3>
Find the z-score that has 15.62% of the distribution’s area to the left.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg2.png">
<b>Method 1: Use the z-table.</b>
The z-score that corresponds to a value of .1562 in the  z-table  is <b>-1.01</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg3.png">
<b>2. Use the Percentile to Z-Score Calculator.</b>
According to the  Percentile to Z-Score Calculator , the z-score that corresponds to a percentile of .1562 is <b>-1.01</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg4.png">
<b>3. Use the invNorm() function on a TI-84 calculator.</b>
Using the  invNorm() function  on a TI-84 calculator, the z-score that corresponds to an area of .1562 to the left is <b>-1.01</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg1.png">
Notice that all three methods lead to the same result.
<h3>Example 2: Find Z-Score Given Area to the Right</h3>
Find the z-score that has 37.83% of the distribution’s area to the right.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg5.png">
<b>Method 1: Use the z-table.</b>
The z table shows the area to the <em>left</em> of various z-scores. Thus, if we know the area to the right is .3783 then the area to the left is 1 – .3783 = .6217
The z-score that corresponds to a value of .6217 in the  z-table  is <b>.31</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg6.png">
<b>2. Use the Percentile to Z-Score Calculator.</b>
According to the  Percentile to Z-Score Calculator , the z-score that corresponds to a percentile of .6217 is .<b>3099</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg7.png">
<b>3. Use the invNorm() function on a TI-84 calculator.</b>
Using the  invNorm() function  on a TI-84 calculator, the z-score that corresponds to an area of .6217 to the left is <b>.3099</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg8.png">
<h3>Example 3: Find Z-Scores Given Area Between Two Values</h3>
Find the z-scores that have 95% of the distribution’s area between them.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg9.png">
<b>Method 1: Use the z-table.</b>
If 95% of the distribution is located between two z-scores, it means that 5% of the distribution lies outside of the z-scores.
Thus, 2.5% of the distribution is less than one of the z-scores and 2.5% of the distribution is greater than the other z-score.
Thus, we can look up .025 in the z-table. The z-score that corresponds to .025 in the  z-table  is <b>-1.96</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg10.png">
Thus, the z-scores that contain 95% of the distribution between them are <b>-1.96</b> and <b>1.96</b>.
<b>2. Use the Percentile to Z-Score Calculator.</b>
According to the  Percentile to Z-Score Calculator , the z-score that corresponds to a percentile of .025 is <b>-1.96</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg11.png">
Thus, the z-scores that contain 95% of the distribution between them are <b>-1.96</b> and <b>1.96</b>.
<b>3. Use the invNorm() function on a TI-84 calculator.</b>
Using the  invNorm() function  on a TI-84 calculator, the z-score that corresponds to an area of .025 to the left is <b>-1.96</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/zg12.png">
Thus, the z-scores that contain 95% of the distribution between them are <b>-1.96</b> and <b>1.96</b>.
<h2><span class="orange">What is the Finite Population Correction Factor?</span></h2>
Most formulas used to compute <b>standard errors </b>are based on the idea that (1) samples are selected with replacement or that (2)  samples  are selected from an infinite population.
In actual research, neither of these ideas hold true. Luckily this doesn’t tend to be a problem if the sample size is less than 5% of the total population size.
However, when the sample size is larger than 5% of the total population it’s best to apply a <b>finite population correction </b>(often abbreviated <em>FPC</em>), which is calculated as:
<b>FPC = √(N-n) / (N-1)</b>
where:
<b>N: </b>Population size
<b>n: </b>Sample size
<h3>How to Use the Finite Population Correction Factor</h3>
To apply a finite population correction, simply multiply it by the standard error that you would have originally used.
For example, the standard error of a mean is calculated as:
<b>Standard error of mean:</b> s / √n
By applying the finite population correction, the formula becomes:
<b>Standard error of mean:</b> s / √n * √(N-n) / (N-1)
The following examples illustrate how to use the finite population correction in different scenarios.
<h3>Example 1: Confidence Interval for a Proportion</h3>
Researchers want to estimate the proportion of residents in a county of 1,300 people that are in favor of a certain law. They select a  random sample  of 100 residents and ask them about their stance on the law. Here are the results:
Sample size <b>n = 100</b>
Proportion in favor of law <b>p = 0.56</b>
Typically the formula to calculate a 95% confidence interval for a population proportion is:
<b>95% C.I. = p  +/-  z*(√p(1-p) / n)</b>
However, our sample size in this example is 100/1,300 = 7.7% of the population, which exceeds 5%. Thus, we need to apply a finite population correction to our formula for the confidence interval:
<b>95% C.I. = p  +/-  z*(√p(1-p)/n) * √(N-n) / (N-1)</b>
Thus, our 95% confidence interval can be calculated as:
<b>95% C.I. = </b>0.56  +/-  1.96*(√.56(1-.56) / 100) * √(1300-100) / (1300-1) = <b>[0.4665, 0.6535]</b>
<h3>Example 2: Confidence Interval for a Mean</h3>
Researchers want to estimate the mean weight of a certain species of 500 turtles so they select a random sample of 40 turtles and weight each of them. Here are the results:
Sample size <b>n = 40</b>
Sample mean weight <b>x = 300</b>
Sample standard deviation <b>s = 18.5</b>
Typically the formula to calculate a 95% confidence interval for a population mean is:
<b>95% C.I. = x  +/-  t<sub>α/2</sub>*(s/√n)</b>
However, our sample size in this example is 40/500 = 8% of the population, which exceeds 5%. Thus, we need to apply a finite population correction to our formula for the confidence interval:
<b>95% C.I. = x  +/-  t<sub>α/2</sub>*(s/√n)  * √(N-n) / (N-1)</b>
Thus, our 95% confidence interval can be calculated as:
<b>95% C.I. = </b>300  +/-  2.0227*(18.5/√40) * √(500-40) / (500-1) = <b>[294.32, 305.69]</b>
<h2><span class="orange">Fisher Z-Transformation: Definition & Example</span></h2>
The <b>Fisher Z transformation</b> is a formula we can use to transform Pearson’s correlation coefficient (r) into a value (z<sub>r</sub>) that can be used to calculate a confidence interval for Pearson’s correlation coefficient.
The formula is as follows:
z<sub>r</sub> = ln((1+r) / (1-r)) / 2
For example, if the Pearson correlation coefficient between two variables is found to be <b>r</b> = 0.55, then we would calculate <b>z<sub>r</sub></b> to be:
z<sub>r</sub> = ln((1+r) / (1-r)) / 2
z<sub>r</sub> = ln((1+.55) / (1-.55)) / 2
z<sub>r</sub> = 0.618
It turns out that the  sampling distribution  of this transformed variable follows a  normal distribution . 
This is important because it allows us to calculate a confidence interval for a Pearson correlation coefficient.
Without performing this Fisher Z transformation, we would be unable to calculate a reliable confidence interval for the Pearson correlation coefficient.
The following example shows how to calculate a confidence interval for a Pearson correlation coefficient in practice.
<h3>Example: Calculating a Confidence Interval for Correlation Coefficient</h3>
Suppose we want to estimate the correlation coefficient between height and weight of residents in a certain county. We select a random sample of 60 residents and find the following information:
Sample size <b>n = 60</b>
Correlation coefficient between height and weight <b>r = 0.56</b>
Here is how to find a 95% confidence interval for the population correlation coefficient:
<b>Step 1:  Perform Fisher transformation.</b>
Let z<sub>r</sub> = ln((1+r) / (1-r)) / 2 = ln((1+.56) / (1-.56)) / 2 = <b>0.6328</b>
<b>Step 2: Find log upper and lower bounds.</b>
Let L = z<sub>r</sub>  –  (z<sub>1-α/2</sub> /√n-3) = .6328  –  (1.96 /√60-3) = <b>.373</b>
Let U = z<sub>r</sub>  +  (z<sub>1-α/2</sub> /√n-3) = .6328  +  (1.96 /√60-3) = <b>.892</b>
<b>Step 3: Find confidence interval.</b>
Confidence interval = [(e<sup>2L</sup>-1)/(e<sup>2L</sup>+1),  (e<sup>2U</sup>-1)/(e<sup>2U</sup>+1)] 
Confidence interval = [(e<sup>2(.373)</sup>-1)/(e<sup>2(.373)</sup>+1),  (e<sup>2(.892)</sup>-1)/(e<sup>2(.892)</sup>+1)] = <b>[.3568, .7126]</b>
<b>Note:</b> You can also find this confidence interval by using the  Confidence Interval for a Correlation Coefficient Calculator .
This interval gives us a range of values that is likely to contain the true population Pearson correlation coefficient between weight and height with a high level of confidence.
Note the importance of the Fisher Z transformation: It was the first step we had to perform before we could actually calculate the confidence interval.
<h2><span class="orange">Fisher’s Exact Test Calculator</span></h2>
svg:not(:root) {
  overflow: visible;
}
td input {
  max-width:60px;
  max-height:30px;
}
</style>
<b>Fisher’s Exact Test</b> is used to determine whether or not there is a significant association between two categorical variables. It is typically used as an alternative to the Chi-Square Test of Independence when one or more of the cell counts in a 2×2 table is less than 5.
To perform Fisher’s Exact Test, simply fill in the cells of the contingency below and then click “Calculate.”
<table><tbody>
<tr style="max-height:10px">
<th style="min-width:120px"></th>
<th><b><span>Group 1</b></th>
<th><b><span>Group 2</b></th>
</tr>
<tr>
<td>Category 1</td>
<td><input type="text" id="o11" value="4"></td>
<td><input type="text" id="o12" value="9"></td>
</tr>
<tr>
<td>Category 2</td>
<td><input type="text" id="o21" value="8"></td>
<td><input type="text" id="o22" value="4"></td>
</tr>
</tbody></table>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
One-tailed p value: <b>0.081178</b>
Two-tailed p value: <b>0.115239</b>
<script>
function calc() {
//get input data
var o11 = document.getElementById('o11').value;
var o12 = document.getElementById('o12').value;
var o21 = document.getElementById('o21').value;
var o22 = document.getElementById('o22').value;
//find one-tailed p value
var n = math.sum(o11, o12, o21, o22);
var rowSum = math.sum(math.sum(o11,o12));
var colSum = math.sum(o11,o21);
var p = jStat.hypgeom.cdf(o11, n, colSum, rowSum);
//find two-tailed p value
var all_p = [];
for (var i = o11-(-1); i <= rowSum; i++) {
            all_p.push(jStat.hypgeom.pdf(i, n, colSum, rowSum));
} 
var greater_p = [];
for (var j = 0; j <= all_p.length; j++) {
  if(all_p[j]<=p) {
            greater_p.push(all_p[j]);
        }
} 
var greater_p_total = math.sum(greater_p);
var p2 = math.sum(greater_p_total, p);
//output results
document.getElementById('p').innerHTML = p.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
  
} //end calc function
</script>
<h2><span class="orange">How to Perform Fisher’s Exact Test in Excel</span></h2>
<b> Fisher’s Exact Test  </b>is used to determine whether or not there is a significant association between two categorical variables. It is typically used as an alternative to the Chi-Square Test of Independence when one or more of the cell counts in a 2×2 table is less than 5. 
This tutorial explains how to perform Fisher’s Exact Test in Excel.
<h3>Example: Fisher’s Exact Test in Excel</h3>
Suppose we want to know whether or not gender is associated with political party preference at a particular college. To explore this, we randomly poll 25 students on campus. The number of students who are Democrats or Republicans, based on gender, is shown in the table below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/fisherExactTestExcel1.png">
To determine if there is a statistically significant association between gender and political party preference, we can perform Fisher’s Exact Test.
Although Excel doesn’t have a built-in function to perform this test, we can use the hypergeometric function to perform the test, which uses the following syntax:
<b>=HYPGEOM.DIST(sample_s, number_sample, population_s, number_pop, cumulative)</b>
where:
<b>sample_s </b>= the number of “successes” in the sample
<b>number_sample</b> = the sample size
<b>population_s</b> = the number of “successes” in the population
<b>number_pop</b> = the population size
<b>cumulative</b> = if TRUE, this returns the cumulative distribution function; if FALSE, this returns the probability mass function. For our purposes, we will always use TRUE.
To apply this function to our example, we will pick one of the four cells in the 2×2 table to use. Any cell will do, but we’ll use the top left cell with the value “4” for this example.
Next, we’ll fill in the following values for the function:
=<b>HYPGEOM.DIST(value in individual cell, total column count, total row count, total sample size, TRUE)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/fisherExactTestExcel2.png">
This produces a one-tailed p-value of <b>0.0812</b>.
In order to find the two-tailed p-value for the test, we will add the following two probabilities together:
The probability of getting x “successes” in the cell we’re interested in. In our case, this is the probability of getting 4 successes (we already found this probability to be 0.0812).
1 – the probability of getting (total column count – x “successes”) in the cell we’re interested in. In this case, the total column count for Democrat is 12, so we’ll find 1 – (probability of 8 “successes”)
Here’s the formula we’ll use:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/fisherExactTestExcel3.png">
This produces a two-tailed p-value of <b>0.1152</b>.
In either case, whether we conduct a one-tailed test or a two-tailed test, the p-value is not less than 0.05 so we cannot reject the null hypothesis. In other words, we don’t have sufficient evidence to say that there is a significant association between gender and political party preference.
<h2><span class="orange">How to Conduct Fisher’s Exact Test in R</span></h2>
 Fisher’s Exact Test  is used to determine whether or not there is a significant association between two categorical variables.
It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5.
Fisher’s Exact Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: (null hypothesis) </b>The two variables are independent.
<b>H<sub>A</sub>: (alternative hypothesis) </b>The two variables are <em>not</em> independent.
The following example shows how to conduct Fisher’s Exact Test in R.
<h2>Example: Fisher’s Exact Test in R</h2>
In order to conduct Fisher’s Exact Test in R, you simply need a 2×2 dataset.
For example, let’s generate a 2×2 dataset to use as an example:
<b>#create 2x2 dataset
data = matrix(c(2,5,9,4), nrow = 2)
#view dataset
data
# 2 9
# 5 4</b>
To conduct Fisher’s Exact Test, we simply use the following code:
<b>fisher.test(data)</b>
 This produces the following output:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/fisherExactTest.jpg" alt="">
In Fisher’s Exact Test, the null hypothesis is that the two columns are independent (or equivalently, that the odds ratio is equal to 1).
To determine if the two columns are independent, we can look at the p-value of the test.
In this case the p-value is <b>0.1597</b>, which tells us we do not have sufficient evidence to reject the null hypothesis.
Thus, we cannot say that there is any statistically significant difference between the two columns.
Note that the odds ratio is 0.1957871. Since the p-value of the test is 0.1597, this tells us that the odds ratio is not significantly different than 1.
The output of the test also gives us a 95% confidence interval for the odds ratio, which is:
95% Confidence Interval for Odds Ratio: <b>(0.0130943, 1.8397543)</b>
 Since the number 1 is within this ratio, it confirms that the odds ratio is not significantly different than 1 (assuming we use alpha level 0.05).
<h2>Additional Resources</h2>
The following tutorials provide additional information about Fisher’s Exact Test:
 An Introduction to Fisher’s Exact Test 
 Fisher’s Exact Test Online Calculator 
 How to Report Fisher’s Exact Test Results 
<h2><span class="orange">How to Perform Fisher’s Exact Test in SAS</span></h2>
 Fisher’s Exact Test  is used to determine whether or not there is a significant association between two categorical variables.
It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5.
Fisher’s Exact Test uses the following null and alternative  hypotheses :
<b>H<sub>0</sub>: (null hypothesis) </b>The two variables are independent.
<b>H<sub>1</sub>: (alternative hypothesis) </b>The two variables are <em>not</em> independent.
If the  p-value  of the test is less than a certain significance level, we can reject the null hypothesis of the test and conclude that the two variables are not independent, i.e. they have a significant association.
The following example shows how to perform Fisher’s Exact Test in SAS.
<h3>Example: Fisher’s Exact Test in SAS</h3>
Suppose we want to know whether or not gender is associated with political party preference at a particular college.
To explore this, we  randomly select  25 students on campus and ask them about their political party preference. The results are shown in the table below:
<table><tbody>
<tr>
<th> </th>
<th><b>Democrat</b></th>
<th><b>Republican</b></th>
</tr>
<tr>
<td><b>Female</b></td>
<td>8</td>
<td>4</td>
</tr>
<tr>
<td><b>Male</b></td>
<td>4</td>
<td>9</td>
</tr>
</tbody></table>
To determine if there is a statistically significant association between gender and political party preference, we can use the following steps to perform Fisher’s Exact Test in SAS:
<b>Step 1: Create the Data</b>
First, let’s create a dataset called <b>my_data</b>:
<b>/*create data to hold survey results*/
data my_data;
    input Party $ Gender $;
    datalines;
Rep Female
Rep Female
Rep Female
Rep Female
Rep Male
Rep Male
Rep Male
Rep Male
Rep Male
Rep Male
Rep Male
Rep Male
Rep Male
Dem Female
Dem Female
Dem Female
Dem Female
Dem Female
Dem Female
Dem Female
Dem Female
Dem Male
Dem Male
Dem Male
Dem Male
;
run;
</b>
<b>Step 2: Perform Fisher’s Exact Test</b>
Next, we can use the following code to perform Fisher’s Exact Test:
<b>/*perform Fisher's Exact test*/
proc freq;
    tables Party*Gender / fisher;
run;</b>
The results of the test are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/fisherSAS1.jpg">
The null hypothesis for Fisher’s Exact Test is that the two variables are independent. In this example, our null hypothesis is that gender and political party preference are independent, which is a two-sided test.
Thus, we’ll look at the <b>two-sided p-value</b> in the final table of the output, which turns out to be <b>0.1152</b>.
Since this p-value is not less than 0.05, we do not reject the null hypothesis.
This means we do not have sufficient evidence to say that there is a significant association between gender and political party preference.
<h2><span class="orange">How to Perform Fisher’s Exact Test in Python</span></h2>
 Fisher’s Exact Test  is used to determine whether or not there is a significant association between two categorical variables.
It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5. 
This tutorial explains how to perform Fisher’s Exact Test in Python.
<h3>Example: Fisher’s Exact Test in Python</h3>
Suppose we want to know whether or not gender is associated with political party preference at a particular college.
To explore this, we randomly poll 25 students on campus. The number of students who are Democrats or Republicans, based on gender, is shown in the table below:
<table><tbody>
<tr>
<th> </th>
<th><b>Democrat</b></th>
<th><b>Republican</b></th>
</tr>
<tr>
<td><b>Female</b></td>
<td>8</td>
<td>4</td>
</tr>
<tr>
<td><b>Male</b></td>
<td>4</td>
<td>9</td>
</tr>
</tbody></table>
To determine if there is a statistically significant association between gender and political party preference, we can use the following steps to perform Fisher’s Exact Test in Python:
<b>Step 1: Create the data.</b>
First, we will create a table to hold our data:
<b>data = [[8, 4],
         [4, 9]]</b>
<b>Step 2: Perform Fisher’s Exact Test.</b>
Next, we can perform Fisher’s Exact Test using the  fisher_exact function  from the SciPy library, which uses the following syntax:
<b>fisher_exact(table, alternative=’two-sided’) </b>
where:
<b>table: </b>A 2×2 contingency table
<b>alternative: </b>Defines the alternative hypothesis. Default is ‘two-sided’, but you can also choose ‘less’ or ‘greater’ for one-sided tests.
The following code shows how to use this function in our specific example:
<b>import scipy.stats as stats
print(stats.fisher_exact(data))
(4.5, 0.1152)
</b>
The p-value for the tests is <b>0.1152</b>.
Fisher’s Exact Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: (null hypothesis) </b>The two variables are independent.
<b>H<sub>1</sub>: (alternative hypothesis) </b>The two variables are <em>not</em> independent.
Since this p-value is not less than 0.05, we do not reject the null hypothesis.
Thus, we don’t have sufficient evidence to say that there is a significant association between gender and political party preference.
In other words, gender and political party preference are independent.
<h2><span class="orange">How to Perform Fisher’s Exact Test in SPSS</span></h2>
 Fisher’s Exact Test  is used to determine whether or not there is a significant association between two categorical variables.
It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5.
This tutorial explains how to perform Fisher’s Exact Test in SPSS.
<h2>Example: Fisher’s Exact Test in SPSS</h2>
Suppose we want to know whether or not gender is associated with political party preference at a particular college. To explore this, we randomly poll 25 students on campus. The number of students who are Democrats or Republicans, based on gender, is shown in the table below:
<table><tbody>
<tr>
<th> </th>
<th><b>Democrat</b></th>
<th><b>Republican</b></th>
</tr>
<tr>
<td><b>Female</b></td>
<td>8</td>
<td>4</td>
</tr>
<tr>
<td><b>Male</b></td>
<td>4</td>
<td>9</td>
</tr>
</tbody></table>
To determine if there is a statistically significant association between gender and political party preference, we can use the following steps to perform Fisher’s Exact Test in SPSS:
<b>Step 1: Enter the data.</b>
First, enter the data as shown below:
<em>Each row shows an individual’s ID, their political party preference, and their gender.</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fisherSPSS1.png">
<b>Step 2: Perform Fisher’s Exact Test.</b>
Click the <b>Analyze </b>tab, then <b>Descriptive Statistics</b>, then <b>Crosstabs</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fisherSPSS2.png">
Drag the variable <b>Gender </b>into the box labelled Rows and the variable <b>Party </b>into the box labelled Columns. Then click the button labelled <b>Statistics</b> and make sure that the box next to <b>Chi-square </b>is checked. Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fisherSPSS3.png">
Next, click the button labelled <b>Exact </b>and make sure the box next to <b>Exact </b>is checked. Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fisherSPSS3-1.png">
Lastly, click <b>OK </b>to perform Fisher’s Exact Test.
<b>Step 3: Interpret the results.</b>
Once you click <b>OK</b>, the results of Fisher’s Exact Test will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fisherSPSS4.png">
The first table displays the number of missing cases in the dataset. We can see that there are 0 missing cases in this example.
The second table displays a crosstab of the total number of individuals by gender and political party preference.
The third table shows the results of Fisher’s Exact Test. We can see the following two p-values for the test:
<li data-slot-rendered-dynamic="true"><b>Two-sided p-value: </b>.115
<li data-slot-rendered-dynamic="true"><b>One-sided p-value: </b>.081
The null hypothesis for Fisher’s Exact Test is that the two variables are independent. In this case, our null hypothesis is that gender and political party preference are independent, which is a two-sided test so we would use the two-sided p-value of 0.115.
Since this p-value is not less than 0.05, we do not reject the null hypothesis. Thus, we don’t have sufficient evidence to say that there is a significant association between gender and political party preference.
<h2><span class="orange">How to Perform Fisher’s Exact Test in Stata</span></h2>
 Fisher’s Exact Test  is used to determine whether or not there is a significant association between two categorical variables. It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5. 
This tutorial explains how to perform Fisher’s Exact Test in Stata.
<h2>Example: Fisher’s Exact Test in Stata</h2>
Suppose we want to know whether or not gender is associated with political party preference at a particular college. To explore this, we randomly poll 25 students on campus. The number of students who are Democrats or Republicans, based on gender, is shown in the table below:
<table><tbody>
<tr>
<th></th>
<th style="text-align: center;"><b>Democrat</b></th>
<th style="text-align: center;"><b>Republican</b></th>
</tr>
<tr>
<td><b>Male</b></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">9</td>
</tr>
<tr>
<td><b>Female</b></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">4</td>
</tr>
</tbody></table>
To determine if there is a statistically significant association between gender and political party preference, we can perform Fisher’s Exact Test.
In Stata, we can use the <b>tabi </b>command to perform Fisher’s Exact test. We enter the counts in the 2×2 table from left to right with a <b>\ </b>to separate the top and bottom rows.
<b>tabi 4 9 \ 8 4</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/fisherExactTestStata1.png">
Here is how to interpret the output:
<b>Output table: </b>This table shows the counts for each cell, just as we entered them in.
<b>Fisher’s exact: </b>This is the p-value associated with a two-sided Fisher’s Exact Test. In this case, it is 0.115.
<b>1-sided Fisher’s exact:</b> This is the p-value associated with a one-sided Fisher’s Exact Test. In this case, it is 0.081. 
The null hypothesis for Fisher’s Exact Test is that the two variables are independent. In this case, our null hypothesis is that gender and political party preference are independent, which is a two-sided test so we would use the first p-value of 0.115.
Since this p-value is not less than 0.05, we do not reject the null hypothesis. Thus, we don’t have sufficient evidence to say that there is a significant association between gender and political party preference.
<h2><span class="orange">Fisher’s Exact Test: Definition, Formula, and Example</span></h2>
<b>Fisher’s Exact Test </b>is used to determine whether or not there is a significant association between two categorical variables. It is typically used as an alternative to the  Chi-Square Test of Independence  when one or more of the cell counts in a 2×2 table is less than 5. 
Fisher’s Exact Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: (null hypothesis) </b>The two variables are independent.
<b>H<sub>1</sub>: (alternative hypothesis) </b>The two variables are <em>not</em> independent.
Suppose we have the following 2×2 table:
<table><tbody>
<tr>
<td></td>
<td style="text-align: center;"><b>Group 1</b></td>
<td style="text-align: center;"><b>Group 2</b></td>
<td style="text-align: center;"><b>Row Total</b></td>
</tr>
<tr>
<td><b>Category 1</b></td>
<td style="text-align: center;">a</td>
<td style="text-align: center;">b</td>
<td style="text-align: center;">a+b</td>
</tr>
<tr>
<td><b>Category 2</b></td>
<td style="text-align: center;">c</td>
<td style="text-align: center;">d</td>
<td style="text-align: center;">c+d</td>
</tr>
<tr>
<td><b>Column Total</b></td>
<td style="text-align: center;">a+c</td>
<td style="text-align: center;">b+d</td>
<td style="text-align: center;">a+b+c+d = n</td>
</tr>
</tbody></table>
The one-tailed p value for Fisher’s Exact Test is calculated as:
p = (a+b)!(c+d)!(a+c)!(b+d)! / (a!b!c!d!n!)
This produces the same p value as the CDF of the  hypergeometric distribution  with the following parameters:
population size = n
population “successes” = a+b
sample size = a + c
sample “successes” = a
The two-tailed p value for Fisher’s Exact Test is less straightforward to calculate and can’t be found by simply multiplying the one-tailed p value by two. To find the two-tailed p value, we recommend using the  Fisher’s Exact Test Calculator .
<h3>Fisher’s Exact Test: Example</h3>
Suppose we want to know whether or not gender is associated with political party preference. We take a simple random sample of 25 voters and survey them on their political party preference. The following table shows the results of the survey:
<table><tbody>
<tr>
<td></td>
<td style="text-align: center;"><b>Democrat</b></td>
<td style="text-align: center;"><b>Republican</b></td>
<td style="text-align: center;"><b>Total</b></td>
</tr>
<tr>
<td><b>Male</b></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">13</td>
</tr>
<tr>
<td><b>Female</b></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td><b>Total</b></td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">25</td>
</tr>
</tbody></table>
<b>Step 1: Define the hypotheses.</b>
We will perform Fisher’s Exact Test using the following hypotheses:
<b>H<sub>0</sub>: </b>Gender and political party preference are independent.
<b>H<sub>1</sub>:</b> Gender and political party preference are <em>not</em> independent.
<b>Step 2: Calculated the two-tailed p value.</b>
We can use the  Fisher’s Exact Test Calculator  with the following input:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/fisher1.png">
The two-tailed p value is <b>0.115239</b>. Since this value is less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that there is any statistically significant association between gender and political party preference.
<h2><span class="orange">Fisher’s Least Significant Difference: Definition + Example</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
The  hypotheses  used in an ANOVA are as follows:
H<sub>0</sub>: The means are equal for each group.
H<sub>A</sub>: At least one of the means is different from the others.
If the  p-value  from the ANOVA is less than some significance level (like α = .05), we can reject the null hypothesis and conclude that at least one of the group means is different from the others.
But in order to find out exactly which groups are different from each other, we must conduct a post-hoc test.
One commonly used post-hoc test is <b>Fisher’s least significant difference test</b>.
To perform this test, we first calculate the following test statistic:
<b>LSD = t<sub>.025</sub>, <sub>DF<sub>w</sub></sub> * √MS<sub>W</sub>(1/n<sub>1</sub> + 1/n<sub>1</sub>)</b>
where:
<b>t<sub>.025</sub>, <sub>DFw</sub>:</b> The t-critical value from the  t-distribution table  with α = .025 and DF<sub>w</sub> is the degrees of freedom within groups from the ANOVA table.
<b>MS<sub>W</sub>:</b> The mean squares within groups from the ANOVA table.
<b>n<sub>1</sub>, n<sub>2</sub>:</b> The sample sizes of each group
We can then compare the mean difference between each group to this test statistic. If the absolute value of the mean difference between two groups is greater than the test statistic, we can declare that there is a statistically significant difference between the group means.
The following example shows how to perform Fisher’s least significant difference test in practice.
<h3>Example: Fisher’s Least Significance Difference Test</h3>
Suppose a professor wants to know whether or not three different studying techniques lead to different exam scores among students. To test this, she randomly assigns 10 students to use each studying technique and records their exam scores.
The following table shows the exam scores for each student based on the studying technique they used:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/leastSigDiff1.png">
The professor performs a one-way ANOVA and get the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/leastSigDiff2.png">
Since the p-value in the ANOVA table (.018771) is less than .05, we can conclude that not all of the mean exam scores between the three groups are equal.
Thus, we can proceed to perform Fisher’s least significant difference test to determine which group means are different.
Using values from the output of the ANOVA, we can calculate Fisher’s test statistic as:
LSD = t<sub>.025</sub>, <sub>DFw</sub> * √MS<sub>W</sub>(1/n<sub>1</sub> + 1/n<sub>1</sub>)
LSD = t<sub>.025</sub>, <sub>27</sub> * √36.948*(1/10 + 1/10)
LSD = 2.052 * √7.3896
LSD = <b>5.578</b>
We can then calculate the absolute mean difference between each group:
Technique 1 vs. Technique 2: |80 – 85.8| = <b>5.8</b>
Technique 1 vs. Technique 3: |80 – 88| = <b>8</b>
Technique 2 vs. Technique 3: |85.8 – 88| = <b>2.2</b>
The absolute mean differences between technique 1 vs. technique 2 and technique 1 vs. technique 3 are greater than Fisher’s test statistic, thus we can conclude that these techniques lead to statistically significantly different mean exam scores.
We can also conclude that there is no significant difference in mean exam scores between technique 2 and technique 3.
<h2><span class="orange">How to Use Fisher’s Least Significant Difference (LSD) in R</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
The  hypotheses  used in a one-way ANOVA are as follows:
<b>H<sub>0</sub></b>: The means are equal for each group.
<b>H<sub style="color: #000000;">A</sub></b>: At least one of the means is different from the others.
If the  p-value  from the ANOVA is less than some significance level (like α = .05), we can reject the null hypothesis and conclude that at least one of the group means is different from the others.
But in order to find out exactly which groups are different from each other, we must conduct a post-hoc test.
One commonly used post-hoc test is <b>Fisher’s least significant difference (LSD) test</b>.
You can use the <b>LSD.test()</b> function from the <b>agricolae</b> package to perform this test in R.
The following example shows how to use this function in practice.
<h3>Example: Fisher’s LSD Test in R</h3>
Suppose a professor wants to know whether or not three different studying techniques lead to different exam scores among students.
To test this, she randomly assigns 10 students to use each studying technique and records their exam scores.
The following table shows the exam scores for each student based on the studying technique they used:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/leastSigDiff1.png">
We can use the following code to create this dataset and perform a one-way ANOVA on it in R:
<b>#create data frame
df &lt;- data.frame(technique = rep(c("tech1", "tech2", "tech3"), each = 10),   score = c(72, 73, 73, 77, 82, 82, 83, 84, 85, 89,             81, 82, 83, 83, 83, 84, 87, 90, 92, 93,             77, 78, 79, 88, 89, 90, 91, 95, 95, 98))
#view first six rows of data frame
head(df)
  technique score
1     tech1    72
2     tech1    73
3     tech1    73
4     tech1    77
5     tech1    82
6     tech1    82
#fit one-way ANOVA
model &lt;- aov(score ~ technique, data = df)
#view summary of one-way ANOVA
summary(model)
            Df Sum Sq Mean Sq F value Pr(>F)  
technique    2  341.6  170.80   4.623 0.0188 *
Residuals   27  997.6   36.95                 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</b>
Since the p-value in the ANOVA table (.0188) is less than .05, we can conclude that not all of the mean exam scores between the three groups are equal.
Thus, we can proceed to perform Fisher’s LSD test to determine which group means are different.
The following code shows how to do so:
<b>library(agricolae)
#perform Fisher's LSD
print(LSD.test(model,"technique"))
            
$statistics
   MSerror Df Mean       CV  t.value     LSD
  36.94815 27 84.6 7.184987 2.051831 5.57767
$parameters
        test p.ajusted    name.t ntr alpha
  Fisher-LSD      none technique   3  0.05
$means
      score      std  r      LCL      UCL Min Max   Q25  Q50   Q75
tech1  80.0 5.868939 10 76.05599 83.94401  72  89 74.00 82.0 83.75
tech2  85.8 4.391912 10 81.85599 89.74401  81  93 83.00 83.5 89.25
tech3  88.0 7.557189 10 84.05599 91.94401  77  98 81.25 89.5 94.00
$comparison
NULL
$groups
      score groups
tech3  88.0      a
tech2  85.8      a
tech1  80.0      b
attr(,"class")
[1] "group"
</b>
The portion of the output that we’re most interested in is the section titled <b>$groups</b>. The techniques that have different characters in the <b>groups</b> column are significantly different.
From the output we can see:
Technique 1 and Technique 3 have significantly different mean exam scores (since tech1 has a value of “b” and tech3 has a value of “a”)
Technique 1 and Technique 2 have significantly different mean exam scores (since tech1 has a value of “b” and tech2 has a value of “a”)
Technique 2 and Technique 3 <b>do not</b> have significantly different mean exam scores (since they both have a value of “a”)
<h2><span class="orange">How to Fit a Gamma Distribution to a Dataset in R</span></h2>
This tutorial explains how to fit a <b>gamma distribution</b> to a dataset in R.
<h2>Fitting a Gamma Distribution in R</h2>
Suppose you have a dataset <em>z </em>that was generated using the approach below:
<b>#generate 50 random values that follow a gamma distribution with shape parameter = 3
#and shape parameter = 10 combined with some gaussian noise
z &lt;- rgamma(50, 3, 10) + rnorm(50, 0, .02)
#view first 6 values
head(z)
[1] 0.07730 0.02495 0.12788 0.15011 0.08839 0.09941</b>
To see how well a gamma distribution fits this dataset <em>z</em>, we can use the <b>fitdistrplus</b> package in R:
<b>#install 'fitdistrplus' package if not already installed
install.packages('fitdistrplus')
#load package
library(fitdistrplus)</b>
The general syntax to use to fit a distribution using this package is:
<b>fitdist(dataset, distr = “your distribution choice”, method = “your method of fitting the data”)</b>
In this case, we will fit the dataset <em>z </em>that we generated earlier using the gamma distribution and maximum likelihood estimation approach to fitting the data:
<b>#fit our dataset to a gamma distribution using mle
fit &lt;- fitdist(z, distr = "gamma", method = "mle")
#view the summary of the fit 
summary(fit)</b>
This produces the following output:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/gammaFit.jpg" alt="">
Next, we can produce some plots that show how well the gamma distribution fits the dataset using the following syntax:
<b>#produce plots
plot(fit)</b>
This produces the following plots:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/gammaFit2.png">
Here is the complete code we used to fit a gamma distribution to a dataset in R:
<b>#install 'fitdistrplus' package if not already installed
install.packages('fitdistrplus')
#load package
library(fitdistrplus)
#generate 50 random values that follow a gamma distribution with shape parameter = 3
#and shape parameter = 10 combined with some gaussian noise
z &lt;- rgamma(50, 3, 10) + rnorm(50, 0, .02)
#fit our dataset to a gamma distribution using mle
fit &lt;- fitdist(z, distr = "gamma", method = "mle")
#view the summary of the fit
summary(fit)
#produce plots to visualize the fit
plot(fit)
</b>
<h2><span class="orange">How to Calculate a Five Number Summary in Excel</span></h2>
A <b>five number summary </b>is a way to summarize a dataset using the following five values:
The minimum
The first quartile
The median
The third quartile
The maximum
The five number summary is useful because it provides a concise summary of the distribution of the data in the following ways:
It tells us where the  middle value  is located, using the median.
It tells us how  spread out  the data is, using the first and third quartiles.
It tells us the range of the data, using the minimum and the maximum.
By simply knowing these five values, we can know a great deal about a dataset.
<h2>How to Find the Five Number Summary in Excel</h2>
We can find the five number summary of a dataset in Excel using the following steps:
<b>Step 1: Enter the data values in one column.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum1.png">
<b>Step 2: Find the five number summary.</b>
The five values of the five number summary are shown in column D and the formulas used to find these values are shown in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum2.png">
Thus, the five number summary for this data is as follows:
<b>Minimum: </b>4
<b>1st Quartile: </b>7.5
<b>Median: </b>17
<b>3rd Quartile: </b>22
<b>Max: </b>28
<b>Technical Note:</b>
 
There are technically two quartile functions in Excel:
 
<b>QUARTILE.INC() </b>– Calculates percentiles using “greater than or equal to” in an “inclusive” manner.
 
<b>QUARTILE.EXC() </b>– Calculates percentiles using “greater than” in an “exclusive” manner.
 
The default function <b>QUARTILE() </b>uses the <b>QUARTILE.INC() </b>method.
<h2>Visualizing a Five Number Summary Using a Boxplot</h2>
One of the easiest ways to visualize a five number summary is by creating a  boxplot , sometimes called a box-and-whisker plot, which uses a box with a line in the middle along with “whiskers” that extend on each end. 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/boxplot.png">
You can perform the following steps to create a boxplot in Excel:
<b>Step 1: Highlight the data values.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum3.png">
<b>Step 2: In the <em>Insert </em>tab in the <em>Charts </em>group along the top ribbon, click the tiny arrow in the bottom left corner to “See All Charts.”</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum4.png">
<b>Step 3: Select “Box & Whisker” and click OK.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum5.png">
A box and whisker plot will automatically be displayed.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum6.png">
The top whisker represents the max, the top of the box represents the 3rd quartile, the middle line in the box represents the median, the tiny “x” in the box represents the average, the bottom of the box represents the 1st quartile, and the bottom whisker represents the minimum value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum7.png">
You can change the background color and the chart title as well to make it more aesthetically pleasing:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/fiveNumSum8.png">
<h2><span class="orange">How to Calculate a Five Number Summary in Google Sheets</span></h2>
A <b>five number summary </b>is a way to summarize a dataset using the following five values:
The minimum
The first quartile
The median
The third quartile
The maximum
The five number summary is useful because it provides a concise summary of the distribution of the data in the following ways:
It tells us where the  middle value  is located, using the median.
It tells us how  spread out  the data is, using the first and third quartiles.
It tells us the range of the data, using the minimum and the maximum.
By simply knowing these five values, we can know a great deal about a dataset.
<h3>How to Find a Five Number Summary in Google Sheets</h3>
We can use the following steps to find the five number summary of a dataset in Google Sheets:
<b>Step 1: Enter all data values in one column.</b>
First, enter the values of the dataset in one column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/fiveNumSumSheets1.png">
<b>Step 2: Calculate the five number summary.</b>
The five values of the five number summary are shown in column D and the formulas used to find these values are shown in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/fiveNumSumSheets2.png">
Thus, the five number summary of this dataset is:
Minimum: <b>4</b>
1st Quartile: <b>7.5</b>
Median: <b>17</b>
3rd Quartile: <b>22</b>
Maximum: <b>28</b>
From these five numbers we can get a good idea of where the center of the dataset is located, how spread out the values are, and the range of values.
<b>Technical Note:</b>
 
There are two quartile functions in Google Sheets:
 
<b>QUARTILE.INC() </b>– Calculates percentiles using “greater than or equal to” in an “inclusive” manner.
 
<b>QUARTILE.EXC() </b>– Calculates percentiles using “greater than” in an “exclusive” manner.
 
The default function <b>QUARTILE() </b>uses the <b>QUARTILE.INC() </b>method.
<h3>Visualize a Five Number Summary</h3>
One of the easiest ways to visualize a five number summary is by creating a  boxplot , which uses a box with a line in the middle along with “whiskers” that extend on each end to represent the minimum and maximum values.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/boxplot.png">
Feel free to use the  Statology Boxplot Generator  to automatically create a boxplot for a given dataset.
You can also follow  this tutorial  to find out how to create a boxplot in Google Sheets for a given dataset.
<h2><span class="orange">How to Calculate Five Number Summary in R (With Examples)</span></h2>
A <b>five number summary </b>is a way to summarize a dataset using the following five values:
The minimum
The first quartile
The median
The third quartile
The maximum
The five number summary is useful because it provides a concise summary of the distribution of the data in the following ways:
It tells us where the  middle value  is located, using the median.
It tells us how  spread out  the data is, using the first and third quartiles.
It tells us the range of the data, using the minimum and the maximum.
The easiest way to calculate a five number summary of a dataset in R is to use the <b>fivenum()</b> function from base R:
<b>fivenum(data)
</b>
The following example shows how to use this syntax in practice.
<h3>Example 1: Five Number Summary of Vector</h3>
The following code shows how to calculate the five number summary of a numeric vector in R:
<b>#define numeric vector
data &lt;- c(4, 6, 6, 7, 8, 9, 12, 13, 14, 15, 15, 18, 22)
#calculate five number summary of data
fivenum(data)
[1]  4  7 12 15 22
</b>
From the output we can see:
The minimum: <b>4</b>
The first quartile: <b>7</b>
The median: <b>12</b>
The third quartile: <b>15</b>
The maximum: <b>22</b>
We can quickly visualize the five number summary by creating a boxplot:
<b>boxplot(data)
[1]  4  7 12 15 22</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/fivenum1.png">
Here’s how to interpret the boxplot:
The line at the bottom of the plot represents the minimum value (<b>4</b>).
The line at the bottom of the box represents the first quartile (<b>7</b>).
The line in the middle of the box represents the median (<b>12</b>).
The line at the top of the box represents the third quartile (<b>15</b>).
The line at the top of the plot represents the maximum value (<b>22</b>).
<h3>Example 2: Five Number Summary of Column in Data Frame</h3>
The following code shows how to calculate the five number summary of a specific column in a data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'), points=c(99, 90, 86, 88, 95, 87, 85, 89), assists=c(33, 28, 31, 39, 34, 30, 29, 25), rebounds=c(30, 28, 24, 24, 28, 30, 31, 35))
#calculate five number summary of points column
fivenum(df$points)
[1] 85.0 86.5 88.5 92.5 99.0
</b>
<h3>Example 3: Five Number Summary of Multiple Columns</h3>
The following code shows how to use the <b>sapply()</b> function to calculate the five number summary of several columns in a data frame at once:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'), points=c(99, 90, 86, 88, 95, 87, 85, 89), assists=c(33, 28, 31, 39, 34, 30, 29, 25), rebounds=c(30, 28, 24, 24, 28, 30, 31, 35))
#calculate five number summary of points, assists, and rebounds column
sapply(df[c('points', 'assists', 'rebounds')], fivenum)
     points assists rebounds
[1,]   85.0    25.0     24.0
[2,]   86.5    28.5     26.0
[3,]   88.5    30.5     29.0
[4,]   92.5    33.5     30.5
[5,]   99.0    39.0     35.0</b>
<b>Related:</b>  A Guide to apply(), lapply(), sapply(), and tapply() in R 
<h2><span class="orange">How to Calculate a Five Number Summary in SPSS</span></h2>
A <b>five number summary </b>is a way to summarize a dataset using the following five values:
The minimum
The first quartile
The median
The third quartile
The maximum
The five number summary is useful because it provides a concise summary of the distribution of the data in the following ways:
It tells us where the middle value is located, using the median.
It tells us how spread out the data is, using the first and third quartiles.
It tells us the range of the data, using the minimum and the maximum.
This tutorial explains how to quickly calculate a five number summary for a dataset in SPSS.
<h3>Example: Five Number Summary in SPSS</h3>
Suppose we have the following dataset in SPSS that displays the annual income (in thousands) of 15 individuals:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/outliersSPSS1.png">
To calculate the five number summary for this dataset, click the <b>Analyze </b>tab, then <b>Descriptive Statistics</b>, then <b>Frequencies</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fiveNumSumSPSS1.png">
In the new window that pops up, drag the variable <b>income </b>into the box labelled Variable(s).
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fiveNumSumSPSS2.png">
Next, click the <b>Statistics </b>button. Make sure each of the following boxes is checked:
Quartiles
Minimum
Maximum
Median
Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fiveNumSumSPSS3.png">
Then click <b>OK</b>. The five number summary results will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/fiveNumSumSPSS4.png">
From the results we can see the five number summary for this dataset is as follows:
The minimum: <b>18</b>
The first quartile: <b>34.00</b>
The median: <b>54.00</b>
The third quartile: <b>85.00</b>
The maximum: <b>108</b>
<h2><span class="orange">How to Find a Five Number Summary on a TI-84 Calculator</span></h2>
A <b>five number summary</b> is a way to summarize a dataset using the following five values:
The minimum
The first quartile
The median
The third quartile
The maximum
By simply knowing these five values, we can know a great deal about a dataset.
The following step-by-step example shows how to find the five number summary for the following dataset on a TI-84 calculator:
<b>Dataset:</b> 4, 6, 6, 7, 8, 12, 15, 17, 20, 21, 21, 23, 24, 27, 28
<h3>Step 1: Enter the Data</h3>
First, we will input the data values. Press Stat, then press EDIT. Then enter the values of the dataset in column L1:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sum1.png">
<h3>Step 2: Find the Five Number Summary</h3>
Next, press Stat and then scroll over to the right and press CALC. Then press 1-Var Stats.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sum2.png">
In the new screen that appears, simply press Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sum3.png">
Once you press Enter, a list of summary statistics will appear. Scroll down to the very bottom of the list:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sum4.png">
From this screen we can observe the five number summary:
The minimum: <b>4</b>
The first quartile (Q1): <b>7</b>
The median: <b>17</b>
The third quartile (Q3): <b>23</b>
The maximum: <b>28</b>
These five numbers summarize the distribution of values in our original dataset.
We can also use these numbers to find the following metrics:
Range: Maximum – Minimum = 28 – 4 = <b>4</b>
Interquartile Range: Q3 – Q1 = 23 – 7 = <b>16</b>
These two metrics give us an idea of how  spread out  the values are in the dataset.
<h2><span class="orange">How to Calculate Fleiss’ Kappa in Excel</span></h2>
<b>Fleiss’ Kappa </b>is a way to measure the degree of agreement between three or more raters when the raters are assigning categorical ratings to a set of items.
Fleiss’ Kappa ranges from 0 to 1 where:
<b>0 </b>indicates no agreement at all among the raters.
<b>1 </b>indicates perfect inter-rater agreement.
This tutorial provides an example of how to calculate Fleiss’ Kappa in Excel.
<h3>Example: Fleiss’ Kappa in Excel</h3>
Suppose 14 individuals rate 10 different products on a scale of Poor to Excellent.
The following screenshot displays the total ratings that each product received:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/fleiss_kappa_excel2.png">
The following screenshot shows how to calculate Fleiss’ Kappa for this data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/fleiss_kappa_excel1.png">
The trickiest calculations in this screenshot are in column J. The formula used for these calculations is shown in the text box near the top of the screen.
Note that the Fleiss’ Kappa in this example turns out to be <b>0.2099</b>. The actual formula used to calculate this value in cell C18 is:
Fleiss’ Kappa = (0.37802 – 0.2128) / (1 –  0.2128) = 0.2099.
Although there is no formal way to interpret Fleiss’ Kappa, the following values show how to interpret Cohen’s Kappa, which is used to assess the level of inter-rater agreement between just two raters:
&lt; 0.20 | Poor
.21 – .40 | Fair
.41 – .60 | Moderate
.61 – .80 | Good
.81 – 1 | Very Good
Based on these values, Fleiss’ Kappa of <b>0.2099 </b>in our example would be interpreted as a “fair” level of inter-rater agreement.
<h2><span class="orange">What is a Floor Effect? (Explanation & Example)</span></h2>
In research, a <b>floor effect</b> (sometimes called a “basement effect”) occurs when there is some lower limit on a survey or questionnaire and a large percentage of respondents score near this lower limit. The opposite of this is known as a  ceiling effect .
A floor effect can cause a variety of problems including:
It makes it difficult to get an accurate  measure of central tendency .
It makes it difficult to get an accurate  measure of dispersion .
It makes it difficult to rank individuals according to score.
It makes it difficult to compare the means between two groups.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/floor1.png">
This tutorial provides several examples of floor effects, details on why they’re problematic, and ways to prevent them from occurring.
<h3>Floor Effect Examples</h3>
The following examples illustrate scenarios where floor effects may occur in research.
<b>Example 1: A Questionnaire on Income.</b>
Suppose researchers want to understand the distribution of household incomes in a particular neighborhood so they create a questionnaire to give to each household. Since they want to prevent  nonresponse bias , they decide to ask households “which income bracket they fall in” and make the lowest bracket <em>$30k or less</em>.
In this case, even if households make far less than $30k per year, they will be grouped into the <em>$30k or less</em> group. If many households fall into this group and if many households make far less than this amount, then researchers will not actually get an accurate idea of the distribution of household income.
<b>Example 2: A Difficult IQ Exam</b>
Suppose a 1st grade teacher administers an IQ exam to her students that is actually designed for adults. More than likely, each student will score at or near the lowest possible score simply because the exam is far too difficult for them.
Because of this, it will be difficult for the teacher to rank the scores of the students in any type of order and she won’t be able to get an accurate idea of how spread out the IQ scores truly are for the students.
<h3>Problems Caused by Floor Effects</h3>
Floor effects cause a variety of problems including:
<b>1. It makes it difficult to get an accurate measure of central tendency.</b>
If a large percentage of respondents score at or near the lowest possible value in an exam, questionnaire, or survey, it will become difficult to get an accurate measure of what the “average” score should be.
<b>2. It makes it difficult to get an accurate measure of dispersion.</b>
Similarly, if many respondents score near the lowest possible value on an exam or survey, it will make it seem as if there is less dispersion than there really is.
<b>3. It makes it difficult to rank individuals according to score.</b>
If many individuals receive the lowest possible score on an exam, it becomes impossible to rank the individuals in any way since many of them received the same score.
<b>4. It makes it difficult to differentiate between two groups.</b>
Suppose a professor wants to know if two different studying techniques lead to different average exam scores. If the exam is far too difficult then most of the students in each group will score near the lowest possible value, which will make it impossible to compare the average exam scores between each group to determine if the studying technique made any difference.
<h3>How to Prevent Floor Effects</h3>
There are two common ways to prevent floor effects:
<b>1. In surveys and questionnaires, provide anonymity and don’t set artificial floors on responses.</b>
For example, in a questionnaire about household incomes researchers need to reassure respondents that their answers will be completely  anonymous  and allow respondents to fill in their actual income instead of selecting from brackets.
This will increase the likelihood that respondents will provide their true income since their answer will be anonymous and it will allow researchers to understand the actual income distribution without extremely low incomes being masked from the responses.
<b>2. Make exams or tests less difficult so respondents can score a wider variety of scores.</b>
For exams and tests, it’s important that researchers increase the difficulty so that a smaller percentage of individuals are able to score at or near a perfect score.
This will allow researchers to gain an accurate understanding of the mean and the dispersion of the data. This also allows researchers to be able to rank the scores of individuals since fewer individuals are likely to receive the same score.
<h2><span class="orange">For-Loop with Range in R (Including Examples)</span></h2>
You can use the following basic syntax to write a for-loop with a range in R:
<b>for(i in 1:10) {
  do something
}
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Print Values in Range</h3>
The following code shows how to use a for-loop to print every value in a certain range:
<b>#print every value in range of 1 to 10
for(i in 1:10) {
  print(i)
}
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
</b>
<h3>Example 2: Perform Operation on Values in Range</h3>
The following code shows how to use a for-loop to perform a specific operation on every value in a certain range:
<b>#define vector
x &lt;- c(4, 7, 9, 12, 14, 16, 19)
#print square root of every value in vector
for(i in 1:length(x)) {
 print(paste('The square root of the value in position', i, 'is', sqrt(x[i])))
}
[1] "The square root of the value in position 1 is 2"
[1] "The square root of the value in position 2 is 2.64575131106459"
[1] "The square root of the value in position 3 is 3"
[1] "The square root of the value in position 4 is 3.46410161513775"
[1] "The square root of the value in position 5 is 3.74165738677394"
[1] "The square root of the value in position 6 is 4"
[1] "The square root of the value in position 7 is 4.35889894354067"</b>
<h3>Example 3: Perform Operation on Values in Data Frame</h3>
The following code shows how to use a for-loop to perform a specific operation on every value in a specific column of a data frame in r:
<b>#define data frame
df &lt;- data.frame(a=c(3, 4, 4, 5, 8), b=c(8, 8, 7, 8, 12), c=c(11, 15, 19, 15, 11))
#view data frame
df
  a  b  c
1 3  8 11
2 4  8 15
3 4  7 19
4 5  8 15
5 8 12 11
#multiply every value in column 'a' by 2
for(i in 1:length(df$a)) {
  df$a[i] = df$a[i]*2
}
#view updated data frame
df
   a  b  c
1  6  8 11
2  8  8 15
3  8  7 19
4 10  8 15
5 16 12 11
</b>
<h2><span class="orange">How to Create a Forecast in Google Sheets (With Example)</span></h2>
You can use the <b>FORECAST</b> function in Google Sheets to calculate the expected value of some future observation using historical data.
This function uses the following methods:
<b>Method 1: Forecast One Future Value</b>
<b>=FORECAST(A17, B2:B16, A2:A16)
</b>
This particular formula forecasts the y-value that corresponds to the x-value in cell <b>A17</b> using the range <b>B2:B16</b> as the past y-values and the range <b>A2:A16</b> as the past x-values.
<b>Method 2: Forecast Multiple Future Values</b>
<b>=ArrayFormula(FORECAST(A17:A19, B2:B16, A2:A16))</b>
This particular formula forecasts the y-values that corresponds to the x-values in the range <b>A17:A19</b> using the range <b>B2:B16</b> as the past y-values and the range <b>A2:A16</b> as the past x-values.
The following examples show how to use each method in practice.
<h3>Example 1: Forecast One Future Value</h3>
The following screenshot shows how to use the <b>FORECAST</b> function to forecast the sales value for 4/1/2021 using <b>A2:A16</b> as the historical months and <b>B2:B16</b> as the historical sales values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/forecastsheets1.jpg">
The <b>FORECAST</b> function predicts that there will be <b>156.955</b> total sales on 4/1/2021.
<h3>Example 2: Forecast Multiple Future Values</h3>
The following screenshot shows how to use the <b>FORECAST</b> function to forecast the sales values for 4/1/2021 through 6/1/2021 using <b>A2:A16</b> as the historical months and <b>B2:B16</b> as the historical sales values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/forecastsheets2.jpg">
We can see that the <b>FORECAST</b> function produces a forecasted number of sales for each of the three months that we specified.
Note that you can also create a bar chart to visualize the predicted sales. Simply highlight the cells in the range <b>A2:B19</b>, then click the <b>Insert</b> tab, then click <b>Chart</b>. A bar chart will automatically be created.
Click on the last three bars in the chart to change each of their fill colors to red to indicate that they represent predicted values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/forecastsheets3.jpg"588">
The x-axis shows the date and the y-axis shows the sales for each date.
<b>Note 1</b>: Under the hood, the <b>FORECAST</b> function simply uses simple linear regression to find the line that best fits the dataset and then uses the fitted regression model to predict future values.
<b>Note 2</b>: You can find the complete documentation for the <b>FORECAST </b>function in Google Sheets  here .
<h2><span class="orange">How to Create a Forest Plot in Excel</span></h2>
A <b>forest plot</b> (sometimes called a “blobbogram”) is used in a meta-analysis to visualize the results of several studies in one plot.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel14.png">
The x-axis displays the value of interest in the studies (often an odds ratio, effect size, or mean difference) and the y-axis displays the results from each individual study.
This type of plot offers a convenient way to visualize the results of several studies all at once.
The following step-by-step example shows how to create a forest plot in Excel.
<h3>Step 1: Enter the Data</h3>
First, we’ll enter the data for each study in the following format:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel1.png">
<h3>Step 2: Create a Horizontal Bar Chart</h3>
Next, highlight the cells in the range A2:B21. Along the top ribbon, click the <b>Insert</b> tab and then click the 2-D clustered bar option in the <b>Charts</b> section. The following horizontal bar chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel2.png">
<h3>Step 3: Move Axis Labels to Left Side</h3>
Next, double click the vertical axis labels. In the <b>Format Axis</b> pane that appears on the right side of the screen, set <b>Label Position</b> to Low:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel3.png">
This will move the vertical axis labels to the left side of the graph:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel4-1.png">
<h3>Step 4: Add Scatterplot Points</h3>
Next, we’ll add a new series titled <b>Points</b> that we’ll use to add scatterplot points to the graph:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel5.png">
Next, right click anywhere on the plot and click <b>Select Data</b>. In the new window that appears, click <b>Add</b> to add a new series. Then leave the Series Name blank and click <b>OK</b>. This will add a single bar to the plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel6.png">
Next, right click the single orange bar and click <b>Change Series Chart Type</b>. In the new window that appears, change Series2 to a scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel7.png">
Once you click <b>OK</b>, a single scatterplot point will appear on the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel8.png">
Next, right click the single orange point and click <b>Select Data</b>. In the window that appears, click <b>Series2</b> and then click <b>Edit</b>.
Use the cell range that contains Effect Size for the x-values and the cell range that contains Points for the y-values. Then click <b>OK</b>.
The following scatterplot points will be added to the plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel9.png">
<h3>Step 5: Remove the Bars</h3>
Next, right click on any of the bars in the plot and change the fill color to <b>No Fill</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel10.png">
Next, double click the y-axis on the right and change the axis bounds to a minimum of 0 and a maximum of 20. Then click the y-axis on the right and delete it. You’ll be left with the following plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel11.png">
<h3>Step 6: Add Error Bars</h3>
Next, click the tiny green plus sign in the top right corner of the plot. In the dropdown menu, check the box next to <b>Error Bars</b>. Then click on one of the vertical error bars on any of the points and click delete to remove the vertical error bars from each point.
Next, click the <b>More Options</b> in the dropdown next to Error Bars. In the pane that appears on the right, specify the custom error bars to use for the upper and lower bounds of the confidence intervals:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel12.png">
This will result in the following error bars on the plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel13.png">
<h3>Step 7: Add Title & Axis Labels</h3>
Lastly, feel free to add a title and axis labels and modify the colors of the chart to look more aesthetically pleasing:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestplotExcel14.png">
You can find more Excel visualization tutorials on  this page .
<h2><span class="orange">How to Create a Forest Plot in R</span></h2>
A <b>forest plot</b> (sometimes called a “blobbogram”) is used in a meta-analysis to visualize the results of several studies in one plot.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestPlotR3.png">
The x-axis displays the value of interest in the studies (often an odds ratio, effect size, or mean difference) and the y-axis displays the results from each individual study.
This type of plot offers a convenient way to visualize the results of several studies all at once.
The following example shows how to create a forest plot in R.
<h3>Example: Forest Plot in R</h3>
To create a forest plot in R, we need to first create a data frame to hold the effect size (or whatever value of interest) and the upper and lower confidence intervals for each study:
<b>#create data
df &lt;- data.frame(study=c('S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7'), index=1:7, effect=c(-.4, -.25, -.1, .1, .15, .2, .3), lower=c(-.43, -.29, -.17, -.02, .04, .17, .27), upper=c(-.37, -.21, -.03, .22, .24, .23, .33))
#view data
head(df)
  study index effect lower upper
1    S1     1  -0.40 -0.43 -0.37
2    S2     2  -0.25 -0.29 -0.21
3    S3     3  -0.10 -0.17 -0.03
4    S4     4   0.10 -0.02  0.22
5    S5     5   0.15  0.04  0.24
6    S6     6   0.20  0.17  0.23
7    S7     7   0.30  0.27  0.33</b>
Next, we can use functions from the ggplot2 data visualization package to create the following forest plot:
<b>#load ggplot2
library(ggplot2)
#create forest plot
ggplot(data=df, aes(y=index, x=effect, xmin=lower, xmax=upper)) +
  geom_point() + 
  geom_errorbarh(height=.1) +
  scale_y_continuous(name = "", breaks=1:nrow(df), labels=df$study)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestPlotR1.png">
The x-axis displays the effect size for each study and the y-axis displays the name of each study.
The points in the plot displays the effect size for each study and the error bars show the confidence interval bounds.
Note that we can also add a title, modify the axis labels, and add a vertical line at an effect size of zero to make the chart more aesthetically pleasing:
<b>#load ggplot2
library(ggplot2)
#create forest plot
ggplot(data=df, aes(y=index, x=effect, xmin=lower, xmax=upper)) +
  geom_point() + 
  geom_errorbarh(height=.1) +
  scale_y_continuous(breaks=1:nrow(df), labels=df$study) +
  labs(title='Effect Size by Study', x='Effect Size', y = 'Study') +
  geom_vline(xintercept=0, color='black', linetype='dashed', alpha=.5) +
  theme_minimal()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestPlotR2.png">
Feel free to modify the theme of the plot to make it look however you’d like. For example, we could also use <b>theme_classic()</b> for an even more classic appearance:
<b>#load ggplot2
library(ggplot2)
#create forest plot
ggplot(data=df, aes(y=index, x=effect, xmin=lower, xmax=upper)) +
  geom_point() + 
  geom_errorbarh(height=.1) +
  scale_y_continuous(breaks=1:nrow(df), labels=df$study) +
  labs(title='Effect Size by Study', x='Effect Size', y = 'Study') +
  geom_vline(xintercept=0, color='black', linetype='dashed', alpha=.5) +
  theme_classic()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/forestPlotR3.png">
<h2><span class="orange">Format Pivot Tables in Google Sheets (Step-by-Step)</span></h2>
Pivot tables offer an easy way to summarize the values of a dataset.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format9-1.png">
This tutorial provides a step-by-step example of how to create and format a pivot table for a raw dataset in Google Sheets.
<h3>Step 1: Enter the Data</h3>
First, let’s enter some sales data for an imaginary company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format1.png">
<h3>Step 2: Create the Pivot Table</h3>
Next, highlight all of the data. Along the top ribbon, click <b>Data</b> and then click <b>Pivot table</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format2.png">
Choose to enter the pivot table in a new sheet or an existing sheet, then click <b>Create</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format3.png">
In the pivot table editor that appears to the right, add the Product to the <b>Rows</b>, Region to the <b>Columns</b>, and Sales to the <b>Values</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format4.png">
Our pivot table will now look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format5.png">
<h3>Step 3: Choose a Custom Theme</h3>
Next, click the <b>Format</b> tab along the top ribbon and click <b>Theme</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format6.png">
In the window that appears to the right, click any theme you’d like for the pivot table. Or you can click <b>Customize</b> to choose your own theme colors.
We’ll choose the <b>Simple Light</b> theme:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format7.png">
<h3>Step 4: Add a Border & Center the Text</h3>
Next, we’ll highlight all of the data and add a border around each cell:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format8.png">
Lastly, we’ll center the data values inside the pivot table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/format9-1.png">
The pivot table is now formatted to look neat and clean.
You can find more Google Sheets tutorials on  this page .
<h2><span class="orange">What is Forward Selection? (Definition & Example)</span></h2>
In statistics, <b>stepwise selection</b> is a procedure we can use to build a  regression model  from a set of predictor variables by entering and removing predictors in a stepwise manner into the model until there is no statistically valid reason to enter or remove any more.
The goal of stepwise selection is to build a regression model that includes all of the predictor variables that are statistically significantly related to the  response variable .
One of the most commonly used stepwise selection methods is known as <b>forward selection</b>, which works as follows:
<b>Step 1:</b> Fit an intercept-only regression model with no predictor variables. Calculate the AIC<b>*</b> value for the model.
<b>Step 2:</b> Fit every possible one-predictor regression model. Identify the model that produced the lowest AIC and also had a statistically significant reduction in AIC compared to the intercept-only model.
<b>Step 3:</b> Fit every possible two-predictor regression model. Identify the model that produced the lowest AIC and also had a statistically significant reduction in AIC compared to the one-predictor model.
Repeat the process until fitting a regression model with more predictor variables no longer leads to a statistically significant reduction in AIC.
<b>*</b>There are several metrics you could use to calculate the quality of fit of a regression model including cross-validation prediction error, Cp, BIC, AIC, or adjusted R<sup>2</sup>. In the example below we choose to use AIC.
The following example shows how to perform forward selection in R.
<h3>Example: Forward Selection in R</h3>
For this example we’ll use the built-in  mtcars dataset  in R:
<b>#view first six rows of <em>mtcars
</em>head(mtcars)
   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
</b>
We will fit a multiple linear regression model using <em>mpg </em>(miles per gallon) as our response variable and all of the other 10 variables in the dataset as potential predictors variables.
The following code shows how to perform forward stepwise selection:
<b>#define intercept-only model
intercept_only &lt;- lm(mpg ~ 1, data=mtcars)
#define model with all predictors
all &lt;- lm(mpg ~ ., data=mtcars)
#perform forward stepwise regression
forward &lt;- step(intercept_only, direction='forward', scope=formula(all), trace=0)
#view results of forward stepwise regression
forward$anova
   Step Df  Deviance Resid. Df Resid. Dev       AIC
1       NA        NA        31  1126.0472 115.94345
2  + wt -1 847.72525        30   278.3219  73.21736
3 + cyl -1  87.14997        29   191.1720  63.19800
4  + hp -1  14.55145        28   176.6205  62.66456
#view final model
forward$coefficients
(Intercept)          wt         cyl          hp 
 38.7517874  -3.1669731  -0.9416168  -0.0180381 
</b>
Here is how to interpret the results:
First, we fit the intercept-only model. This model had an AIC of <b>115.94345</b>.
Next, we fit every possible one-predictor model. The model that produced the lowest AIC and also had a statistically significant reduction in AIC compared to the intercept-only model used the predictor <em>wt</em>. This model had an AIC of <b>73.21736</b>.
Next, we fit every possible two-predictor model. The model that produced the lowest AIC and also had a statistically significant reduction in AIC compared to the single-predictor model added the predictor <em>cyl</em>. This model had an AIC of <b>63.19800</b>.
Next, we fit every possible three-predictor model. The model that produced the lowest AIC and also had a statistically significant reduction in AIC compared to the two-predictor model added the predictor <em>hp</em>. This model had an AIC of <b>62.66456</b>.
Next, we fit every possible four-predictor model. It turned out that none of these models produced a significant reduction in AIC, thus we stopped the procedure.
Thus, the final model turns out to be:
<b>mpg = 38.75 – 3.17*wt – 0.94*cyl – 0.02*hyp</b>
It turns out that attempting to add more predictor variables to the model does not lead to a statistically significant reduction in AIC.
Thus, we conclude that the best model is the one with three predictor variables: wt, cyl, and hp.
<h3>A Note on Using AIC</h3>
In the previous example, we chose to use AIC as the metric for evaluating the fit of various regression models.
AIC stands for <b>Akaike information criterion</b> and is calculated as:
AIC = 2K – 2<em>ln</em>(L)
where:
<b>K:</b> The number of model parameters.
<b><em>ln</em>(L)</b>: The log-likelihood of the model. This tells us how likely the model is, given the data.
However, there are other metrics you might choose to use to evaluate the fit of regression models including cross-validation prediction error, Cp, BIC, AIC, or adjusted R<sup>2</sup>.
Fortunately, most statistical software allows you to specify which metric you would like to use when performing forward selection.
<h2><span class="orange">How to Create a Frequency Distribution in Excel</span></h2>
A <b>frequency distribution </b>describes how often different values occur in a dataset. It’s a useful way to understand how data values are distributed in a dataset.
Fortunately it’s easy to create and visualize a frequency distribution in Excel by using the following function:
<b>=FREQUENCY(data_array, bins_array)</b>
 
where:
 
<b>data_array</b>: array of raw data values
<b>bins_array: </b>array of upper limits for bins
The following example illustrates how to use this function in practice.
<h3>Example: Frequency Distribution in Excel</h3>
Suppose we have the following dataset of 20 values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/frequencyDistExcel1.png">
First, we will tell Excel what upper limits we’d like to use on the bins of our frequency distribution. For this example we’ll choose 10, 20, and 30. That is, we’ll find the frequencies for the following bins:
<b>0 to 10</b>
<b>11 to 20</b>
<b>21 to 30</b>
<b>30+</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/frequencyDistExcel2.png">
Next, we’ll use the following <b>=FREQUENCY() </b>function to calculate the frequencies for each bin:
=FREQUENCY(A2:A21, C2:C4)
Here are the results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/frequencyDistExcel3.png">
The results show that:
<b>6 </b>values in the dataset are within the range of 0-10.
<b>7 </b>values in the dataset are within the range of 11-20.
<b>5 </b>values in the dataset are within the range of 21-30.
<b>2 </b>values in the dataset are greater than 30.
We can then use the following steps to visualize this frequency distribution:
Highlight the frequency counts in the range <b>D2:D5</b>.
Click on the <b>Insert </b>tab, then click on the chart titled <b>2-D Column </b>in the <b>Charts </b>group.
The following chart will appear that displays the frequencies for each bin:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/frequencyDistExcel4.png">
Feel free to modify the axes labels and bar widths to make the chart more aesthetically pleasing:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/frequencyDistExcel5.png">
<em>You can find more Excel tutorials  here .</em>
<h2><span class="orange">How to Calculate Frequencies in Google Sheets</span></h2>
<b>Frequencies </b>tell us how often different values occur in a dataset.
We can easily calculate frequencies in Google Sheets by using the <b>FREQUENCY()</b> function, which has the following syntax:
<b>FREQUENCY(data, classes)</b>
where:
<b>data:</b> Array containing data values
<b>classes: </b>Array containing a set of classes
The following examples show how to calculate frequencies and relative frequencies in Google Sheets.
<h3>Calculating Frequencies in Google Sheets</h3>
Suppose we have the following dataset with 15 values in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets1-1.png">
To calculate the frequency of each individual value (e.g. count how many 12’s occur, how many 13’s occur, etc.) we need to first define the classes in column B. We can easily do this by typing the following formula in cell B2:
<b>=SORT(UNIQUE(A2:A16))</b>
This produces the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets2.png">
Next, we can type the following formula into cell C2:
<b>=FREQUENCY(A2:A16, B2:B7)</b>
This produces the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets3.png">
The way to interpret this output is as follows:
The value <b>12</b> occurs in the original dataset <b>2 </b>times.
The value <b>13</b> occurs in the original dataset <b>3 </b>times.
The value <b>14</b> occurs in the original dataset <b>2 </b>times.
The value <b>15</b> occurs in the original dataset <b>4 </b>times.
The value <b>16</b> occurs in the original dataset <b>1 </b>time.
The value <b>17</b> occurs in the original dataset <b>3 </b>times.
<h3>Calculating Relative Frequencies in Google Sheets</h3>
Once we have calculated the frequencies of each individual data value, we can then calculate the relative frequencies of each value by typing the following formula into cell D2:
<b>=C2/COUNT($A$2:$A$16)</b>
This formula calculates the relative frequency of the value <b>12 </b>in the original dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets5.png">
Once we’ve calculated this relative frequency, we can hover the mouse over the bottom right corner of cell D2 until a small <b>+ </b>appears. Double click the <b>+ </b>to copy the formula down to the remaining cells:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets4.png">
The way to interpret this output is as follows:
The value <b>12</b> accounts for <b>0.133 </b>(or 13.3%) of all values in the dataset.
The value <b>13</b> accounts for <b>0.200 </b>(or 20.0%) of all values in the dataset.
And so on.
You’ll notice that the sum of all of the relative frequencies is equal to <b>1</b> (or 100%).
<h3>Visualizing Relative Frequencies in Google Sheets</h3>
Lastly, we can visualize the relative frequencies by creating a histogram.
First, highlight the array of relative frequencies:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets6.png">
Next, click the <b>Insert </b>tab along the top ribbon, then click <b>Chart</b>. Google Sheets will automatically produce the following histogram of relative frequencies:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets7.png">
We can easily add x-axis labels by clicking the <b>X-axis </b>input button within the <b>Chart Editor </b>and specifying cells <b>B2:B7 </b>as the labels. This produces the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/frequencySheets8.png">
This simple chart helps us quickly understand how often each individual value occurs in the original dataset.
<h2><span class="orange">How to Make a Frequency Polygon in Excel</span></h2>
A <b>frequency polygon </b>is a type of chart that helps us visualize a distribution of values.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly7.png">
This tutorial explains how to create a frequency polygon in Excel.
<h3>Example: Frequency Polygon in Excel</h3>
Use the following steps to create a frequency polygon.
<b>Step 1: Enter the data for a frequency table.</b>
Enter the following data for a frequency table that shows the number of students who received a certain score on an exam:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly1-1.png">
<b>Step 2: Find the midpoint of each class.</b>
Next, use the <b>=AVERAGE() </b>function in Excel to find the  midpoint  of each class, which represents the middle number in each class:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly2.png">
<b>Step 3: Create the frequency polygon.</b>
Next, we will create the frequency polygon. Highlight the frequency values in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly3.png">
Then go to the <b>Charts </b>group in the <b>Insert </b>tab and click the first chart type in <b>Insert Line or Area Chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly4.png">
A frequency polygon will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly5.png">
To change the x-axis labels, right click anywhere on the chart and click <b>Select Data</b>. A new window will pop up. Under <b>Horizontal (Category) Axis Labels </b>click <b>Edit </b>and type in the cell range that contains the Midpoint values. Click <b>OK </b>and the new axis labels will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly6.png">
Feel free to modify the chart title, add axis labels, and change the color of the plot to make it more aesthetically pleasing.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/freqPoly7.png">
From the frequency polygon we can easily see that most students scored in the 70s and 80s, with a few scoring in the 60s and even less scoring in the 50s and the 90s. 
<h2><span class="orange">How to Create a Frequency Polygon in R</span></h2>
A <b>frequency polygon</b> is a type of chart that helps you visualize the distribution of values in a dataset.
You can use the following syntax to create a frequency polygon using the  ggplot2  data visualization package in R:
<b>library(ggplot2)
ggplot(df, aes(value)) + 
  geom_freqpoly()
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Basic Frequency Polygon</h3>
The following code shows how to create a basic frequency polygon for a dataset:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(index=1:100, value=rnorm(100, mean=50, sd=10))
#create frequency polygon
ggplot(df, aes(value)) + 
  geom_freqpoly()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/freqPolyR1.png">
<h3>Example 2: Frequency Polygon with Custom Bins</h3>
By default, ggplot2 uses <b>30</b> bins to create the frequency polygon.
By reducing the number of bins, you can make the lines on the plot smoother. For example, the following code creates a frequency polygon using <b>10</b> bins:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(index=1:100, value=rnorm(100, mean=50, sd=10))
#create frequency polygon
ggplot(df, aes(value)) + 
  geom_freqpoly(bins=10)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/freqPolyR2.png">
<h3>Example 3: Frequency Polygon with Fill Color</h3>
If you’d like to fill in the frequency polygon with a certain color, you’ll need to instead use the <b>geom_area()</b> function as follows:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(index=1:100, value=rnorm(100, mean=50, sd=10))
#create frequency polygon filled with custom color
ggplot(df, aes(value)) + 
  geom_area(aes(y=..count..), bins=10, stat='bin', fill='steelblue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/freqPolyR3.png">
<h2><span class="orange">How to Create Frequency Tables in R (With Examples)</span></h2>
A <b>frequency table </b>is a table that displays the frequencies of different categories. This type of table is particularly useful for understanding the distribution of values in a dataset.
This tutorial explains how to create frequency tables in R using the following data frame:
<b>#make this example reproducible
set.seed(0)
#create data frame 
df &lt;- data.frame(store=rep(c('A', 'B', 'C'), each=3), sales=round(runif(9, 2, 6), 0), returns=round(runif(9, 1, 3), 0))
#view data frame 
df
  store sales returns
1     A     6       2
2     A     3       1
3     A     3       1
4     B     4       1
5     B     6       2
6     B     3       2
7     C     6       3
8     C     6       2
9     C     5       2</b>
<h3>One-Way Frequency Tables in R</h3>
The following code shows how to create a one-way frequency table in R for the variable <em>store</em>:
<b>#calculate frequency of each store
table(df$store)
A B C 
3 3 3 
</b>
This table simply tells us:
Store A appears 3 times in the data frame.
Store B appears 3 times in the data frame.
Store C appears 3 times in the data frame.
<h3>Two-Way Frequency Tables in R</h3>
The following code shows how to create a two-way frequency table in R for the variables <em>store</em> and <em>sales</em>:
<b>#calculate two-way frequency table
table(df$store, df$sales)
    3 4 5 6
  A 2 0 0 1
  B 1 1 0 1
  C 0 0 1 2 
</b>
This table tells us:
Store A made 3 sales on 2 different occasions.
Store A made 4 sales on 0 occassions.
Store A made 5 sales on 0 occassions.
Store A made 1 sale on 1 occassions.
And so on.
<h3>Three-Way Frequency Tables in R</h3>
The following code shows how to create a three-way frequency table for all three variables in our data frame:
<b>#calculate three-way frequency table
table(df$store, df$sales, df$returns)
, ,  = 1
   
    3 4 5 6
  A 2 0 0 0
  B 0 1 0 0
  C 0 0 0 0
, ,  = 2
   
    3 4 5 6
  A 0 0 0 1
  B 1 0 0 1
  C 0 0 1 1
, ,  = 3
   
    3 4 5 6
  A 0 0 0 0
  B 0 0 0 0
  C 0 0 0 1 
</b>
The first table tells us the total sales by store when the number of returns was equal to 1. The second table tells us the total sales by store when the number of returns was equal to 2. And the third table tells us the total sales by store when the number of returns was equal to 3.
Note that R can make frequency tables for even higher dimensions (e.g. 4-way frequency tables, 5-way frequency tables) but the output can become quite large for higher dimensions.
In practice, one-way and two-way frequency tables are used most often.
<h2><span class="orange">How to Create Frequency Tables in Python</span></h2>
A <b>frequency table </b>is a table that displays the frequencies of different categories. This type of table is particularly useful for understanding the distribution of values in a dataset.
This tutorial explains how to create frequency tables in Python.
<h3>One-Way Frequency Table for a Series</h3>
To find the frequencies of individual values in a pandas Series, you can use the <b>value_counts()</b> function:
<b>import pandas as pd
#define Series
data = pd.Series([1, 1, 1, 2, 3, 3, 3, 3, 4, 4, 5])
#find frequencies of each value
data.value_counts()
3    4
1    3
4    2
5    1
2    1
</b>
You can add the argument <b>sort=False </b>if you don’t want the data values sorted by frequency:
<b>data.value_counts(sort=False)
1    3
2    1
3    4
4    2
5    1</b>
The way to interpret the output is as follows:
The value “1” occurs <b>3 </b>times in the Series.
The value “2” occurs <b>1 </b>time in the Series.
The value “3” occurs <b>4 </b>times in the Series.
And so on.
<h3>
<b>One-Way Frequency Table for a DataFrame</b>
</h3>
To find frequencies of a pandas DataFrame you can use the <b>crosstab()</b> function, which uses the following sytax:
<b>crosstab(index, columns)</b>
where:
<b>index:</b> name of column to group by
<b>columns:</b> name to give to frequency column
For example, suppose we have a DataFrame with information about the letter grade, age, and gender of 10 different students in a class. Here’s how to find the frequency for each letter grade:
<b>#create data
df = pd.DataFrame({'Grade': ['A','A','A','B','B', 'B', 'B', 'C', 'D', 'D'],   'Age': [18, 18, 18, 19, 19, 20, 18, 18, 19, 19],   'Gender': ['M','M', 'F', 'F', 'F', 'M', 'M', 'F', 'M', 'F']})
#view data
df
GradeAgeGender
0    A 18     M
1    A 18     M
2    A 18     F
3    B 19     F
4    B 19     F
5    B 20     M
6    B 18     M
7    C 18     F
8    D 19     M
9    D 19     F   
#find frequency of each letter grade
pd.crosstab(index=df['Grade'], columns='count')
col_0count
Grade
A    3
B    4
C    1
D    2</b>
The way to interpret this is as follows:
<b>3 </b>students received an ‘A’ in the class.
<b>4 </b>students received a ‘B’ in the class.
<b>1 </b>student received a ‘C’ in the class.
<b>2 </b>students received a ‘D’ in the class.
We can use a similar syntax to find the frequency counts for other columns. For example, here’s how to find frequency by age:
<b>pd.crosstab(index=df['Age'], columns='count') 
col_0count
Age
18       5
19    4
20    1
</b>
The way to interpret this is as follows:
<b>5 </b>students are 18 years old.
<b>4 </b>students are 19 years old.
<b>1 </b>student is 20 years old.
You can also easily display the frequencies as proportions of the entire dataset by dividing by the sum:
<b>#define crosstab
tab = pd.crosstab(index=df['Age'], columns='count')
#find proportions 
tab/tab.sum()
col_0count
Age
18  0.5
19  0.4
20  0.1
</b>
The way to interpret this is as follows:
<b>50%</b> of students are 18 years old.
<b>40%</b> of students are 19 years old.
<b>10%</b> of students are 20 years old.
<h3>Two-Way Frequency Tables for a DataFrame</h3>
You can also create a two-way frequency table to display the frequencies for two different variables in the dataset. For example, here’s how to create a two-way frequency table for the variables Age and Grade:
<b>pd.crosstab(index=df['Age'], columns=df['Grade'])
GradeABCD
Age
183110
190202
200100
</b>
The way to interpret this is as follows:
There are <b>3 </b>students who are 18 years old and received an ‘A’ in the class.
There is <b>1 </b>student who is 18 years old and received a ‘B’ in the class.
There is <b>1 </b>student who is 18 years old and received a ‘C’ in the class.
There are <b>0 </b>students who are 18 years old and received a ‘D’ in the class.
And so on.
<em>You can find the complete documentation for the <b>crosstab() </b>function  here .</em>
<h2><span class="orange">Friedman Test Calculator</span></h2>
The <b>Friedman Test</b> is the non-parametric alternative to the one-way ANOVA with repeated measures. It is used to test for differences between groups when the dependent variable is ordinal.
To perform a Friedman Test for a given dataset, simply enter the values for up to five samples into the cells below, then press the “Calculate” button.
The calculator will output the test statistic Q, the p-value of the test, and the calculations that were used to derive the test statistic Q.
<table><tbody>
<tr>
<th style="background-color: #bee3ff"><b>Group 1</b></th>
            <th style="background-color: #bee3ff"><b>Group 2</b></th>
            <th style="background-color: #bee3ff"><b>Group 3</b></th>
            <th style="background-color: #bee3ff"><b>Group 4</b></th>
            <th style="background-color: #bee3ff"><b>Group 5</b></th>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
<tr>
<td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
</tbody></table>
<input type="button" id="button" onclick="calc()" value="Calculate">
<div>
Test Statistic Q: 
<div>
p-value: 
<div>
<b>Solution</b>
<div>
<b>Q = </b>
<div>
<b>Q = </b>
<div>
<b>Q = </b>
<script>
//create function that performs calculations
function calc() {
//define addition function
function add(a, b) {
    return a + b;
}
//define function that can flatten a multi-dimensional array
function flatten(arr) {
      return arr.reduce(function (flat, toFlatten) {
        return flat.concat(Array.isArray(toFlatten) ? flatten(toFlatten) : toFlatten);
      }, []);
    }
//get total number of rows
    var row_input = document.getElementsByClassName('table_span_a');
var row_array = [];
for (var i = 0; i < row_input.length; i++) {
      row_array[i] = row_input[i].innerText;
         }
values_row = row_array.filter(n => n);
var n = values_row.length;
//create massive for loop that gets ranks for every single row
all_data = [];
for (var i = 0; i < n; i++) {
var p = "p"
var p_number = i-(-1);
var str = p.concat(p_number);
        str = str.replace(/ +/g, "");
//get row data
    var p1_input = document.getElementsByClassName(str);
var p1_array = [];
for (var j = 0; j < p1_input.length; j++) {
      p1_array[j] = p1_input[j].innerText;
         }
values_p1 = p1_array.filter(n => n);
var p1 = values_p1.map(Number);
    
    //sort row data
    var sorted = p1.slice().sort(function(a,b){return a-b})
    var reversed = sorted.slice(0).reverse();
    var frac_rank = p1.slice().map(function(n) { return ( (sorted.indexOf(n) + 1) + (reversed.length - reversed.indexOf(n)) ) / 2 });
    
    //push sorted row data to total data array
    all_data.push(frac_rank);
    
} //end massive for loop that ranks every row
    
//find total treatments
var k = all_data[0].length;
//flatten multi-dimensional array into one long array
flat_data = flatten(all_data);
//find sum of ranks for each treatment
var a = [], b = [], c = [], d = [], e = [], total_squared_ranks;
    
    if (k == 2) {
    for (i = 0; i < flat_data.length; i+= k) {
        a.push(flat_data[i]);
        }
    for (i = 1; i < flat_data.length; i+= k) {
        b.push(flat_data[i]);
        }
    var sum_a_squared = Math.pow(a.reduce(add, 0), 2);
    var sum_b_squared = Math.pow(b.reduce(add, 0), 2);
    total_squared_ranks = [sum_a_squared, sum_b_squared].reduce(add, 0);
    }
    
    if (k == 3) {
    for (i = 0; i < flat_data.length; i+= k) {
        a.push(flat_data[i]);
        }
    for (i = 1; i < flat_data.length; i+= k) {
        b.push(flat_data[i]);
        }
    for (i = 2; i < flat_data.length; i+= k) {
        c.push(flat_data[i]);
        }
    var sum_a_squared = Math.pow(a.reduce(add, 0), 2);
    var sum_b_squared = Math.pow(b.reduce(add, 0), 2);
    var sum_c_squared = Math.pow(c.reduce(add, 0), 2);
    total_squared_ranks = [sum_a_squared, sum_b_squared, sum_c_squared].reduce(add, 0);
    }
    
    if (k == 4) {
    for (i = 0; i < flat_data.length; i+= k) {
        a.push(flat_data[i]);
        }
    for (i = 1; i < flat_data.length; i+= k) {
        b.push(flat_data[i]);
        }
    for (i = 2; i < flat_data.length; i+= k) {
        c.push(flat_data[i]);
        }
    for (i = 3; i < flat_data.length; i+= k) {
        d.push(flat_data[i]);
        }
    var sum_a_squared = Math.pow(a.reduce(add, 0), 2);
    var sum_b_squared = Math.pow(b.reduce(add, 0), 2);
    var sum_c_squared = Math.pow(c.reduce(add, 0), 2);
    var sum_d_squared = Math.pow(d.reduce(add, 0), 2);
    total_squared_ranks = [sum_a_squared, sum_b_squared, sum_c_squared, sum_d_squared].reduce(add, 0);
    }
    
    if (k == 5) {
    for (i = 0; i < flat_data.length; i+= k) {
        a.push(flat_data[i]);
        }
    for (i = 1; i < flat_data.length; i+= k) {
        b.push(flat_data[i]);
        }
    for (i = 2; i < flat_data.length; i+= k) {
        c.push(flat_data[i]);
        }
    for (i = 3; i < flat_data.length; i+= k) {
        d.push(flat_data[i]);
        }
    for (i = 4; i < flat_data.length; i+= k) {
        e.push(flat_data[i]);
        }
    var sum_a_squared = Math.pow(a.reduce(add, 0), 2);
    var sum_b_squared = Math.pow(b.reduce(add, 0), 2);
    var sum_c_squared = Math.pow(c.reduce(add, 0), 2);
    var sum_d_squared = Math.pow(d.reduce(add, 0), 2);
    var sum_e_squared = Math.pow(e.reduce(add, 0), 2);
    total_squared_ranks = [sum_a_squared, sum_b_squared, sum_c_squared, sum_d_squared, sum_e_squared].reduce(add, 0);
    }
    
     //final calculations for critical value and p value
     q_term1 = 12 / (n*k*(k-(-1)));
     q_term3 = 3*n*(k-(-1));
     q = (q_term1 * total_squared_ranks) - q_term3;
     p = 1 - jStat.chisquare.cdf(q, k-1);
     
     //output results
    document.getElementById('q').innerHTML = q.toFixed(5);
document.getElementById('p').innerHTML = p.toFixed(5);
document.getElementById('solution1').innerHTML = "(12/(nk(k+1)) * (∑R<sup>2</sup>) - 3n(k+1)";
document.getElementById('solution2').innerHTML = q_term1 + " * " + total_squared_ranks.toFixed(1) + " - " + q_term3;
document.getElementById('solution3').innerHTML = q.toFixed(5);
} //end calc() function
</script>
<h2><span class="orange">How to Perform the Friedman Test in Python</span></h2>
The  Friedman Test  is a non-parametric alternative to the  Repeated Measures ANOVA . It is used to determine whether or not there is a statistically significant difference between the means of three or more groups in which the same subjects show up in each group.
This tutorial explains how to perform the Friedman Test in Python.
<h3>Example: The Friedman Test in Python</h3>
A researcher wants to know if the reaction times of patients is equal on three different drugs. To test this, he measures the reaction time (in seconds) of 10 different patients on each of the three drugs.
Use the following steps to perform the Friedman Test in Python to determine if the mean reaction time differs between drugs.
<b>Step 1: Enter the data.</b>
First, we’ll create three arrays that contain the response times for each patient on each of the three drugs:
<b>group1 = [4, 6, 3, 4, 3, 2, 2, 7, 6, 5]
group2 = [5, 6, 8, 7, 7, 8, 4, 6, 4, 5]
group3 = [2, 4, 4, 3, 2, 2, 1, 4, 3, 2]</b>
<b>Step 2: Perform the Friedman Test.</b>
Next, we’ll perform the Friedman Test using the  friedmanchisquare() function  from the scipy.stats library:
<b>from scipy import stats
#perform Friedman Test
stats.friedmanchisquare(group1, group2, group3)
(statistic=13.3514, pvalue=0.00126)</b>
<b>Step 3: Interpret the results.</b>
The Friedman Test uses the following null and alternative hypotheses:
<b>The null hypothesis (H<sub>0</sub>):</b> The mean for each population is equal.
<b>The alternative hypothesis: (Ha):</b> At least one population mean is different from the rest.
In this example, the test statistic is <b>13.3514 </b>and the corresponding p-value is p = <b>0.00126</b>. Since this p-value is less than 0.05, we can reject the null hypothesis that the mean response time is the same for all three drugs.
In other words, we have sufficient evidence to conclude that the type of drug used leads to statistically significant differences in response time.
<h2><span class="orange">How to Perform the Friedman Test in R</span></h2>
The <b>Friedman Test </b>is a non-parametric alternative to the Repeated Measures ANOVA. It is used to determine whether or not there is a statistically significant difference between the means of three or more groups in which the same subjects show up in each group.
This tutorial explains how to perform the Friedman Test in R.
<h3>Example: The Friedman Test in R</h3>
To perform the Friedman Test in R, we can use the <b>friedman.test() </b>function, which uses the following syntax:
<b>friedman.test(y, groups, blocks)</b>
where:
<b>y: </b>a vector of response values.
<b>groups: </b>a vector of values indicating the “group” an observation belongs in.
<b>blocks: </b>a vector of values indicating the “blocking” variable.
This function produces a Chi-Square test statistic and a corresponding p-value. If the p-value is less than a certain significance level (common choices are 0.10, 0.05, and 0.01), then there is sufficient evidence that the means between each of the groups is not equal.
To illustrate how to use this function, we will create a dataset that shows the reaction time of five patients on four different drugs. Since each patient is measured on each of the four drugs, we will use the Friedman Test to determine if the mean reaction time differs between drugs.
First, we’ll create the dataset:
<b>#create data
data &lt;- data.frame(person = rep(1:5, each=4),   drug = rep(c(1, 2, 3, 4), times=5),   score = c(30, 28, 16, 34, 14, 18, 10, 22, 24, 20,             18, 30, 38, 34, 20, 44, 26, 28, 14, 30))
#view data
data
   person drug score
1       1    1    30
2       1    2    28
3       1    3    16
4       1    4    34
5       2    1    14
6       2    2    18
7       2    3    10
8       2    4    22
9       3    1    24
10      3    2    20
11      3    3    18
12      3    4    30
13      4    1    38
14      4    2    34
15      4    3    20
16      4    4    44
17      5    1    26
18      5    2    28
19      5    3    14
20      5    4    30
</b>
Then we’ll perform the Friedman Test using <b>score</b> as the response variable, <b>drug </b>as the grouping variable, and <b>person </b>as the blocking variable:
<b>#perform Friedman Test
friedman.test(y=data$score, groups=data$drug, blocks=data$person)
Friedman rank sum test
data:  data$score, data$drug and data$person
Friedman chi-squared = 13.56, df = 3, p-value = 0.00357
</b>
The Chi-Squared test statistic is <b>13.56 </b>and the corresponding p-value is <b>0.00357</b>. Because this p-value is less than 0.05, we can reject the null hypothesis that the mean response time is the same for all four drugs. We have sufficient evidence to conclude that the type of drug used lead to statistically significant differences in response time.
Although a Friedman Test tells us if there are differences in mean response time across the drugs, it doesn’t tell us specifically which drugs have different mean response times. To figure that out, we need to conduct post-hoc tests.
For a Friedman Test, the appropriate post-hoc test is the pairwise Wilcoxon rank sum test with a bonferroni correction, which can be implemented using the following syntax:
<b> pairwise.wilcox.test(data$score, data$drug, p.adj = “bonf”)</b>
where:
<b>x:</b> response vector
<b>g:</b> grouping vector
<b>p.adj:</b> method for adjusting p-values; options include holm, hochberg, hommel, bonferroni, BH, BY, fdr, and none
Here is the syntax we will use for our example:
<b>#perform post-hoc tests
pairwise.wilcox.test(data$score, data$drug, p.adj = "bonf")
Pairwise comparisons using Wilcoxon rank sum test 
data:  data$score and data$drug 
  1     2     3    
2 1.000 -     -    
3 0.449 0.210 -    
4 1.000 1.000 0.072
P value adjustment method: bonferroni 
</b>
This produces a matrix that shows the p-value for each pairwise Wilcoxon rank sum test. We can see that the only drug groups that have a statistically significant difference at 0.10 are groups 3 and 4 (<b>p = 0.072</b>).
<h2><span class="orange">How to Perform the Friedman Test in SPSS</span></h2>
The <b>Friedman Test </b>is a non-parametric alternative to the  Repeated Measures ANOVA . It is used to determine whether or not there is a statistically significant difference between the means of three or more groups in which the same subjects show up in each group.
This tutorial explains how to perform the Friedman Test in SPSS.
<h3>Example: The Friedman Test in SPSS</h3>
Researchers want to know if four different drugs lead to different reaction times. To test this, they measure the reaction time of five patients on the four different drugs.
Perform the following steps to conduct the Friedman Test in SPSS to determine if the reaction time differs between drugs.
<b>Step 1: Enter the data.</b>
Enter the following data, which shows the response time (in seconds) of five patients on the four drugs:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/repeatedANOVASPSS1.png">
<b>Step 2: Perform the Friedman Test.</b>
Click on the <b>Analyze </b>tab, then <b>Nonparametric Tests</b>, then <b>Legacy Dialogs</b>, then <b>K Related Samples</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/friedmanSPSS1.png">
In the new window that pops up, drag all four of the <b>drug </b>variables into the box labelled <b>Test Variables</b>. Make sure the box is checked next to <b>Friedman</b>, then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/friedmanSPSS2.png">
<b>Step 3: Interpret the results.</b>
Once you click <b>OK</b>, the results of the Friedman Test will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/friedmanSPSS3.png">
Here is how to interpret the output:
<b>N: </b>The total number of individuals in the dataset.
<b>Chi-Square:</b> The test statistic of the Friedman Test.
<b>df: </b>The degrees of freedom, calculated as #groups-1 = 4-1 = 3.
<b>Asymp. Sig: </b>The p-value associated with the test statistic with 3 degrees of freedom. In this case, the p-value is <b>.004</b>. This can also be calculated by using the  Chi-Square Score to P Value Calculator .
Since the p-value is less than .05, we can reject the null hypothesis that the response time is the same for all four drugs. We have sufficient evidence to conclude that the type of drug used leads to statistically significant differences in response time.
<b>Step 4: Report the results.</b>
Lastly, we want to report the results of the test. Here is an example of how to do so:
A Friedman Test was conducted on five individuals to examine the effect that four different drugs had on response time. Each individual used each drug once.
 
Results showed that the type of drug used lead to statistically significant differences in response time (X<sup>2</sup> = 13.56, p = 0.004).
<h2><span class="orange">How to Perform the Friedman Test in Stata</span></h2>
The <b>Friedman Test </b>is a non-parametric alternative to the  Repeated Measures ANOVA . It is used to determine whether or not there is a statistically significant difference between the means of three or more groups in which the same subjects show up in each group.
This tutorial explains how to perform the Friedman Test in Stata.
<h2>Example: The Friedman Test in Stata</h2>
For this example we will use the <em>t43 </em>dataset, which shows the reaction time of five patients on four different drugs. Since each patient is measured on each of the four drugs, we will use the Friedman Test to determine if the mean reaction time differs between drugs.
Use the following steps to perform the Friedman Test:
<b>Step 1: Load and view the data.</b>
Use the following command to load the data in Stata:
<b>use http://www.stata-press.com/data/r14/t43</b>
View the raw data using the following command:
<b>br</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/oneWayRepeatedStata2.png">
<b>Step 2: Install the emh package.</b>
To perform the Friedman Test, we will need to install the <b>emh </b>package, which doesn’t come pre-installed in Stata. To install it, simply type in the following command:
<b>ssc install emh</b>
It should install automatically within a few seconds.
<b>Step 3: Perform the Friedman Test.</b>
Once the <b>emh </b>package is installed, we can perform the Friedman Test by using the following syntax:
<b>emh response_variable explanatory_variable, strata(repeated variable) anova transformation(rank)</b>
In our case, we will use the following syntax:
<b>emh score drug, strata(person) anova transformation(rank)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/friedmanTestStata1.png">
Here is how to interpret the output:
<b>Q (3) =  13.5600. </b>This is the test statistic of the Friedman Test.
<b>P = 0.0036</b>. This is the p-value associated with the test statistic. Since this value is less than 0.05, we can reject the null hypothesis that the mean response time is the same for all four drugs. We have sufficient evidence to conclude that the type of drug used lead to statistically significant differences in response time.
<b>Step 4: Report the results.</b>
Lastly, we want to report the results of the test. Here is an example of how to do so:
A Friedman Test was conducted on 5 individuals to examine the effect that four different drugs had on response time. Each individual used each drug once.
 
Results showed that the type of drug used lead to statistically significant differences in response time (Q(3) = 13.56, p = 0.0036).
<footer>
<imghttps://secure.gravatar.com/avatar/6073170cba542d5d2aa94984be2ac81b?s=68&d=mm&r=g"><b>Irina</b> <span>says:
<!-- .comment-author -->
 <time datetime="2020-03-27T15:11:30-04:00">March 27, 2020 at 3:11 pm</time> 
<!-- .comment-metadata -->
</footer><!-- .comment-meta -->
Thank you for this post, extremely helpful and easy to reproduce.  Can you make an extension for this tutorial on how to run post hoc analysis for Friedman’s Test in Stata?
<!-- .comment-content -->
 Reply </article>
<h2><span class="orange">Friedman Test: Definition, Formula, and Example</span></h2>
The <b>Friedman Test </b>is a non-parametric alternative to the  Repeated Measures ANOVA .
It is used to determine whether or not there is a statistically significant difference between the means of three or more groups in which the same subjects show up in each group.
<h2>When to Use the Friedman Test</h2>
The Friedman Test is commonly used in two situations:
<b>1. Measuring the mean scores of subjects during three or more time points.</b>
For example, you might want to measure the resting heart rate of subjects one month before they start a training program, one month after starting the program, and two months after using the program. You can perform the Friedman Test to see if there is a significant difference in the mean resting heart rate of patients across these three time points.
<b>2. Measuring the mean scores of subjects under three different conditions.</b>
For example, you might have subjects watch three different movies and rate each one based on how much they enjoyed it. Since each subject shows up in each sample, you can perform a Friedman Test to see if there is a significant difference in the mean rating of the three movies.
<h2>Friedman Test: Example</h2>
Suppose we want to know if the mean reaction time of subjects is different on three different drugs. To test this, we recruit 10 patients and measure each of their reaction times (in seconds) on the three different drugs. The results for each patient are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/friedmancalc3.png">
Since each patient is measured on each of the three drugs, we will use the Friedman Test to determine if the mean reaction time differs between the three drugs.
<b>Step 1. State the hypotheses. </b>
<b>The null hypothesis (H<sub>0</sub>):</b> μ<sub>1</sub> = μ<sub>2</sub> = μ<sub>3</sub> (the mean reaction times across the populations are all equal)
<b>The alternative hypothesis: (Ha):</b> at least one population mean is different from the rest
<b>Step 2. Perform the Friedman Test.</b>
We will use the  Friedman Test Calculator  using the following input:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/friedmancalc2.png">
Once we click “Calculate” then the following output will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/friedmancalc1.png">
<b>Step 3: Interpret the results.</b>
The test statistic is Q = <b>12.35 </b>and the corresponding p-value is p = <b>0.00208</b>. Since this value is less than 0.05, we can reject the null hypothesis that the mean response time is the same for all three drugs.
We have sufficient evidence to conclude that the type of drug used leads to statistically significant differences in response time.
<b>Step 4: Report the results.</b>
Lastly, we want to report the results of the test. Here is an example of how to do so:
A Friedman Test was conducted on 10 patients to examine the effect that three different drugs had on response time. Each patient used each drug once.
 
Results showed that the type of drug used lead to statistically significant differences in response time (Q = 12.35, p = 0.00208).
<h2>Additional Resources</h2>
The following tutorials explain how to perform the Friedman Test using different statistical softwares:
 How to Perform the Friedman Test in Excel 
 How to Perform the Friedman Test in R 
 How to Perform the Friedman Test in Python 
 How to Perform the Friedman Test in Stata 
 Online Friedman Test Calculator 
<h2><span class="orange">How to Perform Fuzzy Matching in Excel (With Example)</span></h2>
Often you may want to join together two datasets in Excel based on imperfectly matching strings. This is sometimes called<b> fuzzy matching</b>.
The easiest way to do so is by using the <b>Fuzzy Lookup Add-In</b> for Excel.
The following step-by-step example shows how to use this Add-in to perform fuzzy matching.
<h2>Step 1: Download Fuzzy Lookup Add-In</h2>
First, we need to download the <b>Fuzzy Lookup Add-In</b> from Excel.
It’s completely free and downloads in only a few seconds.
To download this Add-In, go to  this page from Microsoft  and click <b>Download</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy1.jpg"624">
Then click the<b> .exe</b> file and follow the instructions to complete the download.
<h2>Step 2: Enter the Two Datasets</h2>
Next, let’s open Excel and enter the following information for two datasets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy2.jpg"465">
We will perform fuzzy matching to match the team names from the first dataset with the team names in the second dataset.
<h2>Step 3: Create Tables from Datasets</h2>
Before we can perform fuzzy matching, we must first convert each dataset into a table.
To do so, highlight the cell range <b>A1:B6</b> and then press <b>Ctrl+L</b>.
In the new window that appears, click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy3.jpg"445">
The dataset will be converted into a table with the name <b>Table1</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy4.jpg"417">
Repeat the same steps to convert the second dataset into a table with the name <b>Table2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy5.jpg"475">
<h2>Step 4: Perform Fuzzy Matching</h2>
To perform Fuzzy matching, click the <b>Fuzzy Lookup</b> tab along the top ribbon:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy6.jpg"621">
Then click the <b>Fuzzy Lookup</b> icon within this tab to bring up the <b>Fuzzy Lookup</b> panel.
Choose Table1 for the <b>Left Table</b> and Table2 for the <b>Right Table</b>.
Then highlight Team for<b> Left Columns</b> and Team for <b>Right Columns</b> and click the join icon between the boxes, then click <b>Go</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy8.jpg"511">
The results of the fuzzy matching will be shown in the cell you currently have active in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fuzzy9.jpg"481">
From the results we can see that Excel was able to match each team name between the two datasets except for the Kings.
Excel also shows a <b>Similarity</b> score, which represents the similarity between 0 and 1 of the two names that it matched.
Feel free to adjust the minimum Similarity score within the <b>Fuzzy Lookup</b> panel to allow for matching between text values that have lower similarity scores.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Count Frequency of Text in Excel 
 How to Check if Cell Contains Text from List in Excel 
 How to Calculate Average If Cell Contains Text in Excel 
<h2><span class="orange">How to Perform Fuzzy Matching in R (With Example)</span></h2>
Often you may want to join together two datasets in R based on imperfectly matching strings. This is sometimes called <b>fuzzy matching</b>.
The easiest way to perform fuzzy matching in R is to use the<b> stringdist_join()</b> function from the <b>fuzzyjoin</b> package.
The following example shows how to use this function in practice.
<h3>Example: Fuzzy Matching in R</h3>
Suppose we have the following two data frames in R that contain information about various basketball teams:
<b>#create data frames
df1 &lt;- data.frame(team=c('Mavericks', 'Nets', 'Warriors', 'Heat', 'Lakers'),  points=c(99, 90, 104, 117, 100))
df2 &lt;- data.frame(team=c('Mavricks', 'Warrors', 'Heat', 'Netts', 'Kings', 'Lakes'),  assists=c(22, 29, 17, 40, 32, 30))
#view data frames
print(df1)
       team points
1 Mavericks     99
2      Nets     90
3  Warriors    104
4      Heat    117
5    Lakers    100
print(df2)
      team assists
1 Mavricks      22
2  Warrors      29
3     Heat      17
4    Netts      40
5    Kings      32
6    Lakes      30
</b>
Now suppose that we would like to perform a <b>left join</b> in which we keep all of the rows from the first data frame and simply merge them based on the team name that most closely matches in the second data frame.
We can use the following code to do so:
<b>library(fuzzyjoin)
library(dplyr)
#perform fuzzy matching left join
stringdist_join(df1, df2, 
                by='team', #match based on team
                mode='left', #use left join
                method = "jw", #use jw distance metric
                max_dist=99, 
                distance_col='dist') %>%
  group_by(team.x) %>%
  slice_min(order_by=dist, n=1)
# A tibble: 5 x 5
# Groups:   team.x [5]
  team.x    points team.y   assists   dist 
1 Heat         117 Heat          17 0     
2 Lakers       100 Lakes         30 0.0556
3 Mavericks     99 Mavricks      22 0.0370
4 Nets          90 Netts         40 0.0667
5 Warriors     104 Warrors       29 0.0417
</b>
The result is one data frame that contains each of the five original team names from the first data frame along with the team that most closely matches from the second data frame.
<b>Note #1</b>: We chose to use the <b>jw</b> distance metric for matching. This is short for the  Jaro-Winkler distance , which is a metric that measures the difference between two strings.
<b>Note #2:</b> We used the <b>slice_min()</b> function from the dplyr package to only show the team name from the second data frame that most closely matched the team name from the first data frame.
<h2><span class="orange">How to Perform Fuzzy Matching in Pandas (With Example)</span></h2>
Often you may want to join together two datasets in pandas based on imperfectly matching strings. This is called <b>fuzzy matching</b>.
The easiest way to perform fuzzy matching in pandas is to use the<b> get_close_matches()</b> function from the <b>difflib</b> package.
The following example shows how to use this function in practice.
<h3>Example: Fuzzy Matching in Pandas</h3>
Suppose we have the following two pandas DataFrames that contain information about various basketball teams:
<b>import pandas as pd
#create two DataFrames
df1 = pd.DataFrame({'team': ['Mavericks', 'Nets', 'Warriors', 'Heat', 'Lakers'],    'points': [99, 90, 104, 117, 100]})
df2 = pd.DataFrame({'team': ['Mavricks', 'Warrors', 'Heat', 'Netts', 'Lakes'],    'assists': [22, 29, 17, 40, 32]})
#view DataFrames
print(df1)
        team  points
0  Mavericks      99
1       Nets      90
2   Warriors     104
3       Heat     117
4     Lakers     100
print(df2)
       team  assists
0  Mavricks       22
1   Warrors       29
2      Heat       17
3     Netts       40
4     Lakes       32</b>
Now suppose that we would like to merge the two DataFrames based on the <b>team</b> column.
Since the team names are slightly different between the two DataFrames, we must use fuzzy matching to find which team names most closely match.
We can use the<b> get_close_matches()</b> function from the <b>difflib</b> package to do so:
<b>import difflib 
#create duplicate column to retain team name from df2
df2['team_match'] = df2['team']
#convert team name in df2 to team name it most closely matches in df1
df2['team'] = df2['team'].apply(lambda x: difflib.get_close_matches(x, df1['team'])[0])
#merge the DataFrames into one
df3 = df1.merge(df2)
#view final DataFrame
print(df3)
        team  points  assists team_match
0  Mavericks      99       22   Mavricks
1       Nets      90       40      Netts
2   Warriors     104       29    Warrors
3       Heat     117       17       Heat
4     Lakers     100       32      Lakes</b>
The result is one data frame that contains each of the five team names from the first DataFrame along with the team that most closely matches from the second DataFrame.
The <b>team_match</b> column shows the team name from the second DataFrame that most closely matched the team name from the first DataFrame.
<b>Note #1</b>: By default, <b>get_close_matches()</b> returns the three closest matches. However, by using the <b>[0]</b> at the end of the lambda function we were able to only return the closest team name match.
<b>Note #2:</b> You can find the complete documentation for the <b>get_close_matches()</b> function  here .
<h2><span class="orange">G-Test of Goodness of Fit Calculator</span></h2>
</style>
A  G-test of Goodness of Fit   is used to determine whether or not a categorical variable follows a hypothesized distribution.
To perform a G-test of Goodness of Fit, simply enter a list of observed and expected values for up to 10 categories in the boxes below, then click the “Calculate” button:
<table><tbody>
<tr>
<th><b>Category</b></th>
<th><b><span>Observed</b></th>
<th><b><span>Expected</b></th>
</tr>
<tr>
<td>Category 1</td>
<td><input type="text" id="o1" value="80"></td>
<td><input type="text" id="e1" value="100"></td>
</tr>
<tr>
<td>Category 2</td>
<td><input type="text" id="o2" value="125"></td>
<td><input type="text" id="e2" value="100"></td>
</tr>
<tr>
<td>Category 3</td>
<td><input type="text" id="o3" value="95"></td>
<td><input type="text" id="e3" value="100"></td>
</tr>
<tr>
<td>Category 4</td>
<td><input type="text" id="o4"></td>
<td><input type="text" id="e4"></td>
</tr>
<tr>
<td>Category 5</td>
<td><input type="text" id="o5"></td>
<td><input type="text" id="e5"></td>
</tr>
<tr>
<td>Category 6</td>
<td><input type="text" id="o6"></td>
<td><input type="text" id="e6"></td>
</tr>
<tr>
<td>Category 7</td>
<td><input type="text" id="o7"></td>
<td><input type="text" id="e7"></td>
</tr>
<tr>
<td>Category 8</td>
<td><input type="text" id="o8"></td>
<td><input type="text" id="e8"></td>
</tr>
</tbody></table>
<input type="button" id="button" onclick="calc()" value="Calculate">
G Test Statistic: <b>10.337194</b>
p-value: <b>0.005693</b>
<script>
function calc() {
//get input data
var o1 = document.getElementById('o1').value;
var o2 = document.getElementById('o2').value;
var o3 = document.getElementById('o3').value;
var o4 = document.getElementById('o4').value;
var o5 = document.getElementById('o5').value;
var o6 = document.getElementById('o6').value;
var o7 = document.getElementById('o7').value;
var o8 = document.getElementById('o8').value;
var e1 = document.getElementById('e1').value;
var e2 = document.getElementById('e2').value;
var e3 = document.getElementById('e3').value;
var e4 = document.getElementById('e4').value;
var e5 = document.getElementById('e5').value;
var e6 = document.getElementById('e6').value;
var e7 = document.getElementById('e7').value;
var e8 = document.getElementById('e8').value;
var obs = [o1, o2, o3, o4, o5, o6, o7, o8];
var empties = obs.length - obs.filter(String).length;
var df = 7 - empties;
//do calculations
var diff1 = 0;
if (o1) {
o1 = +o1;
e1 = +e1;
diff1 = o1*Math.log(o1/e1);
}
var diff2 = 0;
if (o2) {
o2 = +o2;
e2 = +e2;
diff2 = o2*Math.log(o2/e2);
}
var diff3 = 0;
if (o3) {
o3 = +o3;
e3 = +e3;
diff3 = o3*Math.log(o3/e3);
}
var diff4 = 0;
if (o4) {
o4 = +o4;
e4 = +e4;
diff4 = o4*Math.log(o4/e4);
}
var diff5 = 0;
if (o5) {
o5 = +o5;
e5 = +e5;
diff5 = o5*Math.log(o5/e5);
}
var diff6 = 0;
if (o6) {
o6 = +o6;
e6 = +e6;
diff6 = o6*Math.log(o6/e6);
}
var diff7 = 0;
if (o7) {
o7 = +o7;
e7 = +e7;
diff7 = o7*Math.log(o7/e7);
}
var diff8 = 0;
if (o8) {
o8 = +o8;
e8 = +e8;
diff8 = o8*Math.log(o8/e8);
}
var errors = [diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8];
var X2_hold = math.sum(errors);
var X2 = 2*X2_hold;
var p = 1-jStat.chisquare.cdf(X2, df);
//output results
document.getElementById('X2').innerHTML = X2.toFixed(6);
document.getElementById('p').innerHTML = p.toFixed(6);
  
} //end calc function
</script>
<h2><span class="orange">G-test of Goodness of Fit: Definition + Example</span></h2>
In statistics, the <b>G-test of Goodness of Fit</b> is used to determine whether or not some categorical variable follows a hypothesized distribution.
This test is an alternative to the  Chi-Square Goodness of Fit test  and is often used when outliers are present in the data or when the data you’re working with is extremely large.
The G-Test of Goodness of Fit uses the following null and alternative hypotheses:
<b>H<sub>0</sub>:</b> A variable follows a hypothesized distribution.
<b>H<sub>A</sub>:</b> A variable <em>does not</em> follow a hypothesized distribution.
The test statistic is calculated as follows:
<b>G=2 * Σ[O * ln(O/E)]</b>
where:
<b>O:</b> The observed count in a cell
<b>E:</b> The expected count in a cell
If the p-value that corresponds to the test statistic is less than some  significance level , then you can reject the null hypothesis and conclude that the variable under study does not follow the hypothesized distribution.
The following example shows how to perform a G-test of Goodness of Fit in practice.
<h3>Example: G-test of Goodness of Fit</h3>
A biologist claims that an equal proportion of three species of turtles exist in a certain area. To test this claim, an independent researcher counts the number of each type of species and finds the following:
Species A: <b>80</b>
Species B: <b>125</b>
Species C: <b>95</b>
The independent researcher can use the following steps to perform a G-test of Goodness of Fit to determine if the data she collected is consistent with the biologist’s claim.
<b>Step 1: State the null and alternative hypotheses.</b>
The researcher will perform the G-test of Goodness of Fit using the following hypotheses:
<b>H<sub>0</sub>: </b>An equal proportion of three species of turtles exist in this area.
<b>H<sub>A</sub>: </b>An equal proportion of three species of turtles <em>does not</em> exist in this area.
<b>Step 2: Calculate the test statistic.</b>
The formula to calculate the test statistic is as follows:
<b>G=2 * Σ[O * ln(O/E)]</b>
In this example, there are 300 total observed turtles. If there was an equal proportion of each species, we would expect to observe 100 turtles from each species. Thus, we can calculate the test statistic as:
G = 2 * [80*ln(80/100)  +  125*ln(125/100)  +  95*ln(95/100)] = <b>10.337</b>
<b>Step 3: Calculate the p-value of the test statistic.</b>
According to the  Chi-Square to P-Value Calculator , the p-value associated with a test statistic of 10.337 and #categories-1 = 3-1 = 2 degrees of freedom is <b>0.005693</b>.
Since this p-value is less than .05 the researcher would reject the null hypothesis. This means she has sufficient evidence to say that an equal proportion of each species of turtle <em>does not</em> exist in this particular area.
<h3>Bonus: G-test of Goodness of Fit in R</h3>
You can use the <b>Gtest()</b> function from the DescTools package to quickly perform a G-test of Goodness of Fit in R.
The following code shows how to perform a G-test for the previous example:
<b>#load the DescTools library
library(DescTools)
#perform the G-test 
GTest(x = c(80, 125, 95), #observed values
      p = c(1/3, 1/3, 1/3), #expected proportions
      correct = "none") 
Log likelihood ratio (G-test) goodness of fit test
data:  c(80, 125, 95)
G = 10.337, X-squared df = 2, p-value = 0.005693
</b>
Notice that the G test statistic is <b>10.337 </b>and the corresponding p-value is <b>0.005693</b>. Since this p-value is less than .05, we would reject the null hypothesis.
This matches the results that we calculated by hand.
<h2><span class="orange">How to Plot a Gamma Distribution in Python (With Examples)</span></h2>
In statistics, the <b>Gamma distribution</b> is often used to model probabilities related to waiting times.
The following examples show how to use the  scipy.stats.gamma()  function to plot one or more Gamma distributions in Python.
<h3>Example 1: Plot One Gamma Distribution</h3>
The following code shows how to plot a Gamma distribution with a shape parameter of <b>5</b> and a scale parameter of <b>3</b> in Python:
<b>import numpy as np
import scipy.stats as stats 
import matplotlib.pyplot as plt
#define x-axis values
x = np.linspace (0, 40, 100) 
#calculate pdf of Gamma distribution for each x-value
y = stats.gamma.pdf(x, a=5, scale=3)
#create plot of Gamma distribution
plt.plot(x, y)
#display plot
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/gammaPython1.png">
The x-axis displays the potential values that a Gamma distributed random variable can take on and the y-axis shows the corresponding PDF values of the Gamma distribution with a shape parameter of 5 and scale parameter of 3.
<h3>Example 2: Plot Multiple Gamma Distributions</h3>
The following code shows how to plot multiple Gamma distributions with various shape and scale parameters:
<b>import numpy as np
import scipy.stats as stats 
import matplotlib.pyplot as plt
#define three Gamma distributions
x = np.linspace(0, 40, 100)
y1 = stats.gamma.pdf(x, a=5, scale=3)
y2 = stats.gamma.pdf(x, a=2, scale=5)
y3 = stats.gamma.pdf(x, a=4, scale=2)
#add lines for each distribution
plt.plot(x, y1, label=shape=5, scale=3')
plt.plot(x, y2, label='shape=2, scale=5')
plt.plot(x, y3, label='shape=4, scale=2')
#add legend
plt.legend()
#display plot
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/gammaPython2-1.png">
Notice that the shape of the Gamma distribution can vary quite a bit depending on the shape and scale parameters.
<b>Related: </b> How to Plot Multiple Lines in Matplotlib 
<h2><span class="orange">How to Use the Gamma Distribution in R (With Examples)</span></h2>
In statistics, the <b>gamma distribution</b> is often used to model probabilities related to waiting times.
We can use the following functions to work with the gamma distribution in R:
<b>dgamma(x, shape, rate)</b> – finds the value of the density function of a gamma distribution with certain shape and rate parameters.
<b>pgamma(q, shape, rate)</b> – finds the value of the cumulative density function of a gamma distribution with certain shape and rate parameters.
<b>qgamma(p, shape, rate)</b> – finds the value of the inverse cumulative density function of a gamma distribution with certain shape and rate parameters.
<b>rgamma(n, shape, rate)</b> – generates n random variables that follow a gamma distribution with certain shape and rate parameters.
The following examples show how to use each of these functions in practice.
<h3>Example 1: How to Use dgamma()</h3>
The following code shows how to use the <b>dgamma()</b> function to create a probability density plot of a gamma distribution with certain parameters:
<b>#define x-values
x &lt;- seq(0, 2, by=0.01)   
  
#calculate gamma density for each x-value
y &lt;- dgamma(x, shape=5) 
  
#create density plot
plot(y)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/gamma2.png">
<h3>Example 2: How to Use pgamma()</h3>
The following code shows how to use the <b>pgamma()</b> function to create a cumulative density plot of a gamma distribution with certain parameters:
<b>#define x-values
x &lt;- seq(0, 2, by=0.01)   
  
#calculate gamma density for each x-value
y &lt;- pgamma(x, shape=5) 
  
#create cumulative density plot
plot(y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/gamma3.png">
<h3>Example 3: How to Use qgamma()</h3>
The following code shows how to use the <b>qgamma()</b> function to create a quantile plot of a gamma distribution with certain parameters:
<b>#define x-values
x &lt;- seq(0, 1, by=0.01)   
  
#calculate gamma density for each x-value
y &lt;- qgamma(x, shape=5) 
  
#create quantile plot
plot(y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/gamma4.png">
<h3>Example 4: How to Use rgamma()</h3>
The following code shows how to use the <b>rgamma()</b> function to generate and visualize 1,000 random variables that follow a gamma distribution with a shape parameter of 5 and a rate parameter of 3:
<b>#make this example reproducible
set.seed(0)
#generate 1,000 random values that follow gamma distribution
x &lt;- rgamma(n=1000, shape=5, rate=3)
#create histogram to view distribution of values
hist(x)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/gamma1.png">
<h2><span class="orange">How to Create a Gantt Chart in Excel</span></h2>
A <b>gantt chart</b> is a type of chart that shows the start and end times of various tasks.
This tutorial explains how to create the following gantt chart in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel8.png">
<h3>Example: Gantt Chart in Excel</h3>
Use the following steps to create a gantt chart in Excel.
<b>Step 1: Enter the data.</b>
Enter the name, start date, and duration of each task in separate columns:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel1.png">
<b>Step 2: Convert the date format to the number of days since Jan. 1, 1990.</b>
By default, dates in Excel are stored as the number of days since Jan 1, 1990. In order to create our gantt chart, we’ll need to convert the dates to numbers using the following formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel2.png">
<b>Step 3: Insert a stacked bar chart.</b>
Next, highlight cells A10:C16. In the <b>Charts </b>group within the <b>Insert </b>tab, click on the option that says <b>2-D stacked bar chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel3.png">
The following chart will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel4.png">
<b>Step 4: Modify the appearance of the chart.</b>
Lastly, we will modify the appearance of the gantt chart.
<b>Reverse the order of the tasks. </b>
Right click any task on the chart. Then click <b>Format Axis…</b>
Check the box next to <b>Categories in reverse order</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel5.png">
<b>Remove the blue bars.</b>
Right click on any of the blue bars. Then click <b>Format Data Series…</b>
Click the paint bucket icon, then Fill, then <b>No fill</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel6.png">
<b>Modify the dates on the x-axis.</b>
Right click on any of the dates. Then click <b>Format Axis…</b>
Under <b>Axis Options</b>, change the <b>Minimum </b>value to 43830 to reflect the earliest date of the first task.
Under <b>Number</b>, change the <b>Category </b>to Date.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel7-1.png">
<b>Change the title of the chart to anything you’d like. Click on the legend at the bottom and delete it.</b>
The final result should look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/ganttExcel8.png">
<h2><span class="orange">How to Create a Gantt Chart in R Using ggplot2</span></h2>
A <b>gantt chart</b> is a type of chart that shows the start and end times of various events.
This tutorial explains how to create a gantt chart in R using the package <b>ggplot2</b>.
<h2>Creating a Gantt Chart in R Using ggplot2</h2>
Suppose we have the following dataset that shows the start and end times for the shifts of four different workers at a store:
<b>#create data frame
data &lt;- data.frame(name = c('Bob', 'Greg', 'Mike', 'Andy'), 
start = c(4, 7, 12, 16),
end = c(12, 11, 8, 22),
shift_type = c('early', 'mid_day', 'mid_day', 'late')
)
data
#  name start end shift_type
#1 Bob      4  12      early
#2 Greg     7  11    mid_day
#3 Mike    12   8    mid_day
#4 Andy    16  22       late</b>
In order to create a gantt chart using ggplot2 that visualizes the start and end times for each worker, we can use the following code:
<b>#install (if not already installed) and load ggplot2
if(!require(ggplot2)){install.packages('ggplot2')}
#create gantt chart that visualizes start and end time for each worker
ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +
  geom_segment()
</b>
This produces the following gantt chart:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/gantt2.jpg">
With a couple tweaks to the layout, we can make this gantt chart look much better:
<b>ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +</b>
<b>  theme_bw()+ #use ggplot theme with black gridlines and white background</b>
<b>  geom_segment(size=8) + #increase line width of segments in the chart</b>
<b>  labs(title='Worker Schedule', x='Time', y='Worker Name')</b>
This produces the following chart:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/gantt1.jpg" alt="">
In addition, if you would like to define the exact colors to be used in the chart, you can use the following code:
<b>ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +
  theme_bw()+ #use ggplot theme with black gridlines and white background
  geom_segment(size=8) + #increase line width of segments in the chart
  labs(title='Worker Schedule', x='Time', y='Worker Name') +
  scale_colour_manual(values = c('pink', 'purple', 'blue'))</b>
This produces the following chart with colors pink, purple, and blue to represent the different shift types:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/gantt0.jpg">
<h2>Using Custom Themes</h2>
We can take things a step further by using custom themes from the  <b>ggthemes</b>  library.
For example, we can create a gantt chart that uses a theme inspired by The Wall Street Journal:
<b>#load <em>ggthemes </em>library
library(ggthemes)
#create scatterplot with Wall Street Journal theme
ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +
  theme_bw()+
  geom_segment(size=8) +
  labs(title='Worker Schedule', x='Time', y='Worker Name') +
  scale_colour_manual(values = c('pink', 'purple', 'blue')) +
  theme_wsj() + 
  theme(axis.title = element_text())</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/gantt3.jpg">
Or we could use a theme inspired by The Economist:
<b>ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +
  theme_bw()+
  geom_segment(size=8) +
  labs(title='Worker Schedule', x='Time', y='Worker Name') +
  scale_colour_manual(values = c('pink', 'purple', 'blue')) +
  theme_economist() + 
  theme(axis.title = element_text())</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/gantt4.jpg">
Or perhaps a theme inspired by  Five Thirty Eight :
<b>ggplot(data, aes(x=start, xend=end, y=name, yend=name, color=shift_type)) +
  theme_bw()+
  geom_segment(size=8) +
  labs(title='Worker Schedule', x='Time', y='Worker Name') +
  scale_colour_manual(values = c('pink', 'purple', 'blue')) +
  theme_fivethirtyeight() + 
  theme(axis.title = element_text())</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/gantt5.jpg">
For a complete list of themes available in the <em>ggthemes</em> library, check out  the documentation page .
<h2><span class="orange">How to Use Gather Function in R (With Examples)</span></h2>
The <b>gather()</b> function from the  tidyr  package can be used to “gather” a key-value pair across multiple columns.
This function uses the following basic syntax:
<b>gather(data, key value, …)</b>
where:
<b>data</b>: Name of the data frame
<b>key</b>: Name of the key column to create
<b>value</b>: Name of the value column to create
<b>…</b> : Specify which columns to gather from
The following examples show how to use this function in practice.
<h3>Example 1: Gather Values From Two Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'B', 'C', 'D'), year1=c(12, 15, 19, 19), year2=c(22, 29, 18, 12))
#view data frame
df
  player year1 year2
1      A    12    22
2      B    15    29
3      C    19    18
4      D    19    12</b>
We can use the <b>gather()</b> function to create two new columns called “year” and “points” as follows:
<b>library(tidyr)
#gather data from columns 2 and 3
gather(df, key="year", value="points", 2:3)
  player  year points
1      A year1     12
2      B year1     15
3      C year1     19
4      D year1     19
5      A year2     22
6      B year2     29
7      C year2     18
8      D year2     12</b>
<h3>Example 2: Gather Values From More Than Two Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df2 &lt;- data.frame(player=c('A', 'B', 'C', 'D'),  year1=c(12, 15, 19, 19),  year2=c(22, 29, 18, 12),  year3=c(17, 17, 22, 25))
#view data frame
df2
  player year1 year2 year3
1      A    12    22    17
2      B    15    29    17
3      C    19    18    22
4      D    19    12    25</b>
We can use the <b>gather()</b> function to “gather” the values from columns 2, 3, and 4 into two new columns called “year” and “points” as follows:
<b>library(tidyr)
#gather data from columns 2, 3, and 4
gather(df, key="year", value="points", 2:4)
   player  year points
1       A year1     12
2       B year1     15
3       C year1     19
4       D year1     19
5       A year2     22
6       B year2     29
7       C year2     18
8       D year2     12
9       A year3     17
10      B year3     17
11      C year3     22
12      D year3     25</b>
Every column is a variable.
Every row is an observation.
Every cell is a single value.
The tidyr package uses four core functions to create tidy data:
<b>1.</b> The  <b>spread()</b>  function.
<b>2.</b> The <b>gather()</b> function.
<b>3.</b> The  <b>separate()</b>  function.
4. The  <b>unite()</b>  function.
If you can master these four functions, you will be able to create “tidy” data from any data frame.
<h2><span class="orange">The General Multiplication Rule (Explanation & Examples)</span></h2>
The <b>general multiplication rule</b> states that the probability of any two events, A and B, both happening can be calculated as:
<b>P(A and B) = P(A) * P(B|A)</b>
The vertical bar | means “given.” Thus, P(B|A) can be read as “the probability that B occurs, <em>given</em> that A has occurred.”
If events A and B are independent, then P(B|A) is simply equal to P(B) and the rule can be simplified to:
<b>P(A and B) = P(A) * P(B)</b>
Let’s walk through a few examples of both independent and dependent events to see how we can apply this general multiplication rule in practice.
<h2>The General Multiplication Rule for Dependent Events</h2>
The following examples illustrate how to use the general multiplication rule to find probabilities related to two dependent events. In each example, the probability that the second event occurs is affected by the outcome of the first event.
<h3>Example 1: Balls in an Urn</h3>
An urn contains 4 red balls and 3 green balls. Bob is going to randomly select 2 balls from the urn, without replacement. What is the probability that he chooses 2 red balls?
<b>Solution: </b>The probability that he selects a red ball on the first attempt is 4/7. Once that ball is then removed, the probability that he selects a red ball on the second attempt is 3/6. Thus, the probability that he selects 2 red balls can be calculated as:
P(Both red) = 4/7 * 3/7 ≈ <b>0.2249</b>
<h3>Example 2: Cards in a Deck</h3>
A deck of cards contains 26 black cards and 26 red cards. Debbie is going to randomly select 2 cards from the deck, without replacement. What is the probability that she chooses 2 red cards?
<b>Solution: </b>The probability that she selects a red card on the first attempt is 26/52. Once that card is then removed, the probability that she selects a red card on the second attempt is 25/51. Thus, the probability that she selects 2 red cards can be calculated as:
P(Both red) = 26/52 * 25/51 ≈ <b>0.2451</b>
<h2>The General Multiplication Rule for Independent Events</h2>
The following examples illustrate how to use the general multiplication rule to find probabilities related to two independent events. In each example, the probability that the second event occurs is <em>not</em> affected by the outcome of the first event.
<h3>Example 1: Flipping Two Coins</h3>
Suppose we flip two coins. What is the probability that both coins land on heads?
<b>Solution: </b>The probability that the first coin lands on heads is 1/2. No matter which side the first coin lands on, the probability that the second coin lands on heads is also 1/2. Thus, the probability that both coins land on heads can be calculated as:
P(Both land on heads) = 1/2 * 1/2 = <b>0.25</b>
<h3>Example 2: Rolling Two Dice</h3>
Suppose we roll two dice at once. What is the probability that both dice land on the number 1?
<b>Solution: </b>The probability that the first dice lands on “1” is 1/6. No matter which side the first dice lands on, the probability that the second dice lands on “1” is also 1/6. Thus, the probability that both dice land on “1” can be calculated as:
P(Both land on “1”) = 1/6 * 1/6 = 1/36 ≈ <b>0.0278</b>
<h2><span class="orange">How to Generate a Normal Distribution in Excel</span></h2>
To generate a  normal distribution  in Excel, you can use the following formula:
<b>=NORMINV(RAND(), MEAN, STANDARD_DEVIATION)
</b>
You can then copy this formula down to as many cells in Excel as you’d like, depending on how large you’d like the dataset to be.
The following step-by-step example shows how to use this formula to generate a normal distribution in Excel.
<h3>Step 1: Choose a Mean & Standard Deviation</h3>
First, let’s choose a mean and a standard deviation that we’d like for our normal distribution.
For simplicity, we’ll choose 0 for the mean and 1 for the standard deviation:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/normDistExcel1.png">
<h3>Step 2: Generate a Normally Distributed Random Variable</h3>
Next, we’ll use the following formula to generate a single normally distributed random variable:
<b>=NORMINV(RAND(), $B$1, $B$2)</b>
The following screenshot shows how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/normDistExcel2-1.png">
<h3>Step 3: Choose a Sample Size for the Normal Distribution</h3>
Next, we can simply copy and paste this formula down to as many cells as we’d like.
For example, we may copy and paste this formula to a total of 20 cells:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/normDistExcel3.png">
The end result is a normally distributed dataset with a mean of 0, standard deviation of 1, and sample size of 20.
<b>Note:</b> You can quickly generate a brand new dataset that follows a normal distribution by simply double clicking on any cell and pressing Enter.
<h2><span class="orange">How to Generate a Normal Distribution in R (With Examples)</span></h2>
You can quickly generate a  normal distribution  in R by using the <b>rnorm()</b> function, which uses the following syntax:
<b>rnorm(n, mean=0, sd=1)</b>
where:
<b>n: </b>Number of observations.
<b>mean: </b>Mean of normal distribution. Default is 0.
<b>sd: </b>Standard deviation of normal distribution. Default is 1.
This tutorial shows an example of how to use this function to generate a normal distribution in R.
<b>Related:</b>  A Guide to dnorm, pnorm, qnorm, and rnorm in R 
<h3>Example: Generate a Normal Distribution in R</h3>
The following code shows how to generate a normal distribution in R:
<b>#make this example reproducible
set.seed(1)
#generate sample of 200 obs. that follows normal dist. with mean=10 and sd=3
data &lt;- rnorm(200, mean=10, sd=3)
#view first 6 observations in sample
head(data)
[1]  8.120639 10.550930  7.493114 14.785842 10.988523  7.538595
</b>
We can quickly find the mean and standard deviation of this distribution:
<b>#find mean of sample
mean(data)
[1] 10.10662
#find standard deviation of sample
sd(data)
[1] 2.787292
</b>
We can also create a quick histogram to visualize the distribution of data values:
<b>hist(data, col='steelblue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/normalDistR1.png">
We can even perform a  Shapiro-Wilk test  to see if the dataset comes from a normal population:
<b>shapiro.test(data)
Shapiro-Wilk normality test
data:  data
W = 0.99274, p-value = 0.4272
</b>
 The p-value of the test turns out to be <b>0.4272</b>. Since this value is not less than .05, we can assume the sample data comes from a population that is normally distributed.
This result shouldn’t be surprising since we generated the data using the <b>rnorm() </b>function, which naturally generates a random sample of data that comes from a normal distribution.
<h2><span class="orange">How to Generate a Normal Distribution in Python (With Examples)</span></h2>
You can quickly generate a  normal distribution  in Python by using the <b>numpy.random.normal()</b> function, which uses the following syntax:
<b>numpy.random.normal(loc=0.0, scale=1.0, size=None)</b>
where:
<b>loc: </b>Mean of the distribution. Default is 0.
<b>scale: </b>Standard deviation of the distribution. Default is 1.
<b>size: </b>Sample size.
This tutorial shows an example of how to use this function to generate a normal distribution in Python.
<b>Related:</b>  How to Make a Bell Curve in Python 
<h3>Example: Generate a Normal Distribution in Python</h3>
The following code shows how to generate a normal distribution in Python:
<b>from numpy.random import seed
from numpy.random import normal
#make this example reproducible
seed(1)
#generate sample of 200 values that follow a normal distribution 
data = normal(loc=0, scale=1, size=200)
#view first six values
data[0:5]
array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])
</b>
We can quickly find the mean and standard deviation of this distribution:
<b>import numpy as np
#find mean of sample
np.mean(data)
0.1066888148479486
#find standard deviation of sample
np.std(data, ddof=1)
0.9123296653173484
</b>
We can also create a quick histogram to visualize the distribution of data values:
<b>import matplotlib.pyplot as plt
count, bins, ignored = plt.hist(data, 30)
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/genNormPython1.png">
We can even perform a  Shapiro-Wilk test  to see if the dataset comes from a normal population:
<b>from scipy.stats import shapiro
#perform Shapiro-Wilk test
shapiro(data)
ShapiroResult(statistic=0.9958659410, pvalue=0.8669294714)
</b>
 The p-value of the test turns out to be <b>0.8669</b>. Since this value is not less than .05, we can assume the sample data comes from a population that is normally distributed.
This result shouldn’t be surprising since we generated the data using the <b>numpy.random.normal() </b>function, which generates a random sample of data that comes from a normal distribution.
<h2><span class="orange">How to Add Label to geom_hline in ggplot2</span></h2>
You can use the following basic syntax to add a label to a horizontal line in ggplot2:
<b>+ annotate("text", x=9, y=20, label="Here is my text")</b>
The following examples show how to use this syntax in practice.
<h2>Example 1: Add Label to geom_hline</h2>
The following code shows how to add a label to a horizontal line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with horizontal line at y=20
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=20) +
  annotate("text", x=9, y=20.5, label="Some text")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/labhorz1.jpg">
<h2>Example 2: Add Customized Label to geom_hline</h2>
The following code shows how to use the <b>size</b> and <b>color</b> arguments to add a label with a custom size and color to a horizontal line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with horizontal line at y=20
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=20) +
  annotate("text", x=10, y=21.5, label="Some text", size=15, color="blue")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/labhorz2.jpg"546">
<h2>Example 3: Add Multiple Labels to geom_hline</h2>
The following code shows how to use the <b>annotate()</b> function multiple times to add multiple labels to a horizontal line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with horizontal line at y=10
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=20) +
  annotate("text", x=10, y=19, label="Some text", size=15, color="blue") +
  annotate("text", x=10, y=21, label="More text", size=9, color="red")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/labhorz3.jpg"533">
Feel free to use the <b>annotate()</b> function as many times as you’d like to add as many labels as you’d like to the plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Add Label to geom_vline in ggplot2 
 How to Add an Average Line to Plot in ggplot2 
 How to Change Line Colors in ggplot2 
<h2><span class="orange">How to Change Fill and Border Color of Points in ggplot2</span></h2>
You can use the <b>color </b>and <b>fill</b> arguments to change the border and fill color of points in a ggplot2 scatter plot, respectively:
<b>#create scatter plot with points that have black border and pink fill
ggplot(df, aes(x=x, y=y)) + 
  geom_point(color='black', fill='pink', shape=21)</b>
It’s important to note that the <b>color</b> and <b>fill</b> arguments only work when the <b>shape</b> value is between 21 and 25.
Refer to  this tutorial  for a complete list of shapes available in ggplot2.
The following examples show how to use the <b>color</b> and <b>fill</b> arguments in practice.
<h2>Example 1: Specify One Fill and Border Color for All Points</h2>
The following code shows how to create a scatter plot in ggplot2 in which the border color of all points is black and the fill color is pink:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 7, 7, 10), y=c(5, 8, 10, 14, 13, 19))
#create scatter plot
ggplot(df, aes(x=x, y=y)) + 
  geom_point(color='black', fill='pink', shape=21, size=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fill1.jpg">
<h2>Example 2: Specify Multiple Fill and Border Colors for Points</h2>
The following code shows how to create a scatter plot in ggplot2 in which the border and fill color of points is dependent on the value of a grouping variable:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 7, 7, 10), y=c(5, 8, 10, 14, 13, 19), group=c('A', 'A', 'A', 'B', 'B', 'B'))
#create scatter plot with multiple fill and border colors
ggplot(df, aes(x=x, y=y)) + 
  geom_point(color='black', shape=21, size=4, aes(fill=factor(group))) + 
  scale_fill_manual(values=c('pink', 'lightgreen'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/fil2.jpg">
In this example, we use a border color of ‘black’ for all points, but the fill color was dependent on the value for the <b>group</b> variable in the data frame.
<b>Note</b>: You can find the complete documentation for the <b>geom_point()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change Point Shape in ggplot2 
 How to Change the Legend Title in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Fix in R: could not find function “ggplot” 
<h2><span class="orange">How to Add Label to geom_vline in ggplot2</span></h2>
You can use the following basic syntax to add a label to a vertical line in ggplot2:
<b>+ annotate("text", x=9, y=20, label="Here is my text", angle=90)</b>
The following examples show how to use this syntax in practice.
<h2>Example 1: Add Label to geom_vline</h2>
The following code shows how to add a label to a vertical line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with vertical line at x=10
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=10) +
  annotate("text", x=9.7, y=20, label="Some text", angle=90)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomv1.jpg"487">
<h2>Example 2: Add Customized Label to geom_vline</h2>
The following code shows how to use the <b>size</b> and <b>color</b> arguments to add a label with a custom size and color to a vertical line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with vertical line at x=10
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=10) +
  annotate("text", x=9, y=20, label="Some text", angle=90, size=15, color="blue")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomv2.jpg"487">
<h2>Example 3: Add Multiple Labels to geom_vline</h2>
The following code shows how to use the <b>annotate()</b> function multiple times to add multiple labels to a vertical line in ggplot2:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with vertical line at x=10
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=10) +
  annotate("text", x=9, y=20, label="Some text", angle=90, size=15, color="blue") +
  annotate("text", x=11, y=20, label="More text", angle=90, size=13, color="red")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomv3.jpg"493">
Feel free to use the <b>annotate()</b> function as many times as you’d like to add as many labels as you’d like to the plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot a Linear Regression Line in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Create Side-by-Side Plots in ggplot2 
<h2><span class="orange">How to Use geometpdf() and geometcdf() on a TI-84 Calculator</span></h2>
The  geometric distribution  describes the probability of experiencing a certain number of failures before experiencing the first success in a series of trials that have the following characteristics:
There are only two possible outcomes – success or failure.
The probability of success is the same in each trial.
If a  random variable  <em>X</em> follows a geometric distribution, then the probability of experiencing <em>k</em> failures before experiencing the first success can be found by the following formula:
<b>P(X=k) = (1-p)<sup>k</sup>p</b>
where:
<b>k: </b>number of failures before first success
<b>p: </b>probability of success on each trial
The <b>cumulative probability</b> that we experience <em>k</em> or less failures until the first success can be found by using the following formula:
<b>P(X≤k) = 1 – (1-p)<sup>k+1</sup></b>
To calculate probabilities related to the geometric distribution on a TI-84 calculator, we can use the following functions:
<b>geometpdf(probability, trials)</b>
<b>geometcdf(probability, trials)</b>
The following examples show how to use each of these functions in practice.
<h3>Example 1: How to Use geometpdf()</h3>
Suppose a researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. What is the probability that the fourth person the researcher talks to is the first person to support the law?
To answer this, we can use the <b>geometpdf()</b> function.
Press 2nd and then press VARS. Scroll down to <b>geometpdf()</b> and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/geomet1.png">
Then type in the following values and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/geomet2-2.png">
The probability that the fourth person the researcher talks to is the first person to support the law is <b>0.1024</b>.
<h3>Example 2: How to Use geometcdf()</h3>
Suppose it’s known that 4% of individuals who visit a certain banker are visiting to file bankruptcy. What is the probability that the banker will meet with less than 9 people before encountering someone who is filing for bankruptcy?
To answer this, we can use the <b>geometcdf()</b> function.
Press 2nd and then press VARS. Scroll down to <b>geometcdf()</b> and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/geomet3.png">
Then type in the following values and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/geomet4.png">
The probability that the banker will meet with less than 9 people before encountering someone who is filing for bankruptcy is <b>0.307466</b>.
<b>Bonus:</b> Feel free to use this  online geometric distribution calculator  to confirm your results.
<h2><span class="orange">Geometric Distribution Calculator</span></h2>
This calculator finds probabilities associated with the geometric distribution based on user provided input.
<label><b>p</b> (probability of success on a given trial)</label>
<input type="number" id="p" value="0.3">
<label><b>x</b> (number of failures until first success)</label>
<input type="number" id="x" value="7">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
P(X = 7): 0.02471
P(X &lt; 7): 0.91765
P(X ≤ 7): 0.94235
P(X > 7): 0.05765
P(X ≥ 7): 0.08235
<script>
function calc() {
//get input values
var p = +document.getElementById('p').value;
var x = +document.getElementById('x').value;
//calculate SE
var exactP = jStat.negbin.pdf(x, 1, p);
var lessP = jStat.negbin.cdf(x-1, 1, p);
var lessEP = jStat.negbin.cdf(x, 1, p);
var greatP = 1-jStat.negbin.cdf(x, 1, p);
var greatEP = 1-jStat.negbin.cdf(x-1, 1, p);
//output probabilities
document.getElementById('exactP').innerHTML = exactP.toFixed(5);
document.getElementById('lessP').innerHTML = lessP.toFixed(5);
document.getElementById('lessEP').innerHTML = lessEP.toFixed(5);
document.getElementById('greatP').innerHTML = greatP.toFixed(5);
document.getElementById('greatEP').innerHTML = greatEP.toFixed(5);
document.getElementById('x1').innerHTML = x;
document.getElementById('x2').innerHTML = x;
document.getElementById('x3').innerHTML = x;
document.getElementById('x4').innerHTML = x;
document.getElementById('x5').innerHTML = x;
}
</script>
<h2><span class="orange">How to Use the Geometric Distribution in Excel</span></h2>
The  geometric distribution  describes the probability of experiencing a certain amount of failures before experiencing the first success in a series of Bernoulli trials.
A <b>Bernoulli trial</b> is an experiment with only two possible outcomes – “success” or “failure” – and the probability of success is the same each time the experiment is conducted.
 
An example of a Bernoulli trial is a coin flip. The coin can only land on two sides (we could call heads a “success” and tails a “failure”) and the probability of success on each flip is 0.5, assuming the coin is fair.
If a  random variable  <em>X</em> follows a geometric distribution, then the probability of experiencing <em>k </em>failures before experiencing the first success can be found by the following formula:
<b>P(X=k) = (1-p)<sup>k</sup>p</b>
where:
<b>k: </b>number of failures before first success
<b>p: </b>probability of success on each trial
The following examples show how to calculate probabilities related to the geometric distribution in Excel.
<h3>Example 1: Flipping a Coin</h3>
Suppose we are flipping a coin and we want to know the probability that it will take exactly three “failures” until a coin finally lands on heads.
We would use the following formula to calculate this probability:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/geomDistExcel1.png">
The probability that we will experience three “failures” until a coin finally lands on heads is <b>.0625</b>.
<h3>Example 2: Shooting Free Throws</h3>
Suppose a certain basketball player makes 60% of his free throws. What is the probability that the player will miss four free throws until he finally makes one?
We would use the following formula to calculate this probability:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/geomDistExcel3.png">
The probability that the player will miss four free throws until he finally makes one is <b>.01536</b>.
<h3>Example 3: Supporting a Law</h3>
Suppose a researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. What is the probability that the fourth person the researcher talks to is the first person to support the law?
We would use the following formula to calculate this probability:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/geomDistExcel2.png">
The probability that the fourth person the researcher talks to is the first person to support the law is <b>.1024</b>.
<h2><span class="orange">5 Real-Life Examples of the Geometric Distribution</span></h2>
The  Geometric distribution  is a probability distribution that is used to model the probability of experiencing a certain amount of failures before experiencing the first success in a series of Bernoulli trials.
A <b>Bernoulli trial</b> is an experiment with only two possible outcomes – “success” or “failure” – and the probability of success is the same each time the experiment is conducted.
 
An example of a Bernoulli trial is a coin flip. The coin can only land on two sides (we could call heads a “success” and tails a “failure”) and the probability of success on each flip is 0.5, assuming the coin is fair.
If a  random variable  <em>X</em> follows a geometric distribution, then the probability of experiencing <em>k</em> failures before experiencing the first success can be found by the following formula:
<b>P(X=k) = (1-p)<sup>k</sup>p</b>
where:
<b>k: </b>number of failures before first success
<b>p: </b>probability of success on each trial
In this article we share 5 examples of how the Geometric distribution is used in the real world.
<h3>Example 1: Coin Tosses</h3>
 Suppose we want to know how many times we’ll have to flip a fair coin until it lands on heads.
We can use the following formulas to determine the probability of experiencing 0, 1, 2, 3 failures, etc. before the coin lands on heads:
<em><b>Note: </b>The coin can experience 0 “failures” if it lands on heads on the first flip.</em>
<b>P(X=0) </b>= (1-.5)<sup>0</sup>(.5) = <b>0.5</b>
<b>P(X=1) </b>= (1-.5)<sup>1</sup>(.5) = <b>0.25</b>
<b>P(X=2) </b>= (1-.5)<sup>2</sup>(.5) = <b>0.125</b>
<b>P(X=3) </b>= (1-.5)<sup>3</sup>(.5) = <b>0.0625</b>
<h3>Example 2: Supporters of a Law</h3>
Suppose a researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. 
We can use the following formulas to determine the probability of interviewing 0, 1, 2 people, etc. before the researcher speaks with someone who supports the law:
<b>P(X=0) </b>= (1-.2)<sup>0</sup>(.2) = <b>0.2</b>
<b>P(X=1) </b>= (1-.2)<sup>1</sup>(.2) = <b>0.16</b>
<b>P(X=2) </b>= (1-.2)<sup>2</sup>(.2) = <b>0.128</b>
<h3>Example 3: Number of Defects</h3>
Suppose it’s known that 5% of all widgets on an assembly line are defective. 
We can use the following formulas to determine the probability of inspecting 0, 1, 2 widgets, etc. before an inspector comes across a defective widget:
<b>P(X=0) </b>= (1-.05)<sup>0</sup>(.05) = <b>0.05</b>
<b>P(X=1) </b>= (1-.05)<sup>1</sup>(.05) = <b>0.0475</b>
<b>P(X=2) </b>= (1-.05)<sup>2</sup>(.05) = <b>0.04512</b>
<h3>Example 4: Number of Bankruptcies</h3>
Suppose it’s known that 4% of individuals who visit a certain bank are visiting to file bankruptcy. Suppose a banker wants to know the probability that he will meet with less than 10 people before encountering someone who is filing for bankruptcy.
We can use the  Geometric Distribution Calculator  with p = 0.04 and x = 10 to find that the probability that he meets with less than 10 people before encountering someone who is failing for bankruptcy is <b>0.33517</b>.
<h3>Example 5: Number of Network Failures</h3>
Suppose it’s known that the probability that a a certain company experiences a network failure in a given week is 10%. Suppose the CEO of the company would like to know the probability that the company can go 5 weeks or longer without experiencing a network failure.
We can use the  Geometric Distribution Calculator  with p = 0.10 and x = 5 to find that the probability that the company lasts 5 weeks or longer without a failure is <b>0.59049</b>.
<h2><span class="orange">An Introduction to the Geometric Distribution</span></h2>
The <b>geometric distribution</b> describes the probability of experiencing a certain amount of failures before experiencing the first success in a series of Bernoulli trials.
A <b>Bernoulli trial</b> is an experiment with only two possible outcomes – “success” or “failure” – and the probability of success is the same each time the experiment is conducted.
 
An example of a Bernoulli trial is a coin flip. The coin can only land on two sides (we could call heads a “success” and tails a “failure”) and the probability of success on each flip is 0.5, assuming the coin is fair.
If a  random variable  <em>X</em> follows a geometric distribution, then the probability of experiencing <em>k </em>failures before experiencing the first success can be found by the following formula:
<b>P(X=k) = (1-p)<sup>k</sup>p</b>
where:
<b>k: </b>number of failures before first success
<b>p: </b>probability of success on each trial
For example, suppose we want to know how many times we’ll have to flip a fair coin until it lands on heads. We can use the formula above to determine the probability of experiencing 0, 1, 2, 3 failures, etc. before the coin lands on heads:
<em><b>Note: </b>The coin can experience 0 “failures” if it lands on heads on the first flip.</em>
<b>P(X=0) </b>= (1-.5)<sup>0</sup>(.5) = <b>0.5</b>
<b>P(X=1) </b>= (1-.5)<sup>1</sup>(.5) = <b>0.25</b>
<b>P(X=2) </b>= (1-.5)<sup>2</sup>(.5) = <b>0.125</b>
<b>P(X=3) </b>= (1-.5)<sup>3</sup>(.5) = <b>0.0625</b>
We can calculate the probability for any number of coin flips up to infinity. We create then create a simple histogram to visualize this probability distribution:
<figure><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/geomDist1.png"></figure>
<h3>Calculating Cumulative Geometric Probabilities</h3>
The <b>cumulative probability</b> that we experience <em>k </em>or less failures until the first success can be found by the following formula:
<b>P(X≤k) = 1 – (1-p)<sup>k+1</sup></b>
where:
<b>k: </b>number of failures before first success
<b>p: </b>probability of success on each trial
For example, suppose we want to know the probability that it will take three or less “failures” until the coin finally lands on heads. We would use the following formula to calculate this probability:
<b>P(X≤3)</b> = 1 – (1-.5)<sup>3+1</sup> = <b>0.9375</b>
We can calculate each cumulative probability using a similar formula:
<b>P(X≤0)</b> = 1 – (1-.5)<sup>0+1</sup> = <b>0.5</b>
<b>P(X≤1)</b> = 1 – (1-.5)<sup>1+1</sup> = <b>0.75</b>
<b>P(X≤2)</b> = 1 – (1-.5)<sup>2+1</sup> = <b>0.875</b>
We can calculate these cumulative probabilities for any number of coin flips up to infinity. We can then create a histogram to visualize this cumulative probability distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/geomDist2.png">
<h3>Properties of the Geometric Distribution</h3>
The geometric distribution has the following properties:
The mean of the distribution is<b> (1-p) / p</b>.
The variance of the distribution is <b> (1-p) / p<sup>2</sup></b>.
For example:
The mean number of times we would expect a coin to land on tails before it landed on heads would be (1-p) / p = (1-.5) / .5 = <b>1</b>.
The variance in the number of flips until it landed on heads would be (1-p) / p<sup>2</sup> = (1-.5) / .5<sup>2</sup> = <b>2</b>.
<h3>Geometric Distribution Practice Problems</h3>
Use the following practice problems to test your knowledge of the Geometric distribution.
<em><b>Note: </b>We will use the  Geometric Distribution Calculator  to calculate the answers to these questions.</em>
<b>Problem 1</b>
<b>Question: </b>A researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. What is the probability that the fourth person the researcher talks to is the first person to support the law?
<b>Answer:</b> The number of “failures” until the first success – i.e. the number of people who don’t support the law until the first person supports it – is 3. Thus, using the Geometric Distribution Calculator with p =0.2 and x = 3 failures, we find that P(X=3) = <b>0.10240</b>.
<b>Problem 2</b>
<b>Question: </b>A researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. What is the probability that the researcher will have to talk to <em>more </em>than four people to find someone who supports the law?
<b>Answer:</b> Using the Geometric Distribution Calculator with p =0.2 and x = 4 failures, we find that P(X>4) = <b>0.32768</b>.
<b>Problem 3</b>
<b>Question: </b>A researcher is waiting outside of a library to ask people if they support a certain law. The probability that a given person supports the law is p = 0.2. What is the expected number of people the researcher will have to talk to until she finds someone who supports the law?
<b>Answer:</b> Recall that the mean of the geometric distribution is <b>(1-p) / p</b>. In this situation, the mean would be (1-.2) / .2 = <b>4</b>.
<h2><span class="orange">How to Calculate Geometric Mean in R (With Examples)</span></h2>
You can use the following syntax to calculate the geometric mean of a set of numbers in R:
<b>exp(mean(log(x)))
</b>
The following examples show how to use this function in practice.
<h3>Example 1: Calculate Geometric Mean of Vector</h3>
The following code shows how to calculate the geometric mean for a single vector in R:
<b>#define vector
x &lt;- c(4, 8, 9, 9, 12, 14, 17)
#calculate geometric mean of values in vector
exp(mean(log(x)))
[1] 9.579479
</b>
<h3>Example 2: Calculate Geometric Mean of Vector with Zeros</h3>
If your vector contains zeros or negative numbers, the formula above will return a 0 or a NaN.
To ignore zeros and negative numbers when calculating the geometric mean, you can use the following formula:
<b>#define vector with some zeros and negative numbers
x &lt;- c(4, 8, 9, 9, 12, 14, 17, 0, -4)
#calculate geometric mean of values in vector
exp(mean(log(x[x>0])))
[1] 9.579479</b>
<h3>Example 3: Calculate Geometric Mean of Columns in Data Frame</h3>
The following code shows how to calculate the geometric mean of a column in a data frame:
<b>#define data frame
df &lt;- data.frame(a=c(1, 3, 4, 6, 8, 8, 9), b=c(7, 8, 8, 7, 13, 14, 16), c=c(11, 13, 13, 18, 19, 19, 22), d=c(4, 8, 9, 9, 12, 14, 17))
#calculate geometric mean of values in column 'a'
exp(mean(log(df$a)))
[1] 4.567508</b>
And the following code shows how to calculate the geometric mean of multiple columns in a data frame:
<b>#define data frame
df &lt;- data.frame(a=c(1, 3, 4, 6, 8, 8, 9), b=c(7, 8, 8, 7, 13, 14, 16), c=c(11, 13, 13, 18, 19, 19, 22), d=c(4, 8, 9, 9, 12, 14, 17))
#calculate geometric mean of values in column 'a', 'b', and 'd'
apply(df[ , c('a', 'b', 'd')], 2, function(x) exp(mean(log(x))))
       a        b        d 
4.567508 9.871128 9.579479 </b>
<h2><span class="orange">How to Calculate Geometric Mean in Python (With Examples)</span></h2>
There are two ways to calculate the geometric mean in Python:
<b>Method 1: Calculate Geometric Mean Using SciPy</b>
<b>from scipy.stats import gmean
#calculate geometric mean
gmean([value1, value2, value3, ...])
</b>
<b>Method 2: Calculate Geometric Mean Using NumPy</b>
<b>import numpy as np
#define custom function
def g_mean(x):
    a = np.log(x)
    return np.exp(a.mean())
#calculate geometric mean 
g_mean([value1, value2, value3, ...])</b>
Both methods will return the exact same results.
The following examples show how to use each of these methods in practice.
<h3>Example 1: Calculate Geometric Mean Using SciPy</h3>
The following code shows how to use the <b>gmean()</b> function from the  SciPy  library to calculate the geometric mean of an array of values:
<b>from scipy.stats import gmean
#calculate geometric mean
gmean([1, 4, 7, 6, 6, 4, 8, 9])
4.81788719702029
</b>
The geometric mean turns out to be <b>4.8179</b>.
<h3>Example 2: Calculate Geometric Mean Using NumPy</h3>
The following code shows how to write a custom function to calculate a geometric mean using built-in functions from the  NumPy  library:
<b>import numpy as np
#define custom function
def g_mean(x):
    a = np.log(x)
    return np.exp(a.mean())
#calculate geometric mean
g_mean([1, 4, 7, 6, 6, 4, 8, 9])
4.81788719702029
</b>
The geometric mean turns out to be <b>4.8179</b>, which matches the result from the previous example.
<h3>How to Handle Zeros</h3>
Note that both methods will return a zero if there are any zeros in the array that you’re working with.
Thus, you can use the following bit of code to remove any zeros from an array before calculating the geometric mean:
<b>#create array with some zeros
x = [1, 0, 0, 6, 6, 0, 8, 9]
#remove zeros from array 
x_new = [i for i in x if i != 0]
#view updated array
print(x_new)
[1, 6, 6, 8, 9]
</b>
<h2><span class="orange">How to Get the Index of Max Value in NumPy Array</span></h2>
You can use the following methods to get the index of the max value in a NumPy array:
<b>Method 1: Get Index of Max Value in One-Dimensional Array</b>
<b>x.argmax()
</b>
<b>Method 2: Get Index of Max Value in Each Row of Multi-Dimensional Array</b>
<b>x.argmax(axis=1)</b>
<b>Method 3: Get Index of Max Value in Each Column of Multi-Dimensional Array</b>
<b>x.argmax(axis=0)</b>
The following examples show how to use each method in practice.
<h2>Example 1: Get Index of Max Value in One-Dimensional Array</h2>
The following code shows how to get the index of the max value in a one-dimensional NumPy array:
<b>import numpy as np
#create NumPy array of values
x = np.array([2, 7, 9, 4, 4, 6, 3])
#find index that contains max value
x.argmax()
2</b>
The <b>argmax()</b> function returns a value of <b>2</b>.
This tells us that the value in index position <b>2</b> of the array contains the maximum value.
If we look at the original array, we can see that the value in index position <b>2</b> is <b>9</b>, which is indeed the maximum value in the array.
<h2>Example 2: Get Index of Max Value in Each Row of Multi-Dimensional Array</h2>
The following code shows how to get the index of the max value in each row of a multi-dimensional NumPy array:
<b>import numpy as np
#create multi-dimentsional NumPy array
x = np.array([[4, 2, 1, 5], [7, 9, 2, 0]])
#view NumPy array
print(x)
[[4 2 1 5]
 [7 9 2 0]]
#find index that contains max value in each row
x.argmax(axis=1)
array([3, 1], dtype=int32)
</b>
From the results we can see:
The max value in the first row is located in index position <b>3</b>.
The max value in the second row is located in index position <b>1</b>.
<h2>Example 3: Get Index of Max Value in Each Column of Multi-Dimensional Array</h2>
The following code shows how to get the index of the max value in each column of a multi-dimensional NumPy array:
<b>import numpy as np
#create multi-dimentsional NumPy array
x = np.array([[4, 2, 1, 5], [7, 9, 2, 0]])
#view NumPy array
print(x)
[[4 2 1 5]
 [7 9 2 0]]
#find index that contains max value in each column
x.argmax(axis=0)
array([1, 1, 1, 0], dtype=int32)
</b>
From the results we can see:
The max value in the first column is located in index position <b>1</b>.
The max value in the second column is located in index position <b>1</b>.
The max value in the third column is located in index position <b>1</b>.
The max value in the fourth column is located in index position <b>0</b>.
<b>Related:</b>  A Simple Explanation of NumPy Axes 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Python:
 How to Fill NumPy Array with Values 
 How to Replace Elements in NumPy Array 
 How to Get Specific Row from NumPy Array 
<h2><span class="orange">How to Add an Average Line to Plot in ggplot2</span></h2>
You can use the following basic syntax to add a line that represents the average value in a plot in ggplot2:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept = mean(df$y, na.rm=TRUE))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Add Average Line to Plot in ggplot2</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), y=c(2, 5, 6, 5, 7, 8, 10, 12, 10, 9, 11, 15))
#view head of data frame
head(df)
  x y
1 1 2
2 2 5
3 3 6
4 4 5
5 5 7
6 6 8
</b>
We can use the following code to create a scatter plot of x vs. y and add a horizontal line that represents the average y-value:
<b>library(ggplot2)
#create scatter plot with average line to represent average y-value
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_hline(yintercept = mean(df$y, na.rm=TRUE))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ggplot_avg_line.jpg">
We can see that an average line has been added to the plot just above the y-value of 8.
 If we calculate the average y-value, we’ll find that it’s 8.333:
<b>#calculate average y-value
mean(df$y, na.rm=TRUE)
[1] 8.333333
</b>
Note that we can also use the <b>color</b>, <b>lty</b>, and <b>lwd</b> arguments to specify the color, line type, and line width of the average line, respectively:
<b>library(ggplot2)
#create scatter plot with custom average line
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_hline(yintercept = mean(df$y, na.rm=TRUE), color='blue', lty='dashed', lwd=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ggplot_avg_line2.jpg"492">
The average line is now blue, dashed, and has a line width of 2.
You can find the complete online documentation for the <b>geom_hline()</b> function  here .
<h2><span class="orange">How to Rotate Annotated Text in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to rotate annotated text in plots in ggplot2:
<b>ggplot(df) +
  geom_point(aes(x=x, y=y)) + 
  geom_text(aes(x=x, y=y, label=group), hjust=-0.3, vjust=-0.1, angle=45)</b>
In this particular example we use the <b>angle</b> argument to rotate the annotated text 45 degrees counterclockwise and the <b>hjust</b> and <b>vjust</b> arguments to increase the horizontal and vertical distance of the text from the points in the plot.
The following example shows how to use this syntax in practice.
<h2>Example: Rotate Annotated Text in ggplot2</h2>
Suppose we have the following dataset in R:
<b>#create data frame
df &lt;- data.frame(player=c('Brad', 'Ty', 'Spencer', 'Luke', 'Max'), points=c(17, 5, 12, 20, 22), assists=c(4, 3, 7, 7, 5))
#view data frame
df
   player points assists
1    Brad     17       4
2      Ty      5       3
3 Spencer     12       7
4    Luke     20       7
5     Max     22       5</b>
Now suppose we create the following scatter plot in ggplot2 to visualize this data:
<b>library(ggplot2)
#create scatter plot with annotated labels
ggplot(df) +
  geom_point(aes(x=points, y=assists)) + 
  geom_text(aes(x=points, y=assists, label=player))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/rotate11.jpg"475">
Notice that the labels are horizontal and located directly on top of the points.
We can use the following syntax to rotate the labels and move them slightly further from the points to make them easier to read:
<b>library(ggplot2)
#create scatter plot with annotated rotated labels
ggplot(df) +
  geom_point(aes(x=points, y=assists)) + 
  geom_text(aes(x=points, y=assists, label=player), hjust=-.3, vjust=-.1, angle=45) +
  ylim(3, 8)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/rotate12.jpg"468">
Notice that the labels are now all rotated 45 degrees counterclockwise.
Feel free to play around with the <b>hjust</b>, <b>vjust</b>, and <b>angle</b> arguments to get your annotated text in whatever position you’d like on the plot.
<b>Note</b>: We also used the <b>ylim</b> argument to  increase the y-axis limits  on the plot so the label “Spencer” at the top of the plot wasn’t cut off.
<h2><span class="orange">How to Draw Arrows in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to draw an arrow in a plot in ggplot2:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_segment(aes(x=5, y=6, xend=8, yend=9), arrow = arrow(length=unit(0.5, 'cm')))
</b>
Here is what each argument does in the <b>geom_segment()</b> function:
<b>x</b>: The x-value to start at
<b>y</b>: The y-value to start at
<b>xend</b>: The x-value to end at
<b>yend</b>: The y-value to end at
<b>arrow</b>: The length of the arrow head
The following example shows how to draw an arrow using ggplot2 in practice.
<h2>Example: Draw Arrows in ggplot2</h2>
Suppose we have the following data frame that contains information on the number of points scored and rebounds collected by various basketball players:
<b>#create data frame
df &lt;- data.frame(points=c(3, 3, 5, 6, 7, 8, 9, 9, 8, 5), rebounds=c(2, 6, 5, 5, 8, 5, 9, 9, 8, 6))
#view data frame
df
   points rebounds
1       3        2
2       3        6
3       5        5
4       6        5
5       7        8
6       8        5
7       9        9
8       9        9
9       8        8
10      5        6</b>
We can use the following syntax to create a scatter plot in ggplot2 and add an arrow to specific location on the plot:
<b>library(ggplot2)
#create scatterplot and add arrow
ggplot(df, aes(x=points, y=rebounds)) +
  geom_point() +
  geom_segment(aes(x=5, y=6, xend=8, yend=9), arrow = arrow(length=unit(.5, 'cm')))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/arrow1.jpg">
Feel free to modify the value in the <b>arrow()</b> function to increase or decrease the size of the arrow head.
For example, the following code shows how to increase the size:
<b>library(ggplot2)
#create scatterplot and add arrow with increased arrow head size
ggplot(df, aes(x=points, y=rebounds)) +
  geom_point() +
  geom_segment(aes(x=5, y=6, xend=8, yend=9), arrow = arrow(length=unit(2, 'cm')))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/arrow2.jpg"550">
You can also use the <b>color</b> and <b>lwd</b> arguments to change the color and line width of the arrow, respectively:
<b>library(ggplot2)
#create scatterplot and add customized arrow
ggplot(df, aes(x=points, y=rebounds)) +
  geom_point() +
  geom_segment(aes(x=5, y=6, xend=8, yend=9), arrow = arrow(length=unit(.5, 'cm')),
               color='red', lwd=3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/arrow3.jpg"565">
Feel free to play around with the various arguments in the <b>geom_segment()</b> function to create an arrow that looks exactly how you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Remove Gridlines in ggplot2 
 How to Shade an Area in ggplot2 
 How to Change X-Axis Labels in ggplot2 
<h2><span class="orange">How to Set Axis Breaks in ggplot2 (With Examples)</span></h2>
You can use the following syntax to set the axis breaks for the y-axis and x-axis in  ggplot2 :
<b>#set breaks on y-axis
scale_y_continuous(limits = c(0, 100), breaks = c(0, 50, 100))
#set breaks on y-axis
scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10))
</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 7, 8, 9, 10), y=c(12, 17, 27, 39, 50, 57, 66, 80))
#view data frame
df
   x  y
1  1 12
2  2 17
3  4 27
4  5 39
5  7 50
6  8 57
7  9 66
8 10 80
</b>
<h3>Example 1: Set Y-Axis Breaks</h3>
The following code shows how to create a simple scatterplot using ggplot2:
<b>library(ggplot2)
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point() 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/breaks1.png">
By default, the y-axis shows breaks at 20, 40, 60, and 80. However, we can use the <b>scale_y_continuous()</b> function to display breaks at every 10 values instead:
<b>#create scatterplot of x vs. y with custom breaks on y-axis
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/breaks2.png">
<h3>Example 2: Set X-Axis Breaks</h3>
We can use the <b>scale_x_continuous()</b> function to set the breaks on the x-axis:
<b>#create scatterplot of x vs. y with custom breaks on x-axis
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/breaks3.png">
We typically set axis breaks at uniform intervals, but we could choose to set axis breaks only at specific numbers.
For example, the following code shows how to display x-axis breaks only at the values 0, 7, and 10:
<b>#create scatterplot of x vs. y with custom breaks on x-axis
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_x_continuous(limits = c(0, 10), breaks = c(0, 7, 10))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/breaks4.png">
<h2><span class="orange">How to Set Axis Label Position in ggplot2 (With Examples)</span></h2>
You can use the following syntax to modify the axis label position in ggplot2:
<b>theme(axis.title.x = element_text(margin=margin(t=20)), #add margin to x-axis title
      axis.title.y = element_text(margin=margin(r=60))) #add margin to y-axis title
</b>
Note that you can specify <b>t</b>, <b>r</b>, <b>b</b>, <b>l</b> for the margin argument, which stands for top, right, bottom, and left.
The following examples show how to use this syntax in practice.
<h3>Example 1: Set X-Axis Label Position</h3>
Suppose we create the following scatterplot using ggplot2:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 7, 8, 9, 10), y=c(12, 17, 27, 39, 50, 57, 66, 80))
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/position1.png">
We can add a margin to the top of the x-axis title to make the x-axis title appear further from the axis:
<b>#create scatterplot of x vs. y with margin added on x-axis title
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme(axis.title.x = element_text(margin = margin(t = 70)))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/position2.png">
Notice that we added a significant amount of spacing between the x-axis title and the x-axis.
<h3>Example 2: Set Y-Axis Label Position</h3>
We can use the following code to add a margin to the right of the y-axis title to make the y-axis title appear further from the axis:
<b>#create scatterplot of x vs. y with margin added on y-axis title
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme(axis.title.y = element_text(margin = margin(r = 70)))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/position3.png">
Notice that we added significant spacing between the y-axis title and the y-axis.
<h2><span class="orange">How to Change Number of Axis Ticks in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to change the number of axis ticks on plots in ggplot2:
<b>p +
  scale_x_continuous(n.breaks=10) +
  scale_y_continuous(n.breaks=10)
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change Number of Axis Ticks in ggplot2</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 6, 8, 12, 14, 19), y=c(2, 5, 7, 8, 14, 19, 22, 28, 36))
#view data frame
df
   x  y
1  1  2
2  2  5
3  4  7
4  5  8
5  6 14
6  8 19
7 12 22
8 14 28
9 19 36</b>
If we create a scatter plot, ggplot2 will automatically pick a suitable number of ticks for both the x-axis and y-axis:
<b>library(ggplot2)
#create scatter plot
ggplot(df, aes(x=x, y=y)) +
  geom_point(size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/breaks1.jpg"479">
However, we can use the <b>n.breaks</b> argument to specify the exact number of ticks to use on both axes:
<b>library(ggplot2)
#create scatter plot with custom number of ticks
ggplot(df, aes(x=x, y=y)) +
  geom_point(size=2) +
  scale_x_continuous(n.breaks=10) +
  scale_y_continuous(n.breaks=10)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/breaks2.jpg"489">
Notice that the number of ticks on both axes has increased.
Also note that you can change the number of ticks on just one axis if you’d like:
<b>library(ggplot2)
#create scatter plot with custom number of ticks on x-axis only
ggplot(df, aes(x=x, y=y)) +
  geom_point(size=2) +
  scale_x_continuous(n.breaks=20)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/breaks3.jpg"475">
In this example, ggplot2 chooses the number of ticks to use on the y-axis but the number of ticks on the x-axis is determined by the number in the <b>n.breaks</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Change Background Color in ggplot2 (With Examples)</span></h2>
You can use the following syntax to change the background color of various elements in a ggplot2 plot:
<b>p + theme(panel.background = element_rect(fill = 'lightblue', color = 'purple'),
          panel.grid.major = element_line(color = 'red', linetype = 'dotted'),
          panel.grid.minor = element_line(color = 'green', size = 2))
</b>
Alternatively, you can use built-in ggplot2 themes to automatically change the background color. Here are some of the more commonly used themes:
<b>p + theme_bw() #white background and grey gridlines
p + theme_minimal() #no background annotations
p + theme_classic() #axis lines but no gridlines
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Specify Custom Background Color</h3>
The following code shows how to create a basic scatterplot in ggplot2 with the default grey background:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot
p &lt;- ggplot(df, aes(x=x, y=y)) +
       geom_point()
#display scatterplot
p</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/background1.png">
We can use the following code to change the background color of the panel along with the major and minor gridlines:
<b>p + theme(panel.background = element_rect(fill = 'lightblue', color = 'purple'),
          panel.grid.major = element_line(color = 'red', linetype = 'dotted'),
          panel.grid.minor = element_line(color = 'green', size = 2))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/background2.png">
<h3>Example 2: Use Built-in Theme to Change Background Color</h3>
The following code shows how to use various built-in ggplot2 themes to automatically change the background color of the plots:
<b>p + theme_bw() #white background and grey gridlines
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/background3.png">
<b>p + theme_minimal() #no background annotations</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/background4.png">
<b>p + theme_classic() #axis lines but no gridlines</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/background5.png">
<h2><span class="orange">How to Add Caption to ggplot2 Plots (3 Examples)</span></h2>
You can use the following methods to add a caption to plots in ggplot2:
<b>Method 1: Add Caption in Default Location</b>
<b>p +
  labs(caption = "This is my caption")
</b>
<b>Method 2: Add Caption in Custom Location</b>
<b>p +
  labs(caption = "This is my caption") +
  theme(plot.caption = element_text(hjust=0))</b>
<b>Method 3: Add Caption & Customize Text</b>
<b>p +
  labs(caption = "This is my caption") +
  theme(plot.caption = element_text(size=16, color="red", face="italic"))</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(assists=c(1, 2, 2, 3, 5, 6, 7, 8, 8), points=c(3, 6, 9, 14, 20, 23, 16, 19, 26))
#view data frame
df
  assists points
1       1      3
2       2      6
3       2      9
4       3     14
5       5     20
6       6     23
7       7     16
8       8     19
9       8     26
</b>
<h2>Example 1: Add Caption in Default Location</h2>
The following code shows how to create a scatter plot in gglot2 and add a caption in the default location (bottom right corner below plot):
<b>library(ggplot2)
#create scatter plot with caption in bottom left corner
ggplot(df, aes(x=assists, y=points)) +
  geom_point(size=3) +
  labs(caption = "Based on 2022 Basketball Data")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/caption1.jpg">
Notice that a caption has been added to the bottom right corner outside the plot.
<h2>Example 2: Add Caption in Custom Location</h2>
The following code shows how to create a scatter plot in gglot2 and add a caption in the bottom left corner below the plot:
<b>library(ggplot2)
#create scatter plot with caption in default location
ggplot(df, aes(x=assists, y=points)) +
  geom_point(size=3) +
  labs(caption = "Based on 2022 Basketball Data") +
  theme(plot.caption = element_text(hjust=0))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/caption2.jpg"501">
Notice that a caption has been added to the bottom left corner outside the plot.
<b>Note</b>: You can specify <b>hjust=0.5</b> to place the caption in the bottom center outside the plot.
<b>Related:</b>  How to Use hjust & vjust to Move Elements in ggplot2 
<h2>Example 3: Add Caption & Customize Text</h2>
The following code shows how to create a scatter plot in gglot2 and add a caption with a custom color, font size, and style:
<b>library(ggplot2)
#create scatter plot with caption in default location
ggplot(df, aes(x=assists, y=points)) +
  geom_point(size=3) +
  labs(caption = "Based on 2022 Basketball Data") +
  theme(plot.caption = element_text(size=16, color="red", face="italic"))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/caption3-1.jpg">
Notice that a caption has been added to the bottom right corner outside the plot with a custom color, font size, and style.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Change Font Size in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Change Colors of Bars in Stacked Bart Chart in ggplot2</span></h2>
You can use the following basic syntax to change the color of bars in a stacked bar chart in ggplot2:
<b>#create stacked bar chart
ggplot(df, aes(x=x_var, y=y_var, fill=fill_var)) + 
  geom_bar(position='stack', stat='identity') +
  scale_fill_manual(values=c('red', 'purple', 'pink', ...))</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change Color of Bars in Stacked Bar Chart in ggplot2</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), position=c('G', 'F', 'C', 'G', 'F', 'C', 'G', 'F', 'C'), points=c(22, 12, 10, 30, 12, 17, 28, 23, 20))
#view data frame
df
  team position points
1    A        G     22
2    A        F     12
3    A        C     10
4    B        G     30
5    B        F     12
6    B        C     17
7    C        G     28
8    C        F     23
9    C        C     20</b>
If we create a stacked bar chart to visualize the points scored by players on each team, ggplot2 will use a set of  default colors  to fill in the bars:
<b>library(ggplot2)
#create stacked bar chart
ggplot(df, aes(x=team, y=points, fill=position)) + 
  geom_bar(position='stack', stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/reorder1.jpg"476">
However, we can use the <b>scale_fill_manual()</b> argument to specify the exact colors that ggplot2 should use for the bars:
<b>library(ggplot2)
#create stacked bar chart with custom colors
ggplot(df, aes(x=team, y=points, fill=position)) + 
  geom_bar(position='stack', stat='identity') +
  scale_fill_manual(values=c('red', 'purple', 'pink'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/custom1.jpg"471">
The bars now have the exact colors (in order from top to bottom) that we specified within the <b>scale_fill_manual() </b>function.
Also note that we can use hex color codes within the <b>scale_fill_manual()</b> function:
<b>library(ggplot2)
#create stacked bar chart with custom hex color codes
ggplot(df, aes(x=team, y=points, fill=position)) + 
  geom_bar(position='stack', stat='identity') +
  scale_fill_manual(values=c('#2596BE', '#8225BE', '#D4C443'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/custom2.jpg"468">
The bars now have the hex color codes that we specified.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Reorder Bars in a Stacked Bar Chart in ggplot2 
 How to Create a Barplot in ggplot2 with Multiple Variables 
 How to Order the Bars in a ggplot2 Bar Chart 
<h2><span class="orange">How to Change X-Axis Labels in ggplot2</span></h2>
You can use the <b>scale_x_discrete()</b> function to change the x-axis labels on a plot in ggplot2:
<b>p + scale_x_discrete(labels=c('label1', 'label2', 'label3', ...))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change X-Axis Labels in ggplot2</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball teams:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Heat', 'Nets', 'Lakers'), points=c(100, 122, 104, 109))
#view data frame
df
    team points
1   Mavs    100
2   Heat    122
3   Nets    104
4 Lakers    109
</b>
If we create a bar plot to visualize the points scored by each team, ggplot2 will automatically create labels to place on the x-axis:
<b>library(ggplot2)
#create bar plot
ggplot(df, aes(x=team, y=points)) +
  geom_col()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/bar1.jpg"458">
To change the x-axis labels to something different, we can use the <b>scale_x_discrete()</b> function:
<b>library(ggplot2)
#create bar plot with specific axis order
ggplot(df, aes(x=team, y=points)) +
  geom_col() +
  scale_x_discrete(labels=c('label1', 'label2', 'label3', 'label4'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/bar2.jpg">
The x-axis labels now match the labels that we specified using the<b> scale_x_discrete()</b> function.
You can also specify the labels in a vector outside of the <b>scale_discrete()</b> function if you’d like:
<b>library(ggplot2)
#specify labels for plot
my_labels &lt;- c('label1', 'label2', 'label3', 'label4')
#create bar plot with specific axis order
ggplot(df, aes(x=team, y=points)) +
  geom_col() +
  scale_x_discrete(labels=my_labels)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/bar2.jpg"463">
This matches the previous plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Add a Confidence Interval in ggplot2 (With Example)</span></h2>
You can use <b>geom_smooth()</b> to add confidence interval lines to a plot in ggplot2:
<b>library(ggplot2)
some_ggplot +
  geom_point() +
  geom_smooth(method=lm)</b>
The following examples show how to use this syntax in practice with the built-in  mtcars  dataset in R.
<h3>Example 1: Add Confidence Interval Lines in ggplot2</h3>
The following code shows how to create a scatterplot in ggplot2 and add a line of best fit along with 95% confidence bands:
<b>library(ggplot2)
#create scatterplot with confidence bands
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  geom_smooth(method=lm)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/geomsmooth1.jpg">
The blue line represents the fitted linear regression line and the grey bands represent the 95% confidence interval bands.
<h3>Example 2: Modify Level of Confidence Interval</h3>
By default, <b>geom_smooth()</b> uses 95% confidence bands but you can use the <b>level</b> argument to specify a different confidence level.
For example, we may choose to create 90% confidence bands instead:
<b>library(ggplot2)
#create scatterplot with 90% confidence bands
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  geom_smooth(method=lm, level=0.90)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/geomsmooth2.jpg"586">
The smaller the confidence level you use, the more narrow the confidence interval bands will be around the regression line.
<h3>Example 3: Modify Appearance of Confidence Interval Lines</h3>
You can also use the <b>color</b> and <b>fill</b> arguments to modify the color of the regression line and the color of the confidence interval bands, respectively:
<b>library(ggplot2)
#create scatterplot with custom confidence interval lines
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  geom_smooth(method=lm, color='red', fill='lightblue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/geomsmooth3.jpg"607">
The regression line is now red and the confidence interval bands are filled in with light blue.
<b>Note</b>: You can find the complete documentation for the <b>geom_smooth()</b> function  here .
<h2><span class="orange">How to Connect Points with Lines in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to connect points with lines in a plot in ggplot2:
<b>library(ggplot2)
ggplot(df, aes(x=x_var, y=y_var)) +</b>
<b>  geom_line() +</b>
<b>  geom_point()</b>
The following example shows how to use this syntax in practice.
<h2>Example: Connect Points with Lines in ggplot2</h2>
Suppose we have the following data frame that contains the number of sales made at some store during 10 consecutive days:
<b>#create data frame
df &lt;- data.frame(day=1:10, sales=c(3, 5, 5, 8, 12, 10, 8, 8, 5, 9))
#view data frame
df
   day sales
1    1     3
2    2     5
3    3     5
4    4     8
5    5    12
6    6    10
7    7     8
8    8     8
9    9     5
10  10     9
</b>
We can use the following code to create a plot in ggplot2 that has connected points to represent the sales made each day:
<b>library(ggplot2)
#create plot with connected points
ggplot(df, aes(x=day, y=sales)) +
  geom_line() +
  geom_point()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/connect1.jpg">
The x-axis displays the day and the y-axis displays the sales.
Also note that you can use the <b>color</b>, <b>size</b>, <b>linetype</b>, <b>shape</b>, and <b>fill</b> arguments to modify the appearance of both the line and the points in the plot:
<b>library(ggplot2)
#create plot with connected points
ggplot(df, aes(x=day, y=sales)) +
  geom_line(color='grey', size=1.5, linetype='dashed') +
  geom_point(shape=21, color='black', fill='pink', size=6)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/connect2.jpg"533">
Feel free to change the values for any of these arguments to make the plot appear exactly how you would like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot Multiple Lines in ggplot2 
 How to Add an Average Line to Plot in ggplot2 
 How to Change Line Colors in ggplot2 
<h2><span class="orange">A Complete Guide to the Default Colors in ggplot2</span></h2>
The  ggplot2  package has a list of default colors that it uses for the elements in a plot depending on the number of total elements.
For example, the following code shows how to create a bar plot with three bars:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C'), points=c(22, 28, 15))
#create bar plot using df
ggplot(df, aes(x=team, y=points, fill=team)) +
  geom_bar(stat = "identity")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/hue1.jpg"440">
By default, ggplot2 chooses to use a specific shade of red, green, and blue for the bars.
We can use the <b>hue_pal()</b> from the <b>scales</b> package to extract the actual hex color codes used in the plot:
<b>library(scales)
#extract hex color codes for a plot with three elements in ggplot2 
hex &lt;- hue_pal()(3)
#display hex color codes
hex
[1] "#F8766D" "#00BA38" "#619CFF"
</b>
Here’s how to interpret the output:
The hex color code for the red in the plot is <b>#F8766D</b>.
The hex color code for the green in the plot is <b>#00BA38</b>.
The hex color code for the blue in the plot is <b>#619CFF</b>.
We can use also use <b>show_col()</b> from the <b>scales</b> package to overlay the hex color codes on their actual colors:
<b>library(scales)
#extract hex color codes for a plot with three elements in ggplot2 
hex &lt;- hue_pal()(3)
#overlay hex color codes on actual colors
show_col(hex)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/hue2.jpg">
And we can use the following code to create a plot that shows the default ggplot2 colors for plots with one through eight elements:
<b>library(scales)
#set margins of plot area
par(mai = c(0.1, 0, 0.1, 0), bg = "grey85")
#create plot with ggplot2 default colors from 1 to 8
gc.grid &lt;- layout(matrix(1:8, nrow = 8))
for(i in 1:8){
   gc.ramp &lt;- hue_pal()(i)
   plot(c(0, 8), c(0,1),
        type = "n", 
        bty="n", 
        xaxt="n", 
        yaxt="n", xlab="", ylab="")
   for(j in 1:i){
      rect(j - 1, 0, j - 0.25, 1, col = gc.ramp[j])
   }
}</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/hue3.jpg">
And we can use the following code to display the hex color codes for each color shown in the plot:
<b>library(scales)
#display ggplot2 default hex color codes from 1 to 8
for(i in 1:8){
  print(hue_pal()(i))
}
[1] "#F8766D"
[1] "#F8766D" "#00BFC4"
[1] "#F8766D" "#00BA38" "#619CFF"
[1] "#F8766D" "#7CAE00" "#00BFC4" "#C77CFF"
[1] "#F8766D" "#A3A500" "#00BF7D" "#00B0F6" "#E76BF3"
[1] "#F8766D" "#B79F00" "#00BA38" "#00BFC4" "#619CFF" "#F564E3"
[1] "#F8766D" "#C49A00" "#53B400" "#00C094" "#00B6EB" "#A58AFF" "#FB61D7"
[1] "#F8766D" "#CD9600" "#7CAE00" "#00BE67" "#00BFC4" "#00A9FF" "#C77CFF" "#FF61CC"
</b>
<h2><span class="orange">How to Overlay Density Plots in ggplot2 (With Examples)</span></h2>
A <b>density plot</b> is a useful way to visualize the distribution of values in a dataset.
Often you may want to visualize the density plots of several variables at once. Fortunately, this is easy to do using the  ggplot2  data visualization package in R with the following syntax:
<b>ggplot(data, aes(x=value, fill=variable)) +
  geom_density(alpha=.25)
</b>
The <b>alpha</b> argument controls the opacity of each density plot. It’s important to set this value below 1 so that you can see each density plot when they overlay each other.
The following step-by-step example shows how to use this syntax in practice.
<h3>Step 1: Create the Data</h3>
First, let’s create a fake dataset with three variables:
<b>#make this example reproducible
set.seed(1)
#create data
df &lt;- data.frame(var1=rnorm(1000, mean=0, sd=1), var2=rnorm(1000, mean=0, sd=3), var3=rnorm(1000, mean=3, sd=2))
#view first six rows of data
head(df)
        var1       var2       var3
1 -0.6264538  3.4048953  1.2277008
2  0.1836433  3.3357955 -0.8445098
3 -0.8356286 -2.6123329  6.2394015
4  1.5952808  0.6321948  4.0385398
5  0.3295078  0.2081869  2.8883001
6 -0.8204684 -4.9879466  4.3928352</b>
<h3>Step 2: Convert the Data from Wide to Long</h3>
Next, we need to convert the data from a wide format to a long format to make it compatible with ggplot2:
<b>library(reshape)
#convert from wide format to long format
data &lt;- melt(df)
#view first six rows
head(data)
  variable      value
1     var1 -0.6264538
2     var1  0.1836433
3     var1 -0.8356286
4     var1  1.5952808
5     var1  0.3295078
6     var1 -0.8204684</b>
<h3>Step 3: Create the Overlaying Density Plots</h3>
Lastly, we can create the overlaying density plots:
<b>library(ggplot2)
#create overlaying density plots
ggplot(data, aes(x=value, fill=variable)) +
  geom_density(alpha=.25)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/densityggplot1.png">
Feel free to adjust the <b>alpha</b> value to make the density plots more or less transparent.
For example, here’s what the plots would look like if we increased the alpha value:
<b>library(ggplot2)
#create overlaying density plots
ggplot(data, aes(x=value, fill=variable)) +
  geom_density(alpha=.7)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/densityggplot2.png">
<h2><span class="orange">How to Fix: ggplot2 doesn’t know how to deal with data of class uneval</span></h2>
One error you may encounter in R is:
<b>Error: ggplot2 doesn't know how to deal with data of class uneval
</b>
This error usually occurs when you attempt to use <b>ggplot2</b> to plot two data frames at once, but fail to use the <b>data</b> argument within the <b>geom_line()</b> function.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we have two data frames in R that show the number of sales made during specific hours on various days:
<b>#create first data frame
df &lt;- data.frame(date=c(1, 1, 1, 2, 2, 2, 3, 3, 3), hour=c(1, 2, 3, 1, 2, 3, 1, 2, 3), sales=c(2, 5, 7, 5, 8, 12, 10, 14, 13))
#view data frame
head(df)
  date hour sales
1    1    1     2
2    1    2     5
3    1    3     7
4    2    1     5
5    2    2     8
6    2    3    12
#create second data frame
df_new &lt;- data.frame(date=c(4, 4, 4, 5, 5, 5),     hour=c(1, 2, 3, 1, 2, 3),     sales=c(12, 13, 19, 15, 18, 20))
#view data frame 
head(df_new)
  date hour sales
1    4    1    12
2    4    2    13
3    4    3    19
4    5    1    15
5    5    2    18
6    5    3    20</b>
Now suppose we attempt to create a line chart to visualize the sales grouped by day and hour, using the color blue for the first data frame and red for the second data frame:
<b>library(ggplot2)
#attempt to create line chart
ggplot(df, aes(x=hour, y=sales, group=date)) +
  geom_line(color='blue') +
  geom_line(df_new, aes(x=hour, y=sales, group=date), color='red')
Error: ggplot2 doesn't know how to deal with data of class uneval
</b>
We receive an error because we failed to use the <b>data</b> argument within the second <b>geom_line()</b> function.
<h2>How to Fix the Error</h2>
The way to fix this error is to simply type out data within the second <b>geom_line()</b> argument so that R knows which data frame we’re attempting to plot.
<b>library(ggplot2)
#create line chart
ggplot(df, aes(x=hour, y=sales, group=date)) +
  geom_line(color='blue') +
  geom_line(data=df_new, aes(x=hour, y=sales, group=date), color='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/class1.jpg"435">
Notice that we’re able to create the line chart successfully without any error this time.
<h2><span class="orange">How to Change Facet Axis Labels in ggplot2</span></h2>
You can use the <b>as_labeller()</b> function to change facet axis labels in ggplot2:
<b>ggplot(df, aes(x, y)) + 
  geom_point() +
  facet_wrap(.~group,
             strip.position = 'left', 
             labeller = as_labeller(c(A='new1', B='new2', C='new3', D='new4'))) +
  ylab(NULL) +
  theme(strip.background = element_blank(),
        strip.placement='outside')
</b>
This particular example replaces the following old labels:
A, B, C, D
with the following new labels:
new1, new2, new3, new4
The following example shows how to use this syntax in practice.
<h2>Example: Change Facet Axis Labels in ggplot2</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'), points=c(8, 14, 20, 22, 25, 29, 30, 31), assists=c(10, 5, 5, 3, 8, 6, 9, 12))
#view data frame
df
  team points assists
1    A      8      10
2    A     14       5
3    B     20       5
4    B     22       3
5    C     25       8
6    C     29       6
7    D     30       9
8    D     31      12</b>
The following code shows how to use <b>facet_wrap()</b> to create a grid that displays a scatterplot of assists vs. points for each team:
<b>library(ggplot2)
#create multiple scatter plots using facet_wrap
ggplot(df, aes(assists, points)) +
  geom_point() +
  facet_wrap(.~team, nrow=4)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/facet11.jpg"595">
Currently the facets have the following labels: A, B, C, D.
However, we can use the following code to change the labels to team A, team B, team C, and team D:
<b>library(ggplot2)
#create multiple scatter plots using facet_wrap with custom facet labels
ggplot(df, aes(assists, points)) + 
  geom_point() +
  facet_wrap(.~team, nrow=4,
             strip.position = 'left', 
             labeller = as_labeller(c(A='team A',                      B='team B',                      C='team C',                      D='team D'))) +
  ylab(NULL) +
  theme(strip.background = element_blank(),
        strip.placement='outside')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/facet12.jpg">
Notice that the facet labels have been changed to team A, team B, team C, and team D and they have been moved to the left side of the plot.
<b>Note</b>: The <b>strip.background</b> argument removes the grey background behind the facet labels and the <b>strip.placement</b> argument specifies that the labels should be placed outside of the axis ticks.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Change the Order of Facets in ggplot2 
 How to Change Font Size in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Change the Order of Facets in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to specify the order of facets in ggplot2:
<b>p +
  facet_grid(~factor(my_variable, levels=c('val1', 'val2', 'val3', ...)))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change Order of Facets in ggplot2</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'), points=c(8, 14, 20, 22, 25, 29, 30, 31), assists=c(10, 5, 5, 3, 8, 6, 9, 12))
#view data frame
df
  team points assists
1    A      8      10
2    A     14       5
3    B     20       5
4    B     22       3
5    C     25       8
6    C     29       6
7    D     30       9
8    D     31      12</b>
The following code shows how to use <b>facet_grid()</b> to create a grid that displays a scatterplot of assists vs. points for each team:
<b>library(ggplot2)
#create multiple scatter plots using facet_grid
ggplot(df, aes(assists, points)) +
  geom_point() +
  facet_grid(.~team)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/facet1.jpg"601">
By default, ggplot2 places the scatter plots in order based on which values appear first in the <b>team</b> variable in the data frame.
However, we can convert team to a factor variable and use the <b>levels</b> argument to specify the order that the teams should be placed in the plot:
<b>library(ggplot2)
#create multiple scatter plots using facet_grid with specific order
ggplot(df, aes(assists, points)) +
  geom_point() +
  facet_grid(~factor(team, levels=c('C', 'D', 'A', 'B')))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/facet2.jpg">
Notice that the scatter plots are now in order based on the order we specified within the <b>levels</b> argument: C, D, A, B.
The advantage of using this approach is that we don’t actually modify the underlying data.
Instead, we only change the levels within the <b>facet_grid()</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Change Font Size in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">The Complete Guide: How to Change Font Size in ggplot2</span></h2>
You can use the following syntax to change the font size of various elements in ggplot2:
<b>p + theme(text=element_text(size=20), #change font size of all text
        axis.text=element_text(size=20), #change font size of axis text
        axis.title=element_text(size=20), #change font size of axis titles
        plot.title=element_text(size=20), #change font size of plot title
        legend.text=element_text(size=20), #change font size of legend text
        legend.title=element_text(size=20)) #change font size of legend title   
</b>
The following examples show how to use this syntax with the following scatterplot in ggplot2:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6), y=c(6, 8, 14, 19, 22, 18), z=c('A', 'A', 'B', 'B', 'C', 'C'))
#create scatterplot
p &lt;- ggplot(df, aes(x=x, y=y, color=z)) +
       geom_point(size=3) +
         ggtitle("This is the Title")
p
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font1.png">
<h3>Example 1: Change Font Size of All Text</h3>
The following code shows how to change the font size of all text elements in the plot:
<b>p + theme(text=element_text(size=20))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font2.png">
<h3>Example 2: Change Font Size of Axis Text</h3>
The following code shows how to change the font size of just the axis text:
<b>p + theme(axis.text=element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font3.png">
<h3>Example 3: Change Font Size of Axis Titles</h3>
The following code shows how to change the font size of just the axis titles:
<b>p + theme(axis.title=element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font4.png">
<h3>Example 4: Change Font Size of Plot Title</h3>
The following code shows how to change the font size of just the plot title:
<b>p + theme(plot.title=element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font5.png">
<h3>Example 5: Change Font Size of Legend Text</h3>
The following code shows how to change the font size of just the legend text:
<b>p + theme(legend.text=element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font6.png">
<h3>Example 6: Change Font Size of Legend Title</h3>
The following code shows how to change the font size of just the legend title:
<b>p + theme(legend.title=element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/font7.png">
<h2><span class="orange">How to Group by Two Columns in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to group by two columns when creating a plot in ggplot2:
<b>ggplot(df, aes(x=var1, y=var2, color=var3, shape=var4,
       group=interaction(var3, var4))) + 
  geom_point() +
  geom_line()
</b>
This particular code produces a line plot where the points are grouped by the columns <b>var3</b> and <b>var4</b> in the data frame.
The following example shows how to use this syntax in practice.
<h2>Example: Group by Two Columns in ggplot2</h2>
Suppose we have the following data frame in R that shows the total sales during various weeks at two different stores when two different promotions were run:
<b>#create data frame
df &lt;- data.frame(store=rep(c('A', 'B'), each=8), promo=rep(c('Promo 1', 'Promo 2'), each=4, times=2), week=rep(c(1:4), times=4), sales=c(1, 2, 6, 7, 2, 3, 5, 6, 3, 4, 7, 8, 3, 5, 8, 9))
#view data frame
df
   store   promo week sales
1      A Promo 1    1     1
2      A Promo 1    2     2
3      A Promo 1    3     6
4      A Promo 1    4     7
5      A Promo 2    1     2
6      A Promo 2    2     3
7      A Promo 2    3     5
8      A Promo 2    4     6
9      B Promo 1    1     3
10     B Promo 1    2     4
11     B Promo 1    3     7
12     B Promo 1    4     8
13     B Promo 2    1     3
14     B Promo 2    2     5
15     B Promo 2    3     8
16     B Promo 2    4     9
</b>
We can use the following code to create a line chart in ggplot2 in which the data values are grouped by the <b>store</b> and <b>promo</b> columns:
<b>library(ggplot2)
#create line plot with values grouped by store and promo
ggplot(df, aes(x=week, y=sales, color=store, shape=promo,
               group=interaction(store, promo))) + 
  geom_point(size=3) +
  geom_line()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/grouptwo1.jpg">
The result is a line chart in which each line represents the sales values for each combination of <b>store</b> and <b>promo</b>.
In particular, the four lines represent the sales values for the following combinations:
Promo 1 at Store A
Promo 2 at Store A
Promo 1 at Store B
Promo 1 at Store B
The two legends on the side of the plot indicate which lines represents which combinations.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Set the Number of Bins for a Histogram in ggplot2</span></h2>
You can use the <b>bins</b> argument to specify the number of bins to use in a histogram in  ggplot2 :
<b>library(ggplot2)
ggplot(df, aes(x=x)) +
  geom_histogram(bins=10)
</b>
The following examples show how to use this argument in practice.
<h3>Example: Set Number of Bins for Histogram in ggplot2</h3>
The following code shows how to create a dataset in R that contains 10,000 random values that follow a  Poisson distribution  with a mean value of 2:
<b>#make this example reproducible
set.seed(0)
#create data frame with 10,000 random values that follow Poisson distribution
df &lt;- data.frame(values=rpois(n=10000, lambda=2))
#view first five rows of data frame
head(df)
  values
1      4
2      1
3      1
4      2
5      4
6      1
</b>
We can use the following code to create a histogram in ggplot2 to visualize the distribution of values in the data frame:
<b>library(ggplot2)
ggplot(df, aes(x=values)) +
  geom_histogram(fill='steelblue', col='black')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/binshist1.jpg"447">
By default, ggplot2 will automatically pick a certain number of bins to use in the histogram.
However, we can use the following syntax to specify that we want the histogram to use <b>10</b> bins:
<b>library(ggplot2)
ggplot(df, aes(x=values)) +
  geom_histogram(fill='steelblue', col='black', bins=10)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/binshist2.jpg"453">
Notice that the histogram now has exactly <b>10</b> bins.
Or we could use the following syntax to specify that we want the histogram to use <b>5</b> bins:
<b>library(ggplot2)
ggplot(df, aes(x=values)) +
  geom_histogram(fill='steelblue', col='black', bins=5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/binshist3.jpg"441">
Notice that the histogram now has exactly <b>5</b> bins.
You’ll find that <b>the fewer bins you use, the wider each bin will be.</b>
In general, if you use too few bins then the true underlying distribution of values will be hidden.
However, if you use too many bins then you may just be visualizing the noise in the data.
One way to find the optimal number of bins to use in a histogram is by using <b>Sturges’ Rule</b>. Read more about that rule  here .
<b>Note</b>: You can find the complete documentation for the <b>geom_histogram</b> function  here .
<h2><span class="orange">How to Add Labels to Histogram in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to add labels to a histogram in ggplot2:
<b>ggplot(data=df, aes(x=values_var)) + 
  geom_histogram(aes(fill=group_var), binwidth=1, color='black') +
  stat_bin(binwidth=1, geom='text', color='white', size=4,
           aes(label=..count.., group=group_var), position=position_stack(vjust=0.5))
</b>
This particular example adds a white label to display the count for each bin in each category of a histogram.
The following example show how to use this syntax in practice.
<h2>Example: Add Labels to Histogram in ggplot2</h2>
Suppose we have the following data frame in R that contains information about points scored by basketball players on three different teams:
<b>#make this example reproducible
set.seed(1)
#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=100), points=c(runif(100, 5, 10),          runif(100, 5, 10),          runif(100, 5, 10)))
#view head of data frame
head(df)
  team   points
1    A 6.327543
2    A 6.860619
3    A 7.864267
4    A 9.541039
5    A 6.008410
6    A 9.491948
</b>
We can use the following code to create a histogram that shows the points scored by players on each team with labels that show the count for each bin:
<b>library(ggplot2)
#create histogram with labels for each bin
ggplot(data=df, aes(x=points)) + 
  geom_histogram(aes(fill=team), binwidth=1, color='black') +
  stat_bin(binwidth=1, geom='text', color='white', size=4,
           aes(label=..count.., group=team), position=position_stack(vjust=0.5))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/labs1.jpg">
Notice that each bin has a label that displays the count of each bin.
Note that you can modify the values for <b>color</b> and <b>size</b> within the <b>stat_bin()</b> function to modify the color and size of the labels, respectively.
For example, we can use the following syntax to instead use black labels with increased font size:
<b>library(ggplot2)
#create histogram with labels for each bin
ggplot(data=df, aes(x=points)) + 
  geom_histogram(aes(fill=team), binwidth=1, color='black') +
  stat_bin(binwidth=1, geom='text', color='black', size=6,
           aes(label=..count.., group=team), position=position_stack(vjust=0.5))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/labs2.jpg"571">
The labels on each bin now use black text and have a larger font size.
Feel free to play around with the <b>color</b> and <b>size</b> arguments within the <b>stat_bin()</b> function to make the labels appear however you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Create Histograms by Group in ggplot2 
 How to Display Percentages on Histogram in ggplot2 
 How to Set the Number of Bins for a Histogram in ggplot2 
<h2><span class="orange">How to Display Percentages on Histogram in ggplot2</span></h2>
You can use the following basic syntax to display percentages on the y-axis of a histogram in ggplot2:
<b>library(ggplot2)
library(scales)
#create histogram with percentages
ggplot(data, aes(x = factor(team))) +  
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels=percent)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Basic Histogram with Percentages</h3>
The following code shows how to create a histogram for categorical variables with percentages displayed on the y-axis:
<b>library(ggplot2)
library(scales)
#define data frame
data &lt;- data.frame(team = c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'),   points = c(77, 79, 93, 85, 89, 99, 90, 80, 68, 91, 92))
#create histogram with percentages
ggplot(data, aes(x = factor(team))) +  
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels=percent)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/percent5.png">
<h3>Example 2: Histogram with Percentages (Remove Decimal Places)</h3>
You can use the <b>accuracy</b> argument to only display whole numbers as percentages on the y-axis as well:
<b>library(ggplot2)
library(scales)
#define data frame
data &lt;- data.frame(team = c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'),   points = c(77, 79, 93, 85, 89, 99, 90, 80, 68, 91, 92))
#create histogram with percentages
ggplot(data, aes(x = factor(team))) +  
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1L))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/percent4.png">
<h3>Example 3: Custom Histogram with Percentages</h3>
The following code shows how to create a histogram with percentages shown on the y-axis and a custom title, axis labels, and colors:
<b>library(ggplot2)
library(scales)
#define data frame
data &lt;- data.frame(team = c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'),   points = c(77, 79, 93, 85, 89, 99, 90, 80, 68, 91, 92))
#create histogram with percentages and custom aesthetics
ggplot(data, aes(x = factor(team))) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = 'lightblue') +
  scale_y_continuous(labels=percent) +
  labs(title = 'Breakdown by Team', x = 'Team', y = 'Percent of Total') +
  theme_minimal()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/percent6.png">
<b>Related:</b>  A Complete Guide to the Best ggplot2 Themes 
<h2><span class="orange">How to Add a Horizontal Line to a Plot Using ggplot2</span></h2>
You can quickly add horizontal lines to ggplot2 plots using the <b>geom_hline() </b>function, which uses the following syntax:
<b>geom_hline(yintercept, linetype, color, size)</b>
where:
<b>yintercept:</b> Location to add line on the y-intercept.
<b>linetype:</b> Line style. Default is ‘solid’ but you can specify ‘twodash’, ‘longdash’, ‘dotted’, ‘dotdash’, ‘dashed’, or ‘blank.’
<b>color:</b> Color of the line.
<b>size:</b> Width of the line.
The following examples show how to use this function in practice.
<h3>Add a Single Horizontal Line to a Plot</h3>
The following code shows how to add a single horizontal line to a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with horizontal line at y=20
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=20)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/horizgg1.png">
<h3>Add Multiple Horizontal Lines to Plots</h3>
The following code shows how to add multiple horizontal lines to a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with horizontal lines at y = 10, 20, 30
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=c(10, 20, 30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/horizgg2.png">
<h3>Customize Horizontal Lines</h3>
The following code shows how to customize horizontal lines on a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with customized horizontal lines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_hline(yintercept=c(20, 30), linetype='dashed', color=c('blue', 'red'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/horizgg3.png">
<h2><span class="orange">How to Jitter Points in ggplot2 (With Examples)</span></h2>
When creating a scatter plot, it can be helpful to <b>jitter</b> the points so that it’s easier to view points that may be overlapping.
The easiest way to jitter points in ggplot2 is to use <b>geom_jitter()</b>, which uses the following basic syntax:
<b>ggplot(df, aes(x=x, y=y)) + 
  geom_jitter()</b>
The following examples show how to use the <b>geom_jitter()</b> function in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(4, 4, 4, 4, 6, 6, 6, 6, 8, 8, 8, 8), y=c(3, 3, 3, 3, 7, 7, 7, 7, 9, 9, 9, 9))
#view data frame
df
   x y
1  4 3
2  4 3
3  4 3
4  4 3
5  6 7
6  6 7
7  6 7
8  6 7
9  8 9
10 8 9
11 8 9
12 8 9</b>
<h2>Example 1: Create Scatter Plot without Jitter</h2>
The following code shows how to create a scatter plot in ggplot2 without using any jitter:
<b>library(ggplot2)
#create scatter plot
ggplot(df, aes(x=x, y=y)) + 
  geom_point()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/jitter1.jpg"471">
The original data frame has 12 observations, but since several of the observations have the same x and y values it looks like there are only 3 observations in the scatter plot.
<h2>Example 2: Create Scatter Plot with Default Jitter</h2>
The following code shows how to create a scatter plot in ggplot2 with the default settings in <b>geom_jitter()</b>:
<b>library(ggplot2)
#create scatter plot with jittered points
ggplot(df, aes(x=x, y=y)) + 
  geom_jitter()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/jitter2.jpg">
Notice that each of the 12 observations are now visible in the scatter plot since we used <b>geom_jitter()</b> to add random noise to both the width and height of each point.
<h2>Example 3: Create Scatter Plot with Custom Jitter</h2>
The following code shows how to create a scatter plot in ggplot2 with custom values for the <b>width</b> and <b>height</b> arguments in <b>geom_jitter()</b>:
<b>library(ggplot2)
#create scatter plot with jittered points
ggplot(df, aes(x=x, y=y)) + 
  geom_jitter(width=0.2, height=0.2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/jitter3.jpg"468">
Notice that the points have been jittered, but are much less spread out than in the previous example.
The smaller the values that you use for the <b>width</b> and <b>height</b> arguments in <b>geom_jitter()</b>, the less spread out the points will be from their original positions.
Feel free to play around with the <b>width</b> and <b>height</b> arguments to jitter the points to whatever degree you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change Point Shape in ggplot2 
 How to Change the Legend Title in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Fix in R: could not find function “ggplot” 
<h2><span class="orange">How to Change Legend Labels in ggplot2 (With Examples)</span></h2>
You can use the following syntax to change the legend labels in ggplot2:
<b>p + scale_fill_discrete(labels=c('label1', 'label2', 'label3', ...))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change Legend Labels in ggplot2</h2>
Suppose we create the following grouped boxplot in ggplot2:
<b>library(ggplot2) 
#make this example reproducible
set.seed(1)
#create dataset
data &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=50),   program=rep(c('low', 'high'), each=25),   values=seq(1:150)+sample(1:100, 150, replace=TRUE))
#create grouped boxplots
p &lt;- ggplot(data, aes(x=team, y=values, fill=program)) + 
       geom_boxplot() 
#display grouped boxplots
p</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/labels1.png">
By default, the legend labels take on the following values for the <b>fill</b> variable:
high
low
However, suppose we’d like to change the legend labels to:
High Program
Low Program
We can use the following syntax to do so:
<b>#create grouped boxplots with custom legend labels
p &lt;- ggplot(data, aes(x=team, y=values, fill=program)) + 
       geom_boxplot() +
       scale_fill_discrete(labels=c('High Program', 'Low Program'))
#display grouped boxplots
p</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/labels2.png">
The legend now displays the labels that we specified.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Change the Legend Title in ggplot2 
 How to Change Legend Position in ggplot2 
 How to Change Legend Size in ggplot2 
 How to Remove a Legend in ggplot2 
<h2><span class="orange">How to Change Order of Items in ggplot2 Legend</span></h2>
You can use the following syntax to change the order of the items in a  ggplot2  legend:
<b>scale_fill_discrete(breaks=c('item4', 'item2', 'item1', 'item3', ...)
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Change Order of Items in ggplot2 Legend</h3>
Suppose we create the following plot in ggplot2 that displays multiple boxplots in one plot:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C'), points=c(6, 8, 13, 16, 10, 14, 19, 22, 14, 18, 24, 26))
#create multiple boxplots to visualize points scored by team
ggplot(data=df, aes(x=team, y=points, fill=team)) +
  geom_boxplot()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/orders1.png">
To change the order of the items in the legend, we can use the <b>scale_fill_discrete()</b> function as follows:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C'), points=c(6, 8, 13, 16, 10, 14, 19, 22, 14, 18, 24, 26))
#create multiple boxplots to visualize points scored by team
ggplot(data=df, aes(x=team, y=points, fill=team)) +
  geom_boxplot() +
  scale_fill_discrete(breaks=c('B', 'C', 'A'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/orders2.png">
Notice that the order of the items changed from: A, B, C to B, C, A.
We can also use the <b>labels</b> argument to change the specific labels used for the items in the legend:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C'), points=c(6, 8, 13, 16, 10, 14, 19, 22, 14, 18, 24, 26))
#create multiple boxplots to visualize points scored by team
ggplot(data=df, aes(x=team, y=points, fill=team)) +
  geom_boxplot() +
  scale_fill_discrete(breaks=c('B', 'C', 'A'),      labels=c('B Team', 'C Team', 'A Team'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/orders3.png">
Notice that the legend labels have changed.
<h2><span class="orange">How to Change Legend Position in ggplot2 (With Examples)</span></h2>
You can use the following syntax to specify the position of a ggplot2 legend:
<b>theme(legend.position = "right")
</b>
The following examples show how to use this syntax in practice with the built-in <b>iris</b> dataset in R.
<h3>Example: Place Legend On Outside of Plot</h3>
You can directly tell ggplot2 to place the legend on the “top”, “right”, “bottom” or “left” side of the plot. 
For example, here’s how to place the legend on the top of the plot:
<b>library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
       geom_point() +
       theme(legend.position = "top")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/ggplotLegendPosition1.png">
And here’s how to place the legend on the bottom of the plot:
<b>library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
       geom_point() +
       theme(legend.position = "bottom")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/ggplotLegendPosition2.png">
<h3>Example: Place Legend On Inside of Plot</h3>
You can also specify the exact (x, y) coordinates to place the legend on the inside of the plot.
For example, here’s how to place the legend inside the top right corner:
<b>library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
       geom_point() +
       theme(legend.position = c(.9, .9))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/ggplotLegendPosition3.png">
And here’s how to place the legend inside the bottom right corner:
<b>library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
       geom_point() +
       theme(legend.position = c(.9, .1))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/ggplotLegendPosition4.png">
<h3>Example: Remove Legend Completely</h3>
You can also remove the legend from a plot in ggplot2 entirely by specifying legend.position=”none” as follows:
<b>library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
       geom_point() +
       theme(legend.position = "none")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/ggplotLegendPosition5.png">
<h2><span class="orange">How to Change Spacing Between Legend Items in ggplot2</span></h2>
You can use the following methods to change the spacing between legend items in ggplot2:
<b>Method 1: Change Horizontal Spacing</b>
<b>p +
  theme(legend.spacing.x = unit(1, 'cm'))
</b>
<b>Method 2: Change Vertical Spacing</b>
<b>p +
  theme(legend.spacing.y = unit(1, 'cm')) +
  guides(fill = guide_legend(byrow = TRUE))</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Heat', 'Nets', 'Lakers', 'Suns', 'Cavs'), points=c(24, 20, 34, 39, 28, 29), assists=c(5, 7, 6, 9, 12, 13))
#view data frame
df
    team points assists
1   Mavs     24       5
2   Heat     20       7
3   Nets     34       6
4 Lakers     39       9
5   Suns     28      12
6   Cavs     29      13</b>
<h2>Example 1: Change Horizontal Spacing Between Legend Items</h2>
The following code shows how to create a scatter plot in ggplot2 with a horizontal legend with defaulting spacing:
<b>library(ggplot2)
#create scatterplot with default spacing in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3) +
  theme(legend.position='bottom')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/space1.jpg"498">
To increase the horizontal spacing between the items in the legend, we can use the <b>legend.spacing.x</b> argument:
<b>library(ggplot2)
#create scatterplot with increased horizontal spacing in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3) +
  theme(legend.position='bottom',
        legend.spacing.x = unit(1, 'cm'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/space2.jpg">
Notice that the horizontal spacing between the items in the legend has increased.
The larger the value you use in the <b>unit()</b> function, the greater the spacing will be between items.
<h2>Example 2: Change Vertical Spacing Between Legend Items</h2>
The following code shows how to create a scatter plot in ggplot2 with a vertical legend with defaulting spacing:
<b>library(ggplot2)
#create scatterplot with default spacing in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/space3.jpg"481">
To increase the vertical spacing between the items in the legend, we can use the <b>legend.spacing.y</b> argument:
<b>library(ggplot2)
#create scatterplot with increased vertical spacing in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3) +
  theme(legend.spacing.y = unit(1, 'cm')) +
  guides(fill = guide_legend(byrow = TRUE))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/space4.jpg">
Notice that the vertical spacing between the items in the legend has increased.
The larger the value you use in the <b>unit()</b> function, the greater the spacing will be between items.
<b>Note</b>: We must include the last line that uses the <b>byrow = TRUE</b> argument, otherwise the items in the legend will not be spaced as expected.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change the Legend Title in ggplot2 
 How to Change Legend Size in ggplot2 
 How to Change Legend Position in ggplot2 
<h2><span class="orange">How to Adjust Line Thickness in ggplot2</span></h2>
You can use the <b>size</b> argument to adjust the thickness of a line in  ggplot2 :
<b>ggplot(df, aes(x = x, y = y)) +
  geom_line(size = 1.5)
</b>
The size is equal to 1 by default, but you can specify any decimal value you’d like to adjust the thickness.
This tutorial provides an example of how to adjust line thickness in practice.
<h3>Example: Adjust Line Thickness in ggplot2</h3>
The following code shows how to create a simple line plot using ggplot2:
<b>#load ggplot2 visualization package
library(ggplot2)
#create data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7), y=c(6, 8, 12, 14, 11, 10, 15))
#create line plot
ggplot(df, aes(x = x, y = y)) +
  geom_line()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/lineThickness1.png">
By default, the line thickness is equal to 1 but we can increase it by using the <b>size</b> argument:
<b>library(ggplot2)
#create line plot
ggplot(df, aes(x = x, y = y)) +
  geom_line(size = 2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/lineThickness2.png">
The following code displays various line plots using different sizes for the line thickness:
<b>library(ggplot2)
library(gridExtra)
#create data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7), y=c(6, 8, 12, 14, 11, 10, 15))
#create four line plots
plot1 &lt;- ggplot(df, aes(x=x,y=y)) + geom_line() + ggtitle("Size = 1 (Default)")
plot2 &lt;- ggplot(df, aes(x=x,y=y)) + geom_line(size=1.5) + ggtitle("Size = 1.5")
plot3 &lt;- ggplot(df, aes(x=x,y=y)) + geom_line(size=2) + ggtitle("Size = 2")
plot4 &lt;- ggplot(df, aes(x=x,y=y)) + geom_line(size=3) + ggtitle("Size = 3")
#display all line plots stacked on top of each other
grid.arrange(plot1, plot2, plot3, plot4, ncol=1)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/lineThickness3.png">
The larger the value given to the <b>size</b> argument, the thicker the line will be in the plot.
Find more R tutorials  here .
<h2><span class="orange">How to Change Line Type in ggplot2</span></h2>
You can use the <b>linetype </b>argument to change the line type in a ggplot2 plot:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_line(linetype=1)</b>
The default value for linetype is <b>1</b> (a solid line), but you can specify any value between <b>0</b> to <b>6</b> where:
<b>0</b> = blank
<b>1</b> = solid
<b>2 </b>= dashed
<b>3</b> = dotted
<b>4</b> = dotdash
<b>5</b> = longdash
<b>6</b> = twodash
The following examples show how to modify the <b>linetype </b>argument in different ggplot2 plots.
<h2>Example 1: Create Plot with Default Line Type</h2>
The following code shows how to create a line plot in ggplot2 using the default line type (solid line):
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 8, 9), y=c(5, 8, 10, 14, 13, 19))
#create line plot
ggplot(df, aes(x=x, y=y)) +
  geom_line()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/linetype1.jpg"477">
Since we didn’t use the <b>linetype </b>argument at all, ggplot2 used the default line type of solid.
<h2>Example 2: Create Plot with Custom Line Type</h2>
The following code shows how to create a line plot in ggplot2 using dashed (linetype=2) for the line type:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 8, 9), y=c(5, 8, 10, 14, 13, 19))
#create line plot with custom line type
ggplot(df, aes(x=x, y=y)) +
  geom_line(linetype=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/linetype2.jpg"471">
<h2>Example 3: Create Plot with Line Type Based on Variable</h2>
The following code shows how to create a line plot in ggplot2 where the line type is based on the value of a particular variable in the data frame:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 10, 1, 10, 1, 10), y=c(5, 8, 10, 14, 13, 19), group=c('A', 'A', 'B', 'B', 'C', 'C'))
#create line plot
ggplot(df, aes(x=x, y=y, group=group)) +
  geom_line(aes(linetype=group, color=group), size=1.5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/linetype3.jpg"469">
Notice that the line type and color for each line is based on the value for the <b>group</b> variable.
Notice that ggplot2 also automatically produces a legend on the right side of the plot to show which line corresponds to which team.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change Point Shape in ggplot2 
 How to Change Point Size in ggplot2 
 How to Change Line Colors in ggplot2 
<h2><span class="orange">How to Create a Manual Legend in ggplot2 (With Examples)</span></h2>
Often you may want to add a manual legend to a plot in ggplot2 with custom colors, labels, title, etc.
Fortunately this is simple to do using the <b>scale_color_manual()</b> function and the following example shows how to do so.
<h3>Example: Create Manual Legend in ggplot2</h3>
The following code shows how to plot three fitted regression lines in a plot in ggplot2 with a custom manual legend:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 5, 6, 8, 8, 9, 9, 10, 11, 12, 15, 15), y=c(2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 16, 19, 28))
#create plot with three fitted regression models
ggplot(df, aes(x, y)) +
  geom_point() +
  geom_smooth(se=FALSE, aes(color='Linear')) +
  geom_smooth(formula=y~poly(x, 2), se=FALSE, aes(color='Quadratic')) +
  geom_smooth(formula=y~poly(x, 3), se=FALSE, aes(color='Cubic')) +
  scale_color_manual(name='Regression Model',     breaks=c('Linear', 'Quadratic', 'Cubic'),     values=c('Cubic'='pink', 'Quadratic'='blue', 'Linear'='purple'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/manual1.png">
Using the <b>scale_color_manual()</b> function, we were able to specify the following aspects of the legend:
<b>name</b>: The title of the legend
<b>breaks</b>: The labels in the legend
<b>values</b>: The colors in the legend
Note that we can also use the <b>theme()</b> function to modify the font size of the elements in the legend:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 5, 6, 8, 8, 9, 9, 10, 11, 12, 15, 15), y=c(2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 16, 19, 28))
#create plot with three fitted regression models
ggplot(df, aes(x, y)) +
  geom_point() +
  geom_smooth(se=FALSE, aes(color='Linear')) +
  geom_smooth(formula=y~poly(x, 2), se=FALSE, aes(color='Quadratic')) +
  geom_smooth(formula=y~poly(x, 3), se=FALSE, aes(color='Cubic')) +
  scale_color_manual(name='Regression Model',     breaks=c('Linear', 'Quadratic', 'Cubic'),     values=c('Cubic'='pink', 'Quadratic'='blue', 'Linear'='purple'))+
 theme(legend.title=element_text(size=20),
       legend.text=element_text(size=14))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/manual3.png">
Notice that the font size of both the title and the labels in the legend were increased.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change Legend Position in ggplot2 
 How to Change Legend Size in ggplot2 
 How to Change Legend Title in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Modify the Margins in ggplot2 (With Examples)</span></h2>
You can use the <b>theme()</b> argument in ggplot2 to change the margin areas of a plot:
<b>ggplot(df, aes(x=x)) + 
  geom_histogram() +
  theme(plot.margin=unit(c(5,1,1,1), 'cm'))
</b>
Keep in mind that the order for the plot margins is:
<b>unit(c(top, right, bottom, left), units)</b>
The following examples shows how change the margin areas of ggplot2 plots in practice.
<h3>Example 1: Create Basic Plot</h3>
The following code shows how to create a basic plot in ggplot2 without specifying any margin areas:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data
df &lt;- data.frame(x=rnorm(n=5000))
#create histogram using ggplot2
ggplot(df, aes(x=x)) + 
  geom_histogram() +
  ggtitle('Title of Histogram') +
  theme(plot.background=element_rect(fill='#e3fbff'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/unit1.png">
Notice how the plot has minimal margins on each side. 
<h3>Example 2: Modify Margins of the Plot</h3>
The following code shows how to add significant margins to the top and bottom of the plot:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data
df &lt;- data.frame(x=rnorm(n=5000))
#create histogram with significant margins on top and bottom
ggplot(df, aes(x=x)) + 
  geom_histogram() +
  ggtitle('Title of Histogram') +
  theme(plot.margin=unit(c(5,1,5,1), 'cm'),
        plot.background=element_rect(fill='#e3fbff'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/unit2.png">
Notice how there’s a significant amount of space on the top and bottom of the plot.
And the following code shows how to add significant margins to the left and right of the plot:
<b>library(ggplot2)
#make this example reproducible
set.seed(0)
#create data
df &lt;- data.frame(x=rnorm(n=5000))
#create histogram with significant margins on left and right
ggplot(df, aes(x=x)) + 
  geom_histogram() +
  ggtitle('Title of Histogram') +
  theme(plot.margin=unit(c(1,5,1,5), 'cm'),
        plot.background=element_rect(fill='#e3fbff'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/unit3.png">
Notice how there’s a significant amount of space on the left and right of the plot.
<h2><span class="orange">How to Create Plot in ggplot2 Using Multiple Data Frames</span></h2>
You can use the following basic syntax to create a plot in ggplot2 using multiple data frames:
<b>library(ggplot2)
ggplot() + 
  geom_line(data=df1, aes(x=x_var, y=y_var), color='blue') + 
  geom_line(data=df2, aes(x=x_var, y=y_var), color='red')
</b>
This particular example plots multiple lines in a single plot in ggplot2 using data from two different data frames.
By specifying the data frame names at the <b>geom()</b> level, we’re able to include data from multiple data frames in a single plot.
The following example shows how to use this syntax in practice.
<h2>Example: Create Plot in ggplot2 Using Multiple Data Frames</h2>
Suppose we have the following two data frames in R that contain information on the total sales made at two different stores on various days:
<b>#create first data frame
df1 &lt;- data.frame(day=1:8,  sales=c(6, 8, 9, 14, 13, 13, 7, 10))
df1
  day sales
1   1     6
2   2     8
3   3     9
4   4    14
5   5    13
6   6    13
7   7     7
8   8    10
#create second data frame
df2 &lt;- data.frame(day=1:8,  sales=c(2, 3, 3, 5, 7, 6, 5, 9))
df2
  day sales
1   1     2
2   2     3
3   3     3
4   4     5
5   5     7
6   6     6
7   7     5
8   8     9
</b>
We can use the following syntax to create a plot in ggplot2 that contains multiple lines to represent the sales from the stores in both data frames:
<b>library(ggplot2)
#create line plot using multiple data frames
ggplot() + 
  geom_line(data=df1, aes(x=day, y=sales), color='steelblue') + 
  geom_line(data=df2, aes(x=day, y=sales), color='coral2')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/mult11.jpg">
The blue line represents the values from the data frame called <b>df1</b> and the red line represents the values from the data frame called <b>df2</b>.
Note that this method also works with other <b>geom()</b> functions.
For example, we could create the following scatter plot to display the sales by store from each data frame:
<b>library(ggplot2)
#create scatter plot using multiple data frames
ggplot() + 
  geom_point(data=df1, aes(x=day, y=sales), color='steelblue') + 
  geom_point(data=df2, aes(x=day, y=sales), color='coral2')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/mult12.jpg"488">
The blue points represent the values from the data frame called <b>df1</b> and the red points represent the values from the data frame called <b>df2</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot Multiple Lines in ggplot2 
 How to Change Legend Labels in ggplot2 
 How to Change X-Axis Labels in ggplot2 
<h2><span class="orange">How to Order Items on x-axis in ggplot2</span></h2>
You can use the following basic syntax to order the items on the x-axis of a plot in ggplot2:
<b>ggplot(df, aes(x=factor(x_var, level=c('value1', 'value2', 'value3')), y=y_var)) +
  geom_col()
</b>
The following examples show how to use this syntax in practice.
<h2>Example: Order Items on x-axis in ggplot2</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball teams:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Heat', 'Nets', 'Lakers'), points=c(100, 122, 104, 109))
#view data frame
df
    team points
1   Mavs    100
2   Heat    122
3   Nets    104
4 Lakers    109
</b>
If we create a bar plot to visualize the points scored by each team, ggplot2 will automatically order the bars in alphabetical order:
<b>library(ggplot2)
#create bar plot
ggplot(df, aes(x=team, y=points)) +
  geom_col()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/order1.jpg"488">
To specify an order for the bars on the x-axis, we can use the <b>level</b> argument as follows:
<b>library(ggplot2)
#create bar plot with specific axis order
ggplot(df, aes(x=factor(team, level=c('Mavs', 'Heat', 'Nets', 'Lakers')), y=points)) +
  geom_col()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/order2.jpg"497">
The bars are now in the exact order that we specified inside the <b>level</b> argument.
You may also want to use <b>xlab()</b> to rename the x-axis to something that is easier to read:
<b>library(ggplot2)
#create bar plot with specific axis order
ggplot(df, aes(x=factor(team, level=c('Mavs', 'Heat', 'Nets', 'Lakers')), y=points)) +
  geom_col() +
  xlab('Team')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/order3.jpg"498">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Order Y-Axis Labels Alphabetically in ggplot2</span></h2>
You can use the following basic syntax to order the y-axis labels alphabetically in ggplot2:
<b>#sort y-axis variable in alphabetical order
df$y_var&lt;- factor(df$y_var, levels=rev(sort(df$y_var)))
#create scatter plot with y-axis in alphabetical order
ggplot(df, aes(x=x_var, y=y_var)) + 
  geom_point()
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Order Y-Axis Labels Alphabetically in ggplot2</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball teams:
<b>#create data frame
df &lt;- data.frame(team=c('B', 'D', 'E', 'F', 'A', 'C', 'H', 'G'), points=c(22, 12, 10, 30, 12, 17, 28, 23))
#view data frame
df
  team points
1    B     22
2    D     12
3    E     10
4    F     30
5    A     12
6    C     17
7    H     28
8    G     23
</b>
If we create a scatter plot with <b>points</b> on the x-axis and <b>team</b> on the y-axis, ggplot2 will automatically display the teams in alphabetical order (starting from the bottom):
<b>library(ggplot2)
#create scatter plot
ggplot(df, aes(x=points, y=team)) + 
  geom_point(size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/alpha1.jpg"475">
Notice that the labels on the y-axis are in alphabetical order from A to Z, starting from the bottom.
To arrange the y-axis labels in reverse alphabetical order, we can use the following code:
<b>library(ggplot2)
#sort y-axis variable in alphabetical order
df$team&lt;- factor(df$team, levels=rev(sort(df$team)))
#create scatter plot with y-axis in alphabetical order
ggplot(df, aes(x=points, y=team)) +
  geom_point()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/alpha2.jpg">
Notice that the labels on the y-axis are now in reverse alphabetical order, starting from the bottom.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Make Pie Charts in ggplot2 (With Examples)</span></h2>
A <b>pie chart</b> is a type of chart that is shaped like a circle and uses slices to represent proportions of a whole.
This tutorial explains how to create and modify pie charts in R using the  ggplot2  data visualization library.
<h3>How to Make a Basic Pie Chart</h3>
The following code shows how to create a basic pie chart for a dataset using ggplot2:
<b>library(ggplot2)
#create data frame
data &lt;- data.frame("category" = c('A', 'B', 'C', 'D'),   "amount" = c(25, 40, 27, 8))
#create pie chart
ggplot(data, aes(x="", y=amount, fill=category)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/pieGGplot2.png">
<h3>How to Modify the Appearance of the Pie Chart</h3>
The default pie chart in ggplot2 is quite ugly. The simplest way to improve the appearance is to use <b>theme_void()</b>, which removes the background, the grid, and the labels:
<b>ggplot(data, aes(x="", y=amount, fill=category)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  theme_void()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/pieGGplot3.png">
We can further improve the appearance of the chart by adding labels inside the slices:
<b>ggplot(data, aes(x="", y=amount, fill=category)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = paste0(amount, "%")), position = position_stack(vjust=0.5)) +
  labs(x = NULL, y = NULL, fill = NULL)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/pieGGplot4.png">
We can customize the chart even further by specifying our own hex colors to use for the slices with the <b>scale_fill_manual()</b> argument:
<b>ggplot(data, aes(x="", y=amount, fill=category)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = paste0(amount, "%")), position = position_stack(vjust=0.5)) +
  labs(x = NULL, y = NULL, fill = NULL) +
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()) +
  scale_fill_manual(values=c("#FF5733", "#75FF33", "#33DBFF", "#BD33FF"))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/pieGGplot5.png">
<em><b>Tip: </b>Use this  Hex Color Picker  to find combinations of hex color codes that go well together.</em>
You can also customize the colors of the slices by simply choosing one of the  brewer color scales . For example, here’s what the “blues” color scale looks like:
<b>ggplot(data, aes(x="", y=amount, fill=category)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = paste0(amount, "%")), position = position_stack(vjust=0.5)) +
  labs(x = NULL, y = NULL) +
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()) +
  scale_fill_brewer(palette="Blues")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/pieGGplot6.png">
<h2><span class="orange">How to Change Point Shape in ggplot2</span></h2>
You can use the <b>shape </b>argument to change the shape of points in a ggplot2 scatterplot:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point(shape=19)</b>
The default value for shape is <b>19</b> (a filled-in circle), but you can specify any value between <b>0</b> to <b>25.</b>
The following chart shows the shapes that correspond to each value:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=0:25, y=0:25)
#create scatter plot
ggplot(df, aes(x=x, y=y)) +
  geom_point(shape=0:25, size=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomshape1.jpg">
The following examples show how to modify the <b>shape</b> argument in different ggplot2 scatter plots.
<h2>Example 1: Create Plot with Default Shape</h2>
The following code shows how to create a scatter plot in ggplot2 using the default shape (filled-in circle) for the points: 
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=0:25, y=0:25)
#create scatter plot with default point shape
ggplot(df, aes(x=x, y=y)) +
  geom_point(size=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomshape2.jpg"471">
Since we didn’t use the <b>shape</b> argument to specify a point shape, ggplot2 used the default shape of a filled-in circle.
<h2>Example 2: Create Plot with Custom Shape</h2>
The following code shows how to create a scatter plot in ggplot2 using an empty triangle (shape=2) for the point shape:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=0:25, y=0:25)
#create scatter plot with custom point shape
ggplot(df, aes(x=x, y=y)) +
  geom_point(shape=2, size=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomshape3.jpg"479">
<h2>Example 3: Create Plot with Shape Based on Value</h2>
The following code shows how to create a scatter plot in ggplot2 where the shape of the points is based on the value of a particular variable in the data frame:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C'), points=c(8, 11, 13, 15, 19, 25), assists=c(4, 8, 7, 10, 11, 7))
#create scatter plot where point shape is based on team
ggplot(df, aes(x=points, y=assists, group=team)) +
  geom_point(aes(shape=team, color=team), size=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/geomshape4.jpg"479">Notice that the shape and color of the points in the plot are both based on the value for the <b>team</b> variable.
Notice that ggplot2 also automatically produces a legend on the right side of the plot to show which points correspond to which team.
<b>Note</b>: You can find the complete documentation for the <b>geom_point()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change the Legend Title in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Fix in R: could not find function “ggplot” 
<h2><span class="orange">How to Change Point Size in ggplot2 (3 Examples)</span></h2>
You can use the <b>size</b> argument to change the size of points in a ggplot2 scatterplot:
<b>some_ggplot +
  geom_point(size=1.5)</b>
The default size is <b>1.5</b> but you can decrease or increase this value to make the points smaller or larger.
The following examples show how to use each method in practice with the built-in  mtcars  dataset in R.
For reference, here’s what a ggplot2 scatterplot looks like using the default size:
<b>library(ggplot2)
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/geom1.jpg"566">
<h2>Example 1: Increase Point Size in ggplot2</h2>
The following code shows how to create a scatterplot in ggplot2 and increase the point size by using the <b>size</b> argument:
<b>library(ggplot2)
#create scatterplot with increased point size
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point(size=5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/pointsize1.jpg">
Notice that the points are much larger than the default size.
<h2>Example 2: Decrease Point Size in ggplot2</h2>
The following code shows how to create a scatterplot in ggplot2 and decrease the point size by using the <b>size</b> argument:
<b>library(ggplot2)
#create scatterplot with decreased point size
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point(size=0.5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/pointsize2.jpg">
Notice that the points are much smaller than the default size.
<h2>Example 3: Adjust Point Size Based on Variable</h2>
The following code shows how to create a scatterplot in ggplot2 and adjust each point size based on the value of another variable in the <b>mtcars</b> dataset called <b>qsec</b>:
<b>library(ggplot2)
#create scatterplot with point size based on value of qsec
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point(aes(size=qsec))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/pointsize3.jpg"571">
The size of each point is now dependent on the value of the <b>qsec</b> variable.
Notice that ggplot2 also automatically adds a legend on the right side of the plot to help you understand how the value of the <b>qsec</b> variable is mapped onto the size of each point.
<b>Note</b>: You can find the complete documentation for the <b>geom_point()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change Point Shape in ggplot2 
 How to Change the Legend Title in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Fix in R: could not find function “ggplot” 
<h2><span class="orange">How to Create a Q-Q Plot in ggplot2 (With Example)</span></h2>
A <b>Q-Q plot,</b> short for “quantile-quantile” plot, is used to assess whether or not a set of data potentially came from some theoretical distribution.
In most cases, this type of plot is used to determine whether or not a set of data follows a normal distribution.
If the data is normally distributed, the points in a Q-Q plot will lie on a straight diagonal line.
Conversely, if the points deviate significantly from the straight diagonal line, then it’s less likely that the data is normally distributed.
To create a Q-Q plot in ggplot2, you can use the<b> stat_qq()</b> and <b>stat_qq_line()</b> functions as follows:
<b>library(ggplot2)
ggplot(df, aes(sample=y)) +
  stat_qq() + 
  stat_qq_line()
</b>
The following examples show how to use this syntax to create a Q-Q plot in two different scenarios.
<h2>Example 1: Q-Q Plot for Normal Data</h2>
The following code shows how to generate a normally distributed dataset with 200  observations  and create a Q-Q plot for the dataset in R:
<b>library(ggplot2)
#make this example reproducible
set.seed(1)
#create some fake data that follows a normal distribution
df &lt;- data.frame(y=rnorm(200))
#create Q-Q plot
ggplot(df, aes(sample=y)) +
  stat_qq() + 
  stat_qq_line()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/qq1.jpg">
We can see that the points lie mostly along the straight diagonal line with some minor deviations along each of the tails.
Based on this plot, we would assume that this set of data is normally distributed.
Note that we could also use the color and size arguments to change the color and size of the points in the plot if we’d like to:
<b>library(ggplot2)
#make this example reproducible
set.seed(1)
#create some fake data that follows a normal distribution
df &lt;- data.frame(y=rnorm(200))
#create Q-Q plot
ggplot(df, aes(sample=y)) +
  stat_qq(size=2.5, color='red') + 
  stat_qq_line()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/qq2.jpg"549">
<h2>Example 2: Q-Q Plot for Non-Normal Data</h2>
The following code shows how to create a Q-Q plot for a dataset that follows an exponential distribution with 200 observations:
<b>#make this example reproducible
set.seed(1)
#create some fake data that follows an exponential distribution
df &lt;- data.frame(y=rexp(200, rate=3))
#create Q-Q plot
ggplot(df, aes(sample=y)) +
  stat_qq() + 
  stat_qq_line()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/qq3.jpg"544">
We can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.
This should make sense considering we specified that the data should follow an exponential distribution.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot Multiple Lines in ggplot2 
 How to Plot Mean and Standard Deviation in ggplot2 
 How to Change Line Colors in ggplot2 
<h2><span class="orange">How to Plot a Regression Line by Group with ggplot2</span></h2>
We can use the following syntax to plot a regression line by group using the R visualization package  ggplot2 :
<b>ggplot(df, aes(x = x_variable, y = y_variable, color = group_variable)) +
  geom_point() +
  geom_smooth(method = "lm", fill = NA)
</b>
This tutorial provides a quick example of how to use this function in practice.
<h3>Example: Plot Regression Lines by Group with ggplot2</h3>
Suppose we have the following dataset that shows the following three variables for 15 different students:
Number of hours studied
Exam score received
Study technique used (either A, B, or C)
<b>#create dataset
df &lt;- data.frame(hours=c(1, 2, 3, 3, 4, 1, 2, 2, 3, 4, 1, 2, 3, 4, 4), score=c(84, 86, 85, 87, 94, 74, 76, 75, 77, 79, 65, 67, 69, 72, 80), technique=rep(c('A', 'B', 'C'), each=5))
#view dataset
df
   hours score technique
1      1    84         A
2      2    86         A
3      3    85         A
4      3    87         A
5      4    94         A
6      1    74         B
7      2    76         B
8      2    75         B
9      3    77         B
10     4    79         B
11     1    65         C
12     2    67         C
13     3    69         C
14     4    72         C
15     4    80         C
</b>
The following code shows how to plot a regression line that captures the relationship between hours studied and exam score received for each of the three study techniques:
<b>#load ggplot2
library(ggplot2)
#create regression lines for all three groups
ggplot(df, aes(x = hours, y = score, color = technique)) +
  geom_point() +
  geom_smooth(method = "lm", fill = NA)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/regressionLineGroupR1.png">
Note that in <b>geom_smooth()</b> we used method = ‘lm” to specify a linear trend.
We could also use other smoothing methods like “glm”, “loess”, or “gam” to capture nonlinear trends in the data. You can find the full documentation for geom_smooth()  here .
Note that we could also use different shapes to display the exam scores for each of the three groups:
<b>ggplot(df, aes(x = hours, y = score, color = technique, shape = technique)) +
  geom_point() +
  geom_smooth(method = "lm", fill = NA)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/regressionLineGroupR2.png">
You can find more ggplot2 tutorials  here .
<h2><span class="orange">How to Remove Gridlines in ggplot2 (With Examples)</span></h2>
The easiest way to remove gridlines in ggplot2 is to use <b>theme_classic()</b>:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_classic()
</b>
Alternatively, you can use the following syntax to remove specific gridlines:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_bw() +
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank())</b>
The following examples show how to use both of these methods in practice.
<h3>Example 1: Remove Gridlines with theme_classic()</h3>
The following code shows how to remove gridlines from a ggplot2 plot using <b>theme_classic()</b>:
<b>library(ggplot2)
#define data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6), y=c(6, 8, 14, 19, 29, 31))
#create ggplot with no gridlines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_classic()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/removeGrid1.png">
<h3>Example 2: Remove Specific Gridlines</h3>
The following code shows how to remove gridlines from a ggplot2 plot using a bit more customization:
<b>library(ggplot2)
#define data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6), y=c(6, 8, 14, 19, 29, 31))
#create ggplot with no gridlines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_bw() +
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank())
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/removeGrid1.png">
This code allows you to remove specific gridlines. For example, we could use the following code to keep the major gridlines in the plot:
<b>library(ggplot2)
#define data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6), y=c(6, 8, 14, 19, 29, 31))
#create ggplot with no gridlines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_bw() +
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank())</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/removeGrid2.png">
Alternatively, we could use the following code to remove all gridlines but keep the panel border in the plot:
<b>library(ggplot2)
#define data
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6), y=c(6, 8, 14, 19, 29, 31))
#create ggplot with no gridlines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  theme_bw() +
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank())</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/removeGrid3.png">
<h2><span class="orange">How to Remove NAs from Plot in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to remove NA values from a plot in ggplot2:
<b>library(ggplot2)
ggplot(data=subset(df, !is.na(this_column)), aes(x=this_column)) +
  geom_bar()
</b>
This particular example creates a bar plot and removes any rows in the data frame where an NA value occurs in the column called <b>this_column</b>.
The following example shows how to use this syntax in practice.
<h2>Example: Remove NAs from Plot in ggplot2</h2>
Suppose we have the following data frame that contains information on the number of points scored by basketball players on various teams:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', NA, NA, 'B', 'B', 'B', 'B'), points=c(22, 29, 14, 8, 5, 12, 26, 36))
#view data frame
df
  team points
1    A     22
2    A     29
3 &lt;NA>     14
4 &lt;NA>      8
5    B      5
6    B     12
7    B     26
8    B     36</b>
Now suppose we attempt to create a bar plot in ggplot2 to visualize the number of occurrences of each team:
<b>library(ggplot2)
#create bar plot to visualize occurrences by team
ggplot(df, aes(x=team)) +
  geom_bar()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/removena1.jpg">
Notice that the plot automatically creates a bar to display the occurrences of NA values in the <b>team</b> column.
To remove this bar from the plot, we can use the <b>subset()</b> function to subset the data frame to only include rows where the value in the <b>team</b> column is not NA:
<b>library(ggplot2)
#create bar plot to visualize occurrences by team and remove NA
ggplot(data=subset(df, !is.na(team)), aes(x=team)) +
  geom_bar()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/removena2.jpg"453">
This bar plot still displays the number of occurrences for the values ‘A’ and ‘B’ in the <b>team</b> column but it no longer includes a bar to display the number of occurrences for NA values.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Remove Axis Labels in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Remove Gridlines in ggplot2 
<h2><span class="orange">How to Reorder Bars in a Stacked Bar Chart in ggplot2</span></h2>
You can use the following basic syntax to reorder the position of bars in a stacked bar chart in ggplot2:
<b>#specify order of bars (from top to bottom)
df$fill_var &lt;- factor(df$fill_var, levels=c('value1', 'value2', 'value3', ...))
#create stacked bar chart
ggplot(df, aes(x=x_var, y=y_var, fill=fill_var)) + 
    geom_bar(position='stack', stat='identity')
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Reorder Bars in Stacked Bar Chart in ggplot2</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), position=c('G', 'F', 'C', 'G', 'F', 'C', 'G', 'F', 'C'), points=c(22, 12, 10, 30, 12, 17, 28, 23, 20))
#view data frame
df
  team position points
1    A        G     22
2    A        F     12
3    A        C     10
4    B        G     30
5    B        F     12
6    B        C     17
7    C        G     28
8    C        F     23
9    C        C     20</b>
If we create a stacked bar chart to visualize the points scored by players on each team, ggplot2 will automatically stack the bars in alphabetical order:
<b>library(ggplot2)
#create stacked bar chart
ggplot(df, aes(x=team, y=points, fill=position)) + 
    geom_bar(position='stack', stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/reorder1.jpg"476">
Notice that each stacked bar displays the position (from top to bottom) in alphabetical order.
To reorder the bars in a specific way, we can convert the position variable to a factor and use the <b>levels</b> argument to specify the order that the bars should be in (from top to bottom) in the stacked bar chart:
<b>library(ggplot2)
#convert 'position' to factor and specify level order
df$position &lt;- factor(df$position, levels=c('F', 'G', 'C'))
#create stacked bar chart
ggplot(df, aes(x=team, y=points, fill=position)) + 
    geom_bar(position='stack', stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/reorder2.jpg"476">
The bars are now stacked (from top to bottom) in the exact order that we specified within the <b>levels</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Reverse Order of Axis in ggplot2 (With Examples)</span></h2>
You can use the <b>scale_y_reverse()</b> and <b>scale_x_reverse()</b> functions to quickly reverse the order of an axis in ggplot2.
These functions use the following basic syntax:
<b>ggplot(df, aes(x, y)) +
  geom_point() +
  scale_y_reverse()
</b>
You can also use the <b>limits</b> argument with these functions to specify new axis limits after reversing the axis:
<b>ggplot(df, aes(x, y)) +
  geom_point() +
  scale_y_reverse(limits=c(100, 50))</b>
The following example shows how to use these functions in practice.
<h2>Example: Reverse Order of Axis in ggplot2</h2>
The following code shows how to create a scatterplot in ggplot2 with a normal axis:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(hours=c(1, 2, 2, 3, 4, 6, 7, 7, 8, 9), score=c(76, 77, 75, 79, 84, 88, 85, 94, 95, 90))
#create scatter plot with normal y-axis
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/reverse1.jpg"501">
Notice that the y-axis currently ranges from 75 to 95.
The following code shows how to use the <b>scale_y_reverse()</b> function to reverse the order of values on the y-axis:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(hours=c(1, 2, 2, 3, 4, 6, 7, 7, 8, 9), score=c(76, 77, 75, 79, 84, 88, 85, 94, 95, 90))
#create scatter plot with reversed y-axis
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2) +
  scale_y_reverse()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/reverse2.jpg"507">
Notice that the y-axis now ranges from 95 to 75.
We could also use the <b>limits</b> argument within the <b>scale_y_reverse()</b> function to modify the y-axis limits:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(hours=c(1, 2, 2, 3, 4, 6, 7, 7, 8, 9), score=c(76, 77, 75, 79, 84, 88, 85, 94, 95, 90))
#create scatter plot with reversed y-axis and modified limits
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2) +
  scale_y_reverse(limits=c(100, 50))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/reverse3.jpg"504">
Notice that the y-axis now ranges from 100 to 50.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Set Axis Breaks in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Create Smooth Lines in ggplot2 (With Examples)</span></h2>
You can plot a smooth line in ggplot2 by using the  geom_smooth()  function, which uses the following basic syntax:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_smooth()
</b>
This tutorial shows several examples of how to use this function in practice.
<h3>Example: Create Smooth Lines in ggplot2</h3>
Suppose we have the following data frame:
<b>df &lt;- data.frame(x=c(1, 2, 4, 5, 7, 9, 13, 14, 15, 17, 18, 20), y=c(34, 35, 36, 23, 37, 38, 49, 45, 48, 51, 53, 55))</b>
We can use the following code to create a  scatterplot  of the values in the data frame and add a smooth line to capture the trend:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_smooth()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/smoothR1.png">
By default, the geom_smooth() function uses a <b>loess</b> method to fit the line to the dataset, but we can specify a different method such as <b>lm</b> to fit a straight line to the dataset instead:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_smooth(method='lm')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/smoothR2.png">
We can also hide the standard error bands by specifying <b>se=FALSE</b>:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/smoothR3.png">
You can also quickly change the size and color of the line by using the <b>size</b> and <b>col</b> arguments:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE, col='red', size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/smoothR4.png">
You can find the complete documentation for the geom_smooth() function  here .
<h2><span class="orange">When to Use stat=”identity” in ggplot2 Plots</span></h2>
There are two common ways to use the <b>geom_bar()</b> function in ggplot2 to create bar charts:
<b>Method 1: Use geom_bar()</b>
<b>ggplot(df, aes(x)) +
  geom_bar()
</b>
By default, <b>geom_bar()</b> will simply count the occurrences of each unique value for the x variable and use bars to display the counts.
<b>Method 2: Use geom_bar(stat=”identity”)</b>
<b>ggplot(df, aes(x, y)) +
  geom_bar(stat="identity")</b>
If you provide the argument <b>stat=”identity”</b> to <b>geom_bar()</b> then you’re telling R to calculate the sum of the y variable, grouped by the x variable and use bars to display the sums.
The following examples illustrate the difference between these two methods using the following data frame in R that shows the points scored by basketball players on various teams:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=4), points=c(3, 5, 5, 6, 5, 7, 7, 8, 9, 9, 9, 8))
#view data frame
df
   team points
1     A      3
2     A      5
3     A      5
4     A      6
5     B      5
6     B      7
7     B      7
8     B      8
9     C      9
10    C      9
11    C      9
12    C      8
</b>
<h2>Example 1: Using geom_bar()</h2>
The following code shows how to use the <b>geom_bar()</b> function to create a bar chart that displays the count of each unique value in the <b>team</b> column:
<b>library(ggplot2)
#create bar chart to visualize occurrence of each unique value in team column
ggplot(df, aes(team)) +
  geom_bar()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/bar10.jpg"583">
The x-axis displays the unique values in the <b>team</b> column and the y-axis displays the number of times each unique value occurred.
Since each unique value occurred 4 times, the height of each bar is 4 in the plot.
<h2>Example 2: Using geom_bar(stat=”identity”)</h2>
The following code shows how to use the <b>geom_bar()</b> function with the <b>stat=”identity”</b> argument to create a bar chart that displays the sum of values in the <b>points</b> column, grouped by <b>team</b>:
<b>library(ggplot2)
#create bar chart to visualize sum of points, grouped by team
ggplot(df, aes(team, points)) +
  geom_bar(stat="identity")
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/bar11.jpg" alt='geom_bar with stat="identity" in ggplot2'>
The x-axis displays the unique values in the <b>team</b> column and the y-axis displays the sum of the values in the <b>points</b> column for each team.
For example:
The sum of points for team <b>A</b> is 19.
The sum of points for team <b>B</b> is 27.
The sum of points for team <b>C</b> is 35.
By using <b>stat=”identity”</b> in the<b> geom_bar()</b> function, we’re able to display the sum of values for a particular variable in our data frame instead of counts.
<b>Note</b>: For <b>stat=”identity”</b> to work properly, you must provide both an x variable and a y variable in the <b>aes()</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Adjust Space Between Bars in ggplot2 
 How to Remove NAs from Plot in ggplot2 
 How to Change Colors of Bars in Stacked Bart Chart in ggplot2 
<h2><span class="orange">How to Add Subtitle in ggplot2 (3 Examples)</span></h2>
You can use the following methods to add a subtitle to plots in ggplot2:
<b>Method 1: Add Subtitle</b>
<b>p +
  labs(title='My Title', subtitle='My Subtitle')
</b>
<b>Method 2: Add Multi-line Subtitle</b>
<b>p +
  labs(title='My Title', subtitle='My Subtitle Line1\nLine2\nLine3')</b>
<b>Method 3: Add Subtitle with Custom Font</b>
<b>p +
  labs(title='My Title', subtitle='My Subtitle Line1\nLine2\nLine3') +
  theme(plot.subtitle=element_text(size=18, face='italic', color='red'))</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(hours=c(1, 2, 2, 3, 4, 6, 7, 7, 8, 9), score=c(76, 77, 75, 79, 84, 88, 85, 94, 95, 90))
#view data frame
df
   hours score
1      1    76
2      2    77
3      2    75
4      3    79
5      4    84
6      6    88
7      7    85
8      7    94
9      8    95
10     9    90
</b>
<h2>Example 1: Add Subtitle in ggplot2</h2>
The following code shows how to add a one-line subtitle to a scatterplot in ggplot2:
<b>library(ggplot2)
#create scatter plot with subtitle on one line
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2) +
  labs(title='Hours Studied vs. Exam Score',
       subtitle='Data Collected in 2022')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/subtitle1.jpg"513">
Notice that a one-line subtitle has been added directly below the plot title.
<h2>Example 2: Add Multi-Line Subtitle in ggplot2</h2>
The following code shows how to add a multi-line subtitle to a scatterplot in ggplot2:
<b>library(ggplot2)
#create scatter plot with subtitle on multiple lines
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2) +
  labs(title='Hours Studied vs. Exam Score',
       subtitle='Data Collected in 2022\nUniversity A Exam Scores')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/subtitle2.jpg">
By using the line break syntax ( <b>\n</b> ) we are able to create a multi-line subtitle.
<h2>Example 3: Add Subtitle with Custom Font</h2>
The following code shows how to use the <b>theme()</b> function in ggplot2 to add a subtitle with a custom font size, style, and color:
<b>library(ggplot2)
#create scatter plot with subtitle that has customized font
ggplot(df, aes(x=hours, y=score)) +
  geom_point(size=2) +
  labs(title='Hours Studied vs. Exam Score',
       subtitle='Data Collected in 2022\nUniversity A Exam Scores') +
  theme(plot.subtitle=element_text(size=18, face='italic', color='red'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/subtitle3.jpg">
Notice that the subtitle now has a font size of 18, an italic style, and a red color.
<b>Note</b>: You can also use <b>face=’bold’</b> to use a bold font style.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Add Caption to ggplot2 Plots 
 How to Change Font Size in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Add Tables to Plots in ggplot2 (2 Examples)</span></h2>
Often you may want to add tables to plots made in ggplot2 in R so that readers can view the raw data along with the plot.
Fortunately it’s easy to add tables to plots using the ggpmisc package:
<b>install.packages('ggpmisc')
library(ggpmisc)</b>
The following examples show how to use this package to add a table to a barplot and a scatterplot using the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'F', 'G', 'G', 'F', 'F'), points=c(13, 23, 24, 20, 19, 14, 29, 31))
#view data frame
df
  team position points
1    A        G     13
2    A        G     23
3    A        F     24
4    A        F     20
5    B        G     19
6    B        G     14
7    B        F     29
8    B        F     31</b>
<h3>Example 1: Add Table to Barplot in ggplot2</h3>
We can use the following code to created a grouped barplot in ggplot2 and add a table to the bottom right corner of the plot to shows the actual values from the data frame:
<b><b>library(ggplo2)
library(ggpmisc)</b>
#create barplot with table
ggplot(df, aes(x=team, y=points, fill=position)) + 
    geom_bar(position='dodge', stat='identity') +
    annotate(geom = 'table',
           x=4,
           y=0,
           label=list(df))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/tableggplot1.jpg">
If you’re working with a large dataset and you don’t want to display each individual row, you can use the <b>table()</b> function to summarize the data before creating the table in ggplot2:
<b>library(ggplot2)
<b>library(ggpmisc)
</b>
#summarize frequencies of team and points in table
my_table &lt;- as.data.frame(table(df[ , c(1, 3)]))
#create barplot with table
ggplot(df, aes(x=team, y=points, fill=position)) + 
    geom_bar(position='dodge', stat='identity') +
    annotate(geom = 'table',
           x=4,
           y=0,
           label=list(my_table))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/tableggplot2.jpg"415">
<h3>Example 2: Add Table to Scatterplot in ggplot2</h3>
We can use the following code to created a scatterplot in ggplot2 and add a table to the bottom right corner of the plot to shows the actual values from the data frame:
<b><b>library(ggplo2)
library(ggpmisc)</b>
#create scatterplot with table
ggplot(df, aes(x=team, y=points)) + 
    geom_point(aes(color=position)) +
    annotate(geom='table',
           x=4,
           y=0,
           label=list(df))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/tableggplot3.jpg"476">
<b>Note</b>: Feel free to play around with the <b>x</b> and <b>y</b> values within the <b>annotate()</b> function to place the table in the exact location that you’d like.
<h2><span class="orange">How to Change Title Position in ggplot2 (With Examples)</span></h2>
By default, the title of plots in  ggplot2  are left-aligned.
However, you can use the following methods to change the title position:
<b>Method 1: Center the Title</b>
<b>some_ggplot +
  theme(plot.title = element_text(hjust = 0.5))</b>
<b>Method 2: Right-Align the Title</b>
<b>some_ggplot +
  theme(plot.title = element_text(hjust = 1))</b>
<b>Method 3: Adjust Title Position Vertically</b>
<b>some_ggplot +
  theme(plot.title = element_text(vjust = 10))</b>
The following examples show how to use each method in practice with the built-in  mtcars  dataset in R.
<h3>Example 1: Center the Title</h3>
The following code shows how to create a scatterplot in ggplot2 and center the title using the <b>hjust</b> argument:
<b>library(ggplot2)
#create scatterplot with centered title
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  ggtitle("Plot Title") +
  theme(plot.title = element_text(hjust = 0.5))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/ggposition1.jpg">
Notice that the title is aligned in the center.
<h3>Example 2: Right-Align the Title</h3>
The following code shows how to create a scatterplot in ggplot2 and right-align the title using the <b>hjust</b> argument:
<b>library(ggplot2)
#create scatterplot with right-aligned title
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  ggtitle("Plot Title") +
  theme(plot.title = element_text(hjust = 1))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/ggposition2.jpg">
Notice that the title is aligned to the right.
<h3>Example 3: Adjust Title Position Vertically</h3>
The following code shows how to create a scatterplot in ggplot2 and move the title higher up using the <b>vjust</b> argument:
<b>library(ggplot2)
#create scatterplot with title moved higher up
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  ggtitle("Plot Title") +
  theme(plot.title = element_text(hjust = 1, vjust = 3))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/ggposition3.jpg"603">
Notice that the title is moved higher up.
You can also provide a negative value to the <b>vjust</b> argument to move the title lower down:
<b>library(ggplot2)
#create scatterplot with title moved down
ggplot(data=mtcars, aes(x=mpg, y=wt)) +
  geom_point() +
  ggtitle("Plot Title") +
  theme(plot.title = element_text(hjust = 1, vjust = -10))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/ggposition4.jpg"598">
Notice that the title is now moved inside the plot.
<h2><span class="orange">How to Use a Transparent Background in ggplot2</span></h2>
You can use the following syntax to create a transparent background in a plot in ggplot2:
<b>p +
  theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )
</b>
If you decide to export the plot using <b>ggsave()</b>, be sure to specify that the background should be transparent:
<b>ggsave('<span>myplot.png', p, <span>bg='<span>transparent')
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Use a Transparent Background in ggplot2</h3>
The following code shows how to create a simple grouped boxplot in ggplot2:
<b>library(ggplot2) 
#make this example reproducible
set.seed(1)
#create dataset
data &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=50),   program=rep(c('low', 'high'), each=25),   values=seq(1:150)+sample(1:100, 150, replace=TRUE))
#create boxplot
ggplot(data, aes(x=team, y=values, fill=program)) + 
  geom_boxplot()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/transp1.png">
We can use the following code to create a transparent background for the plot:
<b>library(ggplot2) 
#make this example reproducible
set.seed(1)
#create dataset
data &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=50),   program=rep(c('low', 'high'), each=25),   values=seq(1:150)+sample(1:100, 150, replace=TRUE))
#create boxplot
p &lt;- ggplot(data, aes(x=team, y=values, fill=program)) + 
       geom_boxplot() +
       theme(
         panel.background = element_rect(fill='transparent'),
         plot.background = element_rect(fill='transparent', color=NA),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         legend.background = element_rect(fill='transparent'),
         legend.box.background = element_rect(fill='transparent')
       )
#display boxplot
p</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/transp2.png">
We can then export this plot to a PNG file, specifying that the background should be transparent in the exported image:
<b>ggsave('<span>grouped_boxplot.png', p, <span>bg='<span>transparent')</b>
If I open this exported file on my computer, I can see that the background is indeed transparent:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/transp3.png">
<h2><span class="orange">How to Draw a Trend Line in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to draw a trend line on a plot in ggplot2:
<b>ggplot(df, aes(x=xvar, y=yvar)) +
    geom_point() +
    geom_smooth(method=lm) #add linear trend line
</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 3, 3, 5, 7, 9), y=c(8, 14, 18, 25, 29, 33, 25))
#view data frame
df
  x  y
1 1  8
2 2 14
3 3 18
4 3 25
5 5 29
6 7 33
7 9 25</b>
<h3>Example 1: Add Linear Trend Line</h3>
The following code shows how to add a linear trend line to a scatterplot in ggplot2:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_smooth(method=lm) #add linear trend line</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/trend1.png">
<h3>Example 2: Add Linear Trend Line & Specify Confidence Region</h3>
We can use the <b>level</b> argument to specify the confidence level to use for the shaded confidence region in the plot:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_smooth(method=lm, level=0.99)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/trend4.png">
Note that the default confidence level is 0.95. By specifying a confidence level of 0.99, our shaded confidence region on the plot became even wider.
<h3>Example 3: Add Linear Trend Line & No Confidence Region</h3>
We can use the <b>se=FALSE</b> argument to hide the shaded confidence region around the trend line:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_smooth(method=lm, se=FALSE, col='red', size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/trend2.png">
<h3>Example 4: Add Curved Trend Line</h3>
If we don’t specify a method to use for <b>geom_smooth()</b>, a curved loess line will be used by default:
<b>library(ggplot2)
ggplot(df, aes(x=x, y=y)) +
    geom_point() +
    geom_smooth()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/trend3.png">
You can find the complete online documentation for the <b>geom_smooth()</b> function  here .
<h2><span class="orange">How to Plot Two Lines in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to plot two lines in one graph using  ggplot2 :
<b>ggplot(df, aes(x = x_variable)) + 
  geom_line(aes(y = line1, color = 'line1')) + 
  geom_line(aes(y = line2, color = 'line2'))
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Basic Plot with Two Lines in ggplot2</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(day = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales = c(8, 8, 7, 6, 7, 8, 9, 12, 14, 18), customers = c(4, 6, 6, 4, 6, 7, 8, 9, 12, 13))
#view first six rows of data frame
head(df)
  day sales customers
1   1     8         4
2   2     8         6
3   3     7         6
4   4     6         4
5   5     7         6
6   6     8         7  </b>
The following code shows how to create a basic plot in ggplot2 with two lines to represent the total sales and customers during this 10-day period:
<b>library(ggplot2)
#create plot with two lines
ggplot(df, aes(x = day)) + 
  geom_line(aes(y = sales, color = 'sales')) + 
  geom_line(aes(y = customers, color = 'customers'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/twoLines1.png">
The x-axis displays the day and the y-axis displays the values for the sales and the customers each day.
<h3>Example 2: Custom Plot with Two Lines in ggplot2</h3>
The following code shows how to create the same plot as the previous example with a custom title, labels, colors, line thickness, and theme:
<b>library(ggplot2)
ggplot(df, aes(x = day)) + 
  geom_line(aes(y = sales, color = 'sales'), lwd=2) + 
  geom_line(aes(y = customers, color = 'customers'), lwd=2) +
  scale_color_manual('Metric', values=c('red', 'steelblue')) +
  labs(title = 'Sales & Customers by Day', x = 'Day', y = 'Amount') +
  theme_minimal()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/twoLines2.png">
Note that we chose to use <b>theme_minimal()</b> for this plot, but there are a variety of themes you can use for your plot. Refer to  this guide  for a complete list of ggplot2 themes.
<h2><span class="orange">How to Create a Violin Plot in ggplot2 (With Examples)</span></h2>
You can use the following methods to create a violin plot in ggplot2:
<b>Method 1: Create Violin Plots by Group</b>
<b>ggplot(df, aes(x=group_var, y=values_var, fill=group_var)) + 
  geom_violin() +
</b>
<b>Method 2: Create Horizontal Violin Plots by Group</b>
<b>ggplot(df, aes(x=group_var, y=values_var, fill=group_var)) + 
  geom_violin() +
  coord_flip()
</b>
<b>Method 3: Create Violin Plots by Group and Display Median Value</b>
<b>ggplot(df, aes(x=group_var, y=values_var, fill=group_var)) + 
  geom_violin() +
  stat_summary(fun=median, geom='point', size=2)</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#make this example reproducible
set.seed(1)
#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=100), points=c(rnorm(100, mean=10),          rnorm(100, mean=15),          rnorm(100, mean=20)))
#view head of data frame
head(df)
  team    points
1    A  9.373546
2    A 10.183643
3    A  9.164371
4    A 11.595281
5    A 10.329508
6    A  9.179532</b>
<b>Note</b>: We used the  set.seed()  function to ensure that this example is reproducible.
<h2>Example 1: Create Violin Plots by Group</h2>
We can use the following syntax to create violin plots that show the distribution of the <b>points</b> variable, grouped by the <b>team</b> variable:
<b>library(ggplot2)
#create violin plot to visualize distribution of points by team
ggplot(df, aes(x=team, y=points, fill=team)) + 
  geom_violin() 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/violin1.jpg"523">
The x-axis displays each team and the y-axis displays the distribution of points scored by each team.
<h2>Example 2: Create Violin Plots by Group</h2>
To create horizontal violin plots that show the distribution of the <b>points</b> variable, grouped by the <b>team</b> variable, simply add the <b>coord_flip()</b> function:
<b>library(ggplot2)
#create horizontal violin plots to visualize distribution of points by team
ggplot(df, aes(x=team, y=points, fill=team)) + 
  geom_violin() +
  coord_flip()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/violin2.jpg">
The y-axis displays each team and the x-axis displays the distribution of points scored by each team.
<h2>Example 3: Create Violin Plots by Group and Display Median Value</h2>
The following code shows how to create violin plots that show the distribution of the <b>points</b> variable, grouped by the <b>team</b> variable, with the median points value represented as a circle:
<b>library(ggplot2)
#create violin plots and display median points value as circle
ggplot(df, aes(x=team, y=points, fill=team)) + 
  geom_violin() +
  stat_summary(fun=median, geom='point', size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/violin3.jpg">
The median points value for each team is represented as a tiny circle inside each violin plot.
<b>Note</b>: To increase the size of the circle, simply increase the value for the <b>size</b> argument within the <b>stat_summary()</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Change Font Size in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Create a Barplot in ggplot2 with Multiple Variables</span></h2>
A <b>barplot</b> is useful for visualizing the quantities of different categorical variables.
Sometimes we want to create a barplot that visualizes the quantities of categorical variables that are split into subgroups.
For example, we may want to visualize the total popcorn and soda sales for three different sports stadiums. This tutorial provides a step-by-step example of how to create the following barplot with multiple variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/barMultiple2.png">
<h3>Step 1: Create the Data</h3>
First, let’s create a data frame to hold our data:
<b>#create data
df &lt;- data.frame(stadium=rep(c('A', 'B', 'C'), each=4), food=rep(c('popcorn', 'soda'), times=6), sales=c(4, 5, 6, 8, 9, 12, 7, 9, 9, 11, 14, 13))
#view data
df
   stadium    food sales
1        A popcorn     4
2        A    soda     5
3        A popcorn     6
4        A    soda     8
5        B popcorn     9
6        B    soda    12
7        B popcorn     7
8        B    soda     9
9        C popcorn     9
10       C    soda    11
11       C popcorn    14
12       C    soda    13</b>
<h3>Step 2: Create the Barplot with Multiple Variables</h3>
The following code shows how to create the barplot with multiple variables using the <b>geom_bar()</b> function to create the bars and the <b>‘dodge’</b> argument to specify that the bars within each group should “dodge” each other and be displayed side by side.
<b>ggplot(df, aes(fill=food, y=sales, x=stadium)) +
  geom_bar(position='dodge', stat='identity')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/barMultiple1.png">
The various stadiums – A, B, and C – are displayed along the x-axis and the corresponding popcorn and soda sales (in thousands) are displayed along the y-axis.
<h3>Step 3: Modify the Aesthetics of the Barplot</h3>
The following code shows how to add a title, modify the axes labels, and customize the colors on the barplot:
<b>ggplot(df, aes(fill=food, y=sales, x=stadium)) +
  geom_bar(position='dodge', stat='identity') +
  ggtitle('Sales by Stadium') +
  xlab('Stadium') +
  ylab('Sales (in thousands)') +
  scale_fill_manual('Product', values=c('coral2','steelblue'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/barMultiple2.png">
<h2><span class="orange">How to Adjust Line Thickness in Boxplots in ggplot2</span></h2>
You can use the following methods to adjust the thickness of the lines in a boxplot in ggplot2:
<b>Method 1: Adjust Thickness of All Lines</b>
<b>ggplot(df, aes(x=x, y=y)) + 
  geom_boxplot(lwd=2)
</b>
<b>Method 2: Adjust Thickness of Median Line Only</b>
<b>ggplot(df, aes(x=x, y=y)) + 
  geom_boxplot(fatten=4)</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#make this example reproducible
set.seed(1)
#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=100), points=c(rnorm(100, mean=10),          rnorm(100, mean=15),          rnorm(100, mean=20)))
#view head of data frame
head(df)
  team    points
1    A  9.373546
2    A 10.183643
3    A  9.164371
4    A 11.595281
5    A 10.329508
6    A  9.179532
</b>
<b>Note</b>: We used the  set.seed()  function to ensure that this example is reproducible.
<h2>Example 1: Create Boxplot with Default Line Thickness</h2>
The following code shows how to create a boxplot to visualize the distribution of <b>points</b> grouped by <b>team</b>, using the default line thickness:
<b>library(ggplot2)
#create box plots to visualize distribution of points by team
ggplot(df, aes(x=team, y=points)) + 
  geom_boxplot()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/width11.jpg"543">
<h2>Example 2: Create Boxplot with Increased Line Thickness</h2>
The following code shows how to create a boxplot to visualize the distribution of <b>points</b> grouped by <b>team</b>, using the <b>lwd</b> argument to increase the thickness of all lines in the boxplot:
<b>library(ggplot2)
#create box plots with increased line thickness
ggplot(df, aes(x=team, y=points)) + 
  geom_boxplot(lwd=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/width12.jpg">
Notice that the thickness of each of the lines in each boxplot has increased.
<h2>Example 3: Create Boxplot with Increased Line Thickness of Median Line Only</h2>
The following code shows how to create a boxplot to visualize the distribution of <b>points</b> grouped by <b>team</b>, using the <b>fatten </b>argument to increase the thickness of the median line in each boxplot:
<b>library(ggplot2)
#create box plots with increased median line thickness
ggplot(df, aes(x=team, y=points)) + 
  geom_boxplot(fatten=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/width13.jpg">
Notice that only the thickness of the median line in each boxplot has increased.
Feel free to play around with both the <b>lwd</b> and <b>fatten</b> arguments in <b>geom_boxplot()</b> to create boxplots that have the exact line thickness you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Change Axis Labels of Boxplot in ggplot2 
 How to Create a Grouped Boxplot in ggplot2 
 How to Label Outliers in Boxplots in ggplot2 
<h2><span class="orange">How to Fix in R: Cannot use `+.gg()` with a single argument</span></h2>
One common error message you may encounter when using  ggplot2  in R is:
<b>Error: Cannot use `+.gg()` with a single argument. Did you accidentally put + on
       a new line? 
</b>
This error occurs when you attempt to create a plot using the ggplot2 data visualization package in R, but accidently place the plus (<b>+</b>) sign at the beginning of a new line instead of the end of the current line.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a scatter plot in ggplot2 using variables from the built-in  mtcars  dataset in R:
<b>library(ggplot2)
#attempt to create scatter plot
ggplot(mtcars, aes(mpg, wt))
+  geom_point()
Error: Cannot use `+.gg()` with a single argument. Did you accidentally put + on
       a new line?
</b>
We receive an error because we placed the plus (<b>+</b>) sign at the beginning of a new line.
<h3>How to Fix the Error</h3>
To fix this error, we simply need to make sure we place the plus (<b>+</b>) sign at the end of the first line:
<b>library(ggplot2)
#create scatter plot
ggplot(mtcars, aes(mpg, wt)) +
  geom_point()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/ggerror1.jpg"458">
Notice that we’re able to successfully create a scatter plot without any errors because we moved the plus (<b>+</b>) sign to the end of the first line.
<h2><span class="orange">How to Change Line Colors in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to specify line colors in ggplot2:
<b>ggplot(df, aes(x=x, y=y, group=group_var, color=group_var)) + 
    geom_line() +
    scale_color_manual(values=c('color1', 'color2', 'color3'))</b>
The following example shows how to use this syntax in practice.
<h2>Example: Change Line Colors in ggplot2</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(store=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), week=c(1, 2, 3, 1, 2, 3, 1, 2, 3), sales=c(9, 12, 15, 7, 9, 14, 10, 16, 19))
#view data frame
df
  store week sales
1     A    1     9
2     A    2    12
3     A    3    15
4     B    1     7
5     B    2     9
6     B    3    14
7     C    1    10
8     C    2    16
9     C    3    19
</b>
Now suppose we create the following line plot in ggplot2 to visualize the total sales by week and by store:
<b>library(ggplot2)
#create line plot
ggplot(df, aes(x=week, y=sales, group=store, color=store)) + 
    geom_line(size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/linecolor1.jpg"460">
By default, ggplot2 uses a  default color palette  with red, green, and blue for the lines.
However, you can use the <b>scale_color_manual()</b> function to specify your own colors for the lines:
<b>library(ggplot2)
#create line plot
ggplot(df, aes(x=week, y=sales, group=store, color=store)) + 
    geom_line(size=2) +
    scale_color_manual(values=c('orange', 'pink', 'red'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/linecolor2.jpg"465">
The colors are now orange, pink, and red.
Note that you can also use hex color codes to specify the colors:
<b>library(ggplot2)
#create line plot
ggplot(df, aes(x=week, y=sales, group=store, color=store)) + 
    geom_line(size=2) +
    scale_color_manual(values=c('#063970', '#A69943', '#7843a6'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/linecolor3.jpg"464">
The colors now correspond to the specific hex color codes that we chose.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Rotate Axis Labels in ggplot2 
 How to Change Point Size in ggplot2 
 How to Add Text to ggplot2 Plots 
<h2><span class="orange">How to Fix Error: `data` must be a data frame, or other object coercible by `fortify()`, not a numeric vector</span></h2>
One error you may encounter in R is:
<b>Error: `data` must be a data frame, or other object coercible by `fortify()`,
        not a numeric vector
</b>
This error occurs when you attempt to use <b>ggplot2</b> to plot variables in a data frame, but you reference a vector instead of a data frame for the <b>data</b> argument.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=c(4, 8, 14, 19, 14, 13, 9, 9))
#view data frame
df
  x  y
1 1  4
2 2  8
3 3 14
4 4 19
5 5 14
6 6 13
7 7  9
8 8  9
</b>
Now suppose we attempt to create a scatter plot to visualize the x and y variables within the data frame:
<b>library(ggplot2)
#attempt to create scatter plot
ggplot(df$x, aes(x=x, y=y)) +
    geom_point()
Error: `data` must be a data frame, or other object coercible by `fortify()`,
        not a numeric vector
</b>
We receive an error because we referenced a numeric vector (<b>df$x</b>) within the <b>data</b> argument of the <b>ggplot()</b> function instead of a data frame.
<h2>How to Fix the Error</h2>
The way to fix this error is to reference a data frame for the <b>data</b> argument within the <b>ggplot()</b> function.
In our example, we should use <b>df</b> instead of <b>df$x</b> for the <b>data</b> argument:
<b>library(ggplot2)
#create scatter plot
ggplot(df, aes(x=x, y=y)) +
    geom_point()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/ggerror2.jpg"482">
Notice that we’re able to create the scatter plot successfully without any error this time.
<h2>Additional Resources</h2>
The following tutorials explain how to troubleshoot other common errors in R:
 How to Fix: ggplot2 doesn’t know how to deal with data of class uneval 
 How to Fix: Error in stripchart.default(x1, …) : invalid plotting method 
 How to Fix: Error in eval(predvars, data, env) : object ‘x’ not found 
<h2><span class="orange">How to Plot Mean with geom_bar() in ggplot2</span></h2>
You can use the following basic syntax to plot the mean values by group using the <b>geom_bar()</b> function in ggplot2:
<b>library(ggplot2)
ggplot(df, aes(group_var, values_var)) +
  geom_bar(position='dodge', stat='summary', fun='mean')
</b>
The following example shows how to use this syntax in practice.
<b>Note</b>: The <b>fun</b> argument in <b>geom_bar()</b> tells ggplot2 which descriptive statistic to display using bars. You could also pass a different descriptive statistic such as ‘median’ to this argument to instead plot the median value by group.
<h2>Example: Plot Mean Values with geom_bar() in ggplot2</h2>
Suppose we have the following data frame that contains information on the number of points scored by basketball players on various teams:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=4), points=c(3, 5, 5, 6, 5, 7, 7, 8, 9, 9, 9, 8))
#view data frame
df
   team points
1     A      3
2     A      5
3     A      5
4     A      6
5     B      5
6     B      7
7     B      7
8     B      8
9     C      9
10    C      9
11    C      9
12    C      8
</b>
We can use the following syntax to create a bar chart in which each bar represents the mean value for <b>points</b>, grouped by <b>team</b>:
<b>library(ggplot2)
#create bar plot to visualize mean points value by team
ggplot(df, aes(team, points)) +
  geom_bar(position='dodge', stat='summary', fun='mean')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/meanbar1.jpg">
The height of each bar represents the mean value of <b>points</b> for each <b>team</b>.
To display the actual mean value of points for each team, we can use the <b>summarise()</b> function from the <b>dplyr</b> package:
<b>library(dplyr)
#calcualte mean value of points, grouped by team
df %>%
  group_by(team) %>%
  summarise(mean_pts = mean(points, na.rm=TRUE))
# A tibble: 3 x 2
  team  mean_pts
      
1 A         4.75
2 B         6.75
3 C         8.75
</b>
From the output we can see the mean value of points for each team:
Team A: <b>4.75</b>
Team B: <b>6.75</b>
Team C: <b>8.75</b>
These values match the height of the bars shown in the bar plot above.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Adjust Space Between Bars in ggplot2 
 How to Remove NAs from Plot in ggplot2 
 How to Change Colors of Bars in Stacked Bart Chart in ggplot2 
<h2><span class="orange">How to Create Histograms by Group in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to create a histogram by group in ggplot2:
<b>ggplot(df, aes(x=values_var, fill=group_var)) +
  geom_histogram(color='black', alpha=0.4, position='identity') +
  scale_fill_manual(values=c('red', 'blue', 'purple'))
</b>
This particular example creates a plot with three overlaid histograms that are red, blue, and purple.
The following example show how to use this syntax in practice.
<h2>Example: Create Histogram by Group in ggplot2</h2>
Suppose we have the following data frame in R that contains information about points scored by basketball players on three different teams:
<b>#make this example reproducible
set.seed(1)
#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=100), points=c(rnorm(100, mean=10),          rnorm(100, mean=15),          rnorm(100, mean=20)))
#view head of data frame
head(df)
  team    points
1    A  9.373546
2    A 10.183643
3    A  9.164371
4    A 11.595281
5    A 10.329508
6    A  9.179532</b>
We can use the following code to create histograms that display the distribution of points scored by each of the three teams:
<b>library(ggplot2)
#create histogram by team
ggplot(df, aes(x=points, fill=team)) +
  geom_histogram(color='black', alpha=0.4, position='identity') +
  scale_fill_manual(values=c('red', 'blue', 'purple'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/histbygroup1.jpg"589">
The three histograms represent the distribution of points scored by players on each team.
The legend on the right side of the plot shows which color corresponds with each team.
Note that the <b>color</b> argument specifies the outline color for the bars in each histogram and the <b>alpha</b> argument specifies the transparency (between 0 and 1) to use for the bars.
By setting the value for <b>alpha</b> to be less than 1, we’re able to see any overlapping bars between the histograms.
Feel free to use the <b>labs()</b> function to modify the labels in the plot and choose a  ggplot2 theme  that fits your style:
<b>library(ggplot2)
#create histogram by team
ggplot(df, aes(x=points, fill=team)) +
  geom_histogram(color='black', alpha=0.4, position='identity') +
  scale_fill_manual(values=c('red', 'blue', 'purple')) +
  labs(fill='Team', x='Points Scored', y='Count', title='Points Scored by Team') +
  theme_classic()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/histbygroup2.jpg">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Create a Relative Frequency Histogram in R 
 How to Plot Multiple Boxplots in One Chart in R 
 How to Plot Multiple Lines in One Chart in R 
<h2><span class="orange">How to Create a Legend in ggplot2 with Multiple Rows</span></h2>
You can use the following syntax to create a legend in ggplot2 with multiple rows:
<b>ggplot(df, aes(x=x_var, y=y_var, color=group_var)) +
  geom_point() +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) 
</b>
The value for the <b>nrow</b> argument specifies the number of rows to use in the legend.
The following example shows how to use this syntax in practice.
<h2>Example: Create Legend in ggplot2 with Multiple Rows</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Heat', 'Nets', 'Lakers', 'Suns', 'Cavs'), points=c(24, 20, 34, 39, 28, 29), assists=c(5, 7, 6, 9, 12, 13))
#view data frame
df
    team points assists
1   Mavs     24       5
2   Heat     20       7
3   Nets     34       6
4 Lakers     39       9
5   Suns     28      12
6   Cavs     29      13</b>
If we create a scatter plot in ggplot2 without specifying the number of rows to use in the legend, ggplot2 will place one label on each line by default:
<b>library(ggplot2)
#create default scatterplot
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/legendmult1.jpg"503">
In order to create a legend with multiple rows, we must use the <b>guides()</b> function with the <b>nrow</b> argument:
<b>library(ggplot2)
#create scatterplot with two rows in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/legendmult2.jpg"490">
Notice that the legend now has two rows.
If we’d like to change the location of the legend as well, we can use the <b>theme()</b> function with the <b>legend.position</b> argument:
<b>library(ggplot2)
#create scatterplot with two rows in legend
ggplot(df, aes(x=assists, y=points, color=team)) +
  geom_point(size=3) +
  theme(legend.position='bottom') +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/legendmult3.jpg"508">
The legend is now located at the bottom of the plot and it has two rows.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in ggplot2:
 How to Change the Legend Title in ggplot2 
 How to Change Legend Size in ggplot2 
 How to Change Legend Position in ggplot2 
<h2><span class="orange">How to Change Legend Size in ggplot2 (With Examples)</span></h2>
You can use the following syntax to change the size of elements in a ggplot2 legend:
<b>ggplot(data, aes(x=x, y=y)) +
  theme(legend.key.size = unit(1, 'cm'), #change legend key size
        legend.key.height = unit(1, 'cm'), #change legend key height
        legend.key.width = unit(1, 'cm'), #change legend key width
        legend.title = element_text(size=14), #change legend title font size
        legend.text = element_text(size=10)) #change legend text font size
</b>
The following examples show how to use these arguments in practice.
<h3>Change ggplot2 Legend Key Size</h3>
Suppose we create the following  grouped barplot  using ggplot2:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=3), position=rep(c('Guard', 'Forward', 'Center'), times=3), points=c(14, 8, 8, 16, 3, 7, 17, 22, 26))
#create grouped barplot
ggplot(df, aes(fill=position, y=points, x=team)) +
  geom_bar(position='dodge', stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/legendR1.png">
By default, ggplot2 provides a legend to the right of the graph.
The following code shows how to use the <b>legend.key.size </b>argument to make the keys of the legend larger:
<b>ggplot(df, aes(fill=position, y=points, x=team)) +
  geom_bar(position='dodge', stat='identity') +
  theme(legend.key.size = unit(2, 'cm'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/legendR2.png">
We can also use the <b>legend.key.width </b>and <b>legend.key.height </b>arguments to specify widths and heights for the keys:
<b>ggplot(df, aes(fill=position, y=points, x=team)) +
  geom_bar(position='dodge', stat='identity') +
  theme(legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(4, 'cm'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/legendR3.png">
<h3>Change ggplot2 Legend Title Font Size</h3>
We can use the <b>legend.title </b>argument to make the legend title font size larger:
<b>ggplot(df, aes(fill=position, y=points, x=team)) +
  geom_bar(position='dodge', stat='identity') +
  theme(legend.title = element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/legendR4.png">
<h3>Change ggplot2 Legend Text Font Size</h3>
We can use the <b>legend.text </b>argument to make the legend title font size larger:
<b>ggplot(df, aes(fill=position, y=points, x=team)) +
  geom_bar(position='dodge', stat='identity') +
  theme(legend.text = element_text(size=30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/legendR5.png">
<h2><span class="orange">How to Plot a Linear Regression Line in ggplot2 (With Examples)</span></h2>
You can use the R visualization library  ggplot2  to plot a fitted linear regression model using the following basic syntax:
<b>ggplot(data,aes(x, y)) +
  geom_point() +
  geom_smooth(method='lm')
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Plot a Linear Regression Line in ggplot2</h3>
Suppose we fit a  simple linear regression  model to the following dataset:
<b>#create dataset
data &lt;- data.frame(y=c(6, 7, 7, 9, 12, 13, 13, 15, 16, 19, 22, 23, 23, 25, 26),   x=c(1, 2, 2, 3, 4, 4, 5, 6, 6, 8, 9, 9, 11, 12, 12))
#fit linear regression model to dataset and view model summary
model &lt;- lm(y~x, data=data)
summary(model)
Call:
lm(formula = y ~ x, data = data)
Residuals:
    Min      1Q  Median      3Q     Max 
-1.4444 -0.8013 -0.2426  0.5978  2.2363 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  4.20041    0.56730   7.404 5.16e-06 ***
x            1.84036    0.07857  23.423 5.13e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 1.091 on 13 degrees of freedom
Multiple R-squared:  0.9769,Adjusted R-squared:  0.9751 
F-statistic: 548.7 on 1 and 13 DF,  p-value: 5.13e-12
</b>
The following code shows how to visualize the fitted linear regression model:
<b>library(ggplot2)
#create plot to visualize fitted linear regression model
ggplot(data,aes(x, y)) +
  geom_point() +
  geom_smooth(method='lm') </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/regressionggplot1.png">
By default, ggplot2 adds standard error lines to the chart. You can disable these by using the argument <b>se=FALSE</b> as follows:
<b>library(ggplot2)
#create regression plot with no standard error lines
ggplot(data,aes(x, y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/regressionggplot2.png">
Lastly, we can customize some aspects of the chart to make it more visually appealing:
<b>library(ggplot2)
#create regression plot with customized style
ggplot(data,aes(x, y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE, color='turquoise4') +
  theme_minimal() +
  labs(x='X Values', y='Y Values', title='Linear Regression Plot') +
  theme(plot.title = element_text(hjust=0.5, size=20, face='bold')) </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/regressionggplot3.png">
<em>Refer to  this post  for a complete guide to the best ggplot2 themes.</em>
<h2><span class="orange">How to Create a Log Scale in ggplot2</span></h2>
Often you may want to convert the x-axis or y-axis scale of a ggplot2 plot into a log scale.
You can use one of the following two methods to do so using only ggplot2:
<b>1. Use scale_y_continuous() or scale_x_continuous()</b>
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_y_continuous(trans='log10') +
  scale_x_continuous(trans='log10')
</b>
<b>2. Use coord_trans()</b>
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  coord_trans(y ='log10', x='log10')</b>
If you’d like to format the axis labels to show exponents, you can use  functions from the  scales  package:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_y_continuous(trans='log10',     breaks=trans_breaks('log10', function(x) 10^x),     labels=trans_format('log10', math_format(10^.x)))</b>
This tutorial shows examples of how to use these functions in practice.
<h3>Example 1: Log Scale Using scale_y_continuous()</h3>
The following code shows how to use the <b>scale_y_continuous()</b> function to create a log scale for the y-axis of a scatterplot:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(2, 5, 6, 7, 9, 13, 14, 16, 18), y=c(1400, 1700, 2300, 2500, 2800, 2900, 3400, 3900, 11000))
#create scatterplot with log scale on y-axis
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_y_continuous(trans='log10')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/logScaleggplot1.png">
<h3>Example 2: Log Scale Using coord_trans()</h3>
The following code shows how to use the <b>coord_trans()</b> function to create a log scale for the y-axis of a scatterplot:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(2, 5, 6, 7, 9, 13, 14, 16, 18), y=c(1400, 1700, 2300, 2500, 2800, 2900, 3400, 3900, 11000))
#create scatterplot with log scale on y-axis
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  coord_trans(y='log10')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/logScaleggplot2.png">
<h3>Example 3: Custom Log Scale Labels</h3>
The following code shows how to use functions from the <b>scales</b> package function to create a log scale for the y-axis of a scatterplot and add custom labels with exponents:
<b>library(ggplot2)
library(scales)
#create data frame
df &lt;- data.frame(x=c(2, 5, 6, 7, 9, 13, 14, 16, 18), y=c(1400, 1700, 2300, 2500, 2800, 2900, 3400, 3900, 11000))
#create scatterplot with log scale on y-axis and custom labels
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  scale_y_continuous(trans='log10',     breaks=trans_breaks('log10', function(x) 10^x),     labels=trans_format('log10', math_format(10^.x)))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/logScaleggplot3.png">
Notice that the y-axis labels have exponents, unlike the previous two plots.
<h2><span class="orange">How to Plot Multiple Lines in ggplot2 (With Example)</span></h2>
You can use the following basic syntax to plot multiple lines in ggplot2:
<b>ggplot(df, aes(x=x_var, y=y_var)) + 
  geom_line(aes(color=group_var)) +
  scale_color_manual(name='legend_title', labels=c('lab1', 'lab2', 'lab3'),     values=c('color1', 'color2', 'color3'))
</b>
This particular syntax creates a plot in ggplot2 with three lines.
This syntax assumes that your data frame is in a  long format .
The following example shows how to plot multiple lines in ggplot2 in practice.
<h2>Example: Plot Multiple Lines in ggplot2</h2>
Suppose we have the following data frame in R that contains information on the number of sales made at three different stores on five different days:
<b>#create data frame
df &lt;- data.frame(day=c(1, 2, 3, 4, 5), storeA=c(5, 6, 8, 8, 9), storeB=c(3, 3, 4, 5, 7), storeC=c(8, 10, 12, 12, 17))
#view data frame
df
  day storeA storeB storeC
1   1      5      3      8
2   2      6      3     10
3   3      8      4     12
4   4      8      5     12
5   5      9      7     17
</b>
This data frame is currently in a wide format.
However, we can use the <b>pivot_longer()</b> function from the <b>tidyr</b> package to quickly convert the data into a long format:
<b>library(tidyr)
#convert data from wide to long format
df &lt;- df %>% pivot_longer(cols=c('storeA', 'storeB', 'storeC'),          names_to='store',          values_to='sales')
#view updated data frame
df
# A tibble: 15 x 3
     day store  sales
      
 1     1 storeA     5
 2     1 storeB     3
 3     1 storeC     8
 4     2 storeA     6
 5     2 storeB     3
 6     2 storeC    10
 7     3 storeA     8
 8     3 storeB     4
 9     3 storeC    12
10     4 storeA     8
11     4 storeB     5
12     4 storeC    12
13     5 storeA     9
14     5 storeB     7
15     5 storeC    17</b>
<b>Related:</b>  An Introduction to pivot_longer() in R 
Now that the data frame is in a long format, we can use the following syntax with ggplot2 to plot the sales by each store:
<b>library(ggplot2)
#plot sales by store
ggplot(df, aes(x=day, y=sales)) + 
  geom_line(aes(color=store)) +
  scale_color_manual(name='Store', labels=c('A', 'B', 'C'),     values=c('red', 'purple', 'steelblue'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/multipleline1.jpg"524">
The individual lines display the sales made at each store on each day.
Note that we used the <b>scale_color_manual()</b> function to create a custom legend on the right side of the plot to make the lines easier to interpret.
Feel free to change the arguments in this function to create a legend that appears exactly how you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot Mean and Standard Deviation in ggplot2 
 How to Add a Horizontal Line to a Plot Using ggplot2 
 How to Draw a Trend Line in ggplot2 
<h2><span class="orange">How to Convert Axis in ggplot2 to Percentage Scale</span></h2>
You can use the following basic syntax to convert an axis in ggplot2 to a percentage scale:
<b>+ scale_y_continuous(labels = scales::percent)
</b>
The following example show how to use this syntax in practice.
<h2>Example: Convert Axis in ggplot2 to Percentage Scale</h2>
Suppose we have the following data frame in R that shows the percentage of items that were returned at four different stores:
<b>#create data frame
df &lt;- data.frame(store=c('A', 'B', 'C', 'D'), returns=c(.14, .08, .22, .11))
#view data frame
df
  store returns
1     A    0.14
2     B    0.08
3     C    0.22
4     D    0.11
</b>
Now suppose we create a bar chart in ggplot2 to visualize the return percentages for each store:
<b>library(ggplot2)
#create bar chart
ggplot(data=df, aes(x=store, y=returns)) +
  geom_bar(stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percentaxis1.jpg"474">
By default, ggplot2 displays the values on the y-axis using decimals.
However, we can use the following syntax to change the y-axis to a percentage scale:
<b>library(ggplot2)
#create bar chart with percentages on y-axis
ggplot(data=df, aes(x=store, y=returns)) +
  geom_bar(stat='identity') +
  scale_y_continuous(labels = scales::percent)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percentaxis2.jpg"480">
The y-axis now has a percentage scale.
By default, one decimal place is shown. However, we can use the <b>accuracy</b> argument to drop the decimal place from the y-axis:
<b>library(ggplot2)
#create bar chart with percentages on y-axis
ggplot(data=df, aes(x=store, y=returns)) +
  geom_bar(stat='identity') +
  scale_y_continuous(labels = scales::percent_format(accuracy=1))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/percentaxis3.jpg">
The y-axis is now shown as a percentage without any decimal places.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in ggplot2:
 How to Remove a Legend in ggplot2 
 How to Remove Gridlines in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Plot Mean and Standard Deviation in ggplot2</span></h2>
Often you may want to plot the mean and standard deviation by group in ggplot2.
Fortunately this is easy to do using the <b>geom_point()</b> and <b>geom_errorbar()</b> functions in ggplot2.
The following example shows how to use these functions to create the following plot that shows the mean and standard deviation of points scored by various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/meanstd1.jpg">
<h2>Example: Plot Mean and Standard Deviation in ggplot2</h2>
Suppose we have the following data frame in R that contains information on the number of points scored by basketball players on three different teams:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=6), points=c(8, 10, 12, 12, 14, 15, 10, 11, 12,          18, 22, 24, 3, 5, 5, 6, 7, 9))
#view head of data frame
head(df)
  team points
1    A      8
2    A     10
3    A     12
4    A     12
5    A     14
6    A     15</b>
We can use functions from the <b>dplyr</b> package to quickly calculate the mean and standard deviation of points scored by players on each team:
<b>library(dplyr)
#calculate mean and sd of points by team
df_mean_std &lt;- df %>%
  group_by(team) %>%
  summarise_at(vars(points), list(mean=mean, sd=sd)) %>% 
  as.data.frame()
#view results
df_mean_std
  team      mean       sd
1    A 11.833333 2.562551
2    B 16.166667 6.013873
3    C  5.833333 2.041241
</b>
Lastly, we can use the following functions from <b>ggplot2</b> to visualize the mean and standard deviation of points scored by players on each team:
<b>library(ggplot2)
#plot mean and standard deviation of points by team
ggplot(df_mean_std , aes(x=team, y=mean)) + 
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.3) +
  geom_point(size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/meanstd1.jpg">
The resulting plot shows the mean and standard deviation of points scored by players on each team.
The circles represent the mean values and the length of the bars above and below each circle represent the standard deviation.
<b>Note</b>: The <b>width</b> argument in the <b>geom_errorbar()</b> function specifies how wide the error bars should be. Feel free to modify this value to adjust the width of the error bars in the plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Add Caption to ggplot2 Plots 
 How to Change Font Size in ggplot2 
 How to Remove a Legend in ggplot2 
 How to Rotate Axis Labels in ggplot2 
<h2><span class="orange">How to Create a Residual Plot in ggplot2 (With Example)</span></h2>
<b>Residual plots</b> are used to assess whether or not the  residuals  in a regression model are normally distributed and whether or not they exhibit  heteroscedasticity .
To create a residual plot in ggplot2, you can use the following basic syntax:
<b>library(ggplot2)
ggplot(model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Creating a Residual Plot in ggplot2</h2>
For this example, we’ll use the built-in  mtcars  dataset in R:
<b>#view first six rows of mtcars dataset
head(mtcars)   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</b>
First, we’ll fit a regression model using <b>mpg </b>as the response variable and <b>qsec </b>as the predictor variable:
<b>#fit regression model
model &lt;- lm(mpg ~ qsec, data=mtcars) </b>
Next, we’ll use the following syntax to create a residual plot in ggplot2:
<b>library(ggplot2)
#create residual plot
ggplot(model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/fit1.jpg">
The x-axis displays the fitted values and the y-axis displays the residuals.
The residuals appear to be randomly scattered around zero with no clear pattern, which indicates that the assumption of homoscedasticity is met.
In other words, the  coefficients  of the regression model should be trustworthy and we don’t need to perform a  transformation  on the data.
Also note that we could use the<b> labs()</b> function to add a title and axis labels to the residual plot:
<b>library(ggplot2)
#create residual plot with title and axis labels
ggplot(model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title='Residual vs. Fitted Values Plot', x='Fitted Values', y='Residuals')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/fit2.jpg">
<h2>Additional Resources</h2>
The following tutorials explains how to perform other common tasks in R:
 How to Calculate Standardized Residuals in R 
 How to Calculate Studentized Residuals in R 
 How to Create a Histogram of Residuals in R 
<h2><span class="orange">How to Use scale_x_continuous in ggplot2 (With Examples)</span></h2>
You can use the <b>scale_x_continuous()</b> function in ggplot2 to customize the x-axis of a given plot.
This function uses the following basic syntax:
<b>p +
  scale_x_continuous(breaks, n.breaks, labels, limits, ...)
</b>
where:
<b>breaks</b>: A numeric vector of positions for breaks on the x-axis
<b>n.breaks</b>: An integer vector specifying the number of total breaks on the x-axis
<b>labels</b>: A character vector of labels to use for the x-axis
<b>limits</b>: A numeric vector that specifies the min and max value for the x-axis
The following examples show how to use this function in different scenarios with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(5, 7, 12, 13, 15, 19, 22, 25), assists=c(4, 3, 2, 3, 7, 8, 5, 7))
#view data frame
df
  points assists
1      5       4
2      7       3
3     12       2
4     13       3
5     15       7
6     19       8
7     22       5
8     25       7
</b>
<h2>Example 1: Use scale_x_continuous with Custom Axis Breaks</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_x_continuous()</b> with the <b>breaks </b>argument to specify custom axis breaks of 5, 15 and 25:
<b>library(ggplot2)
#create scatterplot with custom x-axis breaks
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_x_continuous(breaks=c(5, 15, 25))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/xlim1.jpg"487">
Notice that the x-axis only contains axis breaks at 5, 15 and 25, just as we specified using the <b>breaks </b>argument.
<h2>Example 2: Use scale_x_continuous with Custom Number of Breaks</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_x_continuous()</b> with the <b>n.breaks </b>argument to place exactly 12 axis breaks on the x-axis:
<b>library(ggplot2)
#create scatterplot with custom number of breaks on x-axis
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_x_continuous(n.breaks=12)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/xlim2.jpg"487">
Notice that the x-axis contains exactly 12 axis breaks, just as we specified using the <b>n.breaks </b>argument.
<h2>Example 3: Use scale_x_continuous with Custom Labels</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_x_continuous()</b> with the <b>labels </b>argument to specify the label names to place on the x-axis:
<b>library(ggplot2)
#create scatterplot with custom labels on x-axis
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_x_continuous(breaks=c(5, 15, 25), labels=c('five', 'fifteen', 'twenty-five'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/xlim3.jpg"486">
Notice that the x-axis contains 3 axis breaks each with custom labels, just as we specified using the <b>labels </b>argument.
<h2>Example 4: Use scale_x_continuous with Custom Limits</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_x_continuous()</b> with the <b>limits</b> argument to specify custom x-axis limits of 0 and 40:
<b>library(ggplot2)
#create scatterplot with custom x-axis limits
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_x_continuous(limits=c(0, 40))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/xlim4.jpg"487">
Notice that the x-axis ranges from 0 to 40, just as we specified using the <b>limits</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Use scale_y_continuous in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Use scale_y_continuous in ggplot2 (With Examples)</span></h2>
You can use the <b>scale_y_continuous()</b> function in ggplot2 to customize the y-axis of a given plot.
This function uses the following basic syntax:
<b>p +
  scale_y_continuous(breaks, n.breaks, labels, limits, ...)
</b>
where:
<b>breaks</b>: A numeric vector of positions for breaks on the y-axis
<b>n.breaks</b>: An integer vector specifying the number of total breaks on the y-axis
<b>labels</b>: A character vector of labels to use for the y-axis
<b>limits</b>: A numeric vector that specifies the min and max value for the y-axis
The following examples show how to use this function in different scenarios with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(5, 7, 12, 13, 15, 19, 22, 25), assists=c(4, 3, 2, 3, 7, 8, 5, 7))
#view data frame
df
  points assists
1      5       4
2      7       3
3     12       2
4     13       3
5     15       7
6     19       8
7     22       5
8     25       7
</b>
<h2>Example 1: Use scale_y_continuous with Custom Axis Breaks</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_y_continuous()</b> with the <b>breaks </b>argument to specify custom axis breaks of 2, 5 and 8:
<b>library(ggplot2)
#create scatterplot with custom y-axis breaks
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_y_continuous(breaks=c(2, 5, 8))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/ylim2.jpg"484">
Notice that the y-axis only contains axis breaks at 2, 5 and 8, just as we specified using the <b>breaks </b>argument.
<h2>Example 2: Use scale_y_continuous with Custom Number of Breaks</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_y_continuous()</b> with the <b>n.breaks </b>argument to place exactly 2 axis breaks on the y-axis:
<b>library(ggplot2)
#create scatterplot with custom number of breaks on y-axis
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_y_continuous(n.breaks=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/ylim3.jpg"487">
Notice that the y-axis contains exactly 2 axis breaks, just as we specified using the <b>n.breaks </b>argument.
<h2>Example 3: Use scale_y_continuous with Custom Labels</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_y_continuous()</b> with the <b>labels </b>argument to specify the label names to place on the y-axis:
<b>library(ggplot2)
#create scatterplot with custom labels
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_y_continuous(breaks=c(2, 5, 8), labels=c('two', 'five', 'eight'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/ylim4.jpg"479">
Notice that the y-axis contains 3 axis breaks each with custom labels, just as we specified using the <b>labels </b>argument.
<h2>Example 4: Use scale_y_continuous with Custom Limits</h2>
The following code shows how to create a scatterplot in ggplot2 and use <b>scale_y_continuous()</b> with the <b>limits</b> argument to specify custom y-axis limits of 0 and 20:
<b>library(ggplot2)
#create scatterplot with custom y-axis limits
ggplot(df, aes(x=points, y=assists)) +
  geom_point(size=2) + 
  scale_y_continuous(limits=c(0, 20))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/ylim1.jpg"484">
Notice that the y-axis ranges from 0 to 20, just as we specified using the <b>limits</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Use scale_x_continuous in ggplot2 
 How to Rotate Axis Labels in ggplot2 
 How to Change Legend Labels in ggplot2 
<h2><span class="orange">How to Shade an Area in ggplot2 (With Examples)</span></h2>
You can use the following basic syntax to shade a particular area in a plot in ggplot2:
<b>ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  annotate('rect', xmin=3, xmax=5, ymin=3, ymax=7, alpha=.2, fill='red')
</b>
This particular example shades the area between the x-values of 3 and 5 and the y-values of 3 and 7.
The <b>fill</b> argument controls the color of the shaded area and the <b>alpha</b> argument controls the transparency of the color.
The following example shows how to use this syntax in practice.
<h2>Example: Shade an Area in ggplot2</h2>
Suppose we have the following data frame in R that contains information about the points scored and rebounds collected by various basketball players:
<b>#create data frame
df &lt;- data.frame(points=c(3, 3, 5, 6, 7, 8, 9, 9, 8, 5), rebounds=c(2, 6, 5, 5, 8, 5, 9, 9, 8, 6))
#view data frame
df
   points rebounds
1       3        2
2       3        6
3       5        5
4       6        5
5       7        8
6       8        5
7       9        9
8       9        9
9       8        8
10      5        6
</b>
We can use the following code to create a scatter plot and shade the area between the x-values of 3 and 5 and the y-values of 3 and 7 with a light red rectangle:
<b>library(ggplot2)
#create scatter plot with shaded area
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  annotate('rect', xmin=3, xmax=5, ymin=3, ymax=7, alpha=.2, fill='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/shade1.jpg">
The area that we specified in the <b>annotate()</b> function is shaded with a light red rectangle.
Note that the value for the alpha argument ranges between 0 and 1 with lower values indicating greater transparency.
For example, if we change the value for <b>alpha</b> to 0.5, the color of the shaded area will be darker:
<b>library(ggplot2)
#create scatter plot with shaded area
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  annotate('rect', xmin=3, xmax=5, ymin=3, ymax=7, alpha=.5, fill='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/shade2.jpg"543">
Also note that you can use the<b> annotate()</b> function multiple times to create multiple shaded areas in your plot:
<b>library(ggplot2)
#create scatter plot with two shaded areas
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  annotate('rect', xmin=3, xmax=5, ymin=3, ymax=7, alpha=.5, fill='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/shade3.jpg">
Feel free to play around with the arguments in the <b>annotate()</b> function to create the exact shading that you would like in your plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Add Text to ggplot2 Plots 
 How to Remove Gridlines in ggplot2 
 How to Change X-Axis Labels in ggplot2 
<h2><span class="orange">How to Adjust Space Between Bars in ggplot2 (With Examples)</span></h2>
You can use the following methods to adjust the space between bars in ggplot2 bar charts:
<b>Method 1: Adjust Spacing Between Bars in Bar Chart</b>
<b>ggplot(df, aes(x=x_variable)) +
  geom_bar(width=.4)</b>
The default width between bars is <b>0.9</b>.
The closer the width is to <b>1</b>, the closer together the bars will be. The close the width is to <b>0</b>, the more spread out the bars will be.
<b>Method 2: Adjust Spacing Between Bars in Clustered Bar Chart</b>
<b>ggplot(df, aes(x=x_variable, y=y_variable, fill=fill_variable)) +
  geom_bar(width=.5, stat='identity', position=position_dodge(.7))</b>
The <b>width</b> value controls the spacing between clusters while the <b>position_dodge()</b> value controls the spacing between bars within the same cluster.
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C'), position=c('G', 'G', 'F', 'G', 'F', 'F', 'F', 'G'), points=c(12, 22, 24, 23, 20, 15, 11, 30))
#view data frame
df
  team position points
1    A        G     12
2    A        G     22
3    A        F     24
4    B        G     23
5    B        F     20
6    B        F     15
7    C        F     11
8    C        G     30
</b>
<h2>Example 1: Adjust Spacing Between Bars in Bar Chart</h2>
The following code shows how to create a bar chart to visualize the occurrences of each team using the default <b>width</b> spacing of <b>0.9</b>:
<b>library(ggplot2)
#create bar plot with default spacing
ggplot(df, aes(x=team)) +
  geom_bar()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/spacing1.jpg"525">
And the following code shows how to increase the space between the bars by decreasing the value for the <b>width</b> argument to <b>0.4</b>:
<b>library(ggplot2)
#create bar plot with increased spacing
ggplot(df, aes(x=team)) +
  geom_bar(width=.4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/spacing2.jpg">
By decreasing the value for the <b>width</b> argument, we increased the spacing between the bars.
<h2>Example 2: Adjust Spacing Between Bars in Clustered Bar Chart</h2>
The following code shows how to create a clustered bar chart to visualize the total points scored by team and position:
<b>library(ggplot2)
#create clustered bar plot with default spacing
ggplot(df, aes(x=team, y=points, fill=position)) +
  geom_bar(stat='identity', position='dodge')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/spacing3.jpg"538">
And the following code shows how to increase both the space between the clustered bars and the space between bars within the same cluster:
<b>library(ggplot2)
#create clustered bar plot with increased spacing
ggplot(df, aes(x=team, y=points, fill=position)) +
  geom_bar(width=.5, stat='identity', position=position_dodge(.7))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/spacing4.jpg"541">
By decreasing the value for <b>width</b>, we increased the spacing between the clusters.
And by decreasing the value for <b>position_dodge()</b>, we increased the spacing between bars within the same clusters.
Feel free to play around with the values for both of these arguments to make the bar chart appear exactly how you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Order the Bars in a ggplot2 Bar Chart 
 How to Reorder Bars in a Stacked Bar Chart in ggplot2 
 How to Change Colors of Bars in Stacked Bart Chart in ggplot2 
<h2><span class="orange">The Complete Guide to ggplot2 Titles</span></h2>
The data visualization library  ggplot2  makes it easy to create beautiful charts in R from scratch.
However, ggplot2 doesn’t provide a title for charts unless you specify one. This tutorial explains exactly how to add and modify titles on ggplot2 charts.
<h3>How to Add a ggplot2 Title</h3>
The following code shows how to use ggplot2 to create a  grouped boxplot  using the built-in <b>iris</b> dataset:
<b>library(ggplot2)
ggplot(iris, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/ggplot2Title1.png">
To add a title to the chart, we can use the <b>ggtitle() </b>function:
<b>ggplot(iris, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot() +
  ggtitle('Sepal Length by Species')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/ggplot2Title2.png">
<em><b>Note: </b>You could also use <b>labs(title=’Sepal Length by Species’)</b> to create the exact same title.</em>
<h3>How to Center a ggplot2 Title</h3>
By default, ggplot2 titles are left-aligned. The creator of ggplot2, Hadley Wickham, notes that this is because  a left-aligned title works better with subtitles .
If you’d like to center a ggplot2 title, you can use this bit of code:
<b>theme(plot.title = element_text(hjust = 0.5))
</b>
Here’s what that looks like in practice:
<b>ggplot(iris, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot() +
  ggtitle('Sepal Length by Species') +
  theme(plot.title = element_text(hjust = 0.5))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/ggplot2Title3.png">
<h3>How to Modify the Font of a ggplot2 Title</h3>
You can modify many aspects of the font title, including:
<b>family</b>: font family
<b>face</b>: font face. Options include “italic”, “bold”, and “bold.italic”
<b>color</b>: font color
<b>size</b>: font size in pts
<b>hjust</b>: horizontal justification between 0 and 1
<b>vjust</b>: vertical justification between 0 and 1
<b>lineheight</b>: line height, i.e. the spaceing between lines for multi-line titles
Here’s an example of how to modify a few of these aspects:
<b>ggplot(iris, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot() +
  ggtitle('Sepal Length by Species') +
  theme(plot.title = element_text(hjust=0.5, color="blue", size=20, face="bold"))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/ggplot2Title4.png">
<h3>How to Create a Multi-Line ggplot2 Title</h3>
If you have an unusually long title, you can simply throw in <b>\n </b>where you’d like a new line to start.  For example:
<b>ggplot(iris, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot() +
  ggtitle('Sepal Length by Species\nSample size (n = 150)')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/ggplot2Title5.png">
<h2><span class="orange">How to Add a Vertical Line to a Plot Using ggplot2</span></h2>
You can quickly add vertical lines to ggplot2 plots using the <b>geom_vline()</b> function, which uses the following syntax:
<b>geom_vline(xintercept, linetype, color, size)</b>
where:
<b>xintercept:</b> Location to add line on the x-intercept. This can be one value or multiple values.
<b>linetype:</b> Line style. Default is ‘solid’ but you can specify ‘twodash’, ‘longdash’, ‘dotted’, ‘dotdash’, ‘dashed’, or ‘blank.’
<b>color:</b> Color of the line.
<b>size:</b> Width of the line.
The following examples show how to use this function in practice.
<h2>Add a Single Vertical Line to a Plot</h2>
The following code shows how to add a single vertical line to a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with vertical line at x=10
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=10)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/vline1.png">
<h2>Add Multiple Vertical Lines to Plots</h2>
The following code shows how to add multiple vertical lines to a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with vertical line at x=6, 10, and 11
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=c(6, 10, 11))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/vline2.png">
<h2>Customize Vertical Lines</h2>
The following code shows how to customize vertical lines on a plot:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with customized vertical line
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=5, linetype='dashed', color='blue', size=2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/vline3.png">
If you have multiple vertical lines on one chart, you can specify a unique color for each line:
<b>library(ggplot2)
#create data frame 
df &lt;- data.frame(x=c(1, 3, 3, 4, 5, 5, 6, 9, 12, 15), y=c(13, 14, 14, 12, 17, 21, 22, 28, 30, 31))
#create scatterplot with customized vertical lines
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_vline(xintercept=c(5, 7), linetype='dashed', color=c('blue', 'red'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/vline4.png">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in ggplot2:
 How to Plot a Linear Regression Line in ggplot2 
 How to Set Axis Limits in ggplot2 
 How to Create Side-by-Side Plots in ggplot2 
<h2><span class="orange">Matplotlib vs. ggplot2: Which Should You Use?</span></h2>
Two of the most popular data visualization libraries in all of data science are <b>ggplot2</b> and <b>Matplotlib</b>.
The  ggplot2  library is used in the R statistical programming language while  Matplotlib  is used in Python.
Although both libraries allow you to create highly customized data visualizations, ggplot2 generally allows you to do so in fewer lines of code compared to Matplotlib.
To illustrate this point, we’ll show how to create the same types of charts using both libraries.
<h2>Line Charts: ggplot2 vs. Matplotlib</h2>
The following code shows how to create a line chart using <b>ggplot2</b>:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(day=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales=c(2, 4, 5, 8, 6, 12, 15, 19, 15, 22))
#create line chart
ggplot(df, aes(x=day, y=sales)) +
  geom_line(size=1.2, col='purple') +
  ggtitle('Sales by Day') +
  xlab('Day') +
  ylab('Sales')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg1.jpg"511">
And the following code shows how to create the same line chart using <b>Matplotlib</b>:
<b>import pandas as pd
import matplotlib.pyplot as plt 
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],   'sales': [2, 4, 5, 8, 6, 12, 15, 19, 15, 22]})
#create line chart
plt.plot(df.day, df.sales, color='purple')
plt.title('Sales by Day', loc='left')
plt.ylabel('Sales')
plt.xlabel('Day')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg2.jpg"508">
For this example, the number of lines of code needed to generate each plot is roughly the same between ggplot2 and Matplotlib.
<h2>Scatter Plots: ggplot2 vs. Matplotlib</h2>
The following code shows how to create a scatter plot in <b>ggplot2</b> in which the points are colored by category:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), assists=c(1, 2, 2, 4, 5, 7, 8, 10), points=c(4, 6, 10, 8, 12, 15, 22, 28))
#create scatter plot
ggplot(df, aes(x=assists, y=points)) +
  geom_point(aes(col=team), size=3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg3.jpg"511">
And the following code shows how to create the same scatter plot using <b>Matplotlib</b>:
<b>import pandas as pd
import matplotlib.pyplot as plt 
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],   'assists': [1, 2, 2, 4, 5, 7, 8, 10],   'points': [4, 6, 10, 8, 12, 15, 22, 28]})
#define colors to use
color_list = [] 
for x in df['team']: 
    if x == 'A': color_list.append('#F8766D') 
    else: color_list.append('#00BFC4') 
#create scatter plot
plt.scatter(df.assists, df.points, c=color_list)
plt.ylabel('points')
plt.xlabel('assists')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg4.jpg"465">
Notice that we had to use many more lines of code in Matplotlib to generate the same plot as ggplot2.
<h2>Histograms: ggplot2 vs. Matplotlib</h2>
The following code shows how to create a histogram in <b>ggplot2</b>:
<b>library(ggplot2)
#create data frame
df &lt;- data.frame(x=c(2, 2, 4, 4, 4, 5, 5, 6, 7, 7, 8, 8,     10, 11, 11, 11, 12, 13, 14, 14))
#create scatter plot
ggplot(df, aes(x=x)) +
  geom_histogram(bins=6, fill='red', color='black') +
  ggtitle('My Histogram')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg5.jpg"506">
And the following code shows how to create a similar histogram using <b>Matplotlib</b>:
<b>import pandas as pd
import matplotlib.pyplot as plt 
#create DataFrame
df = pd.DataFrame({'x': [2, 2, 4, 4, 4, 5, 5, 6, 7, 7, 8, 8,         10, 11, 11, 11, 12, 13, 14, 14]})
#create histogram
plt.hist(df['x'], bins=6, color='red', ec='black')
plt.title('My Histogram', loc='left') 
plt.xlabel('x') 
plt.ylabel('Count')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/gg6-1.jpg"512">
Once again the Matplotlib version requires more lines of code than ggplot2.
<h2>Conclusion</h2>
Both ggplot2 and Matplotlib allow you to create highly customizable data visualizations, but ggplot2 tends to use less code.
Often the preference between ggplot2 and Matplotlib simply comes down to which programming language you use for data analysis.
People who use Python tend to use Matplotlib since they can perform their data analysis and create data visualizations using one programming language.
Conversely, people who use R tend to use ggplot2 because this allows them to perform all of their data analysis and visualizations in one programming language.
<h2><span class="orange">How to Calculate Gini Coefficient in Excel (With Example)</span></h2>
Named after Italian statistician  Corrado Gini , the <b>Gini coefficient</b> is a way to measure the income distribution of a population.
The value for the Gini coefficient ranges from 0 to 1 where higher values represent greater income inequality and where:
<b>0</b> represents perfect income equality (everyone has the same income)
<b>1</b> represents perfect income inequality (one individual has all the income)
You can find a list of Gini coefficients by country  here .
The following step-by-step example shows how to calculate a Gini coefficient in Excel.
<h3>Step 1: Enter the Data</h3>
First, we must enter values for two columns: the cumulative population % and cumulative income % of individuals in a certain country:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/giniExcel1.jpg"470">
Here’s how to interpret the values:
The bottom 20% of individuals in this country account for <b>10%</b> of the total income.
The bottom 50% of individuals in this country account for <b>31%</b> of the total income.
The bottom 60% of individuals in this country account for <b>40%</b> of the total income.
100% of individuals in this country account for<b> 100%</b> of the total income.
<h3>Step 2: Calculate Areas Under Lorenz Curve</h3>
Next, we need to calculate the individual areas under the  Lorenz curve , which is a curve we use to visualize the distribution of income in a country. 
In our example, we’ll type the following formula in cell <b>C3</b>:
<b>=(A3-A2)*(B3+B2)*0.5
</b>
We’ll then copy and paste this formula down to every remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/giniExcel2.jpg"554">
<h3>Step 3: Calculate Gini Coefficient</h3>
Lastly, we can type the following formula into cell <b>D2 </b>to calculate the Gini coefficient for this population:
<b>=1-2*SUM(C3:C6)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/giniExcel3.jpg">
The Gini coefficient for this population turns out to be <b>0.226</b>.
This is an extremely simple example of how to calculate a Gini coefficient but you can use these exact same formulas to calculate a Gini coefficient for a much larger dataset.
<h2><span class="orange">How to Calculate Gini Coefficient in R (With Example)</span></h2>
Named after Italian statistician  Corrado Gini , the <b>Gini coefficient</b> is a way to measure the income distribution of a population.
The value for the Gini coefficient ranges from 0 to 1 where higher values represent greater income inequality and where:
<b>0</b> represents perfect income equality (everyone has the same income)
<b>1</b> represents perfect income inequality (one individual has all the income)
You can find a list of Gini coefficients by country  here .
The following examples show two ways to calculate a Gini coefficient in R by using the <b>Gini()</b> function from the <b>DescTools</b> package.
<h3>Example 1: Calculate Gini Coefficient Using Individual Incomes</h3>
Suppose we have the following list of annual incomes for 10 individuals:
Income: $50k, $50k, $70k, $70k, $70k, $90k, $150k, $150k, $150k, $150k
The following code shows how to use the <b>Gini()</b> function to calculate the Gini coefficient for this population:
<b>library(DescTools)
#define vector of incomes
x &lt;- c(50, 50, 70, 70, 70, 90, 150, 150, 150, 150)
#calculate Gini coefficient
Gini(x, unbiased=FALSE)
[1] 0.226</b>
The Gini coefficient turns out to be <b>0.226</b>.
<b>Note</b>: In a real-world scenario there would be hundreds of thousands of different incomes for individuals in a certain country, but in this example we used 10 individuals as a simple illustration.
<h3>Example 2: Calculate Gini Coefficient Using Frequencies</h3>
Suppose we have the following frequency table that shows the number of individuals in a certain population with specific incomes:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/giniR1.jpg"165">
The following code shows how to use the <b>Gini()</b> function to calculate the Gini coefficient for this population:
<b>library(DescTools)
#define vector of incomes
x &lt;- c(10, 20, 25, 55, 70, 90, 110, 115, 130)
#define vector of frequencies
n &lt;- c(6, 7, 7, 14, 22, 20, 8, 4, 1)
#calculate Gini coefficient
Gini(x, n, unbiased=FALSE)
[1] 0.2632289
</b>
The Gini coefficient turns out to be <b>0.26232</b>.
<b>Note</b>: You can find the complete documentation for the <b>Gini()</b> function from the <b>DescTools</b> package  here .
<h2><span class="orange">How to Calculate Gini Coefficient in Python (With Example)</span></h2>
Named after Italian statistician  Corrado Gini , the <b>Gini coefficient</b> is a way to measure the income distribution of a population.
The value for the Gini coefficient ranges from 0 to 1 where higher values represent greater income inequality and where:
<b>0</b> represents perfect income equality (everyone has the same income)
<b>1</b> represents perfect income inequality (one individual has all the income)
You can find a list of Gini coefficients by country  here .
The following example shows how to calculate a Gini coefficient in Python.
<h3>Example: Calculate Gini Coefficient in Python</h3>
To calculate a Gini coefficient in Python, we’ll need to first define a simple function to calculate a Gini coefficient for a NumPy array of values:
<b>import numpy as np
#define function to calculate Gini coefficient
def gini(x):
    total = 0
    for i, xi in enumerate(x[:-1], 1):
        total += np.sum(np.abs(xi - x[i:]))
    return total / (len(x)**2 * np.mean(x))</b>
Next, we’ll use this function to calculate a Gini coefficient for an array of income values.
For example, suppose we have the following list of annual incomes for 10 individuals:
Income: $50k, $50k, $70k, $70k, $70k, $90k, $150k, $150k, $150k, $150k
The following code shows how to use the <b>gini()</b> function we just created to calculate the Gini coefficient for this population:
<b>#define NumPy array of income values
incomes = np.array([50, 50, 70, 70, 70, 90, 150, 150, 150, 150])
#calculate Gini coefficient for array of incomes
gini(incomes)
0.226
</b>
The Gini coefficient turns out to be <b>0.226</b>.
<b>Note</b>: In a real-world scenario there would be hundreds of thousands of different incomes for individuals in a certain country, but in this example we used 10 individuals as a simple illustration.
<h2><span class="orange">How to Handle R Warning: glm.fit: algorithm did not converge</span></h2>
One common warning you may encounter in R is:
<b>glm.fit: algorithm did not converge
</b>
This warning often occurs when you attempt to fit a  logistic regression model in R  and you experience <b>perfect separation</b> – that is, a predictor variable is able to perfectly separate the response variable into 0’s and 1’s.
The following example shows how to handle this warning in practice.
<h3>How to Reproduce the Warning</h3>
Suppose we attempt to fit the following logistic regression model in R:
<b>#create data frame
df &lt;- data.frame(x=c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1, 1, 1.1, 1.3, 1.5, 1.7), y=c(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1))
#attempt to fit logistic regression model
glm(y~x, data=df, family="binomial")
Call:  glm(formula = y ~ x, family = "binomial", data = df)
Coefficients:
(Intercept)            x  
     -409.1        431.1  
Degrees of Freedom: 14 Total (i.e. Null);  13 Residual
Null Deviance:    20.19 
Residual Deviance: 2.468e-09 AIC: 4
Warning messages:
1: glm.fit: algorithm did not converge 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
</b>
Notice that we receive the warning message: <b>glm.fit: algorithm did not converge</b>.
We receive this message because the predictor variable x is able to perfectly separate the response variable y into 0’s and 1’s.
Notice that for every x value less than 1, y is equal to 0. And for every x value equal to or greater than 1, y is equal to 1.
The following code shows a scenario where the predictor variable is not able to perfectly separate the response variable into 0’s and 1’s:
<b>#create data frame
df &lt;- data.frame(x=c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1, 1, 1.1, 1.3, 1.5, 1.7), y=c(0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1))
#fit logistic regression model
glm(y~x, data=df, family="binomial")
Call:  glm(formula = y ~ x, family = "binomial", data = df)
Coefficients:
(Intercept)            x  
     -2.112        2.886  
Degrees of Freedom: 14 Total (i.e. Null);  13 Residual
Null Deviance:    20.73 
Residual Deviance: 16.31 AIC: 20.31
</b>
We don’t receive any warning message because the predictor variable is not able to perfectly separate the response variable into 0’s and 1’s.
<h3>How to Handle the Warning</h3>
If we encounter a scenario with perfect separation, there are two ways to handle it:
<b>Method 1: Use penalized regression.</b>
One option is to use some form of penalized logistic regression such as lasso logistic regression or elastic-net regularization.
Refer to the  glmnet  package for options on how to implement penalized logistic regression in R.
<b>Method 2: Use the predictor variable to perfectly predict the response variable.</b>
If you suspect that this perfect separation may exist in the population, you can simply use that predictor variable to perfectly predict the value of the response variable.
For example, in the above scenario we saw that the response variable <b>y</b> was always equal to 0 when the predictor variable <b>x</b> was less than 1.
If we suspect that this relationship holds in the overall population, we can just always predict that the value of <b>y</b> will be equal to 0 when <b>x</b> is less than 1 and not worry about fitting some penalized logistic regression model.
<h2><span class="orange">How to Handle: glm.fit: fitted probabilities numerically 0 or 1 occurred</span></h2>
One warning message you may encounter in R is:
<b>Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 
</b>
This warning occurs when you fit a logistic regression model and the predicted probabilities of one or more observations in your data frame are indistinguishable from 0 or 1.
It’s worth noting that this is a <b>warning message</b> and not an error. Even if you receive this error, your logistic regression model will still be fit, but it may be worth analyzing the original data frame to see if there are any outliers causing this warning message to appear.
This tutorial shares how to address this warning message in practice.
<h3>How to Reproduce the Warning</h3>
Suppose we fit a logistic regression model to the following data frame in R:
<b>#create data frame
df &lt;- data.frame(y = c(0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1), x1 = c(3, 3, 4, 4, 3, 2, 5, 8, 9, 9, 9, 8, 9, 9, 9), x2 = c(8, 7, 7, 6, 5, 6, 5, 2, 2, 3, 4, 3, 7, 4, 4))
#fit logistic regression model
model &lt;- glm(y ~ x1 + x2, data=df, family=binomial)
#view model summary
summary(model)
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 
Call:
glm(formula = y ~ x1 + x2, family = binomial, data = df)
Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-1.729e-05  -2.110e-08   2.110e-08   2.110e-08   1.515e-05  
Coefficients:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)    -75.205 307338.933       0        1
x1              13.309  28512.818       0        1
x2              -2.793  37342.280       0        1
(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 2.0728e+01  on 14  degrees of freedom
Residual deviance: 5.6951e-10  on 12  degrees of freedom
AIC: 6
Number of Fisher Scoring iterations: 24</b>
Our logistic regression model is successfully fit to the data, but we receive a warning message that <b>fitted probabilities numerically 0 or 1 occurred</b>.
If we use the fitted logistic regression model to make predictions on the response value of the observations in the original data frame, we can see that nearly all of the predicted probabilities are indistinguishable from 0 and 1:
<b>#use fitted model to predict response values
df$y_pred = predict(model, df, type="response")
#view updated data frame
df
   y x1 x2       y_pred
1  0  3  8 2.220446e-16
2  0  3  7 2.220446e-16
3  0  4  7 2.220446e-16
4  0  4  6 2.220446e-16
5  0  3  5 2.220446e-16
6  0  2  6 2.220446e-16
7  0  5  5 1.494599e-10
8  1  8  2 1.000000e+00
9  1  9  2 1.000000e+00
10 1  9  3 1.000000e+00
11 1  9  4 1.000000e+00
12 1  8  3 1.000000e+00
13 1  9  7 1.000000e+00
14 1  9  4 1.000000e+00
15 1  9  4 1.000000e+00</b>
<h3>How to Handle the Warning</h3>
There are three ways to deal with this warning message:
<b>(1) Ignore it. </b>
In some cases, you can simply ignore this warning message because it doesn’t necessarily indicate that something is wrong with the logistic regression model. It simply means that one or more observations in the data frame have predicted values indistinguishable from 0 or 1.
<b>(2) Increase the sample size.</b>
In other cases, this warning message appears when you’re working with small data frames where there’s simply not enough data to provide a reliable model fit. To address this error, simply increase the sample size of observations that you feed into the model.
<b>(3) Remove outliers.</b>
In other cases, this error occurs when there are outliers in the original data frame and where only a small number of observations have fitted probabilities close to 0 or 1. By removing these outliers, the warning message often goes away.
<h2><span class="orange">How to Calculate R-Squared for glm in R</span></h2>
Often when we fit a linear regression model, we use <b>R-squared</b> as a way to assess how well a model fits the data.
R-squared represents the proportion of the variance in the  response variable  that can be explained by the predictor variables in a regression model.
This number ranges from 0 to 1, with higher values indicating a better model fit.
However, there is no such R-squared value for general linear models like  logistic regression  models and  Poisson regression  models.
Instead, we can calculate a metric known as <b>McFadden’s R-Squared</b>, which ranges from 0 to just under 1, with higher values indicating a better model fit.
We use the following formula to calculate McFadden’s R-Squared:
McFadden’s R-Squared = 1 – (log likelihood<sub>model</sub> / log likelihood<sub>null</sub>)
where:
<b>log likelihood<sub>model</sub></b>: Log likelihood value of current fitted model
<b>log likelihood<sub>null</sub></b>: Log likelihood value of null model (model with intercept only)
In practice, values over 0.40 indicate that a model fits the data very well.
The following example shows how to calculate McFadden’s R-Squared for a logistic regression model in R.
<h3>Example: Calculating McFadden’s R-Squared in R</h3>
For this example, we’ll use the <b>Default</b> dataset from the ISLR package. We can use the following code to load and view a summary of the dataset:
<b>#install and load ISLR package
install.packages('ISLR')
library(ISLR)
#define dataset
data &lt;- ISLR::Default
#view summary of dataset
summary(data)
 default    student       balance           income     
 No :9667   No :7056   Min.   :   0.0   Min.   :  772  
 Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340         Median : 823.6   Median :34553         Mean   : 835.4   Mean   :33517         3rd Qu.:1166.3   3rd Qu.:43808         Max.   :2654.3   Max.   :73554  
#find total observations in dataset
nrow(data)
[1] 10000
</b>
This dataset contains the following information about 10,000 individuals:
<b>default:</b> Indicates whether or not an individual defaulted.
<b>student:</b> Indicates whether or not an individual is a student.
<b>balance:</b> Average balance carried by an individual.
<b>income:</b> Income of the individual.
We will use student status, bank balance, and income to build a logistic regression model that predicts the probability that a given individual defaults:
<b>#fit logistic regression model
model &lt;- glm(default~student+balance+income, family='binomial', data=data)
#view model summary
summary(model)
Call:
glm(formula = default ~ balance + student + income, family = "binomial", 
    data = data)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4691  -0.1418  -0.0557  -0.0203   3.7383  
Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5
Number of Fisher Scoring iterations: 8
</b>
Next, we’ll use the following formula to calculate McFadden’s R-squared value for this model:
<b>#calculate McFadden's R-squared for model
with(summary(model), 1 - deviance/null.deviance)
[1] 0.4619194
</b>
McFadden’s R-squared value turns out to be <b>0.4619194</b>. This value is fairly high, which indicates that our model fits the data well and has high predictive power.
Also note that we could use the <b>pR2()</b> function from the <b>pscl</b> package to calculate McFadden’s R-square value for the model as well:
<b>#install and load pscl package
install.packages('pscl')
library(pscl)
#calculate McFadden's R-squared for model
pR2(model)['McFadden']
 McFadden 
0.4619194
</b>
Notice that this value matches the one calculated earlier.
<h2><span class="orange">The Difference Between glm and lm in R</span></h2>
The programming language R offers the following functions for fitting linear models:
<b>1. lm – Used to fit linear models</b>
This function uses the following syntax:
<b>lm(formula, data, …)</b>
where:
<b>formula:</b> The formula for the linear model (e.g. y ~ x1 + x2)
<b>data:</b> The name of the data frame that contains the data
<b>2. glm – Used to fit generalized linear models</b>
This function uses the following syntax:
<b>glm(formula, family=gaussian, data, …)</b>
where:
<b>formula:</b> The formula for the linear model (e.g. y ~ x1 + x2)
<b>family:</b> The statistical family to use to fit the model. Default is gaussian but other options include binomial, Gamma, and poisson among others.
<b>data:</b> The name of the data frame that contains the data
Note that the only difference between these two functions is the <b>family</b> argument included in the <b>glm()</b> function.
If you use lm() or glm() to fit a linear regression model, <b>they will produce the exact same results</b>.
However, the glm() function can also be used to fit more complex models like:
 Logistic regression  (family=binomial)
 Poisson regression  (family=poisson)
The following examples show how to use the lm() function and glm() function in practice.
<h3>Example of Using the lm() Function</h3>
The following code shows how to fit a <b>linear regression model</b> using the lm() function:
<b>#fit multiple linear regression model
model &lt;- lm(mpg ~ disp + hp, data=mtcars)
#view model summary
summary(model)
Call:
lm(formula = mpg ~ disp + hp, data = mtcars)
Residuals:
    Min      1Q  Median      3Q     Max 
-4.7945 -2.3036 -0.8246  1.8582  6.9363 
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 30.735904   1.331566  23.083  &lt; 2e-16 ***
disp        -0.030346   0.007405  -4.098 0.000306 ***
hp          -0.024840   0.013385  -1.856 0.073679 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 3.127 on 29 degrees of freedom
Multiple R-squared:  0.7482,Adjusted R-squared:  0.7309 
F-statistic: 43.09 on 2 and 29 DF,  p-value: 2.062e-09</b>
<h3>Examples of Using the glm() Function</h3>
The following code shows how to fit the exact same <b>linear regression model</b> using the glm() function:
<b>#fit multiple linear regression model
model &lt;- glm(mpg ~ disp + hp, data=mtcars)
#view model summary
summary(model)
Call:
glm(formula = mpg ~ disp + hp, data = mtcars)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-4.7945  -2.3036  -0.8246   1.8582   6.9363  
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 30.735904   1.331566  23.083  &lt; 2e-16 ***
disp        -0.030346   0.007405  -4.098 0.000306 ***
hp          -0.024840   0.013385  -1.856 0.073679 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for gaussian family taken to be 9.775636)
    Null deviance: 1126.05  on 31  degrees of freedom
Residual deviance:  283.49  on 29  degrees of freedom
AIC: 168.62
Number of Fisher Scoring iterations: 2</b>
Notice that the coefficient estimates and standard errors of the coefficient estimates are the exact same as those produced by the lm() function.
Note that we can also use the glm() function to fit a <b>logistic regression model</b> by specifying family=binomial as follows:
<b>#fit logistic regression model
model &lt;- glm(am ~ disp + hp, data=mtcars, family=binomial)
#view model summary
summary(model)
Call:
glm(formula = am ~ disp + hp, family = binomial, data = mtcars)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.9665  -0.3090  -0.0017   0.3934   1.3682  
Coefficients:
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)  1.40342    1.36757   1.026   0.3048  
disp        -0.09518    0.04800  -1.983   0.0474 *
hp           0.12170    0.06777   1.796   0.0725 .
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 43.230  on 31  degrees of freedom
Residual deviance: 16.713  on 29  degrees of freedom
AIC: 22.713
Number of Fisher Scoring iterations: 8
</b>
We can also use the glm() function to fit a <b>Poisson regression model</b> by specifying family=poisson as follows:
<b>#fit Poisson regression model
model &lt;- glm(am ~ disp + hp, data=mtcars, family=poisson)
#view model summary
summary(model)
Call:
glm(formula = am ~ disp + hp, family = poisson, data = mtcars)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.1266  -0.4629  -0.2453   0.1797   1.5428  
Coefficients:
             Estimate Std. Error z value Pr(>|z|)   
(Intercept)  0.214255   0.593463   0.361  0.71808   
disp        -0.018915   0.007072  -2.674  0.00749 **
hp           0.016522   0.007163   2.307  0.02107 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for poisson family taken to be 1)
    Null deviance: 23.420  on 31  degrees of freedom
Residual deviance: 10.526  on 29  degrees of freedom
AIC: 42.526
Number of Fisher Scoring iterations: 6
</b>
<h2><span class="orange">How to Perform the Goldfeld-Quandt Test in R</span></h2>
The <b>Goldfeld-Quandt test</b> is used to determine if  heteroscedasticity  is present in a regression model.
Heteroscedasticity refers to the unequal scatter of  residuals  at different levels of a  response variable  in a regression model.
If heteroscedasticity is present, this violates one of the key  assumptions of linear regression  that the residuals are equally scattered at each level of the response variable.
This tutorial provides a step-by-step example of how to perform the Goldfeld-Quandt test in R to determine whether or not heteroscedasticity is present in a given regression model.
<h3>Step 1: Build a Regression Model</h3>
First, we’ll build a  multiple linear regression model  using the built-in <b>mtcars</b> dataset in R:
<b>#fit a regression model
model &lt;- lm(mpg~disp+hp, data=mtcars)
#view model summary
summary(model)
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 30.735904   1.331566  23.083  &lt; 2e-16 ***
disp        -0.030346   0.007405  -4.098 0.000306 ***
hp          -0.024840   0.013385  -1.856 0.073679 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 3.127 on 29 degrees of freedom
Multiple R-squared:  0.7482,Adjusted R-squared:  0.7309 
F-statistic: 43.09 on 2 and 29 DF,  p-value: 2.062e-09
</b>
<h3>Step 2: Perform the Goldfeld-Quandt test</h3>
Next, we will use the <b>gqtest()</b> function from the <b>lmtest</b> package to perform the Goldfeld-Quandt test to determine if heteroscedasticity is present.
This function uses the following syntax:
<b>gqtest(model, order.by, data, fraction)</b>
where:
<b>model:</b> The linear regression model created by the lm() command.
<b>order.by:</b> The predictor variable(s) in the model.
<b>data:</b> The name of the dataset.
<b>fraction*:</b> The number of central observations to remove from the dataset.
*The Goldfeld-Quandt test works by removing some number of observations located in the center of the dataset, then testing to see if the spread of residuals is different from the resulting two datasets that are on either side of the central observations.
Typically we choose to remove around 20% of the total observations. In this case, mtcars has 32 total observations so we can choose to remove the central 7 observations:
<b>#load lmtest library
library(lmtest)
#perform the Goldfeld Quandt test
gqtest(model, order.by = ~disp+hp, data = mtcars, fraction = 7)
Goldfeld-Quandt test
data:  model
GQ = 1.0316, df1 = 10, df2 = 9, p-value = 0.486
alternative hypothesis: variance increases from segment 1 to 2
</b>
Here is how to interpret the output:
The test statistic is <b>1.0316</b>.
The corresponding p-value is <b>0.486</b>.
The Goldfeld-Quandt test uses the following null and alternative hypotheses:
<b>Null (H<sub>0</sub>)</b>: Homoscedasticity is present.
<b>Alternative (H<sub>A</sub>):</b> Heteroscedasticity is present.
Since the p-value is not less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that heteroscedasticity is present in the regression model.
<h3>What To Do Next</h3>
If you fail to reject the null hypothesis of the Goldfeld-Quandt test then heteroscedasticity is not present and you can proceed to interpret the output of the original regression.
However, if you reject the null hypothesis, this means heteroscedasticity is present in the data. In this case, the standard errors that are shown in the output table of the regression may be unreliable.
There are a couple common ways that you can fix this issue, including:
<b>1. Transform the response variable.</b>
You can try performing a transformation on the response variable, such as taking  the log, square root, or cube root  of the response variable. Typically this can cause heteroscedasticity to go away.
<b>2. Use weighted regression.</b>
Weighted regression assigns a weight to each data point based on the variance of its fitted value. Essentially, this gives small weights to data points that have higher variances, which shrinks their squared residuals.
When the proper weights are used, weighted regression can eliminate the problem of heteroscedasticity.
<h2><span class="orange">How to Perform the Goldfeld-Quandt Test in Python</span></h2>
The <b>Goldfeld-Quandt test</b> is used to determine if  heteroscedasticity  is present in a regression model.
Heteroscedasticity refers to the unequal scatter of  residuals  at different levels of a  response variable  in a regression model.
If heteroscedasticity is present, this violates one of the key  assumptions of linear regression  that the residuals are equally scattered at each level of the response variable.
This tutorial provides a step-by-step example of how to perform the Goldfeld-Quandt test in Python.
<h2>Step 1: Create the Dataset</h2>
For this example, let’s create the following pandas DataFrame that contains information about hours studied, prep exams taken, and final exam score received by 13 students in some class:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'hours': [1, 2, 2, 4, 2, 1, 5, 4, 2, 4, 4, 3, 6],   'exams': [1, 3, 3, 5, 2, 2, 1, 1, 0, 3, 4, 3, 2],   'score': [76, 78, 85, 88, 72, 69, 94, 94, 88, 92, 90, 75, 96]})
#view DataFrame
print(df)
    hours  exams  score
0       1      1     76
1       2      3     78
2       2      3     85
3       4      5     88
4       2      2     72
5       1      2     69
6       5      1     94
7       4      1     94
8       2      0     88
9       4      3     92
10      4      4     90
11      3      3     75
12      6      2     96</b>
<h2>Step 2: Fit Linear Regression Model</h2>
Next, we’ll fit a multiple linear regression model using <b>hours</b> and <b>exams</b> as the predictor variables and <b>score</b> as the response variable:
<b>import statsmodels.api as sm
#define predictor and response variables
y = df['score']
x = df[['hours', 'exams']]
#add constant to predictor variables
x = sm.add_constant(x)
#fit linear regression model
model = sm.OLS(y, x).fit()
#view model summary
print(model.summary())
            OLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.718
Model:                            OLS   Adj. R-squared:                  0.661
Method:                 Least Squares   F-statistic:                     12.70
Date:                Mon, 31 Oct 2022   Prob (F-statistic):            0.00180
Time:                        09:22:56   Log-Likelihood:                -38.618
No. Observations:                  13   AIC:                             83.24
Df Residuals:                      10   BIC:                             84.93
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         71.4048      4.001     17.847      0.000      62.490      80.319
hours          5.1275      1.018      5.038      0.001       2.860       7.395
exams         -1.2121      1.147     -1.057      0.315      -3.768       1.344
==============================================================================
Omnibus:                        1.103   Durbin-Watson:                   1.248
Prob(Omnibus):                  0.576   Jarque-Bera (JB):                0.803
Skew:                          -0.289   Prob(JB):                        0.669
Kurtosis:                       1.928   Cond. No.                         11.7
==============================================================================
</b>
<h2>Step 3: Perform the Goldfeld-Quandt test</h2>
Next, we will use the <b>het_goldfeldquandt()</b> function from <b>statsmodels</b> to perform the Goldfeld-Quandt test.
<b>Note</b>: The Goldfeld-Quandt test works by removing some number of observations located in the center of the dataset, then testing to see if the spread of residuals is different from the resulting two datasets that are on either side of the central observations.
Typically we choose to remove around 20% of the total observations. In this case, we can use the <b>drop</b> argument to specify that we’d like to remove 20% of observations:
<b>#perform Goldfeld-Quandt test
sm.stats.diagnostic.het_goldfeldquandt(y, x, drop=0.2)
(1.7574505407790355, 0.38270288684680076, 'increasing')</b>
Here is how to interpret the output:
The test statistic is <b>1.757</b>.
The corresponding p-value is <b>0.383</b>.
The Goldfeld-Quandt test uses the following null and alternative hypotheses:
<b>Null (H<sub>0</sub>)</b>: Homoscedasticity is present.
<b>Alternative (H<sub>A</sub>):</b> Heteroscedasticity is present.
Since the p-value is not less than 0.05, we fail to reject the null hypothesis.
We do not have sufficient evidence to say that heteroscedasticity is a problem in the regression model.
<h2>What To Do Next</h2>
If you fail to reject the null hypothesis of the Goldfeld-Quandt test then heteroscedasticity is not present and you can proceed to interpret the output of the original regression.
However, if you reject the null hypothesis, this means heteroscedasticity is present in the data. In this case, the standard errors that are shown in the output table of the regression may be unreliable.
There are a couple common ways that you can fix this issue, including:
<b>1. Transform the response variable.</b>
You can try performing a transformation on the response variable, such as taking  the log, square root, or cube root  of the response variable. Typically this can cause heteroscedasticity to go away.
<b>2. Use weighted regression.</b>
Weighted regression assigns a weight to each data point based on the variance of its fitted value. Essentially, this gives small weights to data points that have higher variances, which shrinks their squared residuals.
When the proper weights are used, weighted regression can eliminate the problem of heteroscedasticity.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Python:
 How to Perform OLS Regression in Python 
 How to Create a Residual Plot in Python 
 How to Perform White’s Test in Python 
 How to Perform a Breusch-Pagan Test in Python 
<h2><span class="orange">What is a “Good” Accuracy for Machine Learning Models?</span></h2>
When using  classification models  in machine learning, one metric we often use to assess the quality of a model is <b>accuracy</b>.
Accuracy is simply the percentage of all observations that are correctly classified by the model.
It is calculated as:
Accuracy = (# True Positives + # True Negatives) / (Total Sample Size)
One question that students often have about accuracy is:
<em><b>What is considered a “good” value for the accuracy of a machine learning model?</b></em>
While the accuracy of a model can range between 0% and 100%, there is no universal threshold that we use to determine if a model has “good” accuracy or not.
<b>Instead, we typically compare the accuracy of our model to the accuracy of some baseline model.</b>
A baseline model is one that simply predicts every observation in a dataset to belong to the most common class.
In practice, any classification model that has a higher accuracy than a baseline model can be considered “useful” but obviously the greater the difference in accuracy between our model and a baseline model, the better.
The following example shows how to roughly determine if a classification model has “good” accuracy or not.
<h2>Example: Determining if a Model Has “Good” Accuracy</h2>
Suppose we use a  logistic regression model  to predict whether or not 400 different college basketball players get drafted into the NBA.
The following  confusion matrix  summarizes the predictions made by the model:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/fscore1.png">
Here is how to calculate the accuracy of this model:
Accuracy = (# True Positives + # True Negatives) / (Total Sample Size)
Accuracy = (120 + 170) / (400)
Accuracy = <b>0.725</b>
The model correctly predicted the outcome for <b>72.5%</b> of players.
To get an idea of whether or not that is accuracy is “good”, we can calculate the accuracy of a baseline model.
In this example, the most common outcome for the players was to not get drafted. Specifically, 240 out of 400 players did not get drafted.
A baseline model would be one that simply predicts every single player to not get drafted.
The accuracy of this model would be calculated as:
Accuracy = (# True Positives + # True Negatives) / (Total Sample Size)
Accuracy = (0 + 240) / (400)
Accuracy = <b>0.6</b>
This baseline model would correctly predict the outcome for <b>60%</b> of players.
In this scenario, our logistic regression model offers a noticeable improvement in accuracy compared to a baseline model so we would consider our model to at least be “useful.”
In practice, we would likely fit several different classification models and choose the final model as the one that offers the greatest boost in accuracy compared to a baseline model.
<h2>Cautions on Using Accuracy to Assess Model Performance</h2>
Accuracy is a commonly used metric because it’s easy to interpret.
For example, if we say that a model is 90% accurate, we know that it correctly classified 90% of observations.
However, accuracy does not take into account how the data is distributed.
For example, suppose 90% of all players do not get drafted into the NBA. If we have a model that simply predicts every player to not get drafted, the model would correctly predict the outcome for 90% of the players.
This value seems high, but the model is actually unable to correctly predict any player who gets drafted.
An alternative metric that is often used is called the <b>F1 Score</b>, which takes into account how the data is distributed.
For example, if the data is highly imbalanced (e.g. 90% of all players do not get drafted and 10% do get drafted) then F1 score will provide a better assessment of model performance.
Read more about the differences between accuracy and F1 score  here .
<h2><span class="orange">What is a Good R-squared Value?</span></h2>
<b>R-squared</b> is a measure of how well a  linear regression model  “fits” a dataset. Also commonly called the <em>coefficient of determination</em>, R-squared is the proportion of the variance in the response variable that can be explained by the predictor variable.
The value for R-squared can range from 0 to 1. A value of 0 indicates that the response variable cannot be explained by the predictor variable at all. A value of 1 indicates that the response variable can be perfectly explained without error by the predictor variable.
In practice, you will likely never see a value of 0 or 1 for R-squared. Instead, you’ll likely encounter some value between 0 and 1.
For example, suppose you have a dataset that contains the population size and number of flower shops in 30 different cities. You fit a simple linear regression model to the dataset, using population size as the predictor variable and flower shops as the response variable. In the output of the regression results, you see that R<sup>2 </sup> = 0.2. This indicates that 20% of the variance in the number of flower shops can be explained by the population size.
This leads to an important question: <b>is this a “good” value for R-squared?</b>
The answer to this question depends on your objective for the regression model. Namely:
<b>1.</b> Are you interested in explaining the relationship between the predictor(s) and the response variable?
<b>OR</b>
<b>2. </b>Are you interested in predicting the response variable?
Depending on the objective, the answer to <em>“What is a good value for R-squared?</em>” will be different.
<h2>Explaining the Relationship Between the Predictor(s) and the Response Variable</h2>
If your main objective for your regression model is to explain the relationship between the predictor(s) and the response variable, the R-squared is mostly irrelevant.
For example, suppose in the regression example from above, you see that the coefficient  for the predictor <em>population size </em>is 0.005 and that it’s statistically significant. This means that an increase of one in population size is associated with an average increase of 0.005 in the number of flower shops in a particular city. Also, population size is a statistically significant predictor of the number of flower shops in a city.
Whether the R-squared value for this regression model is 0.2 or 0.9 doesn’t change this interpretation. Since you are simply interested in the <em>relationship </em>between population size and the number of flower shops, you don’t have to be overly concerned with the R-square value of the model.
<h2>Predicting the Response Variable</h2>
If your main objective is to predict the value of the response variable accurately using the predictor variable, then R-squared is important.
In general, the larger the R-squared value, the more precisely the predictor variables are able to predict the value of the response variable.
How high an R-squared value needs to be depends on how precise you need to be. For example, in scientific studies, the R-squared may need to be above 0.95 for a regression model to be considered reliable. In other domains, an R-squared of just 0.3 may be sufficient if there is extreme variability in the dataset.
To find out what is considered a “good” R-squared value, you will need to explore what R-squared values are generally accepted in your particular field of study. If you’re performing a regression analysis for a client or a company, you may be able to ask them what is considered an acceptable R-squared value.
<h2>Prediction Intervals</h2>
A <b>prediction interval</b> specifies a range where a new observation could fall, based on the values of the predictor variables. Narrower prediction intervals indicate that the predictor variables can predict the response variable with more precision.
Often a prediction interval can be more useful than an R-squared value because it gives you an exact range of values in which a new observation could fall. This is particularly useful if your primary objective of regression is to predict new values of the response variable.
For example, suppose a population size of 40,000 produces a prediction interval of 30 to 35 flower shops in a particular city. This may or may not be considered an acceptable range of values, depending on what the regression model is being used for.
<h2>Conclusion</h2>
In general, the larger the R-squared value, the more precisely the predictor variables are able to predict the value of the response variable.
How high an R-squared value needs to be to be considered “good” varies based on the field. Some fields require higher precision than others. 
To find out what is considered a “good” R-squared value, consider what is generally accepted in the field you’re working in, ask someone with specific subject area knowledge, or ask the client/company you’re performing the regression analysis for what they consider to be acceptable.
If you’re interested in explaining the relationship between the predictor and response variable, the R-squared is largely irrelevant since it doesn’t impact the interpretation of the regression model.
If you’re interested in predicting the response variable, prediction intervals are generally more useful than R-squared values.
<b>Further Reading:</b>
 Pearson Correlation Coefficient 
 Introduction to Simple Linear Regression 
<h2><span class="orange">Google Sheets: How to Add Commas to a Number</span></h2>
The easiest way to add commas to a number in Google Sheets is to use the <b>Number</b> option within the <b>Format</b> tab.
The following step-by-step example shows how to use this option to add commas to a number in Google Sheets.
<h2>Step 1: Enter the Data</h2>
First, let’s enter the following dataset into Google Sheets that shows the total number of sales made by various employees at a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma1.jpg"484">
<h2>Step 2: Add Commas to Numbers</h2>
Next, highlight the cell range <b>B2:B12</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma2.jpg"485">
Next, click the <b>Format</b> tab, then click <b>Number</b>, then click Number:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma3.jpg">
Commas will automatically be added to the values in the <b>Sales</b> column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma4.jpg"485">
Note that within the <b>Number</b> tab, you can also specify that you’d like the values to be formatted as a currency with commas:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma5.jpg"541">
This will add a dollar sign in front of each value and force two decimal places to be shown for each value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/comma6.jpg"490">
Notice that each value in the <b>Sales</b> column is now displayed in a currency format.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Google Sheets:
 How to Use SUMIF Contains in Google Sheets 
 How to Use SUMIF with OR in Google Sheets 
 How to Sum Only Positive Numbers in Google Sheets 
<h2><span class="orange">How to Add Months to Date in Google Sheets (With Examples)</span></h2>
You can use the <b>EDATE()</b> function in Google Sheets to quickly add a certain number of months to a date.
This formula uses the following basic syntax:
<b>EDATE(start_date, months)</b>
where:
<b>start_date</b>: The starting date
<b>months</b>: The number of months to add to the starting date
For example, we can use the following syntax to add 10 months to the date in cell A1:
<b>=EDATE(A1, 10)
</b>
The following example shows how to use this function in practice.
<h2>Example: Add Months to Date in Google Sheets</h2>
Suppose we have the following list of dates in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/months1.jpg"481">
We can use the following formulas to add a specific number of months to the values in the Date column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/months2.jpg">
The values in column B show the value of the original date plus one month.
The values in column C show the value of the original date plus six months.
The values in column D show the value of the original date plus 15 months.
Note that you can also use negative numbers to subtract months from a date.
The following screenshot shows how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/months3-1.jpg">
The values in column B show the value of the original date <b>minus</b> one month.
The values in column C show the value of the original date <b>minus</b> six months.
The values in column D show the value of the original date <b>minus</b> 15 months.
<b>Note</b>: You can find the complete documentation for the <b>EDATE()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Google Sheets:
 How to Add & Subtract Years to Date in Google Sheets 
 How to Filter by Date Range in Google Sheets 
 How to AutoFill Dates in Google Sheets 

<script src='https://williamkpchan.github.io/LibDocs/readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>
