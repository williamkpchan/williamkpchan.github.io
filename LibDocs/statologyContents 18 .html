<base target="_blank"><html><head><title>statologyContents 18</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://williamkpchan.github.io/lazyload.min.js"></script>
<script src='https://williamkpchan.github.io/mainscript.js'></script>
<script src="https://williamkpchan.github.io/commonfunctions.js"></script>
<script>
  var showTopicNumber = true;
  var topicEnd = "<br>";
  var bookid = "statologyContents 18"
  var markerName = "h2, h3"
</script>
<style>
body{width:70%;margin-left: 15%; font-size:20px;}
h1, h2 {color: gold;}
strong {color: orange;}
b {color: brown;}
img {max-width:60%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>statologyContents 18</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a><br><br>
<div id="toc"></div></center><br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br></div>
<pre><br><br>
<h2><span class="orange">How to Use IF-THEN-ELSE in SAS (With Examples)</span></h2>
You can use an <b>IF-THEN-ELSE </b>statement in SAS to return some value <em>if</em> some condition is true, <em>else</em> return another value if some condition is not true.
This statement uses the following basic syntax:
<b>if var1 > 30 then var2 = 'good';
else var2 = 'bad';
</b>
You can also chain together several <b>ELSE IF</b> statements to return more potential values based on more conditions:
<b>if var1 > 35 then var2 = 'great';
else if var1 > 30 then var2 = 'good';
else var2 = 'bad';
</b>
The following examples show how to use each of these statements in practice with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points;
    datalines;
Cavs 12
Cavs 14
Warriors 15
Hawks 18
Mavs 31
Mavs 32 
Mavs 35
Celtics 36
Celtics 40
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/ifthen1.jpg"181">
<h2>Example 1: <b>IF-THEN-ELSE in SAS</b></h2>
We can use the following <b>IF-THEN-ELSE</b> statement to create a new variable called <b>rating</b> that takes on a value of “good” if the value in the <b>points</b> column is greater than 30 or a value of “bad” otherwise:
<b>/*create new dataset with new variable called rating*/
data new_data;
    set original_data;
    if points > 30 then rating = 'good';
    else rating = 'bad';
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/ifthen2.jpg"237">
Notice that the new column called <b>rating</b> takes on a value of “good” if the value in the <b>points</b> column is greater than 30 or a value of “bad” otherwise.
<h2>Example 2: <b>IF-THEN-ELSE IF in SAS</b></h2>
We can use the following <b>IF-THEN-ELSE IF</b> statement to create a new variable called <b>rating</b> that takes on the following values:
“great” if points is greater than 35
else, “good” if points is greater than 30
else, “bad”
The following code shows how to do so:
<b>/*create new dataset with new variable called rating*/
data new_data;
    set original_data;
    if points > 35 then rating = 'great';
    else if points > 30 then rating = 'good';
    else rating = 'bad';
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/ifthen3.jpg"256">
The new column called <b>rating</b> takes on a value of “great”, “good”, or “bad” based on the corresponding value in the <b>points</b> column.
<b>Note</b>: Feel free to use as many <b>ELSE IF</b> statements as you’d like to return as many different values as you’d like based on various conditions.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use IF-THEN-DO in SAS 
 How to Remove Duplicates in SAS 
 How to Replace Missing Values with Zero in SAS 
<h2><span class="orange">How to Import CSV Files into SAS (With Examples)</span></h2>
You can use <b>proc import </b>to quickly import data from a CSV file into SAS.
This procedure uses the following basic syntax:
<b>/*import data from CSV file called my_data.csv*/
proc import out=my_data
    datafile="/home/u13181/my_data.csv"
    dbms=csv
    replace;
    getnames=YES;
run;</b>
Here’s what each line does:
<b>out</b>: Name to give dataset once imported into SAS
<b>datafile</b>: Location of CSV file to import
<b>dmbs</b>: Format of file being imported
<b>replace</b>: Replace the file if it already exists
<b>getnames</b>: Use first row as variable names (Set to NO if first row does not contain variable names)
The following examples show how to use this function in practice.
<b>Related:</b>  How to Import Excel Files into SAS 
<h3>Example 1: Import Data from CSV File into SAS</h3>
Suppose we have the following CSV file called <b>my_data.csv</b>: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/csv3.jpg"391">
We can use the following code to import this dataset into SAS and call it <b>new_data</b>:
<b>/*import data from CSV file called my_data.csv*/
proc import out=new_data
    datafile="/home/u13181/my_data.csv"
    dbms=csv
    replace;
    getnames=YES;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/export11.jpg"136">
The data shown in the SAS output matches the data shown in the CSV file.
<b>Note</b>: We used <b>getnames=YES</b> when importing the file since the first row of the CSV file contained variable names.
<h3>Example 2: Import Data from CSV File into SAS with No Header and Custom Delimiter</h3>
Suppose we have the following CSV file called <b>data.csv</b>: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/csv12.jpg"414">
Notice that this file has no header row and the values are separated by semi-colons instead of commas.
We can use the following code to import this dataset into SAS and call it <b>new_data</b>:
<b>/*import data from CSV file called data.csv*/
proc import out=new_data
    datafile="/home/u13181/data.csv"
    dbms=csv
    replace;
    delimiter=";";
    getnames=NO;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/csv4.jpg"204">
The data shown in the SAS output matches the data shown in the CSV file.
By default, SAS provides the variable names as VAR1, VAR2, and VAR3.
<h2><span class="orange">How to Import Excel Files into SAS (With Example)</span></h2>
You can use <b>proc import </b>to quickly import data from an Excel file into SAS.
This procedure uses the following basic syntax:
<b>/*import data from Excel file called my_data.xlsx*/
proc import out=my_data
    datafile="/home/u13181/my_data.xlsx"
    dbms=xlsx
    replace;
    getnames=YES;
run;</b>
Here’s what each line does:
<b>out</b>: Name to give dataset once imported into SAS
<b>datafile</b>: Location of Excel file to import
<b>dmbs</b>: Format of file being imported
<b>replace</b>: Replace the file if it already exists
<b>getnames</b>: Use first row as variable names (Set to NO if first row does not contain variable names)
The following example shows how to use this function in practice.
<h3>Example: Import Data from Excel File into SAS</h3>
Suppose we have the following dataset in Excel: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/excel11.jpg"458">
We can use the following code to import this dataset into SAS and call it <b>new_data</b>:
<b>/*import data from Excel file called my_data.xlsx*/
proc import out=new_data
    datafile="/home/u13181/my_data.xlsx"
    dbms=xlsx
    replace;
    getnames=YES;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/export11.jpg"136">
The data shown in the SAS output matches the data shown in the Excel file.
<b>Note</b>: We used <b>getnames=YES</b> when importing the file since the first row of the Excel file contained variable names.
<h2><span class="orange">How to Use the INDEX Function in SAS (With Examples)</span></h2>
You can use the <b>INDEX </b>function in SAS to return the position of the first occurrence of a string within another character string.
This function uses the following basic syntax:
<b>INDEX(source, excerpt)</b>
where:
<b>source</b>: The string to analyze
<b>excerpt</b>: The string of characters to search for within <em>source</em>
The following example shows how to use this function in practice.
<h2>Example: Using the INDEX Function in SAS</h2>
Suppose we have the following dataset in SAS that contains a column of names:
<b>/*create dataset*/
data original_data;
    input name $25.;
    datalines;
Andy Lincoln Bernard
Barren Michael Smith
Chad Simpson Arnolds
Derrick Smith Henrys
Eric Millerton Smith
Frank Giovanni Goode
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/index1.jpg"210">
We can use the <b>INDEX</b> function to search for the position of the first occurrence of the string “Smith” in each row:
<b>/*find position of first occurrence of 'Smith' in name*/
data new_data;
    set original_data;
    first_smith = index(name, 'Smith');
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/index2.jpg"311">
The new column called <b>first_smith</b> displays the position of the first occurrence of the string ‘Smith’ in the <b>name</b> column.
If ‘Smith’ is not found at all, the <b>INDEX</b> function simply returns a value of <b>0</b>.
It’s important to note that the <b>INDEX</b> function is case-sensitive, so if you search for ‘smith’ instead, the <b>INDEX</b> function will return <b>0</b> for each string:
<b>/*find position of first occurrence of 'smith' in name*/
data new_data;
    set original_data;
    first_smith = index(name, 'smith');
run;
/*view results*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/index3.jpg"311">
To perform a case-insensitive search, you can use the  lowcase()  function to first convert each string to all lowercase and then search for ‘smith’ as follows:
<b>/*find position of first occurrence of 'smith' in name*/
data new_data;
    set original_data;
    first_smith = index(lowcase(name), 'smith');
run;
/*view results*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/index2.jpg"305">
By first converting each string to all lowercase, we’re able to use the <b>INDEX</b> function to perform a case-insensitive search.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in SAS:
 How to Use the SUBSTR Function in SAS 
 How to Use the COMPRESS Function in SAS 
 How to Use the FIND Function in SAS 
 How to Use the COALESCE Function in SAS 
<h2><span class="orange">How to Perform an Inner Join in SAS (With Example)</span></h2>
You can use the following basic syntax to perform an inner join with two datasets in SAS:
<b>proc sql;
    create table final_table as
    select * from data1 as x join data2 as y
    on x.ID = y.ID;
quit;</b>
The following example shows how to use this syntax in practice.
<b>Related:</b>  How to Perform a Left Join in SAS 
<h3>Example: Inner Join in SAS</h3>
Suppose we have the following two datasets in SAS:
<b>/*create datasets*/
data data1;
    input team $ points;
    datalines;
Mavs 99
Spurs 93
Rockets 88
Thunder 91
Warriors 104
Cavs 93
Nets 90
Hawks 91
;
run;
data data2;
    input team $ rebounds;
    datalines;
Mavs 21
Spurs 18
Warriors 27
Hawks 29
Knicks 40
Raptors 30
;
run;
/*view datasets*/
proc print data=data1;
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/innersas1.jpg"209">
Notice that the two datasets share one variable in common: <b>team</b>.
We will use the following syntax to perform an inner join and create a new dataset that contains only the rows in which the <b>team</b> variable shows up in both datasets:
<b>/*perform inner join*/
proc sql;
create table final_table as
select * from data1 as x join data2 as y
on x.team = y.team;
quit;
/*view results of inner join*/
proc print data=final_table;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/innersas2.jpg"256">
The resulting dataset contains only the rows in which the <b>team</b> variable appeared in both datasets.
If you refer to the two datasets from earlier, you’ll notice that there are only four teams that appear in both datasets: Mavs, Spurs, Warriors, and Hawks.
Since we chose to join the two datasets on the <b>team</b> variable, these are the four teams that also appear in the final dataset.
<h2><span class="orange">How to Use INTNX Function in SAS (With Examples)</span></h2>
You can use the <b>INTNX</b> function in SAS to increment a date by a specific interval such as a day, week, month, etc.
This function uses the following basic syntax:
<b>INTNX(interval, start_date, increment)</b>
where:
<b>interval</b>: The interval to add to date (day, week, month, year, etc.)
<b>start_date</b>: Variable that contains start dates
<b>increment</b>: The number of intervals to add
To subtract an interval, supply a negative number to the <b>increment</b> argument.
The following examples show some common ways to use the <b>INTNX</b> function in practice with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    format date date9.;
    input date :date9. sales;
    datalines;
01JAN2022 50
01FEB2022 34
14MAR2022 26
01MAY2022 22
24AUG2022 27
28OCT2022 48
14NOV2022 97
04DEC2022 88
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/intnx1.jpg"199">
<h2>Example 1: Use INTNX to Add Days to Date</h2>
We can use the <b>INTNX</b> function to create a new column called <b>plus5days</b> that adds five days to each date in the <b>date</b> column:
<b>/*create new dataset with column that adds 5 days to date*/
data new_data;
    set original_data;
    plus5days=intnx('day', date, 5);
    format plus5days date9.;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/intnx2.jpg"289">
Notice that the new column called <b>plus5days </b>contains the values in the <b>date</b> column with fives days added to them.
<h2>Example 2: Use INTNX to Subtract Days from Date</h2>
You can also subtract days by simply using a negative value in the <b>INTNX</b> function.
For example, we can use the following code to subtract five days from each value in the <b>date</b> column:
<b>/*create new dataset with column that subtracts 5 days from date*/
data new_data;
    set original_data;
    minus5days=intnx('day', date, -5);
    format minusdays date9.;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/intnx3.jpg"284">
Notice that the new column called <b>minus5days </b>contains the values in the <b>date</b> column with fives days subtracted from them.
<h2>Example 3: Use INTNX to Find First Day of Month</h2>
We can use the <b>INTNX</b> function to create a new column called <b>firstmonth </b>that contains the first day of the month for each date in the <b>date</b> column:
<b>/*create new dataset with column that contains first day of the month*/
data new_data;
    set original_data;
    <b>firstmonth</b>=intnx('month', date, 0);
    format <b>firstmonth </b>date9.;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/intnx4.jpg"295">
Notice that the new column called <b>firstmonth </b>contains the first day of the month for each date in the <b>date</b> column.
<h2>Example 4: Use INTNX to Find First Day of Year</h2>
We can also use the <b>INTNX</b> function to create a new column called <b>firstyear </b>that contains the first day of the year for each date in the <b>date</b> column:
<b>/*create new dataset with column that contains first day of the year*/
data new_data;
    set original_data;
    <b>firstyear</b>=intnx('year', date, 0);
    format <b>firstyear </b>date9.;
run;
/*view dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/intnx5.jpg"287">
Notice that the new column called <b>firstyear </b>contains the first day of the year for each date in the <b>date</b> column.
<b>Note</b>: You can find the complete documentation for the SAS <b>INTNX</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Convert Datetime to Date in SAS 
 How to Convert Numeric Variable to Date in SAS 
 How to Calculate Difference Between Two Dates in SAS 
<h2><span class="orange">SAS: How to Select Observations Which are Not Null</span></h2>
You can use the following basic syntax to select observations in a dataset in SAS where a certain column value is not null:
<b>/*select only rows where var1 is not null*/
proc sql;
select *
from my_data1
where not missing(var1);
quit;</b>
The following example shows how to use this syntax in practice.
<h3>Example: Select Observations Which are Not Null in SAS</h3>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data1;
    input team $ points;
    datalines;
A 15
B .
C 22
D 19
E 29
F .
G 40
H 35
;
run;
/*view dataset*/
proc print data=my_data1;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/null1.jpg"151">
Notice that there are some null values in the <b>points</b> column.
We can use the following code to select all of the rows where the value in the <b>points</b> column is not null:
<b>/*select only rows where points is not blank*/
proc sql;
select *
from my_data1
where not missing(points);
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/null2.jpg"123">
Notice that only the rows where the value in the <b>points</b> column is not null are returned.
Note that you could also use the <b>count()</b> function in<b> proc sql</b> to count the number of observations where the value in the <b>points</b> column is not null:
<b>/*count rows where points is not blank*/
proc sql;
select count(*)
from my_data1
where not missing(points);
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/null3.jpg"41">
This tells us that 6 observations in the dataset have a value that is not null in the <b>points</b> column.
<h2><span class="orange">SAS: How to Use the KEEP and DROP Statements</span></h2>
You can use the <b>KEEP</b> and <b>DROP</b> statements in SAS when creating a new dataset to keep or drop specific variables from an existing dataset.
These statements use the following basic syntax:
<b>Method 1: Choose Which Columns to KEEP</b>
<b>data new_data;
    set original_data;
    keep var1 var3;
run;
</b>
<b>Method 2: Choose Which Columns to DROP</b>
<b>data new_data;
    set original_data;
    drop var5;
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
Warriors 25 8
Wizards 18 12
Rockets 22 6
Celtics 24 11
Thunder 27 14
Spurs 33 19
Nets 31 20
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/subset3.jpg"253">
<h3>Example 1: <b>Choose Which Columns to KEEP</b></h3>
The following code shows how to create a new dataset in SAS by using the <b>KEEP</b> statement to only keep the <b>team</b> and <b>rebounds</b> variables from the original dataset:
<b>/*create new dataset*/
data new_data;
    set original_data;
    keep team rebounds;
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/keepdrop1.jpg"199">
Notice that we kept the <b>team</b> and <b>rebounds</b> variables from the original dataset and any other variables were simply dropped.
<h3>Example 2: <b>Choose Which Columns to DROP</b></h3>
The following code shows how to create a new dataset in SAS by using the <b>DROP </b>statement to drop the <b>rebounds</b> variable from the original dataset:
<b>/*create new dataset*/
data new_data;
    set original_data;
    drop rebounds;
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/keepdrop2.jpg"191">
Notice that the <b>rebounds</b> variable was dropped from the dataset while all other variables from the original dataset were kept.
<h3>KEEP vs. DROP: Which Statement Should You Use?</h3>
The <b>KEEP</b> and <b>DROP</b> statements accomplish the same outcome: They both allow you to create a new dataset by keeping or dropping certain variables from an existing dataset.
Typically we use the <b>KEEP</b> statement when we only want to keep a few variables from the original dataset since this is faster than typing out all of the variables we’d like to drop.
Conversely, we typically use the <b>DROP</b> statement when we only want to drop a few variables from the original dataset since this is faster than typing out all of the variables we’d like to keep.
<h2><span class="orange">How to Label Variables in SAS (With Example)</span></h2>
You can use the <b>label</b> function in SAS to provide label names to variables in a dataset.
The following example shows how to use this function in practice.
<h3>Example: Label Variables in SAS</h3>
Suppose we create the following dataset in SAS:
<b>/*create dataset*/
data data1;
    input ID $ x y;
    datalines;
Mavs 99 21
Spurs 93 18
Rockets 88 27
Thunder 91 29
Warriors 104 40
Cavs 93 30
;
run;
/*view contents of dataset*/
proc contents data=data1;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/labelsas0.jpg"291">
The output of the <b>proc contents</b> function shows us the name, data type, and length of each of the three variables in our dataset.
However, it might not be obvious what <b>ID</b>, <b>x</b>, and <b>y</b> actually refer to in the dataset.
Fortunately, we can use the <b>label</b> function when creating the dataset to provide specific labels for each variable:
<b>/*create dataset*/
data data1;
    input ID $ x y;
    label ID = 'Team' x = 'Points' y = 'Rebounds';
    datalines;
Mavs 99 21
Spurs 93 18
Rockets 88 27
Thunder 91 29
Warriors 104 40
Cavs 93 30
;
run;
/*view contents of dataset*/
proc contents data=data1;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/labelsas1.jpg">
Notice that the output of <b>proc contents</b> now contains an extra column called <b>label</b>, which contains the labels for the three variables that we specified.
<h2><span class="orange">How to Use the LAG Function in SAS (With Examples)</span></h2>
You can use the <b>LAG</b> function in SAS to retrieve lagged values of some variable.
This function uses the following basic syntax:
<b>lag1_value = lag(value);
</b>
By default, <b>lag</b> finds the previous value of some variable.
However, you can use <b>lag2</b>, <b>lag3</b>, <b>lagn</b>, etc. to calculate the 2-lagged, 3-lagged, n-lagged, etc. values of some variable.
The following examples show how to use the lag function in practice.
<h3>Example 1: <b>Calculated Lagged Values for Some Variable</b></h3>
Suppose we have the following dataset in SAS that shows the total sales made by some store on consecutive days:
<b>/*create dataset*/
data original_data;
    input day $ sales;
    datalines;
1 14
2 19
3 22
4 20
5 16
6 26
7 40
8 43
9 29
10 30
11 35
12 33
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/lagsas1.jpg"141">
The following code shows how to calculate the value for sales lagged by 1, 2, and 3 days:
<b>/*create new dataset that shows lagged values of sales*/
data new_data;
    set original_data;
    lag1_sales = lag(sales);
    lag2_sales = lag2(sales);
    lag3_sales = lag3(sales);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/lagsas2.jpg">
The three new columns (lag1_sales, lag2_sales, lag3_sales) show the sales lagged by one, two, and three days, respectively.
<h3>Example 2: <b>Calculated Lagged Values by Group</b></h3>
Suppose we have the following dataset in SAS that shows the total sales made by two stores during consecutive days:
<b>/*create dataset*/
data original_data;
    input store $ sales;
    datalines;
A 14
A 19
A 22
A 20
A 16
A 26
B 40
B 43
B 29
B 30
B 35
B 33
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/lagsas3.jpg"146">
We can use the following code to calculate the 1-day lagged sales values by store:
<b>/*create new dataset that shows lagged values of sales by store*/
data new_data;
set original_data;
by store;
lag1_sales = lag(sales);
if first.store then lag1_sales = .;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/lagsas4.jpg">
The values in the <b>lag1_sales</b> column show the 1-day lagged sales values for each store.
Notice that the value for <b>lag1_sales</b> in row 7 is empty because the 1-day lagged value for that row represents a sales value for a different store.
<h2><span class="orange">How to Perform a Left Join in SAS (With Example)</span></h2>
You can use the following basic syntax to perform a left join with two datasets in SAS:
<b>proc sql;
    create table final_table as
    select * from data1 as x left join data2 as y
    on x.ID = y.ID;
quit;</b>
The following example shows how to use this syntax in practice.
<b>Related:</b>  How to Perform an Inner Join in SAS 
<h3>Example: Left Join in SAS</h3>
Suppose we have the following two datasets in SAS:
<b>/*create datasets*/
data data1;
    input team $ points;
    datalines;
Mavs 99
Spurs 93
Rockets 88
Thunder 91
Warriors 104
Cavs 93
Grizzlies 90
Hawks 91
;
run;
data data2;
    input team $ rebounds;
    datalines;
Mavs 21
Spurs 18
Rockets 22
Warriors 27
Cavs 15
Hawks 29
;
run;
/*view datasets*/
proc print data=data1;
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/leftsas1.jpg"225">
Notice that the two datasets share one variable in common: <b>team</b>.
We will use the following syntax to perform a left join and create a new dataset that contains every row from <b>data1</b> and <em>only</em> the rows from <b>data2</b> that match a team name in <b>data1</b>:
<b>/*perform left join*/
proc sql;
create table final_table as
select * from data1 as x left join data2 as y
on x.team = y.team;
quit;
/*view results of left join*/
proc print data=final_table;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/leftsas2.jpg"249">
The resulting dataset contains every original team from <b>data1</b>, but the only teams that have values for the <b>rebounds</b> column are the ones that also appeared in <b>data2</b>.
<h2><span class="orange">How to Use the LENGTH Function in SAS (With Examples)</span></h2>
You can use the <b>LENGTH </b>function in SAS to calculate the length of character variables, excluding trailing blanks.
This function uses the following basic syntax:
<b>LENGTH(expression)</b>
where:
<b>expression</b>: The character string to analyze
The following example shows how to use this function in practice.
<h2>Example: Using the LENGTH Function in SAS</h2>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $1-21 points;
    datalines;
Golden State Warriors 99
Brooklyn Nets         101
Utah Jazz             105
Cleveland Cavs        100
Atlanta Hawks         109
Milwaukee Bucks       98
Miami Heat            93
Houston Rockets       100
Los Angeles Lakers    112
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/length1.jpg"253">
We can use the <b>LENGTH </b>function to calculate the length of each string in the team column:
<b>/*calculate length of each string in team column*/
data new_data;
    set original_data;
    team_length = length(team);
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/length2.jpg">
The new column called <b>team_length </b>displays the length of each string in the <b>team</b> column.
For example:
The string “Golden State Warriors” has a length of <b>21</b>.
The string “Brooklyn Nets” has a length of <b>13</b>.
The string “Utah Jazz” has a length of <b>9</b>.
The string “Cleveland Cavs” has a length of <b>14</b>.
And so on.
Note that the <b>LENGTH</b> function counts spaces in between words as characters, but it does not count any trailing blank spaces as characters.
If you would like to calculate the length of a character variable <em>including</em> trailing blanks, use the  LENGTHC  function instead.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in SAS:
 How to Use the SUBSTR Function in SAS 
 How to Use the COMPRESS Function in SAS 
 How to Use the FIND Function in SAS 
 How to Use the COALESCE Function in SAS 
<h2><span class="orange">How to Use the MAX Function in SAS (With Examples)</span></h2>
You can use the <b>MAX</b> function in SAS to find the largest value in a list of values.
Here are the two most common ways to use this function:
<b>Method 1: Find Max Value of One Column in Dataset</b>
<b>proc sql;
    select max(var1)
    from my_data;
quit;
</b>
<b>Method 2: Find Max Value of One Column Grouped by Another Column in Dataset</b>
<b>proc sql;
    select var2, max(var1)
    from my_data;
    group by var2;
quit;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
A 12
A 14
A 19
A 23
A 20
A 11
A 14
B 20
B 21
B 29
B 14
B 19
B 17
B 30
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmin1.jpg"158">
<b>Note</b>: The <b>MAX</b> function automatically ignores missing values when calculating the max value of a list.
<h2>Example 1: <b>Find Max Value of One Column in Dataset</b></h2>
The following code shows how to calculate the max value in the <b>points</b> column of the dataset:
<b>/*calculate max value of points*/
proc sql;
    select max(points)
    from my_data;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmax1.jpg"65">
We can see that <b>proc sql</b> returns a table with a value of 30.
This represents the max value in the <b>points</b> column.
<h2>Example 2: <b>Find Max Value of One Column Grouped by Another Column</b></h2>
The following code shows how to calculate the max value in the <b>points</b> column, grouped by the <b>team</b> column in the dataset:
<b>/*calculate max value of points grouped by team*/
proc sql;
    select team, max(points)
    from my_data;
    group by team;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmax2.jpg"102">
From the output we can see:
The max points value for team A is <b>11</b>.
The max points value for team B is <b>14</b>.
<b>Note</b>: You can find the complete documentation for the <b>MAX</b> function in SAS  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Calculate Z-Scores in SAS 
 How to Use Proc Summary in SAS 
 How to Calculate Mean, Median, & Mode in SAS 
<h2><span class="orange">How to Calculate the Mean by Group in SAS</span></h2>
You can use the following methods to calculate the mean of values by group in SAS:
<b>Method 1: Calculate Mean by One Group</b>
<b>proc sql;
    select var1, mean(var2) as mean_var2
    from my_data
    group by var1;
quit;
</b>
<b>Method 2: Calculate Mean by Multiple Groups</b>
<b>proc sql;
    select var1, var2, mean(var3) as mean_var3
    from my_data
    group by var1, var2;
quit;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 15
A Guard 12
A Guard 29
A Forward 13
A Forward 9
A Forward 16
B Guard 25
B Guard 20
B Guard 34
B Forward 19
B Forward 3
B Forward 8
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sasSum1.jpg"216">
<h2>Example 1: Calculate Mean by One Group</h2>
The following code shows how to calculate the mean of points by team:
<b>/*calculate mean of points by team*/
proc sql;
    select team, mean(points) as mean_points
    from my_data
    group by team;
quit;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/meansas1.jpg"158">
From the output we can see that players on team A scored a mean of <b>15.66667 </b>points and players on team B scored a mean of <b>18.16667 </b>points.
<h2>Example 2: Calculate Mean by Multiple Groups</h2>
The following code shows how to calculate the mean of points, group by team and position:
<b>/*calculate mean of points, grouped by team and position*/
proc sql;
    select team, position, mean(points) as mean_points
    from my_data
    group by team, position;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/meansas2.jpg"220">
The resulting table shows the mean of points scored by players based on their team and position.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Count Observations by Group in SAS 
 How to Calculate the Sum by Group in SAS 
 How to Create Frequency Tables in SAS 
<h2><span class="orange">How to Use the MIN Function in SAS (With Examples)</span></h2>
You can use the <b>MIN</b> function in SAS to find the smallest value in a list of values.
Here are the two most common ways to use this function:
<b>Method 1: Find Minimum Value of One Column in Dataset</b>
<b>proc sql;
    select min(var1)
    from my_data;
quit;
</b>
<b>Method 2: Find Minimum Value of One Column Grouped by Another Column in Dataset</b>
<b>proc sql;
    select var2, min(var1)
    from my_data;
    group by var2;
quit;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
A 12
A 14
A 19
A 23
A 20
A 11
A 14
B 20
B 21
B 29
B 14
B 19
B 17
B 30
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmin1.jpg"158">
<b>Note</b>: The <b>MIN</b> function automatically ignores missing values when calculating the minimum value of a list.
<h2>Example 1: <b>Find Minimum Value of One Column in Dataset</b></h2>
The following code shows how to calculate the minimum value in the <b>points</b> column of the dataset:
<b>/*calculate minimum value of points*/
proc sql;
    select min(points)
    from my_data;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmin2.jpg"62">
We can see that <b>proc sql</b> returns a table with a value of 11.
This represents the minimum value in the <b>points</b> column.
<h2>Example 2: <b>Find Minimum Value of One Column Grouped by Another Column</b></h2>
The following code shows how to calculate the minimum value in the <b>points</b> column, grouped by the <b>team</b> column in the dataset:
<b>/*calculate minimum value of points grouped by team*/
proc sql;
    select team, min(points)
    from my_data;
    group by team;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sasmin3.jpg"101">
From the output we can see:
The minimum points value for team A is <b>11</b>.
The minimum points value for team B is <b>14</b>.
<b>Note</b>: You can find the complete documentation for the <b>MIN</b> function in SAS  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Calculate Z-Scores in SAS 
 How to Use Proc Summary in SAS 
 How to Calculate Mean, Median, & Mode in SAS 
<h2><span class="orange">How to Calculate a Moving Average in SAS</span></h2>
In statistics, a <b>moving average</b> represents the average of the previous <em>n</em> values in a dataset.
The easiest way to calculate a moving average in SAS is to use the <b>proc expand</b> statement.
The following example shows how to use this statement in practice.
<h2>Example: Calculate a Moving Average in SAS</h2>
Suppose we create the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input time values;
    datalines;
1 7
2 12
3 14
4 12
5 16
6 18
7 11
8 10
9 14
10 17
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/masa1.jpg"163">
Now suppose we would like to calculate a 3-period moving average for the <b>values</b> column.
We can use <b>proc expand </b>to do so:
<b>/*calculate 3-period moving average for values*/
proc expand data=original_data out=out_data method=none;
    id time;
    convert values = values_ma3 / transout=(movave 3);
run;
/*view results*/
proc print data=out_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/masa2.jpg"256">
The new column called <b>values_ma3</b> displays the 3-period moving average for the <b>values</b> column.
For example, the third value in the <b>values_ma3</b> column represents the average of the previous 3 periods:
Moving Average = (7+12+14) / 3 = <b>11.0000</b>
The fourth value in the <b>values_ma3</b> column represents the average of the previous 3 periods as well:
Moving Average = (12+14+12) / 3 = <b>12.6667</b>
And so on.
To calculate the moving average for a different number of periods, simply change the value after <b>movave</b> in the code.
For example, we could use the following code to calculate a 4-period moving average for the <b>values</b> column:
<b>/*calculate 4-period moving average for values*/
proc expand data=original_data out=out_data method=none;
    id time;
    convert values = values_ma4 / transout=(movave 4);
run;
/*view results*/
proc print data=out_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/masa3.jpg"264">
The new column called <b>values_ma4</b> displays the 4-period moving average for the <b>values</b> column.
<h2>Additional Resources</h2>
The following articles explain how to perform other common tasks in SAS:
 How to Identify Outliers in SAS 
 How to Calculate Percentiles in SAS 
 How to Calculate Mean, Median, & Mode in SAS 
<h2><span class="orange">SAS: How to Use a “NOT IN” Operator</span></h2>
You can use the <b>NOT IN </b>operator in SAS to return only the rows where a variable does not have a value in some list of values.
The following example shows how to use the <b>NOT IN </b>operator in practice.
<h2>Example: Using NOT IN Operator in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
Cavs 12
Cavs 14
Warriors 15
Hawks 18
Mavs 31
Mavs 32
Mavs 35
Celtics 36
Celtics 40
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like1.jpg"187">
We can use the <b>NOT IN </b>operator in <b>PROC SQL</b> to select only the rows where the team is not equal to ‘Cavs’ or ‘Celtics’:
<b>/*select all rows where team is not 'Cavs' or 'Celtics'*/ 
proc sql;
   select *
   from my_data
   where team not in ('Cavs', 'Celtics');
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/notin1.jpg"152">
Notice that the only rows returned are the ones where the team is not equal to ‘Cavs’ or ‘Celtics.’
You can also use the <b>NOT IN</b> operator within a <b>SET </b>statement to create a new dataset that only contains rows where the team is not equal to ‘Cavs’ or ‘Celtics’:
<b>/*create new dataset that only contains rows where team is not Cavs or Celtics*/
data new_data;
    set my_data;
    where team not in ('Cavs', 'Celtics');
run;
/*view new dataset*/
proc print data=new_data; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/notin2.jpg"212">
The new dataset called <b>new_data</b> only contains the rows from the original dataset where the team is not equal to ‘Cavs’ or ‘Celtics.’
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use LIKE Operator in PROC SQL 
 SAS: How to Use the WHERE Operator in PROC SQL 
<h2><span class="orange">How to Identify Outliers in SAS (With Example)</span></h2>
An <b>outlier</b> is an observation that lies abnormally far away from other values in a dataset. Outliers can be problematic because they can affect the results of an analysis.
The most common way to identify outliers in a dataset is by using the interquartile range.
The interquartile range (IQR) is the difference between the 75th percentile (Q3) and the 25th percentile (Q1) in a dataset. It measures the spread of the middle 50% of values.
We typically define an observation to be an outlier if it is 1.5 times the interquartile range greater than the third quartile (Q3) or 1.5 times the interquartile range less than the first quartile (Q1).
<b>Outliers = Observations > Q3 + 1.5*IQR  or &lt; Q1 – 1.5*IQR</b>
The following example shows how to use this formula to identify outliers in a dataset in SAS.
<h3>Example: Identifying Outliers in SAS</h3>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points;
    datalines;
A 18
B 24
C 26
D 34
E 38
F 45
G 48
H 54
I 60
J 73
K 79
L 85
M 94
N 98
O 221
P 223
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/outlier1.jpg"141">
The easiest way to identify outliers in SAS is by creating a boxplot, which automatically uses the formula mentioned earlier to identify and display outliers in the dataset as tiny circles:
<b>/*create boxplot to visualize distribution of points*/
ods output sgplot=boxplot_data;
proc sgplot data=original_data;
    vbox points;
run;
/*view summary of boxplot descriptive statistics*/
proc print data=boxplot_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/outlier2.jpg"473">
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/outlier3.jpg"312">
From the boxplot we can see that there are two tiny circles near the top of the plot. This indicates that there are two outliers.
From the table below the boxplot we can see the  exact values for the two outliers: <b>221</b> and <b>223</b>.
We can manually verify that these two values are outliers by using the formula from earlier:
<b>Outliers = Observations > Q3 + 1.5*IQR  or &lt; Q1 – 1.5*IQR</b>
The interquartile range is: Q3 – Q1 = 89.5 – 36 = 53.5.
The upper limit for outliers would be: Q3 + 1.5*IQR = 89.5 + 1.5*53.5 = 169.75.
Since <b>221</b> and <b>223</b> are both greater than this value, they are classified as outliers.
We could then use the following code to remove these two outliers from the dataset if we’d like:
<b>/*create new dataset with outliers removed*/
data new_data;
    set original_data;
    if points >= 221 then delete;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/outlier4.jpg"150">
Notice that the two outliers have been removed.
<h2><span class="orange">How to Calculate Percentiles in SAS (With Examples)</span></h2>
Here are the three most common ways to calculate the percentiles of a dataset in SAS:
<b>Method 1: Calculate One Specific Percentile Value</b>
<b>/*calculate 70th percentile value for var1*/
proc univariate data=original_data;
    var var1;
    output out=percentile_data
    pctlpts = 70
    pctlpre = P_;
run;
</b>
<b>Method 2: Calculate Multiple Specific Percentile Values</b>
<b>/*calculate 70th, 80th, and 90th percentile value for var1*/
proc univariate data=original_data;
    var var1;
    output out=percentile_data
    pctlpts = 70 80 90
    pctlpre = P_;
run;</b>
<b>Method 3: Calculate Percentiles by Group</b>
<b>/*sort original data by var2*/
proc sort data=original_data;
    by var2;
run;
/*calculate percentiles for var1 grouped by var2*/
proc univariate data=original_data;
    var var1;
    by var2;
    output out=percentile_data
    pctlpts = 70, 80, 90
    pctlpre = P_;
run;</b>
<b>Note</b>: The <b>pctlpts</b> statement specifies which percentiles to calculate and the <b>pctlpre</b> statement specifies the prefix to use for the percentiles in the output.
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points;
    datalines;
A 12
A 15
A 16
A 21
A 22
A 25
A 29
A 31
B 16
B 22
B 25
B 29
B 30
B 31
B 33
B 38
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/percent0.jpg"143">
<h3>Example 1: Calculate One Specific Percentile Value</h3>
The following code shows how to calculate the 70th percentile for the <b>points</b> variable:
<b>/*calculate 70th percentile value for points*/
proc univariate data=original_data;
    var points;
    output out=percentile_data
    pctlpts = 70
    pctlpre = P_;
run;
/*view results*/
proc print data=percentile_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/percent11.jpg"92">
The value at the 70th percentile turns out to be <b>30</b>.
<h3>Example 2: Calculate Multiple Specific Percentile Values</h3>
The following code shows how to calculate the values at the 70th, 80th, and 90th percentiles for the <b>points</b> variable:
<b>/*calculate 70th, 80th, and 90th percentile value for points*/
proc univariate data=original_data;
    var points;
    output out=percentile_data
    pctlpts = 70 80 90
    pctlpre = P_;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/percent12.jpg"180">
Here’s how to interpret the output:
The value at the 70th percentile is <b>30</b>.
The value at the 80th percentile is <b>31</b>.
The value at the 90th percentile is <b>33</b>.
<h3>Example 3: Calculate Percentiles by Group</h3>
The following code shows how to calculate the values at the 70th, 80th, 90th, and 95th percentile for the <b>points</b> variable, grouped by the <b>team</b> variable:
<b>/*sort original data by team*/
proc sort data=original_data;
    by team;
run;
/*calculate percentiles for points grouped by team*/
proc univariate data=original_data;
    var points;
    by team;
    output out=percentile_data
    pctlpts = 70, 80, 90 95
    pctlpre = P_;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/percent13.jpg"284">
The output table shows the values for the 70th, 80th, 90th, and 95th percentile for the <b>points</b> variable for both teams A and B.
<h2><span class="orange">How to Use Proc Append in SAS (With Examples)</span></h2>
You can use <b>PROC APPEND </b>in SAS to append the values of one dataset to the end of another dataset.
This procedure uses the following basic syntax:
<b>proc append
    base=data1
    data=data2;
run;</b>
Note that this procedure doesn’t create a new dataset. Rather, it automatically appends the values in data2 to the end of data1.
The following example shows how to use this procedure in practice.
<h3>Example: Using Proc Append in SAS</h3>
Suppose we have the following two datasets in SAS:
<b>/*create datasets*/
data data1;
    input team $ points rebounds;
    datalines;
A 25 10
B 18 4
C 18 7
D 24 12
E 27 11
;
run;
data data2;
    input team $ points rebounds;
    datalines;
F 26 8
G 30 4
H 27 9
I 21 12
J 20 6
;
run;
/*view datasets*/
proc print data=data1;
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/append11.jpg"243">
We can use the following <b>PROC APPEND </b>statement to append the values of data2 to the end of data1:
<b>/*append data2 to end of data1*/
proc append
    base=data1
    data=data2;
run;
/*view updated data1*/
proc print data=data1;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/append12.jpg"226">
We can see that the values of <b>data2</b> have been added to the end of <b>data1</b>. The dataset <b>data1</b> now contains 10 total observations.
It’s important to note that you’ll receive the following error message if you attempt to use <b>PROC APPEND</b> when the two datasets have different column names:
<b>ERROR: No appending done because of anomalies listed above.
       Use FORCE option to append these files.
</b>
In this situation, you can either change the column names to match or you can use the <b>force</b> argument to force the append procedure.
For example, suppose the second dataset had a variable name of “rebound” instead of “rebounds.”
We could use the following syntax to append the two datasets and force them to be appended:
<b>/*append data2 to end of data1*/
proc append
    base=data1
    data=data2
    force;
run;
/*view updated data1*/
proc print data=data1;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/append13.jpg"235">
Notice that data2 has been appended to data1, but the values in the rebounds column are empty for the appended dataset.
<b>Note</b>: You can find the complete documentation for <b>PROC APPEND </b> here .
<h2><span class="orange">How to Use Proc Compare in SAS (With Examples)</span></h2>
You can use <b>PROC COMPARE </b>in SAS to quickly identify the similarities and differences between two datasets.
This procedure uses the following basic syntax:
<b>proc compare
    base=data1
    compare=data2;
run;</b>
The following example shows how to use this procedure in practice.
<h3>Example: Using Proc Compare in SAS</h3>
Suppose we have the following two datasets in SAS:
<b>/*create datasets*/
data data1;
    input team $ points rebounds;
    datalines;
A 25 10
B 18 4
C 18 7
D 24 12
E 27 11
;
run;
data data2;
    input team $ points;
    datalines;
A 25
B 18
F 27
G 21
H 20
;
run;
/*view datasets*/
proc print data=data1;
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/compare11.jpg"341">
We can use the following <b>PROC COMPARE</b> statement to find the similarities and differences between the two datasets:
<b>/*compare the two datasets*/
proc compare
    base=data1
    compare=data2;
run;</b>
This will produce three tables in the output:
<b>Table 1: A Summary of Both Tables</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/compare12-1.jpg"523">
The first table shows a brief summary of each dataset, including:
<b>1.</b> The number of variables (NVar) and observations (NObs) in each dataset.
Data1 has 3 variables and 5 observations
Data2 has 2 variables and 5 observations
<b>2.</b> The number of variables in common between the two datasets.
Data1 and Data2 have 2 variables in common (team and points)
<b>Table 2: A Summary of the Number of Differences in Values</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/compare13.jpg"518">
The second table summarizes the number of differences in values between the two tables.
The most interesting part of this output is located at the end of the table where we can see a summary of differences between the variables:
The <b>team</b> variable has 3 observations with different values.
The <b>points</b> variables has 3 observations with different values. The max difference is 9.
<b>Table 3: The Actual Differences Between Observations</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/compare14.jpg"471">
The third table shows the actual differences between the observations in the two datasets.
The first table shows the differences in the <b>team</b> variable between the two datasets.
For example, in data1 the third observation has a value of <b>C</b> for team while in data2 the third observation has a value of <b>F</b>.
The second table shows the differences in the <b>points</b> variables between the two datasets.
For example, in data1 the third observation has a value of <b>18</b> for points while in data2 the third observation has a value of <b>27</b>. The difference between the two values is <b>9</b>.
These three tables give us a complete understanding of the differences between the two datasets.
Note that if you only want to compare the differences between the two datasets for one specific variable, you can use the following syntax:
<b>/*compare the differences between the datasets only for 'points' variable*/
proc compare
    base=data1
    compare=data2;
    var points;
run;</b>
This will produce the same three tables as earlier, but only the output for the <b>points</b> variable will be shown.
<b>Note</b>: You can find the complete documentation for <b>PROC COMPARE</b>  here .
<h2><span class="orange">How to Use Proc Contents in SAS (With Examples)</span></h2>
You can use <b>proc contents </b>in SAS to print a summary of the contents of a dataset.
The following example shows how to use this procedure in practice.
<h2>Example: Using Proc Contents in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 12 8
A 12 8
A 12 8
A 23 9
A 20 12
A 14 7
A 14 7
B 20 2
B 20 5
B 29 4
B 14 7
B 20 2
B 20 2
B 20 5
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort1.jpg"227">
We can use <b>proc contents</b> to obtain a summary of the contents in the dataset:
<b>/*view contents of dataset*/
proc contents data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/contents1.jpg"678">
The first table in the output displays various information about the dataset but the most useful values include:
<b>Data Set Name</b>: The name of the dataset (original_data)
<b>Observations</b>: The number of rows in the dataset (14)
<b>Variables</b>: The number of columns in the dataset (3)
The second table in the output displays information about the engine and host used in SAS. In most cases, this information won’t be particularly useful to you.
The third table displays an alphabetical list of the variables in the dataset along with their data type and length.
From this table we can see:
<b>points</b> is a numeric variable
<b>rebounds</b> is a numeric variable
<b>team</b> is a character variable
If you would instead like these variables to be displayed in the order they appear in the dataset, you can use <b>order=varnum</b> as follows:
<b>/*view contents of dataset and retain original order of variables*/
proc contents data=original_data order=varnum;</b>
The third table in the output will now display a list of variables in the order in which they appear in the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/contents2.jpg"182">
<h2>Conclusion</h2>
In this tutorial we saw that <b>proc contents</b> can be used in SAS to obtain a summary of the contents of a dataset.
In particular, we saw that <b>proc contents</b> is useful for obtaining the following information:
The size of a dataset (number of columns and rows)
The names and data type of each variable in the dataset
In practice, we often use <b>proc contents</b> before performing any type of statistical analysis just to gain a better understanding of the size and structure of a dataset.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Summary in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">SAS: How to Use PROC FREQ by Group</span></h2>
You can use the following basic syntax to calculate frequencies by group in SAS:
<b>proc freq data=my_data;
    by var1;
    tables var2;
run;</b>
This particular syntax creates a frequency table for the values of the variable called <b>var2</b>, grouped by the variable called <b>var1</b>.
The following example shows how to use this syntax in practice.
<h2>Example: Using Proc FREQ by Group in SAS</h2>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 22
A Guard 20
A Guard 30
A Forward 14
A Forward 11
B Guard 12
B Guard 22
B Forward 30
B Forward 9
B Forward 12
B Forward 25
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/freq1.jpg"220">
We can use the following <b>PROC FREQ </b>statement to calculate the frequency of the position values, grouped by team:
<b>/*calculate frequency of position, grouped by team*/
proc freq data = my_data;
    by team;
    tables position;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/freq2.jpg">
The output displays the frequency of the values for the position variable, grouped by the team variable.
For example, we can see:
The value “Forward” occurred <b>2</b> times for team A.
The value “Guard” occurred <b>3</b> times for team A.
The value “Forward” occurred <b>4</b> times for team B.
The value “Guard” occurred <b>2</b> times for team B.
Note that in this example, we used the <b>tables</b> statement to calculate the frequencies for just one variable, but we could type out the names of multiple variables to calculate frequencies for more than one variable.
<b>Note</b>: You can find the complete documentation for <b>PROC FREQ </b> here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Summary in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">SAS: How to Use PROC FREQ with WHERE Statement</span></h2>
You can use the following basic syntax to use a <b>WHERE</b> statement within <b>PROC FREQ </b>in SAS:
<b>proc freq data=my_data;
    where var1 ='A';
    tables var2;
run;</b>
This particular syntax creates a frequency table for the variable called <b>var2</b> but only for the rows where <b>var1</b> is equal to ‘A’.
The following example shows how to use this syntax in practice.
<h2>Example: Using Proc FREQ with WHERE Statement in SAS</h2>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 22
A Guard 20
A Guard 30
A Forward 14
A Forward 11
B Guard 12
B Guard 22
B Forward 30
B Forward 9
B Forward 12
B Forward 25
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/freq1.jpg"220">
We can use the following <b>PROC FREQ </b>statement with a <b>WHERE</b> statement to calculate the frequency of values in the position column only for the rows where the team is equal to ‘A’:
<span><b>/*calculate frequency of position where team is equal to 'A'*/
proc freq data=my_data;
    where team='A';
    tables position;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/freq11.jpg"435">
The output displays the frequency of the values for the position variable only for the rows where the team is equal to ‘A.’
For example, we can see:
The value “Forward” occurs <b>2</b> times for team A.
The value “Guard” occurs <b>3</b> times for team A.
We can also use the <b>OR</b> and <b>AND</b> operators to specify multiple conditions within the <b>WHERE</b> statement.
For example, we can use the following code to calculate the frequency of values in the position column where the team is equal to ‘A’ <em>and</em> the position is equal to ‘Guard’:
<b>/*calculate frequency of position where team is 'A' and position is 'Guard'*/
proc freq data=my_data;
    where team='A' and position='Guard';
    tables position;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/freq12.jpg"425">
The output displays the frequency of the values for the position variable only for the rows where the team is equal to ‘A’ and the position is equal to ‘Guard.’
<b>Note</b>: You can find the complete documentation for <b>PROC FREQ </b> here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Summary in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">How to Use PROC RANK in SAS (With Examples)</span></h2>
You can use <b>PROC RANK </b>in SAS to calculate the rank for one or more numeric variables.
Here are the four most common ways to use this procedure:
<b>Method 1: Rank One Variable</b>
<b>proc rank data=original_data out=ranked_data;
   var var1;
   ranks var1_rank;
run;</b>
<b>Method 2: Rank One Variable by Group</b>
<b>proc rank data=original_data out=ranked_data;
   var var1;
   by var2;
   ranks var1_rank;
run;</b>
<b>Method 3: Rank One Variable into Percentiles</b>
<b>proc rank data=original_data groups=4 out=ranked_data;
   var var1;
   ranks var1_rank;
run;</b>
<b>Method 4: Rank Multiple Variables</b>
<b>proc rank data=original_data out=ranked_data;
   var var1 var2;
   ranks var1_rank var2_rank;
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 25 10
A 18 4
A 18 7
A 24 8
B 27 9
B 33 13
B 31 11
B 30 16
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/rank1.jpg"240">
<h3>Example 1: Rank One Variable</h3>
The following code shows how to create a new variable called <b>points_rank</b> that ranks the points scored by each team:
<b>/*rank points scored by team*/
proc rank data=original_data out=ranked_data;
   var points;
   ranks points_rank;
run;
/*view ranks*/
proc print data=ranked_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/rank2.jpg"328">
The team with the most points receives the highest rank and the team with the lowest points receives the lowest rank.
Any ties in points scored are assigned a mean rank. For example, the rows with the first and second lowest points scored both receive a rank of 1.5, since this is the average of 1 and 2.
Note that you can instead use the <b>descending</b> statement to assign the team with the most points the <em>lowest</em> rank:
<b>/*rank points scored by team in descending order*/
proc rank data=original_data descending out=ranked_data;
    var points;
    ranks points_rank;
run;
/*view ranks*/
proc print data=ranked_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/ranks3.jpg"321">
<h3>Example 2: Rank One Variable by Group</h3>
The following code shows how to create a new variable called <b>points_rank</b> that ranks the points scored, grouped by team:
<b>/*rank points scored, grouped by team*/
proc rank data=original_data out=ranked_data;
    var points;
    by team;
    ranks points_rank;
run;
/*view ranks*/
proc print data=ranked_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/rank4.jpg"314">
<h3>Example 3: Rank One Variable into Percentiles</h3>
We can use the groups statement to rank variables into percentile groups. For example, we can rank each value of points into a quartile (four groups):
<b>/*rank points into quartiles*/
proc rank data=original_data groups=4 out=ranked_data;
   var points;
   ranks points_rank;
run;
/*view ranks*/
proc print data=ranked_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/rank5.jpg"323">
The rows with the points values in the lowest quartile are assigned a group of <b>0</b>, the rows with the points in the next lowest quartile are assigned a group of <b>1</b>, and so on.
<b>Note</b>: To assign values into deciles instead, simply use <b>groups=10</b>.
<h3>Example 4: Rank Multiple Variables</h3>
The following code shows how to create multiple new variables to rank both <b>points</b> and <b>rebounds</b>:
<b>proc rank data=original_data out=ranked_data;
   var points rebounds;
   ranks points_rank rebounds_rank;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/rank6.jpg"453">
<h2><span class="orange">How to Use Proc Report in SAS (With Examples)</span></h2>
You can use <b>proc report </b>in SAS to generate a report for a dataset in SAS with the exact formatting that you’d like.
This procedure uses the following basic syntax:
<b>/*create report*/
proc report data=my_data;
run;
</b>
This will generate a report that displays the rows in a dataset exactly as they appear.
However, you can customize the output of the report in a variety of ways.
For example, we can use the following syntax to create a more customized report:
<b>/*create customized report*/
title 'Player Statistics for Dallas Mavericks';
proc report data=my_data;
   where team='Mavs';
   column conf team points;
   define conf / display 'Conference' center;
run;</b>
Here’s what each statement does:
<b>title</b> creates a title for the report
<b>where</b> filters the dataset to only contain rows where team is ‘Mavs’
<b>column</b> specifies which columns to display in the report in a certain order
<b>display</b> specifies the title to use for the column called conf and <b>center</b> specifies the text to be centered in the column
The following example shows how to use <b>proc report</b> in practice.
<b>Note</b>: Refer to the  online documentation  for a complete explanation of all the ways you can customize a report.
<h2>Example: Using Proc Report in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points rebounds conf $;
    datalines;
Celtics 12 5 East
Celtics 14 7 East
Celtics 15 8 East
Celtics 18 13 East
Mavs 31 12 West
Mavs 32 6 West
Mavs 35 4 West
Mavs 36 10 West
Mavs 40 12 West
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/report1.jpg"301">
We can use <b>proc report</b> in the following manner to print the entire dataset as it appears:
<b>/*create report that displays entire dataset*/
proc report data=my_data;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/report.jpg"256">
The report simply contains the entire dataset.
However, we can use <b>proc report</b> to generate a customized report by using the following syntax:
<b>/*create customized report*/
title 'Player Statistics for Dallas Mavericks';
proc report data=my_data;
   where team='Mavs';
   column conf team points;
   define conf / display 'Conference' center;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/report2.jpg"322">
Notice that this report contains the following differences compared to the original report:
This report has a title
This report only contains rows where team is ‘Mavs’
This report only contains the conf, team, and points columns
This report uses ‘Conference’ as the title for conf and center-aligns the values in the conf column
This is just a simple example of how to create a customized report using <b>proc report</b> in SAS.
Feel free to explore the  online documentation  to see how you can further customize the output and generate a report that appears exactly how you’d like in SAS.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Append in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Summary in SAS 
<h2><span class="orange">SAS: How to Use PROC SORT with NODUPKEY</span></h2>
You can use <b>PROC SORT </b>in SAS with <b>NODUPKEY</b> to order the observations in a dataset by one or more variables and remove any duplicates.
The following example shows how to use this procedure with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 12 8
A 12 8
A 12 8
A 23 9
A 20 12
A 14 7
A 14 7
B 20 2
B 20 5
B 29 4
B 14 7
B 20 2
B 20 2
B 20 5
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort1.jpg"224">
<h2>Example: Using PROC SORT with NODUPKEY in SAS</h2>
Suppose we simply use <b>proc sort</b> to sort the observations in the dataset in ascending order (smallest to largest) based on the value in the <b>points</b> column:
<b>/*sort by points ascending*/
proc sort data=original_data out=data2;
    by points;
run;
/*view sorted dataset*/
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort2.jpg"249">
Notice that the observations are sorted in ascending order based on the value in the <b>points</b> column.
However, there are several observations that are duplicates.
To sort the observations based on the values in the <b>points</b> column and remove all duplicates, we can add <b>nodupkey</b> after the <b>proc sort</b> statement:
<b>/*sort by points ascending and remove duplicates*/
proc sort data=original_data out=data3 nodupkey;
    by points;
run;
/*view sorted dataset*/
proc print data=data3;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort3.jpg"254">
The observations are now sorted in ascending order based on the value in the <b>points</b> column and all duplicate observations have been removed.
Note that we can also add the argument <b>descending</b> to instead sort the observations based on the value in the <b>points</b> column in descending order and remove all duplicates:
<b>/*sort by points descending and remove duplicates*/
proc sort data=original_data out=data4 nodupkey;
    by descending points;
run;
/*view sorted dataset*/
proc print data=data4;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort4.jpg"239">
The observations are now sorted in descending order based on the value in the <b>points</b> column and all duplicate observations have been removed.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Append in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">How to Use Proc Sort in SAS (With Examples)</span></h2>
You can use <b>proc sort </b>in SAS to order the observations in a dataset by one or more variables.
The following examples show how to use this procedure with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 12 8
A 12 7
A 14 5
A 23 9
A 20 12
A 11 7
A 14 7
B 20 2
B 20 5
B 29 4
B 14 7
B 19 8
B 17 9
B 30 9
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/proc1.jpg"228">
<h2>Example 1: Sort Observations Ascending</h2>
We can use <b>proc sort</b> to sort the observations in the dataset in ascending order (smallest to largest) based on the value in the <b>points</b> column:
<b>/*sort by points ascending*/
proc sort data=original_data out=data2;
    by points;
run;
/*view sorted dataset*/
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/proc2-1.jpg">
Notice that the observations are sorted in ascending order based on the value in the <b>points</b> column.
<h2>Example 2: Sort Observations Descending</h2>
We can use <b>proc sort</b> with the <b>descending</b> statement to sort the observations in the dataset in descending order (largest to smallest) based on the value in the <b>points</b> column:
<b>/*sort by points descending*/
proc sort data=original_data out=data3;
    by descending points;
run;
/*view sorted dataset*/
proc print data=data3;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/proc3.jpg">
Notice that the observations are sorted in ascending order based on the value in the <b>points</b> column.
<h2>Example 3: Sort Observations by Multiple Columns</h2>
We can use <b>proc sort</b> with multiple variables listed in the <b>by </b>statement to sort the observations in the dataset by multiple variables.
The following code shows how to sort the observations in the dataset by the value in the <b>points</b> column ascending, then by the value in the <b>rebounds</b> column ascending:
<b>/*sort by points ascending, then by rebounds ascending*/
proc sort data=original_data out=data4;
    by points rebounds;
run;
/*view sorted dataset*/
proc print data=data4;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/proc4.jpg"240">
Notice that the observations are sorted by the value in the <b>points</b> column ascending, then by the value in the <b>rebounds</b> column ascending.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Append in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">SAS: How to Use CONTAINS in PROC SQL</span></h2>
You can use the <b>CONTAINS </b>operator in the <b>PROC SQL</b> statement in SAS to only return rows where a variable in a dataset contains some string pattern.
The following examples show how to use the <b>CONTAINS </b>operator in practice with the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
Cavs 12
Cavs 14
Warriors 15
Hawks 18
Mavs 31
Mavs 32
Mavs 35
Celtics 36
Celtics 40
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like1.jpg"187">
<h2>Example 1: Select Rows where Variable Contains One Pattern</h2>
We can use the <b>CONTAINS</b> operator in <b>PROC SQL</b> to select only the rows where the team contains the pattern ‘avs’ somewhere in the name:
<b>/*select all rows where team contains 'avs'*/ 
proc sql;
   select *
   from my_data
   where team contains 'avs';
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like2.jpg"124">
Notice that only the rows where the team contains ‘avs’ somewhere in the name are returned.
<h2>Example 2: Select Rows where Variable Contains One of Several Patterns</h2>
We can use the <b>CONTAINS</b> operator in <b>PROC SQL</b> to select only the rows where the team contains the pattern ‘avs’ <em>or</em> the pattern ‘ics’ somewhere in the name:
<b>/*select all rows where team contains 'avs' or 'ics'*/ 
proc sql;
   select *
   from my_data
   where team contains 'avs' or team contains 'ics';
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/contains4.jpg"130">
Only the rows where the team contains ‘avs’ <em>or</em> ‘ics’ somewhere in the name are returned.
<h2>Example 3: Select Rows where Variable Does Not Contain Pattern</h2>
The opposite of the <b>CONTAINS</b> operator in <b>PROC SQL</b> is <b>NOT CONTAINS</b>, which selects rows where some variable in a dataset does <em>not</em> contain a certain string pattern.
The following code shows how to use the <b>NOT CONTAINS  </b>operator to select all rows where the team does not contain ‘avs’ in the name:
<b>/*select all rows where team does not contain 'avs'*/
proc sql;
   select *
   from my_data
   where team not contains 'avs';
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like3.jpg"149">
Notice that only the rows where the team does not contain ‘avs’ somewhere in the name are returned.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use UNION in PROC SQL 
 SAS: How to Use EXCEPT in PROC SQL 
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use the WHERE Operator in PROC SQL 
<h2><span class="orange">SAS: How to Use EXCEPT in PROC SQL</span></h2>
You can use the <b>EXCEPT </b>operator in the <b>PROC SQL</b> statement in SAS to only return rows from one dataset that are not in another dataset.
The following example shows how to use the <b>EXCEPT </b>operator in practice.
<h2>Example: Using EXCEPT in PROC SQL in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create first dataset*/
data data1;
    input team $ points;
    datalines;
A 12
A 14
A 15
A 18
A 20
A 22
;
run;
/*view first dataset*/
proc print data=data1;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union1.jpg"163">
And suppose we have another dataset in SAS that also contains information about various basketball players:
<b>/*create second dataset*/
data data2;
    input team $ points;
    datalines;
A 12
A 14
B 23
B 25
B 29
B 30
;
run;
/*view second dataset*/
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union2.jpg"167">
We can use the <b>EXCEPT </b>operator in the <b>PROC SQL</b> statement to only return the rows from the first dataset that are not in the second dataset
<b>/*only return rows from first dataset that are not in second dataset*/
proc sql;
   title 'data1 EXCEPT data2';
   select * from data1
   except
   select * from data2;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/except1.jpg"196">
Notice that only the rows in the first dataset that do not belong to the second dataset are returned.
We can also use the <b>EXCEPT </b>operator to only return the rows from the second dataset that are not in the first dataset:
<b>/*only return rows from second dataset that are not in first dataset*/
proc sql;
   title 'data2 EXCEPT data1';
   select * from data2
   except
   select * from data1;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/except2.jpg"197">
Notice that only the rows in the second dataset that do not belong to the first dataset are returned.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use UNION in PROC SQL 
 SAS: How to Use Proc Univariate by Group 
 SAS: How to Use Proc Contents 
<h2><span class="orange">SAS: How to Use HAVING Clause Within PROC SQL</span></h2>
You can use the <b>HAVING </b>clause within <b>PROC SQL</b> in SAS to filter for rows that meet a certain condition.
Note the subtle difference between the <b>WHERE </b>and <b>HAVING</b> clause:
<b>WHERE</b> filters rows before any grouping occurs.
<b>HAVING</b> filters rows after any grouping occurs.
The following example shows how to use the <b>HAVING</b> clause in practice.
<h2>Example: How to Use HAVING Clause in PROC SQL</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 22
A Guard 20
A Guard 30
A Forward 14
A Forward 11
B Guard 12
B Guard 22
B Forward 30
B Forward 9
B Forward 12
B Forward 25
C Guard 22
C Guard 19
C Guard 10
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/having1.jpg"236">
We can use the following code to calculate the sum of points scored by players on each team <b>WHERE</b> the players are Guards and then filter the results to only show teams <b>HAVING</b> a sum greater than 50:
<b>proc sql;
    select team, sum(points) as sum_points
    from my_data
    where position='Guard'
    group by team
    having sum_points>50;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/having2.jpg"157">
Here is exactly how this code worked:
First, we used <b>SELECT</b> to select team and the sum of points
Then, we used <b>WHERE</b> to filter for rows where position was ‘Guard’
Then, we used <b>GROUP</b> to group the results by team
Then we used <b>HAVING</b> to filter for teams with sum of points > 50
Here is what the results of this query would have looked like if we didn’t include the <b>HAVING</b> statement:
<b>proc sql;
    select team, sum(points) as sum_points
    from my_data
    where position='Guard'
    group by team;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/having3.jpg"166">
Notice that the sum of points for team B was not greater than 50.
Thus, when we used the <b>HAVING</b> statement in the previous example, we filtered out team B since their sum of points was not greater than 50.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use LIKE Operator in PROC SQL 
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use the WHERE Operator in PROC SQL 
<h2><span class="orange">SAS: How to Use IF Statement in PROC SQL</span></h2>
While it’s not possible to use an <b>IF</b> statement in <b>PROC SQL</b> in SAS, you can use the <b>CASE</b> operator to define the values that a variable should take on based on certain conditions.
The following examples show how to use the <b>CASE </b>operator in practice with the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
Cavs 12
Cavs 14
Warriors 15
Hawks 18
Mavs 31
Mavs 32
Mavs 35
Celtics 36
Celtics 40
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like1.jpg"187">
<h2>Example 1: Use CASE Operator with Only Two Outcomes</h2>
We can use the <b>CASE</b> operator in <b>PROC SQL</b> to generate a new column in the dataset called <b>points_flag</b> that takes a value of 0 if the value in the <b>points</b> column is less than 20 or a value of 1 otherwise:
<b>/*create new column called points_flag using case operator*/ 
proc sql;
  select *,
      case 
      when points &lt; 20 then 0 else 1
      end as points_flag
      from my_data;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/ifsql1.jpg"236">
Notice that the <b>points_flag</b> column takes on a value of 0 if the value in the <b>points</b> column is less than 20 or a value of 1 otherwise.
<h2>Example 2: Use CASE Operator with More Than Two Outcomes</h2>
We can also use the <b>CASE</b> operator in <b>PROC SQL</b> to generate a new column in the dataset called <b>points_flag</b> that takes a value of 0 if the value in the <b>points</b> column is less than 20, a value of 1 if <b>points</b> is less than 35, or a value of 2 otherwise:
<b>/*create new column called points_flag using case operator*/ 
proc sql;
  select *,
      case 
      when points &lt; 20 then 0
      when points &lt; 35 then 1 else 2
      end as points_flag
      from my_data;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/ifsql2.jpg"241">
Notice that the <b>points_flag</b> column takes on a value of 0, 1, or 2 depending on the corresponding value in the <b>points</b> column.
<b>Note</b>: Feel free to use as many <b>when</b> statements as you’d like to generate as many different values as you’d like in a new column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use the WHERE Operator in PROC SQL 
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use UPDATE Within PROC SQL 
 SAS: How to Use CONTAINS in PROC SQL 
<h2><span class="orange">SAS: How to Use the IN Operator in PROC SQL</span></h2>
You can use the <b>IN </b>operator in the <b>PROC SQL</b> statement in SAS to only return rows where a variable in a dataset contains a value in a list.
The following example shows how to use the <b>IN </b>operator in practice.
<h2>Example: Using IN Operator in PROC SQL in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
A 12
A 14
A 15
A 18
B 31
B 32
C 35
C 36
C 40
D 28
E 20
E 21
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/in1.jpg"164">
We can use the <b>IN</b> operator in <b>PROC SQL</b> to select only the rows where the team is equal to A, B, or E:
<b>/*select all rows where team is A, B, or E*/
proc sql;
   select *
   from my_data
   where team in ('A', 'B', 'E');
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/in2.jpg"138">
Notice that only the rows where the team is equal to A, B, or E are returned.
The opposite of the <b>IN</b> operator in <b>PROC SQL</b> is <b>NOT IN</b>, which selects rows where some variable in a dataset does <em>not</em> contain a value in a list.
The following code shows how to use the <b>NOT IN</b> operator to select all rows where the team is not equal to A, B, or E:
<b>/*select all rows where team is not A, B, or E*/
proc sql;
   select *
   from my_data
   where team not in ('A', 'B', 'E');
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/in3.jpg"133">
Notice that only the rows where the team is not equal to A, B, or E are returned.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use UNION in PROC SQL 
 SAS: How to Use EXCEPT in PROC SQL 
 SAS: How to Use Proc Univariate by Group 
<h2><span class="orange">SAS: How to Use LIKE Operator in PROC SQL</span></h2>
You can use the <b>LIKE </b>operator in the <b>PROC SQL</b> statement in SAS to return rows where a variable in a dataset matches some string pattern.
The following example shows how to use the <b>LIKE </b>operator in practice.
<h2>Example: Using LIKE Operator in PROC SQL in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
Cavs 12
Cavs 14
Warriors 15
Hawks 18
Mavs 31
Mavs 32
Mavs 35
Celtics 36
Celtics 40
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like1.jpg"187">
We can use the <b>LIKE</b> operator in <b>PROC SQL</b> to select only the rows where the team contains the pattern ‘avs’ somewhere in the name:
<b>/*select all rows where team contains 'avs'*/ 
proc sql;
   select *
   from my_data
   where team like '%avs%';
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like2.jpg"129">
Notice that only the rows where the team contains ‘avs’ somewhere in the name are returned.
The opposite of the <b>LIKE</b> operator in <b>PROC SQL</b> is <b>NOT LIKE</b>, which selects rows where some variable in a dataset does <em>not</em> contain a certain string pattern.
The following code shows how to use the <b>NOT LIKE </b>operator to select all rows where the team does not contain ‘avs’ in the name:
<b>/*select all rows where team does not contain 'avs'*/
proc sql;
   select *
   from my_data
   where team not like '%avs%';
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/like3.jpg"149">
Notice that only the rows where the team does not contain ‘avs’ somewhere in the name are returned.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use UNION in PROC SQL 
 SAS: How to Use EXCEPT in PROC SQL 
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use the WHERE Operator in PROC SQL 
<h2><span class="orange">SAS: How to Use UNION in PROC SQL</span></h2>
You can use the <b>UNION </b>operator in the <b>PROC SQL</b> statement in SAS to combine two datasets vertically.
The following example shows how to use the <b>UNION</b> operator in practice.
<h2>Example: Using UNION in PROC SQL in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create first dataset*/
data data1;
    input team $ points;
    datalines;
A 12
A 14
A 15
A 18
A 20
A 22
;
run;
/*view first dataset*/
proc print data=data1;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union1.jpg"163">
And suppose we have another dataset in SAS that also contains information about various basketball players:
<b>/*create second dataset*/
data data2;
    input team $ points;
    datalines;
A 12
A 14
B 23
B 25
B 29
B 30
;
run;
/*view second dataset*/
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union2.jpg"167">
We can use the <b>UNION</b> operator in the <b>PROC SQL</b> statement to combine these two datasets vertically and only keep the unique rows:
<b>/*combine tables vertically and only keep unique rows*/
proc sql;
   title 'data1 UNION data2';
   select * from data1
   union
   select * from data2;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union3.jpg"166">
Notice that the two datasets have been combined vertically and only the unique rows are kept.
We can also use the <b>UNION ALL</b> operator in the <b>PROC SQL</b> statement to combine these two datasets vertically and keep <em>all</em> of the rows:
<b>/*combine tables vertically and keep all rows*/
proc sql;
   title 'data1 UNION ALL data2';
   select * from data1
   union all
   select * from data2;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/union4.jpg"202">
Notice that the two datasets have been combined vertically and all rows are kept from both datasets, even the ones that are duplicates.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Calculate Z-Scores in SAS 
 How to Use Proc Summary in SAS 
 How to Calculate Mean, Median, & Mode in SAS 
<h2><span class="orange">SAS: How to Use UPDATE Within PROC SQL</span></h2>
You can use the <b>UPDATE</b> statement within <b>PROC SQL</b> in SAS to update the values in one or more columns of dataset.
Here are the most common ways to use the <b>UPDATE</b> statement in practice:
<b>Method 1: Update Values in Column Based on One Condition</b>
<b>proc sql;
    update my_data
    set var1='new_value'
    where var1='old_value';
quit;</b>
<b>Method 2: Update Values in Column Based on Multiple Conditions</b>
<b>proc sql;
    update my_data
    set var1 = 
    case when var1>25 then 100
    when var1>20 then 50
    else 0
    end;
quit;</b>
The following examples show how to use each method in practice with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 22
A Guard 20
A Guard 30
A Forward 14
A Forward 11
B Guard 12
B Guard 22
B Forward 30
B Forward 9
B Forward 12
B Forward 25
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/freq1.jpg"220">
<h2>Example 1: Update Values in Column Based on One Condition</h2>
We can use the following <b>UPDATE </b>statement within <b>PROC SQL</b> to update each of the values in the team column to be ‘Atlanta’ where the existing values are equal to ‘A’:
<b>/*update values in team column where team is equal to 'A'*/
proc sql;
    update my_data
    set team='Atlanta'
    where team='A';
quit;
/*view updated dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/update1.jpg"245">
Notice that each value in the team column that used to be equal to ‘A’ is now equal to ‘Atlanta.’
Any values that were not equal to ‘A’ in the team column were simply left unchanged.
<h2>Example 2: Update Values in Column Based on Multiple Conditions</h2>
We can use the following <b>UPDATE </b>statement within <b>PROC SQL</b> to update each of the values in the points column based on several conditions:
<b>/*update values in points column based on multiple conditions*/
proc sql;
    update my_data
    set points = 
    case when points>25 then 100
    when points>20 then 50
    else 0
    end;
quit;
/*view updated dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/update2.jpg"237">
We used the <b>UPDATE</b> statement along with a <b>CASE WHEN</b> statement to update the values in the points column.
In particular:
If the existing value in the points column was greater than 25, we updated it to be <b>100</b>.
Else, if the existing value in the points column was greater than 20, we updated it to be <b>50</b>.
Else, we updated the value in the points column to be <b>0</b>.
Note that we only used three conditions in the <b>CASE WHEN</b> statement but you can use as many conditions as you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use LIKE Operator in PROC SQL 
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use the WHERE Operator in PROC SQL 
<h2><span class="orange">SAS: How to Use the WHERE Operator in PROC SQL</span></h2>
You can use the <b>WHERE </b>operator in the <b>PROC SQL</b> statement in SAS to only return rows where certain conditions are met.
The following examples show how to use the <b>WHERE</b> operator in the following scenarios:
Select rows where one condition is met.
Select rows where one of several conditions are met.
Select rows where multiple conditions are met.
The following examples show how to use the <b>WHERE</b> operator in each scenario with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points;
    datalines;
A 12
A 14
A 15
A 18
B 31
B 32
C 35
C 36
C 40
D 28
E 20
E 21
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/where1.jpg"164">
<h2>Example 1: Select Rows Where One Condition is Met</h2>
The following code shows how to use the <b>WHERE</b> operator in the <b>PROC SQL</b> statement to select all rows in the dataset where the team is equal to A:
<b>/*select all rows where team is equal to A*/
proc sql;
   select *
   from my_data
   where team = 'A';
quit;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/where2.jpg"128">
The only rows returned are the ones where the team is equal to A.
<h2>Example 2: Select Rows Where One of Several Conditions are Met</h2>
The following code shows how to use the <b>WHERE</b> operator in the <b>PROC SQL</b> statement to select all rows in the dataset where the team is equal to A <em>or</em> points is greater than 30:
<b>/*select all rows where team is equal to A or points is greater than 30*/
proc sql;
   select *
   from my_data
   where team = 'A' or points > 30;
quit;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/where3.jpg"145">
The only rows returned are the ones where the team is equal to A <em>or</em> points is greater than 30:
<h2>Example 3: Select Rows Where Multiple Conditions are Met</h2>
The following code shows how to use the <b>WHERE</b> operator in the <b>PROC SQL</b> statement to select all rows in the dataset where the team is equal to A <i>and </i>points is greater than 13:
<b>/*select all rows where team is equal to A and points is greater than 13*/
proc sql;
   select *
   from my_data
   where team = 'A' and points > 13;
quit;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/where4.jpg"138">
The only rows returned are the ones where the team is equal to A <i>and </i>points is greater than 13:
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 SAS: How to Use the IN Operator in PROC SQL 
 SAS: How to Use UNION in PROC SQL 
 SAS: How to Use EXCEPT in PROC SQL 
<h2><span class="orange">How to Use PROC TRANSPOSE in SAS (With Examples)</span></h2>
You can use <b>PROC TRANSPOSE</b> in SAS to quickly transpose a dataset from a  long format to a wide format .
This function uses the following basic syntax:
<b>proc transpose data=long_data out=wide_data;
    by var1;
    id var2;
    var var3;
run;
</b>
where:
<b>by</b>: The variable to place along the rows
<b>id</b>: The variable to place along the columns
<b>var</b>: The variable whose values are placed within the dataset
The following example shows how to use <b>PROC TRANSPOSE</b> in practice.
<h3>Example: How to Use PROC TRANSPOSE in SAS</h3>
Suppose we have the following dataset in a long format in SAS:
<b>/*create dataset in long format*/
data long_data;
    input team $ variable $ value;
    datalines;
A Points 88
A Assists 12
A Rebounds 22
B Points 91
B Assists 17
B Rebounds 28
C Points 99
C Assists 24
C Rebounds 30
D Points 94
D Assists 28
D Rebounds 31
;
run;
/*view dataset*/
proc print data=long_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/transpose1.jpg"200">
We can use <b>PROC TRANSPOSE</b> to convert this dataset from a long format to a wide format:
<b>/*create new dataset in wide format*/
proc transpose data=long_data out=wide_data;
    by team;
    id variable;
    var value;
run;
/*view wide data*/
proc print data=wide_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/transpose2.jpg"365">
Notice that this dataset contains the same information as the previous dataset, but it’s simply displayed in a wide format.
By default, SAS creates a <b>_NAME_</b> variable that shows which variable is used for the values in the  dataset.
Feel free to use the <b>DROP</b> statement to drop this variable when using <b>PROC TRANSPOSE</b>:
<b>/*create new dataset in wide format*/
proc transpose data=long_data out=wide_data(drop=_name_);
    by team;
    id variable;
    var value;
run;
/*view wide data*/
proc print data=wide_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/transpose3.jpg"297">
Notice that the <b>_NAME_</b> variable has been dropped from the dataset.
<h2><span class="orange">SAS: How to Use Proc Univariate by Group</span></h2>
You can use <b>proc univariate </b>in SAS with the <b>by </b>statement to calculate descriptive statistics for each numeric variable in a dataset, grouped by a particular variable.
This procedure uses the following basic syntax:
<b>proc univariate data=my_data normal;
    by group_variable;
run;</b>
The following example shows how to use this procedure in practice.
<h2>Example: Proc Univariate by Group in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points rebounds;
    datalines;
A 12 8
A 12 8
A 12 8
A 23 9
A 20 12
A 14 7
A 14 7
B 20 2
B 20 5
B 29 4
B 14 7
B 20 2
B 20 2
B 20 5
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort1.jpg"220">
We can use <b>proc univariate </b>with the <b>by </b>statement to calculate descriptive statistics for the <b>points</b> and <b>rebounds</b> variables, grouped by the <b>team</b> variable:
<span><b>proc univariate data=my_data;
    by team;
run;</b>
This procedure will produce the following results:
Descriptive statistics for <b>points</b> for team <b>A</b>
Descriptive statistics for <b>rebounds </b>for team <b>B</b>
Descriptive statistics for <b>points</b> for team <b>A</b>
Descriptive statistics for <b>rebounds</b> for team <b>B</b>
Here is what the descriptive statistics looks like for the <b>points</b> variable for team <b>A</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/unigroup1.jpg"393">
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/unigroup2.jpg"324">
If you only want to calculate descriptive statistics for one specific variable grouped by another variable, then you can use the <b>var</b> statement.
For example, you can use the following syntax to calculate descriptive statistics only for the <b>points</b> variable, grouped by the <b>team</b> variable:
<b>proc univariate data=my_data;
    var points;
    by team;
run;</b>
Feel free to specify as many variables as you’d like in both the <b>var</b> and <b>by</b> statements to calculate descriptive statistics for whichever variables you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Univariate for Normality Tests in SAS 
 How to Use Proc Summary in SAS 
 How to Use Proc Tabulate in SAS 
<h2><span class="orange">SAS: How to Use Proc Univariate for Normality Tests</span></h2>
You can use <b>proc univariate </b>in SAS with the <b>normal</b> statement to perform several normality tests on a variable in a dataset.
This procedure uses the following basic syntax:
<b>proc univariate data=my_data normal;
    var my_variable;
run;</b>
The following example shows how to use this procedure in practice.
<h2>Example: Proc Univariate for Normality Tests in SAS</h2>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ points rebounds;
    datalines;
A 12 8
A 12 8
A 12 8
A 23 9
A 20 12
A 14 7
A 14 7
B 20 2
B 20 5
B 29 4
B 14 7
B 20 2
B 20 2
B 20 5
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sort1.jpg"220">
We can use <b>proc univariate </b>with the <b>normal</b> statement to perform various normality tests on the <b>points</b> variable:
<b>proc univariate data=my_data normal;
    var points;
run;</b>
Several tables will be shown in the output but the one titled <b>Tests for Normality</b> contains the results of the normality tests:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/normsas1.jpg">
By default, SAS performs four normality tests and displays each of their test statistics and corresponding p-values:
<b>Shapiro-Wilk Test</b>: W = .867, p = .0383
<b>Kolmogorov-Smirnov Test</b>: D = .237, p = .0318
<b>Cramer-von Mises Test</b>: W-Sq = .152, p = .0200
<b>Anderson-Darling Test</b>: A-Sq = .847, p = .0223
Each normality test uses the following null and alternative hypotheses:
<b>H<sub>0</sub></b>: The data are normally distributed.
<b>H<sub>A</sub></b>: The data are not normally distributed.
Since the  p-value  for each normality test is less than .05, we would reject the null hypothesis for each normality test.
This means there is sufficient evidence to conclude that the <b>points</b> variable is not normally distributed.
Note that you can also create a histogram with a normal curve overlaid on it to visualize the distribution of values for the <b>points</b> variable:
<b>proc univariate data=my_data;
    histogram points / normal;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/normtest1.jpg"611">
From the histogram we can see that the distribution of values doesn’t follow the normal curve very well, which agrees with the results of the normality tests that we performed.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Summary in SAS 
 How to Use Proc Tabulate in SAS 
 How to Use Proc Rank in SAS 
<h2><span class="orange">How to Calculate Quartiles in SAS (With Examples)</span></h2>
You can use the following basic syntax to calculate the quartiles for a dataset in SAS:
<b>/*calculate quartile values for variable called var1*/
proc univariate data=original_data;
    var var1;
    output out=quartile_data
    pctlpts = 25 50 75
    pctlpre = Q_;
run;</b>
<b>Note</b>: The <b>pctlpts</b> statement specifies which quartiles to calculate and the <b>pctlpre</b> statement specifies the prefix to use for the quartiles in the output.
The following example shows how to use this syntax in practice.
<h2>Example: How to Calculate Quartiles in SAS</h2>
Suppose we have the following dataset in SAS that contains two variables:
<b>/*create dataset*/
data original_data;
    input team $ points;
    datalines;
A 12
A 15
A 16
A 21
A 22
A 25
A 29
A 31
B 16
B 22
B 25
B 29
B 30
B 31
B 33
B 38
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/percent0.jpg"143">
The following code shows how to calculate the quartiles for the <b>points</b> variable in the dataset
<b>/*calculate quartile values for points*/
proc univariate data=original_data;
    var points;
    output out=quartile_data
    pctlpts = 25 50 75
    pctlpre = Q_;
run;
/*view quartiles for points*/
proc print data=quartile_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/quartsas1.jpg"219">
Here’s how to interpret the output:
The value of the first quartile is <b>18.5</b>.
The value of the second quartile is <b>25</b>.
The value of the third quartile is <b>30.5</b>.
To calculate the quartile values grouped by the team variable, simply add <b>by team</b> in the proc univariate statement:
<b>/*calculate quartile values for points*/
proc univariate data=original_data;
    var points;
    by team;
    output out=quartile_data
    pctlpts = 25 50 75
    pctlpre = Q_;
run;
/*view quartiles for points*/
proc print data=quartile_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/quartsas2.jpg"257">
The output table shows the quartile values for the <b>points </b>variable for both teams A and B.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Calculate Percentiles in SAS 
 How to Use Proc Summary in SAS 
 How to Create Frequency Tables in SAS 
<h2><span class="orange">How to Generate Random Numbers in SAS (3 Examples)</span></h2>
You can use the  rand()  function in SAS to generate random numbers.
The following examples show how to use this function in practice.
<h3>Example 1: Generate One Random Number</h3>
The following code shows how to generate a single random integer in SAS between 1 and 10:
<b>/*create dataset with variable that contain random value*/
data my_data;
   call streaminit(1);  /*make this example reproducible*/
   x = rand("integer", 1, 10);
   output;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randSAS1.jpg"74">
The random number between 1 and 10 turned out to be <b>9</b>.
Note that we used the <b>streaminit()</b> function to ensure that this example is reproducible. This means that each time we run this code, the random number will be 9.
Feel free to leave out the <b>streaminit()</b> function to produce a different random value each time you run the code.
<h3>Example 2: Generate Variable with Several Random Numbers</h3>
The following code shows how to generate a variable in SAS that contains 10 random values between 1 and 20:
<b>/*create dataset with variable that contain random value*/
data my_data;
   call streaminit(10);
   do i = 1 to 10;
   x = rand("integer", 1, 20);
   output;
   end;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randsas2.jpg"113">
Notice that each of the values for the variable x are random integers between 1 and 20.
<h3>Example 3: Generate Multiple Variables with Several Random Numbers</h3>
The following code shows how to generate multiple variables in SAS that contain random values:
<b>/*create dataset with variable that contain random value*/
data my_data;
   call streaminit(10);
   do i = 1 to 10;
   x = rand("integer", 1, 20);
   y = rand("integer", 50, 100);
   output;
   end;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randsas3.jpg"154">
The <b>x</b> variable contains 10 random integers between 1 and 20 while the <b>y</b> variable contains 10 random integers between 50 and 100.
<h2><span class="orange">How to Select a Random Sample in SAS (With Examples)</span></h2>
Here are the two most common ways to select a  simple random sample  of rows from a dataset in SAS:
<b>Method 1: Select Random Sample Using Sample Size</b>
<b>proc surveyselect data=original_data
    out=random_sample
    method=srs /*specify simple random sampling as sampling method*/
    sampsize=3 /*select 3 observations randomly*/
    seed=123; /*set seed to make this example reproducible*/
run;
</b>
<b>Method 2: Select Random Sample Using Proportion of Total Observations</b>
<b>proc surveyselect data=original_data
    out=random_sample
    method=srs /*specify simple random sampling as sampling method*/
    samprate=0.2 /*select 20% of all observations randomly*/
    seed=123; /*set seed to make this example reproducible*/
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
Warriors 25 8
Wizards 18 12
Rockets 22 6
Celtics 24 11
Thunder 27 14
Spurs 33 19
Nets 31 20
Mavericks 34 10
Kings 22 11
Pelicans 39 23
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randomsas1.jpg"248">
<h3>Example 1: Select Random Sample Using Sample Size</h3>
The following code shows how to select a random sample of observations from the dataset using a sample size of n=3:
<b>/*select random sample*/
proc surveyselect data=original_data
    out=random_sample
    method=srs
    sampsize=3
    seed=123;
run;
/*view random sample*/
proc print data=random_sample;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randomsas3.jpg"262">
We can see that three rows were randomly selected from the original dataset.
<h3>Example 2: Select Random Sample Using Proportion of Total Observations</h3>
The following code shows how to select a random sample of observations from the dataset by using the <b>samprate</b> function to specify that we’d like the random sample to represent 20% of all original observations:
<b>/*select random sample*/
proc surveyselect data=original_data
    out=random_sample
    method=srs
    samprate=0.2
    seed=123;
run;
/*view random sample*/
proc print data=random_sample;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randomsas2.jpg"268">
We can see that 20% of the total observations (20% * 10 observations = <b>2</b>) from the original dataset were randomly selected to be in our sample.
<h2><span class="orange">How to Remove Duplicates in SAS (With Examples)</span></h2>
You can use <b>proc sort </b>in SAS to quickly remove duplicate rows from a dataset.
This procedure uses the following basic syntax:
<b>proc sort data=original_data out=no_dups_data nodupkey;
    by _all_;
run;
</b>
Note that the <b>by</b> argument specifies which columns to analyze when removing duplicates.
The following examples show how to remove duplicates from the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ position $ points;
    datalines;
A Guard 12
A Guard 20
A Guard 20
A Guard 24
A Forward 15
A Forward 15
A Forward 19
A Forward 28
B Guard 10
B Guard 12
B Guard 12
B Guard 26
B Forward 10
B Forward 10
B Forward 10
B Forward 19
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/dups1.jpg"213">
<h3>Example 1: Remove Duplicates from All Columns</h3>
We can use the following code to remove rows that have duplicate values across all columns of the dataset:
<b>/*create dataset with no duplicate rows*/
proc sort data=original_data out=no_dups_data nodupkey;
    by _all_;
run;
/*view dataset with no duplicate rows*/
proc print data=no_dups_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/dups2.jpg"205">
Notice that a total of five duplicate rows have been removed from the original dataset.
<h3>
<b>Example 2: Remove Duplicates from Specific Columns</b>
</h3>
We can use the <b>by</b> argument to specify which columns to look at when removing duplicates.
For example, the following code removes rows that have duplicate values in the <b>team</b> and <b>position</b> columns:
<b>/*create dataset with no duplicate rows in team and position columns*/
proc sort data=original_data out=no_dups_data nodupkey;
    by team position;
run;
/*view dataset with no duplicate rows in team and position columns*/
proc print data=no_dups_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/dups3.jpg"223">
Only four rows are left in the dataset after removing the rows that had duplicate values in the <b>team</b> and <b>position</b> columns.
<h2><span class="orange">How to Remove Variable Labels in SAS (With Examples)</span></h2>
You can use the following methods to remove variable labels in SAS:
<b>Method 1: Remove Label from One Variable</b>
<b>proc datasets lib=work;
  modify original_data;
  attrib my_variable label='';
</b>
<b>Method 2: Remove Label from All Variables</b>
<b>proc datasets lib=work;
  modify original_data;
  attrib _all_ label='';
</b>
The following examples show how to use each method in practice with the following dataset that has three variables with a label for each variable:
<b>/*create dataset*/
data original_data;
   label x='REBOUNDS'
         y='POINTS'
         z='ASSISTS';
   input x y z;
datalines;
6 22 5
8 14 9
9 31 10
9 40 7
3 12 3
2 20 5
;
/*view contents of dataset*/
proc contents data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/remove11.jpg"287">
<h2>Example 1: Remove Label from One Variable</h2>
The following code shows how to use <b>proc datasets</b> to remove the label from just the variable called ‘x’ in our dataset:
<b>proc datasets lib=work;
  modify original_data;
  attrib x label='';</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/remove12.jpg"294">
Notice that the label has been removed from variable x while the other variables in the dataset have remained unchanged.
<h2>Example 2: Remove Label from All Variables</h2>
The following code shows how to use <b>proc datasets</b> to remove the label from all variables in the dataset:
<b>proc datasets lib=work;
  modify original_data;
  attrib _all_ label='';</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/remove13.jpg"308">
Notice that the labels for all of the variables in the dataset have been removed.
<b>Note</b>: You can find the complete documentation for <b>proc datasets</b>  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Normalize Data in SAS 
 How to Identify Outliers in SAS 
 How to Extract Numbers from String in SAS 
 How to Remove Leading Zeros in SAS 
<h2><span class="orange">How to Remove Leading Zeros in SAS (With Examples)</span></h2>
The easiest way to remove leading zeros in a character variable in SAS is to use the <b>INPUT</b> function to convert the variable to a numeric variable, which automatically removes leading zeros.
This function uses the following basic syntax:
<b>data new_data;
    set original_data;
    no_zeros = input(some_column, comma9.);
run;
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Remove Leading Zeros in SAS</h2>
Suppose we have the following dataset in SAS that shows the total sales made by various retail stores:
<b>/*create dataset*/
data original_data;
    input store $ sales $;
    datalines;
A 055
B 145
C 199
D 0000443
E 0093
F 00004302
G 38
H 0055
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/leading1-1.jpg"187">
We can use the following code to remove all leading zeros from values in the <b>sales</b> column:
<b>/*remove leading zeros in sales column*/
data new_data;
    set original_data;
    no_zeros = input(sales, comma9.);
run;
/*view results*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/leading2.jpg">
Notice that all leading zeros have been removed from the values in the <b>no_zeros</b> column.
Note that the new <b>no_zeros</b> column is a numeric column.
If you would instead like to keep it as a character column, you can wrap the <b>PUT</b> function around the <b>INPUT</b> function as follows:
<b>/*remove leading zeros in sales column*/
data new_data;
    set original_data;
    no_zeros = put(input(sales, comma9.), 8.);
run;
/*view results*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/leading2.jpg">
If we use use <b>proc contents</b> to view the data type of each variable in the dataset, we’ll see that <b>no_zeros</b> is a character variable:
<b>/*view data type of each variable in new dataset*/
proc contents data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/leading3.jpg"298">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Normalize Data in SAS 
 How to Identify Outliers in SAS 
 How to Use Proc Summary in SAS 
 How to Create Frequency Tables in SAS 
<h2><span class="orange">How to Remove Special Characters from Strings in SAS</span></h2>
The easiest way to remove special characters from a string in SAS is to use the  COMPRESS  function with the ‘kas’ modifier.
This function uses the following basic syntax:
<b>data new_data;
    set original_data;
    remove_specials = compress(some_string, , 'kas');
run;
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Remove Special Characters from String in SAS</h2>
Suppose we have the following dataset in SAS that contains the names of various employees and their total sales:
<b>/*create dataset*/
data data1;
    input name $ sales;
    datalines;
Bob&%^ 45
M&$#@ike 50
Randy)) 39
Chad!? 14
Dan** 29
R[on] 44
;
run;
/*view dataset*/
proc print data=data1;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/remove111.jpg"198">
Notice that the values in the <b>name</b> column contain several special characters.
We can use the <b>COMPRESS</b> function to remove these special characters:
<b>/*create second dataset with special characters removed from names*/
data data2;
  set data1;
  new_name=compress(name, , 'kas');
run;
/*view dataset*/
proc print data=data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/remove112.jpg"277">
Notice that the <b>new_name</b> column contains the values in the <b>name</b> column with the special characters removed.
Here’s exactly what the <b>COMPRESS</b> function did to remove these special characters:
<b>k</b> specifies that we would like to ‘keep’ certain characters
<b>a</b> specifies to keep alphabetic characters
<b>s</b> specifies to keep space characters
<b>Note</b>: You can find a complete list of modifiers for the <b>COMPRESS</b> function on this  SAS documentation page .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Extract Numbers from String in SAS 
 How to Use the SUBSTR Function in SAS 
 How to Convert Strings to Uppercase, Lowercase & Proper Case in SAS 
<h2><span class="orange">How to Rename Variables in SAS (With Examples)</span></h2>
You can use the <b>rename</b> function to rename one or more variables in a SAS dataset.
This function uses the following basic syntax:
<b>data new_data;
    set original_data (rename=(old_name=new_name));
run;</b>
The following examples show how to use this function in practice with the following dataset:
<b>/*create dataset*/
data original_data;
    input x y z;
    datalines;
1 4 76
2 3 49
2 3 85
4 5 88
2 2 90
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/rename1.jpg"140">
<h3>Example 1: Rename One Variable</h3>
The following code shows how to rename just the <b>x</b> variable in the dataset:
<b>/*rename one variable*/
data new_data;
    set original_data (rename=(x=new_x));
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/rename2.jpg"169">
Notice that <b>x</b> has been renamed to <b>new_x</b>, but every other variable name remained the same.
<h3>Example 2: Rename Multiple Variables</h3>
The following code shows how to rename both the <b>x</b> and <b>y</b> variables in the dataset.
Note that you don’t need to include commas in between the new variable names.
<b>/*rename multiple variables*/
data new_data;
    set original_data (rename=(x=new_x y=new_y));
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/rename3.jpg"199">
<h3>Example 3: Add Prefix to All Variables</h3>
The following code shows how to add a prefix of <b>_NEW</b> to all variables in the dataset:
<b>/*define prefix to append to each variable*/
proc sql noprint;
   select cats(name, '=', '_NEW', name)
          into :list
          separated by ' '
          from dictionary.columns
          where libname = 'WORK' and memname = 'ORIGINAL_DATA';
quit;
/*add prefix to each variable in dataset*/
proc datasets library = work;
   modify original_data;
   rename &list;
quit;
/*view updated dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/rename5.jpg"245">
<h3>Example 4: Add Suffix to All Variables</h3>
The following code shows how to add a suffix of <b>_NEW</b> to all variables in the dataset:
<b>/*define suffix to append to each variable*/
proc sql noprint;
   select cats(name, '=', name, '_NEW')
          into :list
          separated by ' '
          from dictionary.columns
          where libname = 'WORK' and memname = 'ORIGINAL_DATA';
quit;
/*add suffix to each variable in dataset*/
proc datasets library = work;
   modify original_data;
   rename &list;
quit;
/*view updated dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/rename4.jpg"244">
<h2><span class="orange">How to Reorder Variables in SAS (With Examples)</span></h2>
You can use the <b>RETAIN</b> function in SAS to quickly reorder the variables in a dataset.
Here are the three most common ways to use this function:
<b>Method 1: Reorder All Variables</b>
<b>data new_data;
    retain var4 var5 var1 var3 var2;
    set original_data;
run;
</b>
<b>Method 2: Move One Variable to Front</b>
<b>data new_data;
    retain var4;
    set original_data;
run;</b>
<b>Method 3: Move Several Variables to Front</b>
<b>data new_data;
    retain var4 var5;
    set original_data;
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds assists steals;
    datalines;
A 18 10 4 5
B 24 11 6 7
C 26 14 6 8
D 34 22 5 3
E 38 3 7 7
F 45 12 4 4
G 23 7 9 1
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/ordersas1.jpg"348">
<h3>Example 1: Reorder All Variables</h3>
The following code shows how to reorder the variables in the following order: team, rebounds, assists steals, then points.
<b>/*create new dataset with variables reordered*/
data new_data;
    retain team rebounds assists steals points;
    set original_data;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/ordersas2.jpg">
Notice that the variables are reordered in the exact order that we specified in the <b>RETAIN</b> function.
<h3>Example 2: Move One Variable to Front</h3>
The following code shows how to move the <b>assists</b> variable to the front while leaving all other variables in the same order:
<b>/*create new dataset with variables reordered*/
data new_data;
    retain assists;
    set original_data;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/ordersas3.jpg"348">
We can see that the <b>assists</b> variable is now in the first position while all of the other variables remained in the same order.
<h3>Example 3: Move Several Variables to Front</h3>
The following code shows how to move the <b>assists</b> and <b>rebounds </b>variables to the front while leaving all other variables in the same order:
<b>/*create new dataset with variables reordered*/
data new_data;
    retain assists;
    set original_data;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/ordersas4.jpg"352">
We can see that the <b>assists</b> and <b>rebounds</b> variables are now in the first and second positions while all of the other variables remained in the same order.
<h2><span class="orange">How to Replace Missing Values with Zero in SAS</span></h2>
Often you may want to replace missing values in a SAS dataset with zeros.
Fortunately this is easy to do using a simple <b>if then</b> statement.
The following examples show how to replace missing values with zeros in practice.
<h3>Example 1: Replace Missing Values in All Columns</h3>
Suppose we have the following dataset in SAS with three columns, each with some missing values:
<b>/*create dataset*/
data my_data;
    input x y z;
    datalines;
1 . 76
2 3 .
2 3 85
4 5 88
2 2 .
1 2 69
5 . 94
4 1 .
. . 88
4 3 92
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/missing1.jpg"135">
We can use the following code to replace the missing values with zeros in every column of the dataset:
<b>/*create new dataset with missing values replaced by zero*/
data my_data_new;
   set my_data;
   array variablesOfInterest _numeric_;
   do over variablesOfInterest;
      if variablesOfInterest=. then variablesOfInterest=0;
   end;
run;
/*view new dataset*/
proc print data=my_data_new;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/missing2.jpg"137">
Notice that the missing values in each column have been replaced with zeros.
<b>Note</b>: The argument <b>_numeric_</b> tells SAS to replace the missing values with zeros in every numeric column in the dataset.
<h3>Example 2: Replace Missing Values in Specific Column</h3>
Once again suppose we have the following dataset in SAS with three columns, each with some missing values:
<b>/*create dataset*/
data my_data;
    input x y z;
    datalines;
1 . 76
2 3 .
2 3 85
4 5 88
2 2 .
1 2 69
5 . 94
4 1 .
. . 88
4 3 92
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/missing1.jpg"135">
We can use the following code to replace the missing values with zeros in only the “y” column of the dataset:
<b>/*create new dataset with missing values in "y" column replaced by zero*/
data my_data_new;
   set my_data;
   array variablesOfInterest y;
   do over variablesOfInterest;
      if variablesOfInterest=. then variablesOfInterest=0;
   end;
run;
/*view new dataset*/
proc print data=my_data_new;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/missing3.jpg"137">
Notice that only the missing values in the “y” column have been replaced with zeros.
<h2><span class="orange">How to Replace Characters in a String in SAS (With Examples)</span></h2>
You can use the <b>tranwrd()</b> function to replace characters in a string in SAS.
Here are the two most common ways to use this function:
<b>Method 1: Replace Characters in String with New Characters</b>
<b>data new_data;
    set original_data;
    new_variable = tranwrd(old_variable, "OldString", "NewString");
run;
</b>
<b>Method 2: Replace Characters in String with Blanks</b>
<b>data new_data;
    set original_data;
    new_variable = tranwrd(old_variable, "OldString", "");
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $1-20;
    datalines;
Angry Bees
Angry Hornets
Wild Mustangs
Kind Panthers
Kind Cobras
Wild Cheetahs
Wild Aardvarks
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/replacesas1.jpg"154">
<h3>Example 1: <b>Replace Characters in String with New Characters</b></h3>
The following code shows how to replace the word “Wild” in the team variable with the word “Fast”:
<b>/*replace "Wild" with "Fast" in team variable*/
data new_data;
    set original_data;
    new_team = tranwrd(team, "Wild", "Fast");
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/replacesas2.jpg"256">
Notice that each team that had “Wild” in the name now has the word “Fast” in the name instead.
Any team that did not have “Wild” in the name simply kept their original name.
<h3>Example 2: <b>Replace Characters in String with Blanks</b></h3>
The following code shows how to replace the word “Wild” in the team variable with a blank:
<b>/*replace "Wild" with a blank in team variable*/
data new_data;
    set original_data;
    new_team = tranwrd(team, "Wild", "");
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/replacesas3.jpg"273">
Notice that any team that had “Wild” in the name simply had the word “Wild” replaced with a blank.
<h2><span class="orange">How to Create a Residual Plot in SAS</span></h2>
<b>Residual plots</b> are often used to assess whether or not the  residuals  in a regression model are normally distributed and whether or not they exhibit  heteroscedasticity .
You can use the following basic syntax to fit a regression model and produce a residual plot for the model in SAS:
<b>symbol value = circle;
proc reg data=my_data;
    model y = x;
    plot residual. * predicted.;
run;
</b>
The following example shows how to use this syntax in practice.
<b>Note</b>: The symbol statement specifies that we would like to display the points in the residual plot as circles. The default shape is a plus sign.
<h2>Example: Create Residual Plot in SAS</h2>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input x y;
    datalines;
8 41
12 42
12 39
13 37
14 35
16 39
17 45
22 46
24 39
26 49
29 55
30 57
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/resid1.jpg"114">
We can use the following syntax to fit a  simple linear regression model  to this dataset and create a residual plot to visualize the residuals vs. predicted values:
<b>/*fit simple linear regression model and create residual plot*/
symbol value = circle;
proc reg data=my_data;
   model y = x;
   plot residual. * predicted.;
run;
</b>
 
The residual plot will be displayed at the bottom of the output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/resid2.jpg">
The x-axis displays the predicted values and the y-axis displays the residuals.
Since the residuals are randomly scattered about the value zero with no clear pattern of increasing or decreasing variance, the assumption of  homoscedasticity of residuals  is met.
Along the top of the plot we can also see the fitted regression equation:
y = 29.631 + 0.7553x
And along the right side of the plot we can also see the following metrics for the regression model:
<b>N</b>: Total number of observations (12)
<b>Rsq</b>: R-squared of the model (0.6324)
<b>AdjRsq</b>: Adjusted R-squared of the model (0.5956)
<b>RMSE</b>: The root mean squared error of the model (4.4417)
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Create Histograms in SAS 
 How to Create Scatter Plots in SAS 
 How to Identify Outliers in SAS 
<h2><span class="orange">How to Use the RETAIN Statement in SAS (With Examples)</span></h2>
You can use the <b>RETAIN</b> statement in SAS to specify some variable that should not have its value set to missing at the beginning of each iteration of a <b>DATA</b> step.
The <b>RETAIN</b> statement can be used for a variety of tasks in SAS, but here are the three most common use cases:
<b>Case 1: Use RETAIN to Calculate a Cumulative Sum</b>
<b>data new_data;
    set original_data;
    retain cum_sum;
    cum_sum + values_variable;
run;
</b>
<b>Case 2: Use RETAIN to Calculate a Cumulative Sum by Group</b>
<b>data new_data;
    set original_data;
    by grouping_variable
    retain cum_sum_by_group;
    if first.grouping_variable then cum_sum_by_group = values_variable;
    else cum_sum_by_group = cum_sum_by_group + values_variable;
run;</b>
<b>Case 3: Use RETAIN to Calculate a Cumulative Count by Group</b>
<b>data new_data;
    set original_data;
    by grouping_variable
    retain count_by_group;
    if first.grouping_variable then count_by_group = 1;
    else count_by_group = count_by_group + 1;
run;</b>
The following examples show how to use each case in practice with the following dataset in SAS that shows the sales made on consecutive days by different stores:
<b>/*create dataset*/
data original_data;
    input store $ sales;
    datalines;
A 4
A 5
A 2
B 6
B 3
B 5
C 3
C 8
C 6
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/retain1.jpg"160">
<h2>Example 1: Use RETAIN to Calculate a Cumulative Sum</h2>
The following code shows how to use the <b>RETAIN</b> statement to create a new column in the dataset that displays the cumulative sum of sales:
<b>/*calculate cumulative sum of sales*/
data new_data;
    set original_data;
    retain cum_sales;
    cum_sales+sales;
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/retain2.jpg"263">
The new column called <b>cum_sales </b>contains the cumulative sum of values in the <b>sales</b> column.
For example:
Cumulative sum on row 1: <b>4</b>
Cumulative sum on row 2: 4 + 5 = <b>9</b>
Cumulative sum on row 3: 4 + 5 + 2 = <b>11</b>
And so on.
In this example, the <b>RETAIN</b> statement set the variable called <b>cum_sales</b> to zero and then during each iteration of the <b>DATA</b> step, it simply added the new value of <b>sales</b> to the running total of <b>cum_sales</b>.
<h2>Example 2: Use RETAIN to Calculate a Cumulative Sum by Group</h2>
The following code shows how to use the <b>RETAIN</b> statement to create a new column in the dataset that displays the cumulative sum of sales by store:
<b>/*calculate cumulative sum of sales by store*/
data new_data;
    set original_data;
    by store;
    retain cum_sales_by_store;
    if first.store then cum_sales_by_store = sales;
    else cum_sales_by_store = cum_sales_by_store + sales;
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/retain3.jpg"328">
The new column called <b>cum_sales_by_store </b>contains the cumulative sum of values in the <b>sales</b> column, grouped by store.
In this example, the <b>RETAIN</b> statement set the variable called <b>cum_sales_by_store </b>to zero and then during each iteration of the <b>DATA</b> step, it checked if the value in the store column was the first occurrence of that particular value.
If it was the first occurrence, then the value of <b>cum_sales_by_store</b> was set to the value in the sales column. Else, the value in the sales column was added to the existing value for <b>cum_sales_by_store</b>.
<h2>Example 3: Use RETAIN to Calculate a Cumulative Count by Group</h2>
The following code shows how to use the <b>RETAIN</b> statement to create a new column in the dataset that displays the cumulative count of sales by store:
<b>/*calculate cumulative count by store*/ 
data new_data;
    set original_data;
    by store
    retain store_count;
    if first.store then store_count = 1;
    else store_count = store_count + 1;
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/retain4.jpg"260">
The new column called <b>store_count </b>contains the cumulative count of each store.
In this example, the <b>RETAIN</b> statement set the variable called <b>store_count </b>to zero and then during each iteration of the <b>DATA</b> step, it checked if the value in the store column was the first occurrence of that particular value.
If it was the first occurrence, then the value of <b>store_count </b>was set to 1. Else, a value of 1 was added to the existing value for <b>store_count</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Calculate the Sum by Group in SAS 
 How to Calculate the Mean by Group in SAS 
 How to Calculate a Moving Average in SAS 
<h2><span class="orange">How to Round Numbers in SAS (4 Examples)</span></h2>
You can use the following methods to round numbers in SAS:
<b>Method 1: Round to Nearest Integer</b>
<b>data new_data;
    set original_data;
    new_value = round(value);
run;
</b>
<b>Method 2: Round to Specific Decimal Places</b>
<b>data new_data;
    set original_data;
    new_value1 = round(value, .1); /*round to 1 decimal place*/
    new_value2 = round(value, .01); /*round to 2 decimal places*/
    new_value3 = round(value, .001); /*round to 3 decimal places*/
run;</b>
<b>Method 3: Round All Values Down (Or Up) to Next Integer</b>
<b>data new_data;
    set original_data;
    new_value1 = floor(value); /*round down to next integer*/
    new_value2 = ceil(value); /*round up to next integer*/
run;</b>
<b>Method 4: Round to Nearest Multiple</b>
<b>data new_data;
    set original_data;
    new_value1 = round(value, 10); /*round to nearest multiple of 10*/
    new_value2 = round(value, 100); /*round to nearest multiple of 100*/
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input value;
    datalines;
0.33
0.9
1.2593
1.61
2.89
4.3
8.8
14.4286
18.2
51.4
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/round1.jpg"121">
<h3>Example 1: <b>Round to Nearest Integer</b></h3>
The following code shows how to round each value to the nearest integer:
<b>/*round to nearest integer*/
data new_data;
    set original_data;
    new_value = round(value);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/round2.jpg"199">
<h3>
<b>Example 2: <b>Round to Specific Decimal Places</b></b>
</h3>
The following code shows how to round the values to a specific number of decimal places:
<b>data new_data;
    set original_data;
    new_value1 = round(value, .1); /*round to 1 decimal place*/
    new_value2 = round(value, .01); /*round to 2 decimal places*/
    new_value3 = round(value, .001); /*round to 3 decimal places*/
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/round3.jpg"381">
<h3>Example 3: Round All Values Down (Or Up) to Next Integer</h3>
The following code shows how to round all values down (or up) to the next integer using the <b>floor()</b> and <b>ceil()</b> functions:
<b>data new_data;
    set original_data;
    new_value1 = floor(value); /*round down to next integer*/
    new_value2 = ceil(value); /*round up to next integer*/
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/round4.jpg"284">
<h3>Method 4: Round to Nearest Multiple</h3>
The following code shows how to round all values to the nearest multiple of some value:
<b>data new_data;
    set original_data;
    nearest10 = round(value, 10); /*round to nearest multiple of 10*/
    nearest100 = round(value, 100); /*round to nearest multiple of 100*/
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/round5.jpg"267">
<h2><span class="orange">How to Use the SCAN Function in SAS (With Examples)</span></h2>
You can use the <b>SCAN </b>function in SAS to extract the <em>n</em>th word from a string.
This function uses the following basic syntax:
<b>SCAN(string, count)</b>
where:
<b>string</b>: The string to analyze
<b>count</b>: The <em>n</em>th word to extract
Here are the three most common ways to use this function:
<b>Method 1: Extract <em>n</em>th Word from String</b>
<b>data new_data;
    set original_data;
    second_word = scan(string_variable, 2);
run;
</b>
<b>Method 2: Extract Last Word from String</b>
<b>data new_data;
    set original_data;
    last_word = scan(string_variable, -1);
run;</b>
<b>Method 3: Extract Multiple Words from String</b>
<b>data new_data;
    set original_data;
    first_word = scan(string_variable, 1);
    second_word = scan(string_variable, 2);
    third_word = scan(string_variable, 3);
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input name $20. sales;
    datalines;
Andy Lincoln Bernard 55
Barren Michael Smith 41
Chad Simpson Arnolds 13
Derrick Parson Henry 29
Eric Miller Johansen 47
Frank Giovanni Goode 61
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scan1.jpg"261">
<h2>Example 1: Extract <em>n</em>th Word from String</h2>
The following code shows how to extract the second word from each string in the <b>name</b> column:
<b>/*extract second word in each row of name column*/
data new_data;
    set original_data;
    second_word = scan(name, 2);
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scan2.jpg">
Notice that the new column called <b>second_word</b> contains the second word from each string in the <b>name</b> column.
<h2>Example 2: Extract Last Word from String</h2>
The following code shows how to use the value <b>-1</b> in the scan function to extract the last word from each string in the <b>name</b> column:
<b>/*extract last word in each row of name column*/
data new_data;
    set original_data;
    last_word = scan(name, -1);
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scan3.jpg"354">
Notice that the new column called <b>last_word</b> contains the last word from each string in the <b>name</b> column.
<h2>Example 3: Extract Multiple Words from String</h2>
The following code shows how to use the scan function to extract every word from each string in the <b>name</b> column:
<b>/*extract each word in each row of name column*/
data new_data;
    set original_data;
    first_word = scan(name, 1);
    second_word = scan(name, 2);
    third_word = scan(name, 3);
run;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scan4.jpg"528">
Notice that three new columns have been created that contain the first, second, and third word from each string in the <b>name</b> column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use the SUBSTR Function in SAS 
 How to Use the FIND Function in SAS 
 How to Use the COALESCE Function in SAS 
<h2><span class="orange">How to Create a Scatter Plot Matrix in SAS</span></h2>
A <b>scatter plot matrix</b> is exactly what it sounds like – a matrix of scatterplots.
This type of matrix is useful because it allows you to visualize the relationship between multiple variables in a dataset at once.
You can use the following basic syntax to create a scatter plot matrix in SAS:
<b>proc sgscatter data=my_data;
  matrix var1 var2 var3;
run;
</b>
This particular syntax creates a scatter plot matrix for the variables <b>var1</b>, <b>var2</b>, and <b>var3</b> in the dataset called <b>my_data</b>.
The following example shows how to use this syntax in practice.
<h2>Example: Create Scatter Plot Matrix in SAS</h2>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points assists rebounds;
    datalines;
A 22 12 8
A 20 18 4
A 14 9 5
A 30 16 10
B 10 4 3
B 9 5 12
B 6 5 14
B 14 10 5
C 4 8 12
C 13 10 5
C 11 12 8
C 19 3 2
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scattermatrix1.jpg"282">
We can use the following syntax to create a scatter plot to visualize the relationship between the <b>points</b>, <b>assists</b>, and <b>rebounds</b> variables:
<b>/*create scatter plot matrix*/
proc sgscatter data=my_data;
  matrix points assists rebounds;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scattermatrix2.jpg"553">
Note that we can also use the <b>title</b> function to add a title to the overall matrix and the <b>group</b> function to color the points in the plot based on the value for the team variable:
<b>/*create scatter plot matrix with points colored by team*/
proc sgscatter data=my_data;
  title "Scatterplot Matrix";
  matrix points assists rebounds / group=team;
run;
title;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/scattermatrix3.jpg">
The scatter plot matrix now has a title and the points in each scatter plot are colored based on their team value.
<h2>Additional Resources</h2>
The following tutorials explain how to create other common charts in SAS:
 How to Create Scatter Plots in SAS 
 How to Create Line Plots in SAS 
 How to Create Boxplots by Group in SAS 
<h2><span class="orange">How to Create Scatter Plots in SAS (With Examples)</span></h2>
You can use the following methods to create scatter plots in SAS:
<b>Method 1: Create One Scatter Plot</b>
<b>proc sgplot data=my_data;
    scatter x=var1 y=var2;
run;
</b>
<b>Method 2: Create Scatter Plots by Group</b>
<b>proc sgplot data=my_data;
    scatter x=var1 y=var2 / group=var3;
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points rebounds;
    datalines;
A 29 8
A 23 6
A 20 6
A 21 9
A 33 14
A 35 11
A 31 10
B 21 9
B 14 5
B 15 7
B 11 10
B 12 6
B 10 8
B 15 10
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/hist1.jpg"208">
<h3>Example 1: <b>Create One Scatter Plot</b></h3>
The following code shows how to create a scatterplot for the <b>points</b> and <b>rebounds</b> variables:
<b>proc sgplot data=my_data;
    scatter x=points y=rebounds;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sas1.jpg"556">
The x-axis displays the values for the <b>points</b> variable and the y-axis displays the values for the <b>rebounds</b> variable.
Note that we can also add a title to the plot and modify the appearance of the markers within the plot to make it more aesthetically pleasing:
<b>title "Points vs. Rebounds";
proc sgplot data=my_data;
    scatter x=points y=rebounds /
    markerattrs=(symbol=CircleFilled size=12 color=purple);
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sas2.jpg"579">
<h3>Example 2: <b>Create Scatter Plots by Group</b></h3>
The following code shows how to create a scatterplot of <b>points</b> vs. <b>rebounds</b> in which the markers are colored based on <b>team</b>:
<b>title "Points vs. Rebounds by Team";
proc sgplot data=my_data;
    scatter x=points y=rebounds /
    markerattrs=(symbol=CircleFilled size=12)
    group=team;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sas3.jpg"598">
This plot allows us to quickly visualize the relationship between points and rebounds for both team A and team B.
<h2><span class="orange">How to Select the First N Rows of a Dataset in SAS</span></h2>
Here are the two most common ways to select the first N rows from a dataset in SAS:
<b>Method 1: Select First Row</b>
<b>data first_row;
    set original_data;
    if _N_ = 1 then output;
run;
</b>
<b>Method 2: Select First N Rows</b>
<b>data first_N_rows;
    set original_data;
    if _N_ &lt;= 5 then output; /*select first 5 rows*/
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
Warriors 25 8
Wizards 18 12
Rockets 22 6
Celtics 24 11
Thunder 27 14
Spurs 33 19
Nets 31 20
Mavericks 34 10
Kings 22 11
Pelicans 39 23
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/randomsas1.jpg"248">
<h3>Example 1: Select First Row</h3>
The following code shows how to select just the first row of the dataset:
<b>/*create new dataset that contains only the first row*/
data first_row;
    set original_data;
    if _N_ = 1 then output;
run;
/*view new dataset*/
proc print data=first_row;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/n1.jpg"249">
We can see that the new dataset contains only the first row of the original dataset.
<h3>Example 2: Select First N Rows</h3>
The following code shows how to select the first five rows of the dataset:
<b>/*create new dataset that contains first 5 rows of original dataset*/
data first_N_rows;
    set original_data;
    if _N_ &lt;= 5 then output;
run;
/*view new dataset*/
proc print data=first_N_rows;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/n2.jpg"242">
We can see that the new dataset contains only the first five rows of the original dataset.
To select a different number of starting rows, simply change the value after <b>_N_</b> in the code above.
<h2><span class="orange">SAS: How to Use SET Statement with Multiple Datasets</span></h2>
You can use the following basic syntax to include multiple datasets in the <b>set</b> statement in SAS:
<b>data new_data;
    set data1 data2 data3;
run;
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Use SET Statement with Multiple Datasets in SAS</h2>
Suppose we have the following dataset in SAS that shows the points scored by various basketball players on a team called A:
<b>/*create first dataset*/
data data1;
    input team $ points;
    datalines;
A 12
A 15
A 16
A 21
A 22
;
run;
/*view dataset*/
proc print data=data1;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/set11.jpg"171">
And suppose we have another dataset that shows the points scored by various basketball players on a team called B:
<b>/*create second dataset*/
data data2;
    input team $ points;
    datalines;
B 16
B 22
B 25
B 29
B 30
;
run;
/*view dataset*/
proc print data=data2; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/set12.jpg"171">
We can use the <b>set</b> statement with multiple datasets to combine these two datasets into one:
<b>/*create new dataset that combines two datasets*/
data data3;
    set data1 data2;
run;
/*view new dataset*/
proc print data=data3; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/set13.jpg"157">
The result is a third dataset called <b>data3</b> that combines the rows from <b>data1</b> and <b>data2</b>.
<b>Note</b>: Even if the two datasets didn’t share the same column names, the <b>set</b> statement would still combine the datasets into one and simply leave empty spaces in the cells where the columns don’t match.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Delete Datasets in SAS 
 How to Add Row Numbers in SAS 
 How to Select the First N Rows of a Dataset in SAS 
<h2><span class="orange">SAS: How to Split Strings by Delimiter</span></h2>
You can use the <b>scan()</b> function in SAS to quickly split a string based on a particular delimiter.
The following example shows how to use this function in practice.
<h3>Example: Split Strings by Delimiter in SAS</h3>
Suppose we have the following dataset in SAS:
<b>/*create dataset*/
data my_data1;
    input name $25.;
    datalines;
Andy_Lincoln_Bernard
Barry_Michael
Chad_Simpson_Smith
Derrick_Parson_Henry
Eric_Miller
Frank_Giovanni_Goodwill
;
run;
/*print dataset*/
proc print data=my_data1;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/delim1.jpg"220">
We can use the following code to quickly split the name string into three separate strings:
<b>/*create second dataset with name split into three columns*/
data my_data2;
    set my_data1;
    name1=scan(name, 1, '_');
    name2=scan(name, 2, '_');
    name3=scan(name, 3, '_');
run;
/*view second dataset*/
proc print data=my_data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/delim2.jpg"410">
Notice that the string in the <b>name</b> column has been split into three new columns.
For the names where there was only one delimiter, the value in the <b>name3</b> column is simply blank.
Note that we could also use the <b>drop</b> function to drop the original name column from the new dataset:
<b>/*create second dataset with name split into three columns, drop original name*/
data my_data2;
    set my_data1;
    name1=scan(name, 1, '_');
    name2=scan(name, 2, '_');
    name3=scan(name, 3, '_');
    drop name;
run;
/*view second dataset*/
proc print data=my_data2;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/delim3.jpg"255">
<h2><span class="orange">How to Calculate Standard Deviation in SAS (3 Examples)</span></h2>
You can use the following methods to calculate the  standard deviation  of values in SAS:
<b>Method 1: Calculate Standard Deviation of One Variable</b>
<b>proc means data=my_data std;
    var variable1;
run;
</b>
<b>Method 2: Calculate Standard Deviation of All Numeric Variables</b>
<b>proc means data=my_data std;
run;</b>
<b>Method 3: Calculate Standard Deviation by Group</b>
<b>proc means data=my_data std;
    class grouping_variable;
    var values_variable;
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ points rebounds;
    datalines;
A 23 6
A 31 5
A 33 5
A 18 8
A 20 9
A 25 12
B 18 10
B 20 7
B 17 8
B 14 3
B 14 3
B 15 6
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/stdev1.jpg"236">
<h3>Example 1: <b>Calculate Standard Deviation of One Variable</b></h3>
The following code shows how to calculate the standard deviation of just the <b>points</b> variable.
<b>proc means data=my_data std;
    var points;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/stdev2.jpg"197">
The standard deviation of the points variable turns out to be <b>6.2716</b>.
<h3>
<b>Example 2: <b>Calculate Standard Deviation of All Numeric Variables</b></b>
</h3>
The following code shows how to calculate the standard deviation of all numeric variables in the dataset:
<b>proc means data=my_data std;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/stdev3.jpg"176">
From the output we can see that the standard deviation for points is <b>6.2716</b> and the standard deviation for rebounds is <b>2.7247</b>.
Since the standard deviation for points is larger, this tells us that the values are more spread out for the points variable compared to the rebounds variable.
<h3>Example 3: Calculate Standard Deviation by Group</h3>
The following code shows how to calculate the standard deviation of <b>points</b>, grouped by <b>team</b>:
<b>proc means data=my_data std;
    class team;
    var points;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/stdev4.jpg"205">
From the output we can see that the standard deviation of points for team A is <b>5.9665</b> and the standard deviation of points for team B is <b>2.4221</b>.
<h2><span class="orange">How to Use the SUBSTR Function in SAS (With Examples)</span></h2>
You can use the <b>SUBSTR</b> function in SAS to extract a portion of a string.
This function uses the following basic syntax:
<b>SUBSTR(Source, Position, N)</b>
where:
<b>Source</b>: The string to analyze
<b>Position</b>: The starting position to read
<b>N</b>: The number of characters to read
Here are the four most common ways to use this function:
<b>Method 1: Extract First N Characters from String</b>
<b>data new_data;
    set original_data;
    first_four = substr(string_variable, 1, 4);
run;
</b>
<b>Method 2: Extract Characters in Specific Position Range from String</b>
<b>data new_data;
    set original_data;
    two_through_five = substr(string_variable, 2, 4);
run;</b>
<b>Method 3: Extract Last N Characters from String</b>
<b>data new_data;
    set original_data;
    last_three = substr(string_variable, length(string_variable)-2, 3);
run;</b>
<b>Method 4: Create New Variable if Characters Exist in String</b>
<b>data new_data;
    set original_data;
    if substr(string_variable, 1, 4) = 'some_string' then new_var = 'Yes';
    else new_var = 'No';
run;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $1-10;
    datalines;
Warriors
Wizards
Rockets
Celtics
Thunder
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/substr1.jpg"130">
<h3>Example 1: Extract First N Characters from String</h3>
The following code shows how to extract the first 4 characters from the <b>team</b> variable:
<b>/*create new dataset*/
data new_data;
    set original_data;
    first_four = substr(team, 1, 4);
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/substr2.jpg"205">
Notice that the <b>first_four</b> variable contains the first four characters of the <b>team</b> variable.
<h3>Example 2: Extract Characters in Specific Position Range from String</h3>
The following code shows how to extract the characters in positions 2 through 5 from the <b>team</b> variable:
<b>/*create new dataset*/
data new_data;
    set original_data;
    two_through_five = substr(team, 2, 4);
run;
/*view new dataset*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/substr3.jpg"255">
<h3>Example 3: Extract Last N Characters from String</h3>
The following code shows how to extract the last 3 characters from the <b>team</b> variable:
<b>/*create new dataset*/
data new_data;
    set original_data;
    last_three = substr(team, length(team)-2, 3);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/substr4.jpg"200">
<h3>Example 4: Create New Variable if Characters Exist in String</h3>
The following code shows how to create a new variable called <b>W_Team</b> that takes a value of ‘<b>yes</b>‘ if the first character in the team name is ‘W’ or a value of ‘<b>no</b>‘ if the first characters is not a ‘W.’
<b>/*create new dataset*/
data new_data;
    set original_data;
    if substr(team, 1, 1) = 'W' then W_Team = 'Yes';
    else W_Team = 'No';
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/substr5.jpg"198">
<h2><span class="orange">How to Calculate the Sum by Group in SAS</span></h2>
You can use the following methods to calculate the sum of values by group in SAS:
<b>Method 1: Calculate Sum by One Group</b>
<b>proc sql;
    select var1, sum(var2) as sum_var2
    from my_data
    group by var1;
quit;
</b>
<b>Method 2: Calculate Sum by Multiple Groups</b>
<b>proc sql;
    select var1, var2, sum(var3) as sum_var3
    from my_data
    group by var1, var2;
quit;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 15
A Guard 12
A Guard 29
A Forward 13
A Forward 9
A Forward 16
B Guard 25
B Guard 20
B Guard 34
B Forward 19
B Forward 3
B Forward 8
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sasSum1.jpg"216">
<h3>Example 1: Calculate Sum by One Group</h3>
The following code shows how to calculate the sum of points by team:
<b>/*calculate sum of points by team*/
proc sql;
    select team, sum(points) as sum_points
    from my_data
    group by team;
quit;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sasSum2.jpg"150">
From the output we can see that players on team A scored a total of <b>94</b> points and players on team B scored a total of <b>109</b> points.
<h3>Example 2: Calculate Sum by Multiple Groups</h3>
The following code shows how to calculate the sum of points, group by team and position:
<b>/*calculate sum of points by team, grouped by team and position*/
proc sql;
    select team, position, sum(points) as sum_points
    from my_data
    group by team, position;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sasSum3.jpg"225">
The resulting table shows the sum of points scored by players based on their team and position.
<h2><span class="orange">How to Add Titles in SAS (With Examples)</span></h2>
You can use the <b>title</b> statement in SAS to quickly add a title to a table or chart.
This statement uses the following basic syntax:
<b>Method 1: Add One Title</b>
<b>/*define title*/
title "This is a title";
/*view dataset with title*/
proc print data=my_data;</b>
<b>Method 2: Add Multiple Titles</b>
<b>/*define titles*/
title1 color="purple" height=25pt bold italic underline=1 "This is a Title";
title2 font="Helvetica" justify=left height=18pt "Second Title";
title3 color="green" justify=right height=14pt "Third Title";
/*view dataset with title*/
proc print data=my_data;
</b>
Note the following statements that you can use to modify the titles:
<b>color</b>: The font color
<b>height</b>: The font size
<b>font</b>: The font family
<b>justify</b>: The location of the title (left, right, center)
<b>style</b>: Use “bold”, “italic”, or “underlin” to modify the font style
The following examples show how to use each method in practice.
<h3>Example 1: Add One Title</h3>
The following code shows how to add one title to a dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 25 10
A 18 4
B 27 9
B 33 13
;
run;
/*view dataset*/
title "This is a title";
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/titlesas1.jpg">
<h3>Example 2: Add Multiple Titles</h3>
The following code shows how to add multiple titles with custom designs to a dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $ points rebounds;
    datalines;
A 25 10
A 18 4
B 27 9
B 33 13
;
run;
/*view dataset*/
title1 color="purple" height=25pt bold italic underlin=1 "First Title";
title2 font="Helvetica" justify=left height=18pt "Second Title";
title3 color="green" justify=right height=14pt "Third Title";
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/titlesas2.jpg"577">
Note that you can use the <b>title1</b>, <b>title2</b>, <b>title3</b>, etc. syntax to add up to <b>10</b> lines of titles to a chart or table.
<h2><span class="orange">SAS: Convert Strings to Uppercase, Lowercase & Proper Case</span></h2>
You can use the following methods to convert strings to uppercase, lowercase, and proper case in SAS:
<b>Method 1: Convert String to Uppercase</b>
<b>new_string = UPCASE(old_string);
</b>
<b>Method 2: Convert String to Lowercase</b>
<b>new_string = LOWCASE(old_string); </b>
<b>Method 3: Convert String to Proper Case</b>
<b>new_string = PROPCASE(old_string); </b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input team $1-20;
    datalines;
Washington wizards
Houston rockets
Boston celtics
San antonio spurs
Orlando magic
Miami heat
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/casesas1.jpg"187">
<h3>Example 1: Convert Strings to Uppercase</h3>
The following code shows how to create a new dataset in which all of the team names are converted to uppercase:
<b>/*create new dataset*/
data new_data;
    set original_data;
    team = UPCASE(team);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/casesas2.jpg"204">
Notice that each of the team names have been converted to uppercase.
<h3>Example 2: Convert Strings to Lowercase</h3>
The following code shows how to create a new dataset in which all of the team names are converted to lowercase:
<b>/*create new dataset*/
data new_data;
    set original_data;
    team = LOWCASE(team);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/casesas3.jpg"193">
Notice that each of the team names have been converted to lowercase.
<h3>Example 3: Convert Strings to Proper Case</h3>
The following code shows how to create a new dataset in which all of the team names are converted to proper case:
<b>Note</b>: Proper case means the first letter of each word is capitalized.
<b>/*create new dataset*/
data new_data;
    set original_data;
    team = PROPCASE(team);
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/casesas4.jpg"193">
Notice that each of the team names have been converted to proper case.
<h2><span class="orange">How to Calculate a Weighted Average in SAS (With Examples)</span></h2>
You can use the following methods to calculate a weighted average in SAS:
<b>Method 1: Calculate Weighted Average</b>
<b>proc sql;
    create table new_data as
    select sum(weight * value) / sum(weight) as weighted_average
    from original_data;
quit;
</b>
<b>Method 2: Calculate Weighted Average by Group</b>
<b>proc sql;
    create table new_data as
    select grouping_variable,
    sum(weight * value) / sum(weight) as weighted_average
    from original_data
    group by grouping_variable;
quit;</b>
The following examples show how to use each method with the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input sales_rep $ price amount;
    datalines;
A 8 1
A 5 3
A 6 2
B 7 2
B 12 5
B 14 4
;
run;
/*view dataset*/
proc print data=original_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/wa1.jpg"240">
<h3>Example 1: Calculate Weighted Average</h3>
The following code shows how to calculate a weighted average for the <b>price</b> variable, using the <b>amount</b> variable as the weight:
<b>/*calculate weighted average of price*/
proc sql;
    create table new_data as
    select sum(amount * price) / sum(amount) as weighted_average
    from original_data;
quit;
/*view weighted average of price*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/wa2.jpg"191">
The weighted average of price turns out to be <b>9.70588</b>.
<h3>Example 2: Calculate Weighted Average by Group</h3>
The following code shows how to calculate the weighted average of the <b>price</b> variable, grouped by the <b>sales_rep</b> variable:
<b>/*calculate weighted average of price, grouped by sales_rep*/
proc sql;
    create table new_data as
    select sales_rep,
    sum(amount * price) / sum(amount) as weighted_average
    from original_data
    group by sales_rep;
quit;
/*view results*/
proc print data=new_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/wa3.jpg"270">
From the output we can see:
The weighted average of price for sales rep A is <b>5.8333</b>.
The weighted average of price for sales rep B is <b>11.8182</b>.
<h2><span class="orange">The Satterthwaite Approximation: Definition & Example</span></h2>
The <b>Satterthwaite approximation</b> is a formula used to find the “effective degrees of freedom” in a two-sample t-test.
It used most commonly in  Welch’s t-test , which compares the means of two independent samples without assuming that the populations the  samples  came from have equal variances.
The formula for the Satterthwaite approximation is as follows:
<b>Degrees of freedom: (s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup> / {[(s<sub>1</sub><sup>2</sup>/n<sub>1</sub>)<sup>2</sup>/(n<sub>1</sub> – 1)] + [(s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup>/(n<sub>2</sub> – 1)]}
</b>
where:
<b>s<sub>1</sub><sup>2</sup>, s<sub>2</sub><sup>2</sup>:</b> The sample variance of the first and second sample, respectively.
<b>n<sub>1</sub>, n<sub>2</sub>:</b> The sample size of the first and second sample, respectively.
The following example shows how to use the Satterthwaite approximation to calculate the effective degrees of freedom.
<h3>Example: Calculating the Satterthwaite approximation</h3>
Suppose we want to know if the mean height of two different plant species is equal so we go out and collect two simple random samples of each species and measure the height of the plants in each sample.
The following values show the height (in inches) for each sample:
<b>Sample 1:</b> 14, 15, 15, 15, 16, 18, 22, 23, 24, 25, 25
<b>Sample 2:</b> 10, 12, 14, 15, 18, 22, 24, 27, 31, 33, 34, 34, 34
The means, variances, and sample sizes turn out to be:
<b>x<sub>1</sub></b>= 19.27
<b>x<sub>2</sub></b> = 23.69
<b>s<sub>1</sub><sup>2</sup></b> = 20.42
<b>s<sub>2</sub><sup>2</sup></b>= 83.23
<b>n</b><sub><b>1 </b></sub>= 11
<b>n</b><sub><b>2</b> </sub>=13
Next, we can plug in the values for the variances and sample sizes into the Satterthwaite approximation formula to find the effective degrees of freedom:
<b>df = (s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup> / {[(s<sub>1</sub><sup>2</sup>/n<sub>1</sub>)<sup>2</sup>/(n<sub>1</sub> – 1)] + [(s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup>/(n<sub>2</sub> – 1)]} 
df = (20.42/11 + 83.23/13)<sup>2</sup>/{[(20.42/11)<sup>2</sup>/(11 – 1)] + [(83.23/13)<sup>2</sup>/(13 – 1)]} = 18.137</b>
The effective degrees of freedom turns out to be <b>18.137</b>.
Typically we round this value down to the next nearest integer, so the degrees of freedom that we would use in our Welch’s t-test is <b>18</b>.
Lastly, would will find the <em>t </em>critical value in the t-distribution table that corresponds to a two-tailed test with alpha = .05 for 18 degrees of freedom:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/t_dist.png">
The t critical value is <b>2.101</b>.
We would then calculate our test statistic to be:
<b>Test statistic: </b>(x<sub>1</sub> – x<sub>2</sub>)  /  (√s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)
Test statistic: (19.27 – 23.69) / (√20.42/11 + 83.23/13) =  -4.42 / 2.873  =  <b>-1.538</b>
Since the absolute value of our test statistic (1.538) is not larger than the t critical value, we fail to reject the null hypothesis of the test.
There is not sufficient evidence to say that the means of the two populations are significantly different.
<h3>The Satterthwaite Approximation in Practice</h3>
In practice, you will rarely have to calculate the Satterthwaite approximation by hand.
Instead, common statistical software like R, Python, Excel, SAS, and Stata can all use the Satterthwaite approximation to calculate the effective degrees of freedom automatically for you.
<h2><span class="orange">How to Save Seaborn Plot to a File (With Examples)</span></h2>
You can use the following syntax to save a Seaborn plot to a file:
<b>import seaborn as sns
line_plot = sns.lineplot(x=x, y=y)
fig = line_plot.get_figure()
fig.savefig('my_lineplot.png')  </b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Save Seaborn Plot to PNG File</h3>
The following code shows how to save a Seaborn plot to a PNG file:
<b>import seaborn as sns
#set theme style
sns.set_style('darkgrid')
#define data
x = [1, 2, 3, 4, 5, 6]
y = [8, 13, 14, 11, 16, 22]
#create line plot and save as PNG file
line_plot = sns.lineplot(x=x, y=y)
fig = line_plot.get_figure()
fig.savefig('my_lineplot.png')  </b>
If we navigate to the location where we saved the file, we can view it:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/save1.png">
Note that we could also use <b>.jpg</b>, <b>.pdf</b>, or other file extensions to save the plot to a different type of file.
<h3>Example 2: Save Seaborn Plot to PNG File with Tight Layout</h3>
By default, Seaborn adds padding around the outside of the figure.
To remove this padding, we can use the <b>bbox_inches=’tight’</b> argument: 
<b>fig.savefig('my_lineplot.png', bbox_inches='tight')  </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/save2.png">
Notice that there is minimal padding around the outside of the plot now.
<h3>Example 3: Save Seaborn Plot to PNG File with Custom Size</h3>
You can use the <b>dpi</b> argument to increase the size of the Seaborn plot when saving it to a file:
<b>fig.savefig('my_lineplot.png', dpi=100)  </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/save3.png">
Notice that this plot is much larger than the previous two. The larger the value you use for <b>dpi</b>, the larger the plot will be.
<h2><span class="orange">How to Use the scale() Function in R (With Examples)</span></h2>
The <b>scale()</b> function in R can be used to scale the values in a vector, matrix, or data frame.
This function uses the following basic syntax:
<b>scale(x, center = TRUE, scale = TRUE)
</b>
where:
<b>x</b>: Name of the object to scale
<b>center</b>: Whether to subtract the mean when scaling. Default is TRUE.
<b>scale</b>: Whether to divide by the standard deviation when scaling. Default is TRUE.
This function uses the following formula to calculate scaled values:
<b>x<sub>scaled</sub> = (x<sub>original</sub> – x<U+0304>) / s</b>
where:
<b>x<sub>original</sub></b>: The original x-value
<b>x<U+0304></b>: The sample mean
<b>s</b>: The sample standard deviation
This is also known as <em>standardizing</em> data, which simply converts each original value into a  z-score .
The following examples show how to use this function in practice.
<h3>Example 1: Scale the Values in a Vector</h3>
Suppose we have the following vector of values in R:
<b>#define vector of values
x &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
#view mean and standard deviation of values
mean(x)
[1] 5
sd(x)
[1] 2.738613
</b>
The following code shows how to scale the values in the vector using the <b>scale()</b> function:
<b>#scale the values of x
x_scaled &lt;- scale(x)
#view scaled values
x_scaled
            [,1]
 [1,] -1.4605935
 [2,] -1.0954451
 [3,] -0.7302967
 [4,] -0.3651484
 [5,]  0.0000000
 [6,]  0.3651484
 [7,]  0.7302967
 [8,]  1.0954451
 [9,]  1.4605935
</b>
Here is how each scaled value was calculated:
Value 1: (1 – 5) / 2.738613 = <b>-1.46</b>
Value 2: (2 – 5) / 2.738613 = <b>-1.09</b>
Value 3: (3 – 5) / 2.738613 = <b>-0.73</b>
And so on.
Note that if we specified <b>scale=FALSE</b> then the function would not have divided by the standard deviation when performing the scaling:
<b>#scale the values of x but don't divide by standard deviation
x_scaled &lt;- scale(x, scale = FALSE)
#view scaled values
x_scaled
      [,1]
 [1,]   -4
 [2,]   -3
 [3,]   -2
 [4,]   -1
 [5,]    0
 [6,]    1
 [7,]    2
 [8,]    3
 [9,]    4
</b>
Here is how each scaled value was calculated:
Value 1: 1 – 5 = <b>-4</b>
Value 2: 2 – 5 = <b>-3</b>
Value 3: 3 – 5 = <b>-2</b>
And so on.
<h3>Example 2: Scale the Column Values in a Data Frame</h3>
More often than not, we use the scale() function when we want to scale the values in multiple columns of a data frame such that each column has a mean of 0 and a standard deviation of 1.
For example, suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7, 8, 9), y=c(10, 20, 30, 40, 50, 60, 70, 80, 90))
#view data frame
df
  x  y
1 1 10
2 2 20
3 3 30
4 4 40
5 5 50
6 6 60
7 7 70
8 8 80
9 9 90
</b>
Notice that the range of values for the y variable is much larger than the range of values for the x variable.
We can use the <b>scale()</b> function to scale the values in both columns such that the scaled values of x and y both have a mean of 0 and a standard deviation of 1:
<b>#scale values in each column of data frame
df_scaled &lt;- scale(df)
#view scaled data frame
df_scaled
               x          y
 [1,] -1.4605935 -1.4605935
 [2,] -1.0954451 -1.0954451
 [3,] -0.7302967 -0.7302967
 [4,] -0.3651484 -0.3651484
 [5,]  0.0000000  0.0000000
 [6,]  0.3651484  0.3651484
 [7,]  0.7302967  0.7302967
 [8,]  1.0954451  1.0954451
 [9,]  1.4605935  1.4605935
</b>
Both the x column and the y column now have a mean of 0 and a standard deviation of 1.
<h2><span class="orange">How to Interpret a Scale-Location Plot (With Examples)</span></h2>
A <b>scale-location plot</b> is a type of plot that displays the fitted values of a  regression model  along the x-axis and the the square root of the standardized residuals along the y-axis.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/scaleLocation1.png">
When looking at this plot, we check for two things:
<b>1.</b> Verify that the red line is roughly horizontal across the plot. If it is, then the assumption of  homoscedasticity  is likely satisfied for a given regression model. That is, the spread of the residuals is roughly equal at all fitted values.
<b>2. </b>Verify that there is no clear pattern among the residuals. In other words, the residuals should be randomly scattered around the red line with roughly equal variability at all fitted values.
<h3>Scale-Location Plot in R</h3>
We can use the following code to fit a simple linear regression model in R and produce a scale-location plot for the resulting model:
<b>#fit simple linear regression model
model &lt;- lm(Ozone ~ Temp, data = airquality)
#produce scale-location plot
plot(model)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/scaleLocation2.png">
We can observe the following two things from the scale-location plot for this regression model.
<b>1.</b> The red line is roughly horizontal across the plot. If it is, then the assumption of  homoscedasticity  is satisfied for a given regression model. That is, the spread of the residuals is roughly equal at all fitted values.
<b>2. </b>Verify that there is no clear pattern among the residuals. In other words, the residuals should be randomly scattered around the red line with roughly equal variability at all fitted values.
<b>Technical Note</b>
 
The three observations from the dataset with the highest standardized residuals are labelled in the plot.
 
We can see that the observations in rows 30, 62, and 117 have the highest standardized residuals.
 
This doesn’t necessarily mean that these observations are outliers, but you may want to view the original data to take a closer look at these observations.
Although we can see that the red line is roughly horizontal across the scale-location plot, this only serves as a visual way to see if the assumption of homoscedasticity is met.
A formal statistical test we can use to see if the assumption of homoscedasticity is met is the  Breusch-Pagan Test .
<h3>Breusch-Pagan Test in R</h3>
The following code shows how to use the <b>bptest()</b> function from the <b>lmtest</b> package to perform a Breusch-Pagan Test in R:
<b>#load lmtest package
library(lmtest)
#perform Breusch-Pagan Test
bptest(model)
studentized Breusch-Pagan test
data:  model
BP = 1.4798, df = 1, p-value = 0.2238
</b>
A Breusch-Pagan Test uses the following null and alternative hypotheses:
Null Hypothesis (H<sub>0</sub>): The residuals are homoscedastic (i.e. evenly spread)
Alternative Hypothesis (H<sub>A</sub>): The residuals are heteroscedastic (i.e. not evenly spread)
From the output we can see that the p-value of the test is <b>0.2238</b>. Since this p-value is not less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that heteroscedasticity is present in the regression model.
This result matches our visual inspection of the red line in the scale-location plot.
<h2><span class="orange">How to Create a Scatter Matrix in Pandas (With Examples)</span></h2>
A scatter matrix is exactly what it sounds like – a matrix of scatterplots.
This type of matrix is useful because it allows you to visualize the relationship between multiple variables in a dataset at once.
You can use the <b>scatter_matrix()</b> function to create a scatter matrix from a pandas DataFrame:
<b>pd.plotting.scatter_matrix(df)
</b>
The following examples show how to use this syntax in practice with the following pandas DataFrame:
<b>import pandas as pd
import numpy as np
#make this example reproducible
np.random.seed(0)
#create DataFrame
df = pd.DataFrame({'points': np.random.randn(1000),   'assists': np.random.randn(1000),   'rebounds': np.random.randn(1000)})
#view first five rows of DataFrame
df.head()
points        assists        rebounds
01.7640520.555963-1.532921
10.4001570.892474-1.711970
20.978738-0.4223150.046135
32.2408930.104714-0.958374
41.8675580.228053-0.080812
</b>
<h3>Example 1: Basic Scatter Matrix</h3>
The following code shows how to create a basic scatter matrix:
<b>pd.plotting.scatter_matrix(df)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/scattermatrix1.png">
<h3>Example 2: Scatter Matrix for Specific Columns</h3>
The following code shows how to create a scatter matrix for just the first two columns in the DataFrame:
<b>pd.plotting.scatter_matrix(df.iloc[:, 0:2])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/scattermatrix2.png">
<h3>Example 3: Scatter Matrix with Custom Colors & Bins</h3>
The following code shows how to create a scatter matrix with custom colors and a specific number of bins for the histograms:
<b>pd.plotting.scatter_matrix(df, color='red', hist_kwds={'bins':30, 'color':'red'})
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/scattermatrix3.png">
<h3>Example 4: Scatter Matrix with KDE Plot</h3>
The following code shows how to create a scatter matrix with a kernel density estimate plot along the diagonals of the matrix instead of a histogram:
<b>pd.plotting.scatter_matrix(df, diagonal='kde')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/scattermatrix4.png">
You can find the complete online documentation for the <b>scatter_matrix()</b> function  here .
<h2><span class="orange">How to Create Scatter Plots by Group in R (2 Examples)</span></h2>
You can use the following methods to create a scatter plot by group in R:
<b>Method 1: Use Base R</b>
<b>plot(df$x, df$y, col=as.factor(df$group))
</b>
<b>Method 2: Use ggplot2</b>
<b>library(ggplot2)
ggplot(df, aes(x, y)) +
  geom_point(aes(color=group))</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 5, 6, 7), y=c(4, 8, 7, 9, 15, 14, 20), group=c('A', 'A', 'A', 'B', 'B', 'B', 'B'))
#view data frame
df
  x  y group
1 1  4     A
2 2  8     A
3 2  7     A
4 3  9     B
5 5 15     B
6 6 14     B
7 7 20     B
</b>
<h3>Example 1: Scatter Plot by Group in Base R</h3>
The following code shows how to create a scatterplot in base R where the points are colored based on the value of the ‘group’ variable:
<b>#create scatterplot with points colored by group
plot(df$x, df$y, col=as.factor(df$group), pch=19)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/colorgroup1.jpg"462">
The color of each point reflects the value of the ‘group’ variable in the data frame.
The points with a ‘group’ value of A are shown in black and the points with a ‘group’ value of B are shown in red.
Note that <b>pch=19</b> tells R to use solid circles for the points in the plot.
You can find a complete list of pch values and their corresponding shapes  here .
<h3>Example 2: Scatter Plot by Group in ggplot2</h3>
The following code shows how to create a scatterplot in ggplot2 where the points are colored based on the value of the ‘group’ variable:
<b>library(ggplot2)
#create scatterplot with points colored by group
ggplot(df, aes(x, y)) +
  geom_point(aes(color=group))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/colorgroup2.jpg"477">
Note that you can also modify the colors and size of the points in the plot:
<b>library(ggplot2)
#create scatterplot with points colored by group
ggplot(df, aes(x, y)) +
  geom_point(aes(color=group), size=3) +
  scale_color_manual(values=c('purple', 'steelblue'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/colorgroup3.jpg">
Notice that we increased the point size using the <b>size</b> argument and the colors of the points match the colors that we specified in the <b>scale_color_manual()</b> argument.
<h2><span class="orange">Scatterplot Generator</span></h2>
A <b>scatterplot</b> is used to display the relationship between two variables.
To create a scatterplot for variables X and Y, simply enter the values for the variables in the boxes below, then press the “Generate Scatterplot” button.
Variable X || Variable Y
<textarea id="x" name="x" rows="15" cols="4"></textarea><textarea id="y" name="y" rows="15" cols="4"></textarea>
<label for="scatterColor" style="margin-top: 20px">Choose a color for the scatter chart:</label>
<input type="color" id="scatterColor" name="scatterColor" value="#e66465">
<input type="button" id="button" onclick="calc()" value="Generate Scatterplot">
<script>
//create function that performs calculations
function calc() {
d3.select("svg").remove();
//get data
var x = document.getElementById('x').value.match(/\d+/g).map(Number);
var y = document.getElementById('y').value.match(/\d+/g).map(Number);
var data = [];
for (var i=0; i < x.length; i++) {
    data.push({
        asd: x[i],
        aror: y[i]
    });
}
//get selected color
var color = document.getElementById('scatterColor').value;     
//create scatterplot
var body = d3.select('#chart')
var margin = { top: 50, right: 50, bottom: 50, left: 50 }
var h = 500 - margin.top - margin.bottom
var w = 500 - margin.left - margin.right
// Scales
  var xScale = d3.scale.linear()
    .domain([
    d3.min([0,d3.min(data,function (d) { return d.asd })]),
    d3.max([0,d3.max(data,function (d) { return d.asd })+5])
    ])
    .range([0,w])
  var yScale = d3.scale.linear()
    .domain([
    d3.min([0,d3.min(data,function (d) { return d.aror })]),
    d3.max([0,d3.max(data,function (d) { return d.aror })+5])
    ])
    .range([h,0])
// SVG
var svg = body.append('svg')
    .attr('height',h + margin.top + margin.bottom)
    .attr('width',w + margin.left + margin.right)
  .append('g')
    .attr('transform','translate(' + margin.left + ',' + margin.top + ')')
// X-axis
var xAxis = d3.svg.axis()
  .scale(xScale)
  .ticks(5)
  .orient('bottom')
  // Y-axis
var yAxis = d3.svg.axis()
  .scale(yScale)
  .ticks(5)
  .orient('left')
  // Circles
  var circles = svg.selectAll('circle')
      .data(data)
      .enter()
    .append('circle')
      .attr('cx',function (d) { return xScale(d.asd) })
      .attr('cy',function (d) { return yScale(d.aror) })
      .attr('r','6')
      .attr('stroke','black')
      .attr('stroke-width',1)
      .attr('fill', color);
  // X-axis
  svg.append('g')
      .attr('class','axis')
      .attr('transform', 'translate(0,' + h + ')')
      .call(xAxis)
    .append('text') // X-axis Label
      .attr('class','label')
      .attr('y',-10)
      .attr('x',w)
      .attr('dy','.71em')
      .style('text-anchor','end')
      .text('X')
  // Y-axis
  svg.append('g')
      .attr('class', 'axis')
      .call(yAxis)
    .append('text') // y-axis Label
      .attr('class','label')
      .attr('transform','rotate(-90)')
      .attr('x',0)
      .attr('y',5)
      .attr('dy','.71em')
      .style('text-anchor','end')
      .text('Y')
} //end calc
</script>
<h2><span class="orange">How to Create a Scatterplot Matrix in Excel (With Example)</span></h2>
A <b>scatterplot matrix </b>is a matrix of scatterplots that lets you understand the pairwise relationship between different variables in a dataset.
This tutorial explains how to create the following scatterplot matrix in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel6.jpg">
Let’s jump in!
<h3>Step 1: Enter the Data</h3>
First, let’s enter the following values for a dataset that contains three variables: points, assists, and rebounds.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel1.jpg"466">
<h3>Step 2: Create the Scatterplots</h3>
Next, let’s highlight the cell range <b>A2:B9</b>, then click the <b>Insert</b> tab, then click the <b>Scatter</b> button within the <b>Charts</b> group.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scatterExcel.png">
The following scatterplot of points vs. assists will automatically be created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel2.jpg"630">
Next, perform the following steps:
Click on the values on the x-axis and change the minimum axis bound to 80.
Click the y-axis and change the minimum axis bound to 20.
Click the Chart Title and delete it.
Click on the gridlines in the chart and delete them.
Lastly, resize the chart to make it smaller.
The end result should looking something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel3.jpg"595">
Next, repeat these exact same steps for the points and rebounds variables and place the scatterplot under the existing scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel4.jpg"594">
Lastly, repeat these steps for the assists and rebounds variables and place the scatterplot in the bottom right corner:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel5.jpg"557">
<h3>Step 3: Label the Scatterplots</h3>
Lastly, type the variable names next to the scatterplots so that it’s easy to understand which scatterplots represent which variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrixexcel6.jpg">
Here’s how to interpret the plots:
The scatterplot in the top left corner represents the relationship between points and assists.
The scatterplot in the bottom left corner represents the relationship between points and rebounds.
The scatterplot in the bottom right corner represents the relationship between assists and rebounds.
<b>Note</b>: Feel free to modify the color and size of the points in the scatterplots to make them appear however you’d’ like.
<h2><span class="orange">How to Create a Scatterplot Matrix in R (2 Examples)</span></h2>
A <b>scatterplot matrix </b>is a matrix of scatterplots that lets you understand the pairwise relationship between different variables in a dataset.
There are two common ways to create a scatterplot matrix in R:
<b>Method 1: Use Base R</b>
<b>#create scatterplot matrix (pch=20 means to use a solid circle for points)
plot(df, pch=20)
</b>
<b>Method 2: Use ggplot2 and GGally packages</b>
<b>library(ggplot2)
library(GGally)
#create scatterplot matrix
ggpairs(df)</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(99, 90, 86, 88, 95, 99, 101, 104), assists=c(33, 28, 31, 39, 40, 40, 35, 47), rebounds=c(30, 28, 24, 24, 20, 20, 15, 12))
#view first few rows of data frame
head(df)
  points assists rebounds
1     99      33       30
2     90      28       28
3     86      31       24
4     88      39       24
5     95      40       20
6     99      40       20
</b>
<h3>Example 1: Create Scatterplot Matrix Using Base R</h3>
We can use the <b>plot()</b> function in base R to create a scatterplot matrix for each variable in our data frame:
<b>#create scatterplot matrix
plot(df, pch=20, cex=1.5, col='steelblue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrix11.jpg">
The way to interpret the matrix is as follows:
The variable names are shown along the diagonals boxes.
All other boxes display a scatterplot of the relationship between each pairwise combination of variables. For example, the box in the top right corner of the matrix displays a scatterplot of values for <b>points </b>and <b>rebounds</b>. The box in the middle left displays a scatterplot of values for <b>points </b>and <b>assists</b>, and so on.
Note that <b>cex</b> controls the size of points in the plot and <b>col</b> controls the color of the points.
<h3>
<b>Example 2: Create Scatterplot Matrix Using ggplot2 and GGally</b>
</h3>
We can also use the <b>ggpairs()</b> function from the ggplot2 and GGally packages in R to create a scatterplot matrix for each variable in our data frame:
<b>library(ggplot2)
library(GGally)
#create scatterplot matrix
ggpairs(df)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/scattermatrix12.jpg">
This scatterplot matrix contains the same scatterplots as the <b>plot()</b> function from base R, but in addition we can also see the correlation coefficient between each pairwise combination of variables as well as a density plot for each individual variable.
For example, we can see:
The correlation coefficient between assists and points is <b>0.571</b>.
The correlation coefficient between rebounds and points is <b>-0.598</b>.
The correlation coefficient between rebounds and assists is <b>-0.740</b>.
The tiny star (<b>*</b>) next to -0.740 also indicates that the correlation between rebounds and assists is statistically significant.
<h2><span class="orange">How to Create a Scatterplot with a Regression Line in Python</span></h2>
Often when you perform simple linear regression, you may be interested in creating a  scatterplot  to visualize the various combinations of x and y values along with the estimation regression line.
Fortunately there are two easy ways to create this type of plot in Python. This tutorial explains both methods using the following data:
<b>import numpy as np 
#create data
x = np.array([1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9])
y = np.array([13, 14, 17, 12, 23, 24, 25, 25, 24, 28, 32, 33])
</b>
<h3>Method 1: Using Matplotlib</h3>
The following code shows how to create a scatterplot with an estimated regression line for this data using Matplotlib:
<b>import matplotlib.pyplot as plt
#create basic scatterplot
plt.plot(x, y, 'o')
#obtain m (slope) and b(intercept) of linear regression line
m, b = np.polyfit(x, y, 1)
#add linear regression line to scatterplot 
plt.plot(x, m*x+b)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/scatterRegressionPython1.png">
Feel free to modify the colors of the graph as you’d like. For example, here’s how to change the individual points to green and the line to red:
<b>#use green as color for individual points
plt.plot(x, y, 'o', color='green')
#obtain m (slope) and b(intercept) of linear regression line
m, b = np.polyfit(x, y, 1)
#use red as color for regression line
plt.plot(x, m*x+b, color='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/scatterRegressionPython2.png">
<h3>Method 2: Using Seaborn</h3>
You can also use the <b>regplot() </b>function from the Seaborn visualization library to create a scatterplot with a regression line:
<b>import seaborn as sns
#create scatterplot with regression line
sns.regplot(x, y, ci=None)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/scatterRegressionPython3.png">
Note that <b>ci=None </b>tells Seaborn to hide the confidence interval bands on the plot. You can choose to show them if you’d like, though:
<b>import seaborn as sns
#create scatterplot with regression line and confidence interval lines
sns.regplot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/scatterRegressionPython4.png">
You can find the complete documentation for the <b>regplot()</b> function  here .
<h2><span class="orange">How to Create a Scatterplot with a Regression Line in R</span></h2>
Often when we perform simple linear regression, we’re interested in creating a  scatterplot  to visualize the various combinations of x and y values.
Fortunately, R makes it easy to create scatterplots using the <b>plot() </b>function. For example:
<b>#create some fake data
data &lt;- data.frame(x = c(1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11),   y = c(13, 14, 17, 12, 23, 24, 25, 25, 24, 28, 32, 33, 35, 40, 41))
#create scatterplot of data
plot(data$x, data$y)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/scatterRegression1.png">
It’s also easy to add a regression line to the scatterplot using the <b>abline() </b>function. For example:
<b>#fit a simple linear regression model
model &lt;- lm(y ~ x, data = data)
#add the fitted regression line to the scatterplot
abline(model)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/scatterRegression2.png">
We can also add confidence interval lines to the plot by using the <b>predict() </b>function. For example:
<b>#define range of x values
newx = seq(min(data$x),max(data$x),by = 1)
#find 95% confidence interval for the range of x values 
conf_interval &lt;- predict(model, newdata=data.frame(x=newx), interval="confidence",         level = 0.95)
#create scatterplot of values with regression line 
plot(data$x, data$y)
abline(model)
#add dashed lines (lty=2) for the 95% confidence interval
lines(newx, conf_interval[,2], col="blue", lty=2)
lines(newx, conf_interval[,3], col="blue", lty=2)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/scatterRegression3.png">
Or we could instead add prediction interval lines to the plot by specifying the interval type within the <b>predict()</b> function. For example:
<b>#define range of x values
newx = seq(min(data$x),max(data$x),by = 1)
#find 95% prediction interval for the range of x values 
pred_interval &lt;- predict(model, newdata=data.frame(x=newx), interval="prediction",         level = 0.95)
#create scatterplot of values with regression line 
plot(data$x, data$y)
abline(model)
#add dashed lines (lty=2) for the 95% confidence interval
lines(newx, pred_interval[,2], col="red", lty=2)
lines(newx, pred_interval[,3], col="red", lty=2)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/scatterRegression4.png">
Lastly, we can make the plot more aesthetically pleasing by adding a title, changing the axes names, and changing the shape of the individual points in the plot.
<b>plot(data$x, data$y,
     main = "Scatterplot of x vs. y", #add title
     pch=16, #specify points to be filled in
     xlab='x', #change x-axis name
     ylab='y') #change y-axis name
abline(model, col='steelblue') #specify color of regression line
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/scatterRegression5.png">
<h2><span class="orange">How to Create a Scatterplot with Regression Line in SAS</span></h2>
You can use <b>proc sgplot</b> to quickly create a scatterplot with a regression line in SAS.
The following examples show how to use this procedure in practice.
<h3>Example 1: Create Basic Scatterplot with Regression Line</h3>
The following code shows how to create a basic scatterplot with a regression line using the built-in SAS  class dataset :
<b>/*create scatterplot with regression line*/
proc sgplot data=sashelp.class;
   reg y=height x=weight;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/scatterSAS1.jpg">
The points in the plot display the individual  observations  from the dataset and the blue line displays the fitted regression line.
<h3>Example 2: Create Custom Scatterplot with Regression Line</h3>
Note that <b>proc sgplot</b> can create highly customizable scatterplots.
For example, you can:
Add a title to the chart
Modify the axis labels
Remove the legend
Customize the color and thickness of the regression line
Customize the appearance of the points in the plot
The following code shows how to customize each of these aspects of the plot:
<b>/*create custom scatterplot with regression line*/
proc sgplot data=sashelp.class noautolegend;
   title 'Regression Model';
   xaxis label='Weight (pounds)';
   yaxis label='Height (inches)';
   reg y=height x=weight /
   lineattrs=(color=red thickness=2)
   markerattrs=(color=green size=12px symbol=circlefilled);
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/scatterSAS2.jpg"589">
Notice that the title, axis labels, individual points, and the regression line have all been modified.
<h2><span class="orange">How to Create and Interpret Scatterplots in SPSS</span></h2>
A  <b>scatterplot</b>  is a type of plot that we can use to display the relationship between two variables. It helps us visualize both the direction (positive or negative) and the strength (weak, moderate, strong) of the relationship between the two variables.
This tutorial explains how to create and interpret scatterplots in SPSS.
<h2>How to Create Scatterplots in SPSS</h2>
Suppose we have the following dataset that displays the hours studied and exam score received for 15 students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS1.png">
We can create a scatterplot to visualize the relationship between hours studied and exam score received.
<h3>Basic Scatterplot</h3>
We can create a basic scatterplot in SPSS by clicking on the <b>Graphs</b> tab, then <b>Chart Builder</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS2.png">
In the window that pops up, click <b>Scatter/Dot </b>in the <b>Choose from: </b>list. Then drag the first option that says <b>Simple Scatter</b> into the editing window. Drag the variable <b>hours </b>into the x-axis and <b>score </b>into the y-axis:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS3.png">
Once you click <b>OK</b>, the following scatterplot will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS4.png">
By default, SPSS chooses a minimum point for the y-axis based on the smallest value in your dataset. In this example the minimum point on the y-axis is 65. To change this to 0, click <b>Y-Axis1 (Point1) </b>in the <b>Element Properties </b>box and set the <b>Minimum </b>value to 0:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS5.png">
Once you click <b>OK</b>, a new scatterplot will appear with the y-axis minimum value set to 0:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS6.png">
<h3>Scatterplot with Regression Line</h3>
We can also produce a scatterplot with a line of best fit by selecting the option called <b>Simple Scatter with Fit Line </b>in the Chart Builder window:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS7.png">
Once we click <b>OK</b>, a scatterplot with a line of best fit will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS8.png">
The R<sup>2</sup> value also appears in the top right hand corner of the plot. This represents the percentage of variation in the response variable that can be explained by the predictor variable. In this case, it means 66.2% of the variation in exam scores can be explained by the number of hours spent studying.
<h3>Grouped Scatterplot</h3>
Suppose we also have a categorical variable in our dataset, such as gender:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatterSPSS9.png">
In this case, we could create a scatterplot of hours studied vs. exam score, grouped by gender.
To do so, we can once again open the Chart Builder and choose <b>Grouped Scatter </b>as the chart type. Once again we’ll place the variable <b>hours </b>on the x-axis and <b>score </b>on the y-axis, but this time we’ll add <b>gender </b>as the variable under <b>Set color</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatters10.png">
Once we click <b>OK</b>, the following grouped scatterplot appears:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/scatters11.png">
The red circles represent males and the blue circles represent females.
<h2><span class="orange">How to Create and Modify Scatterplots in Stata</span></h2>
A  <b>scatterplot</b>  is a type of plot that we can use to display the relationship between two variables. It helps us visualize both the direction (positive or negative) and the strength (weak, moderate, strong) of the relationship between the two variables.
This tutorial explains how to create and modify scatterplots in Stata.
<h2>How to Create Scatterplots in Stata</h2>
We’ll use a dataset called <em>auto </em>to illustrate how to create and modify scatterplots in Stata.
First, load the data by typing the following into the Command box:
<b>use http://www.stata-press.com/data/r13/auto</b>
We can get a quick look at the dataset by typing the following into the Command box:
<b>summarize</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata1.png">
We can see that there are 12 total variables in the dataset.
<h3>Basic Scatterplot</h3>
We can create a scatterplot for the variables <em>weight </em>and <em>length </em>by using the <b>scatter </b>command. The first variable you type will go along the y-axis and the second variable will go along the x-axis:
<b>scatter weight length</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata2.png">
We can see that there is a strong positive correlation between weight and length. That is, cars that weigh more also tend to be longer.
<h3>Scatterplot with a Regression Line</h3>
You can add a simple linear regression line to the scatterplot by using two “pipe” symbols || along with the <b>lfit </b>command:
<b>scatter weight length || lfit weight length</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata3.png">
<h3>Scatterplot with Multiple Variables</h3>
You can create a scatterplot with more than two variables by simply typing more variables after the <b>scatter </b>command. Note that the last variable you type will be used for the x-axis. 
For example, the following command tells Stata to create a scatterplot using <em>length </em>as the x-axis variable and <em>weight </em>and <em>displacement </em>as the y-axis variables:
<b>scatter weight displacement length</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata4.png">
<h2>How to Modify Scatterplots in Stata</h2>
We can use several different commands to modify the appearance of the scatterplots.
<h3>Adding a Title</h3>
We can add a title to the plot using the <b>title() </b>command:
<b>scatter weight length, title(“Weight vs. Length”)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata5.png">
<h3>Adding a Subtitle</h3>
We can also add a subtitle underneath the title using the <b>subtitle() </b>command:
<b>scatter weight length, title(“Weight vs. Length”) subtitle(“n = 74 cars”)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata6.png">
<h3>Adding a Comment</h3>
We can also add a note or comment at the bottom of the graph by using the <b>note() </b>command:
<b>scatter weight length, note(“Source: 1978 Automobile Data”)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata7.png">
<h3>Changing Colors</h3>
We can change the color of the points in the scatterplot by using the <b>mcolor() </b>command:
<b>scatter weight length, mcolor(green)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata8.png">
A full list of available colors can be found in the  Stata Documentation for colors .
<h3>Changing Shapes</h3>
We can also change the shape of the points in the scatterplot by using the <b>msymbol() </b>command. For example the symbol “D” corresponds to diamonds:
<b>scatter weight length, msymbol(D)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/scatterStata9.png">
A full list of available shapes can be found in the  Stata Documentation for shapes .
<h2><span class="orange">Scatterplots</span></h2>
<b>Scatterplots</b> are used to display the relationship between two variables.
Suppose we have the following dataset that shows the weight and height of players on a basketball team:
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/weight_height.jpg"220"> 
The two variables in this dataset are height and weight. To make a scatterplot, we place the height along the x-axis and the weight along the y-axis. Each player is then represented as a dot on the scatterplot:
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/scatterplot.jpg"422"> 
Scatterplots help us see relationships between two variables. In this case, we see that height and weight have a positive relationship. As height increases, weight tends to increase as well.
<h2>Interpreting Scatterplots</h2>
Scatterplots help us see the <b>relationship</b> (positive, negative, none) between two variables as well as the <b>strength</b> of that relationship (weak, strong).
<b>Strong, positive relationship:</b> As the variable on the x-axis increases, the variable on the y-axis increases as well. The dots are packed together tightly, which indicates a strong relationship. <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/pos_strong.jpg"323"> 
<b>
Weak, positive relationship:</b> As the variable on the x-axis increases, the variable on the y-axis increases as well. The dots are fairly spread out, which indicates a weak relationship.
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/pos_weak.jpg"323"> 
<b>No relationship: </b>There is no clear relationship (positive or negative) between the variables. 
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/none.jpg"324"> 
<b>Strong, negative relationship: </b>As the variable on the x-axis increases, the variable on the y-axis decreases. The dots are packed tightly together, which indicates a strong relationship.
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/neg_strong.jpg"321"> 
<b>Weak, negative relationship:</b> As the variable on the x-axis increases, the variable on the y-axis decreases. The dots are fairly spread out, which indicates a weak relationship.
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/neg_weak.jpg"324"> 
<h2>Scatterplot Generator</h2>
Use the free  Statology scatterplot generator  to generate a scatterplot for a dataset simply by entering data values.
<h2><span class="orange">How to Perform Scheffe’s Test in Excel</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
If the overall  p-value  from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal.
In order to find out exactly which groups are different from each other, we must conduct a  post-hoc test  that is capable of controlling the  family-wise error rate .
One of the most commonly used post hoc tests is Scheffe’s test.
The following step-by-step example shows how to perform Scheffe’s test in Excel.
<h3>Step 1: Enter the Data</h3>
Suppose a teacher wants to know whether or not three different studying techniques lead to different exam scores among students. To test this, she randomly assigns 10 students to use each studying technique and records their exam scores.
First, we’ll enter the grades for each student based on their studying technique used:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scheffeExcel5.png">
<h3>Step 2: Perform a One-Way ANOVA</h3>
To perform a one-way ANOVA, click the <b>Data</b> tab along the top ribbon, then click on the <b>Data Analysis</b> option within the <b>Analysis</b> group.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see this option, you need to first  load the Analysis ToolPak .
In the new window that appears, click <b>Anova: Single Factor</b> and then click <b>OK</b>.
In the new window that appears, fill in the following information:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scheffeExcel6.png">
Once you click <b>OK</b>, the results of the one-way ANOVA will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scheffeExcel7.png">
Since the overall p-value (<b>0.016554</b>) in the ANOVA table is less than .05, this means that each group does not have the same average exam score.
Next, we will perform Scheffe’s test to determine which groups are different.
<h3>Step 3: Perform Scheffe’s Test</h3>
First, we need to calculate Scheffe’s critical value. This is calculated as:
Scheffe’s Critical Value = F Critical Value * 2
In our example, Scheffe’s critical value is 3.354131 * 2 =  <b>6.708</b>.
Next, we can calculate the F-statistic for each pairwise comparison, which is calculated as:
F-statistic: (x<sub>1</sub>–x<sub>2</sub>)<sup>2</sup> / (MS<sub>within</sub>(1/n<sub>1</sub> + 1/n<sub>2</sub>))
For example, we can use the following formulas to calculate the F-statistic for the pairwise difference between each technique:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scheffeExcel9.png">
The only F-statistic that exceeds Scheffe’s Critical Value is the one for the comparison between technique 1 and technique 3.
Thus, the only two groups that are statistically significantly different are technique 1 and technique 3.
<h2><span class="orange">How to Perform Scheffe’s Test in R</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
If the overall  p-value  from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal.
In order to find out exactly which groups are different from each other, we must conduct a  post-hoc test  that is capable of controlling the  family-wise error rate .
One of the most commonly used post hoc tests is Scheffe’s test.
This tutorial explains how to perform Scheffe’s test in R.
<h3>Example: Scheffe’s Test in R</h3>
Suppose a teacher wants to know whether or not three different studying techniques lead to different exam scores among students. To test this, she randomly assigns 10 students to use each studying technique and records their exam scores.
We can use the following steps in R to fit a one-way ANOVA to test for differences in mean exam scores among the three groups and use Scheffe’s test to determine exactly which groups are different.
<b>Step 1: Create the dataset.</b>
The following code shows how to create a dataset that contains exam scores for all 30 students:
<b>#create data frame
data &lt;- data.frame(technique = rep(c("tech1", "tech2", "tech3"), each = 10),   score = c(76, 77, 77, 81, 82, 82, 83, 84, 85, 89,             81, 82, 83, 83, 83, 84, 87, 90, 92, 93,             77, 78, 79, 88, 89, 90, 91, 95, 95, 98))
#view first six rows of data frame
head(data)
  technique score
1     tech1    76
2     tech1    77
3     tech1    77
4     tech1    81
5     tech1    82
6     tech1    82
</b>
<b>Step 2: Visualize the exam scores for each group.</b>
The following code shows how to produce boxplots to visualize the distribution of exam scores for each group:
<b>boxplot(score ~ technique,
        data = data,
        main = "Exam Scores by Studying Technique",
        xlab = "Studying Technique",
        ylab = "Exam Scores",
        col = "steelblue",
        border = "black")
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/bonf1.png">
<b>Step 3: Perform a one-way ANOVA.</b>
The following code shows how to perform a one-way ANOVA to test for differences among mean exam scores in each group:
<b>#fit the one-way ANOVA model
model &lt;- aov(score ~ technique, data = data)
#view model output
summary(model)
            Df Sum Sq Mean Sq F value Pr(>F)  
technique    2  211.5  105.73   3.415 0.0476 *
Residuals   27  836.0   30.96                 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</b>
Since the overall p-value (<b>0.0476</b>) is less than .05, this is an indication that each group does not have the same average exam score.
Next, we will perform Scheffe’s test to determine which groups are different.
<b>Step 4: Perform Scheffe’s Test.</b>
To perform Scheffe’s test, we’ll use the <b>ScheffeTest()</b> function from the  DescTools  package.
The following code shows how to use this function for our example:
<b>#load DescTools package
library(DescTools)
#perform Scheffe's test
ScheffeTest(model)
  Posthoc multiple comparisons of means : Scheffe Test 
    95% family-wise confidence level
$technique
            diff      lwr.ci    upr.ci   pval    
tech2-tech1  4.2 -2.24527202 10.645272 0.2582    
tech3-tech1  6.4 -0.04527202 12.845272 0.0519 .  
tech3-tech2  2.2 -4.24527202  8.645272 0.6803    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</b>
The way to interpret the output is as follows:
The mean difference in exam scores between technique 2 and technique 1 is <b>4.2</b>. The corresponding p-value for the mean difference is <b>.2582</b>.
The mean difference in exam scores between technique 3 and technique 1 is <b>6.4</b>. The corresponding p-value for the mean difference is <b>.0519</b>.
The mean difference in exam scores between technique 3 and technique 2 is <b>2.2</b>. The corresponding p-value for the mean difference is <b>.6803</b>.
Depending on the significance level we decide to use, the only two groups that seem to be statistically significantly different are technique 3 and technique 1.
<h2><span class="orange">How to Create a Scree Plot in Python (Step-by-Step)</span></h2>
Principal components analysis (PCA) is an  unsupervised machine learning technique  that finds principal components (linear combinations of the predictor variables) that explain a large portion of the variation in a dataset.
When we perform PCA, we’re interested in understanding what percentage of the total variation in the dataset can be explained by each principal component.
One of the easiest ways to visualize the percentage of variation explained by each principal component is to create a <b>scree plot</b>.
This tutorial provides a step-by-step example of how to create a scree plot in Python.
<h3>Step 1: Load the Dataset</h3>
For this example we’ll use a dataset called USArrests, which contains data on the number of arrests per 100,000 residents in each U.S. state in 1973 for various crimes.
The following code shows how to import this dataset and prep it for principal components analysis:
<b>import pandas as pd
from sklearn.preprocessing import StandardScaler
#define URL where dataset is located
url = "https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/USArrests.csv"
#read in data
data = pd.read_csv(url)
#define columns to use for PCA
df = data.iloc[:, 1:5]
#define scaler
scaler = StandardScaler()
#create copy of DataFrame
scaled_df=df.copy()
#created scaled version of DataFrame
scaled_df=pd.DataFrame(scaler.fit_transform(scaled_df), columns=scaled_df.columns)</b>
<h3>Step 2: Perform PCA</h3>
Next, we’ll use the <b>PCA()</b> function from the <b>sklearn</b> package perform principal components analysis.
<b>from sklearn.decomposition import PCA
#define PCA model to use
pca = PCA(n_components=4)
#fit PCA model to data
pca_fit = pca.fit(scaled_df)
</b>
<h3>Step 3: Create the Scree Plot</h3>
Lastly, we’ll calculate the percentage of total variance explained by each principal component and use <b>matplotlib </b>to create a scree plot:
<b>import matplotlib.pyplot as plt
import numpy as np
PC_values = np.arange(pca.n_components_) + 1
plt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')
plt.title('Scree Plot')
plt.xlabel('Principal Component')
plt.ylabel('Variance Explained')
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/scree_plot_python.png">
The x-axis displays the principal component and the y-axis displays the percentage of total variance explained by each individual principal component.
We can also use the following code to display the exact percentage of total variance explained by each principal component:
<b>print(pca.explained_variance_ratio_)
[0.62006039 0.24744129 0.0891408  0.04335752]
</b>
We can see:
The first principal component explains <b>62.01%</b> of the total variation in the dataset.
The second principal component explains <b>24.74%</b> of the total variation.
The third principal component explains <b>8.91%</b> of the total variation.
The fourth principal component explains <b>4.34%</b> of the total variation.
Note that the percentages sum to 100%.
You can find more machine learning tutorials on  <em>this page</em> .
<h2><span class="orange">How to Create a Scree Plot in R (Step-by-Step)</span></h2>
Principal components analysis (PCA) is an  unsupervised machine learning technique  that seeks to find principal components – linear combinations of the predictor variables – that explain a large portion of the variation in a dataset.
When we perform PCA, we’re often interested in understanding what percentage of the total variation in the dataset can be explained by each principal component.
One of the easiest ways to visualize the percentage of variation explained by each principal component is to create a <b>scree plot</b>.
This tutorial provides a step-by-step example of how to create a scree plot in R.
<h3>Step 1: Load the Dataset</h3>
For this example we’ll use a dataset called USArrests, which contains data on the number of arrests per 100,000 residents in each U.S. state in 1973 for various crimes.
The following code shows how to load and view the first few rows of this dataset:
<b>#load data
data("USArrests")
#view first six rows of data
head(USArrests)
           Murder Assault UrbanPop Rape
Alabama      13.2     236       58 21.2
Alaska       10.0     263       48 44.5
Arizona       8.1     294       80 31.0
Arkansas      8.8     190       50 19.5
California    9.0     276       91 40.6
Colorado      7.9     204       78 38.7</b>
<h3>Step 2: Perform PCA</h3>
Next, we’ll use the <b>prcomp()</b> function built into R to perform principal components analysis.
<b>#perform PCA
results &lt;- prcomp(USArrests, scale = TRUE)
</b>
<h3>Step 3: Create the Scree Plot</h3>
Lastly, we’ll calculate the percentage of total variance explained by each principal component and use <b>ggplot2</b> to create a scree plot:
<b>#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)
#create scree plot
library(ggplot2)
qplot(c(1:4), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") +
  ylim(0, 1)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/screeR1.png">
The x-axis displays the principal component and the y-axis displays the percentage of total variance explained by each individual principal component.
We can also use the following code to display the exact percentage of total variance explained by each principal component:
<b>print(var_explained)
[1] 0.62006039 0.24744129 0.08914080 0.04335752
</b>
We can see:
The first principal component explains <b>62.01%</b> of the total variation in the dataset.
The second principal component explains <b>24.74%</b> of the total variation in the dataset.
The third principal component explains <b>8.91%</b> of the total variation in the dataset.
The fourth principal component explains <b>4.34%</b> of the total variation in the dataset.
Notice that all of the percentages sum to 100%.
You can find more machine learning tutorials on  this page .
<h2><span class="orange">How to Create an Area Chart in Seaborn (With Examples)</span></h2>
You can use the following basic syntax to create an area chart in  seaborn :
<b>import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn style
sns.set_theme()
#create seaborn area chart
plt.stackplot(df.x, df.y1, df.y2, df.y3)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Create Basic Area Chart in Seaborn</h3>
The following code shows how to create a basic area chart in seaborn:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn style
sns.set_theme()
 
#define DataFrame
df = pd.DataFrame({'period': [1, 2, 3, 4, 5, 6, 7, 8],   'team_A': [20, 12, 15, 14, 19, 23, 25, 29],   'team_B': [5, 7, 7, 9, 12, 9, 9, 4],   'team_C': [11, 8, 10, 6, 6, 5, 9, 12]})
#create area chart
plt.stackplot(df.period, df.team_A, df.team_B, df.team_C)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/area1.png">
The x-axis displays the period variable and the y-axis displays the values for each of the three teams over time.
<h3>Example 2: Create Custom Area Chart in Seaborn</h3>
The following code shows how to modify the colors of the area chart and add a legend with specific labels:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn style
sns.set_theme()
 
#define DataFrame
df = pd.DataFrame({'period': [1, 2, 3, 4, 5, 6, 7, 8],   'team_A': [20, 12, 15, 14, 19, 23, 25, 29],   'team_B': [5, 7, 7, 9, 12, 9, 9, 4],   'team_C': [11, 8, 10, 6, 6, 5, 9, 12]})
#define colors to use in chart
color_map = ['red', 'steelblue', 'pink']
    
#create area chart
plt.stackplot(df.period, df.team_A, df.team_B, df.team_C,
              labels=['Team A', 'Team B', 'Team C'],
              colors=color_map)
#add legend
plt.legend(loc='upper left')
#add axis labels
plt.xlabel('Period')
plt.ylabel('Points Scored')
#display area chart
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/area2.png">
Note that the <b>colors</b> argument accepts color names along with hex color codes.
<h2><span class="orange">How to Change Axis Labels on a Seaborn Plot (With Examples)</span></h2>
There are two ways to change the axis labels on a seaborn plot.
The first way is to use the <b>ax.set()</b> function, which uses the following syntax:
<b>ax.set(xlabel='x-axis label', ylabel='y-axis label')
</b>
The second way is to use matplotlib functions, which use the following syntax:
<b>plt.xlabel('x-axis label')
plt.ylabel('y-axis label')
</b>
The following examples show how to use each of these methods in practice.
<h3>Method 1: Change Axis Labels Using ax.set()</h3>
The following code shows how to create a seaborn barplot and use <b>ax.set()</b> to specify the axis labels:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create some fake data
df = pd.DataFrame({'quarter': ['Q1', 'Q2', 'Q3', 'Q4'],   'sales': [23, 26, 24, 34]})
#create seaborn barplot
ax = sns.barplot(x='quarter', y='sales',  data = df,  color='steelblue')
#specfiy axis labels
ax.set(xlabel='Sales Quarter',
       ylabel='Total Sales',
       title='Sales by Quarter')
#display barplot
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornAxisLabels1.png">
<h3>Method 2: Change Axis Labels Using Matplotlib Functions</h3>
The following code shows how to create a seaborn barplot and use matplotlib functions to specify the axis labels:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create some fake data
df = pd.DataFrame({'quarter': ['Q1', 'Q2', 'Q3', 'Q4'],   'sales': [23, 26, 24, 34]})
#create seaborn barplot
ax = sns.barplot(x='quarter', y='sales',  data = df,  color='steelblue')
#specify axis labels
plt.xlabel('Sales Quarter')
plt.ylabel('Total Sales')
plt.title('Sales by Quarter')
#display barplot
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornAxisLabels2.png">
Note that you can also specify the font size, font style, font family, and other font features using this method:
<b>#specify axis labels
plt.xlabel('Sales Quarter', size=16, fontstyle='italic', weight=900)
plt.ylabel('Total Sales', size=16, family='monospace')
plt.title('Sales by Quarter')
#display barplot
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornAxisLabels3.png">
Refer to the  matplotlib documentation  for a full list of ways you can customize the font on the axis labels.
<h2><span class="orange">How to Change Background Color in Seaborn</span></h2>
You can use the following basic syntax to change the background color of a Seaborn plot in Python:
<b>sns.set(rc={'axes.facecolor':'lightblue', 'figure.facecolor':'lightgreen'})
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Change Background Color in Seaborn</h3>
The following code shows how to create a scatterplot in Seaborn with a light blue background inside the plot and a light green background outside the plot:
<b>import seaborn as sns
import matplotlib.pyplot as plt
#define data
x = [1, 2, 2, 3, 5, 6, 6, 7, 9, 10, 12, 13]
y = [8, 8, 10, 12, 13, 15, 18, 15, 19, 22, 24, 29]
#define seaborn background colors
sns.set(rc={'axes.facecolor':'lightblue', 'figure.facecolor':'lightgreen'})
#create seaborn scatterplot
sns.scatterplot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/seabornbackground1.jpg">
The background color inside the plot is light blue and the background color outside of the plot is light green, just as we specified.
In most cases, it’s more common to use the same color inside and outside of the plot.
For example, we can use the following code to make the background color light blue both inside and outside of the plot:
<b>import seaborn as sns
import matplotlib.pyplot as plt
#define data
x = [1, 2, 2, 3, 5, 6, 6, 7, 9, 10, 12, 13]
y = [8, 8, 10, 12, 13, 15, 18, 15, 19, 22, 24, 29]
#define seaborn background colors
sns.set(rc={'axes.facecolor':'lightblue', 'figure.facecolor':'lightblue'})
#create seaborn scatterplot
sns.scatterplot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/seabornbackground2.jpg"526">
Note that we can also use hex color codes to set specific colors.
For example, we can use the following code to specify <b>#33FFA2</b> as the background color inside the plot:
<b>import seaborn as sns
import matplotlib.pyplot as plt
#define data
x = [1, 2, 2, 3, 5, 6, 6, 7, 9, 10, 12, 13]
y = [8, 8, 10, 12, 13, 15, 18, 15, 19, 22, 24, 29]
#define seaborn background colors
sns.set(rc={'axes.facecolor':'#33FFA2', 'figure.facecolor':'lightgrey'})
#create seaborn scatterplot
sns.scatterplot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/seabornbackground3.jpg"528">
<h2><span class="orange">How to Set the Color of Bars in a Seaborn Barplot</span></h2>
You can use the following methods to set the color of bars in a  seaborn  barplot:
<b>Method 1: Set Color for All Bars</b>
<b>#use steelblue for the color of all bars
sns.barplot(x=xvar, y=yvar, color='steelblue')</b>
<b>Method 2: Set Color for Bar with Max Value</b>
<b>#use orange for bar with max value and grey for all other bars
cols = ['grey' if (x &lt; max(df.yvar)) else 'orange' for x in df.yvar]
#create barplot using specified colors
sns.barplot(x=df.xvar, y=df.yvar, palette=cols)</b>
<b>Method 3: Set Color for Bars Based on Condition</b>
<b>#use red for bars with value less than 10 and green for all other bars
cols = ['red' if x &lt; 10 else 'green' for x in df.yvar]
#create barplot using specified colors
sns.barplot(x=df.xvar, y=df.yvar, palette=cols)</b>
The following examples show how to use each method in practice with the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'employee': ['Andy', 'Bert', 'Chad', 'Doug', 'Eric', 'Frank'],   'sales': [22, 14, 9, 7, 29, 20]})
#view DataFrame
print(df)
  employee  sales
0     Andy     22
1     Bert     14
2     Chad      9
3     Doug      7
4     Eric     29
5    Frank     20
</b>
<h2>Example 1: Set Color for All Bars</h2>
The following code shows how to create a barplot in seaborn and use the color ‘steelblue’ for all bars in the plot:
<b>import seaborn as sns
#create barplot using steelblue as color for each bar
sns.barplot(x=df.employee, y=df.sales, color='steelblue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/scolor1.jpg"528">
<h2>Example 2: Set Color for Bar with Max Value</h2>
The following code shows how to use orange for the bar with the max value in the barplot and grey for all other bars:
<b>import seaborn as sns
#use orange for bar with max value and grey for all other bars
cols = ['grey' if (x &lt; max(df.sales)) else 'orange' for x in df.sales]
#create barplot with custom colors
sns.barplot(x=df.employee, y=df.sales, palette=cols)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/scolor2.jpg">
<h2>Example 3: Set Color for Bar with Max Value</h2>
The following code shows how to use orange for the bar with the max value in the barplot and grey for all other bars:
<b>import seaborn as sns
#use red for bars with value less than 10 and green for all other bars
cols = ['red' if x &lt; 10 else 'green' for x in df.sales]
#create barplot with custom colors
sns.barplot(x=df.employee, y=df.sales, palette=cols)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/scolor3.jpg">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in seaborn:
 How to Create a Grouped Barplot in Seaborn 
 How to Create a Pie Chart in Seaborn 
 How to Create Multiple Seaborn Plots in One Figure 
<h2><span class="orange">How to Change the Order of Bars in Seaborn Barplot</span></h2>
You can use the following methods to change the order of bars in a  seaborn  plot:
<b>Method 1: Sort Bars in Barplot Created from Raw Data</b>
<b>sns.barplot(x='xvar', y='yvar', data=df, order=df.sort_values('yvar').xvar)</b>
<b>Method 2: Sort Bars in Barplot Created from Aggregated Data</b>
<b>sns.barplot(x='xvar', y='yvar', data=df, order=df_agg['xvar']
</b>
The following examples show how to use each method in practice.
<h2>Example 1: Sort Bars in Barplot Created from Raw Data</h2>
Suppose we have the following pandas DataFrame that contains information about the total sales made by various employees at a company:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'employee': ['Andy', 'Bert', 'Chad', 'Doug', 'Eric', 'Frank'],   'sales': [22, 14, 9, 7, 29, 20]})
#view DataFrame
print(df)
  employee  sales
0     Andy     22
1     Bert     14
2     Chad      9
3     Doug      7
4     Eric     29
5    Frank     20
</b>
We can use the following syntax to create a barplot where the bars are sorted in ascending order based on the <b>sales</b> value:
<b>import seaborn as sns
#create barplot with bars sorted by sales values ascending
sns.barplot(x='employee', y='sales', data=df, order=df.sort_values('sales').employee)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sorted1.jpg"494">
To instead sort the bars in descending order, simply use <b>ascending=False</b> within the <b>sort_values()</b> function:
<b>import seaborn as sns
#create barplot with bars sorted by sales values descending
sns.barplot(x='employee', y='sales', data=df,
            order=df.sort_values('sales', ascending=False).employee)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/sorted2.jpg"507">
<h2>Example 2: Sort Bars in Barplot Created from Aggregated Data</h2>
Suppose we have the following pandas DataFrame that contains information about the total sales made by various employees at a company:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'employee': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],   'sales': [24, 20, 25, 14, 19, 13, 30, 35, 28]})
#view DataFrame
print(df)
  employee  sales
0        A     24
1        A     20
2        A     25
3        B     14
4        B     19
5        B     13
6        C     30
7        C     35
8        C     28</b>
We can use the following syntax to calculate the mean <b>sales</b> value, grouped by <b>employee</b>:
<b>#calculate mean sales by employee
df_agg = df.groupby(['employee'])['sales'].mean().reset_index().sort_values('sales')
#view aggregated data
print(df_agg)
  employee      sales
1        B  15.333333
0        A  23.000000
2        C  31.000000</b>
We can then use the following syntax to create a barplot in seaborn that displays the mean sales by employee with the bars displayed in ascending order:
<b>import seaborn as sns
#create barplot with bars ordered in ascending order by mean sales
sns.barplot(x='employee', y='sales', data=df,
            order=df_agg['employee'], errorbar=('ci', False))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/barplot3.jpg"473">
The x-axis displays the employee name and the y-axis displays the mean sales value for each employee.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in seaborn:
 How to Show Values on Seaborn Barplot 
 How to Create a Grouped Barplot in Seaborn 
 How to Set the Color of Bars in a Seaborn Barplot 
<h2><span class="orange">How to Show Values on Seaborn Barplot (With Examples)</span></h2>
You can use the following function to display the values on a  seaborn  barplot:
<b>def show_values(axs, orient="v", space=.01):
    def _single(ax):
        if orient == "v":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() / 2
                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)
                value = '{:.1f}'.format(p.get_height())
                ax.text(_x, _y, value, ha="center") 
        elif orient == "h":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() + float(space)
                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)
                value = '{:.1f}'.format(p.get_width())
                ax.text(_x, _y, value, ha="left")
    if isinstance(axs, np.ndarray):
        for idx, ax in np.ndenumerate(axs):
            _single(ax)
    else:
        _single(axs)
</b>
This function works for both horizontal and vertical barplots.
The following examples show how to use this function in practice with the built-in seaborn “tips” dataset:
<b>import seaborn as sns
import pandas as pd
import numpy as np
#load tips dataset
data = sns.load_dataset("tips")
#view first five rows
data.head()
total_billtipsexsmokerdaytimesize
016.99        1.01FemaleNoSunDinner2
110.34        1.66MaleNoSunDinner3
221.01        3.50MaleNoSunDinner3
323.68        3.31MaleNoSunDinner2
424.59        3.61FemaleNoSunDinner4
</b>
<h3>Example 1: Show Values on Vertical Barplot</h3>
The following code shows how to display the values on a vertical barplot:
<b>#create vertical barplot
p = sns.barplot(x="day", y="tip", data=data, ci=None)
#show values on barplot
show_values(p)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/barShow1.png">
<h3>Example 2: Show Values on Horizontal Barplot</h3>
The following code shows how to display the values on a horizontal barplot:
<b>#create horizontal barplot
p = sns.barplot(x="tip", y="day", data=data, ci=None)
#show values on barplot
show_values(p, "h", space=0)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/barShow2.png">
Note that the larger the value you use for space, the further away the labels will be from the bars.
For example, let’s change the space from <b>0</b> to <b>.05</b>:
<b>#create horizontal barplot
p = sns.barplot(x="tip", y="day", data=data, ci=None)
#show values on barplot
show_values(p, "h", space=0.05)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/barShow3.png">
<b>Note</b>: To change the number of decimal places shown, simply change the value in this line of the function:
<b>value = '{:.1f}'.format(p.get_height())
</b>
For example, change it from .<b>1f</b> to<b> .2f</b> to show two decimal places instead of one.
<h2><span class="orange">How to Change the Width of Bars in Seaborn Bar Plot</span></h2>
You can use the <b>width</b> argument to change the width of bars in a  seaborn  bar plot:
<b>sns.barplot(x='xvar', y='yvar', data=df, width=0.8)</b>
The default value for width is <b>0.8</b>.
The smaller the value for <b>width</b>, the thinner the bars will be.
The following example shows how to use this argument in practice.
<h2>Example: Change Width of Bars in Seaborn Bar Plot</h2>
Suppose we have the following pandas DataFrame that contains information about the total sales made by various employees at a company:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'employee': ['Andy', 'Bert', 'Chad', 'Doug', 'Eric', 'Frank'],   'sales': [22, 14, 9, 7, 29, 20]})
#view DataFrame
print(df)
  employee  sales
0     Andy     22
1     Bert     14
2     Chad      9
3     Doug      7
4     Eric     29
5    Frank     20
</b>
We can use the following syntax to create a bar plot in seaborn using the default value of <b>0.8</b> for <b>width</b>:
<b>import seaborn as sns
#create bar plot with default width
sns.barplot(x='employee', y='sales', data=df).set(title='Default Width')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/width1-1.jpg"527">
The following code shows how to decrease the width of each bar by setting the <b>width</b> argument equal to <b>0.4</b>:
<b>import seaborn as sns
#create bar plot with width = 0.4
sns.barplot(x='employee', y='sales', data=df, width=0.4).set(title='Width = 0.4')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/width2.jpg"536">
Notice that the bars are much thinner in this plot compared to the previous one.
If you’d like each of the bars to be touching, you can set the <b>width</b> equal to <b>1</b>:
<b>import seaborn as sns
#create bar plot with width = 1
sns.barplot(x='employee', y='sales', data=df, width=1).set(title='Width = 1')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/width3.jpg"509">
Note that if you set the <b>width</b> equal to any value greater than 1, the bars will be overlapping.
<b>Note</b>: You can find the complete documentation for the <b>barplot()</b> function in seaborn  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in seaborn:
 How to Show Values on Seaborn Barplot 
 How to Create a Grouped Barplot in Seaborn 
 How to Set the Color of Bars in a Seaborn Barplot 
<h2><span class="orange">How to Make Barplots with Seaborn (With Examples)</span></h2>
A <b>barplot</b> is a type of plot that displays the numerical values for different categorical variables.
This tutorial explains how to create heatmaps using the Python visualization library  Seaborn  with the built-in <b>tips</b> dataset:
<b>import seaborn as sns
#load <em>tips </em>dataset
data = sns.load_dataset("tips")
#view first five rows of <em>tips</em> dataset
data.head()
total_billtipsexsmokerdaytimesize
016.991.01FemaleNoSunDinner2
110.341.66MaleNoSunDinner3
221.013.50MaleNoSunDinner3
323.683.31MaleNoSunDinner2
424.593.61FemaleNoSunDinner4</b>
<h3>Make a Basic Barplot</h3>
The following syntax shows how to make a simple barplot that displays the time of day along the x-axis and the mean tip along the y-axis:
<b>sns.barplot(x="time", y="tip", data=data)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot1.png">
The barplot displays the standard error of the mean for each bar by default, but we can turn these off by using the argument <b>ci=None</b> as follows:
<b>sns.barplot(x="time", y="tip", data=data, ci=None)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot2.png">
<h3>Order the Bars in the Barplot</h3>
We can use the <b>order</b> argument to quickly put the bars in a certain order:
<b>sns.barplot(x="time", y="tip", data=data, order=["Dinner", "Lunch"])</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot3.png">
<h3>Make a Grouped Barplot</h3>
We can make a grouped barplot by using the <b>hue</b> argument. For example, we can use the following syntax to display the mean tip grouped by day and sex:
<b>sns.barplot(x="time", y="tip", hue="sex", data=data)</b>
<h3><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot4.png"></h3>
<h3>Make a Horizontal Barplot</h3>
To create a horizontal barplot, we simply need to pass a categorical variable to the <b>y</b> argument and a numerical variable to the <b>x</b> argument:
<b>sns.barplot(x="tip", y="time", data=data)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot5.png">
<h3>Modify the Colors of the Barplot</h3>
We can use the <b>palette</b> argument to pass a list of colors to use for the bars in the barplot:
<b>sns.barplot(x="tip", y="time", palette=["pink", "green"], data=data)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_barplot6.png">
<h2><span class="orange">Seaborn: How to Create a Boxplot of Multiple Columns</span></h2>
You can use the following basic syntax in seaborn to create a boxplot of multiple columns of a pandas DataFrame:
<b>sns.boxplot(x='variable', y='value', data=df)
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Boxplot of Multiple Columns Using Seaborn</h3>
Suppose we have the following pandas DataFrame that shows the points scored by players on three different basketball teams:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'A': [5, 7, 7, 9, 12, 12],   'B': [8, 8, 9, 13, 15, 17],   'C': [1, 2, 2, 4, 5, 7]})
#view DataFrame
df
        ABC
0581
1782
2792
39134
412155
512177
</b>
Suppose we’d like to create three boxplots that show the distribution of points scored by each team.
To create multiple boxplots in seaborn, we must first melt the pandas DataFrame into a  long format :
<b>#melt data frame into long format
df_melted = pd.melt(df)
#view first 10 rows of melted data frame
df_melted.head(10)
variable value
0A 5
1A 7
2A 7
3A 9
4A 12
5A 12
6B 8
7B 8
8B 9
9B 13</b>
Now we can create multiple boxplots using seaborn:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create seaborn boxplots by group
sns.boxplot(x='variable', y='value', data=df_melted)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/mult11.jpg">
The x-axis displays the teams and the y-axis displays the distribution of points scored.
Note that we can use the following syntax to also  add a title  and modify the  axis labels :
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create seaborn boxplots by group
sns.boxplot(x='variable', y='value', data=df_melted).set(title='Points by Team')
#modify axis labels
plt.xlabel('Team')
plt.ylabel('Points')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/mult12.jpg"532">
<h2><span class="orange">How to Adjust the Figure Size of a Seaborn Plot</span></h2>
There are two ways to change the figure size of a seaborn plot in Python.
The first method can be used to change the size of “axes-level” plots such as <b>sns.scatterplot()</b> or <b>sns.boxplot()</b> plots:
<b>sns.set(rc={"figure.figsize":(3, 4)}) #width=3, #height=4
</b>
The second method can be used to change the size of “figure-level” plots such as <b>sns.lmplot()</b> and <b>sns.catplot()</b> or <b>sns.jointplot() </b>plots.
This method requires you to specify the <b>height</b> and <b>aspect</b> (the ratio of the width to the height) within the chart arguments:
<b>sns.lmplot(data=df, x="var1", y="var2",
              height=6, aspect=1.5) #height=6, width=1.5 times larger than height</b>
The following examples show how to use both of these methods in practice.
<h3>Method 1: Change the Size of Axes-Level Plots</h3>
The following code shows how to create a seaborn scatterplot with a width of 8 and a height of 4:
<b>import pandas as pd
import seaborn as sns
#create data
df = pd.DataFrame({"var1": [25, 12, 15, 14, 19, 23, 25, 29],   "var2": [5, 7, 7, 9, 12, 9, 9, 4],   "var3": [11, 8, 10, 6, 6, 5, 9, 12]})
#define figure size
sns.set(rc={"figure.figsize":(8, 4)}) #width=8, height=4
#display scatterplot
sns.scatterplot(data=df, x="var1", y="var2")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornFigSize1.png">
And the following code shows how to create a seaborn boxplot with a width of 6 and a height of 5:
<b>#define figure size
sns.set(rc={"figure.figsize":(6, 5)}) #width=6, height=5
#display scatterplot
sns.boxplot(data=df["var1"])</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornFigSize2.png">
<h3>Method 2: Change the Size of Figure-Level Plots</h3>
For figure-level plots (such as sns.lmplot, sns.catplot, sns.jointplot, etc.), you must specify the height and width within the chart itself.
The following code shows how to create a seaborn lmplot with a height of 5 and a width 1.5 times larger than the height:
<b>import pandas as pd
import seaborn as sns
#create data
df = pd.DataFrame({"var1": [25, 12, 15, 14, 19, 23, 25, 29],   "var2": [5, 7, 7, 9, 12, 9, 9, 4],   "var3": [11, 8, 10, 6, 6, 5, 9, 12]})
#create lmplot
sns.lmplot(data=df, x="var1", y="var2",
              height=5, aspect=1.5) #height=5, width=1.5 times larger than height
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornFigSize3.png">
And the following code shows how to create a seaborn jointplot with a height of 3.5. Since a jointplot is square by default, we don’t need to specify the aspect value:
<b>sns.jointplot(data=df, x="var1", y="var2", height=3.5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornFigSize4.png">
Check out the  seaborn documentation  for an in-depth explanation of the difference between figure-level and axes-level functions.
<h2><span class="orange">How to Change Font Size in Seaborn Plots (With Examples)</span></h2>
You can use the following basic syntax to change the font size in Seaborn plots:
<b>import seaborn as sns
sns.set(font_scale=2)
</b>
Note that the default value for <b>font_scale</b> is 1. By increasing this value, you can increase the font size of all elements in the plot.
The following examples show how to use this syntax in practice.
<h3>Example 1: Change Font Size of All Elements in Seaborn Plot</h3>
The following code shows how to create a simple line chart in Seaborn with the default font size:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'date': ['1/1/2021', '1/30/2021', '1/1/2021', '1/30/2021'],   'sales': [4, 11, 6, 18],   'company': ['A', 'A', 'B', 'B']})
#plot multiple lines
sns.lineplot(x='date', y='sales', hue='company', data=df).set(title='Sales Data')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/seabornFont1.png">
And the following code shows how to use the <b>sns.set()</b> function to increase the font size of all elements in the plot:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#increase font size of all elements
sns.set(font_scale=2)
#create DataFrame
df = pd.DataFrame({'date': ['1/1/2021', '1/30/2021', '1/1/2021', '1/30/2021'],   'sales': [4, 11, 6, 18],   'company': ['A', 'A', 'B', 'B']})
#plot multiple lines
sns.lineplot(x='date', y='sales', hue='company', data=df).set(title='Sales Data')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/seabornFont2.png">
Notice that the font size for each element in the plot has increased dramatically.
<h3>Example 2: Change Font Size of Specific Elements in Seaborn Plot</h3>
The following code shows how to change the font size of specific elements in a Seaborn plot:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'date': ['1/1/2021', '1/30/2021', '1/1/2021', '1/30/2021'],   'sales': [4, 11, 6, 18],   'company': ['A', 'A', 'B', 'B']})
#plot multiple lines
sns.lineplot(x='date', y='sales', hue='company', data=df)
#modify individual font size of elements
plt.legend(title='Company', fontsize=20)
plt.xlabel('Date', fontsize=16);
plt.ylabel('Sales', fontsize=16);
plt.title('Sales Data', fontsize=20)
plt.tick_params(axis='both', which='major', labelsize=14)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/seabornFont3.png">
Notice that each element in the plot has a unique font size based on the value specified in the <b>fontsize</b> argument.
<h2><span class="orange">How to Create a Grouped Bar Plot in Seaborn (Step-by-Step)</span></h2>
A <b>grouped bar plot</b> is a type of chart that uses bars grouped together to visualize the values of multiple variables at once.
This tutorial provides a step-by-step example of how to create the following grouped bar plot in Python using the  Seaborn  data visualization package:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/grouped2.png">
<h3>Step 1: Create the Data</h3>
First, let’s create the following pandas DataFrame that shows the total number of customers that a restaurant receives in the morning and evening from Monday through Friday:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'Day': ['Mon', 'Tue', 'Wed', 'Thur', 'Fri',           'Mon', 'Tue', 'Wed', 'Thur', 'Fri'],   'Customers': [44, 46, 49, 59, 54,                 33, 46, 50, 49, 60],   'Time': ['M', 'M', 'M', 'M', 'M',            'E', 'E', 'E', 'E', 'E']})
#view DataFrame
df
DayCustomers Time
0Mon44  M
1Tue46  M
2Wed49  M
3Thur59  M
4Fri54  M
5Mon33  E
6Tue46  E
7Wed50  E
8Thur49  E
9Fri60  E
</b>
<h3>Step 2: Create the Grouped Bar Chart</h3>
We can use the following code to create a grouped bar chart to visualize the total customers each day, grouped by time:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn plotting aesthetics
sns.set(style='white')
#create grouped bar chart
sns.barplot(x='Day', y='Customers', hue='Time', data=df) 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/grouped1.png">
The x-axis displays the day of the week and the bars display how many customers visited the restaurant in the morning and evening each day.
<h3>Step 3: Customize the Grouped Bar Chart</h3>
The following code shows how to add axis titles, add an overall title, change the colors of the bars, and rotate the x-axis labels to make them easier to read:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn plotting aesthetics
sns.set(style='white')
#create grouped bar chart
sns.barplot(x='Day', y='Customers', hue='Time', data=df,
            palette=['purple', 'steelblue'])
#add overall title
plt.title('Customers by Time & Day of Week', fontsize=16)
#add axis titles
plt.xlabel('Day of Week')
plt.ylabel('Number of Customers')
#rotate x-axis labels
plt.xticks(rotation=45)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/grouped2.png">
<b>Note</b>: We set the seaborn style to ‘white’ for this plot, but you can find a complete list of Seaborn plotting aesthetics on  this page .
<h2><span class="orange">How to Adjust the Size of Heatmaps in Seaborn</span></h2>
You can use the <b>figsize</b> argument to specify the size (in inches) of a  seaborn  heatmap:
<b>#specify size of heatmap
fig, ax = plt.subplots(figsize=(15, 5))
#create seaborn heatmap
sns.heatmap(df)
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Adjust Size of Heatmaps in Seaborn</h3>
For this example, we’ll use the seaborn dataset called <b>flights</b>, which contains the number of airline passengers who flew in each month from 1949 to 1960:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#load "flights" dataset
data = sns.load_dataset("flights")
data = data.pivot("month", "year", "passengers")
#view first five rows of dataset
print(data.head())
year   1949  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960
month                                                                        
Jan     112   115   145   171   196   204   242   284   315   340   360   417
Feb     118   126   150   180   196   188   233   277   301   318   342   391
Mar     132   141   178   193   236   235   267   317   356   362   406   419
Apr     129   135   163   181   235   227   269   313   348   348   396   461
May     121   125   172   183   229   234   270   318   355   363   420   472
</b>
Next, we’ll create a heatmap using <b>figsize</b> dimensions of 10 by 10:
<b>#specify size of heatmap
fig, ax = plt.subplots(figsize=(10, 10))
#create heatmap
sns.heatmap(data, linewidths=.3)
</b>
<h3><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/heat1.jpg"536"></h3>
Notice that the heatmap has the same dimensions for the height and the width.
We can make the heatmap more narrow by making the first argument in <b>figsize</b> smaller:
<b>#specify size of heatmap
fig, ax = plt.subplots(figsize=(5, 10))
#create heatmap
sns.heatmap(data, linewidths=.3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/heat2.jpg"334">
Or we could make the heatmap more wide by making the second argument in <b>figsize</b> smaller:
<b>#specify size of heatmap
fig, ax = plt.subplots(figsize=(10, 5))
#create heatmap
sns.heatmap(data, linewidths=.3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/heat3.jpg"554">
Feel free to modify the values in <b>figsize </b>to change the dimensions of the heatmap.
<h2><span class="orange">How to Make Heatmaps with Seaborn (With Examples)</span></h2>
A <b>heatmap </b>is a type of chart that uses different shades of colors to represent data values.
This tutorial explains how to create heatmaps using the Python visualization library  Seaborn  with the following dataset:
<b>#import seaborn
import seaborn as sns
#load "flights" dataset
data = sns.load_dataset("flights")
data = data.pivot("month", "year", "passengers")
#view first five rows of dataset
data.head()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap1.png">
<h3>Create a Basic Heatmap</h3>
We can use the following syntax to create a basic heatmap for this dataset:
<b>sns.heatmap(data)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap2.png">
The x-axis displays the year, the y-axis displays the month, and the color of the squares within the heatmap represent the number of flights in those particular year-month combinations.
<h3>Adjust the Size of the Heatmap</h3>
We can use the <b>figsize</b> argument to adjust the overall size of the heatmap:
<b>#set heatmap size
import matplotlib.pyplot as plt
plt.figure(figsize = (12,8))
#create heatmap
sns.heatmap(data)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap3.png">
<h3>Change the Colors of the Heatmap</h3>
We can use the <b>cmap</b> argument to change the colors used in the heatmap. For example, we could choose the “Spectral” color map:
<b>sns.heatmap(data, cmap="Spectral")
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap4.png">
Or we could choose the “coolwarm” color map:
<b>sns.heatmap(data, cmap="coolwarm")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap5.png">
Find a complete list of cmap options available  here .
<h3>Annotate the Heatmap</h3>
We can use the following syntax to annotate each cell in the heatmap with integer formatting and specify the font size:
<b>sns.heatmap(data, annot=True, fmt="d", annot_kws={"size":13})</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap6.png">
<h3>Modify the Colorbar of the Heatmap</h3>
Lastly, we can turn the colorbar off if we’d like using the <b>cbar </b>argument:
<b>sns.heatmap(data, cbar=False)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/seaborn_heatmap7.png">
Find more Seaborn tutorials on  this page .
<h2><span class="orange">How to Create a Horizontal Barplot in Seaborn (With Example)</span></h2>
You can use the following basic syntax to create a horizontal barplot in  seaborn :
<b>sns.barplot(x=df.values_var, y=df.group_var, orient='h')</b>
The<b> orient=’h’</b> argument tells seaborn to orient the bars horizontally instead of the default vertical.
The following example shows how to use this syntax in practice.
<h2>Example: How to Create a Horizontal Barplot in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the total sales made by various employees at a company:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'employee': ['Andy', 'Bert', 'Chad', 'Doug', 'Eric', 'Frank'],   'sales': [22, 14, 9, 7, 29, 20]})
#view DataFrame
print(df)
  employee  sales
0     Andy     22
1     Bert     14
2     Chad      9
3     Doug      7
4     Eric     29
5    Frank     20
</b>
We can use the following syntax to create a horizontal barplot to visualize the sales by each employee:
<b>import seaborn as sns
#create horizontal barplot
sns.barplot(x=df.sales, y=df.employee, orient='h')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/horz1.jpg"536">
The x-axis displays the sales made by each employee and the y-axis shows the names of the employees.
Note that we can also specify the colors of the bars and add a custom title with axis labels:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create horizontal bar chart
sns.barplot(x=df.sales, y=df.employee, color='steelblue', orient='h')
#add plot title
plt.title('Total Sales by Employee', fontsize=16)
#add axis labels
plt.xlabel('Total Sales')
plt.ylabel('Employee Name')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/horz2.jpg">
The bars in the plot now each have the same color and we’ve added an overall plot title and axis labels to make the plot easier to read.
<b>Note</b>: If you have trouble importing seaborn in a Jupyter notebook, you may first need to run the command <b>%pip install seaborn</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in seaborn:
 How to Show Values on Seaborn Barplot 
 How to Create a Grouped Barplot in Seaborn 
 How to Set the Color of Bars in a Seaborn Barplot 
<h2><span class="orange">How to Place Legend Outside a Seaborn Plot (With Examples)</span></h2>
You can use the <b>bbox_to_anchor()</b> argument to place a seaborn legend outside of the plot.
For example, you can use the following syntax to place the legend in the top right corner outside of the plot:
<b>plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)
</b>
Note that the <b>(1.05, 1)</b> coordinates correspond to the (x, y) coordinates where the legend should be placed and the <b>borderaxespad</b> specifies the padding between the axes and the border legend.
The following examples show how to use this function in practice.
<h3>Example: Place Legend Outside of Seaborn Plot</h3>
The following code shows how to place the legend outside the top right corner of a seaborn plot:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend outside top right corner of plot
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend3.png">
And here’s how to place the legend outside the center right border of the plot:
<b>#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend outside center right border of plot
plt.legend(bbox_to_anchor=(1.02, 0.55), loc='upper left', borderaxespad=0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornOutsideLegend.png">
And here’s how to place the legend outside the bottom right corner of the plot:
<b>#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend outside bottom right corner of plot
plt.legend(bbox_to_anchor=(1.02, 0.15), loc='upper left', borderaxespad=0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend4.png">
Refer to the  matplotlib documentation  for a detailed explanation of the <b>bbox_to_anchor()</b> argument.
Refer to the  seaborn documentation  for details on how to style the aesthetics of the plot.
<h2><span class="orange">How to Change the Position of a Legend in Seaborn</span></h2>
To change the position of a legend in a seaborn plot, you can use the <b>plt.legend()</b> command.
For example, you can use the following syntax to place the legend in the upper right corner of the plot:
<b>plt.legend(loc='upper right')
</b>
The default location is “best” – which is where Matplotlib automatically finds a location for the legend based on where it avoids covering any data points.
However, you can specify any of the following legend locations:
upper right
upper left
lower left
lower right
right
center left
center right
lower center
upper center
center
You can also use the <b>bbox_to_anchor()</b> argument to place the legend outside of the plot. For example, you can use the following syntax to place the legend in the top right corner outside of the plot:
<b>plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)
</b>
The following examples show how to use each of these methods in practice.
<h3>Example 1: Change Legend Position Inside of Seaborn Plot</h3>
The following code shows how to place the legend inside the center right portion of a seaborn scatterplot:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend in center right of plot
plt.legend(loc='center right', title='Team')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend1.png">
And the following code shows how to place the legend inside the upper left portion of a seaborn scatterplot:
<b>#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend in upper left of plot
plt.legend(loc='upper left', title='Team')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend2.png">
<h3>Example 2: Change Legend Position Outside of Seaborn Plot</h3>
To place the legend outside of a seaborn plot, we can use the <b>bbox_to_anchor()</b> argument.
For example, here’s how to place the legend outside the top right corner of the plot:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend outside top right corner of plot
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend3.png">
And here’s how to place the legend outside the bottom right corner of the plot:
<b>#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#place legend outside bottom right corner of plot
plt.legend(bbox_to_anchor=(1.02, 0.15), loc='upper left', borderaxespad=0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegend4.png">
Refer to the  matplotlib documentation  for a detailed explanation of the <b>bbox_to_anchor()</b> argument.
<h2><span class="orange">How to Change Legend Font Size in a Seaborn Plot</span></h2>
You can use the following syntax to change the font size within a legend of a seaborn plot:
<b>plt.legend(title='Team', fontsize='10', title_fontsize='14')
</b>
The <b>fontsize</b> argument specifies the font size for the labels in the legend and the <b>title_fontsize</b> specifies the font size for the title of the legend.
The following example shows how to use this function in practice.
<h2>Example: Changing Legend Font Size in a Seaborn Plot</h2>
The following code shows how to create a scatterplot in Seaborn and specify the font size for both the labels and the title within the legend:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style('whitegrid')
#create data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#add legend
plt.legend(title='Team', fontsize='10', title_fontsize='14')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegendSize1.png">
The font size arguments can also take on the following values:
xx-small
x-small
small
medium
large
x-large
xx-large
The following example shows how to use these arguments in practice:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style('whitegrid')
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create scatterplot
sns.scatterplot(data=df, x='points', y='assists', hue='team')
#add legend
plt.legend(title='Team', fontsize='medium', title_fontsize='x-large')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornLegendSize2.png">
Reference the  matplotlib documentation  for an in-depth explanation of the <b>plt.legend()</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Adjust the Figure Size of a Seaborn Plot 
 How to Change Axis Labels on a Seaborn Plot 
 How to Change the Position of a Legend in Seaborn 
 How to Place Legend Outside a Seaborn Plot 
<h2><span class="orange">How to Change Line Style in a Seaborn Lineplot</span></h2>
You can use the <b>linestyle </b>argument within the <b>lineplot()</b> function to adjust the style of a line in a seaborn lineplot:
<b>import seaborn as sns
sns.lineplot(data=df, x='x_var', y='y_var', linestyle='dashed')</b>
The most common styles to provide in the <b>linestyle</b> argument include:
solid (default)
dashed
dotted
dashdot
The following example shows how to change the line style in a seaborn lineplot in practice.
<h2>Example: Change Line Style in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made each day at some retail store:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],   'sales': [3, 3, 5, 4, 5, 6, 8, 9, 14, 18]})
#view DataFrame
print(df)
   day  sales
0    1      3
1    2      3
2    3      5
3    4      4
4    5      5
5    6      6
6    7      8
7    8      9
8    9     14
9   10     18
</b>
We can use the <b>lineplot()</b> function in seaborn to create a line plot with a solid line:
<b>import seaborn as sns
#create line plot with default line width
sns.lineplot(data=df, x='day', y='sales')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linet1.jpg"516">
We can also use the <b>linestyle</b> argument to instead use a <b>dashed</b> line:
<b>import seaborn as sns
#create line plot with dashed line
sns.lineplot(data=df, x='day', y='sales', linestyle='dashed')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linestyle1.jpg"528">
Or we could use the <b>linestyle</b> argument to instead use a <b>dotted </b>line:
<b>import seaborn as sns
#create line plot with dotted line
sns.lineplot(data=df, x='day', y='sales', linestyle='dotted')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linestyle2.jpg"538">
Or we could use the <b>linestyle</b> argument to instead use a <b>dashdot </b>line:
<b>import seaborn as sns
#create line plot with dashdot line
sns.lineplot(data=df, x='day', y='sales', linestyle='dashdot')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linestyle3.jpg"537">
Also note that if you create a  seaborn plot with multiple lines , the <b>linestyle </b>argument will affect the style of each line in the plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Change the Colors in a Seaborn Lineplot 
 How to Adjust Line Thickness in Seaborn 
 How to Plot Multiple Lines in Seaborn 
<h2><span class="orange">How to Adjust Line Thickness in Seaborn (With Example)</span></h2>
You can use the <b>linewidth</b> argument within the <b>lineplot()</b> function to adjust the line thickness in seaborn plots:
<b>import seaborn as sns
sns.lineplot(data=df, x='x_var', y='y_var', linewidth=2)</b>
The greater the value you provide, the thicker the line will be.
The following example shows how to use this syntax in practice.
<h2>Example: Adjust Line Thickness in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made each day at some retail store:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],   'sales': [3, 3, 5, 4, 5, 6, 8, 9, 14, 18]})
#view DataFrame
print(df)
   day  sales
0    1      3
1    2      3
2    3      5
3    4      4
4    5      5
5    6      6
6    7      8
7    8      9
8    9     14
9   10     18
</b>
We can use the <b>lineplot()</b> function in seaborn to create a line plot with a default line width:
<b>import seaborn as sns
#create line plot with default line width
sns.lineplot(data=df, x='day', y='sales')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linet1.jpg"516">
To increase the line width, we can use the <b>linewidth</b> argument:
<b>import seaborn as sns
#create line plot with increased line width
sns.lineplot(data=df, x='day', y='sales', linewidth=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linet2.jpg"523">
Notice that the line is much thicker in this plot.
Also note that you can use <b>lw</b> as shorthand for “linewidth” if you’d like:
<b>import seaborn as sns
#create line plot with increased line width
sns.lineplot(data=df, x='day', y='sales', lw=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/linet2.jpg"523">
This produces the same result.
Also note that if you create a  seaborn plot with multiple lines , the <b>linewidth</b> argument will affect the thickness of each line in the plot.
<b>Note</b>: If you have trouble importing seaborn in a Jupyter notebook, you may first need to run the command <b>%pip install seaborn</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Add a Title to Seaborn Plots 
 How to Change Font Size in Seaborn Plots 
 How to Adjust the Figure Size of a Seaborn Plot 
<h2><span class="orange">How to Change the Colors in a Seaborn Lineplot</span></h2>
You can use the following methods to change the colors of lines in a seaborn plot:
<b>Method 1: Change Color of One Line in Seaborn</b>
You can use the <b>color</b> argument to specify the color when creating a line plot with one line:
<b>sns.lineplot(data=df, x='x_var', y='y_var', color='red')
</b>
<b>Method 2: Change Color of Multiple Lines in Seaborn</b>
You can use the <b>palette </b>argument to specify several colors when creating a line plot with multiple lines:
<b>sns.lineplot(data=df, x='x_var', y='y_var', hue='group_var', palette=['red', 'blue'])</b>
The following examples show how to use each method in practice.
<h2>Example 1: Change Color of One Line in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made during ten consecutive days at some retail store:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],   'sales': [3, 3, 5, 4, 5, 6, 8, 9, 14, 18]})
#view DataFrame
print(df)
   day  sales
0    1      3
1    2      3
2    3      5
3    4      4
4    5      5
5    6      6
6    7      8
7    8      9
8    9     14
9   10     18</b>
We can use the <b>color</b> argument within the <b>lineplot()</b> function to create a line plot with a specific color:
<b>import seaborn as sns
#create lineplot with red line to show sales by day
<b>sns.lineplot(data=df, x='day', y='sales', color='red')</b>
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/colorline1.jpg"513">
The color of the line in the plot corresponds to the ‘red’ that we specified using the <b>color</b> argument.
Also note that we can provide hex color codes to the <b>color</b> argument:
<b>import seaborn as sns
<b>#create lineplot with teal line to show sales by day
sns.lineplot(data=df, x='day', y='sales', color='#028ca1')</b></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/colorline2.jpg"548">
<h2>Example 2: Change Color of Multiple Lines in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made during five consecutive days at two different retail stores:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],   'store': ['A', 'A', 'A', 'A', 'A',             'B', 'B', 'B', 'B', 'B'],   'sales': [3, 3, 5, 4, 7, 6, 8, 9, 12, 13]})
#view DataFrame
print(df)
   day store  sales
0    1     A      3
1    2     A      3
2    3     A      5
3    4     A      4
4    5     A      7
5    1     B      6
6    2     B      8
7    3     B      9
8    4     B     12
9    5     B     13
</b>
We can use the <b>palette </b>argument within the <b>lineplot()</b> function to create a line plot with multiple specific colors:
<b>import seaborn as sns
#create lineplot with red and blue lines to show sales by day by store
<b>sns.lineplot(data=df, x='day', y='sales', hue='store', palette=['red', 'blue'])</b>
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/colorline3.jpg"514">
The colors of the lines correspond to the colors that we specified using the <b>palette</b> argument.
Also note that you can provide hex color codes to the <b>palette</b> argument as well.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Adjust Line Thickness in Seaborn 
 How to Plot Multiple Lines in Seaborn 
 How to Change the Position of a Legend in Seaborn 
<h2><span class="orange">How to Use a Log Scale in Seaborn Plots</span></h2>
You can use the <b>plt.xscale()</b> and <b>plt.yscale()</b> functions to use a log scale for the x-axis and y-axis, respectively, in a seaborn plot:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create scatterplot with log scale on both axes
sns.scatterplot(data=df, x='x', y='y')
plt.xscale('log')
plt.yscale('log')</b>
The following example shows how to use these functions in practice.
<h2>Example: Use Log Scale in Seaborn Plot</h2>
Suppose we have the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'x': [2, 5, 6, 7, 9, 13, 14, 16, 18],   'y': [200, 1700, 2300, 2500, 2800, 2900, 3400, 3900, 11000]})
#view DataFrame
print(df)
    x      y
0   2    200
1   5   1700
2   6   2300
3   7   2500
4   9   2800
5  13   2900
6  14   3400
7  16   3900
8  18  11000</b>
We can use the <b>scatterplot()</b> function in seaborn to create a scatterplot that uses a linear scale on both the x-axis and y-axis:
<b>import seaborn as sns
#create scatterplot with default axis scales
sns.scatterplot(data=df, x='x', y='y')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/logs1.jpg"554">
To use a log scale for the y-axis only, we can use the following syntax:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create scatterplot with log scale on y-axis
sns.scatterplot(data=df, x='x', y='y')
plt.yscale('log')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/logs2.jpg">
Notice that the y-axis now uses a log scale.
We can also use a log scale on the x-axis if we’d like:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create scatterplot with log scale on both axes
sns.scatterplot(data=df, x='x', y='y')
plt.yscale('log')
plt.xscale('log')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/logs3.jpg"545">
Notice that both axes now use a log scale.
<b>Related:</b>  When Should You Use a Log Scale in Charts? 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Add a Title to Seaborn Plots 
 How to Rotate Axis Labels in Seaborn Plots 
 How to Change Axis Labels on a Seaborn Plot 
<h2><span class="orange">How to Create Multiple Seaborn Plots in One Figure</span></h2>
You can use the <b>FacetGrid()</b> function to create multiple Seaborn plots in one figure:
<b>#define grid
g = sns.FacetGrid(data=df, col='variable1', col_wrap=2)
#add plots to grid
g.map(sns.scatterplot, 'variable2', 'variable3')
</b>
Note that the<b> col</b> argument specifies the variable to group by and the <b>col_wrap</b> argument specifies the number of plots to display per row.
The following examples show how to use this function in practice with the built-in ‘tips’ dataset:
<b>#load tips dataset
tips = sns.load_dataset('tips')
#view first five rows of tips dataset
tips.head()
   total_billtipsexsmokerdaytimesize
016.991.01FemaleNoSunDinner2
110.341.66MaleNoSunDinner3
221.013.50MaleNoSunDinner3
323.683.31MaleNoSunDinner2
424.593.61FemaleNoSunDinner4
</b>
<h3>Example 1: Create Multiple Plots</h3>
The following code shows how to create multiple Seaborn plots in one figure:
<b>#define grid with two plots per row
g = sns.FacetGrid(data=tips, col='day', col_wrap=2)
#add histograms to each plot
g.map(sns.histplot, 'tip')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/snsMlut1.png">
Here’s what we did with this simple code:
Specified to group by the variable ‘day’
Specified to display 2 plots per row
Specified to display a histogram in each plot that shows the distribution of ‘tip’ values for each particular day
<h3>Example 2: Create Multiple Plots with Specific Height</h3>
The following code shows how to create multiple Seaborn plots with a specific height and aspect ratio:
<b>#define grid
g = sns.FacetGrid(data=tips, col='day', col_wrap=2, height=4, aspect=.75)
#add histograms to each plot
g.map(sns.histplot, 'tip')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/snsMult2.png">
<h3>
<b>Example 3: Create Multiple Plots with Legend</b>
</h3>
The following code shows how to create multiple Seaborn plots and add a legend:
<b>#define grid
g = sns.FacetGrid(data=tips, col='day', hue='sex', col_wrap=2)
#add density plots to each plot
g.map(sns.kdeplot, 'tip')
#add legend
g.add_legend()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/snsMult3.png">
<h2><span class="orange">How to Plot a Normal Distribution in Seaborn (With Examples)</span></h2>
You can use the following methods to plot a normal distribution with the  seaborn  data visualization library in Python:
<b>Method 1: Plot Normal Distribution Histogram</b>
<b>sns.displot(x)
</b>
<b>Method 2: Plot Normal Distribution Curve</b>
<b>sns.displot(x, kind='kde')</b>
<b>Method 3: Plot Normal Distribution Histogram with Curve</b>
<b>sns.displot(x, kde=True)</b>
The following examples show how to use each method in practice.
<h3>Example 1: Plot a Normal Distribution Histogram</h3>
The following code shows how to plot a normal distribution histogram in seaborn:
<b>import numpy as np
import seaborn as sns
#make this example reproducible
np.random.seed(0)
#create data
x = np.random.normal(size=1000)
#create normal distribution histogram
sns.displot(x)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/seaborn1.png">
<h3>Example 2: Plot a Normal Distribution Curve</h3>
The following code shows how to plot a normal distribution curve in seaborn:
<b>import numpy as np
import seaborn as sns
#make this example reproducible
np.random.seed(0)
#create data
x = np.random.normal(size=1000)
#create normal distribution curve
sns.displot(x, kind='kde')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/seaborn2.png">
<h3>Example 3: Plot a Normal Distribution Histogram with Curve</h3>
The following code shows how to plot a normal distribution histogram with a curve in seaborn:
<b>import numpy as np
import seaborn as sns
#make this example reproducible
np.random.seed(0)
#create data
x = np.random.normal(size=1000)
#create normal distribution curve
sns.displot(x, kde=True)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/seaborn3.png">
<h2><span class="orange">How to Create a Pie Chart in Seaborn</span></h2>
The Python data visualization library  Seaborn  doesn’t have a default function to create pie charts, but you can use the following syntax in Matplotlib to create a pie chart and add a Seaborn color palette:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#define data
data = [value1, value2, value3, ...]
labels = ['label1', 'label2', 'label3', ...]
#define Seaborn color palette to use
colors = sns.color_palette('pastel')[0:5]
#create pie chart
plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')
plt.show()
</b>
Refer to the  Seaborn documentation  for a complete list of color palettes.
The following examples show how to use this syntax in practice.
<h3>Example 1: Pie Chart with Pastel Seaborn Color Palette</h3>
The following code shows how to create a pie chart using the ‘<b>pastel</b>‘ Seaborn color palette:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#define data
data = [15, 25, 25, 30, 5]
labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4', 'Group 5']
#define Seaborn color palette to use
colors = sns.color_palette('pastel')[0:5]
#create pie chart
plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/seabornPie1.png">
<h3>Example 2: Pie Chart with Bright Seaborn Color Palette</h3>
The following code shows how to create a pie chart using the ‘<b>bright</b>‘ Seaborn color palette:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#define data
data = [15, 25, 25, 30, 5]
labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4', 'Group 5']
#define Seaborn color palette to use
colors = sns.color_palette('bright')[0:5]
#create pie chart
plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/seabornPie2.png">
These two examples illustrate how to create a pie chart with two different Seaborn color palettes.
However, there are many more styles you could use. Refer to the  online documentation  for a complete list of color palettes.
<h2><span class="orange">How to Plot Multiple Lines in Seaborn (With Example)</span></h2>
You can use the following basic syntax to plot multiple lines on the same plot using seaborn in Python:
<b>import seaborn as sns
sns.lineplot(data=df[['col1', 'col2', 'col3']]
</b>
This particular example will create a plot with three different lines.
The following example shows how to use this syntax in practice.
<h2>Example: Plot Multiple Lines in Seaborn</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made by four different retail stores (A, B, C, and D) during eight consecutive years:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'year': [1, 2, 3, 4, 5, 6, 7, 8],   'A': [10, 12, 14, 15, 15, 14, 13, 18],   'B': [18, 18, 19, 14, 14, 11, 20, 28],   'C': [5, 7, 7, 9, 12, 9, 9, 4],   'D': [11, 8, 10, 6, 6, 5, 9, 12]})
#view DataFrame
print(df)
   year   A   B   C   D
0     1  10  18   5  11
1     2  12  18   7   8
2     3  14  19   7  10
3     4  15  14   9   6
4     5  15  14  12   6
5     6  14  11   9   5
6     7  13  20   9   9
7     8  18  28   4  12
</b>
We can use the <b>lineplot()</b> function in seaborn to create a plot that displays four lines to represent the sales made by each store during each year:
<b>import seaborn as sns
#plot sales of each store as a line
sns.lineplot(data=df[['A', 'B', 'C', 'D']])
</b>
 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/se1.jpg">
Each line represents the values for one of the four stores.
The legend in the top left corner shows which color corresponds to which store.
Note that we can also use the <b>palette</b> argument to specify our own colors to use in the plot:
<b>import seaborn as sns
#plot sales of each store with custom colors
sns.lineplot(data=df[['A', 'B', 'C', 'D']], palette=['red', 'blue', 'purple', 'pink'])</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/se2.jpg"516">
Notice that the colors of the lines now correspond to the four colors that we specified in the <b>palette</b> argument.
If you’d like each of the lines to be solid, you can use the pandas <b>melt()</b> function to melt the DataFrame into a  long format  and then use the following syntax to plot the lines:
<b>import seaborn as sns
#plot sales of each store with custom colors
sns.lineplot(x='year', y='value', hue='variable', 
             data=pd.melt(df, ['year']),
             palette=['red', 'blue', 'purple', 'pink'])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/se3.jpg"524">
Each of the lines are now solid instead of having their own line styles.
<b>Note</b>: If you have trouble importing seaborn in a Jupyter notebook, you may first need to run the command <b>%pip install seaborn</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Add a Title to Seaborn Plots 
 How to Change Font Size in Seaborn Plots 
 How to Adjust the Figure Size of a Seaborn Plot 
<h2><span class="orange">How to Rotate Axis Labels in Seaborn Plots</span></h2>
You can use the following basic syntax to rotate the axis labels in a plot in  seaborn :
<b>my_plot.set_xticklabels(my_plot.get_xticklabels(), rotation=45)</b>
The following example shows how to use this syntax in practice.
<h2>Example: How to Rotate Axis Labels in Seaborn Plot</h2>
Suppose we have the following pandas DataFrame that contains information about the points scored by basketball players on various teams:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['Mavericks', 'Mavericks', 'Mavericks',            'Mavericks', 'Warriors', 'Warriors',            'Blazers', 'Blazers', 'Kings',            'some_really_really_long_name'],   'points': [22, 14, 9, 7, 29, 20, 30, 34, 19, 12]})
#view DataFrame
print(df)
           team  points
0                     Mavericks      22
1                     Mavericks      14
2                     Mavericks       9
3                     Mavericks       7
4                      Warriors      29
5                      Warriors      20
6                       Blazers      30
7                       Blazers      34
8                         Kings      19
9  some_really_really_long_name      12</b>
We can use the <b>countplot()</b> function in seaborn to create a plot that displays the count of each team in the DataFrame:
<b>import seaborn as sns
#create seaborn countplot
my_plot = sns.countplot(data=df, x='team')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/rotate12.jpg"572">
Since one of the team names is extremely long, it overlaps another team name on the x-axis.
To get around this, we can use the following code to rotate the x-axis labels:
<b>import seaborn as sns
#create seaborn countplot
my_plot = sns.countplot(data=df, x='team')
#rotate x-axis labels
my_plot.set_xticklabels(my_plot.get_xticklabels(), rotation=45)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/rotate13.jpg"564">
Notice that each of the x-axis labels are now rotated 45 degrees.
If we’d like, we can also use the <b>horizontalalignment</b> argument to shift the x-axis labels to the left:
<b>import seaborn as sns
#create seaborn countplot
my_plot = sns.countplot(data=df, x='team')
#rotate x-axis labels
my_plot.set_xticklabels(my_plot.get_xticklabels(), rotation=45,        horizontalalignment='right')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/rotate14.jpg">
 Each of the x-axis labels are rotated 45 degrees and shifted to the left.
<b>Note</b>: If you have trouble importing seaborn in a Jupyter notebook, you may first need to run the command <b>%pip install seaborn</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Add a Title to Seaborn Plots 
 How to Change Font Size in Seaborn Plots 
 How to Adjust the Figure Size of a Seaborn Plot 
<h2><span class="orange">How to Change Marker Size in Seaborn Scatterplot</span></h2>
You can use the <b>s </b>argument within the <b>scatterplot()</b> function to adjust the marker size in a seaborn scatterplot:
<b>import seaborn as sns
sns.scatterplot(data=df, x='x_var', y='y_var', hue='group_var', s=20)</b>
The greater the value you provide for the <b>s</b> argument, the larger the points in the plot will be.
The following example shows how to use this syntax in practice.
<h2>Example: Change Marker Size in Seaborn Scatterplot</h2>
Suppose we have the following pandas DataFrame that contains information about the sales made during five consecutive days at two different retail stores:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'day': [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],   'store': ['A', 'A', 'A', 'A', 'A',             'B', 'B', 'B', 'B', 'B'],   'sales': [3, 3, 5, 4, 7, 6, 8, 9, 12, 13]})
#view DataFrame
print(df)
   day store  sales
0    1     A      3
1    2     A      3
2    3     A      5
3    4     A      4
4    5     A      7
5    1     B      6
6    2     B      8
7    3     B      9
8    4     B     12
9    5     B     13</b>
We can use the <b>scatterplot()</b> function in seaborn to create a scatterplot that displays the sales made each day at each store
<b>import seaborn as sns
#create scatterplot with default marker size
sns.scatterplot(data=df, x='day', y='sales', hue='store')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/marker1.jpg"516">
We can use the <b>s</b> argument to increase the size of the points in the plot:
<b>import seaborn as sns
#create scatterplot with increased marker size
sns.scatterplot(data=df, x='day', y='sales', hue='store', s=200)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/marker2.jpg"521">
Notice that the size of the points has increased.
However, the size of the points in the legend have remained the same.
To increase the size of the points in the legend, you can use the <b>markerscale</b> argument within the matplotlib <b>legend()</b> function:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#create scatterplot with increased marker size
sns.scatterplot(data=df, x='day', y='sales', hue='store', s=200)
#increase marker size in legend
plt.legend(markerscale=2)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/marker3.jpg"523">
Note that the default value for <b>markerscale</b> is 1.
By increasing this value, you can change the size of the markers relative to the originally drawn ones.
Feel free to play around with the <b>s</b> argument and <b>markerscale</b> argument to make the points in the scatterplot be the exact size that you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in seaborn:
 How to Add a Title to Seaborn Plots 
 How to Change Font Size in Seaborn 
 How to Change the Position of a Legend in Seaborn 
<h2><span class="orange">How to Create a Stacked Bar Plot in Seaborn (Step-by-Step)</span></h2>
A <b>stacked bar plot</b> is a type of chart that uses bars divided into a number of sub-bars to visualize the values of multiple variables at once.
This tutorial provides a step-by-step example of how to create the following stacked bar plot in Python using the  Seaborn  data visualization package:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/stacked2.png">
<h3>Step 1: Create the Data</h3>
First, let’s create the following pandas DataFrame that shows the total number of customers that a restaurant receives in the morning and evening from Monday through Friday:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'Day': ['Mon', 'Tue', 'Wed', 'Thur', 'Fri'],   'Morning': [44, 46, 49, 59, 54],   'Evening': [33, 46, 50, 49, 60]})
#view DataFrame
df
DayMorningEvening
0Mon4433
1Tue4646
2Wed4950
3Thur5949
4Fri5460
</b>
<h3>Step 2: Create the Stacked Bar Chart</h3>
We can use the following code to create a stacked bar chart to visualize the total customers each day:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn plotting aesthetics
sns.set(style='white')
#create stacked bar chart
df.set_index('Day').plot(kind='bar', stacked=True, color=['steelblue', 'red'])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/stacked1.png">
The x-axis displays the day of the week and the bars display how many customers visited the restaurant in the morning and evening each day.
<h3>Step 3: Customize the Stacked Bar Chart</h3>
The following code shows how to add axis titles, add an overall title, and rotate the x-axis labels to make them easier to read:
<b>import matplotlib.pyplot as plt
import seaborn as sns
#set seaborn plotting aesthetics
sns.set(style='white')
#create stacked bar chart
df.set_index('Day').plot(kind='bar', stacked=True, color=['steelblue', 'red'])
#add overall title
plt.title('Customers by Time & Day of Week', fontsize=16)
#add axis titles
plt.xlabel('Day of Week')
plt.ylabel('Number of Customers')
#rotate x-axis labels
plt.xticks(rotation=45)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/stacked2.png">
<b>Note</b>: We set the seaborn style to ‘white’ for this plot, but you can find a complete list of seaborn plotting aesthetics on  this page .
<h2><span class="orange">How to Create Subplots in Seaborn (With Examples)</span></h2>
You can use the following basic syntax to create subplots in the  seaborn  data visualization library in Python:
<b>#define dimensions of subplots (rows, columns)
fig, axes = plt.subplots(2, 2)
#create chart in each subplot
sns.boxplot(data=df, x='team', y='points', ax=axes[0,0])
sns.boxplot(data=df, x='team', y='assists', ax=axes[0,1])
...
</b>
The following example shows how to use this syntax in practice.
<h3>Example: Creating Subplots in Seaborn</h3>
Suppose we have the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],   'points': [19, 12, 15, 14, 19, 23, 25, 29],   'assists': [13, 15, 11, 8, 6, 8, 11, 14],   'rebounds': [11, 7, 8, 12, 13, 7, 6, 8],   'blocks': [1, 2, 2, 3, 5, 4, 3, 3]})
#view DataFrame
print(df)
  team  points  assists  rebounds  blocks
0    A      19       13        11       1
1    A      12       15         7       2
2    A      15       11         8       2
3    A      14        8        12       3
4    B      19        6        13       5
5    B      23        8         7       4
6    B      25       11         6       3
7    B      29       14         8       3</b>
The following code shows how to define a plotting region with two rows and two columns and create a boxplot in each subplot for each of the four numeric variables in the DataFrame:
import <b>matplotlib.</b>pyplot<b> </b>as<b> plt
</b>import<b> seaborn </b>as<b> sns
#set seaborn plotting aesthetics as default
sns.</b>set<b>()
#define plotting region (2 rows, 2 columns)
fig, axes = plt.</b>subplots<b>(2, 2)
</b>#create boxplot in each subplot
<b>sns.boxplot(data=df, x='team', y='points', ax=axes[0,0])
sns.boxplot(data=df, x='team', y='assists', ax=axes[0,1])
sns.boxplot(data=df, x='team', y='rebounds', ax=axes[1,0])
sns.boxplot(data=df, x='team', y='blocks', ax=axes[1,1])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/seabornSub1.png">
In this example, we created a plotting region with two rows and two columns and filled each subplot with boxplots. 
However, we can use similar syntax to create a plotting region with different dimensions and fill in the subplots with different charts.
For example, the following code shows how to create a plotting region with one row and two columns and fill in each plot with a violin plot:
import <b>matplotlib.</b>pyplot<b> </b>as<b> plt
</b>import<b> seaborn </b>as<b> sns
#set seaborn plotting aesthetics as default
sns.</b>set<b>()
#define plotting region (1 row, 2 columns)
fig, axes = plt.</b>subplots<b>(1, 2)
</b>#create boxplot in each subplot
<b>sns.violinplot(data=df, x='team', y='points', ax=axes[0])
sns.violinplot(data=df, x='team', y='assists', ax=axes[1])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/seabornSub2.png">
<h2><span class="orange">How to Adjust Number of Ticks in Seaborn Plots</span></h2>
You can use the following basic syntax to specify the positions and labels of axis ticks on  seaborn  plots:
<b>#specify x-axis tick positions and labels
plt.xticks([1, 2, 3], ['A', 'B', 'C'])
#specify y-axis tick positions and labels
plt.yticks([4, 5, 6], ['D', 'E', 'F'])
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Set Axis Tick Positions</h3>
The following code shows how to create a simple scatterplot using seaborn:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'var1': [25, 12, 15, 14, 19, 23, 25, 29],   'var2': [5, 7, 7, 9, 12, 9, 9, 4]})
#create scatterplot
sns.scatterplot(data=df, x='var1', y='var2')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/seabornTicks1.png">
By default, seaborn chooses an optimal number of ticks to display on both the x-axis and y-axis.
However, we can use the following code to specify the number of ticks and their exact positions on each axis:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'var1': [25, 12, 15, 14, 19, 23, 25, 29],   'var2': [5, 7, 7, 9, 12, 9, 9, 4]})
#create scatterplot
sns.scatterplot(data=df, x='var1', y='var2')
#specify positions of ticks on x-axis and y-axis
plt.xticks([15, 20, 25])
plt.yticks([4, 8, 12])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/seabornTicks2.png">
<h3>Example 2: Set Axis Tick Positions & Labels</h3>
The following code shows how to create a scatterplot and specify both the axis tick <b>positions</b> and the tick <b>labels</b>:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'var1': [25, 12, 15, 14, 19, 23, 25, 29],   'var2': [5, 7, 7, 9, 12, 9, 9, 4]})
#create scatterplot
sns.scatterplot(data=df, x='var1', y='var2')
#specify positions of ticks on x-axis and y-axis
plt.xticks([15, 20, 25], ['A', 'B', 'C'])
plt.yticks([4, 8, 12], ['Low', 'Medium', 'High'])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/seabornTicks3.png">
<b>Note</b>: Refer to  this article  to see how to change just the axis labels.
<h2><span class="orange">How to Create a Time Series Plot in Seaborn</span></h2>
A <b>time series plot</b> is useful for visualizing data values that change over time.
This tutorial explains how to create various time series plots using the  seaborn  data visualization package in Python.
<h3>Example 1: Plot a Single Time Series</h3>
The following code shows how to plot a single time series in seaborn:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'date': ['1/2/2021',            '1/3/2021',            '1/4/2021',            '1/5/2021',            '1/6/2021',            '1/7/2021',            '1/8/2021'],   'value': [4, 7, 8, 13, 17, 15, 21]})
sns.lineplot(x='date', y='value', data=df)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/timeseries1.png">
Note that we can also customize the colors, line width, line style, labels, and titles of the plot:
<b style="font-size: 15px;">#create time series plot with custom aesthetics</b><b style="font-size: 15px;"> 
sns.</b>lineplot<b style="font-size: 15px;">(x='</b>date<b style="font-size: 15px;">', y='</b>value<b style="font-size: 15px;">', data=df, linewidth=</b>3<b style="font-size: 15px;">, color='</b>purple<b style="font-size: 15px;">',
             linestyle='</b>dashed<b style="font-size: 15px;">').</b>set<b style="font-size: 15px;">(title='</b>Time Series Plot<b style="font-size: 15px;">')
#rotate x-axis labels by 15 degrees
plt.</b>xticks<b style="font-size: 15px;">(rotation=</b>15<b style="font-size: 15px;">)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/timeseries2.png">
<h3>Example 2: Plot Multiple Time Series</h3>
The following code shows how to plot multiple time series in seaborn:
<b>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#create DataFrame
df = pd.DataFrame({'date': ['1/1/2021',            '1/2/2021',            '1/3/2021',            '1/4/2021',            '1/1/2021',            '1/2/2021',            '1/3/2021',            '1/4/2021'],   'sales': [4, 7, 8, 13, 17, 15, 21, 28],   'company': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#plot multiple time series
sns.lineplot(x='date', y='sales', hue='company', data=df)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/timeseries3.png">
Note that the <b>hue</b> argument is used to provide different colors to each line in the plot.
<h2><span class="orange">How to Add a Title to Seaborn Plots (With Examples)</span></h2>
To add a title to a single seaborn plot, you can use the <b>.set()</b> function.
For example, here’s how to add a title to a boxplot:
<b>sns.boxplot(data=df, x='var1', y='var2').set(title='Title of Plot')
</b>
To add an overall title to a seaborn facet plot, you can use the <b>.suptitle()</b> function.
For example, here’s how to add an overall title to a relplot:
<b>#define relplot
rel = sns.relplot(data=df, x='var1', y='var2', col='var3')</b>
<b>
#add overall title to replot
rel.fig.suptitle('Overall Title')</b>
The following examples show how to use these functions in practice.
<h3>Example 1: Add a Title to a Single Seaborn Plot</h3>
The following code shows how to add a title to a seaborn boxplot:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create boxplot
sns.boxplot(data=df, x='team', y='points').set(title='Points by Team')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornTitle1.png">
And the following code shows how to add a title to a seaborn scatterplot:
<b>sns.scatterplot(data=df, x='points', y='assists').set(title='Points vs. Assists')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornTitle2.png">
And the following code shows how to add a title to a seaborn regplot:
<b>sns.regplot(data=df, x='points', y='assists').set(title='Points vs. Assists')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornTitle3.png">
<h3>Example 2: Add an Overall Title to a Seaborn Face Plot</h3>
The following code shows how to add a title to a seaborn facet plot:
<b>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#create fake data
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']})
#create relplot
rel = sns.relplot(data=df, x='points', y='assists', col='team')
#add overall title
rel.fig.suptitle('Stats by Team')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornTitle4.png">
We can also use the <b>subplots_adjust()</b> argument to move the overall title slightly higher so that it doesn’t get in the way of the individual plots:
<b>#create relplot
rel = sns.relplot(data=df, x='points', y='assists', col='team')
#move overall title up
rel.fig.subplots_adjust(top=.8)
#add overall title
rel.fig.suptitle('Stats by Team')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/seabornTitle5.png">
<h2><span class="orange">Pandas: Search for String in All Columns of DataFrame</span></h2>
You can use the following syntax to search for a particular string in each column of a pandas DataFrame and filter for rows that contain the string in at least one column:
<b>#define filter
mask = np.column_stack([df[col].str.contains(r"my_string", na=False) for col in df])
#filter for rows where any column contains 'my_string'
df.loc[mask.any(axis=1)]</b>
The following example shows how to use this syntax in practice.
<h2>Example: Search for String in All Columns of Pandas DataFrame</h2>
Suppose we have the following pandas DataFrame that contains information about the first role and second role of various basketball players on a team:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'player': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],   'first_role': ['P Guard', 'P Guard', 'S Guard', 'S Forward',                  'P Forward', 'Center', 'Center', 'Center'],   'second_role': ['S Guard', 'S Guard', 'Forward', 'S Guard',                   'S Guard', 'S Forward', 'P Forward', 'P Forward']})
#view DataFrame
print(df)
  player first_role second_role
0      A    P Guard     S Guard
1      B    P Guard     S Guard
2      C    S Guard     Forward
3      D  S Forward     S Guard
4      E  P Forward     S Guard
5      F     Center   S Forward
6      G     Center   P Forward
7      H     Center   P Forward</b>
The following code shows how to filter the pandas DataFrame for rows where the string “Guard” occurs in any column:
<b>import numpy as np
#define filter
mask = np.column_stack([df[col].str.contains(r"Guard", na=False) for col in df])
#filter for rows where any column contains 'Guard'
df.loc[mask.any(axis=1)]
        playerfirst_role  second_role
0AP Guard    S Guard
1BP Guard    S Guard
2CS Guard    Forward
3DS Forward   S Guard
4EP Forward   S Guard
</b>
Notice that each row in the resulting DataFrame contains the string “Guard” in at least one column.
You could also filter for rows where one of several strings occurs in at least one column by using the “OR” ( <b>|</b> ) operator in pandas.
For example, the following code shows how to filter for rows where either “P Guard” or “Center” occurs in at least one column:
<b>import numpy as np
#define filter
mask = np.column_stack([df[col].str.contains(r"P Guard|Center", na=False) for col in df])
#filter for rows where any column contains 'P Guard' or 'Center'
df.loc[mask.any(axis=1)]
        playerfirst_role  second_role
0AP Guard    S Guard
1BP Guard    S Guard
5FCenter    S Forward
6GCenter    P Forward
7HCenter    P Forward
</b>
Notice that each row in the resulting DataFrame contains “P Guard” or “Center” in at least one column.
<b>Note</b>: It’s important to include the argument <b>na=False</b> within the <b>contains()</b> function or else you will encounter  an error  if NaN values are present in the DataFrame.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common filtering operations in pandas:
 How to Filter a Pandas DataFrame by Column Values 
 How to Filter Pandas DataFrame Rows by Date 
 How to Filter a Pandas DataFrame on Multiple Conditions 
<h2><span class="orange">What is a Segmented Bar Chart? (Definition & Example)</span></h2>
A <b>segmented bar chart</b> is a type of chart that uses segmented bars that add up to 100% to help us visualize the distribution of categorical data.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented3.png">
The following step-by-step example shows how to create a segmented bar chart for a dataset.
<h3>Step 1: Collect the Data</h3>
Suppose we go out and ask 100 students at a certain college to tell us their favorite sport. The following table shows the results of the survey, based on gender and favorite sport:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented1.png">
<h3>Step 2: Convert the Data to Percentages</h3>
Next, let’s convert the raw frequencies into percentages.
For example, here’s how to convert the frequencies into percentages for the baseball category:
Number of respondents who were male: 13/36 = <b>36.1%</b>
Number of respondents who were female: 23/36 = <b>63.9%</b>
We can repeat the same process for basketball:
Number of respondents who were male: 15/31 = <b>48.4%</b>
Number of respondents who were female: 16/31 = <b>51.6%</b>
And we can repeat this process for football:
Number of respondents who were male: 20/33 = <b>60.6%</b>
Number of respondents who were female: 13/33 = <b>39.4%</b>
This leaves us with the following table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented2.png">
<h3>Step 3: Create the Segmented Bar Chart</h3>
Lastly, we can create the segmented bar chart by using three separate bars (one for each sport) and filling in the bars according to the percentage of respondents who were male or female:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented3.png">
This helps us quickly understand the breakdown of the percentage of students who prefer each sport, based on gender.
For example, we can see that out of the respondents who chose football as their favorite sport, about 60% of them were male.
Conversely, out of the respondents who chose baseball as their favorite sport, less than 40% of them were male.
<h3>Pros & Cons of Segmented Bar Charts</h3>
The biggest <b>pro</b> of a segmented bar chart is the fact that it lets us quickly understand the composition of categorical data.
For example, suppose we only had this table of data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented1.png">
It’s hard to tell right away what percentage of respondents chose each sport as their favorite, based on gender.
However, we can quickly understand the breakdown of respondents by gender with a segmented bar chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented3.png">
The biggest <b>con</b> of a segmented bar chart is that it doesn’t tell us the total frequency of respondents in each category.
For example, suppose 90 out of 100 students chose baseball as their favorite sport. Using a segmented bar chart, we wouldn’t have access to this information because each bar in the chart is forced to add up to 100%.
Keep this in mind when deciding whether or not to use a segmented bar chart to visualize your categorical data.
<h3>How to Make a Segmented Bar Chart in Excel</h3>
Suppose we have the following data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented4-1.png">
To create a segmented bar chart for this data, simply highlight the cells in the range <b>C7:E8</b> as follows:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented5.png">
Then click the <b>Insert</b> tab along the top ribbon. Within the <b>Charts</b> group, click <b>Insert Column or Bar</b> <b>Chart</b> and then click the option titled <b>100% Stacked Column</b>.
This will automatically produce the following segmented bar chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/segmented7.png">
Feel free to modify the colors, title, and axis labels to make the chart more aesthetically pleasing.
<h2><span class="orange">How to Select First N Rows of Data Frame in R (3 Examples)</span></h2>
You can use one of the following methods to select the first N rows of a data frame in R:
<b>Method 1: Use head() from Base R</b>
<b>head(df, 3)
</b>
<b>Method 2: Use indexing from Base R</b>
<b>df[1:3, ]
</b>
<b>Method 3: Use slice() from dplyr</b>
<b>library(dplyr)
df %>% slice(1:3)</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G'), points=c(99, 90, 86, 88, 95, 99, 91), assists=c(33, 28, 31, 39, 34, 35, 40))
#view data frame
df
  team points assists
1    A     99      33
2    B     90      28
3    C     86      31
4    D     88      39
5    E     95      34
6    F     99      35
7    G     91      40
</b>
<h2>Example 1: Use head() from Base R</h2>
One way to select the first N rows of a data frame is by using the <b>head()</b> function from base R:
<b>#select first 3 rows of data frame
head(df, 3)
  team points assists
1    A     99      33
2    B     90      28
3    C     86      31</b>
If you use the <b>head()</b> function without any numerical argument, R will automatically select the first 6 rows of the data frame:
<b>#select first 6 rows of data frame
head(df)
  team points assists
1    A     99      33
2    B     90      28
3    C     86      31
4    D     88      39
5    E     95      34
6    F     99      35
</b>
<h2>Example 2: Use indexing from Base R</h2>
Another way to select the first N rows of a data frame is by using indexing syntax from base R:
<b>#select first 3 rows of data frame
df[1:3, ]
  team points assists
1    A     99      33
2    B     90      28
3    C     86      31</b>
You can also use this syntax to only select the first N rows of a specific column:
<b>#select first 3 rows of 'team' and 'points' columns only
df[1:3, c('team', 'points')]
  team points
1    A     99
2    B     90
3    C     86</b>
<h2>Example 3: Use slice() from dplyr</h2>
Another way to select the first N rows of a data frame is by using the <b>slice()</b> function from the  dplyr  package:
<b>library(dplyr)
#select first 3 rows of data frame
df %>% slice(1:3)
  team points assists
1    A     99      33
2    B     90      28
3    C     86      31</b>
<b>Related:</b>  How to Use the slice() Function in dplyr (With Examples) 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Append Rows to a Data Frame in R 
 How to Remove Duplicate Rows in R 
 How to Sum Specific Rows in R 
<h2><span class="orange">How to Select the First Row by Group Using dplyr</span></h2>
Often you may want to select the first row in each group using the  dplyr  package in R. You can use the following basic syntax to do so:
<b>df %>%
  group_by(group_var) %>%
  arrange(values_var) %>%
  filter(row_number()==1)
</b>
The following example shows how to use this function in practice.
<h3>Example: Select the First Row by Group in R</h3>
Suppose we have the following dataset in R:
<b>#create dataset
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'), points=c(4, 9, 7, 7, 6, 13, 8, 8, 4, 17))
#view dataset
df
   team points
1     A      4
2     A      9
3     A      7
4     B      7
5     B      6
6     B     13
7     C      8
8     C      8
9     C      4
10    C     17
</b>
The following code shows how to use the dplyr package to select the first row by group in R:
<b>library(dplyr)
df %>%
  group_by(team) %>%
  arrange(points) %>%
  filter(row_number()==1)
# A tibble: 3 x 2
# Groups:   team [3]
  team  points
    
1 A          4
2 C          4
3 B          6
</b>
By default, <b>arrange()</b> sorts the values in ascending order but we can easily sort the values in descending order instead:
<b>df %>%
  group_by(team) %>%
  arrange(desc(points)) %>%
  filter(row_number()==1)
# A tibble: 3 x 2
# Groups:   team [3]
  team  points
    
1 C         17
2 B         13
3 A          9</b>
Note that you can easily modify this code to select the n<sup>th</sup> row by each group. Simply change <b>row_number() == n</b>.
For example, if you’d like to select the 2nd row by group, you can use the following syntax:
<b>df %>%
  group_by(team) %>%
  arrange(desc(points)) %>%
  filter(row_number()==2)
</b>
Or you could use the following syntax to select the last row by group:
<b>df %>%
  group_by(team) %>%
  arrange(desc(points)) %>%
  filter(row_number()==n())</b>
<h2><span class="orange">How to Use SELECT-WHEN in SAS (With Example)</span></h2>
You can use a <b>SELECT-WHEN</b> statement in SAS to assign values to a new variable based on the values of an existing categorical variable in a dataset.
This statement uses the following basic syntax:
<b>data new_data;
set my_data;
select (Existing_Column);
   when ('value1')    New_Column=1;
   when ('value2')    New_Column=2;
   when ('value3')    New_Column=3;
   otherwise          New_Column=4;
end;
run;
</b>
This syntax produces a new column called <b>New_Column</b> whose values are dependent on the values in <b>Existing_Column</b>.
The following example shows how to use a <b>SELECT-WHEN</b> statement in practice.
<h3>Example: <b>SELECT-WHEN in SAS</b></h3>
Suppose we have the following dataset in SAS that contains information about various basketball players:
<b>/*create dataset*/
data my_data;
    input team $ rating $ points;
    datalines;
Mavs Great 22
Mavs Good 29
Mavs OK 15
Mavs Bad 8
Spurs Good 30
Spurs OK 15
Spurs OK 20
Spurs Bad 7
;
run;
/*view dataset*/
proc print data=my_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/selectwhen1.jpg"226">
We can use the following <b>SELECT-WHEN</b> statement to create a new variable called <b>Player_Status</b> whose values depend on the value in the <b>rating</b> column:
<b>/*create new dataset with Player_Status column*/
data new_data;
set my_data;
select (rating);
   when ('Great')    Player_Status=1;
   when ('Good')     Player_Status=2;
   when ('OK')       Player_Status=3;
   otherwise         Player_Status=4;
end;
run;
/*view new dataset*/
proc print data=new_data;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/selectwhen2.jpg"326">
Here is how the values were generated in the new <b>Player_Status</b> column:
If <b>rating</b> was equal to “Great” then <b>Player_Status</b> was assigned <b>1</b>.
If <b>rating</b> was equal to “Good” then <b>Player_Status</b> was assigned <b>2</b>.
If <b>rating</b> was equal to “OK” then <b>Player_Status</b> was assigned <b>3</b>.
If <b>rating</b> was not equal to any of the previously specified values then <b>Player_Status</b> was assigned <b>4</b>.
<b>Note</b>: You can find the complete documentation for the <b>SELECT</b> statement in SAS  here .
<h2><span class="orange">Self-Selection Bias: Definition & Examples</span></h2>
<b>Self-selection bias</b> occurs when individuals select themselves to be included in a survey.
For example, suppose a local government mails out a survey to all of its residents asking them whether or not they think a new intersection should be placed in the middle of the town.
Residents who drive through that particular part of town often and residents who have to deal with daily traffic are more likely to hold a strong opinion about a new intersection and are far more likely to actually respond to the survey.
On the other hand, residents who work from home or simply have no interest in the happenings around the town are unlikely to take the time to respond to the survey.
Thus, the percentage of individuals in the survey who are in favor of the new intersection is unlikely to match the percentage of all residents in the town who are in favor of the new intersection.
<b>Self-Selection Bias:</b> When individuals select themselves to be included in a survey.
 
This results in a sample of individuals that is not representative of the overall population.
 
This makes it difficult to generalize the findings from the sample to the  population .
In other words, there is <b>bias</b> in our sample data. This makes it difficult to generalize the findings from the sample data to the overall population of interest.
<h3>Examples of Self-Selection Bias</h3>
The following examples illustrate a few scenarios where self-selection bias is likely to occur.
<b>Example 1: Test Prep</b>
Suppose a teacher wants to know if a new test prep course helps students improve test scores. She posts a sign-up sheet outside of her classroom and lets students decide if they’d like to participate in the course.
Self-selection bias is likely to occur because students who are more studious are more likely to sign up which means the sample of students who take the course aren’t likely to match the overall population of students who could potentially take the course.
<b>Example 2: Multiple Languages</b>
Suppose a local government mails out a survey asking its residents if they should include other languages besides English on street signs to make it easier for people who speak other languages to navigate around town.
Self-selection bias is likely to occur because only residents who can actually read English will respond to the survey. This means the opinions of survey respondents are unlikely to match the opinions of all residents in the town.
<b>Example 3: Biology Research</b>
Suppose a biologist is trying to estimate the average height of a certain species of deer so she places a certain deer feed in an open meadow and takes pictures of the deer that enter the meadow to eat the food.
In this example, self-selection bias is likely to occur because only the deer who like that type of deer feed or who are more comfortable with being out in the open are likely to enter the meadow and thus be included in the sample data.
Thus, it’s unlikely that the average height of deer in this sample will match the average height of deer in the overall population. 
<h3>Why Self-Selection Bias is a Problem</h3>
Self-selection bias is a problem because it causes the individuals in the sample to not be  representative  of the population.
Recall that the purpose of collecting sample data is to use it to draw conclusions about some population of interest. However, we can only draw valid conclusions if we use a representative sample.
<b>Representative sample:</b> A sample in which the characteristics of the individuals closely match the characteristics of the overall population.
Ideally we would like the sample to be like a “mini version” of the population. This allows us to be confident about using the sample to draw conclusions about the population.
<h3>How to Reduce Self-Selection Bias</h3>
The obvious way to reduce self-selection bias is to not give individuals the ability to select themselves to be included in a survey.
Ideally, a  probability sampling method  should be used to obtain a sample.
<b>Probability sampling method:</b> A sampling method in which each member in a population has an equal probability of being selected to be in the sample.
Examples of probability sampling methods include:
<b>1. Simple random sample:</b> Randomly select individuals through the use of a random number generator or some means of random selection.
<b>2. Systematic random sample: </b>Put every member of a population into some order. Choose a random starting point and select every n<sup>th</sup> member to be in the sample.
<b>3. Stratified random sample:</b> Split a population into groups. Randomly select some members from each group to be in the sample.
<b>4. Cluster random sample:</b> Split a population into clusters. Randomly select some clusters and use each individual in the chosen clusters to be in the sample.
Each of these methods is likely to produce samples that are representative of the population we’re interested in, which allows us to generalize the findings from the sample data to the population.
<h2><span class="orange">Semi-Interquartile Range Calculator</span></h2>
The <b>semi-interquartile range</b> is a way to measure the spread of observations in a dataset. It is calculated as one half the distance between the first quartile (Q1) and the third quartile (Q3):
Semi-interquartile range = (Q3 – Q1) / 2
This calculator finds the semi-interquartile range for a given dataset.
Simply enter the list of the comma-separated values for the dataset, then click the “Calculate” button:
<b>Dataset values:</b>
<textarea id="x" rows="5" cols="40">45, 47, 52, 52, 53, 55, 56, 58, 62, 80</textarea>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>Q1: 52.0000</b>
<b>Q3: 57.5000</b>
<b>Semi-interquartile range: 2.7500</b>
<script>
function calc() {
var x = document.getElementById('x').value.split(',').map(Number);
var Q1 = jStat.percentile(x, 0.25);
var Q3 = jStat.percentile(x, 0.75);
var SIQR = (Q3-Q1)/2;
document.getElementById('Q1').innerHTML = Q1.toFixed(4);
document.getElementById('Q3').innerHTML = Q3.toFixed(4);
document.getElementById('SIQR').innerHTML = SIQR.toFixed(4);
  
} //end calc function
</script>
<h2><span class="orange">How to Create a Semi-Log Graph in Excel</span></h2>
A <b>semi-log graph</b> is a type of graph that uses a logarithmic scale on the y-axis and a linear scale on the x-axis.
This type of graph is often used when the values for the y variable have much greater variability compared to the values for the x variable.
This occurs often in datasets in finance, economics, biology, and astronomy among other fields.
The following step-by-step example shows how to create a semi-log graph in Excel for a given dataset.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the values for a fake dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel1.png">
<h3>Step 2: Create a Scatterplot</h3>
Next, highlight the data values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel2.png">
Along the top ribbon, click <b>Insert</b>. Then click the first option under the <b>Scatter</b> graph option:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scatterExcel.png">
The following scatterplot will automatically be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel3.png">
From the plot we can see that the values for the y variable have much higher variability than the values for the x variable.
This means it’s a good idea to convert the y-axis into a logarithmic scale to visualize the y-values more effectively.
<h3>Step 3: Modify the Y-Axis Scale</h3>
Next, right click the y-axis. In the dropdown menu that appears, click <b>Format Axis</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel4.png">
In the window that appears on the right side of the screen, check the box next to <b>Logarithmic scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel5.png">
The y-axis will automatically be converted to a logarithmic scale:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/semilogExcel6.png">
The x-axis remains on a linear scale, but the y-axis has been converted into a logarithmic scale.
Notice how much easier it is to interpret the y values in this graph compared to the previous graph.
<h2><span class="orange">How to Use Separate Function in R (With Examples)</span></h2>
The <b>separate()</b> function from the  tidyr  package can be used to separate a data frame column into multiple columns.
This function uses the following basic syntax:
<b>separate(data, col, into, sep)</b>
where:
<b>data</b>: Name of the data frame
<b>col</b>: Name of the column to separate
<b>into</b>: Vector of names for the column to be separated into
<b>sep</b>: The value to separate the column at
The following examples show how to use this function in practice.
<h3>Example 1: Separate Column into Two Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'A', 'B', 'B', 'C', 'C'), year=c(1, 2, 1, 2, 1, 2), stats=c('22-2', '29-3', '18-6', '11-8', '12-5', '19-2'))
#view data frame
df
  player year stats
1      A    1  22-2
2      A    2  29-3
3      B    1  18-6
4      B    2  11-8
5      C    1  12-5
6      C    2  19-2
</b>
We can use the <b>separate()</b> function to separate the stats column into two new columns called “points” and “assists” as follows:
<b>library(tidyr)
#separate stats column into points and assists columns
separate(df, col=stats, into=c('points', 'assists'), sep='-')
  player year points assists
1      A    1     22       2
2      A    2     29       3
3      B    1     18       6
4      B    2     11       8
5      C    1     12       5
6      C    2     19       2</b>
<h3>Example 2: Separate Column into More Than Two Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df2 &lt;- data.frame(player=c('A', 'A', 'B', 'B', 'C', 'C'), year=c(1, 2, 1, 2, 1, 2), stats=c('22/2/3', '29/3/4', '18/6/7', '11/1/2', '12/1/1', '19/2/4'))
#view data frame
df2
  player year   stats
1      A    1  22/2/3
2      A    2  29/3/4
3      B    1  18/6/7
4      B    2  11/1/2
5      C    1  12/1/1
6      C    2  19/2/4</b>
We can use the <b>separate()</b> function to separate the stats column into three separate columns:
<b>library(tidyr)
#separate stats column into three new columns
separate(df, col=stats, into=c('points', 'assists', 'steals'), sep='/')
  player year points assists steals
1      A    1     22       2      3
2      A    2     29       3      4
3      B    1     18       6      7
4      B    2     11       1      2
5      C    1     12       1      1
6      C    2     19       2      4</b>
Every column is a variable.
Every row is an observation.
Every cell is a single value.
The tidyr package uses four core functions to create tidy data:
<b>1.</b> The  <b>spread()</b>  function.
<b>2.</b> The  <b>gather()</b>  function.
<b>3.</b> The <b>separate()</b> function.
4. The  <b>unite()</b>  function.
If you can master these four functions, you will be able to create “tidy” data from any data frame.
<h2><span class="orange">How to Use seq Function in R (With Examples)</span></h2>
The <b>seq()</b> function in R can be used to generate a sequence of numbers.
This function uses the following basic syntax:
<b>seq(from=1, to=1, by=1, length.out=NULL, along.with=NULL)</b>
where:
<b>from</b>: The starting value of the sequence.
<b>to</b>: The end value of the sequence.
<b>by</b>: The value to increment by. Default is 1.
<b>length.out</b>: The desired length of the sequence.
<b>along.with:</b> The desired length that matches the length of this data object.
The following examples show how to use this function to generate sequences of numbers in practice.
<h3>Example 1: Generate Sequence Starting from One</h3>
The following code shows how to generate a sequence of values from 1 to 20:
<b>#define sequence
x &lt;- seq(20)
#view sequence
x
[1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
</b>
<h3>Example 2: Generate Sequence with Specific Start and End Values</h3>
The following code shows how to generate a sequence of values from 5 to 15:
<b>#define sequence
x &lt;- seq(from=5, to=15)
#view sequence
x
[1]  5  6  7  8  9 10 11 12 13 14 15
</b>
<h3>Example 3: Generate Sequence with Custom Incrementing</h3>
The following code shows how to generate a sequence of values from 0 to 20, incrementing by <b>4</b>:
<b>#define sequence
x &lt;- seq(from=0, to=20, by=4)
#view sequence
x
[1]  0  4  8 12 16 20
</b>
<h3>Example 4: Generate Sequence with Specific Length</h3>
The following code shows how to generate a sequence of values from 0 to 20, where the specified length of the sequence is <b>4</b>:
<b>#define sequence
x &lt;- seq(from=0, to=20, length.out=4)
#view sequence
x
[1]  0.000000  6.666667 13.333333 20.000000
</b>
<h3>Example 5: Generate Sequence with Length Based on Some Data Object</h3>
The following code shows how to generate a sequence of values from 0 to 20, where the specified length of the sequence should match the length of another data object:
<b>#define vector <em>y</em>
y &lt;- c(1, 4, 6, 9)
 
#define sequence <em>x</em>, make sure length matches the length of <em>y</em>
x &lt;- seq(from=0, to=20, along.with=y)
#view sequence
x
[1]  0.000000  6.666667 13.333333 20.000000</b>
Notice that sequence <em>x</em> goes from 0 to 20 and its length (4) matches the length of vector <em>y</em>.
<h2><span class="orange">Sequence Effects: Definition & Example</span></h2>
A <b>sequence effect</b> occurs when the sequence of experimental treatments given to participants in a research study interact with each other.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sequence_effect1.png">
This tutorial provides several examples of sequence effects along with methods that can be used to minimize sequence effects.
<h3>Examples of Sequence Effects</h3>
The following examples illustrate scenarios where sequence effects could occur:
<b>1. Quiz Difficulty</b>
Suppose researchers ask participants to take five different math quizzes and assess how difficult they thought the quiz was along with how well they believe they performed at the end of each quiz.
In this study, the difficulty of the previous quiz is likely to affect how the participants rate the difficulty of the current quiz.
For example, if a participant takes an extremely difficult quiz for quiz #1, then a moderately difficult quiz for quiz #2, they may rate quiz #2 as “easy” simply because it was much easier relative to the extremely difficult quiz they just took.
In a similar manner, the difficulty of each previous quiz is likely to affect how a participant rates the difficulty of a quiz they most recently took.
<b>2. Assessing Weight</b>
Suppose researchers ask participants to assess the weight of three different dumbbells, one after the other.
In this study, the weight of the previous dumbbell is likely to affect how heavy the participant thinks the current dumbbell is.
For example, if a participant picks up a 20-pound dumbbell and then a 10-pound dumbbell, they might incorrectly think the 10-pound dumbbell is much lighter than it actually is simply because they’re comparing it to the 20-pound dumbbell they just picked up.
<b>3. Assessing Speed</b>
Suppose researchers ask participants to assess the speed of four different sprinters, one after the other.
In this study, the speed of the previous sprinter is likely to affect how fast the participant thinks the current sprinter is.
For example, if a participant watches the fastest sprinter in North America run and then watches a normal person run, they might think the normal person is much slower than they actually are because they’re comparing them to the previous fast sprinter.
<h3>How to Minimize Sequence Effects</h3>
There are two common ways that researchers minimize sequence effects:
<b>1. Increase time between experimental treatments.</b>
Researchers can simply increase the time between the experimental treatments given to the patients. 
For example, instead of making participants assess the weight of dumbbells one after the other, researchers could provide 10 minutes in between each assessment so the participant has time to forget the heaviness of the previous dumbbell.
By spacing out the time between experimental treatments, participants are more likely to provide responses that aren’t affected so much by previous treatments.
<b>2. Use counterbalancing.</b>
Counterbalancing is when researchers assign experimental treatments in different orders to different participants.
For example, researchers might have five participants assess the weight of three dumbbells in the order of 123, another five participants use the order of 213, another five participants use the order of 312, and so on.
By using each order the same number of times, we can “counterbalance” any order effects. 
<h3>Sequence Effects vs. Order Effects</h3>
A term that is similar to a sequence effect is known as an <b>order effect</b>. Here’s the difference between the two terms:
<b>1. Order Effect: </b>When the order of experimental treatments causes a participant to systematically get better or worse at some task.
For example, participants may get better at some task simply from practice in previous treatments. Conversely, they may get worse at some task by becoming tired or fatigue from participating in previous treatments.
<b>2. Sequence Effect: </b>When the order of experimental treatments interact with each other in some way. 
For example, the treatment that a participant was previously exposed to may affect their performance during a current treatment.
In most cases, this doesn’t cause a participant to systematically get better or worse at some task over time; rather, it causes the participant to be less accurate in some way during their current task.
<h2><span class="orange">How to Set Axis Limits in ggplot2</span></h2>
Often you may want to set the axis limits on a plot using  ggplot2 . You can easily do this using the following functions:
<b>xlim()</b>: specifies the lower and upper limit of the x-axis.
<b>ylim(): </b>specifies the lower and upper limit of the y-axis.
Note that both of these methods will remove data outside of the limits, which can sometimes produce unintended consequences. To change the axis limits without dropping data observations, you can instead use coord_cartesian():
<b>coord_cartesian():</b> specifies the limits for the x-axis and y-axis without dropping observations.
This tutorial explains several ways to use these functions using the following scatterplot made with the built-in R dataset <em>mtcars</em>:
<b>#load ggplot2
library(ggplot2)
#create scatterplot
ggplot(mtcars, aes(mpg, wt)) +
  geom_point()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot1.png">
<h3>Example 1: Set X-Axis Limits Using xlim()</h3>
The following code shows how to set the x-axis limits of the scatterplot using the <b>xlim()</b> function:
<b>#create scatterplot with x-axis ranging from 15 to 30
ggplot(mtcars, aes(mpg, wt)) +
  geom_point() +
  xlim(15, 30)
<em>Warning message:
“Removed 9 rows containing missing values (geom_point).”
</em></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot2.png">
You can also use <b>NA </b>to only set the upper limit of the x-axis and let ggplot2 automatically choose the lower limit:
<b>#create scatterplot with x-axis upper limit at 30
ggplot(mtcars, aes(mpg, wt)) +
  geom_point() +
  xlim(NA, 30)
<em>Warning message:
“Removed 4 rows containing missing values (geom_point).”</em></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot3.png">
<h3>Example 2: Set Y-Axis Limits Using ylim()</h3>
The following code shows how to set the y-axis limits of the scatterplot using the <b>ylim()</b> function:
<b>#create scatterplot with y-axis ranging from 2 to 4
ggplot(mtcars, aes(mpg, wt)) +
  geom_point() +
  ylim(2, 4)
<em>Warning message:
“Removed 8 rows containing missing values (geom_point).”</em></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot4.png">
You can also use <b>NA </b>to only set the lower limit of the y-axis and let ggplot2 automatically choose the upper limit:
<b>#create scatterplot with y-axis lower limit at 2
ggplot(mtcars, aes(mpg, wt)) +
  geom_point() +
  xlim(2, NA)
<em>Warning message:
“Removed 4 rows containing missing values (geom_point).”</em></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot5.png">
<h3>Example 3: Set Axis Limits Using coord_cartesian()</h3>
The following code shows how to set the y-axis limits of the scatterplot using the <b>coord_cartesian()</b> function:
<b>#create scatterplot with y-axis ranging from 2 to 4
ggplot(mtcars, aes(mpg, wt)) +
  geom_point() +
  coord_cartesian(xlim =c(15, 25), ylim = c(3, 4))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/axislimitsggplot6.png">
<em>You can find more ggplot2 tutorials  here .</em>
<h2><span class="orange">Set Operations: Union, Intersection, Complement, and Difference</span></h2>
A <b>set </b>is a collection of items.
We denote a set using a capital letter and we define the items within the set using curly brackets. For example, suppose we have some set called “A” with elements 1, 2, 3. We would write this as:
<b>A = {1, 2, 3}</b>
This tutorial explains the most common <b>set operations </b>used in probability and statistics.
<h3>Union</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops1.png">
<b>Definition: </b>The <em>union </em>of sets A and B is the set of items that are in either A or B.
<b>Notation: </b>A ∪ B
<b>Examples:</b>
{1, 2, 3} ∪ {4, 5, 6} = {1, 2, 3, 4, 5, 6}
{1, 2} ∪ {1, 2} = {1, 2}
{1, 2, 3} ∪ {3, 4} = {1, 2, 3, 4}
<h3>Intersection</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops2.png">
<b>Definition: </b>The <em>intersection </em>of sets A and B is the set of items that are in both A and B.
<b>Notation: </b>A ∩ B
<b>Examples:</b>
{1, 2, 3} ∩ {4, 5, 6} = {<U+2205>}
{1, 2} ∩ {1, 2} = {1, 2}
{1, 2, 3} ∩ {3, 4} = {3}
<h3>Complement</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops4.png">
<b>Definition: </b>The <em>complement </em>of set A is the set of items that are in the universal set U but are not in A.
<b>Notation: </b>A’  or  A<sup>c</sup>
<b>Examples:</b>
If U = {1, 2, 3, 4, 5, 6} and A = {1, 2}, then A<sup>c</sup> = {3, 4, 5, 6}
If U = {1, 2, 3} and A = {1, 2}, then A<sup>c</sup> = {3}
<h3>Difference</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops3.png">
<b>Definition: </b>The <em>difference </em>of sets A and B is the set of items that are in A but not B.
<b>Notation: </b>A – B
<b>Examples:</b>
{1, 2, 3} – {2, 3, 4} = {1}
{1, 2} – {1, 2} = {<U+2205>}
{1, 2, 3} – {4, 5} = {1, 2, 3}
<h3>Symmetric Difference</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops5.png">
<b>Definition: </b>The <em>symmetric difference </em>of sets A and B is the set of items that are in either A or B, but not in both.
<b>Notation: </b>A Δ B
<b>Examples:</b>
{1, 2, 3} Δ {2, 3, 4} = {1, 4}
{1, 2} Δ {1, 2} = {<U+2205>}
{1, 2, 3} Δ {4, 5} = {1, 2, 3, 4, 5}
<h3>Cartesian Product</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/setops6.png">
<b>Definition: </b>The <em>cartesian product </em>of sets A and B is the set of ordered pairs from A and B.
<b>Notation: </b>A x B
<b>Examples:</b>
If A = {H, T} and B = {1, 2, 3}, then A x B = {(H, 1), (H, 2), (H, 3), (T, 1), (T, 2), (T, 3)}
If A = {T, H} and B = {1, 2, 3}, then A x B = {(T, 1), (T, 2), (T, 3), (H, 1), (H, 2), (H, 3)}
<h2><span class="orange">How (And When) to Use set.seed in R</span></h2>
The <b>set.seed()</b> function in R is used to create reproducible results when writing code that involves creating variables that take on random values.
By using the <b>set.seed()</b> function, you guarantee that the same random values are produced each time you run the code.
This function uses the following basic syntax:
<b>set.seed(seed)</b>
where:
<b>seed</b>: Any number you would like.
The following examples show how to use this function in practice.
<h2>Example 1: Generate Random Values Without Using set.seed()</h2>
Suppose we use the <b>rnorm()</b> function to create a data frame with three variables that take on random values that follow a standard normal distribution:
<b>#create data frame
df &lt;- data.frame(var1 = rnorm(10), var2 = rnorm(10), var3 = rnorm(10))
#view data frame
df
          var1        var2        var3
1   0.13076685 -0.32183484  0.08083558
2   0.93926332  0.92271464  1.14695121
3   1.97227368  0.01140237  0.29325751
4   1.99656555  0.26735086  1.17131155
5  -1.07893403 -0.12748185 -0.75510058
6  -0.58955485 -0.29720114  0.57928670
7   1.39367811 -1.43043111 -0.39395086
8  -0.09977302 -1.93133994 -0.66654713
9  -0.71876371  2.27999183  0.45990405
10  0.90421007  2.28077581  0.57545709</b>
If we attempt to create the same data frame again using <b>rnorm()</b>, there is no guarantee that the values will be the same since we didn’t use the<b> set.seed()</b> function:
<b>#create data frame
df &lt;- data.frame(var1 = rnorm(10), var2 = rnorm(10), var3 = rnorm(10))
#view data frame
df
         var1        var2       var3
1   0.1841698  1.18134622 -0.9410759
2  -1.3535924 -0.73136515 -0.2802438
3   1.0323083  0.06530416 -1.3447057
4  -0.6540649 -0.45005680  1.1222456
5   0.5201189 -0.03688566 -0.6317776
6   0.6119033 -0.13083390  0.7034120
7  -0.1781823  0.56807218  0.2138826
8  -0.1325103  1.10700318 -0.6799447
9  -0.6185180  0.12327017 -0.2411492
10 -0.2699959 -0.04093012  0.5289240
</b>
Notice that the values in each column of the data frame are completely different.
<h2>Example 2: Generate Random Values Using set.seed()</h2>
The following code shows how to use the <b>set.seed()</b> function before using the <b>rnorm()</b> function to create a data frame with three variables that take on random values:
<b>#make this example reproducible
set.seed(7)
#create data frame
df &lt;- data.frame(var1 = rnorm(10), var2 = rnorm(10), var3 = rnorm(10))
#view data frame
df
         var1         var2       var3
1   2.2872472  0.356986230  0.8397504
2  -1.1967717  2.716751783  0.7053418
3  -0.6942925  2.281451926  1.3059647
4  -0.4122930  0.324020540 -1.3879962
5  -0.9706733  1.896067067  1.2729169
6  -0.9472799  0.467680511  0.1841928
7   0.7481393 -0.893800723  0.7522799
8  -0.1169552 -0.307328300  0.5917451
9   0.1526576 -0.004822422 -0.9830526
10  2.1899781  0.988164149 -0.2760640
</b>
If we use <b>set.seed()</b> with the same seed value as before and create the data frame once again, it’s guaranteed to have the same values as the previous data frame:
<b>#make this example reproducible
set.seed(7)
#create data frame
df2 &lt;- data.frame(var1 = rnorm(10),  var2 = rnorm(10),  var3 = rnorm(10))
#view data frame
df2
         var1         var2       var3
1   2.2872472  0.356986230  0.8397504
2  -1.1967717  2.716751783  0.7053418
3  -0.6942925  2.281451926  1.3059647
4  -0.4122930  0.324020540 -1.3879962
5  -0.9706733  1.896067067  1.2729169
6  -0.9472799  0.467680511  0.1841928
7   0.7481393 -0.893800723  0.7522799
8  -0.1169552 -0.307328300  0.5917451
9   0.1526576 -0.004822422 -0.9830526
10  2.1899781  0.988164149 -0.2760640</b>
Notice that the values in this data frame match the ones in the previous data frame.
<b>Note</b>: In this example, we chose to use <b>7</b> as our seed value but you can choose whatever number you’d like such as 0, 54, 99, 100, 48787, etc.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Use the dim() Function in R 
 How to Use the table() Function in R 
 How to Use sign() Function in R 
<h2><span class="orange">How to Set X-Axis Values in Matplotlib</span></h2>
You can use the following syntax to set the x-axis values for a plot in Matplotlib:
<b>#specify x-axis locations
x_ticks = [2, 4, 6, 8, 10]
#specify x-axis labels
x_labels = ['A', 'B', 'C', 'D', 'E'] 
#add x-axis values to plot
plt.xticks(ticks=x_ticks, labels=x_labels)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Set X-Axis Values at Equal Intervals</h3>
The following code shows how to set the x-axis values at equal intervals in Matplotlib:
<b>import matplotlib.pyplot as plt
#define x and y
x = [1, 4, 10]
y = [5, 11, 27]
#create plot of x and y
plt.plot(x, y)
#specify x-axis locations
x_ticks = [2, 4, 6, 8, 10]
#specify x-axis labels
x_labels = ['A', 'B', 'C', 'D', 'E'] 
#add x-axis values to plot
plt.xticks(ticks=x_ticks, labels=x_labels)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/axis1.png">
Notice that each x-axis value appears at equally spaced intervals.
<h3>Example 2: Set X-Axis Values at Unequal Intervals</h3>
The following code shows how to set the x-axis values at unequal intervals in Matplotlib:
<b>import matplotlib.pyplot as plt
#define x and y
x = [1, 4, 10]
y = [5, 11, 27]
#create plot of x and y
plt.plot(x, y)
#specify x-axis locations
x_ticks = [1, 2, 6, 10]
#specify x-axis labels
x_labels = [1, 2, 6, 10] 
#add x-axis values to plot
plt.xticks(ticks=x_ticks, labels=x_labels)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/axis3.png">
<h3>Example 3: Set X-Axis Values at Data Points Only</h3>
The following code shows how to set the x-axis values at the data points only:
<b>import matplotlib.pyplot as plt
#define x and y
x = [1, 4, 10]
y = [5, 11, 27]
#create plot of x and y
plt.plot(x, y)
#specify x-axis labels
x_labels = ['A', 'B', 'C'] 
#add x-axis values to plot
plt.xticks(ticks=x, labels=x_labels)</b>
<h3><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/axis2.png"></h3>
<b>Note:</b> You can find the complete documentation for the <b>plt.xticks()</b> function  here .
<h2><span class="orange">How to Use the setdiff Function in R (With Examples)</span></h2>
The <b>setdiff()</b> function in R can be used to find differences between two sets. This function uses the following syntax:
<b>setdiff(x, y)</b>
where:
<b>x, y:</b> Vectors or data frames containing a sequence of items
This tutorial provides several examples of how to use this function in practice.
<h3>Example 1: Setdiff with Numeric Vectors</h3>
The following code shows how to use <b>setdiff()</b> to identify all of the values in vector <em>a</em> that do not occur in vector <em>b</em>:
<b>#define vectors
a &lt;- c(1, 3, 4, 5, 9, 10)
b &lt;- c(1, 2, 3, 4, 5, 6)
#find all values in <em>a</em> that do not occur in <em>b</em>
setdiff(a, b)
[1]  9 10</b>
There are two values that occur in vector <em>a</em> that do not occur in vector <em>b</em>: <b>9</b> and <b>10</b>.
If we reverse the order of the vectors in the <b>setdiff()</b> function, we can instead identify all of the values in vector <em>b</em> that do not occur in vector <em>a</em>:
<b>#find all values in <em>b</em> that do not occur in <em>a</em>
setdiff(b, a)
[1] 2 6</b>
There are two values that occur in vector <em>b</em> that do not occur in vector <em>a</em>: <b>2</b> and <b>6</b>.
<h3>Example 2: Setdiff with Character Vectors</h3>
The following code shows how to use <b>setdiff()</b> to identify all of the values in vector <em>char1</em> that do not occur in vector <em>char2</em>:
<b>#define character vectors
char1 &lt;- c('A', 'B', 'C', 'D', 'E')
char2 &lt;- c('A', 'B', 'E', 'F', 'G')
#find all values in <em>char1</em> that do not occur in <em>char2</em>
setdiff(char1, char2)
[1] "C" "D"
</b>
<h3>Example 3: Setdiff with Data Frames</h3>
The following code shows how to use <b>setdiff()</b> to identify all of the values in one data frame column that do not appear in the same column of a second data frame:
<b>#define data frames
df1 &lt;- data.frame(team=c('A', 'B', 'C', 'D'), conference=c('West', 'West', 'East', 'East'), points=c(88, 97, 94, 104))
df2 &lt;- data.frame(team=c('A', 'B', 'C', 'D'), conference=c('West', 'West', 'East', 'East'), points=c(88, 97, 98, 99))
#find differences between the points columns in the two data frames
setdiff(df1$points, df2$points)
[1]  94 104
</b>
We can see that the values <b>94</b> and <b>104</b> occur in the points column of the first data frame, but not in the points column of the second data frame.
<h2><span class="orange">How to Use setNames Function in R (With Examples)</span></h2>
You can use the <b>setNames </b>function in R to set the names of an object and return the object.
This function uses the following basic syntax:
<b>setNames(object, nm)
</b>
where:
<b>names</b>: The name of the object
<b>nm</b>: A character vector of names
The following examples show how to use this function in different scenarios.
<h3>Example 1: Use setNames with Vector</h3>
Suppose we create the following vector in R with names:
<b>#create vector
data &lt;- c(1, 3, 4, 4)
#create names for vector
names(data) &lt;- c('points', 'rebounds', 'blocks', 'steals')
#view vector
data
  points rebounds   blocks   steals 
       1        3        4        4</b>
We can create this exact same vector with names by just using the <b>setNames()</b> function:
<b>#create vector with names
data &lt;- setNames(c(1, 3, 4, 4), c('points', 'rebounds', 'blocks', 'steals'))
#view vector
data
  points rebounds   blocks   steals 
       1        3        4        4
</b>
By using just one line, we’re able to create the exact same vector with names.
<h3>
<b>Example 2: Use setNames with List</b>
</h3>
The following code shows how to use the <b>setNames</b> function to create a list with specific names in R and return the list:
<b>#create list with names and return list
setNames(list(c(1, 2), 3:6, c('A', 'B')), c('points', 'steals', 'team'))
$points
[1] 1 2
$steals
[1] 3 4 5 6
$team
[1] "A" "B"
</b>
Notice that a list is returned with the names that we specified using the <b>setNames</b> function.
Also note that you can type the following into R to read the complete documentation for the <b>setNames</b> function:
<b>?setNames</b>
<h2><span class="orange">How to Use setwd / getwd in R (With Examples)</span></h2>
Whenever you use R, your environment is always pointed to some working directory.
You can use the following functions in R to get the working directory and set the working directory:
<b>getwd()</b> – Get the current working directory
<b>setwd(‘Path/To/Some/Directory’)</b> – Set current working directory
The following examples show how to use these functions in practice.
<h3>Example 1: Get Working Directory</h3>
We can use the <b>getwd()</b> function to display the current working directory in R:
<b>#display current working directory
getwd()
[1] "C:/Users/Bob/Desktop"
</b>
<h3>Example 2: Set Working Directory</h3>
We can then use the <b>setwd()</b> function to set the working directory to some new location:
<b>#set working directory
setwd('C:/Users/Bob/Documents')
</b>
We can then verify that the working directory has changed by using the <b>getwd()</b> function again to get the current working directory:
<b>#display current working directory
getwd()
"C:/Users/Bob/Documents"
</b>
<h3>Example 3: View Files in Working Directory</h3>
Once we’ve set the working directory, we can use the <b>list.files()</b> function to view the file names within the directory:
<b>#view number of files in working directory
length(list.files())
[1] 147
#view first five file names in working directory
head(list.files())
"output.yml"  "analysis3.R"  "analysis3-1.R"  "testdoc.R"  "final_model2.Rmd" 
</b>
We can also use the <b>%in%</b> operator to check if a specific file is located in our current working directory:
<b>#check if file 'analysis3.R' exists in working directory
'analysis3.R' %in% list.files()
[1] TRUE
</b>
An output value of <b>TRUE</b> indicates that the specific file is indeed located in the current working directory.
<h2><span class="orange">Shannon Diversity Index Calculator</span></h2>
</style>
The <b> Shannon Diversity Index </b> is a way to measure the diversity of species in a community.
To calculate this index for a given community, simply enter a list of observed frequencies for up to 10 species in the boxes below, then click the “Calculate” button:
<table><tbody>
<tr>
<th><b>Species</b></th>
<th><b><span>Frequency</b></th>
</tr>
<tr>
<td>Species #1</td>
<td><input type="text" id="o1" value="80"></td>
</tr>
<tr>
<td>Species #2</td>
<td><input type="text" id="o2" value="125"></td>
</tr>
<tr>
<td>Species #3</td>
<td><input type="text" id="o3" value="95"></td>
</tr>
<tr>
<td>Species #4</td>
<td><input type="text" id="o4"></td>
</tr>
<tr>
<td>Species #5</td>
<td><input type="text" id="o5"></td>
</tr>
<tr>
<td>Species #6</td>
<td><input type="text" id="o6"></td>
</tr>
<tr>
<td>Species #7</td>
<td><input type="text" id="o7"></td>
</tr>
<tr>
<td>Species #8</td>
<td><input type="text" id="o8"></td>
</tr>
<tr>
<td>Species #9</td>
<td><input type="text" id="o9"></td>
</tr>
<tr>
<td>Species #10</td>
<td><input type="text" id="o10"></td>
</tr>
</tbody></table>
<input type="button" id="button" onclick="calc()" value="Calculate">
Shannon Diversity Index (H): <b>1.081384</b>
Shannon Equitability Index (E<sub>H</sub>): <b>0.984318</b>
<script>
function calc() {
//get input data
var o1 = +document.getElementById('o1').value;
var o2 = +document.getElementById('o2').value;
var o3 = +document.getElementById('o3').value;
var o4 = +document.getElementById('o4').value;
var o5 = +document.getElementById('o5').value;
var o6 = +document.getElementById('o6').value;
var o7 = +document.getElementById('o7').value;
var o8 = +document.getElementById('o8').value;
var o9 = +document.getElementById('o9').value;
var o10 = +document.getElementById('o10').value;
var obs = [o1, o2, o3, o4, o5, o6, o7, o8, o9, o10];
var empties = obs.filter(x => x==0).length;
var n = obs.reduce((a, b) => a + b, 0);
//do calculations
var diff1 = 0;
if (o1) {
diff1 = (o1/n)*Math.log(o1/n);
}
var diff2 = 0;
if (o2) {
diff2 = (o2/n)*Math.log(o2/n);
}
var diff3 = 0;
if (o3) {
diff3 = (o3/n)*Math.log(o3/n);
}
var diff4 = 0;
if (o4) {
diff4 = (o4/n)*Math.log(o4/n);
}
var diff5 = 0;
if (o5) {
diff5 = (o5/n)*Math.log(o5/n);
}
var diff6 = 0;
if (o6) {
diff6 = (o6/n)*Math.log(o6/n);
}
var diff7 = 0;
if (o7) {
diff7 = (o7/n)*Math.log(o7/n);
}
var diff8 = 0;
if (o8) {
diff8 = (o8/n)*Math.log(o8/n);
}
var diff9 = 0;
if (o9) {
diff9 = (o9/n)*Math.log(o9/n);
}
var diff10 = 0;
if (o10) {
diff10 = (o10/n)*Math.log(o10/n);
}
var errors = [diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9, diff10];
var H = -1*math.sum(errors);
var E = H / Math.log(obs.length-empties);
//output results
document.getElementById('H').innerHTML = H.toFixed(6);
document.getElementById('E').innerHTML = E.toFixed(6);
  
} //end calc function
</script>
<h2><span class="orange">Shannon Diversity Index: Definition & Example</span></h2>
The <b>Shannon Diversity Index</b> (sometimes called the Shannon-Wiener Index) is a way to measure the diversity of species in a community.
Denoted as <em>H</em>, this index is calculated as:
<b><em>H</em> = -Σ<em>p</em><sub>i</sub> * <em>ln(p</em><sub>i</sub>)</b>
where:
<b>Σ:</b> A Greek symbol that means “sum”
<b><em>ln</em>:</b> Natural log
<b><em>p</em><sub>i</sub>:</b> The proportion of the entire community made up of species <em>i</em>
The higher the value of <em>H</em>, the higher the diversity of species in a particular community. The lower the value of <em>H</em>, the lower the diversity. A value of <em>H</em> = 0 indicates a community that only has one species.
The Shannon Equitability Index is a way to measure the evenness of species in a community. The term “evenness” simply refers to how similar the abundances of different species are in the community.
Denoted as <em>E<sub>H</sub></em>, this index is calculated as:
<b><em>E<sub>H</sub></em> = <em>H</em> / <em>ln</em>(<em>S</em>)</b>
where:
<b><em>H</em>:</b> The Shannon Diversity Index
<b><em>S</em>:</b> The total number of unique species
This value ranges from 0 to 1 where 1 indicates complete evenness.
The following step-by-step example shows how to calculate the Shannon Diversity Index and the Shannon Equitability Index for a given community.
<h3>Step 1: Collect the Data</h3>
Suppose a biologist wants to measure the diversity of species in a local forest. She collects the following data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon1.png">
<h3>Step 2: Calculate the Proportions</h3>
Next, the biologist can calculate the proportion of the community made up of each species.
For example, there are a total of 105 individuals and 40 are classified as species A. Thus, species A makes up 40 /105 =  <b>0.38</b> of the total community.
She can perform a similar calculation for each species:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon2.png">
<h3>Step 3: Calculate the Natural Log of the Proportions</h3>
Next, she can calculate the natural log of each proportion:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon3.png">
<h3>Step 4: Multiply the Proportions by the Natural Log of the Proportions</h3>
Next, she can multiply the proportions by the natural log of the proportions:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon4.png">
<h3>Step 5: Calculate the Shannon Diversity Index</h3>
Lastly, she can use the following formula to calculate the Shannon Diversity Index:
<em>H</em> = -Σ<em>p</em><sub>i</sub> * <em>ln(p</em><sub>i</sub>)
For this example, she can take the sum of the last column and multiply by negative one:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon5.png">
The Shannon Diversity Index for this community is <b>1.49</b>.
She can also use the following formula to calculate the Shannon Equitability Index:
<em>E<sub>H</sub></em> = <em>H</em> / <em>ln</em>(<em>S</em>)
For this example, there are <em>S</em> = 5 total species, so see can calculate this index to be:
<em>E<sub>H</sub></em> = 1.49 / <em>ln</em>(5) = <b>0.92</b>.
<h2><span class="orange">How to Perform a Shapiro-Wilk Test in SAS</span></h2>
The <b>Shapiro-Wilk test </b>is used to determine whether or not a dataset follows a  normal distribution .
The following step-by-step example shows how to perform a Shapiro-Wilk test for a dataset in SAS.
<h3>Step 1: Create the Data</h3>
First, we’ll create a dataset that contains 15 observations:
<b>/*create dataset*/
data my_data;
    input x;
    datalines;
3
3
4
6
7
8
8
9
12
14
15
15
17
20
21
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/shapiroSAS1.jpg"83">
<h3>Step 2: Perform the Shapiro-Wilk Test</h3>
Next, we’ll use <b>proc univariate </b>with the <b>normal</b> command to perform a Shapiro-Wilk test for normality:
<b>/*perform Shapiro-Wilk test*/
proc univariate data=my_data normal; 
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/shapiroSAS2.jpg">
The output provides us with a ton of information, but the only table we need to look at is the one titled <b>Tests for Normality</b>.
This table provides the test statistics and p-values for several normality tests including:
The Shapiro-Wilk Test
The Kolmogorov-Smirnov Test
The Cramer-von Mises Test
The Anderson-Darling Test
From this table we can see that the p-value for the Shapiro-Wilk test is <b>.3452</b>.
Recall that a Shapiro-Wilk test uses the following null and alternative  hypotheses :
<b>H<sub>0</sub></b>: The data is normally distributed.
<b>H<sub>A</sub></b>: The data is <em>not </em>normally distributed.
Since the p-value (<b>.3452</b>) is not less than .05, we fail to reject the null hypothesis.
This means we do not have sufficient evidence to say that the dataset is not normally distributed.
In other words, it’s safe to assume that the dataset is normally distributed.
<h2><span class="orange">How to Perform a Shapiro-Wilk Test in Python</span></h2>
The <b>Shapiro-Wilk test </b>is a test of normality. It is used to determine whether or not a sample comes from a  normal distribution .
To perform a Shapiro-Wilk test in Python we can use the  scipy.stats.shapiro()  function, which takes on the following syntax:
<b>scipy.stats.shapiro(x)</b>
where:
<b>x: </b>An array of sample data.
This function returns a test statistic and a corresponding p-value.
If the p-value is below a certain significance level, then we have sufficient evidence to say that the sample data does not come from a normal distribution.
This tutorial shows a couple examples of how to use this function in practice.
<h3>Example 1: Shapiro-Wilk Test on Normally Distributed Data</h3>
Suppose we have the following sample data:
<b>from numpy.random import seed
from numpy.random import randn
#set seed (e.g. make this example reproducible)
seed(0)
#generate dataset of 100 random values that follow a standard normal distribution
data = randn(100)</b>
The following code shows how to perform a Shapiro-Wilk test on this sample of 100 data values to determine if it came from a normal distribution:
<b>from scipy.stats import shapiro
#perform Shapiro-Wilk test
shapiro(data)
ShapiroResult(statistic=0.9926937818527222, pvalue=0.8689165711402893)
</b>
From the output we can see that the test statistic is <b>0.9927 </b>and the corresponding p-value is <b>0.8689</b>. 
Since the p-value is not less than .05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the sample data does not come from a normal distribution.
This result shouldn’t be surprising since we generated the sample data using the <b>randn() </b>function, which generates random values that follow a standard normal distribution.
<h3>Example 2: Shapiro-Wilk Test on Non-Normally Distributed Data</h3>
Now suppose we have the following sample data:
<b>from numpy.random import seed
from numpy.random import poisson
#set seed (e.g. make this example reproducible)
seed(0)
#generate dataset of 100 values that follow a Poisson distribution with mean=5
data = poisson(5, 100)</b>
The following code shows how to perform a Shapiro-Wilk test on this sample of 100 data values to determine if it came from a normal distribution:
<b>from scipy.stats import shapiro
#perform Shapiro-Wilk test
shapiro(data)
ShapiroResult(statistic=0.9581913948059082, pvalue=0.002994443289935589)
</b>
From the output we can see that the test statistic is <b>0.9582 </b>and the corresponding p-value is <b>0.00299</b>. 
Since the p-value is less than .05, we reject the null hypothesis. We have sufficient evidence to say that the sample data does not come from a normal distribution.
This result also shouldn’t be surprising since we generated the sample data using the <b>poisson() </b>function, which generates random values that follow a  Poisson distribution .
<h2><span class="orange">How to Perform a Shapiro-Wilk Test in R (With Examples)</span></h2>
The <b>Shapiro-Wilk test </b>is a test of normality. It is used to determine whether or not a sample comes from a  normal distribution .
This type of test is useful for determining whether or not a given dataset comes from a normal distribution, which is a common assumption used in many statistical tests including  regression ,  ANOVA ,  t-tests , and many others.
We can easily perform a Shapiro-Wilk test on a given dataset using the following built-in function in R:
<b>shapiro.test(x)</b>
where:
<b>x:</b> A numeric vector of data values.
This function produces a test statistic <em>W </em>along with a corresponding p-value. If the p-value is less than α =.05, there is sufficient evidence to say that the sample does not come from a population that is normally distributed.
<em><b>Note:</b> The sample size must be between 3 and 5,000 in order to use the shapiro.test() function.</em>
This tutorial shows several examples of how to use this function in practice.
<h3>Example 1: Shapiro-Wilk Test on Normal Data</h3>
The following code shows how to perform a Shapiro-Wilk test on a dataset with sample size n=100:
<b>#make this example reproducible
set.seed(0)
#create dataset of 100 random values generated from a normal distribution
data &lt;- rnorm(100)
#perform Shapiro-Wilk test for normality
shapiro.test(data)
Shapiro-Wilk normality test
data:  data
W = 0.98957, p-value = 0.6303
</b>
The p-value of the test turns out to be <b>0.6303</b>. Since this value is not less than .05, we can assume the sample data comes from a population that is normally distributed.
This result shouldn’t be surprising since we generated the sample data using the rnorm() function, which generates random values from a normal distribution with mean = 0 and standard deviation = 1.
<b>Related: </b> A Guide to dnorm, pnorm, qnorm, and rnorm in R 
We can also produce a histogram to visually verify that the sample data is normally distributed:
<b>hist(data, col='steelblue')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/shapiroR1.png">
We can see that the distribution is fairly bell-shaped with one peak in the center of the distribution, which is typical of data that is normally distributed.
<h3>Example 2: Shapiro-Wilk Test on Non-Normal Data</h3>
The following code shows how to perform a Shapiro-Wilk test on a dataset with sample size n=100 in which the values are randomly generated from a  Poisson distribution :
<b>#make this example reproducible
set.seed(0)
#create dataset of 100 random values generated from a Poisson distribution
data &lt;- rpois(n=100, lambda=3)
#perform Shapiro-Wilk test for normality
shapiro.test(data)
Shapiro-Wilk normality test
data:  data
W = 0.94397, p-value = 0.0003393
</b>
The p-value of the test turns out to be <b>0.0003393</b>. Since this value is less than .05, we have sufficient evidence to say that the sample data does <em>not </em>come from a population that is normally distributed.
This result shouldn’t be surprising since we generated the sample data using the rpois() function, which generates random values from a Poisson distribution.
<b>Related: </b> A Guide to dpois, ppois, qpois, and rpois in R 
We can also produce a histogram to visually see that the sample data is not normally distributed:
<b>hist(data, col='coral2')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/shapiroR2.png">
We can see that the distribution is right-skewed and doesn’t have the typical “bell-shape” associated with a normal distribution. Thus, our histogram matches the results of the Shapiro-Wilk test and confirms that our sample data does not come from a normal distribution.
<h3>What to Do with Non-Normal Data</h3>
If a given dataset is <em>not</em> normally distributed, we can often perform one of the following transformations to make it more normal:
<b>1. Log Transformation: </b>Transform the response variable from y to <b>log(y)</b>.
<b>2. Square Root Transformation: </b>Transform the response variable from y to <b>√y</b>.
<b>3. Cube Root Transformation: </b>Transform the response variable from y to <b>y<sup>1/3</sup></b>.
By performing these transformations, the response variable typically becomes closer to normally distributed.
Check out  this tutorial  to see how to perform these transformations in practice.
<h2><span class="orange">How to Shuffle Rows in a Pandas DataFrame</span></h2>
You can use the following syntax to randomly shuffle the rows in a pandas DataFrame:
<b>#shuffle entire DataFrame
df.sample(frac=1)
#shuffle entire DataFrame and reset index
df.sample(frac=1).reset_index(drop=True)
</b>
Here’s what each piece of the code does:
The <b>sample()</b> function takes a sample of all rows without replacement.
The <b>frac</b> argument specifies the fraction of rows to return in the sample. A frac value of 1 specifies to use all rows.
The <b>reset_index(drop=True)</b> function specifies to reset the index of the rows.
The following examples show how to use this syntax in practice.
<h3>Example 1: Shuffle Entire DataFrame</h3>
The following code shows how to shuffle all rows in a pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'B', 'B', 'C'],   'points': [77, 82, 86, 88, 80, 95],   'rebounds': [19, 22, 15, 28, 33, 29]})
#view DataFrame
df
teampointsrebounds
0A7719
1A8222
2A8615
3B8828
4B8033
5C9529
#shuffle all rows of DataFrame
df.sample(frac=1)
teampointsrebounds
1A8222
3B8828
2A8615
5C9529
4B8033
0A7719
</b>
Notice that the rows are shuffled and each row retained its original index value.
Also note that each time you run this function, the order of the rows will change. 
<h3>Example 2: Shuffle Entire DataFrame & Reset Index</h3>
The following code shows how to shuffle all rows in a pandas DataFrame and reset the index values:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'B', 'B', 'C'],   'points': [77, 82, 86, 88, 80, 95],   'rebounds': [19, 22, 15, 28, 33, 29]})
#view DataFrame
df
teampointsrebounds
0A7719
1A8222
2A8615
3B8828
4B8033
5C9529
#shuffle all rows of DataFrame
df.sample(frac=1).reset_index(drop=True)
teampointsrebounds
0A7719
1C9529
2A8222
3B8828
4A8615
5B8033
</b>
Notice that the rows are shuffled and the index is also reset so that the first row has an index value of 0, the second row has an index value of 1, and so on.
<h2><span class="orange">How to Create Side-by-Side Boxplots in R (With Examples)</span></h2>
Side-by-side boxplots can be used to quickly visualize the similarities and differences between different distributions.
This tutorial explains how to create side-by-side boxplots in both base R and  ggplot2  using the following data frame:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=8), points=c(5, 5, 6, 6, 8, 9, 13, 15,          11, 11, 12, 14, 15, 19, 22, 24,          19, 23, 23, 23, 24, 26, 29, 33))
#view first 10 rows
head(df, 10)
   team points
1     A      5
2     A      5
3     A      6
4     A      6
5     A      8
6     A      9
7     A     13
8     A     15
9     B     11
10    B     11</b>
<h3>Side-by-Side Boxplots in Base R</h3>
The following code shows how to create side-by-side boxplots in base R:
<b>#create vertical side-by-side boxplots
boxplot(df$points ~ df$team,
        col='steelblue',
        main='Points by Team',
        xlab='Team',
        ylab='Points') 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/sidebox1.png">
We can use the argument <b>horizontal=TRUE</b> to display the boxplots horizontally instead of vertically:
<b>#create horizontal side-by-side boxplots
boxplot(df$points ~ df$team,
        col='steelblue',
        main='Points by Team',
        xlab='Points',
        ylab='Team',
        horizontal=TRUE) </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/sidebox2-1.png">
<h3>Side-by-Side Boxplots in ggplot2</h3>
The following code shows how to create vertical side-by-side boxplots in ggplot2:
<b>library(ggplot2)
#create vertical side-by-side boxplots
ggplot(df, aes(x=team, y=points, fill=team)) +
  geom_boxplot() +
  ggtitle('Points by Team') </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/sidebox.png">
And we can use the <b>coord_flip()</b> argument to display the boxplots horizontally instead of vertically:
<b>library(ggplot2)
#create horizontal side-by-side boxplots
ggplot(df, aes(x=team, y=points, fill=team)) +
  geom_boxplot() +
  coord_flip() +
  ggtitle('Points by Team') </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/sidebox3.png">
<h2><span class="orange">How to Create Side-by-Side Boxplots in Excel</span></h2>
A  boxplot  (sometimes called a box-and-whisker plot) is a plot that shows the five-number summary of a dataset, which includes the following values:
Minimum
First Quartile
Median
Third Quartile
Maximum
Using these five values, we can create a boxplot to gain a solid understanding of the distribution of values in a given dataset.
We can also compare two or more boxplots to quickly visualize the differences between two or more datasets.
The following step-by-step example shows how to create side-by-side boxplots in Excel.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the values for three datasets in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel1.png">
<h3>Step 2: Create the Side-by-Side Boxplots</h3>
Next, highlight cells A1:C21.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel6.png">
Next, click the <b>Insert</b> tab along the top ribbon. Then click <b>Recommended Charts</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel3.png">
Next, click <b>All Charts</b> and then click <b>Box & Whisker</b>. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel4.png">
The following side-by-side boxplots will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel5.png">
<h3>Step 3: Customize the Plot</h3>
Next, click the gridlines in the background of the plot and then click delete.
Then click the green plus “+” sign in the top right corner of the plot. Then check the box next to <b>Legend</b> and select <b>Bottom</b> as the position:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel7.png">
Lastly, feel free to click on any of the individual boxplots and change the colors to anything that you’d like.
Here’s what our final side-by-side boxplots look like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/sidebysideExcel8.png">
We can make the following observations from the boxplots:
Dataset 1 has the highest variance (since it’s the longest boxplot)
Dataset 2 has the lowest variance (since it’s the shortest boxplot)
Dataset 3 has the highest median value (as indicated by the horizontal bar in the middle of the box)
<h2><span class="orange">How to Create Side-by-Side Plots in ggplot2</span></h2>
Often you may want to create two plots side-by-side using the  ggplot2  package in R. Fortunately this is easy to do with the help of the  patchwork  package.
<b>#install ggplot2 and patchwork packages
install.packages('ggplot2')
install.packages('patchwork')
#load the packages 
library(ggplot2)
library(patchwork)</b>
This tutorial shows several examples of how to use these packages to create side-by-side plots.
<h3>Example 1: Two Side-by-Side Plots</h3>
The following code shows how to create two side-by-side plots using the R built-in <b>iris </b>dataset:
<b>#create box plot
plot1 &lt;- ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot()
#create density plot
plot2 &lt;- ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_density(alpha = 0.8)
#display plots side by side
plot1 + plot2 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/sideBySideggplot1.png">
<h3>Example 2: Three Side-by-Side Plots</h3>
The following code shows how to create three side-by-side plots using the R built-in <b>iris </b>dataset:
<b>#create box plot
plot1 &lt;- ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot()
#create density plot
plot2 &lt;- ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_density(alpha = 0.7)
#create scatterplot 
plot3 &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +
  geom_point()
#display three plots side by side
plot1 + plot2 + plot3
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/sideBySideggplot2.png">
<h3>Example 3: Two Stacked Plots</h3>
The following code shows how to create two stacked plots, one on top of the other:
<b>#create box plot
plot1 &lt;- ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot()
#create density plot
plot2 &lt;- ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_density(alpha = 0.7)
#display plots stacked on top of each other
plot1 / plot2 </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/sideBySideggplot3.png">
<h3>Example 4: Add Titles, Subtitles, and Captions</h3>
The following code shows how to add titles, subtitles, and captions to the plots:
<b>#create box plot
plot1 &lt;- ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot() +
  ggtitle('Boxplot')
#create density plot
plot2 &lt;- ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_density(alpha = 0.7) +
  ggtitle('Density Plot')
#display plots side by side with title, subtitle, and captions
patchwork &lt;- plot1 + plot2 
patchwork + plot_annotation(
  title = 'This is a title',
  subtitle = 'This is a subtitle that describes more information about the plots',
  caption = 'This is a caption'
)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/sideBySideggplot4-1.png">
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">How to Interpret Sig. (2-Tailed) Values in SPSS</span></h2>
Often when you perform statistical tests in SPSS, the output table will contain a <b>Sig. (2-tailed)</b> value.
This value represents the 2-tailed p-value of the test.
If this value is less than your significance level (common choices are .05 or .01), then you can  reject the null hypothesis  of your test.
This tutorial provides examples of how to interpret the <b>Sig. (2-tailed)</b> value of different statistical tests.
<h2>Example 1: One Sample t-test</h2>
A <b>one sample t-test</b> is used to test whether or not the mean of a population is equal to some value.
For example, suppose a botanist wants to know if the mean height of a certain species of plant is equal to 15 inches. She collects a random sample of 12 plants and records each of their heights in inches.
She then uses this sample to perform a one sample t-test with the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ = 15 (the true population mean is equal to 15 inches)
<b>H<sub>A</sub>: </b>μ ≠ 15 (the true population mean is not equal to 15 inches)
She performs this one sample t-test in SPSS and gets the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/oneSampSPSS5.png">
The Sig. (2-tailed) value is <b>0.120</b>.
This represents the two-sided p-value that corresponds to a t value of -1.685 with 11 degrees of freedom.
Since the p-value of the test (.120) is not less than 0.05, we fail to reject the null hypothesis.
In other words, we do not have sufficient evidence to say that the true mean height of this species of plant is different than 15 inches.
<h2>Example 2: Two Sample t-test</h2>
A <b>two sample t-test</b> is used to test whether or not the mean values of two populations are equal.
For example, suppose researchers want to know if a new fuel treatment leads to a change in the average miles per gallon of a certain car. To test this, they conduct an experiment in which 12 cars receive the new fuel treatment and 12 cars do not.
The researchers perform a two sample t-test with the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<b><sub>1</sub></b> = μ<b><sub>2 </sub></b>(average mpg between the two populations is equal)
<b>H<sub>1</sub>: </b>μ<b><sub>1</sub></b> ≠ μ<b><sub>2 </sub></b>(average mpg between the two populations is not equal)
They perform a two sample t-test in SPSS and get the following results:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS5.png">
The Sig. (2-tailed) value is <b>0.167</b>.
This represents the two-sided p-value that corresponds to a t value of -1.428 with 22 degrees of freedom.
Since the p-value of the test (.167) is not less than 0.05, we fail to reject the null hypothesis.
In other words, we do not have sufficient evidence to say that the true mean mpg is different between cars that receive treatment and cars that don’t.
<h2>Additional Resources</h2>
The following tutorials explain how to perform various statistical tests in SPSS:
 How to Perform a One Sample t-test in SPSS 
 How to Perform a Two Sample t-test in SPSS 
 How to Perform a Paired Samples t-test in SPSS 
<h2><span class="orange">How to Calculate a Sigmoid Function in Excel</span></h2>
A  sigmoid function  is a mathematical function that has an “S” shaped curve when plotted.
The most common example of a sigmoid function is the logistic sigmoid function, which is calculated as:
<b>F(x) = 1 / (1 + e<sup>-x</sup>)</b>
To calculate the value of a sigmoid function for a given x value in Excel, we can use the following formula:
<b>=1/(1+EXP(-A1))
</b>
This formula assumes the x value is located in cell <b>A1</b>.
The following example shows how to use this formula in practice.
<h3>Example: Calculate Sigmoid Function in Excel</h3>
Suppose we have the following list of x values in a column in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sig1.jpg"402">
To calculate the value of the sigmoid function for each x value, I can type the following formula into cell <b>B2</b>:
<b>=1/(1+EXP(-A2))</b>
I can then drag this formula down to every remaining cell in column B to calculate the value of the sigmoid function for each x value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sig2.jpg">
We can then create a line plot to visualize the values of the sigmoid function.
First, highlight every value in column A and B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sig3.jpg"466">
Then click the <b>Insert</b> tab along the top ribbon. Then click the <b>Charts</b> group and click the chart titled <b>Scatter with Smooth Lines and Markers</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sig4.jpg"440">
Once you click this, the following line chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sig5.jpg"551">
The x-axis displays the x values and the y-axis displays the value of the sigmoid function for each x value.
Notice that the plot exhibits the “S” shaped curve that is characteristic of a sigmoid function.
<h2><span class="orange">How to Calculate a Sigmoid Function in Python (With Examples)</span></h2>
A  sigmoid function  is a mathematical function that has an “S” shaped curve when plotted.
The most common example of a sigmoid function is the logistic sigmoid function, which is calculated as:
<b>F(x) = 1 / (1 + e<sup>-x</sup>)</b>
The easiest way to calculate a sigmoid function in Python is to use the  expit()  function from the <b>SciPy</b> library, which uses the following basic syntax:
<b>from scipy.special import expit
#calculate sigmoid function for x = 2.5
expit(2.5)
</b>
The following examples show how to use this function in practice.
<h3>Example 1: Calculate Sigmoid Function for One Value</h3>
The following code shows how to calculate the sigmoid function for the value x = 2.5:
<b>from scipy.special import expit
#calculate sigmoid function for x = 2.5
expit(2.5)
0.9241418199787566
</b>
The value of the sigmoid function for x = 2.5 is <b>0.924</b>.
We can confirm this by calculating the value manually:
F(x) = 1 / (1 + e<sup>-x</sup>)
F(x) = 1 / (1 + e<sup>-2.5</sup>)
F(x) = 1 / (1 + .082)
F(x) = <b>0.924</b>
<h3>Example 2: Calculate Sigmoid Function for Multiple Values</h3>
The following code shows how to calculate the sigmoid function for multiple x values at once:
<b>from scipy.special import expit
#define list of values
values = [-2, -1, 0, 1, 2]
#calculate sigmoid function for each value in list
expit(values)
array([0.11920292, 0.26894142, 0.5, 0.73105858, 0.88079708])
</b>
<h3>Example 3: Plot Sigmoid Function for Range of Values</h3>
The following code shows how to plot the values of a sigmoid function for a range of x values using  matplotlib :
<b>import matplotlib.pyplot as plt
from scipy.special import expit
import numpy as np
#define range of x-values
x = np.linspace(-10, 10, 100)
#calculate sigmoid function for each x-value
y = expit(x)
  
#create plot
plt.plot(x, y)
plt.xlabel('x')
plt.ylabel('F(x)')
#display plot
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/sigmoid_python.jpg">
Notice that the plot exhibits the “S” shaped curve that is characteristic of a sigmoid function.
<h2><span class="orange">How to Use sign() Function in R (3 Examples)</span></h2>
You can use the <b>sign()</b> function in base R to return the sign of each element in a vector.
This function uses the following basic syntax:
<b>sign(x)</b>
where:
<b>x:</b> A numeric vector
The function will return:
<b>-1</b>: If a value is negative
<b>0</b>: If a value is zero
<b>1</b>: If a value is positive
The following examples show how to use the <b>sign()</b> function in different scenarios.
<h3>Example 1: Use sign() with Vector</h3>
The following code shows how to use the <b>sign()</b> function to display the sign of each value in a numeric vector:
<b>#define vector of values
x &lt;- c(-3, 0, 3)
#return sign of each element in vector
sign(x)
[1] -1  0  1
</b>
Here’s how to interpret the output:
The first value is <b>-1</b> since the first value in the vector is negative.
The second value is <b>0</b> since the second value in the vector is zero.
The third value is <b>1</b> since the third value in the vector is positive.
<h3>Example 2: Use sign() with Data Frame Column</h3>
The following code shows how to use the <b>sign()</b> function to display the sign of each value in a column of a data frame:
<b>#create data frame
df &lt;- data.frame(x=c(0, 1.4, -1, 5, -4, 12), y=c(3, 4, 3, 6, 10, 11))
#view data frame
df
     x  y
1  0.0  3
2  1.4  4
3 -1.0  3
4  5.0  6
5 -4.0 10
6 12.0 11
#view sign of each value in column x
sign(df$x)
[1]  0  1 -1  1 -1  1
</b>
<h3>Example 3: Use sign() to Create New Data Frame Column</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(0, 1.4, -1, 5, -4, 12), y=c(3, 4, 3, 6, 10, 11))
#view data frame
df
     x  y
1  0.0  3
2  1.4  4
3 -1.0  3
4  5.0  6
5 -4.0 10
6 12.0 11</b>
The following code shows how to use the <b>sign()</b> function to create a new column called ‘z’ whose values are dependent on the values in the existing column ‘x’:
<b>#create new column 'z' based on sign of values in column 'x'
df$z &lt;- with(df, ifelse(sign(x) == -1, 'negative',   ifelse(sign(x) == 0, 'zero', 'positive')))
#view updated data frame
df
     x  y        z
1  0.0  3     zero
2  1.4  4 positive
3 -1.0  3 negative
4  5.0  6 positive
5 -4.0 10 negative
6 12.0 11 positive</b>
Notice that the values in column ‘z’ correspond to the sign of the values in column ‘x’.
<h2><span class="orange">How to Perform a Sign Test in Excel (Step-by-Step)</span></h2>
A <b>sign-test</b> is a non-parametric test that is used to determine whether a population median is equal to some value.
The following step-by-step example shows how to perform a sign test in Excel.
<h3>Step 1: Enter the Data</h3>
Suppose a manufacturing plant claims to produce widgets that weigh 50 pounds. To test this, an inspector goes out to the plant and randomly measures the weight of 20 widgets.
He then enters the following weights for each widget:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/signExcel1.png">
We can perform a sign test to determine if the median weight is significantly different from 50 pounds.
<h3>Step 2: Calculate the Signs</h3>
Next, let’s calculate the signs of each widget using the following rules:
If the weight of a widget is less than 50, assign it a sign of <b>-1</b>
If the weight of a widget is equal to 50, assign it a sign of <b>0</b>
If the weight of a widget is greater than 50, assign it a sign of <b>1</b>
We’ll use the following formula in Excel to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/signExcel2.png">
<h3>Step 3: Calculate the P-Value of the Test</h3>
Lastly, we’ll use the following formulas to calculate the total positive signs and negative signs and calculate the corresponding p-value of the sign test:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/signExcel3.png">
The sign test uses the following null and alternative hypotheses:
<b>H<sub>0</sub></b>: Population median weight = 20 pounds
<b>H<sub>A</sub></b>: Population median weight ≠ 20 pounds
Since the p-value is not less than .05, we fail to reject the null hypothesis. This means we don’t have sufficient evidence to say that the true median weight of widgets produced is different than 50 pounds.
<b>Note:</b> In this example, we multiplied the p-value by two since we performed a two-sided test. We also used the smaller of the negative and positive counts since we used a two-sided test. 
<h2><span class="orange">How to Interpret Significance Codes in R</span></h2>
When you perform  regression analysis  or  ANOVA  in R, the output tables will contain p-values for the variables used in the analysis along with corresponding <b>significance codes</b>.
These significance codes are displayed as a series of stars or a decimal point if the variables are statistically significant.
Here is how to interpret the various significance codes:
<b>significance code         p-value
   ***                 [0, 0.001]
    **              (0.001, 0.01]
     *               (0.01, 0.05]
     .                (0.05, 0.1]         (0.1, 1] </b>
The following examples show how to interpret these significance codes in practice.
<h3>Example: Significance Codes in Regression</h3>
The following code shows how to fit a multiple linear regression model with the built-in <b>mtcars</b> dataset using <em>hp</em>, <em>drat</em>, and <em>wt</em> as predictor variables and <em>mpg</em> as the response variable:
<b>#fit regression model using hp, drat, and wt as predictors
model &lt;- lm(mpg ~ hp + drat + wt, data = mtcars)
#view model summary
summary(model)
Call:
lm(formula = mpg ~ hp + drat + wt, data = mtcars)
Residuals:
    Min      1Q  Median      3Q     Max 
-3.3598 -1.8374 -0.5099  0.9681  5.7078 
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 29.394934   6.156303   4.775 5.13e-05 ***
hp          -0.032230   0.008925  -3.611 0.001178 ** 
drat         1.615049   1.226983   1.316 0.198755    
wt          -3.227954   0.796398  -4.053 0.000364 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 2.561 on 28 degrees of freedom
Multiple R-squared:  0.8369,Adjusted R-squared:  0.8194 
F-statistic: 47.88 on 3 and 28 DF,  p-value: 3.768e-11
</b>
Here is how to interpret the significance codes for the three predictor variables:
<em>hp</em> has a p-value of <b>.001178</b>. Since this value is in the range <b>(0.001, 0.01]</b>, it has a significance code of <b>**</b>
<i>drat </i>has a p-value of <b>.198755</b>. Since this value is in the range <b>(0.1, 1]</b>, it has no significance code.
<em>wt</em> has a p-value of <b>.000364</b>. Since this value is in the range <b>[0, 0.001]</b>, it has a significance code of <b>***</b>
If we used an alpha level of α = .05 to determine which predictors were significant in this regression model, we’d say that <em>hp</em> and <em>wt</em> are statistically significant predictors while <em>drat</em> is not.
<h3>Example: Significance Codes in ANOVA</h3>
The following code shows how to fit a one-way ANOVA model with the built-in <b>mtcars</b> dataset using <em>gear</em> as the factor variable and <em>mpg</em> as the response variable:
<b>#fit one-way ANOVA
model &lt;- aov(mpg ~ gear, data = mtcars)
#view the model output
summary(model)
            Df Sum Sq Mean Sq F value Pr(>F)   
gear         1  259.7  259.75   8.995 0.0054 **
Residuals   30  866.3   28.88                  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</b>
Here is how to interpret the significance code in the output:
<em>gear</em> has a p-value of <b>.0054</b>. Since this value is in the range <b>(0.001, 0.01]</b>, it has a significance code of <b>**</b>
Using an alpha level of α = .05, we would say that <em>gear</em> is statistically significant. In other words, there is a statistically significant difference between the mean <i>mpg</i> of cars based on their value for <em>gear</em>.
<h2><span class="orange">How to Round to Significant Figures in Excel</span></h2>
Often you may want to round a value to a certain number of significant figures in Excel.
You can use the following formula to do so:
<b>=ROUND(value,figures-(1+INT(LOG10(ABS(value)))))
</b>
where:
 <b>value:</b> The value that you want to round.
<b>figures</b>: The number of significant figures to round to.
Here’s what the formula does in a nutshell:
<b>1.</b> <b>ABS</b> converts the value to a positive value.
<b>2. LOG10</b> finds the exponent of the value.
<b>3. INT</b> removes the decimal from the value.
<b>4. ROUND</b> then finds the number of significant figures to round to.
The following example shows how to use this formula in practice.
<h3>Example: Rounding to Significant Figures in Excel</h3>
The following screenshot shows how to round the value <b>934745</b> to <b>1</b> significant figure:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sigexcel1.jpg">
We can see that the value <b>934745</b> gets rounded to <b>900000</b>.
Note that we can round to however many significant figures we’d like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/sigexcel2.jpg"495">
<b>Note</b>: For a quick introduction to significant figures, refer to  this paper  from the Yale Department of Astronomy.
<h2><span class="orange">How to Round to Significant Figures in Google Sheets</span></h2>
Often you may want to round a value to a certain number of significant figures in Google Sheets.
You can use the following formula to do so:
<b>=ROUND(value,figures-(1+INT(LOG10(ABS(value)))))
</b>
where <b>value</b> is the value that you want to round and <b>figures</b> is the number of significant figures to round to.
Here’s what the formula does in a nutshell:
<b>1.</b> <b>ABS</b> converts the value to a positive value.
<b>2. LOG10</b> finds the exponent of the value.
<b>3. INT</b> removes the decimal from the value.
<b>4. ROUND</b> then finds the number of significant figures to round to.
The following example shows how to use this formula in practice.
<h3>Example: Rounding to Significant Figures in Google Sheets</h3>
The following screenshot shows how to round the value <b>934745</b> to <b>1</b> significant figure:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/sigFigGoogleSheets1.png">
We can see that the value <b>934745</b> gets rounded to <b>900000</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/sigFigGoogleSheets3.png">
Note that we can round to however many significant figures we’d like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/sigFigGoogleSheets2.png">
<em>You can find more Google Sheets tutorials  here .</em>
<h3>A Simple Explanation of Significant Figures</h3>
For a wonderful introduction to significant figures, check out the video below from Kahn Academy:
<iframe title="Significant figures | Decimals | Pre-Algebra | Khan Academy" src="https://www.youtube.com/embed/eCJ76hz7jPM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h2><span class="orange">How to Perform Simple Linear Regression in Excel</span></h2>
<b>Simple linear regression </b>is a method we can use to understand the relationship between an explanatory variable, x, and a response variable, y.
This tutorial explains how to perform simple linear regression in Excel.
<h2>Example: Simple Linear Regression in Excel</h2>
Suppose we are interested in understanding the relationship between the number of hours a student studies for an exam and the exam score they receive.
To explore this relationship, we can perform simple linear regression using <b>hours studied</b> as an explanatory variable and <b>exam score </b>as a response variable.
Perform the following steps in Excel to conduct a simple linear regression.
<b>Step 1: Enter the data.</b>
Enter the following data for the number of hours studied and the exam score received for 20 students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionExcel1.png">
<b>Step 2: Visualize the data.</b>
Before we perform simple linear regression, it’s helpful to create a  scatterplot  of the data to make sure there actually exists a linear relationship between hours studied and exam score.
Highlight the data in columns A and B. Along the top ribbon in Excel go to the <b>Insert </b>tab. Within the <b>Charts</b> group, click <b>Insert Scatter (X, Y) </b>and click on the first option titled <b>Scatter</b>. This will automatically produce the following scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionExcel2.png">
The number of hours studied is shown on the x-axis and the exam scores are shown on the y-axis. We can see that there is a linear relationship between the two variables – more hours studied is associated with higher exam scores.
To quantify the relationship between these two variables, we can perform simple linear regression.
<b>Step 3: Perform simple linear regression.</b>
Along the top ribbon in Excel, go to the <b>Data</b> tab and click on <b>Data Analysis</b>. If you don’t see this option, then you need to first  install the free Analysis ToolPak .
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
Once you click on <b>Data Analysis,</b> a new window will pop up. Select <b>Regression </b>and click OK.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionExcel3.png">
For <b>Input Y Range</b>, fill in the array of values for the response variable. For <b>Input X Range</b>, fill in the array of values for the explanatory variable.
Check the box next to <b>Labels </b>so Excel knows that we included the variable names in the input ranges. 
For <b>Output Range</b>, select a cell where you would like the output of the regression to appear.
Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionExcel4.png">
The following output will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionExcel5.png">
<b>Step 4: Interpret the output.</b>
Here is how to interpret the most relevant numbers in the output:
<b>R Square: 0.7273</b>. This is known as the coefficient of determination. It is the proportion of the variance in the response variable that can be explained by the explanatory variable. In this example, 72.73% of the variation in the exam scores can be explained by the number of hours studied.
<b>Standard error:</b> <b>5.2805</b>. This is the average distance that the observed values fall from the regression line. In this example, the observed values fall an average of 5.2805 units from the regression line.
<b>F: 47.9952</b>. This is the overall F statistic for the regression model, calculated as regression MS / residual MS.
<b>Significance F: 0.0000</b>. This is the p-value associated with the overall F statistic. It tells us whether or not the regression model is statistically significant. In other words, it tells us if the explanatory variable has a statistically significant association with the response variable. In this case the p-value is less than 0.05, which indicates that there is a statistically significant association between hours studied and exam score received.
<b>Coefficients: </b>The coefficients give us the numbers necessary to write the estimated regression equation. In this example the estimated regression equation is:
<b>exam score = 67.16 + 5.2503*(hours)</b>
We interpret the coefficient for hours to mean that for each additional hour studied, the exam score is expected to increase by <b>5.2503</b>, on average. We interpret the coefficient for the intercept to mean that the expected exam score for a student who studies zero hours is <b>67.16</b>.
We can use this estimated regression equation to calculate the expected exam score for a student, based on the number of hours they study.
For example, a student who studies for three hours is expected to receive an exam score of <b>82.91</b>:
exam score = 67.16 + 5.2503*(3) = 82.91
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Create a Residual Plot in Excel 
 How to Construct a Prediction Interval in Excel 
 How to Create a Q-Q Plot in Excel 
<h2><span class="orange">How to Perform Simple Linear Regression in Python (Step-by-Step)</span></h2>
 Simple linear regression  is a technique that we can use to understand the relationship between a single  explanatory variable  and a single  response variable .
This technique finds a line that best “fits” the data and takes on the following form:
<b><U+0177> = b<sub>0</sub> + b<sub>1</sub>x</b>
where:
<b><U+0177></b>: The estimated response value
<b>b<sub>0</sub></b>: The intercept of the regression line
<b>b<sub>1</sub></b>: The slope of the regression line
This equation can help us understand the relationship between the explanatory and response variable, and (assuming it’s statistically significant) it can be used to predict the value of a response variable given the value of the explanatory variable.
This tutorial provides a step-by-step explanation of how to perform simple linear regression in Python.
<h3>Step 1: Load the Data</h3>
For this example, we’ll create a fake dataset that contains the following two variables for 15 students:
Total hours studied for some exam
Exam score
We’ll attempt to fit a simple linear regression model using <em>hours</em> as the explanatory variable and <em>exam score</em> as the response variable.
The following code shows how to create this fake dataset in Python:
<b>import pandas as pd
#create dataset
df = pd.DataFrame({'hours': [1, 2, 4, 5, 5, 6, 6, 7, 8, 10, 11, 11, 12, 12, 14],   'score': [64, 66, 76, 73, 74, 81, 83, 82, 80, 88, 84, 82, 91, 93, 89]})
      
#view first six rows of dataset
df[0:6]
    hours    score
0164
1266
2476
3573
4574
5681
</b>
<h3>Step 2: Visualize the Data</h3>
Before we fit a simple linear regression model, we should first visualize the data to gain an understanding of it.
First, we want to make sure that the relationship between <em>hours</em> and <em>score</em> is roughly linear, since that is an  underlying assumption  of simple linear regression.
We can create a simple  scatterplot  to view the relationship between the two variables:
<b>import matplotlib.pyplot as plt
plt.scatter(df.hours, df.score)
plt.title('Hours studied vs. Exam Score')
plt.xlabel('Hours')
plt.ylabel('Score')
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegPython1.png">
From the plot we can see that the relationship does appear to be linear. As <em>hours</em> increases, <em>score</em> tends to increase as well in a linear fashion.
Next, we can create a boxplot to visualize the distribution of exam scores and check for  outliers . By default, Python defines an observation to be an outlier if it is 1.5 times the interquartile range greater than the third quartile (Q3) or 1.5 times the interquartile range less than the first quartile (Q1).
If an observation is an outlier, a tiny circle will appear in the boxplot:
<b>df.boxplot(column=['score'])</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegPython2.png">
There are no tiny circles in the boxplot, which means there are no outliers in our dataset.
<h3>Step 3: Perform Simple Linear Regression</h3>
Once we’ve confirmed that the relationship between our variables is linear and that there are no outliers present, we can proceed to fit a simple linear regression model using <em>hours</em> as the explanatory variable and <em>score</em> as the response variable:
<em><b>Note:</b> We’ll use the  OLS() function  from the statsmodels library to fit the regression model.</em>
<b>import statsmodels.api as sm
#define response variable
y = df['score']
#define explanatory variable
x = df[['hours']]
#add constant to predictor variables
x = sm.add_constant(x)
#fit linear regression model
model = sm.OLS(y, x).fit()
#view model summary
print(model.summary())
            OLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.831
Model:                            OLS   Adj. R-squared:                  0.818
Method:                 Least Squares   F-statistic:                     63.91
Date:                Mon, 26 Oct 2020   Prob (F-statistic):           2.25e-06
Time:                        15:51:45   Log-Likelihood:                -39.594
No. Observations:                  15   AIC:                             83.19
Df Residuals:                      13   BIC:                             84.60
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         65.3340      2.106     31.023      0.000      60.784      69.884
hours          1.9824      0.248      7.995      0.000       1.447       2.518
==============================================================================
Omnibus:                        4.351   Durbin-Watson:                   1.677
Prob(Omnibus):                  0.114   Jarque-Bera (JB):                1.329
Skew:                           0.092   Prob(JB):                        0.515
Kurtosis:                       1.554   Cond. No.                         19.2
==============================================================================</b>
From the model summary we can see that the fitted regression equation is:
<b>Score = 65.334 + 1.9824*(hours)</b>
This means that each additional hour studied is associated with an average increase in exam score of <b>1.9824</b> points. And the intercept value of <b>65.334</b> tells us the average expected exam score for a student who studies zero hours.
We can also use this equation to find the expected exam score based on the number of hours that a student studies. For example, a student who studies for 10 hours is expected to receive an exam score of <b>85.158</b>:
<b>Score = 65.334 + 1.9824*(10) = 85.158</b>
Here is how to interpret the rest of the model summary:
<b>P>|t|:</b> This is the p-value associated with the model coefficients. Since the p-value for <em>hours</em> (0.000) is significantly less than .05, we can say that there is a statistically significant association between <em>hours</em> and <em>score</em>.
<b>R-squared:</b> This number tells us the percentage of the variation in the exam scores can be explained by the number of hours studied. In general, the larger the R-squared value of a regression model the better the explanatory variables are able to predict the value of the response variable. In this case, <b>83.1%</b> of the variation in scores can be explained by hours studied.
<b>F-statistic & p-value:</b> The F-statistic (<b>63.91</b>) and the corresponding p-value (<b>2.25e-06</b>) tell us the overall significance of the regression model, i.e. whether explanatory variables in the model are useful for explaining the variation in the response variable. Since the p-value in this example is less than .05, our model is statistically significant and <em>hours</em> is deemed to be useful for explaining the variation in <em>score</em>.
<h3>Step 4: Create Residual Plots</h3>
After we’ve fit the simple linear regression model to the data, the last step is to create residual plots.
One of the key assumptions of linear regression is that the residuals of a regression model are roughly normally distributed and are  homoscedastic  at each level of the explanatory variable. If these assumptions are violated, then the results of our regression model could be misleading or unreliable.
To verify that these assumptions are met, we can create the following residual plots:
<b>Residual vs. fitted values plot:</b> This plot is useful for confirming homoscedasticity. The x-axis displays the fitted values and the y-axis displays the residuals. As long as the residuals appear to be randomly and evenly distributed throughout the chart around the value zero, we can assume that homoscedasticity is not violated:
<b>#define figure size
fig = plt.figure(figsize=(12,8))
#produce residual plots
fig = sm.graphics.plot_regress_exog(model, 'hours', fig=fig)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegPython3.png">
Four plots are produced. The one in the top right corner is the residual vs. fitted plot. The x-axis on this plot shows the actual values for the predictor variable <em>points</em> and the y-axis shows the residual for that value.
Since the residuals appear to be randomly scattered around zero, this is an indication that heteroscedasticity is not a problem with the explanatory variable.
<b>Q-Q plot:</b> This plot is useful for determining if the residuals follow a normal distribution. If the data values in the plot fall along a roughly straight line at a 45-degree angle, then the data is normally distributed:
<b>#define residuals
res = model.resid
#create Q-Q plot
fig = sm.qqplot(res, fit=True, line="45")
plt.show() 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegPython4.png">
The residuals stray from the 45-degree line a bit, but not enough to cause serious concern. We can assume that the normality assumption is met.
Since the residuals are normally distributed and homoscedastic, we’ve verified that the assumptions of the simple linear regression model are met. Thus, the output from our model is reliable.
<em>The complete Python code used in this tutorial can be found  here .</em>
<h2><span class="orange">How to Perform Simple Linear Regression in R (Step-by-Step)</span></h2>
 Simple linear regression  is a technique that we can use to understand the relationship between a single  explanatory variable  and a single  response variable .
In a nutshell, this technique finds a line that best “fits” the data and takes on the following form:
<b><U+0177> = b<sub>0</sub> + b<sub>1</sub>x</b>
where:
<b><U+0177></b>: The estimated response value
<b>b<sub>0</sub></b>: The intercept of the regression line
<b>b<sub>1</sub></b>: The slope of the regression line
This equation can help us understand the relationship between the explanatory and response variable, and (assuming it’s statistically significant) it can be used to predict the value of a response variable given the value of the explanatory variable.
This tutorial provides a step-by-step explanation of how to perform simple linear regression in R.
<h3>Step 1: Load the Data</h3>
For this example, we’ll create a fake dataset that contains the following two variables for 15 students:
Total hours studied for some exam
Exam score
We’ll attempt to fit a simple linear regression model using <em>hours</em> as the explanatory variable and <em>exam score</em> as the response variable.
The following code shows how to create this fake dataset in R:
<b>#create dataset
df &lt;- data.frame(hours=c(1, 2, 4, 5, 5, 6, 6, 7, 8, 10, 11, 11, 12, 12, 14), score=c(64, 66, 76, 73, 74, 81, 83, 82, 80, 88, 84, 82, 91, 93, 89))
#view first six rows of dataset
head(df)
  hours score
1     1    64
2     2    66
3     4    76
4     5    73
5     5    74
6     6    81
#attach dataset to make it more convenient to work with
attach(df)
</b>
<h3>Step 2: Visualize the Data</h3>
Before we fit a simple linear regression model, we should first visualize the data to gain an understanding of it.
First, we want to make sure that the relationship between <em>hours</em> and <em>score</em> is roughly linear, since that is a massive  underlying assumption  of simple linear regression. We can create a simple  scatterplot  to view the relationship between the two variables:
<b>scatter.smooth(hours, score, main='Hours studied vs. Exam Score')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegR1.png">
From the plot we can see that the relationship does appear to be linear. As <em>hours</em> increases, <em>score</em> tends to increase as well in a linear fashion.
Next, we can create a boxplot to visualize the distribution of exam scores and check for  outliers . By default, R defines an observation to be an outlier if it is 1.5 times the interquartile range greater than the third quartile (Q3) or 1.5 times the interquartile range less than the first quartile (Q1).
If an observation is an outlier, a tiny circle will appear in the boxplot:
<b>boxplot(score)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegR2.png">
There are no tiny circles in the boxplot, which means there are no outliers in our dataset.
<h3>Step 3: Perform Simple Linear Regression</h3>
Once we’ve confirmed that the relationship between our variables is linear and that there are no outliers present, we can proceed to fit a simple linear regression model using <em>hours</em> as the explanatory variable and <em>score</em> as the response variable:
<b>#fit simple linear regression model
model &lt;- lm(score~hours)
#view model summary
summary(model)
Call:
lm(formula = score ~ hours)
Residuals:
   Min     1Q Median     3Q    Max 
-5.140 -3.219 -1.193  2.816  5.772 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   65.334      2.106  31.023 1.41e-13 ***
hours          1.982      0.248   7.995 2.25e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 3.641 on 13 degrees of freedom
Multiple R-squared:  0.831,Adjusted R-squared:  0.818 
F-statistic: 63.91 on 1 and 13 DF,  p-value: 2.253e-06
</b>
From the model summary we can see that the fitted regression equation is:
<b>Score = 65.334 + 1.982*(hours)</b>
This means that each additional hour studied is associated with an average increase in exam score of <b>1.982</b> points. And the intercept value of <b>65.334</b> tells us the average expected exam score for a student who studies zero hours.
We can also use this equation to find the expected exam score based on the number of hours that a student studies. For example, a student who studies for 10 hours is expected to receive an exam score of <b>85.15</b>:
<b>Score = 65.334 + 1.982*(10) = 85.15</b>
Here is how to interpret the rest of the model summary:
<b>Pr(>|t|):</b> This is the p-value associated with the model coefficients. Since the p-value for <em>hours</em> (2.25e-06) is significantly less than .05, we can say that there is a statistically significant association between <em>hours</em> and <em>score</em>.
<b>Multiple R-squared:</b> This number tells us the percentage of the variation in the exam scores can be explained by the number of hours studied. In general, the larger the R-squared value of a regression model the better the explanatory variables are able to predict the value of the response variable. In this case, <b>83.1%</b> of the variation in scores can be explained hours studied.
<b>Residual standard error:</b> This is the average distance that the observed values fall from the regression line. The lower this value, the more closely a regression line is able to match the observed data. In this case, the average observed exam score falls <b>3.641</b> points away from the score predicted by the regression line.
<b>F-statistic & p-value:</b> The F-statistic (<b>63.91</b>) and the corresponding p-value (<b>2.253e-06</b>) tell us the overall significance of the regression model, i.e. whether explanatory variables in the model are useful for explaining the variation in the response variable. Since the p-value in this example is less than .05, our model is statistically significant and <em>hours</em> is deemed to be useful for explaining the variation in <em>score</em>.
<h3>Step 4: Create Residual Plots</h3>
After we’ve fit the simple linear regression model to the data, the last step is to create residual plots.
One of the key assumptions of linear regression is that the residuals of a regression model are roughly normally distributed and are  homoscedastic  at each level of the explanatory variable. If these assumptions are violated, then the results of our regression model could be misleading or unreliable.
To verify that these assumptions are met, we can create the following residual plots:
<b>Residual vs. fitted values plot:</b> This plot is useful for confirming homoscedasticity. The x-axis displays the fitted values and the y-axis displays the residuals. As long as the residuals appear to be randomly and evenly distributed throughout the chart around the value zero, we can assume that homoscedasticity is not violated:
<b>#define residuals
res &lt;- resid(model)
#produce residual vs. fitted plot
plot(fitted(model), res)
#add a horizontal line at 0 
abline(0,0)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegR3.png">
The residuals appear to be randomly scatted around zero and don’t exhibit any noticeable patterns, so this assumption is met.
<b>Q-Q plot:</b> This plot is useful for determining if the residuals follow a normal distribution. If the data values in the plot fall along a roughly straight line at a 45-degree angle, then the data is normally distributed:
<b>#create Q-Q plot for residuals
qqnorm(res)
#add a straight diagonal line to the plot
qqline(res) 
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/simpleRegR4.png">
The residuals stray from the 45-degree line a bit, but not enough to cause serious concern. We can assume that the normality assumption is met.
Since the residuals are normally distributed and homoscedastic, we’ve verified that the assumptions of the simple linear regression model are met. Thus, the output from our model is reliable.
<em>The complete R code used in this tutorial can be found  here .</em>
<h2><span class="orange">How to Perform Simple Linear Regression in SAS</span></h2>
 Simple linear regression  is a technique that we can use to understand the relationship between one predictor variable and a  response variable .
This technique finds a line that best “fits” the data and takes on the following form:
<b><U+0177> = b<sub>0</sub> + b<sub>1</sub>x</b>
where:
<b><U+0177></b>: The estimated response value
<b>b<sub>0</sub></b>: The intercept of the regression line
<b>b<sub>1</sub></b>: The slope of the regression line
This equation helps us understand the relationship between the predictor variable and the response variable.
The following step-by-step example shows how to perform simple linear regression in SAS.
<h3>Step 1: Create the Data</h3>
For this example, we’ll create a dataset that contains the total hours studied and final exam score for 15 students.
We’ll to fit a simple linear regression model using <em>hours</em> as the predictor variable and <em>score</em> as the response variable.
The following code shows how to create this dataset in SAS:
<b>/*create dataset*/
data exam_data;
    input hours score;
    datalines;
1 64
2 66
4 76
5 73
5 74
6 81
6 83
7 82
8 80
10 88
11 84
11 82
12 91
12 93
14 89
;
run;
/*view dataset*/
proc print data=exam_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/simpleSAS1.jpg"143">
<h3>Step 2: Fit the Simple Linear Regression Model</h3>
Next, we’ll use <b>proc reg</b> to fit the simple linear regression model:
<b>/*fit simple linear regression model*/
proc reg data=exam_data;
   model score = hours;
run;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/simpleSAS2.jpg">
Here’s how to interpret the most important values from each table in the output:
<b>Analysis of Variance Table:</b>
The overall  F-value  of the regression model is <b>63.91</b> and the corresponding p-value is <b>&lt;.0001</b>.
Since this p-value is less than .05, we conclude that the regression model as a whole is statistically significant. In other words, hours is a useful variable for predicting exam score.
<b>Model Fit Table:</b>
The R-Square value tells us the percentage of variation in the exam scores that can be explained by the number of hours studied.
In general, the larger the  R-squared value  of a regression model the better the predictor variables are able to predict the value of the response variable.
In this case, <b>83.1%</b> of the variation in exam scores can be explained by the number of hours studied. This value is quite high, which indicates that hours studied is a highly useful variable for predicting exam score.
<b>Parameter Estimates Table:</b>
From this table we can see the fitted regression equation:
<b>Score = 65.33 + 1.98*(hours)</b>
We interpret this to mean that each additional hour studied is associated with an average increase of <b>1.98 points</b> in exam score.
The intercept value tells us that the average exam score for a student who studies zero hours is <b>65.33</b>.
We can also use this equation to find the expected exam score based on the number of hours that a student studies.
For example, a student who studies for 10 hours is expected to receive an exam score of <b>85.13</b>:
<b>Score = 65.33 + 1.98*(10) = 85.13</b>
Since the p-value (&lt;.0001) for <em>hours</em> is less than .05 in this table, we conclude that it’s a statistically significant predictor variable.
<h3>Step 3: Analyze the Residual Plots</h3>
Simple linear regression makes two important  assumptions  about the  residuals  of the model:
The residuals are normally distributed.
The residuals have equal variance (“ homoscedasticity “) at each level of the predictor variable.
If these assumptions are violated, then the results of our regression model can be unreliable.
To verify that these assumptions are met, we can analyze the residual plots that SAS automatically in the output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/simpleSAS3.jpg"663">
To verify that the residuals are <b>normally distributed</b>, we can analyze the plot in the left position of the middle row with “Quantile” along the x-axis and “Residual” along the y-axis.
This plot is called a  Q-Q plot , short for “quantile-quantile” plot, and is used to determine whether or not data is normally distributed. If the data is normally distributed, the points in a Q-Q plot will lie on a straight diagonal line.
From the plot we can see that the points fall roughly along a straight diagonal line, so we can assume that the residuals are normally distributed.
Next, to verify that the residuals are <b>homoscedastic</b> we can look at the plot in the left position of the first row with “Predicted Value” along the x-axis and “Residual” along the y-axis.
If the points in the plot are scattered randomly about zero with no clear pattern then we can assume that the residuals are homoscedastic.
From the plot we can see that the points are scattered about zero randomly with roughly equal variance at each level throughout the plot so we can assume that the residuals are homoscedastic.
Since both assumptions are met, we can assume that the results of the simple linear regression model are reliable.
<h2><span class="orange">How to Perform Simple Linear Regression in SPSS</span></h2>
<b> Simple linear regression  </b>is a method we can use to understand the relationship between a predictor variable and a response variable.
This tutorial explains how to perform simple linear regression in SPSS.
<h3>Example: Simple Linear Regression in SPSS</h3>
Suppose we have the following dataset that shows the number of hours studied and the exam score received by 20 students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS0.png">
Use the following steps to perform simple linear regression on this dataset to quantify the relationship between hours studied and exam score:
<b>Step 1: Visualize the data.</b>
First, we’ll create a scatterplot to visualize the relationship between hours and score to make sure that the relationship between the two variables appears to be linear. Otherwise, simple linear regression won’t be an appropriate technique to use.
Click the <b>Graphs</b> tab, then click <b>Chart Builder</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS1.png">
In the <b>Choose from </b>menu, click and drag <b>Scatter/Dot </b>into the main editing window. Then drag the variable <b>hours </b>onto the x-axis and <b>score </b>onto the y-axis.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS2.png">
Once you click <b>OK</b>, the following scatterplot will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS3.png">
From the plot we can see that there is a positive linear relationship between hours and score. In general, students who study for more hours tend to get higher scores.
Since there’s a clear linear relationship between the two variables, we’ll proceed to fit a simple linear regression model to the dataset.
<b>Step 2: Fit a simple linear regression model.</b>
Click the <b>Analyze </b>tab, then <b>Regression</b>, then <b>Linear</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS4.png">
In the new window that pops up, drag the variable <b>score </b>into the box labelled Dependent and drag <b>hours </b>into the box labelled Independent. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS5.png">
<b>Step 3: Interpret the results.</b>
Once you click <b>OK</b>, the results of the simple linear regression will appear. The first table we’re interested in is the one titled <b>Model Summary</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS6.png">
Here is how to interpret the most relevant numbers in this table:
<b>R Square: </b>This is the proportion of the variance in the response variable that can be explained by the explanatory variable. In this example, <b>50.6%</b> of the variation in exam scores can be explained by hours studied.
<b>Std. Error of the Estimate: </b>The  standard error  is the average distance that the observed values fall from the regression line. In this example, the observed values fall an average of <b>5.861</b> units from the regression line.
The next table we’re interested in is titled <b>Coefficients</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/simpRegSPSS7.png">
Here is how to interpret the most relevant numbers in this table:
<b>Unstandardized B (Constant)</b>: This tells us the average value of the response variable when the predictor variable is zero. In this example, the average exam score is <b>73.662 </b>when hours studied is equal to zero.
<b>Unstandardized B (hours): </b>This tells us the average change in the response variable associated with a one unit increase in the predictor variable. In this example, each additional hour studied is associated with an increase of <b>3.342</b> in exam score, on average.
<b>Sig (hours): </b> This is the p-value associated with the test statistic for hours. In this case, since this value is less than 0.05, we can conclude that the predictor variable <b>hours </b>is statistically significant. 
Lastly, we can form a regression equation using the values for <b>constant </b>and <b>hours</b>. In this case, the equation would be:
Estimated exam score = 73.662 + 3.342*(hours)
We can use this equation to find the estimated exam score for a student, based on the number of hours they studied. For example, a student that studies for 3 hours is expected to receive an exam score of 83.688:
Estimated exam score = 73.662 + 3.342*(3) = 83.688
<b>Step 4: Report the results.</b>
Lastly, we want to summarize the results of our simple linear regression. Here’s an example of how to do so:
A simple linear regression was performed to quantify the relationship between hours studied and exam score received. A sample of 20 students was used in the analysis.
 
Results showed that there was a statistically significant relationship between hours studied and exam score (t = 4.297, p &lt; 0.000) and hours studied accounted for 50.6% of explained variability in exam score.
 
The regression equation was found to be:
 
Estimated exam score = 73.662 + 3.342*(hours)
 
Each additional hour studied is associated with an increase of <b>3.342</b> in exam score, on average.
<h2><span class="orange">How to Perform Simple Linear Regression in Stata</span></h2>
<b> Simple linear regression  </b>is a method you can use to understand the relationship between an explanatory variable, x, and a response variable, y.
This tutorial explains how to perform simple linear regression in Stata.
<h2>Example: Simple Linear Regression in Stata</h2>
Suppose we are interested in understanding the relationship between the weight of a car and its miles per gallon. To explore this relationship, we can perform simple linear regression using weight as an explanatory variable and miles per gallon as a response variable.
Perform the following steps in Stata to conduct a simple linear regression using the dataset called <em>auto</em>, which contains data on 74 different cars.
<b>Step 1: Load the data.</b>
Load the data by typing the following into the Command box:
<b> use http://www.stata-press.com/data/r13/auto</b>
<b>Step 2: Get a summary of the data.</b>
Gain a quick understanding of the data you’re working with by typing the following into the Command box:
<b>summarize</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionStata1.png">
We can see that there are 12 different variables in the dataset, but the only two that we care about are <em>mpg </em>and <em>weight</em>.
<b>Step 3: Visualize the data.</b>
Before we perform simple linear regression, let’s first create a  scatterplot  of weight vs. mpg so we can visualize the relationship between these two variables and check for any obvious outliers. Type the following into the Command box to create a scatterplot:
<b>scatter mpg weight</b>
This produces the following scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionStata2.png">
We can see that cars with higher weights tend to have lower miles per gallon. To quantify this relationship, we will now perform a simple linear regression.
<b>Step 4: Perform simple linear regression.</b>
Type the following into the Command box to perform a simple linear regression using weight as an explanatory variable and mpg as a response variable.
<b>regress mpg weight</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionStata3.png">
Here is how to interpret the most interesting numbers in the output:
<b>R-squared:</b> 0.6515. This is the proportion of the variance in the response variable that can be explained by the explanatory variable. In this example, 65.15% of the variation in mpg can be explained by weight.
<b>Coef (weight): </b>-0.006. This tells us the average change in the response variable associated with a one unit increase in the explanatory variable. In this example, each one pound increase in weight is associated with a decrease of 0.006 in mpg, on average.
<b>Coef (_cons): </b>39.44028. This tells us the average value of the response variable when the explanatory variable is zero. In this example, the average mpg is 39.44028 when the weight of a car is zero. This doesn’t actually make much sense to interpret since the weight of a car can’t be zero, but the number 39.44028 is needed to form a regression equation.
<b>P>|t| (weight): </b>0.000. This is the p-value associated with the test statistic for weight. In this case, since this value is less than 0.05, we can conclude that there is a statistically significant relationship between weight and mpg.
<b>Regression Equation: </b>Lastly, we can form a regression equation using the two coefficient values. In this case, the equation would be:
predicted mpg = 39.44028 – 0.0060087*(weight)
We can use this equation to find the predicted mpg for a car, given its weight. For example, a car that weighs 4,000 pounds is predicted to have mpg of 15.405:
predicted mpg = 39.44028 – 0.0060087*(4000) = 15.405
<b>Step 5: Report the results.</b>
Lastly, we want to report the results of our simple linear regression. Here is an example of how to do so:
A linear regression was performed to quantify the relationship between the weight of a car and its miles per gallon. A sample of 74 cars was used in the analysis.
 
Results showed that there was a statistically significant relationship between weight and mpg (t = -11.60, p &lt; 0.0001) and weight accounted for 65.15% of explained variability in mpg. 
 
The regression equation was found to be:
 
predicted mpg =  39.44 – 0.006(weight)
 
Each additional pound was associated with a decrease, on average, of -.006 miles per gallon.
<h2><span class="orange">Simpson’s Diversity Index Calculator</span></h2>
</style>
<b> Simpson’s Diversity Index </b> is a way to measure the diversity of species in a community.
To calculate this index for a given community, simply enter a list of observed frequencies for up to 10 species in the boxes below, then click the “Calculate” button:
<table><tbody>
<tr>
<th><b>Species</b></th>
<th><b><span>Frequency</b></th>
</tr>
<tr>
<td>Species #1</td>
<td><input type="text" id="o1" value="80"></td>
</tr>
<tr>
<td>Species #2</td>
<td><input type="text" id="o2" value="125"></td>
</tr>
<tr>
<td>Species #3</td>
<td><input type="text" id="o3" value="95"></td>
</tr>
<tr>
<td>Species #4</td>
<td><input type="text" id="o4"></td>
</tr>
<tr>
<td>Species #5</td>
<td><input type="text" id="o5"></td>
</tr>
<tr>
<td>Species #6</td>
<td><input type="text" id="o6"></td>
</tr>
<tr>
<td>Species #7</td>
<td><input type="text" id="o7"></td>
</tr>
<tr>
<td>Species #8</td>
<td><input type="text" id="o8"></td>
</tr>
<tr>
<td>Species #9</td>
<td><input type="text" id="o9"></td>
</tr>
<tr>
<td>Species #10</td>
<td><input type="text" id="o10"></td>
</tr>
</tbody></table>
<input type="button" id="button" onclick="calc()" value="Calculate">
Simpson’s Diversity Index (D): <b>0.343</b>
Dominance Index (1 – D): <b>0.657</b>
Simpson’s Reciprocal Index (1 / D): <b>2.917</b>
<script>
function calc() {
//get input data
var o1 = +document.getElementById('o1').value;
var o2 = +document.getElementById('o2').value;
var o3 = +document.getElementById('o3').value;
var o4 = +document.getElementById('o4').value;
var o5 = +document.getElementById('o5').value;
var o6 = +document.getElementById('o6').value;
var o7 = +document.getElementById('o7').value;
var o8 = +document.getElementById('o8').value;
var o9 = +document.getElementById('o9').value;
var o10 = +document.getElementById('o10').value;
var obs = [o1, o2, o3, o4, o5, o6, o7, o8, o9, o10];
var empties = obs.filter(x => x==0).length;
var n = obs.reduce((a, b) => a + b, 0);
//do calculations
var diff1 = 0;
if (o1) {
diff1 = o1*(o1-1);
}
var diff2 = 0;
if (o2) {
diff2 = o2*(o2-1);
}
var diff3 = 0;
if (o3) {
diff3 = o3*(o3-1);
}
var diff4 = 0;
if (o4) {
diff4 = o4*(o4-1);
}
var diff5 = 0;
if (o5) {
diff5 = o5*(o5-1);
}
var diff6 = 0;
if (o6) {
diff6 = o6*(o6-1);
}
var diff7 = 0;
if (o7) {
diff7 = o7*(o7-1);
}
var diff8 = 0;
if (o8) {
diff8 = o8*(o8-1);
}
var diff9 = 0;
if (o9) {
diff9 = o9*(o9-1);
}
var diff10 = 0;
if (o10) {
diff10 = o10*(o10-1);
}
var errors = [diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9, diff10];
var summer = math.sum(errors);
var D = summer / (n*(n-1));
var D1 = 1-D;
var R = 1/D;
//output results
document.getElementById('D').innerHTML = D.toFixed(3);
document.getElementById('D1').innerHTML = D1.toFixed(3);
document.getElementById('R').innerHTML = R.toFixed(3);
  
} //end calc function
</script>
<h2><span class="orange">Simpson’s Diversity Index: Definition & Examples</span></h2>
<b>Simpson’s Diversity Index</b> is a way to measure the diversity of species in a community.
Denoted as <em>D</em>, this index is calculated as:
<b><em>D</em> = Σn<sub>i</sub>(n<sub>i</sub>-1)  /  N(N-1)</b>
where:
<b>n<sub>i</sub>:</b> The number of organisms that belong to species <em>i</em>
<b>N:</b> The total number of organisms
The value for Simpson’s Diversity Index ranges between 0 and 1. The higher the value, the lower the diversity. 
Since this interpretation is a bit counterintuitive, we often calculate <b>Simpson’s Index of Diversity</b> (sometimes called a Dominance Index), which is calculated as 1 – D. The higher the value for this index, the higher the diversity of species.
We can also calculate <b>Simpson’s Reciprocal Index</b>, which is calculated as 1/D. The lowest value for this index is 1 and the highest value is equal to the number of species.
For example, if there are 7 different species then the max value for this index would be 7. The higher the value for this index, the greater the diversity of the species.
The following step-by-step example shows how to calculate these various indices for a given community.
<h3>Step 1: Collect the Data</h3>
Suppose a biologist wants to measure the diversity of species in a local forest. She collects the following data: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/shannon1.png">
<h3>Step 2: Calculate N</h3>
Next, she can calculate the total number of organisms.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/simpson1.png">
There are <b>105</b> total organims.
<h3>Step 3: Calculate n<sub>i</sub>(n<sub>i</sub>-1)</h3>
Next, she can calculate n<sub>i</sub>(n<sub>i</sub>-1). For example, the first species  would be calculated as 40*(40-1) = 1,560. She can repeat this calculation for each species:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/simpson2.png">
<h3>Step 4: Calculate Simpson’s Diversity Index</h3>
Lastly, we can use the following formula to calculate Simpson’s Index:
<b><em>D</em> = Σn<sub>i</sub>(n<sub>i</sub>-1) / N(N-1)</b>
Using the values we found earlier, <b>Simpson’s Index</b> can be calculated as:
<em>D</em> = 2,668 / (105*(105-1)) = <b>0.244</b>.
We can also calculate <b>Simpson’s Index of Diversity</b> as 1 – <em>D</em> = 1 – 0.244 = <b>0.756</b>.
We can also calculate <b>Simpson’s Reciprocal Index</b> as 1 / <em>D</em> = 1 / .244 = <b>4.09</b>.
<h2><span class="orange">Skewness and Kurtosis Calculator</span></h2>
<b>Skewness</b> is a measure of the asymmetry of a dataset or distribution. This value can be positive or negative. A negative skew typically indicates that the <i>tail</i> is on the left side of the distribution. A positive value typically indicates that the tail is on the right.
<b>Kurtosis</b> is simply a measure of the “tailedness” of a dataset or distribution. The kurtosis formula used by this calculator is identical to the formula used in Excel, which finds what is known as <i>excess kurtosis</i>.
To find the skewness and kurtosis of a dataset, simply enter the comma-separated values in the box below, then click the “Calculate” button.
<textarea id="input_data" name="input_data" rows="5" cols="40"></textarea>
<input type="button" id="button" onclick="calc()" value="Calculate">
<div>
<div>
<script>
//define addition function
function add(a, b) {
    return a + b;
}
//create function that performs t test calculations
function calc() {
//get user input data
var input_data = document.getElementById('input_data').value.match(/\d+/g).map(Number);
//find summary statistics
var n = input_data.length;
var total_mean = math.mean(input_data);
var total_var = math.var(input_data)
var total_sd = Math.sqrt(total_var);
//calculate skewness
var term1 = n / ( (n-1)*(n-2) );
var term2 = (input_data.map(function(x) { return Math.pow((x-total_mean) / total_sd, 3); })).reduce(add, 0)
var skewness = term1 * term2;
//calculate kurtosis
var term1 = ( n*(n+1) ) / ( (n-1)*(n-2)*(n-3) );
var term2 = ( (input_data.map(function(x) { return Math.pow(x-total_mean, 4); })).reduce(add, 0) ) / ( Math.pow(total_var, 2) );
var term3 = ( 3 * (Math.pow(n-1, 2)) ) / ( (n-2)*(n-3) );
var kurtosis = term1 * term2 - term3;
//output results 
document.getElementById('skewness').innerHTML = "Skewness: " + skewness.toFixed(5);
document.getElementById('kurtosis').innerHTML = "Kurtosis: " + kurtosis.toFixed(5);
}
</script>
<h2><span class="orange">How to Calculate Skewness in Excel</span></h2>
<b>Skewness</b> is a measure of the asymmetry of a dataset or distribution. This value can be positive or negative. It’s useful to know because it helps us understand the shape of a distribution.
A negative skew indicates that the tail is on the left side of the distribution, which extends towards more negative values.
A positive skew indicates that the tail is on the right side of the distribution, which extends towards more positive values.
A value of zero indicates that there is no skewness in the distribution at all, meaning the distribution is perfectly symmetrical. This is unusual and rarely occurs in practice.
<h2>How to Calculate Skewness in Excel</h2>
Excel offers the following built-in function to calculate the skewness of a distribution:
<b>=SKEW(array of values)</b>
This function uses the following formula to calculate skewness:
Skewness = [n/(n-1)(n-2)] * Σ[(x<sub>i</sub>–x)/s]<sup>3</sup>
where:
n = sample size
Σ = fancy symbol that means “sum”
x<sub>i </sub>= the value of the i<sup>th</sup> value in the dataset
x = mean
s = standard deviation
The formula is a bit complex, but luckily Excel performs this calculation for you so that you don’t have to do it manually.
<h3>Example: Calculating Skewness in Excel</h3>
Suppose we have the following dataset that contains the exam scores of 20 students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/skewExcel0.png">
We can calculate the skewness of the distribution using <b>=SKEW(A2:A21)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/skewExcel1.png">
This tells us that the skewness of this dataset is <b>-0.1849</b>. Since this value is negative, we know that the tail of the distribution extends towards the left. 
<b>Technical Note:</b>
 
The SKEW() function will return the error #DIV/0! in the following two scenarios:
 
If there are fewer than three data points
If the sample standard deviation is zero
<h2>Additional Resource: Skewness & Kurtosis Calculator</h2>
You can also calculate the skewness for a given dataset using the  Statology Skewness and Kurtosis Calculator , which automatically calculates both the skewness and kurtosis for a given dataset. You simply enter the raw data values for your dataset into the input box, then click “Calculate.”
For example, here is how to calculate the skewness for the dataset from the example above:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/skewExcel2.png">
Note that the skewness value from the calculator matches the skewness value that we found in Excel.
<h2><span class="orange">How to Interpret Skewness in Statistics (With Examples)</span></h2>
In the field of statistics, we use <b>skewness </b>to describe the symmetry of a distribution.
We say that a distribution of data values is <b>left skewed</b> if it has a “tail” on the left side of the distribution:
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew2.png">
We say that a distribution is <b>right skewed</b> if it has a “tail” on the right side of the distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew1.png">
And we say a distribution has <b>no skew</b> if it’s symmetrical on both sides:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew3.png">
<h2>How to Interpret Skewness</h2>
The value for skewness can range from negative infinity to positive infinity.
Here’s how to interpret skewness values:
A <b>negative value</b> for skewness indicates that the tail is on the left side of the distribution, which extends towards more negative values.
A <b>positive value</b> for skewness indicates that the tail is on the right side of the distribution, which extends towards more positive values.
A <b>value of zero</b> indicates that there is no skewness in the distribution at all, meaning the distribution is perfectly symmetrical.
The following examples show how to interpret skewness values in practice.
<h3>Example 1: Left-Skewed Distribution</h3>
The distribution of the age of deaths in most populations is left-skewed. Most people live to be between 70 and 80 years old, with fewer and fewer living less than this age.
If we created a  density plot  to visualize the distribution of values for age of death, it might look something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew9.png">
Suppose we calculate the skewness for this distribution and find that it is <b>-1.3225</b>.
Since this value is negative, we interpret this to mean that the distribution is left-skewed, which means the tail extends to the left side of the distribution.
<h3>Example 2: Right-Skewed Distribution</h3>
The distribution of household incomes in the U.S. is right-skewed, with most households earning between $30k and $70k per year but with a long right tail of households that earn much more.
If we created a density plot to visualize the distribution of values for household income, it might look something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew10.png">
Suppose we calculate the skewness for this distribution and find that it is <b>2.0043</b>.
Since this value is positive, we interpret this to mean that the distribution is right-skewed, which means the tail extends to the right side of the distribution.
<h3>Example 3: No Skew</h3>
The height of males is roughly normally distributed and has no skew. For example, the average height of a male in the U.S. is roughly 69.1 inches. The distribution of heights is roughly symmetrical, with some being shorter and some being taller.
If we created a density plot to visualize the distribution of male heights in the U.S. it might look something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew8.png">
Suppose we calculate the skewness for this distribution and find that it is <b>0.0013</b>.
Since this value is close to zero, we interpret this to mean that the distribution has basically no skew, which means the tails on either side of the distribution are about equal.
<h2><span class="orange">How to Calculate Skewness & Kurtosis in Google Sheets</span></h2>
In statistics, <b>skewness </b>and <b>kurtosis </b>are two ways to measure the shape of a distribution.
<b>Skewness </b>is a measure of the asymmetry of a distribution. This value can be positive or negative.
A negative skew indicates that the tail is on the left side of the distribution, which extends towards more negative values.
A positive skew indicates that the tail is on the right side of the distribution, which extends towards more positive values.
A value of zero indicates that there is no skewness in the distribution at all, meaning the distribution is perfectly symmetrical.
<b>Kurtosis </b>is a measure of whether or not a distribution is heavy-tailed or light-tailed relative to a  normal distribution .
The kurtosis of a normal distribution is 3.
If a given distribution has a kurtosis less than 3, it is said to be <em>playkurtic</em>, which means it tends to produce fewer and less extreme outliers than the normal distribution.
If a given distribution has a kurtosis greater than 3, it is said to be <em>leptokurtic</em>, which means it tends to produce more outliers than the normal distribution.
This tutorial explains how to calculate both the skewness and kurtosis of a given dataset in Google Sheets.
<h3>Example: Skewness & Kurtosis in Google Sheets</h3>
Suppose we have the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/skew_kurt_sheets1-1.png">
To calculate the skewness and kurtosis of this dataset, we can use the <b>SKEW()</b> and <b>KURT()</b> functions with the following syntax:
<b>SKEW(Array of values)</b>
<b>KURT(Array of values)</b>
It’s important to note that either function will return the error <b>#DIV/0!</b> in the following two scenarios:
If there are fewer than three data points.
If the sample standard deviation is zero.
The image below shows how to use these functions for our particular dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/skew_kurt_sheets2.png">
The skewness turns out to be <b>-0.18490</b> and the kurtosis turns out to be <b>0.34624</b>.
<h3>Additional Resource: Skewness & Kurtosis Calculator</h3>
You can also calculate the skewness for a given dataset using the  Statology Skewness and Kurtosis Calculator , which automatically calculates both the skewness and kurtosis for a given dataset. 
<h2><span class="orange">How to Calculate Skewness & Kurtosis in R</span></h2>
In statistics, <b>skewness </b>and <b>kurtosis </b>are two ways to measure the shape of a distribution.
<b>Skewness </b>is a measure of the asymmetry of a distribution. This value can be positive or negative.
A negative skew indicates that the tail is on the left side of the distribution, which extends towards more negative values.
A positive skew indicates that the tail is on the right side of the distribution, which extends towards more positive values.
A value of zero indicates that there is no skewness in the distribution at all, meaning the distribution is perfectly symmetrical.
<b>Kurtosis </b>is a measure of whether or not a distribution is heavy-tailed or light-tailed relative to a  normal distribution .
The kurtosis of a normal distribution is 3.
If a given distribution has a kurtosis less than 3, it is said to be <em>playkurtic</em>, which means it tends to produce fewer and less extreme outliers than the normal distribution.
If a given distribution has a kurtosis greater than 3, it is said to be <em>leptokurtic</em>, which means it tends to produce more outliers than the normal distribution.
<b>Note: </b>Some formulas (Fisher’s definition) subtract 3 from the kurtosis to make it easier to compare with the normal distribution. Using this definition, a distribution would have kurtosis greater than a normal distribution if it had a kurtosis value greater than 0.
This tutorial explains how to calculate both the skewness and kurtosis of a given dataset in R.
<h3>Example: Skewness & Kurtosis in R</h3>
Suppose we have the following dataset:
<b>data = c(88, 95, 92, 97, 96, 97, 94, 86, 91, 95, 97, 88, 85, 76, 68)
</b>
We can quickly visualize the distribution of values in this dataset by creating a histogram:
<b>hist(data, col='steelblue')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/skewR1.png">
From the histogram we can see that the distribution appears to be left-skewed. That is, more of the values are concentrated on the right side of the distribution.
To calculate the skewness and kurtosis of this dataset, we can use <b>skewness() </b>and <b>kurtosis() </b>functions from the <b>moments </b>library in R:
<b>library(moments)
#calculate skewness
skewness(data)
[1] -1.391777
#calculate kurtosis
kurtosis(data)
[1] 4.177865
</b>
The skewness turns out to be <b>-1.391777</b> and the kurtosis turns out to be <b>4.177865</b>.
Since the skewness is negative, this indicates that the distribution is left-skewed. This confirms what we saw in the histogram. 
Since the kurtosis is greater than 3, this indicates that the distribution has more values in the tails compared to a normal distribution.
The <b>moments</b> library also offers the <b>jarque.test()</b> function, which performs a goodness-of-fit test that determines whether or not sample data have skewness and kurtosis that matches a normal distribution. The null and alternative hypotheses of this test are as follows:
<b>Null Hypothesis</b>: The dataset has a skewness and kurtosis that matches a normal distribution.
<b>Alternative Hypothesis</b>: The dataset has a skewness and kurtosis that <em>does not</em> match a normal distribution.
The following code shows how to perform this test:
<b>jarque.test(data)
Jarque-Bera Normality Test
data:  data
JB = 5.7097, p-value = 0.05756
alternative hypothesis: greater
</b>
The p-value of the test turns out to be <b>0.05756</b>. Since this value is not less than α = .05, we fail to rejec the null hypothesis. We do not have sufficient evidence to say that this dataset has a skewness and kurtosis that is different from the normal distribution. 
<em>You can find the complete documentation for the <b>moments</b> library  here .</em>
<h3>Bonus: Skewness & Kurtosis Calculator</h3>
You can also calculate the skewness for a given dataset using the  Statology Skewness and Kurtosis Calculator , which automatically calculates both the skewness and kurtosis for a given dataset. 
<h2><span class="orange">How to Calculate Skewness & Kurtosis in Python</span></h2>
In statistics, <b>skewness </b>and <b>kurtosis </b>are two ways to measure the shape of a distribution.
<b>Skewness </b>is a measure of the asymmetry of a distribution. This value can be positive or negative.
A negative skew indicates that the tail is on the left side of the distribution, which extends towards more negative values.
A positive skew indicates that the tail is on the right side of the distribution, which extends towards more positive values.
A value of zero indicates that there is no skewness in the distribution at all, meaning the distribution is perfectly symmetrical.
<b>Kurtosis </b>is a measure of whether or not a distribution is heavy-tailed or light-tailed relative to a  normal distribution .
The kurtosis of a normal distribution is 3.
If a given distribution has a kurtosis less than 3, it is said to be <em>playkurtic</em>, which means it tends to produce fewer and less extreme outliers than the normal distribution.
If a given distribution has a kurtosis greater than 3, it is said to be <em>leptokurtic</em>, which means it tends to produce more outliers than the normal distribution.
<b>Note: </b>Some formulas (Fisher’s definition) subtract 3 from the kurtosis to make it easier to compare with the normal distribution. Using this definition, a distribution would have kurtosis greater than a normal distribution if it had a kurtosis value greater than 0.
This tutorial explains how to calculate both the skewness and kurtosis of a given dataset in Python.
<h3>Example: Skewness & Kurtosis in Python</h3>
Suppose we have the following dataset:
<b>data = [88, 85, 82, 97, 67, 77, 74, 86, 81, 95, 77, 88, 85, 76, 81]
</b>
To calculate the sample skewness and sample kurtosis of this dataset, we can use the  skew()  and  kurt()  functions from the Scipy Stata librarywith the following syntax:
<b>skew(array of values, bias=False)</b>
<b>kurt(array of values, bias=False)</b>
We use the argument <b>bias=False </b>to calculate the sample skewness and kurtosis as opposed to the population skewness and kurtosis.
Here is how to use these functions for our particular dataset:
<b>data = [88, 85, 82, 97, 67, 77, 74, 86, 81, 95, 77, 88, 85, 76, 81]
#calculate sample skewness
skew(data, bias=False)
0.032697
#calculate sample kurtosis
kurtosis(data, bias=False)
0.118157
</b>
The skewness turns out to be <b>0.032697</b> and the kurtosis turns out to be <b>0.118157</b>.
This means the distribution is slightly positively skewed and the distribution has more values in the tails compared to a normal distribution.
<h3>Additional Resource: Skewness & Kurtosis Calculator</h3>
You can also calculate the skewness for a given dataset using the  Statology Skewness and Kurtosis Calculator , which automatically calculates both the skewness and kurtosis for a given dataset. 
<h2><span class="orange">How to Interpret the Classification Report in sklearn (With Example)</span></h2>
When using  classification models  in machine learning, there are three common metrics that we use to assess the quality of the model:
<b>1. Precision</b>: Percentage of correct positive predictions relative to total positive predictions.
<b>2. Recall</b>: Percentage of correct positive predictions relative to total actual positives.
<b>3. F1 Score</b>: A weighted harmonic mean of precision and recall. The closer to 1, the better the model.
F1 Score: 2 * (Precision * Recall) / (Precision + Recall)
Using these three metrics, we can understand how well a given classification model is able to predict the outcomes for some  response variable .
Fortunately, when fitting a classification model in Python we can use the <b>classification_report()</b> function from the <b>sklearn</b> library to generate all three of these metrics.
The following example shows how to use this function in practice.
<h3>Example: How to Use the Classification Report in sklearn</h3>
For this example, we’ll fit a logistic regression model that uses points and assists to predict whether or not 1,000 different college basketball players get drafted into the NBA. 
First, we’ll import the necessary packages to perform logistic regression in Python:
<b>import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report</b>
Next, we’ll create the data frame that contains the information on 1,000 basketball players:
<b>#make this example reproducible
np.random.seed(1)
#create DataFrame
df = pd.DataFrame({'points': np.random.randint(30, size=1000),   'assists': np.random.randint(12, size=1000),   'drafted': np.random.randint(2, size=1000)})
#view DataFrame
df.head()
pointsassistsdrafted
0511
11180
21241
3870
4900
</b>
<b>Note</b>: A value of <b>0</b> indicates that a player did not get drafted while a value of <b>1</b> indicates that a player did get drafted.
Next, we’ll split our data into a training set and testing set and fit the logistic regression model:
<b>#define the predictor variables and the response variable
X = df[['points', 'assists']]
y = df['drafted']
#split the dataset into training (70%) and testing (30%) sets
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)  
#instantiate the model
logistic_regression = LogisticRegression()
#fit the model using the training data
logistic_regression.fit(X_train,y_train)
#use model to make predictions on test data
y_pred = logistic_regression.predict(X_test)</b>
Lastly, we’ll use the <b>classification_report()</b> function to print the classification metrics for our model:
<b>#print classification report for model
print(classification_report(y_test, y_pred))
              precision    recall  f1-score   support
           0       0.51      0.58      0.54       160
           1       0.43      0.36      0.40       140
    accuracy                           0.48       300
   macro avg       0.47      0.47      0.47       300
weighted avg       0.47      0.48      0.47       300
</b>
Here’s how to interpret the output:
<b>Precision</b>: Out of all the players that the model predicted would get drafted, only <b>43%</b> actually did.
<b>Recall</b>: Out of all the players that actually did get drafted, the model only predicted this outcome correctly for <b>36%</b> of those players.
<b>F1 Score</b>: This value is calculated as:
F1 Score: 2 * (Precision * Recall) / (Precision + Recall)
F1 Score: 2 * (.43 * .36) / (.43 + .36)
F1 Score: <b>0.40</b>.
Since this value isn’t very close to 1, it tells us that the model does a poor job of predicting whether or not players will get drafted.
<b>Support</b>: These values simply tell us how many players belonged to each class in the test dataset. We can see that among the players in the test dataset, <b>160</b> did not get drafted and <b>140</b> did get drafted.
<b>Note</b>: You can find the complete documentation for the <b>classification_report()</b> function  here .
<h2><span class="orange">Scikit-Learn: Use Label Encoding Across Multiple Columns</span></h2>
In machine learning, <b>label encoding</b> is the process of converting the values of a  categorical variable  into integer values.
For example, the following screenshot shows how to convert each unique value in a categorical variable called <b>Team</b> into an integer value based on alphabetical order:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/labelencode2-1.jpg"467">
You can use the following syntax to perform label encoding across multiple columns in Python:
<b>from sklearn.preprocessing import LabelEncoder
#perform label encoding on col1, col2 columns
df[['col1', 'col2']] = df[['col1', 'col2']].apply(LabelEncoder().fit_transform)
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Label Encoding in Python</h2>
Suppose we have the following pandas DataFrame that contains information about various basketball players:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'D'],   'position': ['G', 'F', 'G', 'F', 'F', 'G', 'G', 'F'],   'all_star': ['Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N'],   'points': [11, 8, 10, 6, 6, 5, 9, 12]})
#view DataFrame
print(df)
  team position all_star  points
0    A        G        Y      11
1    A        F        N       8
2    B        G        Y      10
3    B        F        Y       6
4    B        F        Y       6
5    C        G        N       5
6    C        G        Y       9
7    D        F        N      12
</b>
We can use the following code to perform label encoding to convert each categorical value in the <b>team</b>, <b>position</b>, and <b>all_star</b> columns into integer values:
<b>from sklearn.preprocessing import LabelEncoder
#perform label encoding across team, position, and all_star columns
df[['team', 'position', 'all_star']] = df[['team', 'position', 'all_star']].apply(LabelEncoder().fit_transform)
#view udpated DataFrame
print(df)
   team  position  all_star  points
0     0         1         1      11
1     0         0         0       8
2     1         1         1      10
3     1         0         1       6
4     1         0         1       6
5     2         1         0       5
6     2         1         1       9
7     3         0         0      12</b>
From the output we can see that each value in the <b>team</b>, <b>position</b>, and <b>all_star</b> columns have been converted into integer values.
For example, in the <b>team</b> column we can see:
Each “A” value has been converted to <b>0</b>.
Each “B” value has been converted to <b>1</b>.
Each “C” value has been converted to <b>2</b>.
Each “D” value has been converted to <b>3</b>.
Note that in this example we performed label encoding on three columns in the DataFrame, but we can use similar syntax to perform label encoding on as many categorical columns as we’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Python:
 How to Convert Categorical Variable to Numeric in Pandas 
 How to Convert Boolean Values to Integer Values in Pandas 
 How to Use factorize() to Encode Strings as Numbers in Pandas 
<h2><span class="orange">How to Get Regression Model Summary from Scikit-Learn</span></h2>
Often you may want to extract a summary of a regression model created using  scikit-learn  in Python.
Unfortunately, scikit-learn doesn’t offer many built-in functions to analyze the summary of a regression model since it’s typically only used for  predictive purposes .
So, if you’re interested in getting a summary of a regression model in Python, you have two options:
<b>1.</b> Use limited functions from scikit-learn.
<b>2.</b> Use  statsmodels  instead.
The following examples show how to use each method in practice with the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'x1': [1, 2, 2, 4, 2, 1, 5, 4, 2, 4, 4],   'x2': [1, 3, 3, 5, 2, 2, 1, 1, 0, 3, 4],   'y': [76, 78, 85, 88, 72, 69, 94, 94, 88, 92, 90]})
#view first five rows of DataFrame
df.head()
       x1      x2 y
01176
12378
22385
34588
42272
</b>
<h3>Method 1: Get Regression Model Summary from Scikit-Learn</h3>
We can use the following code to fit a  multiple linear regression  model using scikit-learn:
<b>from sklearn.linear_model import LinearRegression
#initiate linear regression model
model = LinearRegression()
#define predictor and response variables
X, y = df[['x1', 'x2']], df.y
#fit regression model
model.fit(X, y)
</b>
We can then use the following code to extract the regression coefficients of the model along with the  R-squared value  of the model:
<b>#display regression coefficients and R-squared value of model
print(model.intercept_, model.coef_, model.score(X, y))
70.4828205704 [ 5.7945 -1.1576] 0.766742556527
</b>
Using this output, we can write the equation for the fitted regression model:
y = 70.48 + 5.79x<sub>1</sub> – 1.16x<sub>2</sub>
We can also see that the R<sup>2</sup> value of the model is 76.67. 
This means that <b>76.67%</b> of the variation in the response variable can be explained by the two predictor variables in the model.
Although this output is useful, we still don’t know the  overall F-statistic  of the model, the p-values of the individual  regression coefficients , and other useful metrics that can help us understand how well the model fits the dataset.
<h3>Method 2: Get Regression Model Summary from Statsmodels</h3>
If you’re interested in extracting a summary of a regression model in Python, you’re better off using the <b>statsmodels</b> package.
The following code shows how to use this package to fit the same multiple linear regression model as the previous example and extract the model summary:
<b>import statsmodels.api as sm
#define response variable
y = df['y']
#define predictor variables
x = df[['x1', 'x2']]
#add constant to predictor variables
x = sm.add_constant(x)
#fit linear regression model
model = sm.OLS(y, x).fit()
#view model summary
print(model.summary())
            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.767
Model:                            OLS   Adj. R-squared:                  0.708
Method:                 Least Squares   F-statistic:                     13.15
Date:                Fri, 01 Apr 2022   Prob (F-statistic):            0.00296
Time:                        11:10:16   Log-Likelihood:                -31.191
No. Observations:                  11   AIC:                             68.38
Df Residuals:                       8   BIC:                             69.57
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         70.4828      3.749     18.803      0.000      61.839      79.127
x1             5.7945      1.132      5.120      0.001       3.185       8.404
x2            -1.1576      1.065     -1.087      0.309      -3.613       1.298
==============================================================================
Omnibus:                        0.198   Durbin-Watson:                   1.240
Prob(Omnibus):                  0.906   Jarque-Bera (JB):                0.296
Skew:                          -0.242   Prob(JB):                        0.862
Kurtosis:                       2.359   Cond. No.                         10.7
==============================================================================
</b>
Notice that the regression coefficients and the R-squared value match those calculated by scikit-learn, but we’re also provided with a ton of other useful metrics for the regression model.
For example, we can see the p-values for each individual predictor variable:
p-value for x<sub>1</sub> = .001
p-value for x<sub>2</sub> = 0.309
We can also see the overall F-statistic of the model, the  adjusted R-squared  value, the  AIC value  of the model, and much more.
<h2><span class="orange">How to Extract Regression Coefficients from Scikit-Learn Model</span></h2>
You can use the following basic syntax to extract the regression coefficients from a regression model built with scikit-learn in Python:
<b>pd.DataFrame(zip(X.columns, model.coef_))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Extract Regression Coefficients from Scikit-Learn Model</h2>
Suppose we have the following pandas DataFrame that contains information about hours studied, number of prep exams taken, and final exam score received by 11 students in some class:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'hours': [1, 2, 2, 4, 2, 1, 5, 4, 2, 4, 4],   'exams': [1, 3, 3, 5, 2, 2, 1, 1, 0, 3, 4],   'score': [76, 78, 85, 88, 72, 69, 94, 94, 88, 92, 90]})
#view DataFrame
print(df)
    hours  exams  score
0       1      1     76
1       2      3     78
2       2      3     85
3       4      5     88
4       2      2     72
5       1      2     69
6       5      1     94
7       4      1     94
8       2      0     88
9       4      3     92
10      4      4     90</b>
We can use the following code to fit a  multiple linear regression model  using <b>hours</b> and <b>exams</b> as the predictor variables and <b>score</b> as the response variable:
<b>from sklearn.linear_model import LinearRegression
#initiate linear regression model
model = LinearRegression()
#define predictor and response variables
X, y = df[['hours', 'exams']], df.score
#fit regression model
model.fit(X, y)
</b>
We can then use the following syntax to extract the regression coefficients for <b>hours</b> and <b>exams</b>:
<b>#print regression coefficients
pd.DataFrame(zip(X.columns, model.coef_))
            0        1
0hours 5.794521
1exams-1.157647
</b>
From the output we can see the regression coefficients for both predictor variables in the model:
Coefficient for <b>hours</b>: 5.794521
Coefficient for <b>exams</b>: -1.157647
If we’d like, we can also use the following syntax to extract the intercept value for the regression model:
<b>#print intercept value
print(model.intercept_)
70.48282057040197
</b>
Using each of these values, we can write the fitted regression model equation:
Score = 70.483 + 5.795(hours) – 1.158(exams)
We can then use this equation to predict the final exam score of a student based on their number of hours spent studying and number of prep exams taken.
For example, a student who studied for 3 hours and took 2 prep exams is expected to receive a final exam score of <b>85.55</b>:
Score = 70.483 + 5.795(hours) – 1.158(exams)
Score = 70.483 + 5.795(3) – 1.158(2)
Score = 85.55
<b>Related:</b>  How to Interpret Regression Coefficients 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Python:
 How to Perform Simple Linear Regression in Python 
 How to Perform Multiple Linear Regression in Python 
 How to Calculate AIC of Regression Models in Python 
<h2><span class="orange">How to Find the Slope of a Trendline in Excel</span></h2>
Often you may want to find the slope of a trendline in Excel.
Fortunately this is fairly easy to do and the following step-by-step example shows how to do so.
<h3>Step 1: Create the Data</h3>
First, let’s create a fake dataset to work with:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope1.png">
<h3>Step 2: Create a Scatterplot</h3>
Next, let’s create a scatterplot to visualize the data.
To do so, highlight the data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope2.png">
Then click the <b>Insert</b> tab along the top ribbon and click the first option within the <b>Insert Scatter (X, Y)</b> option in the <b>Charts</b> group. This will produce the following scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope3.png">
<h3>Step 3: Add a Trendline</h3>
Next, let’s add a trendline to the scatterplot.
To do so, click anywhere on the scatterplot. Then click the green plus (+) sign in the top right corner of the chart and click the box next to <b>Trendline</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope4.png">
<h3>Step 4: Display the Slope of the Trendline</h3>
To find the slope of the trendline, click the right arrow next to <b>Trendline</b> and click <b>More Options</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope5.png">
In the window that appears on the right side of the screen, check the box next to <b>Display Equation on chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope6.png">
The trendline equation will automatically appear on the scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/slope7.png">
The trendline equation turns out to be <b>y = 2.4585x – 1.3553</b>.
This means the intercept is <b>-1.3553</b> and the slope is <b>2.4585</b>. 
You can find more Excel tutorials on  this page .
<h2><span class="orange">How to Find the Slope of a Trendline in Google Sheets</span></h2>
The <b>slope </b>of a trendline represents the average increase in the y-value for a one unit increase in the x-value.
To find the slope of a trendline in Google Sheets, we can use the <b>SLOPE </b>function.
This functions uses the following syntax:
<b>SLOPE(data_y, data_x)</b>
where:
<b>data_y</b>: The range of y-values
<b>data_x</b>: The range of x-values
The following example shows how to use this function in practice to calculate the slope of a trendline in Google Sheets.
<h2>Step 1: Create the Data</h2>
First, let’s create a dataset with two variables in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/slope1.jpg"455">
<h2>Step 2: Calculate Slope of Trendline</h2>
Next, let’s type the following formula into cell <b>E1</b> to calculate the slope of the trendline for this dataset:
<b>=SLOPE(B2:B21, A2:A21)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/slope2.jpg">
From the output we can see that the slope is roughly <b>0.917</b>.
This means that the value for y increases by an average of <b>0.917</b> for a one-unit increase in x.
<h2>Step 3: Visualize Slope of Trendline</h2>
To visualize the slope value, we can create a scatterplot and add a trendline.
To do so, highlight the values in the range <b>A2:B21</b>, then click the <b>Insert </b>tab, then click <b>Chart</b> from the dropdown menu:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/slope3.jpg"499">
In the <b>Chart editor</b> window that appears on the right side of the screen, choose <b>Scatter chart</b> as the <b>Chart type</b>.
Then click the <b>Customize</b> tab, then scroll down to <b>Series</b>, then check the box next to <b>Trendline</b> and click <b>Use Equation</b> in the dropdown under <b>Label</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/slope4.jpg"325">
The trendline and the equation for the trendline will be displayed on the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/slope5.jpg">
From the output we can see the formula for the linear trendline:
<b>y = 0.917x + 12.5</b>
This tells us that the y-intercept for the trendline is <b>12.5</b> and the slope is <b>0.917</b>.
This means that the value for y increases by an average of <b>0.917</b> for a one-unit increase in x.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Google Sheets:
 Curve Fitting in Google Sheets 
 How to Add Trendline to Chart in Google Sheets 
 How to Add Multiple Trendlines to Chart in Google Sheets 
<h2><span class="orange">How to Use SMALL IF Function in Excel (With Examples)</span></h2>
You can use the following formulas to perform a SMALL IF function in Excel:
<b>Formula 1: SMALL IF with One Criteria</b>
<b>=SMALL(IF(A2:A16="A",C2:C16),2)
</b>
This formula finds the 2nd smallest value in C2:C16 where the value in A2:A16 is equal to “A”.
<b>Formula 2: SMALL IF with Multiple Criteria</b>
<b>=SMALL(IF((A2:A16="A")*(B2:B16="Forward"),C2:C16),2)
</b>
This formula finds the 2nd smallest value in C2:C16 where the value in A2:A16 is equal to “A” <b>and</b> the value in B2:B16 is equal to “Forward”.
The following examples show how to use each formula in practice with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/largeifexcel1.jpg"456">
<h3>Example 1: SMALL IF with One Criteria</h3>
We can use the following formula to find the 2nd smallest value in C2:C16 where the value in A2:A16 is equal to “A”:
<b>=SMALL(IF(A2:A16="A",C2:C16),2)
</b>
The following screenshot shows how to use this formula: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/smallif1.jpg"501">
This tells us that the 2nd smallest points value among all players on team A is <b>5</b>.
<h3>Example 2: SMALL IF with Multiple Criteria</h3>
We can use the following formula to find the 2nd smallest value in C2:C16 where the value in A2:A16 is equal to “A” <b>and</b> the value in B2:B16 is equal to “Forward”:
<b>=SMALL(IF((A2:A16="A")*(B2:B16="Forward"),C2:C16),2)</b>
The following screenshot shows how to use this formula: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/smallif2-1.jpg"618">
This tells us that the 2nd smallest points value among all Forwards on team A is <b>10</b>.
<h2><span class="orange">How to Calculate SMAPE in Excel (With Examples)</span></h2>
The <b>symmetric mean absolute percentage error (SMAPE) </b>is used to measure the predictive accuracy of models. It is calculated as:
<b>SMAPE</b> = (1/n) * Σ(|forecast – actual| / ((|actual| + |forecast|)/2) * 100
where:
<b>Σ</b> – a symbol that means “sum”
<b>n</b> – sample size
<b>actual</b> – the actual data value
<b>forecast</b> – the forecasted data value
The smaller the value for SMAPE, the better the predictive accuracy of a given model.
The following step-by-step example explains how to calculate SMAPE in Excel.
<h3>Step 1: Enter the Data</h3>
First, we’ll enter some fake data for the actual sales and the forecasted sales during 12 consecutive sales periods for some company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/smapeExcel1.png">
<h3>Step 2: Calculate the SMAPE Differences</h3>
Next, we’ll calculate the SMAPE difference for each sales period using the following formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/smapeExcel2.png">
<h3>Step 3: Calculate SMAPE</h3>
Lastly, we’ll use the following formula to calculate SMAPE:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/smapeExcel3-1.png">
The SMAPE for this particular model turns out to be <b>9.89</b>%.
<h2><span class="orange">How to Calculate SMAPE in R</span></h2>
The <b>symmetric mean absolute percentage error (SMAPE) </b>is used to measure the predictive accuracy of models. It is calculated as:
<b>SMAPE</b> = (1/n) * Σ(|forecast – actual| / ((|actual| + |forecast|)/2) * 100
where:
<b>Σ</b> – a symbol that means “sum”
<b>n</b> – sample size
<b>actual</b> – the actual data value
<b>forecast</b> – the forecasted data value
The smaller the value for SMAPE, the better the predictive accuracy of a given model.
This tutorial explains two different methods you can use to calculate SMAPE in R.
<h3>Method 1: Use smape() from the Metrics Package</h3>
One way to calculate SMAPE in R is to use the <b>smape()</b> function from the <b>Metrics</b> package:
<b>library(Metrics)
#define actual values
actual &lt;- c(12, 13, 14, 15, 15, 22, 27)
#define forecasted values
forecast &lt;- c(11, 13, 14, 14, 15, 16, 18)
#calculate SMAPE
smape(actual, forecast)
[1] 0.1245302
</b>
We can see that the symmetric mean absolute percentage error for this model is <b>12.45%</b>.
<h3>Method 2: Write Your Own Function</h3>
Another way to calculate SMAPE is to create our own function as follows:
<b>find_smape &lt;- function(a, f) {
  return (1/length(a) * sum(2*abs(f-a) / (abs(a)+abs(f))*100))
}
</b>
We can then use this function to calculate the SMAPE between a vector of actual values and forecasted values:
<b>#define actual values
actual &lt;- c(12, 13, 14, 15, 15,22, 27)
#define forecasted values
forecast &lt;- c(11, 13, 14, 14, 15, 16, 18)
#calculate SMAPE
find_smape(actual, forecast)
[1] 12.45302</b>
Once again the SMAPE turns out to be <b>12.45%</b>, which matches the results from the previous example.
<h2><span class="orange">How to Calculate SMAPE in Python</span></h2>
The <b>symmetric mean absolute percentage error (SMAPE) </b>is used to measure the predictive accuracy of models. It is calculated as:
<b>SMAPE</b> = (1/n) * Σ(|forecast – actual| / ((|actual| + |forecast|)/2) * 100
where:
<b>Σ</b> – a symbol that means “sum”
<b>n</b> – sample size
<b>actual</b> – the actual data value
<b>forecast</b> – the forecasted data value
This tutorial explains how to calculate SMAPE in Python.
<h3>How to Calculate SMAPE in Python</h3>
There is no built-in Python function to calculate SMAPE, but we can create a simple function to do so:
<b>import numpy as np
def smape(a, f):
    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)
</b>
We can then use this function to calculate the SMAPE for two arrays: one that contains the actual data values and one that contains the forecasted data values.
<b>#define arrays of actual and forecasted data values
actual = np.array([12, 13, 14, 15, 15,22, 27])
forecast = np.array([11, 13, 14, 14, 15, 16, 18])
#calculate SMAPE
smape(actual, forecast)
12.45302
</b>
 From the results we can see that the symmetric mean absolute percentage error for this model is <b>12.45302%</b>.
<h2><span class="orange">How to Use SMOTE for Imbalanced Data in R (With Example)</span></h2>
Often when working with  classification algorithms  in machine learning, the classes in the dataset will be imbalanced.
For example:
A dataset that contains information on whether or not college players get drafted into the NBA might have 98% of players not get drafted and 2% get drafted.
A dataset that contains information on whether or not patients have cancer might have 99% of patients without cancer and just 1% with cancer.
A dataset that contains information on bank fraud may contain 96% of transactions that are legitimate and 4% that are fraudulent.
As a result of these imbalanced classes, the predictive model that you build is likely to perform poorly on the minority class.
Worse still, the minority class is often the class we’re most interested in predicting.
One way to address this imbalance problem is to use <b>Synthetic Minority Oversampling Technique</b>, often abbreviated <b>SMOTE</b>.
This technique involves creating a new dataset by oversampling observations from the minority class, which produces a dataset that has more balanced classes.
The easiest way to use SMOTE in R is with the <b>SMOTE()</b> function from the <b>DMwR</b> package.
This function uses the following basic syntax:
<b>SMOTE(form, data, perc.over = 200, perc.under = 200, ...)
</b>
where:
<b>form</b>: A formula describing the model you’d like to fit
<b>data</b>: Name of the data frame 
<b>perc.over</b>: Number that determines how many extra cases from the minority class are generated
<b>perc.under</b>: Number that determines how many extra cases from the majority class are generated
The following example shows how to use this function in practice.
<h3>Example: How to Use SMOTE in R</h3>
Suppose we have the following dataset with 100  observations  in R in which 90 have a class of ‘Yes’ and 10 have a class of ‘No’ for the response variable:
<b>#make this example reproducible
set.seed(0)
#create data frame with one response variable and two predictor variables
df &lt;- data.frame(y=rep(as.factor(c('Yes', 'No')), times=c(90, 10)), x1=rnorm(100), x2=rnorm(100))
#view first six rows of data frame
head(df)
    y         x1         x2
1 Yes  1.2629543  0.7818592
2 Yes -0.3262334 -0.7767766
3 Yes  1.3297993 -0.6159899
4 Yes  1.2724293  0.0465803
5 Yes  0.4146414 -1.1303858
6 Yes -1.5399500  0.5767188
 
#view distribution of response variable
table(df$y)
 No Yes 
 10  90</b>
This is a classic example of an imbalanced dataset because the response variable that we’re predicting has 90 observations that have a class of ‘Yes’ and just 10 observations that have a class of ‘No.’
To create a more balanced dataset, we can use the <b>SMOTE()</b> function from the <b>DMwR</b> package:
<b>library(DMwR)
#use SMOTE to create new dataset that is more balanced
new_df &lt;- SMOTE(y ~ ., df, perc.over = 2000, perc.under = 400)
#view distribution of response variable in new dataset
table(new_df$y)
 No Yes 
210 800
</b>
The resulting dataset has 210 observations with ‘No’ as their class and 800 observations with ‘Yes’ as their class.
Here’s exactly how the SMOTE function produced this new dataset:
The<b> perc.over</b> argument specified that we wanted to add 2000/100 (i.e. 20) times the number of existing minority observations to the dataset. Since 10 observations existed in the original dataset, we added 20*10 = <b>200 more minority observations</b>.
The <b>perc.under</b> argument specified that we wanted to make the number of majority observations equal to 400/100 (i.e. 4) times the number of minority observations added to the existing minority observations. Since 200 more minority observations were added, we made the number of majority observations equal to 200 * 4 = <b>800 majority observations</b>.
The end result is a dataset that still contains more majority classes, but is still more balanced than the original dataset.
You can now proceed to fit your classification algorithm of your choice to this new dataset, which should perform better on the minority class since there are more observations from the minority class in this new dataset.
<b>Note</b>: Feel free to play around with the <b>perc.over</b> and<b> perc.under</b> arguments in the SMOTE function to get a dataset that suits your needs.
<h2><span class="orange">Snowball Sampling: Definition + Examples</span></h2>
When researchers are interested in studying a particular population, they often recruit members of the population to be in a study using some type of  sampling method .
One such method is <b>snowball sampling</b>, a method in which researchers recruit initial subjects to be in a study and then ask those initial subjects to recruit additional subjects to be in the study.
<em>Snowball sampling is also sometimes referred to as chain-referral sampling.</em>
Using this approach, the sample size “snowballs” bigger and bigger as each additional subject recruits more subjects.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/snowball1-1.png">
This sampling method is often used when researchers wish to study a population where the subjects are particularly hard to identify or reach. Examples include:
<b>Individuals with rare diseases</b>. If researchers are conducting a study of individuals with rare diseases, it may be difficult to find these individuals. However, if they can find just a few initial individuals to be in the study then they can ask them to recruit further individuals they may know through a private support group or through some other means.
<b>Homeless individuals. </b>It may be difficult to obtain a list of homeless individuals in a city. However, researchers could find a few homeless individuals and then ask them to recruit more individuals they know who are homeless to be involved in the study. 
<b>Ex-convicts. </b>If researchers are interested in conducting a study of ex-convicts, it could be difficult to find a large sample of people who would be willing to come forward to be in the study. But if researchers can find just a few ex-convicts to be in the study, they could ask each of them to recruit additional people they may know who are also ex-convicts.
The reason snowball sampling is so effective is because it’s often difficult for researchers to recruit individuals who don’t want to be identified for a particular reason. However, it’s much easier to recruit these individuals if they’re being recruited by people who are in similar circumstances as them and can reassure them that their privacy will be maintained in the study.
A researcher might have a difficult time recruiting someone with a rare disease to be involved in a study, but if that person is being recruited by someone who has the exact same disease, they’re far more likely to oblige.
<b>Technical Notes:</b>
 
Snowball sampling is an exampling of a <em>non-probability sampling method</em>, which means that not every member in a particular population has an equal probability of being selected for a study.
 
After all, using this method, the only way that an individual could become part of a study is if they were recruited directly by a researcher to be an initial subject or if they were recruited by a subject that was already in the study.
 
The opposite of a non-probability sampling method would be a probability-based sampling method, in which each member of a population has an equal probability of being selected for a study. The most obvious example of this would be  a simple random sample .
<h3>
<b>Advantages of Snowball Sampling</b>
</h3>
There are some advantages to using snowball sampling, including:
Researchers can reach subjects in a particular population that would otherwise be difficult or impossible to reach.
Snowball sampling is low-cost and easy to implement.
Snowball sampling doesn’t require a research team to hire recruiters for the study since the initial subjects act as the recruiters who bring in additional subjects.
<h3>Disadvantages of Snowball Sampling</h3>
There are also several disadvantages to using snowball sampling, including:
The sample for the study is not guaranteed to be  a sample that is representative of the larger population .
Sampling bias is likely to occur. Because initial subjects recruit additional subjects, it’s likely that many of the subjects will share similar traits or characteristics that might be unrepresentative of the larger population under study.
Because the sample is likely to be biased, it can be hard to draw conclusions about the larger population with any confidence. For this reason, snowball sampling is often used as part of exploratory analysis – when researchers are simply interested in gaining a better understanding of a certain population and potentially uncovering information that they weren’t aware of.
<h3>The Ethics of Snowball Sampling</h3>
Because snowball sampling is often used to recruit individuals who don’t want to be identified or known, the topic of the research is usually sensitive and personal.
For this reason, researchers must be extra careful to protect the private information of the individuals in the study so that their contact details and information isn’t leaked.
The researchers should inform existing subjects and potential future subjects that all of their private information will be kept safe.
<h2><span class="orange">How to Conduct a Sobel Test in R</span></h2>
A <b>Sobel test</b> is a method of testing the significance of a mediation effect. 
According to  Wikipedia :
In mediation, the relationship between the independent variable and the dependent variable is hypothesized to be an indirect effect that exists due to the influence of a third variable (the mediator). As a result when the mediator is included in a regression analysis model with the independent variable, the effect of the independent variable is reduced and the effect of the mediator remains significant.
 
The <b>Sobel test</b> is basically a specialized t test that provides a method to determine whether the reduction in the effect of the independent variable, after including the mediator in the model, is a significant reduction and therefore whether the mediation effect is statistically significant.
This tutorial explains how to conduct a sobel test in R.
<h2>Conducting a Sobel Test in R</h2>
To conduct a sobel test in R, we can use the <em>bda </em>library.
<b>#install bda package if not already installed
install.packages('bda')
#load bda package
library(bda)</b>
The basic syntax to conduct a sobel test is the following:
<b>mediation.test(mv,iv,dv)</b>
where <b>mv </b>is the mediator variable, <b>iv </b>is the independent variable, and <b>dv </b>is the dependent variable.
The following code conducts a sobel test using a list of 50 normal random variables for the mediator variable, independent variable, and dependent variable:
<b>mv &lt;- rnorm(50)
iv &lt;- rnorm(50)
dv &lt;- rnorm(50)
mediation.test(mv,iv,dv)
</b>
This code produces the following output:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/sobelTest.jpg" alt="">
In this case, we are interested primarily in the values in the <em>Sobel </em>column. The z value is -1.047 and the corresponding p-value is 0.295.
Since this p-value is greater than the alpha level of 0.05, we would fail to reject the null hypothesis that there is no mediation effect.
Thus, the mediation effect is not statistically significant.
<em><b>Note:</b> </em>You may use a different alpha level in your own test. Common choices for alpha include 0.01, 0.05, and 0.10.
 
<h2><span class="orange">How to Solve a System of Equations in Excel (3 Examples)</span></h2>
To solve a system of equations in Excel, we can use the <b>MMULT</b> and <b>MINVERSE</b> functions.
The following examples show how to use these functions to solve several different systems of equations in Excel.
<h3>Example 1: Solve System of Equations with Two Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x and y:
5x + 4y = 35
2x + 6y = 36
To solve this system of equations, we can first type in the following values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve1-1.png">
We can then use the following formula to solve for the values of x and y:
<b>=MMULT(MINVERSE(A1:B2),C1:C2)
</b>
We can type this formula into cell E1 and then press CTRL + SHIFT + ENTER:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve2.png">
This tells us that the value for x is <b>3</b> and the value for y is <b>5</b>.
<h3>Example 2: Solve System of Equations with Three Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x, y, and z:
4x + 2y + 1z = 34
3x + 5y – 2z = 41
2x + 2y + 4z = 30
To solve this system of equations, we can first type in the following values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve3.png">
We can then use the following formula to solve for the values of x, y, and z:
<b>=MMULT(MINVERSE(A1:C3),D1:D3)
</b>
We can type this formula into cell F1 and then press CTRL + SHIFT + ENTER:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve4.png">
This tells us that the value for x is <b>5</b>,the value for y is <b>6</b>, and the value for z is <b>2</b>.
<h3>Example 3: Solve System of Equations with Four Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of w, x, y, and z:
6w + 2x + 2y + 1z = 37
2w + 1x + 1y + 0z = 14
3w + 2x + 2y + 4z = 28
2w + 0x + 5y + 5z = 28
To solve this system of equations, we can first type in the following values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve5.png">
We can then use the following formula to solve for the values of w, x, y, and z:
<b>=MMULT(MINVERSE(A1:D4),E1:E4)
</b>
We can type this formula into cell G1 and then press CTRL + SHIFT + ENTER:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/solve6.png">
This tells us that the value for w is <b>4</b>, x is <b>3</b>, y is <b>3</b>, and z is <b>1</b>.
<h2><span class="orange">How to Solve a System of Equations in Python (3 Examples)</span></h2>
To solve a system of equations in Python, we can use functions from the  NumPy  library.
The following examples show how to use NumPy to solve several different systems of equations in Python.
<h3>Example 1: Solve System of Equations with Two Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x and y:
5x + 4y = 35
2x + 6y = 36
The following code shows how to use NumPy to solve for the values of x and y:
<b>import numpy as np
#define left-hand side of equation
left_side = np.array([[5, 4], [2, 6]])
#define right-hand side of equation
right_side = np.array([35, 36])
#solve for x and y
np.linalg.inv(left_side).dot(right_side)
array([3., 5.])
</b>
This tells us that the value for x is <b>3</b> and the value for y is <b>5</b>.
<h3>Example 2: Solve System of Equations with Three Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x, y, and z:
4x + 2y + 1z = 34
3x + 5y – 2z = 41
2x + 2y + 4z = 30
The following code shows how to use NumPy to solve for the values of x, y, and z:
<b>import numpy as np
#define left-hand side of equation
left_side = np.array([[4, 2, 1], [3, 5, -2], [2, 2, 4]])
#define right-hand side of equation
right_side = np.array([34, 41, 30])
#solve for x, y, and z
np.linalg.inv(left_side).dot(right_side)
array([5., 6., 2.])
</b>
This tells us that the value for x is <b>5</b>, the value for y is <b>6</b>, and the value for z is <b>2</b>.
<h3>Example 3: Solve System of Equations with Four Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of w, x, y, and z:
6w + 2x + 2y + 1z = 37
2w + 1x + 1y + 0z = 14
3w + 2x + 2y + 4z = 28
2w + 0x + 5y + 5z = 28
The following code shows how to use NumPy to solve for the values of w, x, y, and z:
<b>import numpy as np
#define left-hand side of equation
left_side = np.array([[6, 2, 2, 1], [2, 1, 1, 0], [3, 2, 2, 4], [2, 0, 5, 5]])
#define right-hand side of equation
right_side = np.array([37, 14, 28, 28])
#solve for w, x, y, and z
np.linalg.inv(left_side).dot(right_side)
 
array([4., 3., 3., 1.])
</b>
This tells us that the value for w is <b>4</b>, x is <b>3</b>, y is <b>3</b>, and z is <b>1</b>.
<h2><span class="orange">How to Solve a System of Equations in R (3 Examples)</span></h2>
To solve a system of equations in R, we can use the built-in <b>solve()</b> function.
The following examples show how to use this functions to solve several different systems of equations in R.
<h3>Example 1: Solve System of Equations with Two Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x and y:
5x + 4y = 35
2x + 6y = 36
The following code shows how to use the <b>solve()</b> function in R to solve for the values of x and y:
<b>#define left-hand side of equations
left_matrix &lt;- matrix(c(5, 2, 4, 6), nrow=2)
left_matrix
     [,1] [,2]
[1,]    5    4
[2,]    2    6
#define right-hand side of equations
right_matrix &lt;- matrix(c(35, 36), nrow=2)
right_matrix
     [,1]
[1,]   35
[2,]   36
#solve for x and y
solve(left_matrix, right_matrix)  
     [,1]
[1,]    3
[2,]    5
</b>
This tells us that the value for x is <b>3</b> and the value for y is <b>5</b>.
<h3>Example 2: Solve System of Equations with Three Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of x, y, and z:
4x + 2y + 1z = 34
3x + 5y – 2z = 41
2x + 2y + 4z = 30
The following code shows how to use the <b>solve()</b> function in R to solve for the values of x, y, and z:
<b>#define left-hand side of equations
left_matrix &lt;- matrix(c(4, 3, 2, 2, 5, 2, 1, -2, 4), nrow=3)
left_matrix
     [,1] [,2] [,3]
[1,]    4    2    1
[2,]    3    5   -2
[3,]    2    2    4
#define right-hand side of equations
right_matrix &lt;- matrix(c(34, 41, 30), nrow=3)
right_matrix
     [,1]
[1,]   34
[2,]   41
[3,]   30
#solve for x, y, and z
solve(left_matrix, right_matrix) 
     [,1]
[1,]    5
[2,]    6
[3,]    2</b>
This tells us that the value for x is <b>5</b>, the value for y is <b>6</b>, and the value for z is <b>2</b>.
<h3>Example 3: Solve System of Equations with Four Variables</h3>
Suppose we have the following system of equations and we’d like to solve for the values of w, x, y, and z:
6w + 2x + 2y + 1z = 37
2w + 1x + 1y + 0z = 14
3w + 2x + 2y + 4z = 28
2w + 0x + 5y + 5z = 28
The following code shows how to use the <b>solve()</b> function in R to solve for the values of w, x, y, and z:
<b>#define left-hand side of equations
left_matrix &lt;- matrix(c(6, 2, 3, 2, 2, 1, 2, 0, 2, 1, 2, 5, 1, 0, 4, 5), nrow=4)
left_matrix
     [,1] [,2] [,3] [,4]
[1,]    6    2    2    1
[2,]    2    1    1    0
[3,]    3    2    2    4
[4,]    2    0    5    5
#define right-hand side of equations
right_matrix &lt;- matrix(c(37, 14, 28, 28), nrow=4)
right_matrix
     [,1]
[1,]   37
[2,]   14
[3,]   28
[4,]   28
#solve for w, x, y and z
solve(left_matrix, right_matrix)
     [,1]
[1,]    4
[2,]    3
[3,]    3
[4,]    1</b>
This tells us that the value for w is <b>4</b>, x is <b>3</b>, y is <b>3</b>, and z is <b>1</b>.
<h2><span class="orange">What is Somers’ D? (Definition & Example)</span></h2>
<b>Somers’ D</b>, short for Somers’ Delta, is a measure of the strength and direction of the association between an ordinal dependent variable and an ordinal independent variable.
An <em>ordinal </em>variable is one in which the values have a natural order (e.g. “bad”, “neutral”, “good”).
The value for Somers’ D ranges between -1 and 1 where:
<b>-1:</b> Indicates that all pairs of the variables disagree
<b>1:</b> Indicates that all pairs of the variables agree
Somers’ D is used in practice for many nonparametric statistical methods.
<h3>Somers’ D: Definition</h3>
Given two variables, X and Y, we can say :
Two pairs (x<sub>i</sub>, y<sub>i</sub>) and (x<sub>j</sub>, y<sub>j</sub>) are <b>concordant</b> if the ranks of both elements agree.
Two pairs (x<sub>i</sub>, y<sub>i</sub>) and (x<sub>j</sub>, y<sub>j</sub>) are <b>discordant </b>if the ranks of both elements agree.
We can then calculate Somers’ D using the following formula:
<b>Somers’ D = (N<sub>C</sub> – N<sub>D</sub>) / (N<sub>C</sub> + N<sub>D</sub> + N<sub>T</sub>)</b>
where:
<b>N<sub>C</sub>:</b> The number of concordant pairs
<b>N<sub>D</sub>:</b> The number of discordant pairs
<b>N<sub>T</sub>:</b> The number of tied pairs
The resulting value will always be between -1 and 1.
<h3>Somers’ D: Example in R</h3>
Suppose a grocery store would like to assess the relationship between the following two ordinal variables:
The overall niceness of the cashier (ranked from 1 to 3)
The overall satisfaction of the customer’s experience (also ranked from 1 to 3)
They collect the following ratings from a  sample  of 10 customers:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/somer1.png">
To quantify the relationship between the two variables, we can calculate Somers’ D using the following code in R:
<b>#enter data
nice &lt;- c(1, 1, 1, 2, 2, 2, 3, 3, 3, 3)
satisfaction &lt;- c(2, 2, 1, 2, 3, 2, 2, 3, 3, 3)
#load <em>DescTools</em> package
library(DescTools)
#calculate Somers' D
SomersDelta(nice, satisfaction)
[1] 0.6896552</b>
Somers’ D turns out to be <b>0.6896552</b>.
Since this value is fairly close to 1, this indicates that there is a fairly strong positive relationship between the two variables.
This makes sense intuitively: Customers who rate the cashiers as nicer also tend to rate their overall satisfaction higher.
<h2><span class="orange">How to Sort Values Alphabetically in R</span></h2>
You can use the following functions to sort values alphabetically in R:
<b>#sort values in vector alphabetically
sort(x)
#sort data frame column alphabetically
df[order(df$var1), ]
#sort data frame by multiple columns alphabetically
df[with(df, order(var1, var2)), ]
</b>
The following examples show how to use each of these functions in practice.
<h3>Example 1: Sort a Vector Alphabetically</h3>
The following code shows how to sort a vector alphabetically in R:
<b>#define vector
x &lt;- c('A', 'F', 'C', 'D', 'B', 'E')
#sort values in vector alphabetically
sort(x)
[1] "A" "B" "C" "D" "E" "F"
</b>
<h3>Example 2: Sort Data Frame Column Alphabetically</h3>
The following code shows how to sort a data frame alphabetically based on a specific column:
<b>#define data frame
df &lt;- data.frame(player=c('A', 'F', 'C', 'D', 'B', 'E'), points=c(14, 19, 22, 29, 31, 16))
#view data frame
df
  player points
1      A     14
2      F     19
3      C     22
4      D     29
5      B     31
6      E     16
#sort data frame alphabetically based on player column
df[order(df$player),]
  player points
1      A     14
5      B     31
3      C     22
4      D     29
6      E     16
2      F     19</b>
<h3>Example 3: Sort Multiple Columns Alphabetically</h3>
The following code shows how to sort a data frame alphabetically based on multiple columns:
<b>#define data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), player=c('A', 'F', 'C', 'D', 'B', 'E'), points=c(14, 19, 22, 29, 31, 16))
#view data frame
df
  team player points
1    A      A     14
2    A      F     19
3    A      C     22
4    B      D     29
5    B      B     31
6    B      E     16
#sort data frame alphabetically by team, then by player
df[with(df, order(team, player)), ]
  team player points
1    A      A     14
3    A      C     22
2    A      F     19
5    B      B     31
4    B      D     29
6    B      E     16</b>
<h2><span class="orange">How to Sort by Date in Google Sheets (With Example)</span></h2>
The easiest way to sort by date in Google Sheets is to use the <b>Sort range</b> function within the <b>Data</b> tab.
The following step-by-step example shows how to use this function in practice.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the following set of date values in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortdate1-1.jpg"490">
<h3>Step 2: Verify that Data is in Date Format</h3>
If your data values are not in a date format, you won’t be able to sort them correctly.
To verify that the values are in a date format, make sure that all of the values are <b>aligned to the right</b> in the cell.
In the following screenshot, some of the values are left-aligned which means they’re not in a date format:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortdate2-1.jpg"489">
To convert each of the values in a column to a date format, simply highlight all of the values in the column and then click the <b>Format</b> tab, then click <b>Number</b>, then click <b>Date</b>.
Each of the values should now be right-aligned.
<h3>Step 3: Sort the Data</h3>
To sort the date values, highlight the range <b>A2:A12</b> and then click the <b>Data</b> tab, then click <b>Sort range</b>, then click <b>Sort range by column A (A to Z)</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortdate3-1.jpg">
The dates will automatically be sorted from earliest to latest date:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortdate4.jpg"490">
If you instead click <b>Sort range by column A (Z to A)</b>, the dates will be sorted from latest to earliest date:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortdate5.jpg"480">
<h2><span class="orange">How to Sort a Data Frame by Date in R (With Examples)</span></h2>
There are two easy ways to sort a data frame by date in R:
<b>Method 1: User order() from base R</b>
<b>#sort from least recent to most recent
df[order(as.Date(df$date, format="%m/%d/%Y")),]
#sort from most recent to least recent
df[rev(order(as.Date(df$date, format="%m/%d/%Y"))),]
</b>
<b>Method 2: Use functions from the  lubridate  and  dplyr  packages</b>
<b>library(lubridate)
library(dplyr)
#sort from least recent to most recent 
df %>% arrange(mdy(df$date))
#sort from most recent to least recent
df %>% arrange(desc(mdy(df$date)))
</b>
This tutorial shows an example of how to use each of these methods in practice.
<h3>Method 1: Use order() from base R</h3>
The most basic way to sort a data frame by a date variable in R is to use the <b>order()</b> function from base R. The following code shows how to use this function in practice:
<b>#create and view data frame
df &lt;- data.frame(date=c('10/30/2021', '11/18/2021', '11/13/2021', '11/19/2021'), sales=c(3, 15, 14, 9))
df
        date sales
1 10/30/2021     3
2 11/18/2021    15
3 11/13/2021    14
4 11/19/2021     9
#sort from least recent to most recent
df[order(as.Date(df$date, format="%m/%d/%Y")),]
        date sales
1 10/30/2021     3
3 11/13/2021    14
2 11/18/2021    15
4 11/19/2021     9
#sort from most recent to least recent
df[rev(order(as.Date(df$date, format="%m/%d/%Y"))),]
        date sales
4 11/19/2021     9
2 11/18/2021    15
3 11/13/2021    14
1 10/30/2021     3
</b>
<h3>Method 2: Use lubridate and dplyr</h3>
A faster way to sort a data frame by a date variable is to use functions from the lubridate and dplyr packages. The following code shows how to use these functions in practice:
<b>#create and view data frame
df &lt;- data.frame(date=c('10/30/2021', '11/18/2021', '11/13/2021', '11/19/2021'), sales=c(3, 15, 14, 9))
df
        date sales
1 10/30/2021     3
2 11/18/2021    15
3 11/13/2021    14
4 11/19/2021     9
#sort from least recent to most recent
df %>% arrange(mdy(df$date))
        date sales
1 10/30/2021     3
2 11/13/2021    14
3 11/18/2021    15
4 11/19/2021     9
#sort from most recent to least recent
df %>% arrange(desc(mdy(df$date)))
        date sales
1 11/19/2021     9
2 11/18/2021    15
3 11/13/2021    14
4 10/30/2021     3</b>
Note that we used lubridate to specify the date as a <b>mdy()</b> format, but you can refer to  this cheat sheet  to see other date formats if your date happens to be in a different format.
<h2><span class="orange">How to Sort by Multiple Columns in Excel</span></h2>
Often you may want to sort by multiple columns in Excel. Fortunately this is easy to do using the <b>Custom Sort</b> option.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple3.png">
This tutorial provides a step-by-step example of how to use custom sort in practice.
<h3>Step 1: Create the Data</h3>
First, let’s create a fake dataset to work with:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple1.png">
<h3>Step 2: Sort by Multiple Columns</h3>
Next, we will sort the data in the following manner:
First, sort by <b>Household Size</b> from largest to smallest.
Next, sort by <b>Last Name</b> from A to Z.
To do this, highlight each of the columns including the headers:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple2.png">
Next, click the <b>Sort & Filter </b>option within the <b>Editing</b> section of the <b>Home</b> tab. In the dropdown menu, click <b>Custom Sort</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple3.png">
In the window that appears, sort by <b>Household Size</b> and choose <b>Largest to Smallest</b>.
Then, click <b>Add Level</b> in the top left corner and sort by <b>Last Name</b> and choose <b>A to Z</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple4.png">
Once you click <b>OK</b>, the data will automatically be sorted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple5.png">
Notice that the rows are sorted by <b>Household Size</b> from largest to smallest, which is why the household with a size 7 appears first.
Next, we sort by <b>Last Name</b> from A to Z. This means for any households that have the same size, we determine their order by sorting from A to Z.
For example, each of the households that have a size of 4 are sorted from A to Z:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sortMultiple6.png">
Note that in this example we sorted by two columns, but using the <b>Custom Sort</b> option you can sort by as many columns as you’d like.
<h2><span class="orange">How to Sort by Multiple Columns in R (With Examples)</span></h2>
You can use one of the following methods to sort a data frame by multiple columns in R:
<b>Method 1: Use Base R</b>
<b>df[order(-df$column1, df$column2), ]
</b>
<b>Method 2: Use dplyr</b>
<b>library(dplyr)
df %>%
  arrange(desc(column1), column2)
</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G'), points=c(90, 90, 93, 91, 91, 99, 85), assists=c(33, 28, 31, 39, 34, 40, 44))
#view data frame
df
  team points assists
1    A     90      33
2    B     90      28
3    C     93      31
4    D     91      39
5    E     91      34
6    F     99      40
7    G     85      44
</b>
<h3>Method 1: Use Base R</h3>
The following code shows how to sort the data frame in base R by <b>points</b> descending (largest to smallest), then by <b>assists</b> ascending:
<b>#sort by points descending, then by assists ascending
df[order(-df$points, df$assists), ]
  team points assists
6    F     99      40
3    C     93      31
5    E     91      34
4    D     91      39
2    B     90      28
1    A     90      33
7    G     85      44
</b>
Notice that the rows of the data frame are ordered by points from largest to smallest, then by assists from smallest to largest.
<h3>Method 2: Use dplyr</h3>
The following code shows how to use functions from the  dplyr  package to sort the data frame by <b>points</b> descending (largest to smallest), then by <b>assists</b> ascending:
<b>library(dplyr)
df %>%
  arrange(desc(points), assists)
  team points assists
1    F     99      40
2    C     93      31
3    E     91      34
4    D     91      39
5    B     90      28
6    A     90      33
7    G     85      44
</b>
Once again, the rows of the data frame are ordered by points from largest to smallest, then by assists from smallest to largest.
<b>Note</b>: You can find the complete documentation for the <b>arrange()</b> function  here .
<h2><span class="orange">How to Sort a Data Frame by Column in R (With Examples)</span></h2>
The easiest way to sort a data frame by a column in R is to use the <b>order()</b> function:
<b>#sort ascending
df[order(df$var1), ]
#sort descending
df[order(-df$var1), ]
</b>
This tutorial provides several examples of how to use this function in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(var1=c(1, 3, 3, 4, 5), var2=c(7, 7, 8, 3, 2), var3=letters[1:5])
#view data frame
df
  var1 var2 var3
1    1    7    a
2    3    7    b
3    3    8    c
4    4    3    d
5    5    2    e
</b>
<h3>Example 1: Sort by One Column</h3>
The following code shows how to sort the data frame by the <b>var1</b> column, both in an ascending and descending manner:
<b>#sort by var1 ascending
df[order(df$var1), ]
  var1 var2 var3
1    1    7    a
2    3    7    b
3    3    8    c
4    4    3    d
5    5    2    e
#sort by var1 descending
df[order(-df$var1), ]
  var1 var2 var3
5    5    2    e
4    4    3    d
2    3    7    b
3    3    8    c
1    1    7    a</b>
Note that we can also sort by a character vector alphabetically:
<b>#sort by var3 ascending
df[order(df$var3), ]
  var1 var2 var3
1    1    7    a
2    3    7    b
3    3    8    c
4    4    3    d
5    5    2    e
</b>
<h3>Example 2: Sort by Multiple Columns</h3>
The following code shows how to sort the data frame by multiple columns:
<b>#sort by var2 ascending, then var1 ascending
df[order(df$var2, df$var1), ]
  var1 var2 var3
5    5    2    e
4    4    3    d
1    1    7    a
2    3    7    b
3    3    8    c
#sort by var2 ascending, then var1 descending
df[order(df$var2, -df$var1), ]
  var1 var2 var3
5    5    2    e
4    4    3    d
2    3    7    b
1    1    7    a
3    3    8    c</b>

<script src='https://williamkpchan.github.io/LibDocs/readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>
