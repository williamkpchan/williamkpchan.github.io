<base target="_blank"><html><head><title>statologyContents 15</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://williamkpchan.github.io/lazyload.min.js"></script>
<script src='https://williamkpchan.github.io/mainscript.js'></script>
<script src="https://williamkpchan.github.io/commonfunctions.js"></script>
<script>
  var showTopicNumber = true;
  var topicEnd = "<br>";
  var bookid = "statologyContents 15"
  var markerName = "h2, h3"
</script>
<style>
body{width:70%;margin-left: 15%; font-size:20px;}
h1, h2 {color: gold;}
strong {color: orange;}
b {color: brown;}
img {max-width:60%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>statologyContents 15</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a><br><br>
<div id="toc"></div></center><br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br></div>
<pre><br><br>
<h2><span class="orange">5 Examples of Positively Skewed Distributions</span></h2>
<b>Skewness</b> is a way to describe the  symmetry  of a distribution.
A distribution is <b>positively skewed</b> if it has a “tail” on the right side of the distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew1.png">
<b>Note:</b> Sometimes positively skewed distributions are also called “right skewed” distributions.
In this article we share 5 examples of positively skewed distributions in the real world.
<h3>Example 1: Distribution of Income</h3>
The distribution of individual incomes in the U.S. is right-skewed, with most individuals earning between $20k and $40k per year but with a long right tail of households that earn much more.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/rightSkew1-1.png">
<h3>Example 2: Distribution of Scores on a Difficult Exam</h3>
The distribution of scores on any particularly difficult exam will be positively skewed with most students scoring around some mean value with a few outlier students scoring much higher.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/rightSkew2.png">
<h3>Example 3: Distribution of Pet Ownership</h3>
The distribution of the number of pets that households own in any particular city is likely to be right skewed because most households have either 0 or 1 pet, but there are many outlier households that have 7, 8, 9+ pets that cause the distribution to be right skewed.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/rightSkew3.png">
<h3>Example 4: Distribution of Points Scored</h3>
The distribution of points scored per game by NBA players is right skewed because most players score between 5-10 points per game, but there are some outliers who score 25+ points per game that cause the distribution to be right skewed.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/rightSkew4.png">
<h3>Example 5: Distribution of Movie Ticket Sales</h3>
The distribution of tickets sold per movie is right skewed because most movies are duds and sell relatively few total tickets. However, some blockbuster hits sell millions of tickets, which causes the distribution of movie ticket sales to be right skewed.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/rightSkew5.png">
<h2><span class="orange">Posterior Probability: Definition + Example</span></h2>
A <b>posterior probability </b>is the updated probability of some event occurring after accounting for new information.
For example, we might be interested in finding the probability of some event “A” occurring after we account for some event “B” that has just occurred. We could calculate this posterior probability by using the following formula:
<b>P(A|B)</b> = P(A) * P(B|A)  /  P(B)
where:
P(A|B) = the probability of event A occurring, given that event B has occurred. Note that “|” means “given.”
P(A) = the probability that event A occurs.
P(B) = the probability that event B occurs.
P(B|A) = the probability of event B occurring, given that event A has occurred.
<h2>Example: Calculating Posterior Probability</h2>
A forest is composed of 20% Oak trees and 80% Maple trees. Suppose it is known that 90% of the Oak trees are healthy while just 50% of the Maple trees are healthy. Suppose that from a distance you can tell that a particular tree is healthy. What is the probability that the tree is an Oak tree?
Recall that the probability of event A occurring given that event B has occurred is:
P(A|B) = P(A) * P(B|A)  /  P(B)
In this example, the probability that the tree is an Oak given that the tree is healthy is:
P(Oak|Healthy) = P(Oak) * P(Healthy|Oak)  /  P(Healthy)
P(Oak) = The probability that a given tree is an Oak tree is <b>0.2</b> because 20% of all trees in the forest are Oak.
P(Healthy) = The probability that a given tree is healthy can be calculated as (0.20)*(0.9) + (0.8)*(0.5) = <b>0.58</b>. 
P(Healthy|Oak) = The probability that a tree is healthy given that it’s an Oak tree is<b> 0.9</b>, since we were told that 90% of the Oak trees are healthy.
Using these three numbers, we can find the probability that the tree is an Oak tree given that it’s healthy:
P(Oak|Healthy) = P(Oak) * P(Healthy|Oak)  /  P(Healthy) = (0.2) * (0.9) / (0.58) = <b>0.3103</b>.
For an intuitive understanding of this probability, suppose the following grid represents this forest with 100 trees. Exactly 20 of the trees are Oak trees and 18 of them are healthy. The other 80 trees are Maple and 40 of them are healthy.
(O = Oak, M = Maple, Green = Healthy, Red = Unhealthy)
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/posterior_prob0.png">
Out of all the trees, exactly 58 of them are healthy and 18 of these healthy ones are Oak trees. Thus, if we know that we’ve selected a healthy tree then the probability that it’s an Oak tree is 18/58 = <b>0.3103</b>.
<h2>When Should You Use Posterior Probability?</h2>
Posterior probability is used in a wide variety of domains including finance, medicine, economics, and weather forecasting.
The whole point of using posterior probabilities is to update a previous belief we had about something once we obtain new information.
Recall in the previous example that we knew the probability of a given tree in the forest being Oak was 20%. This is known as a <b>prior probability</b>. If we simply picked a tree at random, we knew that the probability of it being an Oak was 0.20.
However, once we obtained the new information that the tree we selected was healthy, we were able to use this new information to determine that the <b>posterior probability</b> of this tree being an Oak was instead 0.3103.
In the real world, people come across new information all the time. This new information helps us update our prior beliefs. In statistical terms, it means we’re able to generate posterior probabilities of events occurring, which helps us gain a more accurate understanding of the world and enables us to make more accurate predictions about future events.
<h2><span class="orange">Power Regression Calculator</span></h2>
This calculator produces a power regression equation based on values for a predictor variable and a response variable.
This equation takes on the following form:
<b>y = ax<sup>b</sup></b>
To find a power regression equation, simply enter a list of values for a predictor variable and a response variable in the boxes below, then click the “Calculate” button:
<b>Predictor values:</b>
<textarea id="x" rows="5" cols="40">6, 7, 7, 8, 12, 14, 15, 16, 16, 19</textarea>
<b>Response values:</b>
<textarea id="y" rows="5" cols="40">14, 15, 15, 17, 18, 18, 19, 24, 25, 29</textarea>
<input type="button" id="button" onclick="calc()" value="Calculate">
<b>Power Regression Equation:</b>
y = 5.4151x<sup>0.5184</sup>
<script>
function calc() {
//get input data
var x_hold = document.getElementById('x').value.split(',').map(Number);
var y_hold = document.getElementById('y').value.split(',').map(Number);
var x = [];
var y = [];
for(var i=0; i<y_hold.length; i++) {
    y[i] = Math.log10(y_hold[i]);
}
for(var i=0; i<x_hold.length; i++) {
    x[i] = Math.log10(x_hold[i]);
}
//check that both lists are equal length
if (x.length - y.length == 0) {
document.getElementById('error_msg').innerHTML = '';
function linearRegression(y,x){
        var lr = {};
        var n = y.length;
        var sum_x = 0;
        var sum_y = 0;
        var sum_xy = 0;
        var sum_xx = 0;
        var sum_yy = 0;
        for (var i = 0; i < y.length; i++) {
            sum_x += x[i];
            sum_y += y[i];
            sum_xy += (x[i]*y[i]);
            sum_xx += (x[i]*x[i]);
            sum_yy += (y[i]*y[i]);
        } 
        lr['slope'] = (n * sum_xy - sum_x * sum_y) / (n*sum_xx - sum_x * sum_x);
        lr['intercept'] = (sum_y - lr.slope * sum_x)/n;
        lr['r2'] = Math.pow((n*sum_xy - sum_x*sum_y)/Math.sqrt((n*sum_xx-sum_x*sum_x)*(n*sum_yy-sum_y*sum_y)),2);
        return lr;
}
var lr = linearRegression(y, x);
var a = lr.slope;
var b = lr.intercept;
var first = Math.pow(10, b);
var second = Math.pow(10, a);
document.getElementById('a').innerHTML = a.toFixed(4);
document.getElementById('b').innerHTML = first.toFixed(4);
}
//output error message if boths lists are not equal
else {
document.getElementById('error_msg').innerHTML = 'The two lists must be of equal length.';
}
  
} //end calc function
</script>
<h2><span class="orange">How to Perform Power Regression in Excel (Step-by-Step)</span></h2>
<b>Power regression</b> is a type of non-linear regression that takes on the following form:
<b>y = ax<sup>b</sup></b>
where:
<b>y:</b> The response variable
<b>x:</b> The predictor variable
<b>a, b:</b> The regression coefficients that describe the relationship between <em>x</em> and <em>y</em>
This type of regression is used to model situations where the  response variable  is equal to the predictor variable raised to a power.
The following step-by-step example shows how to perform power regression for a given dataset in Excel.
<h3>Step 1: Create the Data</h3>
First, let’s create some fake data for two variables: x and y.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/powerExcel1.png">
<h3>Step 2: Transform the Data</h3>
 Next, let’s take the natural log of both x and y by using the <b>=LN(number)</b> formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/powerExcel2.png">
<h3>Step 3: Fit the Power Regression Model</h3>
Next, we’ll fit a regression model to the transformed data.
To do so, click the <b>Data</b> tab along the top ribbon. Then click the <b>Data Analysis</b> option within the <b>Analyze</b> section.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see this option available, you need to first  load the Analysis ToolPak .
In the dropdown window that appears, click <b>Regression</b> and then click <b>OK</b>. Then fill in the following information:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/powerExcel3.png">
Once you click <b>OK</b>, the regression output will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/powerExcel4.png">
The  overall F-value  of the model is 254.2367 and the corresponding p-value is extremely small (4.61887e-12), which indicates that the model as a whole is useful.
Using the coefficients from the output table, we can see that the fitted power regression equation is:
<b>ln(y) = 0.15333 + 1.43439ln(x)</b>
Applying <em>e</em> to both sides, we can rewrite the equation as:
<b>y = e<sup> 0.15333 + 1.43439ln(x)</sup></b>
<b>y = 1.1657x<sup>1.43439</sup></b>
We can use this equation to predict the response variable, <em>y</em>, based on the value of the predictor variable, <em>x</em>.
For example, if <em>x</em> = 12, then we would predict that <em>y</em> would be <b>41.167</b>:
y = 1.1657(12)<sup>1.43439</sup> = 41.167
<b>Bonus:</b> Feel free to use this online  Power Regression Calculator  to automatically compute the power regression equation for a given predictor and response variable.
<h2><span class="orange">How to Perform Power Regression in R (Step-by-Step)</span></h2>
<b>Power regression</b> is a type of non-linear regression that takes on the following form:
<b>y = ax<sup>b</sup></b>
where:
<b>y:</b> The response variable
<b>x:</b> The predictor variable
<b>a, b:</b> The regression coefficients that describe the relationship between <em>x</em> and <em>y</em>
This type of regression is used to model situations where the  response variable  is equal to the predictor variable raised to a power.
The following step-by-step example shows how to perform power regression for a given dataset in R.
<h3>Step 1: Create the Data</h3>
First, let’s create some fake data for two variables: x and y.
<b>#create data
x=1:20
y=c(1, 8, 5, 7, 6, 20, 15, 19, 23, 37, 33, 38, 49, 50, 56, 52, 70, 89, 97, 115) </b>
<h3>Step 2: Visualize the Data</h3>
 Next, let’s create a scatterplot to visualize the relationship between x and y:
<b>#create scatterplot
plot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/powerR1.png">
From the plot we can see that there exists a clear power relationship between the two variables. Thus, it seems like a good idea to fit a power regression equation to the data instead of a linear regression model.
<h3>Step 3: Fit the Power Regression Model</h3>
Next, we’ll use the <b>lm()</b> function to fit a regression model to the data, specifying that R should use the log of the response variable and the log of the predictor variable when fitting the model:
<b>#fit the model
model &lt;- lm(log(y)~ log(x))
#view the output of the model
summary(model)
Call:
lm(formula = log(y) ~ log(x))
Residuals:
     Min       1Q   Median       3Q      Max 
-0.67014 -0.17190 -0.05341  0.16343  0.93186 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.15333    0.20332   0.754    0.461    
log(x)       1.43439    0.08996  15.945 4.62e-12 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.3187 on 18 degrees of freedom
Multiple R-squared:  0.9339,Adjusted R-squared:  0.9302 
F-statistic: 254.2 on 1 and 18 DF,  p-value: 4.619e-12</b>
The  overall F-value  of the model is 252.1 and the corresponding p-value is extremely small (4.619e-12), which indicates that the model as a whole is useful.
Using the coefficients from the output table, we can see that the fitted power regression equation is:
<b>ln(y) = 0.15333 + 1.43439ln(x)</b>
Applying <em>e</em> to both sides, we can rewrite the equation as:
<b>y = e<sup> 0.15333 + 1.43439ln(x)</sup></b>
<b>y = 1.1657x<sup>1.43439</sup></b>
We can use this equation to predict the response variable, <em>y</em>, based on the value of the predictor variable, <em>x</em>.
For example, if <em>x</em> = 12, then we would predict that <em>y</em> would be <b>41.167</b>:
y = 1.1657(12)<sup>1.43439</sup> = 41.167
<b>Bonus:</b> Feel free to use this online  Power Regression Calculator  to automatically compute the power regression equation for a given predictor and response variable.
<h2><span class="orange">What is Pre-Test and Post-Test Probability?</span></h2>
In the medical field, a  diagnostic test  is used to determine whether or not an individual has a particular disease.
Whenever a diagnostic test is performed, there are always two probabilities of interest:
<b>1. Pre-Test Probability:</b> The probability that an individual has the disease before the diagnostic test is even performed.
This is calculated as the proportion of individuals who are known to have the disease in the population of interest.
This can be calculated using data that has been collected in prior studies or it can be roughly estimated by professionals in the field.
<b>2. Post-Test Probability:</b> The probability that an individual has the disease after testing positive in the diagnostic test.
This is calculated using pre-test probability and the known sensitivity and specificity of the diagnostic test being used.
Sensitivity is the “true positive rate” – the percentage of positive cases the model is able to detect.
Specificity is the “true negative rate” – the percentage of negative cases the model is able to detect. 
Both sensitivity and specificity can be calculated using data from prior studies.
The following example shows how to calculate pre-test and post-test probability in practice.
<h3>Example: Calculating Pre-Test and Post-Test Probabilities</h3>
Suppose it is known that about 7 in 100 individuals in a certain population have disease X.
If we selected an individual from this population at random and performed a diagnostic test to determine if they have disease X, the <b>pre-test probability</b> that they have the disease would be <b>0.7</b> or 7%.
Now suppose it’s also known that the sensitivity of the diagnostic test is 0.74 and the specificity is 0.92.
We can use the following formulas to calculate the <b>post-test probability</b>:
Likelihood ratio positive = sensitivity / (1<U+2212>specificity) = .92 / (1<U+2212>.92) = 11.5
Likelihood ratio negative = (1<U+2212>sensitivity) / specificity = (1<U+2212>.74) / .92 = .2826
Pre-test odds =pre-test prob. / (1<U+2212>pre-test prob.) = .07 / (1<U+2212>.07) = .0752
Positive post-test odds = .0752 * 11.5 = 0.8648
Positive post-test probability = .8648 / (.8648+1) =<b> .4637</b>
Here is how to interpret these results:
The pre-test probability is <b>7%</b>. 
This means the probability that a randomly selected individual has disease X is 7%, even before any diagnostic test is performed.
The post-test probability is <b>46.37%</b>.
For an individual who tests positive on this diagnostic test, the probability that they actually have disease X is 46.37%.
You might be thinking to yourself that a positive test result on the diagnostic test should indicate that an individual definitely has the disease, but keep two things in mind:
1. The probability that a randomly selected individual from the population has the disease (7%) is very low to start.
2. The diagnostic test is known to not be perfect at detecting true positive cases and true negative cases.
Keeping both these facts in mind, it’s a little easier to understand how a positive result on the diagnostic test doesn’t necessarily mean that the individual actually has disease X.
<h2><span class="orange">How to Create a Precision-Recall Curve in Python</span></h2>
When using  classification models  in machine learning, two metrics we often use to assess the quality of the model are precision and recall.
<b>Precision</b>: Correct positive predictions relative to total positive predictions.
This is calculated as:
Precision = True Positives / (True Positives + False Positives)
<b>Recall</b>: Correct positive predictions relative to total actual positives
This is calculated as:
Recall = True Positives / (True Positives + False Negatives)
To visualize the precision and recall for a certain model, we can create a <b>precision-recall curve</b>. This curve shows the tradeoff between precision and recall for different thresholds.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/precisionRecall2.png">
The following step-by-step example shows how to create a precision-recall curve for a logistic regression model in Python.
<h3>Step 1: Import Packages
</h3>
First, we’ll import the necessary packages:
<b>from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
</b>
<h3>Step 2: Fit the Logistic Regression Model</h3>
Next, we’ll create a dataset and fit a logistic regression model to it:
<b>#create dataset with 5 predictor variables
X, y = datasets.make_classification(n_samples=1000,                    n_features=4,                    n_informative=3,                    n_redundant=1,                    random_state=0)
#split dataset into training and testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,random_state=0)
#fit logistic regression model to dataset
classifier = LogisticRegression()
classifier.fit(X_train, y_train)
#use logistic regression model to make predictions
y_score = classifier.predict_proba(X_test)[:, 1]</b>
<h3>Step 3: Create the Precision-Recall Curve</h3>
Next, we’ll calculate the precision and recall of the model and create a precision-recall curve:
<b>#calculate precision and recall
precision, recall, thresholds = precision_recall_curve(y_test, y_score)
#create precision recall curve
fig, ax = plt.subplots()
ax.plot(recall, precision, color='purple')
#add axis labels to plot
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')
#display plot
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/precisionRecall2.png">
The x-axis shows the recall and the y-axis shows the precision for various thresholds.
Notice that as recall increases, precision decreases.
This represents the tradeoff between the two metrics. To increase the recall of our model, the precision must decrease and vice versa.
<h2><span class="orange">How to Predict Values in R Using Multiple Regression Model</span></h2>
You can use the following basic syntax to predict values in R using a fitted multiple linear regression model:
<b>#define new observation
new &lt;- data.frame(x1=c(5), x2=c(10), x3=c(12.5))
#use fitted model to predict the response value for the new observation
predict(model, newdata=new)</b>
The following example shows how to use this function in practice.
<h3>Example: Predict Values Using Fitted Multiple Linear Regression Model</h3>
Suppose we have the following dataset in R that contains information about basketball players:
<b>#create data frame
df &lt;- data.frame(rating=c(67, 75, 79, 85, 90, 96, 97), points=c(8, 12, 16, 15, 22, 28, 24), assists=c(4, 6, 6, 5, 3, 8, 7), rebounds=c(1, 4, 3, 3, 2, 6, 7))
#view data frame
df
  rating points assists rebounds
1     67      8       4        1
2     75     12       6        4
3     79     16       6        3
4     85     15       5        3
5     90     22       3        2
6     96     28       8        6
7     97     24       7        7
</b>
Now suppose we fit a multiple linear regression model using <b>points</b>, <b>assists</b>, and <b>rebounds</b> as predictor variables and <b>rating</b> as the  response variable :
<b>#fit multiple linear regression model
model &lt;- lm(rating ~ points + assists + rebounds, data=df)
#view model summary
summary(model)
Call:
lm(formula = rating ~ points + assists + rebounds, data = df)
Residuals:
      1       2       3       4       5       6       7 
-1.5902 -1.7181  0.2413  4.8597 -1.0201 -0.6082 -0.1644 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)  66.4355     6.6932   9.926  0.00218 **
points        1.2152     0.2788   4.359  0.02232 * 
assists      -2.5968     1.6263  -1.597  0.20860   
rebounds      2.8202     1.6118   1.750  0.17847   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 3.193 on 3 degrees of freedom
Multiple R-squared:  0.9589,Adjusted R-squared:  0.9179 
F-statistic: 23.35 on 3 and 3 DF,  p-value: 0.01396
</b>
From the values in the <b>Estimate</b> column, we can write the fitted regression model:
Rating = 66.4355 + 1.2151(points) – 2.5968(assists) + 2.8202(rebounds)
We can use the following code to predict the rating of a new player who has 20 points, 5 assists, and 2 rebounds:
<b>#define new player
new &lt;- data.frame(points=c(20), assists=c(5), rebounds=c(2))
#use the fitted model to predict the rating for the new player
predict(model, newdata=new)
       1 
83.39607 
</b>
The model predicts that this new player will have a rating of <b>83.39607</b>.
We can confirm this is correct by plugging in the values for the new player into the fitted regression equation:
Rating = 66.4355 + 1.2151(points) – 2.5968(assists) + 2.8202(rebounds)
Rating = 66.4355 + 1.2151(20) – 2.5968(5) + 2.8202(2)
Rating = 83.39
This matches the value we calculated using the <b>predict()</b> function in R.
<h2><span class="orange">How to Obtain Predicted Values and Residuals in Stata</span></h2>
 Linear regression  is a method we can use to understand the relationship between one or more explanatory variables and a response variable.
When we perform linear regression on a dataset, we end up with a regression equation which can be used to predict the values of a response variable, given the values for the explanatory variables.
We can then measure the difference between the predicted values and the actual values to come up with the <b>residuals</b> for each prediction. This helps us get an idea of how well our regression model is able to predict the response values.
This tutorial explains how to obtain both the <b>predicted values </b>and the <b>residuals </b>for a regression model in Stata.
<h3>Example: How to Obtain Predicted Values and Residuals</h3>
For this example we will use the built-in Stata dataset called <em>auto</em>. We’ll use <em>mpg </em>and <em>displacement </em>as the explanatory variables and <em>price </em>as the response variable.
Use the following steps to perform linear regression and subsequently obtain the predicted values and residuals for the regression model.
<b>Step 1: Load and view the data.</b>
First, we’ll load the data using the following command:
<b>sysuse auto</b>
Next, we’ll get a quick summary of the data using the following command:
<b>summarize</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata1.png">
<b>Step 2: Fit the regression model.</b>
Next, we’ll use the following command to fit the regression model:
<b>regress price mpg displacement</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata2.png">
The estimated regression equation is as follows:
estimated price = 6672.766 -121.1833*(mpg) + 10.50885*(displacement)
<b>Step 3: Obtain the predicted values.</b>
We can obtain the predicted values by using the <b>predict </b>command and storing these values in a variable named whatever we’d like. In this case, we’ll use the name <b>pred_price</b>:
<b>predict pred_price</b>
We can view the actual prices and the predicted prices side-by-side using the <b>list </b>command. There are 74 total predicted values, but we’ll view just the first 10 by using the <b>in 1/10 </b>command:
<b>list price pred_price in 1/10</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata3.png">
<b>Step 4: Obtain the residuals.</b>
We can obtain the residuals of each prediction by using the <b>residuals </b>command and storing these values in a variable named whatever we’d like. In this case, we’ll use the name <b>resid_price</b>:
<b>predict resid_price, residuals</b>
We can view the actual price, the predicted price, and the residuals all side-by-side using the <b>list </b>command again:
<b>list price pred_price resid_price in 1/10</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata4.png">
<b>Step 5: Create a predicted values vs. residuals plot.</b>
Lastly, we can created a scatterplot to visualize the relationship between the predicted values and the residuals:
<b>scatter resid_price pred_price</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata5.png">
We can see that, on average, the residuals tend to grow larger as the fitted values grow larger. This could be a sign of  heteroscedasticity  – when the spread of the residuals is not constant at every response level.
We could formally test for heteroscedasticity using the  Breusch-Pagan Test  and we could address this problem using  robust standard errors .
<h2><span class="orange">What is Prediction Error in Statistics? (Definition & Examples)</span></h2>
In statistics, <b>prediction error</b> refers to the difference between the predicted values made by some model and the actual values.
Prediction error is often used in two settings:
<b>1. Linear regression:</b> Used to predict the value of some continuous response variable.
We typically measure the prediction error of a linear regression model with a metric known as  RMSE , which stands for root mean squared error. 
It is calculated as:
RMSE = √Σ(<U+0177><sub>i</sub> – y<sub>i</sub>)<sup>2</sup> / n
where:
Σ is a symbol that means “sum”
<U+0177><sub>i</sub> is the predicted value for the i<sup>th</sup> observation
y<sub>i</sub> is the observed value for the i<sup>th</sup> observation
n is the sample size
<b>2. Logistic Regression:</b> Used to predict the value of some binary response variable.
One common way to measure the prediction error of a logistic regression model is with a metric known as the total misclassification rate.
It is calculated as:
Total misclassification rate = (# incorrect predictions / # total predictions)
The lower the value for the misclassification rate, the better the model is able to predict the outcomes of the response variable.
The following examples show how to calculate prediction error for both a linear regression model and a logistic regression model in practice.
<h3>Example 1: Calculating Prediction Error in Linear Regression</h3>
 Suppose we use a regression model to predict the number of points that 10 players will score in a basketball game.
The following table shows the predicted points from the model vs. the actual points the players scored:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/mse_1.png">
We would calculate the root mean squared error (RMSE) as:
RMSE = √Σ(<U+0177><sub>i</sub> – y<sub>i</sub>)<sup>2</sup> / n
RMSE = √(((14-12)<sup>2</sup>+(15-15)<sup>2</sup>+(18-20)<sup>2</sup>+(19-16)<sup>2</sup>+(25-20)<sup>2</sup>+(18-19)<sup>2</sup>+(12-16)<sup>2</sup>+(12-20)<sup>2</sup>+(15-16)<sup>2</sup>+(22-16)<sup>2</sup>) / 10)
RMSE = 4
The root mean squared error is <b>4.</b> This tells us that the average deviation between the predicted points scored and the actual points scored is 4.
<b>Related:</b>  What is Considered a Good RMSE Value? 
<h3>Example 2: Calculating Prediction Error in Logistic Regression</h3>
Suppose we use a logistic regression model to predict whether or not 10 college basketball players will get drafted into the NBA.
The following table shows the predicted outcome for each player vs. the actual outcome (1 = Drafted, 0 = Not Drafted):
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/predError.jpg"270">
We would calculate the total misclassification rate as:
Total misclassification rate = (# incorrect predictions / # total predictions)
Total misclassification rate = 4/10
Total misclassification rate = 40%
The total misclassification rate is <b>40%</b>.
This value is quite high, which indicates that the model doesn’t do a very good job of predicting whether or not a player will get drafted.
<h2><span class="orange">How to Fix: prediction from a rank-deficient fit may be misleading</span></h2>
One common warning you may encounter in R is:
<b>Warning message:
In predict.lm(model, df) :
  prediction from a rank-deficient fit may be misleading
</b>
There are two reasons this warning may occur:
<b>Reason 1</b>: Two predictor variables are perfectly correlated.
<b>Reason 2</b>: You have more model parameters than observations in the dataset.
The following examples show how each problem could occur in practice.
<h3>Reason #1: Two Predictor Variables Are Perfectly Correlated</h3>
Suppose we fit the following multiple linear regression model in R and attempt to use it to make predictions:
<b>#create data frame
df &lt;- data.frame(x1=c(1, 2, 3, 4), x2=c(2, 4, 6, 8), y=c(6, 10, 19, 26))
#fit multiple linear regression model
model &lt;- lm(y~x1+x2, data=df)
#use model to make predictions
predict(model, df)
   1    2    3    4 
 4.9 11.8 18.7 25.6 
Warning message:
In predict.lm(model, df) :
  prediction from a rank-deficient fit may be misleading</b>
We receive a warning message because the predictor variables x1 and x2 are <b>perfectly correlated</b>.
Notice that the values of x2 are simply equal to the values of x1 multiplied by two. This is an example of  perfect multicollinearity .
This means that x1 and x2 do not provide unique or independent information in the regression model, which cause problems when fitting and interpreting the model.
The easiest way to handle this problem is to simply remove one of the predictor variables from the model since having both predictor variables in the model is redundant.
<h3>Reason #2: There Are More Model Parameters Than Observations</h3>
Suppose we fit the following multiple linear regression model in R and attempt to use it to make predictions:
<b>#create data frame
df &lt;- data.frame(x1=c(1, 2, 3, 4), x2=c(3, 3, 8, 12), x3=c(4, 6, 3, 11), y=c(6, 10, 19, 26))
#fit multiple linear regression model
model &lt;- lm(y~x1*x2*x3, data=df)
#use model to make predictions
predict(model, df)
 1  2  3  4 
 6 10 19 26 
Warning message:
In predict.lm(model, df) :
  prediction from a rank-deficient fit may be misleading
</b>
We receive a warning message because we attempted to fit a regression model with seven total model coefficients:
x1
x2
x3
x1*x2
x1*3
x2*x3
x1*x2*x3 
However, we only have four total observations in the dataset.
Since the number of model parameters is greater than the number of observations in the dataset, we refer to this as  high dimensional data .
With high dimensional data, it becomes impossible to find a model that can describe the relationship between the predictor variables and the response variable because we don’t have enough observations to train the model on.
The easiest way to resolve this issue is to collect more observations for our dataset or use a simpler model with less coefficients to estimate.
<h2><span class="orange">Prediction Interval Calculator</span></h2>
This calculator creates a prediction interval for a given value in a regression analysis.
Simply enter a list of values for a predictor variable, a response variable, an individual value to create a prediction interval for, and a confidence level, then click the “Calculate” button:
<b>Predictor values:</b>
<textarea id="x" rows="5" cols="40">3, 5, 2, 4, 4, 1, 5, 4, 6, 2, 2, 3, 1, 2, 3</textarea>
<b>Response values:</b>
<textarea id="y" rows="5" cols="40">80, 94, 81, 87, 86, 67, 90, 91, 95, 77, 74, 81, 66, 75, 79</textarea>
<b>X value for prediction:</b>
<input type="number" id="xpred" value="3">
<b>Confidence Level:</b>
<input type="number" id="CI" value="0.95" min="0" max="1">
<input type="button" id="button" onclick="calc()" value="Calculate">
90% Prediction Interval: <b>(74.643, 86.903)</b>
<script>
function calc() {
//get input data
var x = document.getElementById('x').value.split(',').map(Number);
var y = document.getElementById('y').value.split(',').map(Number);
var xpred = +document.getElementById('xpred').value;
var CI = +document.getElementById('CI').value;
//check that both lists are equal length
if (x.length - y.length == 0) {
document.getElementById('error_msg').innerHTML = '';
function linearRegression(y,x){
        var lr = {};
        var n = y.length;
        var sum_x = 0;
        var sum_y = 0;
        var sum_xy = 0;
        var sum_xx = 0;
        var sum_yy = 0;
        for (var i = 0; i < y.length; i++) {
            sum_x += x[i];
            sum_y += y[i];
            sum_xy += (x[i]*y[i]);
            sum_xx += (x[i]*x[i]);
            sum_yy += (y[i]*y[i]);
        } 
        lr['slope'] = (n * sum_xy - sum_x * sum_y) / (n*sum_xx - sum_x * sum_x);
        lr['intercept'] = (sum_y - lr.slope * sum_x)/n;
        lr['r2'] = Math.pow((n*sum_xy - sum_x*sum_y)/Math.sqrt((n*sum_xx-sum_x*sum_x)*(n*sum_yy-sum_y*sum_y)),2);
        lr['sum_y'] = sum_y;
        lr['sum_xx'] = sum_xx;
        return lr;
}
//create regression variables
var lr = linearRegression(y, x);
var a = lr.slope;
var b = lr.intercept;
var r2 = lr.r2;
var r2p = r2*100;
var sxx = lr.sum_xx;
//create sse variable
var my = lr.sum_y / y.length;
let sst = 0;
for (let i = 0; i < y.length; i++) {
       sst += Math.pow((y[i] - my), 2);
    }
var CI_out = CI*100
var sse = sst - r2*sst;
var n = y.length;
var var2 = sse/(n-2);
var xbar = math.mean(x);
var ypred = b - (-1*a*xpred);
var df = n-2;
var tcrit = -1*jStat.studentt.inv((1-CI)/2, df);
//calculate lower and upper bounds of prediction interval
var lowCI = ypred-tcrit*Math.sqrt(var2*(1-(-1*(1/n))-(-1*Math.pow(xpred-xbar,2)/sxx)));
var highCI = ypred-(-1*(tcrit*Math.sqrt(var2*(1-(-1*(1/n))-(-1*Math.pow(xpred-xbar,2)/sxx)))));
//output results
document.getElementById('lowCI').innerHTML = lowCI.toFixed(3);
document.getElementById('highCI').innerHTML = highCI.toFixed(3);
document.getElementById('CI_out').innerHTML = CI_out.toFixed(0);
}
//output error message if boths lists are not equal
else {
document.getElementById('error_msg').innerHTML = 'The two lists must be of equal length.';
}
  
} //end calc function
</script>
<h2><span class="orange">How to Construct a Prediction Interval in Excel</span></h2>
In statistics,  simple linear regression  is a technique we can use to quantify the relationship between a predictor variable, x, and a response variable, y. 
When we conduct a simple linear regression, we obtain a “line of best fit” that describes the relationship between x and y, which can be written as:
<U+0177> = b<sub>0</sub> + b<sub>1</sub>x
where:
<U+0177> is the predicted value of the response variable
b<sub>0</sub> is the y-intercept
b<sub>1</sub> is the regression coefficient
x is the value of the predictor variable
Sometimes we’re interested in using this line of best fit to construct a <b>prediction interval </b>for a given value of x<sub>0</sub>, which is an interval around the predicted value <U+0177><sub>0</sub> such that there is a 95% probability that the real value of y in the population corresponding to x<sub>0</sub> is within this interval.
The formula to calculate the prediction interval for a given value x<sub>0</sub> is written as:
<U+0177><sub>0</sub>  +/-  t<sub>α/2,df=n-2</sub> * s.e.
where:
 s.e. = S<sub>yx</sub>√(1 + 1/n + (x<sub>0</sub> – x)<sup>2</sup>/SS<sub>x</sub>)
The formula might look a bit intimidating, but it’s actually straightforward to calculate in Excel. Next, we’ll walk through an example of how to use this formula to calculate a prediction interval for a given value in Excel.
<h3>Example: How to Construct a Prediction Interval in Excel</h3>
The following dataset shows the number of hours studied along with the exam score received by 15 different students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/prediction_interval1.png">
Suppose we would like to create a 95% prediction interval for the value x<sub>0</sub> = 3. That is, we want to create an interval such that there is a 95% probability that the exam score is within this interval for a student who studies for 3 hours.
The following screenshot shows how to calculate all of the necessary values to obtain this prediction interval.
<b>Note:</b> The formulas in column <em>F </em>show how the values in column <em>E </em>were calculated.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/prediction_interval2-1.png">
The 95% prediction interval for a value of x<sub>0</sub> = 3 is <b>(74.64, 86.90)</b>. That is, we predict with 95% probability that a student who studies for 3 hours will earn a score between 74.64 and 86.90.
A couple notes on the calculations used:
To calculate the t-critical value of t<sub>α/2,df=n-2</sub> we used α/2 = .05/2 = 0.25 since we wanted a 95% prediction interval. Note that higher prediction intervals (e.g. 99% prediction interval) will lead to wider intervals. Conversely, a lower prediction interval (e.g. 90% prediction interval) will lead to a more narrow interval.
We used the formula <b>=FORECAST() </b>to obtain the predicted value for <U+0177><sub>0 </sub>but the formula <b>=FORECAST.LINEAR() </b>will return the exact same value.
<h2><span class="orange">How to Create a Prediction Interval in R</span></h2>
A  linear regression model  can be useful for two things:
<b>(1)</b> Quantifying the relationship between one or more predictor variables and a response variable.
<b>(2) </b>Using the model to predict future values.
In regards to <b>(2)</b>, when we use a regression model to predict future values, we are often interested in predicting both an <em>exact value </em>as well as an <em>interval </em>that contains a range of likely values. This interval is known as a <b>prediction interval</b>.
For example, suppose we fit a simple linear regression model using <em>hours studied </em>as a predictor variable and <em>exam score </em>as the response variable. Using this model, we might predict that a student who studies for 6 hours will receive an exam score of <b>91</b>.
However, because there is uncertainty around this prediction, we might create a prediction interval that says there is a 95% chance that a student who studies for 6 hours will receive an exam score between <b>85</b> and <b>97</b>. This range of values is known as a 95% prediction interval and it’s often more useful to us than just knowing the exact predicted value.
<h2>How to Create a Prediction Interval in R</h2>
To illustrate how to create a prediction interval in R, we will use the built-in <em>mtcars </em>dataset, which contains information about characteristics of several different cars:
<b>#view first six rows of <em>mtcars</em>
head(mtcars)
#                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
#Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
#Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
#Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
#Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
#Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
#Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
</b>
First, we’ll fit a simple linear regression model using <em>disp </em>as the predictor variable and <em>mpg </em>as the response variable.
<b>#fit simple linear regression model
model &lt;- lm(mpg ~ disp, data = mtcars)
#view summary of fitted model
summary(model)
#Call:
#lm(formula = mpg ~ disp, data = mtcars)
#
#Residuals:
#    Min      1Q  Median      3Q     Max 
#-4.8922 -2.2022 -0.9631  1.6272  7.2305 
#
#Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
#(Intercept) 29.599855   1.229720  24.070  &lt; 2e-16 ***
#disp        -0.041215   0.004712  -8.747 9.38e-10 ***
#---
#Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#Residual standard error: 3.251 on 30 degrees of freedom
#Multiple R-squared:  0.7183,Adjusted R-squared:  0.709 
#F-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10
</b>
Then, we’ll use the fitted regression model to predict the value of <em>mpg </em>based on three new values for <em>disp</em>. 
<b>#create data frame with three new values for <em>disp
</em>new_disp &lt;- data.frame(disp= c(150, 200, 250))
#use the fitted model to predict the value for <em>mpg </em>based on the three new values
#for <em>disp
</em>predict(model, newdata = new_disp)
#       1        2        3 
#23.41759 21.35683 19.29607 
</b>
The way to interpret these values is as follows:
For a new car with a <em>disp </em>of 150, we predict that it will have a <em>mpg </em>of <b>23.41759</b>. 
For a new car with a <em>disp </em>of 200, we predict that it will have a <em>mpg </em>of <b>21.35683 </b>. 
For a new car with a <em>disp </em>of 250, we predict that it will have a <em>mpg </em>of <b>19.29607</b>. 
Next, we’ll use the fitted regression model to make prediction intervals around these predicted values:
<b>#create prediction intervals around the predicted values
predict(model, newdata = new_disp, interval = "predict")
#       fit      lwr      upr
#1 23.41759 16.62968 30.20549
#2 21.35683 14.60704 28.10662
#3 19.29607 12.55021 26.04194
</b>
The way to interpret these values is as follows:
The 95% prediction interval of the <em>mpg </em>for a car with a <em>disp </em>of 150 is between <b>16.62968</b> and <b>30.20549</b>.
The 95% prediction interval of the <em>mpg </em>for a car with a <em>disp </em>of 200 is between <b>14.60704 </b>and <b>28.10662</b>.
The 95% prediction interval of the <em>mpg </em>for a car with a <em>disp </em>of 250 is between <b>12.55021 </b>and <b>26.04194</b>.
By default, R uses a 95% prediction interval. However, we can change this to whatever we’d like using the <b>level </b>command. For example, the following code illustrates how to create 99% prediction intervals:
<b>#create 99% prediction intervals around the predicted values
predict(model, newdata = new_disp, interval = "predict", level = 0.99)
#       fit      lwr      upr
#1 23.41759 14.27742 32.55775
#2 21.35683 12.26799 30.44567
#3 19.29607 10.21252 28.37963
</b>
Note that the 99% prediction intervals are wider than the 95% prediction intervals. This makes sense because the wider the interval, the higher the likelihood that it will contain the predicted value.
<h2>How to Visualize a Prediction Interval in R</h2>
The following code illustrates how to create a chart with the following features:
A scatterplot of the data points for <em>disp </em>and <em>mpg</em>
A blue line for the fitted regression line
Gray confidence bands
Red prediction bands
<b>#define dataset
data &lt;- mtcars[ , c("mpg", "disp")]
#create simple linear regression model
model &lt;- lm(mpg ~ disp, data = mtcars)
#use model to create prediction intervals
predictions &lt;- predict(model, interval = "predict")
#create dataset that contains original data along with prediction intervals
all_data &lt;- cbind(data, predictions)
#load <em>ggplot2</em> library
library(ggplot2)
#create plot
ggplot(all_data, aes(x = disp, y = mpg)) + #define x and y axis variables
  geom_point() + #add scatterplot points
  stat_smooth(method = lm) + #confidence bands
  geom_line(aes(y = lwr), col = "coral2", linetype = "dashed") + #lwr pred interval
  geom_line(aes(y = upr), col = "coral2", linetype = "dashed") #upr pred interval</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/pred1.jpg">
<h2>When to Use a Confidence Interval vs. a Prediction Interval</h2>
A <b>prediction interval </b>captures the uncertainty around a single value. A <b>confidence interval </b>captures the uncertainty around the mean predicted values. Thus, a prediction interval will always be wider than a confidence interval for the same value.
You should use a prediction interval when you are interested in specific individual predictions because a confidence interval will produce too narrow of a range of values, resulting in a greater chance that the interval will not contain the true value.
<h2><span class="orange">How to Make Predictions with Linear Regression</span></h2>
<b>Linear regression</b> is a method we can use to quantify the relationship between one or more predictor variables and a  response variable .
One of the most common reasons for fitting a regression model is to use the model to predict the values of new observations.
We use the following steps to make predictions with a regression model:
<b>Step 1:</b> Collect the data.
<b>Step 2:</b> Fit a regression model to the data.
<b>Step 3:</b> Verify that the model fits the data well.
<b>Step 4:</b> Use the fitted regression equation to predict the values of new observations.
The following examples show how to use regression models to make predictions.
<h3>Example 1: Make Predictions with a Simple Linear Regression Model</h3>
Suppose a doctor collects data for height (in inches) and weight (in pounds) on 50 patients.
She then fits a simple linear regression model using “weight” as the predictor variable and “height” as the response variable.
The fitted regression equation is as follows:
Height = 32.7830 + 0.2001*(weight)
After checking that  the assumptions  of the linear regression model are met, the doctor concludes that the model fits the data well.
He can then use the model to predict the height of new patients based on their weight.
For example, suppose a new patient weighs 170 pounds. Using the model, we would predict that this patient would have a height of 66.8 inches:
Height = 32.7830 + 0.2001*(170) = <b>66.8 inches</b>
<h3>Example 2: Make Predictions with a Multiple Linear Regression Model</h3>
Suppose an economist collects data for total years of schooling, weekly hours worked, and yearly income on 30 individuals.
He then fits a multiple linear regression model using “total years of schooling” and “weekly hours worked” as the predictor variable and “yearly income” as the response variable.
The fitted regression equation is as follows:
Income = 1,342.29 + 3,324.33*(years of schooling) + 765.88*(weekly hours worked)
After checking that  the assumptions  of the linear regression model are met, the economist concludes that the model fits the data well.
He can then use the model to predict the yearly income of a new individual based on their total years of schooling and weekly hours worked.
For example, suppose a new individual has 16 years of total schooling and works an average of 40 hours per week. Using the model, we would predict that this individual would have a yearly income of $85,166.77:
Income = 1,342.29 + 3,324.33*(16) + 765.88*(45) = <b>$85,166.77</b>
<h3>On Using Confidence Intervals</h3>
When using a regression model to make predictions on new observations, the value predicted by the regression model is known as a  point estimate .
Although the point estimate represents our best guess for the value of the new observation, it’s unlikely to <em>exactly</em> match the value of the new observation.
So, to capture this uncertainty we can create a <b>confidence interval</b> – a range of values that is likely to contain a population parameter with a certain level of confidence.
For example, instead of predicting that a new individual will be 66.8 inches tall, we may create the following confidence interval:
95% Confidence Interval = [64.8 inches, 68.8 inches]
We would interpret this interval to mean that we’re 95% confident that the true height of this individual is between 64.8 inches and 68.8 inches.
<h3>Cautions on Making Predictions</h3>
Keep in mind the following when using a regression model to make predictions:
<b>1. Only use the model to make predictions within the range of data used to estimate the regression model.</b>
For example, suppose we fit a regression model using the predictor variable “weight” and the weight of individuals in the sample we used to estimate the model ranged between 120 pounds and 180 pounds.
It would be invalid to use the model to estimate the height of an individual who weighted 200 pounds because this falls outside of the range of the predictor variable that we used to estimate the model.
It’s possible that the relationship between weight and height is different outside of the range of 120 to 180 pounds, so we shouldn’t use the model to estimate the height of an individual who weighs 200 pounds.
<b>2. Only use the model to make predictions for the population you sampled.</b>
For example, suppose the population that an economist draws a sample from all lives in a particular city. 
We should only use the fitted regression model to predict the yearly income of individuals in this city since the entire sample that was used to fit the model lived in this city.
<h2><span class="orange">What is Predictive Validity? (Definition & Examples)</span></h2>
In statistics, the term <b>predictive validity</b> refers to the extent that it’s valid to use the score on some scale or test to predict the value of some other variable in the future.
For example, we might want to know how well some college entrance exam is able to predict the first semester grade point average of students.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/predictive_validity1.png">
To determine if predictive validity exists, we could use the following process:
Administer the college entrance exam to 1,000 seniors.
One year later, collect data on the first semester GPA of the same 1,000 students.
Calculate the  correlation  between the scores on the entrance exam and the first semester GPA.
If there is a high correlation between scores on the entrance exam and the first semester GPA, it’s likely that there is <b>predictive validity</b> between these two variables.
In other words, the score that a student receives on this particular college entrance exam is <em>predictive</em> of the GPA they’re likely to receive during their first semester in college.
For example, students who score high on the entrance exam also tend to earn high GPA’s during their first semester. Conversely, students who score low on the entrance exam tend to earn low GPA’s during their first semester.
<b>Technical Notes:</b>
 
Predictive validity is a type of criterion validity, which refers to how well the measurement of one variable can predict the response of another variable.
 
One variable is referred to as the  explanatory variable  while the other variable is referred to as the response variable or  criterion variable .
 
In our previous example, the explanatory variable would be the entrance exam and the criterion variable would be the first semester GPA.
<h3>Examples of Predictive Validity</h3>
The following examples illustrate a few more scenarios where we might calculate predictive validity.
<b>Example 1: Pre-Employment Test</b>
A company might administer a 40-question pre-employment test to all individuals they hire and then rate the employee productivity one year later.
If there is a high degree of correlation between the scores on the test and the employee productivity, then we can say that it’s valid to use the test to predict the future productivity of the individual.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/predictive_validity2.png">
<b>Example 2: IQ Testing & Income</b>
Researchers might administer an IQ test to 100 individuals and then track the annual income of those individuals 10 years later.
If there is a high degree of correlation between the scores on the IQ test and the annual income of the individuals, then the researchers can say that it’s valid to use the test to predict the future income of individuals.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/predictive_validity3.png">
<b>Example 3: Physical Fitness</b>
A personal trainer might administer a fitness test to NBA rookies and then record the average points per game scored by the players during their next five years in the league.
If there is a high degree of correlation between the scores on the fitness test and the average points per game scored by the players, then the personal trainer can say that it’s valid to use the test to predict the future points per game of players.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/predictive_validity4.png">
<h3>What is Considered High Correlation for Predictive Validity?</h3>
There is no specific value that is considered to be a “high” correlation between two variables. However, the higher the correlation between a test and the construct it sets out to measure, the higher the predictive validity of the test.
For example, if the correlation between a pre-employment test and the employee productivity one year later is <b>0.86</b>, this test is more predictive of employee productivity compared to a test that only has a correlation of <b>0.35</b>.
However, even a correlation that seems quite low (like r = 0.35) can still be useful to an employer because it gives them at least some sense of how productive the employee is likely to be.
<h2><span class="orange">What is the PRESS Statistic?</span></h2>
In statistics, we fit  regression models  for two reasons:
<b>(1)</b> To <em>explain </em>the relationship between one or more  explanatory variables  and a  response variable .
<b>(2) </b>To <em>predict </em>values of a response variable based on the values of one or more explanatory variables.
When our goal is to <b>(2) </b><em>predict</em> the values of a response variable, we want to make sure that we’re using the best possible regression model to do so.
One metric that we can use to find the regression model that will make the best predictions on new data is the <b>PRESS Statistic</b>, which stands for the “<b>P</b>redicted <b>RE</b>sidual <b>S</b>um of <b>S</b>quares.”
It is calculated as:
<b>PRESS = Σ(e<sub>i</sub> / (1-h<sub>ii</sub>))<sup>2</sup></b>
where:
<b>e<sub>i</sub>: </b>The i<sup>th</sup> residual.
<b>h<sub>ii</sub>: </b>A measure of the influence (also called “leverage”) of the i<sup>th</sup> observation on the model fit.
Given several regression models, the one with the lowest PRESS should be selected as the one that will perform best on a new dataset.
The following example shows how to calculate the PRESS statistic for three different linear regression models in R.
<h3>Example: Calculating the PRESS Statistic</h3>
Suppose we have a dataset with three explanatory variables, x<sub>1</sub>, x<sub>2</sub>, and x<sub>3</sub>, and one response variable y:
<b>data &lt;- data.frame(x1 = c(2, 3, 3, 4, 4, 6, 8, 9, 9, 9),   x2 = c(2, 2, 3, 3, 2, 3, 5, 6, 6, 7),   x3 = c(12, 14, 14, 13, 8, 8, 9, 14, 11, 7),    y = c(23, 24, 15, 9, 14, 17, 22, 26, 34, 35))
</b>
The following code shows how to fit three different regression models to this dataset using the <b>lm()</b> function:
<b>model1 &lt;- lm(y~x1, data=data)
model2 &lt;- lm(y~x1+x2, data=data)
model3 &lt;- lm(y~x2+x3, data=data)
</b>
The following code shows how to calculate the PRESS statistic for each model.
<b>#create custom function to calculate the PRESS statistic
PRESS &lt;- function(model) {
    i &lt;- residuals(model)/(1 - lm.influence(model)$hat)
    sum(i^2)
}
#calculate PRESS for model 1
PRESS(model1)
[1] 590.2197
#calculate PRESS for model 2
PRESS(model2)
[1] 519.6435
#calculate PRESS for model 3
PRESS(model3)
[1] 537.7503
</b>
It turns out that the model with the lowest PRESS statistic is model 2 with a PRESS statistic of <b>519.6435</b>. Thus, we would choose this model as the one that is best suited to make predictions on a new dataset.
<h2><span class="orange">Pretest-Posttest Design: Definition & Examples</span></h2>
A <b>pretest-posttest design </b>is an experiment in which measurements are taken on individuals both <em>before</em> and <em>after</em> they’re involved in some treatment.
Pretest-posttest designs can be used in both experimental and quasi-experimental research and may or may not include control groups. The process for each research approach is as follows:
<h3>Quasi-Experimental Research</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/pretest-posttest1.png">
<b>1.</b> Administer a pre-test to a group of individuals and record their scores.
<b>2. </b>Administer some treatment designed to change the score of individuals.
<b>3. </b>Administer a post-test to the same group of individuals and record their scores.
<b>4. </b>Analyze the difference between pre-test and post-test scores.
<b>Example: </b>All students in a certain class take a pre-test. The teacher then uses a certain teaching technique for one week and administers a post-test of similar difficulty. She then analyzes the differences between the pre-test and post-test scores to see if the teaching technique had a significant effect on scores.
<h3>Experimental Research</h3>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/pretest-posttest2.png">
<b>1. </b>Randomly assign individuals to a treatment group or control group.
<b>2.</b> Administer the same pre-test to all individuals and record their scores.
<b>3. </b>Administer some treatment procedure to individuals in the treatment group and administer some standard procedure to individuals in the control group.
<b>4. </b>Administer the same post-test to individuals in both groups.
<b>5. </b>Analyze the difference between pre-test and post-test scores between the treatment group and control group.
<b>Example: </b>A teacher splits randomly assigns half of her class to a control group and the other half to a treatment group. She then uses a standard teaching technique and a new teaching technique with each group respectively for one week and then administers a post-test of similar difficulty to all students. She then analyzes the differences between the pre-test and post-test scores to see if the teaching technique had a significant effect on scores between the two groups.
<h3>Potential Issues with Internal Validity</h3>
<b>Internal validity </b>refers to the extent in which a study establishes a reliable cause-and-effect relationship between a treatment and an outcome.
In a pretest-posttest design experiment, there are several factors that could affect internal validity, including:
<b>History</b> – Individuals experience some event outside of the study that affects the measurements before and after a treatment.
<b>Maturity</b> – Biological changes in participants affect the measurements before and after a treatment.
<b>Attrition </b>– An individual leaves the study before a post-measurement can be taken.
<b>Regression to the mean</b> – People who score extremely high or low on some measurement have a tendency to score closer to the average next time, despite the treatment they partake in.
 <b>Selection bias </b>– The individuals in the treatment group and control group are not actually comparable.
Often random selection and  random assignment  of individuals to groups can minimize these threats to internal validity, but not in all cases.
<h2><span class="orange">What is Prevalence in Statistics? (Definition & Example)</span></h2>
In statistics, <b>prevalence</b> is the proportion of individuals in a population who have a specific characteristic at a certain time period.
Researchers typically measure prevalence by taking a  random sample  of individuals from the population and simply counting how many of the individuals in the sample have the specific characteristic.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/CIprop1.png">
For example, suppose researchers want to understand the prevalence of disease X in a certain city.
To calculate this, they may collect a random sample of 5,000 individuals from the city and find that 120 of the individuals in the sample have disease X.
The prevalence of disease X would then be calculated as:
Prevalence = Individuals with disease / Total individuals in sample
Prevalence = 120 / 5,000
Prevalence = <b>.024</b>
The researchers would conclude that the prevalence of disease X in this particular city at this point in time is <b>.024</b> or <b>2.4%</b>.
<b>Note</b>: It’s important that a  random sampling method  is used so that a  representative sample  is obtained. This ensures that the findings from the sample can be extrapolated to the overall population of interest.
<h2>How to Report Prevalence</h2>
When reporting prevalence in a formal paper, researchers typically either use a percentage or a number divided by 10,000 or 100,000.
For example, suppose the prevalence of disease X is calculated as .024.
When reporting this value, researchers will write something like:
The prevalence of disease X is 2.4%.
Disease X is prevalent in 240 out of 10,000 people.
Disease X is prevalent in 2,400 out of 100,000 people.
In general, the lower the value for prevalence the higher the denominator for the number of people will be.
For example, suppose the prevalence of disease X is .000031.
Since this number is so tiny, researchers may report this as:
The prevalence of disease X is 31 out of 1,000,000 people.
This makes the value for the prevalence easier to interpret and understand.
<h2>The Difference Between Prevalence and Incidence</h2>
One term that people sometimes confuse with prevalence is <b>incidence</b>.
<b>Incidence</b> refers to the number of new cases of a specific characteristic at a certain time period.
For example, suppose researchers take a random sample of 5,000 individuals in a certain city and find that 90 people have developed disease X in the past year while an additional 30 have been living with disease X for a long time.
We would calculate the <b>incidence</b> as:
Incidence = Individuals with newly developed disease / Total sample size
Incidence = 90 / 5,000
Incidence = .<b>018</b>
The researchers would conclude that the incidence of disease X in this particular city at this point in time is <b>.018</b> or <b>1.8%</b>.
However, the prevalence would be calculated as the total proportion of individuals in the sample with disease X, regardless of when they developed the disease.
Thus, the <b>prevalence</b> would be calculated as:
Prevalence = (Newly developed disease + Existing disease) / Total individuals in sample
Prevalence = (90 + 30) / 5,000
Prevalence = <b>.024</b>
The researchers would conclude that the incidence of disease X in this particular city at this point in time is <b>.024</b> or <b>2.4%</b>.
<h2>Additional Resources</h2>
The following tutorials provide information about other terms commonly used in statistics:
 What is an Observation in Statistics? 
 What are Cases in Statistics? 
 What is Pre-Test and Post-Test Probability? 
<h2><span class="orange">Principal Components Analysis in R: Step-by-Step Example</span></h2>
Principal components analysis, often abbreviated PCA, is an  unsupervised  machine learning technique that seeks to find principal components – linear combinations of the original predictors – that explain a large portion of the variation in a dataset.
The goal of PCA is to explain most of the variability in a dataset with fewer variables than the original dataset.
For a given dataset with <em>p</em> variables, we could examine the scatterplots of each pairwise combination of variables, but the sheer number of scatterplots can become large very quickly.
For <em>p</em> predictors, there are p(p-1)/2 scatterplots.
So, for a dataset with p = 15 predictors, there would be 105 different scatterplots!
Fortunately, PCA offers a way to find a low-dimensional representation of a dataset that captures as much of the variation in the data as possible.
If we’re able to capture most of the variation in just two dimensions, we could project all of the observations in the original dataset onto a simple scatterplot.
The way we find the principal components is as follows:
Given a dataset with <em>p</em> predictors: X<sub>1</sub>, X<sub>2</sub>, … , X<sub>p,</sub>, calculate Z<sub>1</sub>, … , Z<sub>M</sub> to be the <em>M</em> linear combinations of the original <em>p</em> predictors where:
Z<sub>m</sub> = ΣΦ<sub>jm</sub>X<sub>j</sub> for some constants Φ<sub>1m</sub>, Φ<sub>2m</sub>, Φ<sub>pm</sub>, m = 1, …, M.
Z<sub>1</sub> is the linear combination of the predictors that captures the most variance possible.
Z<sub>2</sub> is the next linear combination of the predictors that captures the most variance while being <em>orthogonal</em> (i.e. uncorrelated) to Z<sub>1</sub>.
Z<sub>3 </sub>is then the next linear combination of the predictors that captures the most variance while being orthogonal to Z<sub>2</sub>.
And so on.
In practice, we use the following steps to calculate the linear combinations of the original predictors:
<b>1. </b>Scale each of the variables to have a mean of 0 and a standard deviation of 1.
<b>2. </b>Calculate the covariance matrix for the scaled variables.
<b>3. </b>Calculate the eigenvalues of the covariance matrix.
Using linear algebra, it can be shown that the eigenvector that corresponds to the largest eigenvalue is the first principal component. In other words, this particular combination of the predictors explains the most variance in the data.
The eigenvector corresponding to the second largest eigenvalue is the second principal component, and so on.
This tutorial provides a step-by-step example of how to perform this process in R.
<h3>Step 1: Load the Data</h3>
First we’ll load the <b>tidyverse</b> package, which contains several useful functions for visualizing and manipulating data:
<b>library(tidyverse)
</b>
For this example we’ll use the <em>USArrests</em> dataset built into R, which contains the number of arrests per 100,000 residents in each U.S. state in 1973 for <em>Murder</em>, <em>Assault</em>, and <em>Rape</em>.
It also includes the percentage of the population in each state living in urban areas, <em>UrbanPop</em>.
The following code show how to load and view the first few rows of the dataset:
<b>#load data
data("USArrests")
#view first six rows of data
head(USArrests)
           Murder Assault UrbanPop Rape
Alabama      13.2     236       58 21.2
Alaska       10.0     263       48 44.5
Arizona       8.1     294       80 31.0
Arkansas      8.8     190       50 19.5
California    9.0     276       91 40.6
Colorado      7.9     204       78 38.7
</b>
<h3>Step 2: Calculate the Principal Components</h3>
After loading the data, we can use the R built-in function <b>prcomp()</b> to calculate the principal components of the dataset.
Be sure to specify <b>scale = TRUE</b> so that each of the variables in the dataset are scaled to have a mean of 0 and a standard deviation of 1 before calculating the principal components.
Also note that eigenvectors in R point in the negative direction by default, so we’ll multiply by -1 to reverse the signs.
<b>#calculate principal components
results &lt;- prcomp(USArrests, scale = TRUE)
#reverse the signs
results$rotation &lt;- -1*results$rotation
#display principal components
results$rotation
               PC1        PC2        PC3         PC4
Murder   0.5358995 -0.4181809  0.3412327 -0.64922780
Assault  0.5831836 -0.1879856  0.2681484  0.74340748
UrbanPop 0.2781909  0.8728062  0.3780158 -0.13387773
Rape     0.5434321  0.1673186 -0.8177779 -0.08902432</b>
We can see that the first principal component (PC1) has high values for Murder, Assault, and Rape which indicates that this principal component describes the most variation in these variables.
We can also see that the second principal component (PC2) has a high value for UrbanPop, which indicates that this principle component places most of its emphasis on urban population.
Note that the principal components scores for each state are stored in <b>results$x</b>. We will also multiply these scores by -1 to reverse the signs:
<b>#reverse the signs of the scores
results$x &lt;- -1*results$x
#display the first six scores
head(results$x)
  PC1        PC2         PC3          PC4
Alabama     0.9756604 -1.1220012  0.43980366 -0.154696581
Alaska      1.9305379 -1.0624269 -2.01950027  0.434175454
Arizona     1.7454429  0.7384595 -0.05423025  0.826264240
Arkansas   -0.1399989 -1.1085423 -0.11342217  0.180973554
California  2.4986128  1.5274267 -0.59254100  0.338559240
Colorado    1.4993407  0.9776297 -1.08400162 -0.001450164
</b>
<h3>Step 3: Visualize the Results with a Biplot</h3>
Next, we can create a <b>biplot</b> – a plot that projects each of the observations in the dataset onto a scatterplot that uses the first and second principal components as the axes:
Note that <b>scale = 0 </b>ensures that the arrows in the plot are scaled to represent the loadings.
<b>biplot(results, scale = 0)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/pca1.png">
From the plot we can see each of the 50 states represented in a simple two-dimensional space.
The states that are close to each other on the plot have similar data patterns in regards to the variables in the original dataset.
We can also see that the certain states are more highly associated with certain crimes than others. For example, Georgia is the state closest to the variable <em>Murder</em> in the plot.
If we take a look at the states with the highest murder rates in the original dataset, we can see that Georgia is actually at the top of the list:
<b>#display states with highest murder rates in original dataset
head(USArrests[order(-USArrests$Murder),])
               Murder Assault UrbanPop Rape
Georgia          17.4     211       60 25.8
Mississippi      16.1     259       44 17.1
Florida          15.4     335       80 31.9
Louisiana        15.4     249       66 22.2
South Carolina   14.4     279       48 22.5
Alabama          13.2     236       58 21.2</b>
<h3>Step 4: Find Variance Explained by Each Principal Component</h3>
We can use the following code to calculate the total variance in the original dataset explained by each principal component:
<b>#calculate total variance explained by each principal component
results$sdev^2 / sum(results$sdev^2)
[1] 0.62006039 0.24744129 0.08914080 0.04335752
</b>
From the results we can observe the following:
The first principal component explains <b>62%</b> of the total variance in the dataset.
The second principal component explains <b>24.7%</b> of the total variance in the dataset.
The third principal component explains <b>8.9%</b> of the total variance in the dataset.
The fourth principal component explains <b>4.3%</b> of the total variance in the dataset.
Thus, the first two principal components explain a majority of the total variance in the data.
This is a good sign because the previous biplot projected each of the observations from the original data onto a scatterplot that only took into account the first two principal components.
Thus, it’s valid to look at patterns in the biplot to identify states that are similar to each other.
We can also create a <b>scree plot</b> – a plot that displays the total variance explained by each principal component – to visualize the results of PCA:
<b>#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)
#create scree plot
qplot(c(1:4), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") +
  ylim(0, 1)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/pca2.png">
<h3>Principal Components Analysis in Practice</h3>
In practice, PCA is used most often for two reasons:
<b>1. Exploratory Data Analysis</b> – We use PCA when we’re first exploring a dataset and we want to understand which observations in the data are most similar to each other.
<b>2. Principal Components Regression </b>– We can also use PCA to calculate principal components that can then be used in  principal components regression . This type of regression is often used when  multicollinearity  exists between predictors in a dataset.
The complete R code used in this tutorial can be found  here .
<h2><span class="orange">Principal Components Regression in Python (Step-by-Step)</span></h2>
Given a set of <em>p</em> predictor variables and a response variable,  multiple linear regression  uses a method known as least squares to minimize the sum of squared residuals (RSS):
<b>RSS = Σ(y<sub>i</sub> – <U+0177><sub>i</sub>)<sup>2</sup></b>
where:
<b>Σ</b>: A greek symbol that means <em>sum</em>
<b>y<sub>i</sub></b>: The actual response value for the i<sup>th</sup> observation
<b><U+0177><sub>i</sub></b>: The predicted response value based on the multiple linear regression model
However, when the predictor variables are highly correlated then  multicollinearity  can become a problem. This can cause the coefficient estimates of the model to be unreliable and have high variance.
One way to avoid this problem is to instead use  principal components regression , which finds <em>M</em> linear combinations (known as “principal components”) of the original <em>p</em> predictors and then uses least squares to fit a linear regression model using the principal components as predictors.
This tutorial provides a step-by-step example of how to perform principal components regression in Python.
<h3>Step 1: Import Necessary Packages</h3>
First, we’ll import the necessary packages to perform principal components regression (PCR) in Python:
<b>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import scale 
from sklearn import model_selection
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
</b>
<h3>Step 2: Load the Data</h3>
For this example, we’ll use a dataset called <b>mtcars</b>, which contains information about 33 different cars. We’ll use <b>hp</b> as the response variable and the following variables as the predictors:
mpg
disp
drat
wt
qsec
The following code shows how to load and view this dataset:
<b>#define URL where data is located
url = "https://raw.githubusercontent.com/Statology/Python-Guides/main/mtcars.csv"
#read in data
data_full = pd.read_csv(url)
#select subset of data
data = data_full[["mpg", "disp", "drat", "wt", "qsec", "hp"]]
#view first six rows of data
data[0:6]
        mpgdispdratwtqsechp
021.0160.03.902.62016.46110
121.0160.03.902.87517.02110
222.8108.03.852.32018.6193
321.4258.03.083.21519.44110
418.7360.03.153.44017.02175
518.1225.02.763.46020.22105</b>
<h3>Step 3: Fit the PCR Model</h3>
The following code shows how to fit the PCR model to this data. Note the following:
<b>pca.fit_transform(scale(X))</b>: This tells Python that each of the predictor variables should be scaled to have a mean of 0 and a standard deviation of 1. This ensures that no predictor variable is overly influential in the model if it happens to be measured in different units.
<b>cv = RepeatedKFold()</b>: This tells Python to use  k-fold cross-validation  to evaluate the performance of the model. For this example we choose k = 10 folds, repeated 3 times.
<b>#define predictor and response variables
X = data[["mpg", "disp", "drat", "wt", "qsec"]]
y = data[["hp"]]
#scale predictor variables
pca = PCA()
X_reduced = pca.fit_transform(scale(X))
#define cross validation method
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
regr = LinearRegression()
mse = []
# Calculate MSE with only the intercept
score = -1*model_selection.cross_val_score(regr,
           np.ones((len(X_reduced),1)), y, cv=cv,
           scoring='neg_mean_squared_error').mean()    
mse.append(score)
# Calculate MSE using cross-validation, adding one component at a time
for i in np.arange(1, 6):
    score = -1*model_selection.cross_val_score(regr,
               X_reduced[:,:i], y, cv=cv, scoring='neg_mean_squared_error').mean()
    mse.append(score)
    
# Plot cross-validation results    
plt.plot(mse)
plt.xlabel('Number of Principal Components')
plt.ylabel('MSE')
plt.title('hp')</b>
<h3><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/pcrPython1.png"></h3>
The plot displays the number of principal components along the x-axis and the test MSE (mean squared error) along the y-axis.
From the plot we can see that the test MSE decreases by adding in two principal components, yet it begins to increase as we add more than two principal components.
Thus, the optimal model includes just the first two principal components.
We can also use the following code to calculate the percentage of variance in the response variable explained by adding in each principal component to the model:
<b>np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)
array([69.83, 89.35, 95.88, 98.95, 99.99])
</b>
We can see the following:
By using just the first principal component, we can explain <b>69.83%</b> of the variation in the response variable.
By adding in the second principal component, we can explain <b>89.35%</b> of the variation in the response variable.
Note that we’ll always be able to explain more variance by using more principal components, but we can see that adding in more than two principal components doesn’t actually increase the percentage of explained variance by much.
<h3>Step 4: Use the Final Model to Make Predictions</h3>
We can use the final PCR model with two principal components to make predictions on new observations.
The following code shows how to split the original dataset into a training and testing set and use the PCR model with two principal components to make predictions on the testing set.
<b>#split the dataset into training (70%) and testing (30%) sets
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0) 
#scale the training and testing data
X_reduced_train = pca.fit_transform(scale(X_train))
X_reduced_test = pca.transform(scale(X_test))[:,:1]
#train PCR model on training data 
regr = LinearRegression()
regr.fit(X_reduced_train[:,:1], y_train)
#calculate RMSE
pred = regr.predict(X_reduced_test)
np.sqrt(mean_squared_error(y_test, pred))
40.2096
</b>
We can see that the test RMSE turns out to be <b>40.2096</b>. This is the average deviation between the predicted value for <em>hp</em> and the observed value for <em>hp</em> for the observations in the testing set.
The complete Python code use in this example can be found  here .
<h2><span class="orange">Principal Components Regression in R (Step-by-Step)</span></h2>
Given a set of <em>p</em> predictor variables and a response variable,  multiple linear regression  uses a method known as least squares to minimize the sum of squared residuals (RSS):
<b>RSS = Σ(y<sub>i</sub> – <U+0177><sub>i</sub>)<sup>2</sup></b>
where:
<b>Σ</b>: A greek symbol that means <em>sum</em>
<b>y<sub>i</sub></b>: The actual response value for the i<sup>th</sup> observation
<b><U+0177><sub>i</sub></b>: The predicted response value based on the multiple linear regression model
However, when the predictor variables are highly correlated then  multicollinearity  can become a problem. This can cause the coefficient estimates of the model to be unreliable and have high variance.
One way to avoid this problem is to instead use  principal components regression , which finds <em>M</em> linear combinations (known as “principal components”) of the original <em>p</em> predictors and then uses least squares to fit a linear regression model using the principal components as predictors.
This tutorial provides a step-by-step example of how to perform principal components regression in R.
<h3>Step 1: Load Necessary Packages</h3>
The easiest way to perform principal components regression in R is by using functions from the  pls  package.
<b>#install pls package (if not already installed)
install.packages("pls")
load pls package
library(pls)
</b>
<h3>Step 2: Fit PCR Model</h3>
For this example, we’ll use the built-in R dataset called <b>mtcars</b> which contains data about various types of cars:
<b>#view first six rows of mtcars dataset
head(mtcars)
   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
</b>
For this example we’ll fit a principal components regression (PCR) model using <em>hp</em> as the  response variable  and the following variables as the predictor variables:
mpg
disp
drat
wt
qsec
The following code shows how to fit the PCR model to this data. Note the following arguments:
<b>scale=TRUE</b>: This tells R that each of the predictor variables should be scaled to have a mean of 0 and a standard deviation of 1. This ensures that no predictor variable is overly influential in the model if it happens to be measured in different units.
<b>validation=”CV”</b>: This tells R to use  k-fold cross-validation  to evaluate the performance of the model. Note that this uses k=10 folds by default. Also note that you can specify “LOOCV” instead to perform  leave-one-out cross-validation .
<b>#make this example reproducible
set.seed(1)
#fit PCR model
model &lt;- pcr(hp~mpg+disp+drat+wt+qsec, data=mtcars, scale=TRUE, validation="CV")</b>
<h3>Step 3: Choose the Number of Principal Components</h3>
Once we’ve fit the model, we need to determine the number of principal components worth keeping.
The way to do so is by looking at the test root mean squared error (test RMSE) calculated by the k-fold cross-validation:
<b>#view summary of model fitting
summary(model)
Data: X dimension: 32 5 
Y dimension: 32 1
Fit method: svdpc
Number of components considered: 5
VALIDATION: RMSEP
Cross-validated using 10 random segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps
CV           69.66    44.56    35.64    35.83    36.23    36.67
adjCV        69.66    44.44    35.27    35.43    35.80    36.20
TRAINING: % variance explained
    1 comps  2 comps  3 comps  4 comps  5 comps
X     69.83    89.35    95.88    98.96   100.00
hp    62.38    81.31    81.96    81.98    82.03
</b>
There are two tables of interest in the output:
<b>1. VALIDATION: RMSEP</b>
This table tells us the test RMSE calculated by the k-fold cross validation. We can see the following:
If we only use the intercept term in the model, the test RMSE is <b>69.66</b>.
If we add in the first principal component, the test RMSE drops to <b>44.56.</b>
If we add in the second principal component, the test RMSE drops to <b>35.64.</b>
We can see that adding additional principal components actually leads to an increase in test RMSE. Thus, it appears that it would be optimal to only use two principal components in the final model.
<b>2. TRAINING: % variance explained</b>
This table tells us the percentage of the variance in the response variable explained by the principal components. We can see the following:
By using just the first principal component, we can explain <b>69.83%</b> of the variation in the response variable.
By adding in the second principal component, we can explain <b>89.35%</b> of the variation in the response variable.
Note that we’ll always be able to explain more variance by using more principal components, but we can see that adding in more than two principal components doesn’t actually increase the percentage of explained variance by much.
We can also visualize the test RMSE (along with the test MSE and R-squared) based on the number of principal components by using the <b>validationplot()</b> function. 
<b>#visualize cross-validation plots
validationplot(model)
validationplot(model, val.type="MSEP")
validationplot(model, val.type="R2")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/PCR1.png">
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/PCR2.png">
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/PCR3.png">
In each plot we can see that the model fit improves by adding in two principal components, yet it tends to get worse when we add more principal components.
Thus, the optimal model includes just the first two principal components.
<h3>Step 4: Use the Final Model to Make Predictions</h3>
We can use the final PCR model with two principal components to make predictions on new observations.
The following code shows how to split the original dataset into a training and testing set and use the PCR model with two principal components to make predictions on the testing set.
<b>#define training and testing sets
train &lt;- mtcars[1:25, c("hp", "mpg", "disp", "drat", "wt", "qsec")]
y_test &lt;- mtcars[26:nrow(mtcars), c("hp")]
test &lt;- mtcars[26:nrow(mtcars), c("mpg", "disp", "drat", "wt", "qsec")]
    
#use model to make predictions on a test set
model &lt;- pcr(hp~mpg+disp+drat+wt+qsec, data=train, scale=TRUE, validation="CV")
pcr_pred &lt;- predict(model, test, ncomp=2)
#calculate RMSE
sqrt(mean((pcr_pred - y_test)^2))
[1] 56.86549
</b>
We can see that the test RMSE turns out to be <b>56.86549</b>. This is the average deviation between the predicted value for <em>hp</em> and the observed value for <em>hp</em> for the observations in the testing set.
The complete R code use in this example can be found  here .
<h2><span class="orange">An Introduction to Principal Components Regression</span></h2>
One of the most common problems that you’ll encounter when building models is  multicollinearity . This occurs when two or more predictor variables in a dataset are highly correlated.
When this occurs, a given model may be able to fit a training dataset well but it will likely perform poorly on a new dataset it has never seen because it  overfit  the training set.
One way to avoid overfitting is to use some type of <b>subset selection</b> method like:
 Best subset selection 
 Stepwise selection 
These methods attempt to remove irrelevant predictors from the model so that only the most important predictors that are capable of predicting the variation in the response variable are left in the final model.
Another way to avoid overfitting is to use some type of <b>regularization</b> method like:
 Ridge Regression 
 Lasso Regression 
These methods attempt to constrain or <em>regularize</em> the coefficients of a model to reduce the variance and thus produce models that are able to generalize well to new data.
An entirely different approach to dealing with multicollinearity is known as <b>dimension reduction</b>.
A common method of dimension reduction is know as <b>principal components regression</b>, which works as follows:
<b>1.</b> Suppose a given dataset contains <em>p</em> predictors: X<sub>1</sub>, X<sub>2</sub>, … , X<sub>p</sub>
<b>2.</b> Calculate Z<sub>1</sub>, … , Z<sub>M</sub> to be the <em>M</em> linear combinations of the original <em>p</em> predictors.
Z<sub>m</sub> = ΣΦ<sub>jm</sub>X<sub>j</sub> for some constants Φ<sub>1m</sub>, Φ<sub>2m</sub>, Φ<sub>pm</sub>, m = 1, …, M.
Z<sub>1</sub> is the linear combination of the predictors that captures the most variance possible.
Z<sub>2</sub> is the next linear combination of the predictors that captures the most variance while being <em>orthogonal</em> (i.e. uncorrelated) to Z<sub>1</sub>.
Z<sub>3 </sub>is then the next linear combination of the predictors that captures the most variance while being orthogonal to Z<sub>2</sub>.
And so on.
<b>3.</b> Use the method of least squares to fit a linear regression model using the first <em>M</em> principal components Z<sub>1</sub>, …, Z<sub>M</sub> as predictors.
The phrase <b>dimension reduction</b> comes from the fact that this method only has to estimate M+1 coefficients instead of p+1 coefficients, where M &lt; p.
In other words, the <em>dimension</em> of the problem has been reduced from p+1 to M+1.
In many cases where multicollinearity is present in a dataset, principal components regression is able to produce a model that can generalize to new data better than conventional  multiple linear regression .
<h3>Steps to Perform Principal Components Regression</h3>
In practice, the following steps are used to perform principal components regression:
<b>1. Standardize the predictors.</b>
First, we typically standardize the data such that each predictor variable has a mean value of 0 and a standard deviation of 1. This prevents one predictor from being overly influential, especially if it’s measured in different units (i.e. if X<sub>1</sub> is measured in inches and X<sub>2</sub> is measured in yards).
<b>2. Calculate the principal components and perform linear regression using the principal components as predictors.</b>
Next, we calculate the principal components and use the method of least squares to fit a linear regression model using the first <em>M</em> principal components Z<sub>1</sub>, …, Z<sub>M</sub> as predictors.
<b>3. Decide how many principal components to keep.</b>
Next, we use  k-fold cross-validation  to find the optimal number of principal components to keep in the model. The “optimal” number of principal components to keep is typically the number that produces the lowest test mean-squared error (MSE).
<h3>Pros & Cons of Principal Components Regression</h3>
Principal Components Regression (PCR) offers the following <b>pros</b>:
PCR tends to perform well when the first few principal components are able to capture most of the variation in the predictors along with the relationship with the response variable.
PCR can perform well even when the predictor variables are highly correlated because it produces principal components that are orthogonal (i.e. uncorrelated) to each other.
PCR doesn’t require you to choose which predictor variables to remove from the model since each principal component uses a linear combination of all of the predictor variables.
PCR can be used when there are more predictor variables than observations, unlike multiple linear regression.
However, PCR comes with one <b>con:</b>
PCR does not consider the response variable when deciding which principal components to keep or drop. Instead, it only considers the magnitude of the variance among the predictor variables captured by the principal components. It’s possible that in some cases the principal components with the largest variances aren’t actually able to predict the response variable well.
In practice, we fit many different types of models (PCR, Ridge, Lasso, Multiple Linear Regression, etc.) and use k-fold cross-validation to identify the model that produces the lowest test MSE on new data.
In cases where multicollinearity is present in the original dataset (which is often), PCR tends to perform better than ordinary least squares regression. However, it’s a good idea to fit several different models so that you can identify the one that generalizes best to unseen data.
<h3>Principal Components Regression in R & Python</h3>
The following tutorials show how to perform principal components regression in R and Python:
 Principal Components Regression in R (Step-by-Step) 
 Principal Components Regression in Python (Step-by-Step) 
<h2><span class="orange">How to Print All Rows of a Tibble in R</span></h2>
A <b>tibble</b> is a data frame in R that has a refined print method that only shows the first 10 rows of a data frame. This makes it much easier to work with large data and prevents R from attempting to display every row of a data frame.
For example, consider the following tibble with 80 rows and 2 columns:
<b>#load dplyr
library(dplyr)
#make this example reproducible
set.seed(1)
#create tibble
data &lt;- tibble(a = rnorm(80),
               b = rnorm(80))
</b>
<b>#view tibble
data
# A tibble: 80 x 2
        a      b
      
 1 -0.626 -0.569
 2  0.184 -0.135
 3 -0.836  1.18 
 4  1.60  -1.52 
 5  0.330  0.594
 6 -0.820  0.333
 7  0.487  1.06 
 8  0.738 -0.304
 9  0.576  0.370
10 -0.305  0.267
# ... with 70 more rows</b>
When we type in the name of the tibble in R, it will only show the first 10 rows by default. However, it does tell us that there are <b>70 more rows </b>that are not being displayed.
But in some cases you may actually want to see more than just 10 rows of a tibble.
<b>Note: </b>If you’re new to tibbles, a great place to start is the  tibbles chapter  in <em>R for Data Science</em>.
<h3>Print a Specific Number of Rows of a Tibble</h3>
You can print a specific number of rows of a tibble by specifying a number in the <b>print() </b>function:
<b>#print first 20 rows of tibble
print(data, n=20)
# A tibble: 80 x 2
         a      b
       
 1 -0.626  -0.569
 2  0.184  -0.135
 3 -0.836   1.18 
 4  1.60   -1.52 
 5  0.330   0.594
 6 -0.820   0.333
 7  0.487   1.06 
 8  0.738  -0.304
 9  0.576   0.370
10 -0.305   0.267
11  1.51   -0.543
12  0.390   1.21 
13 -0.621   1.16 
14 -2.21    0.700
15  1.12    1.59 
16 -0.0449  0.558
17 -0.0162 -1.28 
18  0.944  -0.573
19  0.821  -1.22 
20  0.594  -0.473
# ... with 60 more rows</b>
You can also use the pipe operator to achieve the same result:
<b>#print first 20 rows of tibble
data %>% print(n=20)
# A tibble: 80 x 2
         a      b
       
 1 -0.626  -0.569
 2  0.184  -0.135
 3 -0.836   1.18 
 4  1.60   -1.52 
 5  0.330   0.594
 6 -0.820   0.333
 7  0.487   1.06 
 8  0.738  -0.304
 9  0.576   0.370
10 -0.305   0.267
11  1.51   -0.543
12  0.390   1.21 
13 -0.621   1.16 
14 -2.21    0.700
15  1.12    1.59 
16 -0.0449  0.558
17 -0.0162 -1.28 
18  0.944  -0.573
19  0.821  -1.22 
20  0.594  -0.473
# ... with 60 more rows</b>
<h3>Print a All Rows of a Tibble</h3>
You can print every row of a tibble by specifying <b>n = Inf</b>:
<b>#print all rows of tibble
data %>% print(n=Inf)
# A tibble: 80 x 2
          a       b
         
 1 -0.626   -0.569 
 2  0.184   -0.135 
 3 -0.836    1.18  
 4  1.60    -1.52  
 5  0.330    0.594 
 6 -0.820    0.333 
 7  0.487    1.06  
 8  0.738   -0.304 
 9  0.576    0.370 
10 -0.305    0.267 
11  1.51    -0.543 
12  0.390    1.21  
13 -0.621    1.16  
14 -2.21     0.700 
15  1.12     1.59  
16 -0.0449   0.558 
17 -0.0162  -1.28  
18  0.944   -0.573 
19  0.821   -1.22  
20  0.594   -0.473 
21  0.919   -0.620 
22  0.782    0.0421
23  0.0746  -0.911 
24 -1.99     0.158 
25  0.620   -0.655 
26 -0.0561   1.77  
27 -0.156    0.717 
28 -1.47     0.910 
29 -0.478    0.384 
30  0.418    1.68  
31  1.36    -0.636 
32 -0.103   -0.462 
33  0.388    1.43  
34 -0.0538  -0.651 
35 -1.38    -0.207 
36 -0.415   -0.393 
37 -0.394   -0.320 
38 -0.0593  -0.279 
39  1.10     0.494 
40  0.763   -0.177 
41 -0.165   -0.506 
42 -0.253    1.34  
43  0.697   -0.215 
44  0.557   -0.180 
45 -0.689   -0.100 
46 -0.707    0.713 
47  0.365   -0.0736
48  0.769   -0.0376
49 -0.112   -0.682 
50  0.881   -0.324 
51  0.398    0.0602
52 -0.612   -0.589 
53  0.341    0.531 
54 -1.13    -1.52  
55  1.43     0.307 
56  1.98    -1.54  
57 -0.367   -0.301 
58 -1.04    -0.528 
59  0.570   -0.652 
60 -0.135   -0.0569
61  2.40    -1.91  
62 -0.0392   1.18  
63  0.690   -1.66  
64  0.0280  -0.464 
65 -0.743   -1.12  
66  0.189   -0.751 
67 -1.80     2.09  
68  1.47     0.0174
69  0.153   -1.29  
70  2.17    -1.64  
71  0.476    0.450 
72 -0.710   -0.0186
73  0.611   -0.318 
74 -0.934   -0.929 
75 -1.25    -1.49  
76  0.291   -1.08  
77 -0.443    1.00  
78  0.00111 -0.621 
79  0.0743  -1.38  
80 -0.590    1.87</b>
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">How to Print Tables in R (3 Examples)</span></h2>
Often you may want to print a table to the console in R to summarize the values in some dataset.
The following examples show how to print tables in R by using the <b>table()</b> and <b>as.table()</b> functions.
<h2>Example 1: Print One-Way Table from Data</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), position=c('Guard', 'Guard', 'Forward', 'Guard', 'Forward',            'Forward', 'Guard', 'Guard', 'Forward'), points=c(14, 12, 15, 20, 22, 36, 10, 16, 19))
#view data frame
df
  team position points
1    A    Guard     14
2    A    Guard     12
3    A  Forward     15
4    B    Guard     20
5    B  Forward     22
6    B  Forward     36
7    C    Guard     10
8    C    Guard     16
9    C  Forward     19</b>
We can use the <b>table()</b> function to summarize the count of each unique value in the <b>position</b> column:
<b>#create table for 'position' variable
table1 &lt;- table(df$position)
#view table
table1
Forward   Guard 
      4       5
</b>
From the table we can see that ‘Forward’ appears 4 times in the position column and ‘Guard’ appears 5 times.
This is referred to as a <b>one-way table</b> because it summarizes one variable.
<h2>Example 2: Print Two-Way Table from Data</h2>
Once again suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), position=c('Guard', 'Guard', 'Forward', 'Guard', 'Forward',            'Forward', 'Guard', 'Guard', 'Forward'), points=c(14, 12, 15, 20, 22, 36, 10, 16, 19))
#view data frame
df
  team position points
1    A    Guard     14
2    A    Guard     12
3    A  Forward     15
4    B    Guard     20
5    B  Forward     22
6    B  Forward     36
7    C    Guard     10
8    C    Guard     16
9    C  Forward     19</b>
We can use the <b>table()</b> function to summarize the count of each unique value in the <b>team</b> and <b>position</b> columns:
<b>#create two-way table for 'team' and 'position' variables
table2 &lt;- table(df$team, df$position)
#view table
table2
    Forward Guard
  A       1     2
  B       2     1
  C       1     2
</b>
From the table we can see:
There is <b>1</b> Forward on team A.
There are <b>2</b> Guards on team A.
There are <b>2</b> Forwards on team B.
And so on.
This is referred to as a <b>two-way table</b> because it summarizes the count of two variables.
<h2>Example 3: Print Table From Scratch</h2>
Suppose we already know the values that we’d like to fill in a table.
For example, suppose we want to create the following table in R that shows the results of a survey that asked 100 people which sport they liked best:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/jointFreq1.png">
We can use the <b>as.table()</b> function in R to quickly create this table:
<b>#create matrix
data &lt;- matrix(c(13, 23, 15, 16, 20, 13), ncol=3)
#specify row and column names of matrix
rownames(data) &lt;- c('Male', 'Female')
colnames(data) &lt;- c('Baseball', 'Basketball', 'Football')
#convert matrix to table
data &lt;- as.table(data)
#display table
data
       Baseball Basketball Football
Male         13         15       20
Female       23         16       13</b>
The values in the table match the values from the table we saw earlier.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Create a Two Way Table in R 
 How to Create a Contingency Table in R 
 How to Use rbindlist in R to Make One Data Table from Many 
<h2><span class="orange">Probability Distribution Calculator</span></h2>
</style>
This calculator automatically finds the mean, standard deviation, and variance for any probability distribution.
Simply fill in the cells below for up to 10 values, then click the “Calculate” button:
<i><b>Note:</b> The Probability column must add up to 1.</i>
<table><tbody>
<tr>
<th><b>Outcome</b></th>
<th><b><span>Probability</b></th>
<th><b><span>Value</b></th>
</tr>
<tr>
<td>Outcome 1</td>
<td><input type="text" id="p1" value="0.18"></td>
<td><input type="text" id="f1" value="0"></td>
</tr>
<tr>
<td>Outcome 2</td>
<td><input type="text" id="p2" value="0.34"></td>
<td><input type="text" id="f2" value="1"></td>
</tr>
<tr>
<td>Outcome 3</td>
<td><input type="text" id="p3" value="0.35"></td>
<td><input type="text" id="f3" value="2"></td>
</tr>
<tr>
<td>Outcome 4</td>
<td><input type="text" id="p4" value="0.11"></td>
<td><input type="text" id="f4" value="3"></td>
</tr>
<tr>
<td>Outcome 5</td>
<td><input type="text" id="p5" value="0.02"></td>
<td><input type="text" id="f5" value="4"></td>
</tr>
<tr>
<td>Outcome 6</td>
<td><input type="text" id="p6"></td>
<td><input type="text" id="f6"></td>
</tr>
<tr>
<td>Outcome 7</td>
<td><input type="text" id="p7"></td>
<td><input type="text" id="f7"></td>
</tr>
<tr>
<td>Outcome 8</td>
<td><input type="text" id="p8"></td>
<td><input type="text" id="f8"></td>
</tr>
<tr>
<td>Outcome 9</td>
<td><input type="text" id="p9"></td>
<td><input type="text" id="f9"></td>
</tr>
<tr>
<td>Outcome 10</td>
<td><input type="text" id="p10"></td>
<td><input type="text" id="f10"></td>
</tr>
</tbody></table>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
Mean (μ) =  <b>1.4500</b>
Standard Deviation (σ) =  <b>0.9734</b>
Variance (σ<sup>2</sup>) =  <b>0.9475</b>
<b>Probabilities must add up to 1. They currently add up to 0.359</b>
<script>
//show answer to start
var answer_display = document.getElementById("answer");
//hide error message to start
var error_msg_display = document.getElementById("error_msg");
error_msg_display.style.display = "none";
function calc() {
//get input data
var p1 = document.getElementById('p1').value;
var p2 = document.getElementById('p2').value;
var p3 = document.getElementById('p3').value;
var p4 = document.getElementById('p4').value;
var p5 = document.getElementById('p5').value;
var p6 = document.getElementById('p6').value;
var p7 = document.getElementById('p7').value;
var p8 = document.getElementById('p8').value;
var p9 = document.getElementById('p9').value;
var p10 = document.getElementById('p10').value;
var f1 = document.getElementById('f1').value;
var f2 = document.getElementById('f2').value;
var f3 = document.getElementById('f3').value;
var f4 = document.getElementById('f4').value;
var f5 = document.getElementById('f5').value;
var f6 = document.getElementById('f6').value;
var f7 = document.getElementById('f7').value;
var f8 = document.getElementById('f8').value;
var f9 = document.getElementById('f9').value;
var f10 = document.getElementById('f10').value;
var p_group = [p1, p2, p3, p4, p5, p6, p7, p8, p9, p10];
var f_group = [f1, f2, f3, f4, f5, f6, f7, f8, f9, f10];
var p_sum = parseFloat(math.sum(p_group)).toFixed(5);
var n = math.sum(f_group);
//do calculations
if (p_sum == 1) {
  answer_display.style.display = "block";
  error_msg_display.style.display = "none";
  
  var muSTUFF = [];
  for (var i=0; i<f_group.length; i++) {
    muSTUFF[i] = f_group[i] * p_group[i];
  }
  var mu = muSTUFF.reduce((product, n) => product+n, 0);
  var varSTUFF = [];
  for (var i=0; i<f_group.length; i++) {
    varSTUFF[i] = f_group[i] * f_group[i] * p_group[i];
  }
  var variance = varSTUFF.reduce((product, n) => product+n, 0) - (mu*mu);
  var sd = math.sqrt(variance);
  
  document.getElementById('mu').innerHTML = mu.toFixed(4);
  document.getElementById('variance').innerHTML = variance.toFixed(4);
  document.getElementById('sd').innerHTML = sd.toFixed(4);
}
else {
  answer_display.style.display = "none";
  error_msg_display.style.display = "block";
  document.getElementById('p_sum').innerHTML = p_sum;
}
  
} //end massive calc function
</script>
<h2><span class="orange">What is a Probability Distribution Table? (Definition & Example)</span></h2>
A <b>probability distribution table</b> is a table that displays the probability that a  random variable  takes on certain values.
For example, the following probability distribution table tells us the probability that a certain soccer team scores a certain number of goals in a given game:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist1.png">
The left-hand column shows the number of goals and the right-hand column tells us the probability that the team will score this number of goals.
For example:
The probability that the team scores exactly 0 goals is <b>0.18</b>.
The probability that the team scores exactly 1 goal is <b>0.34</b>.
The probability that the team scores exactly 2 goals is <b>0.35</b>.
And so on.
<h3>Properties of a Probability Distribution Table</h3>
A probability distribution table has the following properties:
<b>1. All probabilities must add up to 1. </b>
For a probability distribution table to be valid, all of the individual probabilities must add up to 1. We can verify that the previous probability distribution table is valid:
Sum of probabilities = 0.18 + 0.34 + 0.35 + 0.11 + 0.02 = 1.
<b>2. The mean can be calculated.</b>
The formula to calculate the mean of a given probability distribution table is:
<b>μ = Σx * P(x)</b>
where:
<b>x:</b> Data value
<b>P(x):</b> Probability of value
For example, consider our probability distribution table for the soccer team:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist1.png"(max-width: 261px) 100vw, 261px">
The mean number of goals for the soccer team would be calculated as:
μ = 0*0.18  +  1*0.34  +  2*0.35  +  3*0.11  +  4*0.02  =  <b>1.45</b> goals.
<b>3. The standard deviation can be calculated.</b>
The formula to calculate the standard deviation of a given probability distribution table is:
<b>σ = √Σ(x<sub>i</sub>-μ)<sup>2</sup> * P(x<sub>i</sub>)</b>
where:
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value
<b>μ:</b> The mean of the distribution
<b>P(x<sub>i</sub>):</b> The probability of the i<sup>th</sup> value
For example, here’s how to calculate the standard deviation of goals scored by the soccer team:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sdDist1.png">
The standard deviation is the square root of the sum of the values in the third column:
Standard deviation = √(.3785 + .0689 + .1059 + .2643 + .1301) = <b>0.9734</b>
<h3>How to Visualize a Probability Distribution Table</h3>
The easiest way to visualize the values in a probability distribution table is by using a histogram, which displays the values of the random variable along the x-axis and the probability of those values along the y-axis:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/probDist1.png">
This lets us quickly visualize the probability values from the table.
In particular, we can see that there is a high probability that the team scores 2 goals or less while there is a tiny probability that the team scores as many as 4 goals.
<h2><span class="orange">Probability for Three Events Calculator</span></h2>
This calculator finds the probabilities associated with three events <i>A</i>, <i>B</i>, and <i>C</i>.
Simply enter the probabilities for the three events in the boxes below and then click the “Calculate” button.
<label for="a"><b>Probability of Event A</b></label>
<input type="number" id="a" min="0" max="1" value="0.3"><label for="b"><b>Probability of Event B</b></label>
<input type="number" id="b" min="0" max="1" value="0.25"><label for="c"><b>Probability of Event C</b></label>
<input type="number" id="c" min="0" max="1" value="0.6">
<input type="button" id="button_calc" onclick="calc()" value="Calculate">
P(all events occur) = <b>0.045000</b>
P(None of the events occur) = <b>0.210000</b>
P(At least one event occurs) = <b>0.790000</b>
P(Exactly one event occurs) = <b>0.475000</b>
<script>
function calc() {
//get input values and calculate WHIP
var a = document.getElementById('a').value*1;
var b = document.getElementById('b').value*1;
var c = document.getElementById('c').value*1;
var all = a*b*c;
var none = (1-a)*(1-b)*(1-c);
var atleast1 = 1-none;
var exactly1 = ((a)*(1-b)*(1-c)) - (-(1-a)*(b)*(1-c)) - (-(1-a)*(1-b)*(c));
//output
document.getElementById('all').innerHTML = all.toFixed(6);
document.getElementById('none').innerHTML = none.toFixed(6);
document.getElementById('atleast1').innerHTML = atleast1.toFixed(6);
document.getElementById('exactly1').innerHTML = exactly1.toFixed(6);
}
</script>
<h2><span class="orange">How to Calculate Probability in Excel (With Examples)</span></h2>
<b>Probability</b> describes the likelihood that some event occurs.
We can calculate probabilities in Excel by using the  PROB  function, which uses the following syntax:
<b>PROB(x_range, prob_range, lower_limit, [upper_limit])</b>
where:
<b>x_range: </b>The range of numeric x values.
<b>prob_range:</b> The range of probabilities associated with each x value.
<b>lower_limit:</b> The lower limit on the value for which you want a probability.
<b>upper_limit:</b> The upper limit on the value for which you want a probability. Optional.
This tutorial provides several examples of how to use this function in practice.
<h3>Example 1: Dice Probabilities</h3>
The following image shows the probability of a dice landing on a certain value on a given roll:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/probExcel1.png">
<em>Since the dice is equally likely to land on each value, the probability is the same for each value.</em>
The following image shows how to find the probability that the dice lands on a number between 3 and 6:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/probExcel2.png">
The probability turns out to be <b>0.5</b>.
Note that the upper limit argument is optional. So, we could use the following syntax to find the probability that the dice lands on just 4:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/probExcel3.png">
The probability turns out to be <b>0.166667</b>.
<h3>Example 2: Sales Probabilities</h3>
The following image shows the probability of a company selling a certain number of products in the upcoming quarter:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/probExcel4.png">
The following image shows how to find the probability that the company makes either 3 or 4 sales:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/probExcel5.png">
The probability turns out to be <b>0.7</b>.
<h2><span class="orange">How to Find the Probability of A and B (With Examples)</span></h2>
Given two events, A and B, to “find the probability of A and B” means to find the probability that <b>event A and event B both occur</b>.
We typically write this probability in one of two ways:
 P(A and B) – Written form
P(A∩B) – Notation form
The way we calculate this probability depends on whether or not events A and B are independent or dependent.
If A and B are <b>independent</b>, then the formula we use to calculate P(A∩B) is simply:
<b>Independent Events: P(A∩B) = P(A) * P(B)
</b>
If A and B are <b>dependent</b>, then the formula we use to calculate P(A∩B) is:
<b>Dependent Events: P(A∩B) = P(A) * P(B|A)</b>
Note that P(B|A) is the conditional probability of event B occurring, <em>given<b> </b></em>event A occurs.
The following examples show how to use these formulas in practice.
<h3>Examples of P(A∩B) for Independent Events</h3>
The following examples show how to calculate P(A∩B) when A and B are independent events.
<b>Example 1:</b> The probability that your favorite baseball team wins the World Series is 1/30 and the probability that your favorite football team wins the Super Bowl is 1/32. What is the probability that both of your favorite teams win their respective championships?
<b>Solution:</b> In this example, the probability of each event occurring is independent of the other. Thus, the probability that they both occur is calculated as:
P(A∩B) = (1/30) * (1/32) = 1/960 = .00104.
<b>Example 2:</b> You roll a dice and flip a coin at the same time. What is the probability that the dice lands on 4 and the coin lands on tails?
<b>Solution:</b> In this example, the probability of each event occurring is independent of the other. Thus, the probability that they both occur is calculated as:
P(A∩B) = (1/6) * (1/2) = 1/12 = .083333.
<h3>Examples of P(A∩B) for Dependent Events</h3>
The following examples show how to calculate P(A∩B) when A and B are dependent events.
<b>Example 1:</b> An urn contains 4 red balls and 4 green balls. You randomly choose one ball from the urn. Then, without replacement, you select another ball. What is the probability that you choose a red ball each time?
<b>Solution:</b> In this example, the color of the ball that we choose the first time affects the probability of choosing a red ball the second time. Thus, the two events are dependent.
Let’s define event A as the probability of selecting a red ball the first time. This probability is P(A) = 4/8. Next, we have to find the probability of selecting a red ball again, <em>given</em> that the first ball was red. In this case, there are only 3 red balls left to choose and only 7 total balls in the urn. Thus, P(B|A) is 3/7.
Thus, the probability that we select a red ball each time would be calculated as:
P(A∩B) = P(A) * P(B|A) = (4/8) * (3/7) = 0.214.
<b>Example 2:</b> In a certain classroom there are 15 boys and 12 girls. Suppose we place the names of each student in a bag. We randomly choose one name from the bag. Then, without replacement, we choose another name. What is the probability that both names are boys?
<b>Solution:</b> In this example, the name we choose the first time affects the probability of choosing a boy name during the second draw. Thus, the two events are dependent.
Let’s define event A as the probability of selecting a boy first time. This probability is P(A) = 15/27. Next, we have to find the probability of selecting a boy again, <em>given</em> that the first name was a boy. In this case, there are only 14 boys left to choose and only 26 total names in the bag. Thus, P(B|A) is 14/26.
Thus, the probability that we select a boy name each time would be calculated as:
P(A∩B) = P(A) * P(B|A) = (15/27) * (14/26) = 0.299.
<h2><span class="orange">How to Find the Probability of A Given B (With Examples)</span></h2>
Given two events, A and B, to “find the probability of A given B” means to find the probability that <b>event A occurs, given that event B has already occurred.</b>
We use the following formula to calculate this probability:
<b>P(A|B) = P(A)*P(B|A) / P(B)</b>
where:
P(A|B): The probability of event A, given event B has occurred.
P(B|A): The probability of event B, given event A has occurred.
P(A): The probability of event A.
P(B): The probability of event B.
The following examples show how to use this formula in practice.
<h2>Example 1: Probability of A Given B (Weather)</h2>
Suppose the probability of the weather being cloudy is <b>40%.</b>
 Also suppose the probability of rain on a given day is <b>20%</b>.
Also suppose the probability of clouds on a rainy day is <b>85%</b>. 
If it is cloudy outside on a given day, what is the probability that it will rain that day?
<b>Solution</b>:
P(cloudy) = 0.40
P(rain) = 0.20
P(cloudy | rain) = 0.85
Thus, we can calculate:
P(rain | cloudy) = P(rain) * P(cloudy | rain) / P(cloudy)
P(rain | cloudy) = 0.20 * 0.85 / 0.40
P(rain | cloudy) = 0.425
If it is cloudy outside on a given day, the probability that it will rain that day is <b>0.425</b> or <b>42.5%</b>.
<h2>Example 2: Probability of A Given B (Crime)</h2>
Suppose the probability of a crime being committed in a certain place is <b>1%</b>.
 Also suppose the probability of a police car driving by is <b>10%</b>.
Also suppose the probability of a crime causing a police car to drive by is <b>90%</b>.
If a police car drives by, what is the probability that a crime has been committed?
<b>Solution</b>:
P(crime) = 0.01
P(police car) = 0.10
P(police car | crime) = 0.90
Thus, we can calculate:
P(crime | police car) = P(crime) * P(police car | crime) / P(police car)
P(crime | police car) = 0.01 * 0.90 / 0.10
P(crime | police car) = 0.09
If a police car drives by, the probability that a crime has been committed is .09 or <b>9%</b>.
<h2>Example 3: Probability of A Given B (Baseball)</h2>
Suppose the probability of a home run being hit in a baseball game is <b>5%</b>.
 Also suppose the probability of a crowd cheering in a stadium when you walk by is <b>15%</b>.
Also suppose the probability of a crowd cheering when a home run has been hit is <b>99%</b>.
If you hear a crowd cheering as you walk by the stadium, what is the probability that a home run has been hit?
<b>Solution</b>:
P(home run) = 0.05
P(cheer) = 0.15
P(cheer | home run) = 0.99
Thus, we can calculate:
P(home run | cheer) = P(home run) * P(cheer | home run) / P(cheer)
P(home run | cheer) = 0.05 * 0.99 / 0.15
P(home run | cheer) = 0.33
If you hear a crowd cheering as you walk by the stadium, the probability that a home run has been hit is 0.33 or <b>33%</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other calculations related to probabilities:
 How to Find the Probability of A or B 
 How to Find the Probability of A and B 
 How to Find the Probability of “At Least One” Success 
<h2><span class="orange">How to Find the Probability of A or B (With Examples)</span></h2>
Given two events, A and B, to “find the probability of A or B” means to find the probability that <b>either event A or event B occurs</b>.
We typically write this probability in one of two ways:
 P(A or B) – Written form
P(A∪B) – Notation form
The way we calculate this probability depends on whether or not events A and B are  mutually exclusive  or not. Two events are mutually exclusive if they cannot occur at the same time.
If A and B are <b>mutually exclusive</b>, then the formula we use to calculate P(A∪B) is:
<b>Mutually Exclusive Events: P(A∪B) = P(A) + P(B)
</b>
If A and B are <b>not mutually exclusive</b>, then the formula we use to calculate P(A∪B) is:
<b>Not Mutually Exclusive Events: P(A∪B) = P(A) + P(B) - P(A∩B)</b>
Note that P(A∩B) is the probability that event A and event B both occur.
The following examples show how to use these formulas in practice.
<h3>Examples: P(A∪B) for Mutually Exclusive Events</h3>
<b>Example 1:</b> What is the probability of rolling a dice and getting either a 2 or a 5?
<b>Solution:</b> If we define event A as getting a 2 and event B as getting a 5, then these two events are mutually exclusive because we can’t roll a 2 <em>and</em> a 5 at the same time. Thus, the probability that we roll either a 2 or a 5 is calculated as:
P(A∪B) = (1/6) + (1/6) = 2/6 = 1/3.
<b>Example 2:</b> Suppose an urn contains 3 red balls, 2 green balls, and 5 yellow balls. If we randomly select one ball, what is the probability of selecting either a red or green ball?
<b>Solution:</b> If we define event A as selecting a red ball and event B as selecting a green ball, then these two events are mutually exclusive because we can’t select a ball that is both red and green. Thus, the probability that we select either a red or green ball is calculated as:
P(A∪B) = (3/10) + (2/10) = 5/10 = 1/2.
<h3>
<b>Examples: P(A∪B) for Not Mutually Exclusive Events</b>
</h3>
The following examples show how to calculate P(A∪B) when A and B are not mutually exclusive events.
<b>Example 1:</b> If we randomly select a card from a standard 52-card deck, what is the probability of choosing either a Spade or a Queen?
<b>Solution:</b> In this example, it’s possible to choose a card that is both a Spade <em>and</em> a Queen, thus these two events are not mutually exclusive.
If we let event A be the event of choosing a Spade and event B be the event of choosing a Queen, then we have the following probabilities:
P(A) = 13/52
P(B) = 4/52
P(A∩B) = 1/52
Thus, the probability of choosing either a Spade or a Queen is calculated as:
P(A∪B) = P(A) + P(B) – P(A∩B) = (13/52) + (4/52) – (1/52) = 16/52 = 4/13.
<b>Example 2:</b> If we roll a dice, what is the probability that it lands on a number greater than 3 or an even number?
<b>Solution:</b> In this example, it’s possible for the dice to land on a number that is both greater than 3 <em>and</em> even, thus these two events are not mutually exclusive.
If we let event A be the event of rolling a number greater than 3 and event B be the event of rolling an even number, then we have the following probabilities:
P(A) = 3/6
P(B) = 3/6
P(A∩B) = 2/6
Thus, the probability that the dice lands on a number greater than 3 or an even number is calculated as:
P(A∪B) = P(A) + P(B) – P(A∩B) = (3/6) + (3/6) – (2/6) = 4/6 = 2/3.
<h2><span class="orange">Probability of “At Least One” Calculator</span></h2>
The formula to find the probability of “at least one” success in a series of <i>n</i> trials is calculated as:
P(at least one success) = P(failure in a given trial)<sup>n</sup>
This calculator finds the probability of at least one success, given the probability of success in a single trial and the total number of trials.
<label><b>p</b> (probability of success in a given trial)</label>
<input type="number" id="p" value="0.04">
<label><b>n</b> (number of trials)</label>
<input type="number" id="n" value="3">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
P(at least one success) = 1 – P(failure in a given trial)<sup>n</sup>
P(at least one success) = 1 – (0.96)<sup>3</sup>
P(at least one success): 0.11526
<script>
function calc() {
//get input values
var p = +document.getElementById('p').value;
var n = +document.getElementById('n').value;
var fail = 1-p;
//calculate prob of at least one success
var atLeast = 1 - Math.pow(1-p, n);
//output probabilities
document.getElementById('atLeast').innerHTML = atLeast.toFixed(5);
document.getElementById('fail').innerHTML = fail;
document.getElementById('n_out').innerHTML = n;
}
</script>
<h2><span class="orange">How to Find Probability of At Least One Head in Coin Flips</span></h2>
For any given coin flip, the probability of getting “heads” is 1/2 or 0.5.
To find the probability of at least one head during a certain number of coin flips, you can use the following formula:
<b>P(At least one head) = 1 – 0.5<sup>n</sup></b>
where:
<b>n</b>: Total number of flips
For example, suppose we flip a coin 2 times.
The probability of getting at least one head during these 3 flips is:
P(At least one head) = 1 – 0.5<sup>n</sup>
P(At least one head) = 1 – 0.5<sup>3</sup>
P(At least one head) = 1 – 0.125
P(At least one head) = <b>0.875</b>
This answer makes sense if we list out every possible outcome for 2 coin flips with “T” representing tails and “H” representing heads:
TTT
TTH
THH
THT
HHH
HHT
HTH
HTT
Notice that at least one head (H) appears in 7 out of 8 possible outcomes, which is equal to 7/8 = <b>0.875</b>.
Or suppose we flip a coin 5 times.
The probability of getting at least one head during these 5 flips is:
P(At least one head) = 1 – 0.5<sup>n</sup>
P(At least one head) = 1 – 0.5<sup>5</sup>
P(At least one head) = 1 – 0.25
P(At least one head) = <b>0.96875</b>
The following table shows the probability of getting at least one head during various amounts of coin flips:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/head1.jpg">
Notice that the higher number of coin flips, the higher the probability of getting at least one head.
This should make sense considering the fact that we should have a higher probability of eventually seeing a head appear if we keep flipping the coin more times.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common calculations related to probabilities:
 How to Find the Probability of “At Least One” Success 
 How to Find the Probability of “At Least Two” Successes 
 How to Find the Probability of A and B 
 How to Find the Probability of A or B 
<h2><span class="orange">How to Find the Probability of “At Least One” Success</span></h2>
<b>Probability</b> tells us the likelihood that some event occurs.
For example, suppose 4% of all students at a certain school prefer math as their favorite subject. If we randomly select one student, the probability that they prefer math would be 4%.
But often we’re interested in probabilities involving <em>several</em> trials. For example, if we randomly select three students, what is the probability that <b>at least one</b> prefers math? 
We can use the following steps to answer this:
<b>1. Find the probability that a student does not prefer math.</b>
We know the probability that a student prefers math is P(prefers math) = .04.
Thus, the probability that a student does not prefer math is P(does not prefer math) = .96.
<b>2. Find the probability that all students selected do not prefer math.</b>
Since the probability that each student prefers math is independent of each other, we can simply multiply the individual probabilities together:
P(all students do not prefer math) = .96 * .96 * .96 = .8847.
This represents the probability that all three students do not prefer math as their favorite subject.
<b>3. Find the probability that at least one student prefers math.</b>
Lastly, the probability that at least one student prefers math is calculated as:
P(at least one prefers math) = 1 – P(all do not prefer math) = 1 – .8847 = <b>.1153</b>.
It turns out that we can use the following general formula to find the probability of at least one success in a series of trials:
<b>P(at least one success) = 1 - P(failure in one trial)<sup>n</sup></b>
In the formula above, <em>n</em> represents the total number of trials.
For example, we could have used this formula to find the probability that at least one student in a random sample of three preferred math as their favorite subject:
P(at least one student prefers math) = 1 – (.96)<sup>3</sup> = <b>.1153</b>.
This matches the answer that we got using the three-step process above.
Use the following examples as additional practice for finding the probability of “at least one” success.
<b>Related:</b>  How to Find the Probability of “At Least Two” Successes 
<h3>Example 1: Free-Throw Attempts</h3>
Mike makes 20% of his free-throw attempts. If he attempts 5 free-throws, find the probability that he makes at least one.
<b>Solution:</b>
P(makes at least one) = 1 – P(misses a given attempt)<sup>n</sup>
P(makes at least one) = 1 – (0.80)<sup>5</sup>
P(makes at least one) = 0.672
The probability that Mike makes at least one free-throw in five attempts is <b>0.672</b>.
<h3>Example 2: Widgets</h3>
At a given factory, 2% of all widgets are defective. In a random sample of 10 widgets, find the probability that at least one is defective.
<b>Solution:</b>
P(at least one defective) = 1 – P(given widget is not defective)<sup>n</sup>
P(at least one defective) = 1 – (0.98)<sup>10</sup>
P(at least one defective) = 0.183
The probability that at least one widget is defective in a random sample of 10  is <b>0.183</b>.
<h3>Example 3: Trivia Questions</h3>
Bob answers 75% of trivia questions correctly. If we ask him 3 trivia questions, find the probability that he answers at least one incorrectly.
<b>Solution:</b>
P(at least one incorrect) = 1 – P(given answer is correct)<sup>n</sup>
P(at least one incorrect) = 1 – (0.75)<sup>3</sup>
P(at least one incorrect) = 0.578
The probability that he answers at least one incorrectly is <b>0.578</b>.
<h3>Bonus: Probability of “At Least One” Calculator</h3>
Use  this calculator  to automatically find the probability of “at least one” success, based on the probability of success in a given trial and the total number of trials.
<h2><span class="orange">How to Find the Probability of “At Least Three” Successes</span></h2>
We can use the following general formula to find the <b>probability of at least three successes</b> in a series of trials:
<b>P(at least 3) = 1 - P(0 successes) - P(1 success) - P(2 successes) </b>
In the formula above, we can calculate each probability by using the following formula for the  binomial distribution :
<b>P(X=k) = <sub>n</sub>C<sub>k</sub> * p<sup>k</sup> * (1-p)<sup>n-k</sup></b>
where:
<b>n:</b> number of trials
<b>k: </b>number of successes
<b>p:</b> probability of success on a given trial
<b><sub>n</sub>C<sub>k</sub>: </b>the number of ways to obtain <em>k</em> successes in <em>n</em> trials
The following examples show how to use this formula to find the probability of “at least three” successes in different scenarios.
<h3>Example 1: Free-Throw Attempts</h3>
Ty makes 25% of his free-throw attempts. If he attempts 5 free-throws, find the probability that he makes at least three.
First, let’s calculate the probability that he makes exactly zero, exactly one, or exactly two free-throws:
<b>P(X=0) </b>= <sub>5</sub>C<sub>0</sub> * .25<sup>0</sup> * (1-.25)<sup>5-0</sup> = 1 * 1 * .75<sup>5</sup> =<b> 0.2373</b>
<b>P(X=1) </b>= <sub>5</sub>C<sub>1</sub> * .25<sup>1</sup> * (1-.25)<sup>5-1</sup> = 5 * .25 * .75<sup>4</sup> =<b> 0.3955</b>
<b>P(X=2) </b>= <sub>5</sub>C<sub>2</sub> * .25<sup>2</sup> * (1-.25)<sup>5-2</sup> = 10 * .0625 * .75<sup>3</sup> =<b> 0.2636</b>
Next, let’s plug these values into the following formula to find the probability that Ty makes at least three free-throws:
P(X≥3) = 1 – P(X=0) – P(X=1) – P(X=2)
P(X≥3) = 1 – .2373 – .3955 – .2636
P(X≥3) = <b>0.1036</b>
The probability that Ty makes at least three free-throws in five attempts is <b>0.1036</b>.
<h3>Example 2: Widgets</h3>
At a given factory, 2% of all widgets are defective. In a random sample of 10 widgets, find the probability that at least two are defective.
First, let’s calculate the probability that exactly zero, exactly one, or exactly two are defective:
<b>P(X=0) </b>= <sub>10</sub>C<sub>0</sub> * .02<sup>0</sup> * (1-.02)<sup>10-0</sup> = 1 * 1 * .98<sup>10</sup> =<b> 0.8171</b>
<b>P(X=1) </b>= <sub>10</sub>C<sub>1</sub> * .02<sup>1</sup> * (1-.02)<sup>10-1</sup> = 10 * .02 * .98<sup>9</sup> =<b> 0.1667</b>
<b>P(X=2) </b>= <sub>10</sub>C<sub>2</sub> * .02<sup>2</sup> * (1-.02)<sup>10-2</sup> = 45 * .0004 * .98<sup>8</sup> =<b> 0.0153</b>
Next, let’s plug these values into the following formula to find the probability that at least three widgets are defective:
P(X≥3) = 1 – P(X=0) – P(X=1) – P(X=2)
P(X≥3) = 1 – 0.8171 – 0.1667 – 0.0153
P(X≥3) = <b>0.0009</b>
The probability that at least three widgets are defective in this random sample of 10 is <b>0.0009</b>.
<h3>Example 3: Trivia Questions</h3>
Bob answers 60% of trivia questions correctly. If we ask him 5 trivia questions, find the probability that he answers at least three correctly.
First, let’s calculate the probability that he answers exactly zero, exactly one, or exactly two correctly:
<b>P(X=0) </b>= <sub>5</sub>C<sub>0</sub> * .60<sup>0</sup> * (1-.60)<sup>5-0</sup> = 1 * 1 * .40<sup>5</sup> =<b> 0.01024</b>
<b>P(X=1) </b>= <sub>5</sub>C<sub>1</sub> * .60<sup>1</sup> * (1-.60)<sup>5-1</sup> = 5 * .60 * .40<sup>4</sup> =<b> 0.0768</b>
<b>P(X=2) </b>= <sub>5</sub>C<sub>2</sub> * .60<sup>2</sup> * (1-.60)<sup>5-2</sup> = 10 * .36 * .40<sup>3</sup> =<b> 0.2304</b>
Next, let’s plug these values into the following formula to find the probability that he answers at least three questions correctly:
P(X≥3) = 1 – P(X=0) – P(X=1) – P(X=2)
P(X≥3) = 1 – 0.01024 – 0.0768 – 0.2304
P(X≥3) = <b>0.6826</b>
The probability that he answers at least three questions correctly out of five is <b>0.6826</b>.
<h3>Bonus: Probability of “At Least Three” Calculator</h3>
Use  this calculator  to automatically find the probability of “at least three” successes, based on the probability of success in a given trial and the total number of trials.
<h2><span class="orange">How to Find the Probability of “At Least Two” Successes</span></h2>
We can use the following general formula to find the <b>probability of at least two successes</b> in a series of trials:
<b>P(at least two successes) = 1 - P(zero successes) - P(one success) </b>
In the formula above, we can calculate each probability by using the following formula for the  binomial distribution :
<b>P(X=k) = <sub>n</sub>C<sub>k</sub> * p<sup>k</sup> * (1-p)<sup>n-k</sup></b>
where:
<b>n:</b> number of trials
<b>k: </b>number of successes
<b>p:</b> probability of success on a given trial
<b><sub>n</sub>C<sub>k</sub>: </b>the number of ways to obtain <em>k</em> successes in <em>n</em> trials
The following examples show how to use this formula to find the probability of “at least two” successes in different scenarios.
<h3>Example 1: Free-Throw Attempts</h3>
Ty makes 25% of his free-throw attempts. If he attempts 5 free-throws, find the probability that he makes at least two.
First, let’s calculate the probability that he makes exactly zero free throws or exactly one free throw:
<b>P(X=0) </b>= <sub>5</sub>C<sub>0</sub> * .25<sup>0</sup> * (1-.25)<sup>5-0</sup> = 1 * 1 * .75<sup>5</sup> =<b> 0.2373</b>
<b>P(X=1) </b>= <sub>5</sub>C<sub>1</sub> * .25<sup>1</sup> * (1-.25)<sup>5-1</sup> = 5 * .25 * .75<sup>4</sup> =<b> 0.3955</b>
Next, let’s plug these values into the following formula to find the probability that Ty makes at least two free-throws:
P(X≥2) = 1 – P(X=0) – P(X=1)
P(X≥2) = 1 – 0.2372 – 0.3955
P(X≥2) = <b>0.3673</b>
The probability that Ty makes at least two free-throw in five attempts is <b>0.3673</b>.
<h3>Example 2: Widgets</h3>
At a given factory, 2% of all widgets are defective. In a random sample of 10 widgets, find the probability that at least two are defective.
First, let’s calculate the probability that exactly zero or exactly one are defective:
<b>P(X=0) </b>= <sub>10</sub>C<sub>0</sub> * .02<sup>0</sup> * (1-.02)<sup>10-0</sup> = 1 * 1 * .98<sup>10</sup> =<b> 0.8171</b>
<b>P(X=1) </b>= <sub>10</sub>C<sub>1</sub> * .02<sup>1</sup> * (1-.02)<sup>10-1</sup> = 10 * .02 * .98<sup>9</sup> =<b> 0.1667</b>
Next, let’s plug these values into the following formula to find the probability that at least two widgets are defective:
P(X≥2) = 1 – P(X=0) – P(X=1)
P(X≥2) = 1 – 0.8171 – 0.1667
P(X≥2) = <b>0.0162</b>
The probability that at least two widgets are defective in this random sample of 10 is <b>0.0162</b>.
<h3>Example 3: Trivia Questions</h3>
Bob answers 60% of trivia questions correctly. If we ask him 5 trivia questions, find the probability that he answers at least two correctly.
First, let’s calculate the probability that he answers exactly zero or exactly one correctly:
<b>P(X=0) </b>= <sub>5</sub>C<sub>0</sub> * .60<sup>0</sup> * (1-.60)<sup>5-0</sup> = 1 * 1 * .40<sup>5</sup> =<b> 0.01024</b>
<b>P(X=1) </b>= <sub>5</sub>C<sub>1</sub> * .60<sup>1</sup> * (1-.60)<sup>5-1</sup> = 5 * .60 * .40<sup>4</sup> =<b> 0.0768</b>
Next, let’s plug these values into the following formula to find the probability that he answers at least two questions correctly:
P(X≥2) = 1 – P(X=0) – P(X=1)
P(X≥2) = 1 – 0.01024 – 0.0768
P(X≥2) = <b>0.91296</b>
The probability that he answers at least two questions correctly out of five is <b>0.91296</b>.
<h3>Bonus: Probability of “At Least Two” Calculator</h3>
Use  this calculator  to automatically find the probability of “at least two” successes, based on the probability of success in a given trial and the total number of trials.
<h2><span class="orange">How to Find the Probability of Neither A Nor B</span></h2>
Given two events, A and B, to “find the probability of neither A nor B” means to find the probability that <b>neither event A nor event B occurs.</b>
We use the following formula to calculate this probability:
<b>P(Neither A Nor B) = 1 – ( P(A) + P(B) – P(A∩B) )</b>
where:
P(A): The probability that event A occurs.
P(B): The probability that event B occurs.
P(A∩B): The probability that event A and event B both occur.
The following examples show how to use this formula in practice.
<h2>Example 1: Probability of Neither A Nor B (Basketball Players)</h2>
Suppose the probability that a given college basketball player gets drafted into the NBA is <b>0.03</b>.
Also suppose the probability that a given college basketball player has a 4.0 GPA is <b>0.25</b>.
Also suppose the probability that a given college basketball player has a 4.0 GPA <em>and</em> gets drafted into the NBA is <b>0.005</b>.
If we randomly select some college basketball player, what is the probability that they neither get drafted nor have a 4.0 GPA?
<b>Solution</b>:
P(drafted) = 0.03
P(4.0 GPA) = 0.25
P(drafted ∩ 4.0 GPA) = 0.005
Thus, we can calculate:
P(Neither drafted Nor 4.0 GPA) = 1 – ( P(drafted) + P(4.0 GPA) – P(drafted ∩ 4.0 GPA) )
P(Neither drafted Nor 4.0 GPA) = 1 -(.03 + .25 – .005)
P(Neither drafted Nor 4.0 GPA) = 0.715
If we randomly select some college basketball player, the probability that they neither get drafted nor have a 4.0 GPA is 0.715 or <b>71.5%</b>.
<h2>Example 2: Probability of Neither A Nor B (Exam Scores)</h2>
Suppose the probability that a given student receives a perfect score on a final exam is <b>0.13</b>.
Also suppose the probability that a given student used a new studying method is <b>0.35</b>.
Also suppose the probability that a given student received a perfect score <em>and</em> used a new studying method is <b>0.04</b>.
If we randomly select some student, what is the probability that they neither received a perfect score nor used a new studying method?
<b>Solution</b>:
P(perfect score) = 0.13
P(new method) = 0.35
P(perfect score ∩ new method) = 0.04
Thus, we can calculate:
P(Neither perfect score Nor new method) = 1 – ( P(perfect score) + P(new method) – P(perfect score ∩ new method) )
P(Neither perfect score Nor new method) = 1 – (0.13 + 0.35 – 0.04)
P(Neither perfect score Nor new method) = 0.56
If we randomly select some student, the probability that they neither received a perfect score nor used a new studying method is 0.56 or <b>56%</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other calculations related to probabilities:
 How to Find the Probability of A or B 
 How to Find the Probability of A and B 
 How to Find the Probability of A Given B 
 How to Find the Probability of “At Least One” Success 
<h2><span class="orange">10 Examples of Using Probability in Real Life</span></h2>
<b>Probability</b> refers to how likely an event is to occur.
Probability is used in all types of areas in real life including weather forecasting, sports betting, investing, and more.
The following examples share how probability is used in 10 real-life situations on a regular basis.
<h3>Example 1: Weather Forecasting</h3>
Perhaps the most common real life example of using probability is <b>weather forecasting</b>.
Probability is used by weather forecasters to assess how likely it is that there will be rain, snow, clouds, etc. on a given day in a certain area.
Forecasters will regularly say things like “there is an 80% chance of rain today between 2PM and 5PM” to indicate that there’s a high likelihood of rain during certain hours.
<h3>Example 2: Sports Betting</h3>
Probability is heavily used by sports betting companies to determine the odds they should set for certain teams to win certain games.
For example, a sports betting company may look at the current record of two teams and determine that team A has a 90% probability of winning while team B has just a 10% probability of winning.
Based on these probabilities, the company would offer a higher payout for people who bet on team B to win since it’s highly unlikely that team B will actually win.
<h3>Example 3: Politics</h3>
Political forecasters use probability to predict the chances that certain candidates will win various elections.
For example, a forecaster might say that candidate A has a 60% chance of winning, candidate B has a 20% chance of winning, candidate C has a 10% chance of winning, etc. to give voters an idea of how likely it is that each candidate will win.
<b>Note</b>: A real-life example of a site that uses probability to perform political forecasting is  FiveThirtyEight .
<h3>Example 4: Sales Forecasting</h3>
Many retail companies use probability to predict the chances that they’ll sell a certain amount of goods in a given day, week, or month.
This allows the companies to predict how much inventory they’ll need. For example, a company might use a forecasting model that tells them the probability of selling at least 100 products on a certain day is 90%.
This means they’ll need to make sure they have at least 100 products on hand to sell (or preferably more) so they don’t run out.
<h3>Example 5: Health Insurance</h3>
Health insurance companies often use probability to determine how likely it is that certain individuals will spend a certain amount on healthcare each year.
For example, a company might use factors like age, existing medical conditions, current health status, etc. to determine that there’s a 90% probability that a certain individual will spend $10,000 or more on healthcare in a given year.
Individuals who are likely to spend more on healthcare will be charged higher premiums because the insurance company knows that they’ll be more expensive to insure.
<h3>Example 6: Grocery Store Staffing</h3>
Grocery stores often use probability to determine how many workers they should schedule to work on a given day.
For example, a grocery store may use a model that tells them there is a 75% chance that they’ll have more than 800 customers come into the store on a given day.
Based on this probability, they’ll schedule a certain amount of workers to be at the store on that day to handle that many customers.
<h3>Example 7: Natural Disasters</h3>
The environmental departments of countries often use probability to determine how likely it is that a natural disaster like a hurricane, tornado, earthquake, etc. will strike the country in a given year.
If the probability is quite high, then the department will make decisions about housing, resource allocation, etc. that will minimize the effects done by the natural disaster.
<h3>Example 8: Traffic</h3>
Ordinary people use probability every day when they decide to drive somewhere.
Based on the time of day, location in the city, weather conditions, etc. we all tend to make probability predictions about how bad traffic will be during a certain time.
For example, if you think there’s a 90% probability that traffic will be heavy from 4PM to 5:30PM in your area then you may decide to wait to drive somewhere during that time.
<h3>Example 9: Investing</h3>
Investors use probability to assess how likely it is that a certain investment will pay off.
For example, a given investor might determine that there is a 1% chance that the stock of company A will increase 100x during the upcoming year.
Based on this probability, the investor will decide how much of their net worth to invest in the stock.
<h3>Example 10: Card Games</h3>
Probability is routinely used by anyone who plays card games on a regular basis.
For example, professional poker players use probability to determine how likely it is that a certain hand of cards will win and this informs them on how much they should bet.
If a player knows that there is a high probability that they will win a certain hand based on their cards, they will be more likely to bet more money.
Conversely, if they think the probability that they’ll win is low then they may bet significantly less money.
<h2><span class="orange">Probability vs. Proportion: What’s the Difference?</span></h2>
Two terms that students often get confused in statistics are <b>probability</b> and <b>proportion</b>.
Here’s the difference:
<b>Probability</b> represents the chances of some event happening. It is <em>theoretical</em>.
<b>Proportion</b> summarizes how frequently some event actually happened. It is <em>empirical</em>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/prob1.png">
We often use probability when talking about the chances of some event happening in the future.
By contrast, we often use proportion when describing how often some event actually happened in the past.
The following examples illustrate the differences between probabilities and proportions in different scenarios.
<h3>Example 1: Probability vs. Proportion in Coin Flips</h3>
If we flip a fair coin, the <b>probability</b> that it will land on heads is 0.5 or <b>50%</b>.
However, if we flip a fair coin 20 times then we can actually count the <b>proportion</b> of times it landed on heads. For example, perhaps it landed on heads in <b>60%</b> of the flips.
The probability of landing on heads is theoretical, but the proportion of times the coin landed on heads is empirical – we could actually count the proportion.
<h3>
<b>Example 2: Probability vs. Proportion in Die Rolls</b>
</h3>
If we roll a six-sided die, the <b>probability</b> that it will land on the number “4” is 1/6 or about <b>16.67%</b>.
However, if we roll the die 10 times then we can actually count the <b>proportion</b> of times it landed on 4. For example, perhaps it landed on “4” in <b>20%</b> of the rolls.
The probability of rolling a “4” is theoretical, but the proportion of times the die landed on “4” is empirical – we could actually count the proportion.
<h3>
<b>Example 3: Probability vs. Proportion in Spinners</b>
</h3>
If we spin a spinner split into four equal parts – red, blue, green, purple –  the <b>probability</b> that it will land on purple on any given spin is <b>25%</b>.
However, if we spin the spinner 100 times then we can actually count the <b>proportion</b> of times it landed on purple. For example, perhaps it landed on purple during <b>15%</b> of spins.
The probability of the spinner landing on purple is theoretical, but the proportion of times it landed on purple is empirical – we could actually count the proportion.
<h3>
<b>Example 4: Probability vs. Proportion in Card Decks</b>
</h3>
In a standard deck of 52 cards, there are 4 Queens. Thus, the <b>probability</b> of choosing a Queen on any random draw is 4/52 = <b>7.69%</b>.
However, if we take a random draw (and replace the card we draw) 50 times, we can actually count the <b>proportion</b> of times we draw a Queen. For example, perhaps we draw a Queen in <b>10%</b> of the draws.
The probability of the choosing a Queen is theoretical, but the proportion of times we actually choose a Queen is empirical – we could actually count the proportion.
<h2><span class="orange">How to Use Proc Summary in SAS (With Examples)</span></h2>
You can use <b>proc summary</b> in SAS to quickly calculate the following  descriptive statistics  for one or more variables in a dataset:
<b>N</b>: The total number of observations
<b>MIN</b>: The minimum value
<b>MAX</b>: The maximum value
<b>MEAN</b>: The mean
<b>STD</b>: The standard deviation
The following examples show how to use this procedure with the SAS built-in dataset called  Fish , which contains various measurements for 159 different fish caught in a lake in Finland.
We can use <b>proc print</b> to view the first 10  observations  from this dataset:
<b>/*view first 10 observations from <em>Fish</em> dataset*/
proc print data=sashelp.Fish (obs=10);
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/fish1.jpg"492">
<b>Related:</b>  How to Identify Outliers in SAS 
<h3>Example 1: Proc Summary with One Variable</h3>
We can use the following code to calculate descriptive statistics for the Weight variable:
<b>/*calculate descriptive statistics for Weight variable*/
proc summary data=sashelp.Fish;
   var Weight;
   output out=summaryWeight;
run;
/*print output dataset*/
proc print data=summaryWeight;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/fish2.jpg"340">
Here’s how to interpret the output table:
_TYPE_: This column shows whether or not every row in the dataset was used to calculate the descriptive statistics. 0 = Every row was used.
_FREQ_: The number of rows used to calculate each descriptive statistic.
_STAT_: The name of the descriptive statistic.
Weight: The numerical value for the corresponding descriptive statistic.
From the output we can see:
The total number of observations was <b>158</b>.
The minimum weight value was <b>0</b>.
The maximum weight value was <b>1,650</b>.
The mean weight value was <b>398.70</b>.
The standard deviation of weight values was <b>359.09</b>.
From these five values we can gain a pretty good understanding of the distribution of values for the Weight variable.
<h3>Example 2: Proc Summary with Multiple Variables</h3>
To calculate descriptive statistics for multiple variables at once, simply list several variable names in the <b>var</b> statement.
For example, we can use the following code to calculate descriptive statistics for the Weight and Height variables:
<b>/*calculate descriptive statistics for Weight and Height variables*/
proc summary data=sashelp.Fish;
   var Weight Height;
   output out=summaryWeightHeight;
run;
/*print output dataset*/
proc print data=summaryWeightHeight;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/fish3.jpg"416">
From the output we can see the five descriptive statistics for both Weight and Height.
<h3>Example 3: Proc Summary with One Variable Grouped by Another Variable</h3>
To calculate descriptive statistics for one variable grouped by another variable, we can use the <b>class</b> statement.
For example, we can use the following code to calculate descriptive statistics for Weight grouped by Species:
<b>/*calculate descriptive statistics for Weight grouped by Species*/
proc summary data=sashelp.Fish;
   var Weight;
   class Species;
   output out=summaryWeightSpecies;
run;
/*print output dataset*/
proc print data=summaryWeightSpecies;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/fish4.jpg"307">
The output table displays the descriptive statistics for each Species of fish.
For example, we can observe the following descriptive statistics for just the Bream fish:
The total number of observations was <b>34</b>.
The minimum weight value was <b>242</b>.
The maximum weight value was <b>1,000</b>.
The mean weight value was <b>626</b>.
The standard deviation of weight values was <b>206.60</b>.
We can observe these descriptive statistics for every other species as well.
<h2><span class="orange">How to Use Proc Tabulate in SAS (With Examples)</span></h2>
You can use <b>proc tabulate </b>in SAS to quickly display  descriptive statistics  for one or more variables in a tabular format.
The following examples show how to use this procedure with the following dataset that shows the total points scored by 12 different basketball players:
<b>/*create dataset*/
data my_data;
    input team $ position $ points;
    datalines;
A Guard 15
A Guard 12
A Guard 29
A Forward 13
A Forward 9
A Forward 16
B Guard 25
B Guard 20
C Guard 34
C Forward 19
C Forward 3
C Forward 8
;
run;
/*view dataset*/
proc print data=my_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/count11.jpg"226">
<h2>Example 1: Proc Tabulate with One Variable</h2>
We can use the following code to calculate descriptive statistics for the points variable:
<b>/*create table that displays descriptive stats for points variable*/
proc tabulate data=my_data;
    var points;
    table points * (N Min Q1 Median Mean Q3 Max);
run; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/tabulate1.jpg"349">
<b>Note</b>: The values inside the parenthesis tell SAS which descriptive statistics to calculate for points.
Here are some of the most commonly used descriptive statistics:
<b>N</b>: The total number of observations
<b>Min</b>: The minimum value
<b>Q1</b>: The value for the first quantile (i.e. the 25th percentile)
<b>Median</b>: The median value
<b>Mean</b>: The mean value
<b>Q3</b>: The value for the third quantile (i.e. the 75th percentile)
<b>Max</b>: The maximum value
From the output we can see:
The total observations is <b>12</b>.
The minimum value for points is <b>3</b>.
The number of points at the 25th percentile is <b>10.5</b>.
The median number of points is <b>15.5</b>.
The mean number of points is <b>16.92</b>.
The number of points at the 75th percentile is <b>22.5</b>.
The maximum number of points is <b>34</b>.
From these five values we can gain a pretty good understanding of the distribution of values for the Weight variable.
<h2>Example 2: Proc Tabulate with Two Variables</h2>
We can use the following code to calculate descriptive statistics for the points variable, grouped by the team variable:
<b>/*create table that displays descriptive stats for points, grouped by team*/
proc tabulate data=my_data;
    class team;
    var points;
    table team, points * (N Min Q1 Median Mean Q3 Max);
run; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/tabulate2.jpg"411">
The resulting table shows the descriptive statistics of points for each of the three teams.
For example:
Team A has <b>6</b> observations.
The minimum value for points on team A is <b>9</b>.
The number of points on team A at the 25th percentile is <b>12</b>.
The median number of points on team A is <b>14</b>.
And so on.
<h2>Example 3: Proc Tabulate with Three Variables</h2>
We can use the following code to calculate descriptive statistics for the points variable, grouped by the team and position variables:
<b>/*create table that shows descriptive stats for points, grouped by team and position*/
proc tabulate data=my_data;
    class team position;
    var points;
    table team, position * points * (N Min Q1 Median Mean Q3 Max);
run; </b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/tabulate3.jpg"649">
The resulting table shows the descriptive statistics for points, grouped by team and position.
Note that the cells for team “B” and position “Forward” are empty because there were no players on team B who had a position of Forward.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in SAS:
 How to Use Proc Summary in SAS 
 How to Calculate Correlation in SAS 
 How to Create Frequency Tables in SAS 
 How to Create Boxplots by Group in SAS 
<h2><span class="orange">Pythagorean Triples Calculator</span></h2>
A <b>Pythagorean triple</b> is a group of three positive numbers that represent the three sides of a triangle and satisfy the following equation:
a<sup>2</sup> + b<sup>2</sup> = c<sup>2</sup>
where <i>a</i> is the perpendicular side of the triangle, <i>b</i> is the base side of the triangle, and <i>c</i> is the hypotenuse side of the triangle.
To find out if the three sides of a triangle are a Pythagorean triple, simply fill in the values below and then click the “Calculate” button.
<label for="a"><b>Perpendicular side (a)</b></label>
<input type="number" id="a" value="3"><label for="b"><b>Base side (b)</b></label>
<input type="number" id="b" value="4"><label for="c"><b>Hypotenuse side (c)</b></label>
<input type="number" id="c" value="5">
<input type="button" id="button_calc" onclick="calc()" value="Calculate">
Are these three numbers a Pythagorean triple? <b>Yes</b>
<script>
function calc() {
//get input values and calculate WHIP
var a = document.getElementById('a').value*1;
var b = document.getElementById('b').value*1;
var c = document.getElementById('c').value*1;
var result = "No";
if (((a*a) - (-b*b)) == (c*c)) {
result = "Yes";
}
//output
document.getElementById('result').innerHTML = result;
}
</script>
<h2><span class="orange">How to Create an Array of Arrays in Python (With Examples)</span></h2>
You can use one of the following two methods to create an array of arrays in Python using the NumPy package:
<b>Method 1: Combine Individual Arrays</b>
<b>import numpy as np
array1 = np.array([1, 2, 3])
array2 = np.array([4, 5, 6])
array3 = np.array([7, 8, 9])
all_arrays = np.array([array1, array2, array3])
</b>
<b>Method 2: Create Array of Arrays Directly</b>
<b>import numpy as np
all_arrays = np.array([[1, 2, 3],       [4, 5, 6],       [7, 8, 9]])
</b>
The following examples show how to use each method in practice.
<h3>Method 1: Combine Individual Arrays</h3>
The following code shows how to create an array of arrays by simply combining individual arrays:
<b>import numpy as np
#define individual arrays
array1 = np.array([10, 20, 30, 40, 50])
array2 = np.array([60, 70, 80, 90, 100])
array3 = np.array([110, 120, 130, 140, 150])
#combine individual arrays into one array of arrays
all_arrays = np.array([array1, array2, array3])
#view array of arrays
print(all_arrays)
[[ 10  20  30  40  50]
 [ 60  70  80  90 100]
 [110 120 130 140 150]]
</b>
<h3>Method 2: Create Array of Arrays Directly</h3>
The following code shows how to create an array of arrays directly:
<b>import numpy as np
#create array of arrays
all_arrays = np.array([[10, 20, 30, 40, 50],       [60, 70, 80, 90, 100],       [110, 120, 130, 140, 150]])
#view array of arrays
print(all_arrays)
[[ 10  20  30  40  50]
 [ 60  70  80  90 100]
 [110 120 130 140 150]]
</b>
 Notice that this array of arrays matches the one created using the previous method.
<h3>How to Access Elements in an Array of Arrays</h3>
You can use the <b>shape</b> function to retrieve the dimensions of an array of arrays:
<b>print(all_arrays.shape)
(3, 5)
</b>
This tells us that there are three rows and five columns in the array of arrays.
You can use the <b>size</b> function to see how many total values are in the array of arrays:
<b>print(all_arrays.size)
15</b>
This tells us that there are 15 total values in the array of arrays.
You can use <b>brackets</b> to access elements in certain positions of the array of arrays.
For example, you can use the following syntax to retrieve the value in the first array located in index position 3:
<b>print(all_arrays[0, 3])
40</b>
We can use this syntax to access any value we’d like in the array of arrays.
<h2><span class="orange">How to Plot Histogram from List of Data in Python</span></h2>
You can use the following basic syntax to plot a histogram from a list of data in Python:
<b>import matplotlib.pyplot as plt
#create list of data
x = [2, 4, 4, 5, 6, 6, 7, 8, 14]
#create histogram from list of data
plt.hist(x, bins=4)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Create Histogram with Fixed Number of Bins</h3>
The following code shows how to create a histogram from a list of data, using a fixed number of bins:
<b>import matplotlib.pyplot as plt
#create list of data
x = [2, 4, 4, 5, 6, 6, 7, 7, 7, 8, 8, 8, 12, 13]
#create histogram with 4 bins
plt.hist(x, bins=4, edgecolor='black')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/histList1.png">
<h3>Example 2: Create Histogram with Specific Bin Ranges</h3>
The following code shows how to create a histogram from a list of data, using specified bin ranges:
<b>import matplotlib.pyplot as plt
#create list of data
x = [2, 4, 4, 5, 6, 6, 7, 7, 7, 8, 8, 8, 12, 13]
#specify bin start and end points
bin_ranges = [0, 5, 10, 15]
#create histogram with 4 bins
plt.hist(x, bins=bin_ranges, edgecolor='black')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/histList2.png">
You can find the complete documentation for the Matplotlib histogram function  here .
<h2><span class="orange">How to Convert a List to a DataFrame Row in Python</span></h2>
You can use the following syntax to convert a list into a DataFrame row in Python:
<b>#define list
x = [4, 5, 8, 'A' 'B']
#convert list to DataFrame
df = pd.DataFrame(x).T
</b>
And you can use the following syntax to convert a list of lists into several rows of a DataFrame:
<b>#define list of lists
big_list = [[4, 5, 6, 'B'],
            [4, 2, 1, 'A'],
            [12, 4, 8, 'C']]
#convert list of lists into DataFrame
df = pd.DataFrame(columns=['col1', 'col2', 'col3', 'col4'], data=big_list)</b>
The following examples show how to use each of these functions in practice.
<h3>Example 1: Convert a List into a DataFrame Row</h3>
The following code shows how to convert a single list into a DataFrame with one row in Python:
<b>import pandas as pd
#define list
x = [4, 5, 8, 'Mavericks']
#convert list to DataFrame
df = pd.DataFrame(x).T
#specify column names of DataFrame
df.columns = ['Points', 'Assists', 'Rebounds', 'Team']
#display DataFrame
print(df)
  Points Assists Rebounds       Team
0      4       5        8  Mavericks
</b>
<h3>Example 2: Convert a List of Lists into Several DataFrame Rows</h3>
The following code shows how to convert a list of lists into a DataFrame with several rows in Python:
<b>import pandas as pd
#define list of lists
big_list = [[6, 7, 12, 'Mavericks'],
            [4, 2, 1, 'Lakers'],
            [12, 4, 8, 'Spurs']]
#convert list of lists into DataFrame
df = pd.DataFrame(columns=['Points', 'Assists', 'Rebounds', 'Team'], data=big_list)
#display DataFrame
print(df)
        PointsAssistsRebounds  Team
06712  Mavericks
1421  Lakers
21248  Spurs
</b>
We can verify the number of rows and columns of the resulting DataFrame by using the <b>.shape()</b> function:
<b>print(df.shape)
(3, 4)
</b>
This tells us that the resulting DataFrame has 3 rows and 4 columns.
<h2><span class="orange">How to Use a Monthly Payment Function in Python (3 Examples)</span></h2>
You can use the following function in Python to calculate the monthly payments necessary to pay off a certain loan, given the initial size of the loan, duration of the loan, and annual interest rate:
<b>(rate/12) * (1/(1-(1+rate/12)**(-months)))*P
</b>
The following examples show how to use this function in different scenarios.
<h3>Example 1: Calculate Loan Payments for Mortgage</h3>
Suppose a family takes out a mortgage loan for a house with the following details:
Mortgage Amount: $200,000
Number of Months: 360
Annual Interest Rate: 4%
We can use the following code to calculate the necessary monthly loan payment:
<b>#define initial size of loan, duration of loan, and annual interest rate
P = 200000
months = 360
rate = .04
#calculate monthly payment
(rate/12) * (1/(1-(1+rate/12)**(-months)))*P
954.8305909309076
</b>
The monthly loan payment is <b>$954.83</b>. This is how much the family must pay each month in order to pay off the $200,000 loan in 360 months.
<h3>Example 2: Calculate Loan Payments for Car Loan</h3>
Suppose an individual takes out a loan for a car with the following details:
Loan Amount: $20,000
Number of Months: 60
Annual Interest Rate: 3%
We can use the following code to calculate the necessary monthly loan payment:
<b>#define initial size of loan, duration of loan, and annual interest rate
P = 20000
months = 60
rate = .03
#calculate monthly payment
(rate/12) * (1/(1-(1+rate/12)**(-months)))*P
359.3738132812698
</b>
The monthly loan payment is <b>$359.37</b>. This is how much the individual must pay each month in order to pay off the $20,000 loan in 60 months.
<h3>Example 3: Calculate Loan Payments for Student Loan</h3>
Suppose a student takes out a loan for university with the following details:
Loan Amount: $40,000
Number of Months: 120
Annual Interest Rate: 5.2%
We can use the following code to calculate the necessary monthly loan payment:
<b>#define initial size of loan, duration of loan, and annual interest rate
P = 40000
months = 120
rate = .052
#calculate monthly payment
(rate/12) * (1/(1-(1+rate/12)**(-months)))*P
428.18316863206525
</b>
The monthly loan payment is <b>$428.18</b>. This is how much the individual must pay each month in order to pay off the $40,000 loan in 120 months.
<h2><span class="orange">How to Convert NumPy Array to List in Python (With Examples)</span></h2>
You can use the following basic syntax to convert a NumPy array to a list in Python:
<b>my_list = my_array.tolist()
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Convert 1-Dimensional Array to List</h3>
The following code shows how to convert a 1-dimensional NumPy array to a list in Python:
<b>import numpy as np
#create NumPy array
my_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
  
#convert NumPy array to list                
my_list = my_array.tolist()
#view list
print(my_list)
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
#view object type
type(my_list)
list</b>
<h3>Example 2: Convert Multi-Dimensional Array to List</h3>
The following code shows how to convert a multi-dimensional NumPy array to a list in Python:
<b>import numpy as np
#create NumPy array
my_array = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
  
#convert NumPy array to list                
my_list = my_array.tolist()
#view list
print(my_list)
[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]
#view object type
type(my_list)
list</b>
<h3>Example 3: Convert Multi-Dimensional Array to Flattened List</h3>
The following code shows how to convert a multi-dimensional NumPy array to a flattened list in Python:
<b>import numpy as np
#create NumPy array
my_array = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
  
#convert NumPy array to flattened list                
my_list = my_array.flatten().tolist()
#view list
print(my_list)
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
#view object type
type(my_list)
list</b>
<h2><span class="orange">How to Fix: numpy.linalg.LinAlgError: Singular matrix</span></h2>
One error you may encounter in Python is:
<b>numpy.linalg.LinAlgError: Singular matrix
</b>
This error occurs when you attempt to invert a singular matrix, which by definition is a matrix that has a determinant of zero and cannot be inverted.
This tutorial shares how to resolve this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following matrix using NumPy:
<b>import numpy as np
#create 2x2 matrix
my_matrix = np.array([[1., 1.], [1., 1.]])
#display matrix
print(my_matrix)
[[1. 1.]
 [1. 1.]]</b>
Now suppose we attempt to use the <b>inv()</b> function from NumPy to calculate the inverse of the matrix:
<b>from numpy import inv
#attempt to invert matrix
inv(my_matrix)
numpy.linalg.LinAlgError: Singular matrix</b>
We receive an error because the matrix that we created does not have an inverse matrix.
<b>Note</b>: Check out  this page  from Wolfram MathWorld that shows 10 different examples of matrices that have no inverse matrix.
By definition, a matrix is singular and cannot be inverted if it has a determinant of zero.
You can use the <b>det()</b> function from NumPy to calculate the determinant of a given matrix before you attempt to invert it:
<b>from numpy import det
#calculate determinant of matrix
det(my_matrix)
0.0
</b>
The determinant of our matrix is zero, which explains why we run into an error.
<h3>How to Fix the Error</h3>
The only way to get around this error is to simply create a matrix that is not singular.
For example, suppose we use the <b>inv()</b> function to invert the following matrix:
<b>import numpy as np
from numpy.linalg import inv, det
#create 2x2 matrix that is not singular
my_matrix = np.array([[1., 7.], [4., 2.]])
#display matrix
print(my_matrix)
[[1. 7.]
 [4. 2.]]
#calculate determinant of matrix
print(det(my_matrix))
-25.9999999993
#calculate inverse of matrix
print(inv(my_matrix))
[[-0.07692308  0.26923077]
 [ 0.15384615 -0.03846154]]
</b>
We don’t receive any error when inverting the matrix because the matrix is not singular.
<h2><span class="orange">How to Read Text File Into List in Python (With Examples)</span></h2>
You can use one of the following two methods to read a text file into a list in Python:
<b>Method 1: Use open() </b>
<b>#define text file to open
my_file = open('my_data.txt', 'r')
#read text file into list
data = my_file.read()
</b>
<b>Method 2: Use loadtxt() </b>
<b>from numpy import loadtxt
#read text file into NumPy array
data = loadtxt('my_data.txt')
</b>
The following examples shows how to use each method in practice.
<h3>Example 1: Read Text File Into List Using open()</h3>
The following code shows how to use the <b>open()</b> function to read a text file called <b>my_data.txt</b> into a list in Python:
<b>#define text file to open
my_file = open('my_data.txt', 'r')
#read text file into list 
data = my_file.read()
#display content of text file
print(data)
4
6
6
8
9
12
16
17
19
</b>
<h3>Example 2: Read Text File Into List Using loadtxt()</h3>
The following code shows how to use the NumPy <b>loadtxt()</b> function to read a text file called <b>my_data.txt</b> into a NumPy array:
<b>from numpy import loadtxt
#import text file into NumPy array
data = loadtxt('my_data.txt')
#display content of text file
print(data)
[ 4.  6.  6.  8.  9. 12. 16. 17. 19.]
#display data type of NumPy array
print(data.dtype)
float64
</b>
The nice thing about using <b>loadtxt()</b> is that we can specify the data type when importing the text file by using the <b>dtype</b> argument.
For example, we could specify the text file to be imported into a NumPy array as an integer:
<b>from numpy import loadtxt
#import text file into NumPy array as integer
data = loadtxt('my_data.txt', dtype='int')
#display content of text file
print(data)
[ 4  6  6  8  9 12 16 17 19]
#display data type of NumPy array
print(data.dtype)
int64</b>
<b>Note</b>: You can find the complete documentation for the <b>loadtxt()</b> function  here .
<h2><span class="orange">How to Resample Time Series Data in Python (With Examples)</span></h2>
To <b>resample</b> time series data means to summarize or aggregate the data by a new time period.
We can use the following basic syntax to resample time series data in Python:
<b>#find sum of values in column1 by month
weekly_df['column1'] = df['column1'].resample('M').sum()
#find mean of values in column1 by week
weekly_df['column1'] = df['column1'].resample('W').mean() 
</b>
Note that we can resample the time series data by various time periods, including:
<b>S</b>: Seconds
<b>min</b>: Minutes
<b>H</b>: Hours
<b>D</b>: Day
<b>W</b>: Week
<b>M</b>: Month
<b>Q</b>: Quarter
<b>A</b>: Year
The following example shows how to resample time series data in practice.
<h3>Example: Resample Time Series Data in Python</h3>
Suppose we have the following pandas DataFrame that shows the total sales made each hour by some company during a one-year period:
<b>import pandas as pd
import numpy as np
#make this example reproducible
np.random.seed(0)
#create DataFrame with hourly index
df = pd.DataFrame(index=pd.date_range('2020-01-06', '2020-12-27', freq='h'))
#add column to show sales by hour
df['sales'] = np.random.randint(low=0, high=20, size=len(df.index))
#view first five rows of DataFrame
df.head()
             sales
2020-01-06 00:00:0012
2020-01-06 01:00:0015
2020-01-06 02:00:000
2020-01-06 03:00:003
2020-01-06 04:00:003
</b>
If we create a line plot to visualize the sales data, it would look like this:
<b>import matplotlib.pyplot as plt
#plot time series data
plt.plot(df.index, df.sales, linewidth=3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/timeS1.png">
This plot is difficult to interpret, so we may instead summarize the sales data by week:
<b>#create new DataFrame
weekly_df = pd.DataFrame()
#create 'sales' column that summarizes total sales by week
weekly_df['sales'] = df['sales'].resample('W').sum()
#view first five rows of DataFrame
weekly_df.head()
                sales
2020-01-121519
2020-01-191589
2020-01-261540
2020-02-021562
2020-02-091614</b>
This new DataFrame shows the sum of sales by week.
We can then create a time series plot using this weekly data:
<b>import matplotlib.pyplot as plt
#plot weekly sales data
plt.plot(weekly_df.index, weekly_df.sales, linewidth=3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/times2.png">
This plot is much easier to read because we only plot sales data for 51 individual weeks as opposed to sales data for 8,545 individual hours in the first example.
<b>Note</b>: In this example, we summarized the sales data by week but we could also summarize by month or quarter if we would like to plot even fewer data points.
<h2><span class="orange">How to Fix in Pandas: The truth value of a Series is ambiguous</span></h2>
One error you may encounter in Python is:
<b>ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(),
            a.any() or a.all().
</b>
This error usually occurs when you attempt to filter a pandas DataFrame using the words <b>and</b> and <b>or</b> instead of using the <b>&</b> and <b>|</b> operators.
This tutorial shares how to resolve this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],   'points': [18, 22, 19, 14, 14, 11, 20, 28],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#view DataFrame
print(df)
  team  points  assists  rebounds
0    A      18        5        11
1    A      22        7         8
2    A      19        7        10
3    A      14        9         6
4    B      14       12         6
5    B      11        9         5
6    B      20        9         9
7    B      28        4        12
</b>
Now suppose we attempt to filter for rows where the team is equal to “A” <b>and</b> the points is less than 20:
<b>#attempt to filter DataFrame
df[(df['team'] == 'A') and (df['points'] &lt; 20)]
ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(),
            a.any() or a.all().
</b>
Or suppose we attempt to filter for rows where the team is equal to “A” <b>or </b>the points is less than 20:
<b>#attempt to filter DataFrame
df[(df['team'] == 'A') or (df['points'] &lt; 20)]
ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(),
            a.any() or a.all().</b>
In both scenarios we receive an error that tells us the truth value of a Series is ambiguous.
<h3>How to Fix the Error</h3>
To avoid this error when filtering, we need to make sure we use the <b>&</b> and <b>|</b> operators.
For example, we can use the following code to filter for rows where the team is equal to “A” <b>and</b> the points is less than 20:
<b>#filter DataFrame
df[(df['team'] == 'A') & (df['points'] &lt; 20)]
        teampointsassistsrebounds
0A18511
2A19710
3A1496</b>
Or we could use the following code to filter for rows where the team is equal to “A” <b>or </b>the points is less than 20:
<b>#filter DataFrame
df[(df['team'] == 'A') | (df['points'] &lt; 20)]
        teampointsassistsrebounds
0A18511
1A2278
2A19710
3A1496
4B14126
5B1195</b>
In both scenarios we don’t receive an error since we used the <b>&</b> and <b>|</b> operators.
<b>Note</b>: It’s important that you include parenthesis around each individual condition when filtering a pandas DataFrame by multiple conditions, otherwise you will receive an error.
<h2><span class="orange">How to Create a Q-Q Plot in Excel</span></h2>
A <b>Q-Q plot</b>, short for “quantile-quantile” plot, is often used to assess whether or not a set of data potentially came from some theoretical distribution. In most cases, this type of plot is used to determine whether or not a set of data follows a normal distribution.
This tutorial explains how to create a Q-Q plot for a set of data in Excel.
<h3>Example: Q-Q Plot in Excel</h3>
Perform the follow steps to create a Q-Q plot for a set of data.
<b>Step 1: Enter and sort the data.</b>
Enter the following data into one column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel1.png">
Note that this data is already sorted from smallest to largest. If your data is not already sorted, go to the <b>Data </b>tab along the top ribbon in Excel, then go to the <b>Sort & Filter </b>group, then click the <b>Sort A to Z </b>icon.
<b>Step 2: Find the rank of each data value.</b>
Next, use the following formula to calculate the rank of the first value:
<b>=RANK(A2, $A$2:$A$11, 1)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel2.png">
Copy this formula down to all of the other cells in the column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel3.png">
<b>Step 3: Find the percentile of each data value.</b>
Next, use the following formula to calculate the percentile of the first value:
<b>=(B2-0.5)/COUNT($B$2:$B$11)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel4.png">
Copy this formula down to all of the other cells in the column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel5.png">
<b>Step 4: Calculate the z-score for each data value.</b>
Use the following formula to calculate the z-score for the first data value:
<b>=NORM.S.INV(C2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel6.png">
Copy this formula down to all of the other cells in the column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel7.png">
<b>Step 5: Create the Q-Q plot.</b>
Copy the original data from column A into column E, then highlight the data in columns D and E.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel8.png">
 Along the top ribbon, go to <b>Insert</b>. Within the <b>Charts </b>group, choose <b>Insert Scatter (X, Y) </b>and click the option that says <b>Scatter</b>. This will produce the follow Q-Q plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel9.png">
Click the plus sign on the top right-hand corner of the graph and check the box next to <b>Trendline</b>. This will add the following line to the chart:
 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel10.png">
Feel free to add labels for the title and axes of the graph to make it more aesthetically pleasing:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotExcel11.png">
The way to interpret a Q-Q plot is simple: if the data values fall along a roughly straight line at a 45-degree angle, then the data is normally distributed. We can see in our Q-Q plot above that the data values tend to deviate from the 45-degree line quite a bit, especially on the tail ends, which could be an indication that the data set is not normally distributed.
Although a Q-Q plot isn’t a formal statistical test, it offers an easy way to visually check whether or not a data set is normally distributed.
<h2><span class="orange">How to Use Q-Q Plots to Check Normality</span></h2>
A <b>Q-Q plot,</b> short for “quantile-quantile” plot, is used to assess whether or not a set of data potentially came from some theoretical distribution.
In most cases, this type of plot is used to determine whether or not a set of data follows a normal distribution.
<b>If the data is normally distributed, the points in a Q-Q plot will lie on a straight diagonal line.</b>
Conversely, the more the points in the plot deviate significantly from a straight diagonal line, the less likely the set of data follows a normal distribution.
The following examples show how to create Q-Q plots in R to check for normality.
<h3>Example 1: Q-Q Plot for Normal Data</h3>
The following code shows how to generate a normally distributed dataset with 200  observations  and create a Q-Q plot for the dataset in R:
<b>#make this example reproducible
set.seed(1)
#create some fake data that follows a normal distribution
data &lt;- rnorm(200)
#create Q-Q plot
qqnorm(data)
qqline(data)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/qqnorm1.png">
We can see that the points lie mostly along the straight diagonal line with some minor deviations along each of the tails.
Based on this plot, we could safely assume that this set of data is normally distributed.
<h3>Example 2: Q-Q Plot for Non-Normal Data</h3>
The following code shows how to create a Q-Q plot for a dataset that follows an exponential distribution with 200 observations:
<b>#make this example reproducible
set.seed(1)
#create some fake data that follows an exponential distribution
data &lt;- rexp(200, rate=3)
#create Q-Q plot
qqnorm(data)
qqline(data)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/qqnorm2.png">
We can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.
This should make sense considering we specified that the data should follow an exponential distribution.
<h3>Q-Q Plots vs. Histograms</h3>
It’s worth noting that Q-Q plots are a way to <em>visually</em> check whether or not a dataset follows a normal distribution.
Another way to visually check for normality is to create a histogram of the dataset. If the data roughly follows a bell curve shape in the histogram, then we can assume that the dataset is normally distributed.
For example, here’s how to create a histogram for the normally distributed dataset from earlier:
<b>#make this example reproducible
set.seed(1)
#create some fake data that follows a normal distribution
data &lt;- rnorm(200)
#create a histogram to visualize the distribution
hist(data)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/qqnorm3.png">
And here’s how to create a histogram for the dataset that follows an exponential distribution from earlier:
<b>#make this example reproducible
set.seed(1)
#create some fake data that follows an exponential distribution
data &lt;- rexp(200, rate=3)
#create a histogram to visualize the distribution
hist(data)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/qqnorm4.png">
We can see that the histogram does not resemble a bell curve at all, which clearly indicates that the data does not follow a normal distribution.
<h2><span class="orange">How to Create a Q-Q Plot in Python</span></h2>
A <b>Q-Q plot</b>, short for “quantile-quantile” plot, is often used to assess whether or not a set of data potentially came from some theoretical distribution.
In most cases, this type of plot is used to determine whether or not a set of data follows a  normal distribution .
This tutorial explains how to create a Q-Q plot for a set of data in Python.
<h3>Example: Q-Q Plot in Python</h3>
Suppose we have the following dataset of 100 values:
<b>import numpy as np
#create dataset with 100 values that follow a normal distribution
np.random.seed(0)
data = np.random.normal(0,1, 1000)
#view first 10 values
data[:10] 
array([ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,
       -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ])</b>
To create a Q-Q plot for this dataset, we can use the  qqplot() function  from the statsmodels library:
<b>import statsmodels.api as sm
import matplotlib.pyplot as plt
#create Q-Q plot with 45-degree line added to plot
fig = sm.qqplot(data, line='45')
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/qqplotpython1.png">
In a Q-Q plot, the x-axis displays the <b>theoretical quantiles</b>. This means it doesn’t show your actual data, but instead it represents where your data would be if it were normally distributed.
The y-axis displays your <b>actual data</b>. This means that if the data values fall along a roughly straight line at a 45-degree angle, then the data is normally distributed.
We can see in our Q-Q plot above that the data values tend to closely follow the 45-degree, which means the data is likely normally distributed. This shouldn’t be surprising since we generated the 100 data values by using the  numpy.random.normal() function .
Consider instead if we generated a dataset of 100 uniformally distributed values and created a Q-Q plot for that dataset:
<b>#create dataset of 100 uniformally distributed values
data = np.random.uniform(0,1, 1000)
#generate Q-Q plot for the dataset
fig = sm.qqplot(data, line='45')
plt.show()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/qqplotpython2.png">
The data values clearly do not follow the red 45-degree line, which is an indication that they do not follow a normal distribution.
<h3>Notes on Q-Q Plots</h3>
Keep in mind the following notes about Q-Q plots:
Although a Q-Q plot isn’t a formal statistical test, it offers an easy way to visually check whether or not a data set is normally distributed.
Be careful not to confuse Q-Q plots with  P-P plots , which are less commonly used and not as useful for analyzing data values that fall on the extreme tails of the distribution.
<em>You can find more Python tutorials  here .</em>
<h2><span class="orange">How to Create & Interpret a Q-Q Plot in R</span></h2>
A <b>Q-Q plot</b>, short for “quantile-quantile” plot, is a type of plot that we can use to determine whether or not a set of data potentially came from some theoretical distribution. 
Many statistical tests make the assumption that a set of data follows a normal distribution, and a Q-Q plot is often used to assess whether or not this assumption is met.
Although a Q-Q plot isn’t a formal statistical test, it does provide an easy way to visually check whether a dataset follows a normal distribution, and if not, how this assumption is violated and which data points potentially cause this violation.
We can create a Q-Q plot by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, then the points on the plot should roughly form a straight diagonal line.
<figure style="width: 477px"><img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot1.jpg"><figcaption><b>Example of Q-Q plot</b></figcaption></figure><b>Quantiles</b> represent points in a dataset below which a certain portion of the data fall. For example, the 0.9 quantile represents the point below which 90% of the data fall below. The 0.5 quantile represents the point below which 50% of the data fall below, and so on.
Q-Q plots identify the quantiles in your sample data and plot them against the quantiles of a theoretical distribution. In most cases the normal distribution is used, but a Q-Q plot can actually be created for any theoretical distribution.
If the data points fall along a straight diagonal line in a Q-Q plot, then the dataset likely follows a normal distribution.
<h2>How to Create a Q-Q Plot in R</h2>
We can easily create a Q-Q plot to check if a dataset follows a normal distribution by using the built-in <b>qqnorm() </b>function.
For example, the following code generates a vector of 100 random values that follow a normal distribution and creates a Q-Q plot for this dataset to verify that it does indeed follow a normal distribution:
<b>#make this example reproducible
set.seed(11)
#generate vector of 100 values that follows a normal distribution
data &lt;- rnorm(100)
#create Q-Q plot to compare this dataset to a theoretical normal distribution
qqnorm(data)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot2.jpg">
To make it even easier to see if the data falls along a straight line, we can use the <b>qqline() </b>function:
<b>#create Q-Q plot
qqnorm(data)
#add straight diagonal line to plot
qqline(data)</b>
<h2><img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot3.jpg"></h2>
We can see that the data points near the tails don’t fall exactly along the straight line, but for the most part this sample data appears to be normally distributed (as it should be since we told R to generate the data from a normal distribution).
Consider instead the following code that generates a vector of 100 random values that follow a gamma distribution and creates a Q-Q plot for this data to check if it follows a normal distribution:
<b>#make this example reproducible
set.seed(11)
#generate vector of 100 values that follows a gamma distribution
data &lt;- rgamma(100, 1)
#create Q-Q plot to compare this dataset to a theoretical normal distribution
qqnorm(data)
qqline(data)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot4.jpg">
We can see the clear departure from the straight line in this Q-Q plot, indicating that this dataset likely does not follow a normal distribution.
Consider another chunk of code that generates a vector of 100 random values that follow a Chi-Square distribution with 5 degrees of freedom and creates a Q-Q plot for this data to check if it follows a normal distribution:
<b>#make this example reproducible
set.seed(11)
#generate vector of 100 values that follows a Chi-Square distribution
data &lt;- rchisq(100, 5)
#create Q-Q plot to compare this dataset to a theoretical normal distribution
qqnorm(data)
qqline(data)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot5.jpg">
Once again we can see that this dataset does not appear to follow a normal distribution, especially near the tails.
<h2>Modifying the Aesthetics of a Q-Q Plot in R</h2>
We can modify some of the aesthetics of the Q-Q plot in R including the title, axis labels, data point colors, line color, and line width.
The following code modifies the titles, axis labels, and color of the points in the plot:
<b>#make this example reproducible
set.seed(11)
#generate vector of 100 values that follows a normal distribution
data &lt;- rnorm(100)
#create Q-Q plot
qqnorm(data, main = 'Q-Q Plot for Normality', xlab = 'Theoretical Dist',
       ylab = 'Sample dist', col = 'steelblue')</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot6.jpg">
Next, the following code adds a straight diagonal line to the plot with a color of red, a line width of 2 (lwd = 2, default is 1), and a dashed line (lty = 2, default is 1):
<b>qqline(data, col = 'red', lwd = 2, lty = 2)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/qqplot7.jpg">
<h2>Technical Notes</h2>
Keep in mind that a Q-Q plot is simply a way to <em>visually </em>check if a dataset follows a theoretical distribution. To formally test whether or not a dataset follows a particular distribution, the following tests can be performed (assuming you’re comparing your dataset to a normal distribution):
<b> Anderson-Darling Test 
 Shapiro-Wilk Test 
 Kolmogorov-Smirnov Test 
</b>
<h2><span class="orange">How to Create and Interpret Q-Q Plots in SPSS</span></h2>
A <b>Q-Q plot</b>, short for “quantile-quantile” plot, is often used to assess whether or not a variable is normally distributed.
This tutorial explains how to create and interpret a Q-Q plot in SPSS.
<h3>Example: Q-Q Plot in SPSS</h3>
Suppose we have the following dataset in SPSS that displays the points per game for 25 different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/qqplotSPSS1.png">
We can use the following steps in SPSS to create a Q-Q plot to determine whether or not the variable <b>points </b>is normally distributed.
<b>Step 1: Choose the Explore option.</b>
Click the <b>Analyze </b>tab, then <b>Descriptive Statistics</b>, then <b>Explore</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/qqplotSPSS2.png">
<b>Step 2: Create the Q-Q plot.</b>
Drag the variable <b>points </b>into the box labelled Dependent List. Then click the button labelled <b>Plots </b>and make sure the box is checked next to <b>Normality plots with tests</b>. Then click <b>Continue</b>. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/qqplotSPSS3.png">
<b>Step 3: Interpret the Q-Q plot.</b>
Once you click <b>OK</b>, the following Q-Q plot will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/qqplotSPSS4.png">
The idea behind a Q-Q plot is simple: if the residuals fall along a roughly straight line at a 45-degree angle, then the residuals are roughly normally distributed.
We can see in our Q-Q plot above that the residuals tend to deviate from the 45-degree line quite a bit, especially on the tail ends, which could be an indication that they’re not normally distributed.
Although a Q-Q plot isn’t a formal statistical test, it offers an easy way to visually check whether or not the residuals are normally distributed.
For two formal statistical tests, refer to the p-values from the Kolmogorov-Smirnov Test and the Shapiro-Wilk Test displayed above the Q-Q plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/qqplotSPSS5.png">
P-value of Kolmogorov-Smirnov Normality Test: <b>.086</b>
P-value of Shapiro-Wilk Normality Test: <b>.042</b>
Since both of these values are close to .05, this is an indication that the variable <b>points</b> may not be normally distributed.
<h2><span class="orange">How to Create and Interpret Q-Q Plots in Stata</span></h2>
A <b>Q-Q plot</b>, short for “quantile-quantile” plot, is often used to assess whether or not the residuals in a regression analysis are normally distributed.
This tutorial explains how to create and interpret a Q-Q plot in Stata.
<h2>Example: Q-Q Plot in Stata</h2>
For this example we will use the built-in <em>auto </em>dataset in Stata. We will fit a multiple linear regression model, using <em>mpg </em>and <em>displacement </em>as the explanatory variables and <em>price </em>as the response variable. We will then obtain the residuals for the model and create a Q-Q plot to see if the residuals following a normal distribution.
<b>Step 1: Load and view the data.</b>
First, we’ll load the data using the following command:
<b>sysuse auto</b>
Next, we’ll get a quick summary of the data using the following command:
<b>summarize</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata1.png"(max-width: 520px) 100vw, 520px">
<b>Step 2: Fit the regression model.</b>
Next, we’ll use the following command to fit the regression model:
<b>regress price mpg displacement</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/residualsStata2.png"(max-width: 565px) 100vw, 565px">
<b>Step 3: Calculate the residuals</b>.
Recall that a <b>residual </b>is simply the difference between the predicted response value (as calculated by the estimated regression equation) and the actual response value.
We can obtain the residuals of each prediction by using the <b>residuals </b>command and storing these values in a variable named whatever we’d like. In this case, we’ll use the name <b>resid_price</b>:
<b>predict resid_price, residuals</b>
<b>Step 4: Create the Q-Q Plot.</b>
Now that we have a list of residuals, we can create a Q-Q plot using the <b>qnorm </b>command:
<b>qnorm resid_price</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/qqplotStata1.png">
<b>Step 5: Interpret the Q-Q Plot.</b>
The idea behind a Q-Q plot is simple: if the residuals fall along a roughly straight line at a 45-degree angle, then the residuals are roughly normally distributed. We can see in our Q-Q plot above that the residuals tend to deviate from the 45-degree line quite a bit, especially on the tail ends, which could be an indication that they’re not normally distributed.
Although a Q-Q plot isn’t a formal statistical test, it offers an easy way to visually check whether or not the residuals are normally distributed.
If it turns out that your residuals deviate severely from the 45-degree line in the Q-Q plot, you may consider performing a transformation on the response variable in your regression, such as using the square root or the log of the response variable.
If the residuals only deviate slightly, you don’t need to worry about transforming the response variable as regression is fairly robust to departures from normality.
<h2><span class="orange">How to Create a Quadrant Chart in Excel (Step-by-Step)</span></h2>
A <b>quadrant chart</b> is a type of chart that allows you to visualize points on a scatter plot in four distinct quadrants.
This tutorial provides a step-by-step example of how to create the following quadrant chart in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel11.jpg">
<h3>Step 1: Enter the Data</h3>
First, let’s enter the following dataset of x and y values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel1.jpg"458">
<h3>Step 2: Create a Scatter Plot</h3>
Next, highlight the cells in the range <b>A2:B9</b>, then click the <b>Insert</b> tab, then click the <b>Scatter</b> option in the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scatterExcel.png">
Excel will automatically insert the following scatter plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel2.jpg"505">
<h3>Step 3: Create the Quadrant Chart</h3>
To turn this scatter plot into a quadrant chart, we’ll first click on the horizontal and vertical gridlines and delete both:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel3.jpg"518">
Next, we need to add a vertical line in the middle of the x-axis range and a horizontal line in the middle of the y-axis range.
Here’s how to calculate the values for the <b>horizontal line</b>:
<b>x-values</b>: The min and max values of the x-axis
<b>y-values</b>: The average of the min and max values of the y-axis
Here’s how to calculate the values for the <b>vertical line</b>:
<b>x-values</b>: The average of the min and max values of the x-axis
<b>y-values</b>: The min and max values of the y-axis
The following screenshot shows how to calculate the values for both the horizontal and vertical lines:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel4.jpg"671">
Next, right click anywhere on the scatter plot and click <b>Select Data</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel5.jpg"505">
In the new window that appears, click <b>Add</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel6.jpg"616">
In the new window that appears, type any name you’d like in the Series name box, then choose <b>B12:B13</b> in the <b>Series X Values</b> box, then type <b>C12:C13</b> in the <b>Series Y Values</b> Box, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel7.jpg"612">
Two orange dots will be added to the plot. Click on either dot to bring up the <b>Format Data Series</b> panel on the right side of the screen.
Then click the <b>Line</b> icon, then click <b>Solid line</b> and choose Black as the <b>Color</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel8.jpg"274">
Then click the <b>Marker</b> icon, then click <b>None:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel9.jpg"304">
The following horizontal line will automatically be added to the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel10.jpg"488">
Repeat this exact same process to add the vertical line to the chart.
The result will the following quadrant chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrantexcel11.jpg">
There are now four distinct quadrants in the chart and each point in the chart falls in one of the four quadrants.
<h2><span class="orange">How to Create a Quadrant Chart in Google Sheets</span></h2>
A <b>quadrant chart</b> is a type of chart that allows you to visualize points on a scatter plot in four distinct quadrants.
This tutorial provides a step-by-step example of how to create the following quadrant chart in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant5.jpg"531">
<h3>Step 1: Create the Data</h3>
First, let’s enter the following dataset of x and y values in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant1.jpg"480">
<h3>Step 2: Create a Scatter Plot</h3>
Next, highlight the cells in the range <b>A2:B9</b>, then click the <b>Insert</b> tab, then click <b>Chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant2.jpg"469">
Google Sheets will automatically insert the following scatter plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant3.jpg"533">
<h3>Step 3: Create the Quadrant Chart</h3>
Notice that the x-axis of the scatter plot ranges from <b>-8</b> to <b>6</b> and the y-axis ranges from <b>-10</b> to <b>10</b>.
However, a quadrant chart requires that each axis has the same range.
To change the range of the x-axis, double click anywhere on the chart.
In the <b>Chart editor</b> panel that appears on the right side of the screen, click the <b>Customize</b> tab, then click <b>Horizontal axis</b>, then change the <b>Min</b> and <b>Max</b> values to -10 and 10:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant4.jpg"291">
The range of the x-axis will automatically be modified to range from -10 to 10:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/quadrant5.jpg"531">
There are now four distinct <b>quadrants</b> in the chart that are each the same size and each point in the chart falls in one of the distinct quadrants.
<h2><span class="orange">Quadratic Discriminant Analysis in Python (Step-by-Step)</span></h2>
 Quadratic discriminant analysis  is a method you can use when you have a set of predictor variables and you’d like to classify a  response variable  into two or more classes.
It is considered to be the non-linear equivalent to  linear discriminant analysis .
This tutorial provides a step-by-step example of how to perform quadratic discriminant analysis in Python.
<h3>Step 1: Load Necessary Libraries</h3>
First, we’ll load the necessary functions and libraries for this example:
<b>from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis 
from sklearn import datasets
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np</b>
<h3>Step 2: Load the Data</h3>
For this example, we’ll use the <b>iris</b> dataset from the sklearn library. The following code shows how to load this dataset and convert it to a pandas DataFrame to make it easy to work with:
<b>#load <em>iris </em>dataset
iris = datasets.load_iris()
#convert dataset to pandas DataFrame
df = pd.DataFrame(data = np.c_[iris['data'], iris['target']], columns = iris['feature_names'] + ['target'])
df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)
df.columns = ['s_length', 's_width', 'p_length', 'p_width', 'target', 'species']
#view first six rows of DataFrame
df.head()
   s_length  s_width  p_length  p_width  target species
0       5.1      3.5       1.4      0.2     0.0  setosa
1       4.9      3.0       1.4      0.2     0.0  setosa
2       4.7      3.2       1.3      0.2     0.0  setosa
3       4.6      3.1       1.5      0.2     0.0  setosa
4       5.0      3.6       1.4      0.2     0.0  setosa
#find how many total observations are in dataset
len(df.index)
150</b>
We can see that the dataset contains 150 total observations.
For this example we’ll build a quadratic discriminant analysis model to classify which species a given flower belongs to.
We’ll use the following predictor variables in the model:
Sepal length
Sepal width
Petal length
Petal width
And we’ll use them to predict the response variable <em>Species</em>, which takes on the following three potential classes:
setosa
versicolor
virginica
<h3>Step 3: Fit the QDA Model</h3>
Next, we’ll fit the QDA model to our data using the  QuadraticDiscriminantAnalsyis  function from sklearn:
<b>#define predictor and response variables
X = df[['s_length', 's_width', 'p_length', 'p_width']]
y = df['species']
#Fit the QDA model
model = QuadraticDiscriminantAnalysis()
model.fit(X, y)
</b>
<h3>Step 4: Use the Model to Make Predictions</h3>
Once we’ve fit the model using our data, we can evaluate how well the model performed by using repeated stratified k-fold cross validation.
For this example, we’ll use 10 folds and 3 repeats:
<b>#Define method to evaluate model
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
#evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
print(np.mean(scores))   
0.97333333333334</b>
We can see that the model performed a mean accuracy of <b>97.33%</b>.
We can also use the model to predict which class a new flower belongs to, based on input values:
<b>#define new observation
new = [5, 3, 1, .4]
#predict which class the new observation belongs to
model.predict([new])
array(['setosa'], dtype='&lt;U10')
</b>
We can see that the model predicts this new observation to belong to the species called <em>setosa</em>.
You can find the complete Python code used in this tutorial  here .
<h2><span class="orange">Quadratic Discriminant Analysis in R (Step-by-Step)</span></h2>
 Quadratic discriminant analysis  is a method you can use when you have a set of predictor variables and you’d like to classify a  response variable  into two or more classes. It is considered to be the non-linear equivalent to  linear discriminant analysis .
This tutorial provides a step-by-step example of how to perform quadratic discriminant analysis in R.
<h3>Step 1: Load Necessary Libraries</h3>
First, we’ll load the necessary libraries for this example:
<b>library(MASS)
library(ggplot2)</b>
<h3>Step 2: Load the Data</h3>
For this example, we’ll use the built-in <b>iris</b> dataset in R. The following code shows how to load and view this dataset:
<b>#attach <em>iris</em> dataset to make it easy to work with
attach(iris)
#view structure of dataset
str(iris)
'data.frame':150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 ...
</b>
We can see that the dataset contains 5 variables and 150 total observations.
For this example we’ll build a quadratic discriminant analysis model to classify which species a given flower belongs to.
We’ll use the following predictor variables in the model:
Sepal.length
Sepal.Width
Petal.Length
Petal.Width
And we’ll use them to predict the response variable <em>Species</em>, which takes on the following three potential classes:
setosa
versicolor
virginica
<h3>Step 3: Create Training and Test Samples</h3>
Next, we’ll split the dataset into a training set to train the model on and a testing set to test the model on:
<b>#make this example reproducible
set.seed(1)
#Use 70% of dataset as training set and remaining 30% as testing set
sample &lt;- sample(c(TRUE, FALSE), nrow(iris), replace=TRUE, prob=c(0.7,0.3))
train &lt;- iris[sample, ]
test &lt;- iris[!sample, ] 
</b>
<h3>Step 4: Fit the QDA Model</h3>
Next, we’ll use the  qda() function  from the <b>MASS</b> package to fit the QDA model to our data:
<b>#fit QDA model
model &lt;- qda(Species~., data=train)
#view model output
model
Call:
qda(Species ~ ., data = train)
Prior probabilities of groups:
    setosa versicolor  virginica 
 0.3207547  0.3207547  0.3584906 
Group means:
           Sepal.Length Sepal.Width Petal.Length Petal.Width
setosa         4.982353    3.411765     1.482353   0.2411765
versicolor     5.994118    2.794118     4.358824   1.3676471
virginica      6.636842    2.973684     5.592105   2.0552632 
</b>
Here is how to interpret the output of the model:
<b>Prior probabilities of group: </b>These represent the proportions of each Species in the training set. For example, 35.8% of all observations in the training set were of species <em>virginica</em>.
<b>Group means:</b> These display the mean values for each predictor variable for each species.
<h3>Step 5: Use the Model to Make Predictions</h3>
Once we’ve fit the model using our training data, we can use it to make predictions on our test data:
<b>#use QDA model to make predictions on test data
predicted &lt;- predict(model, test)
names(predicted)
[1] "class"     "posterior" "x"   
</b>
This returns a list with two variables:
<b>class:</b> The predicted class
<b>posterior:</b> The  posterior probability  that an observation belongs to each class
We can quickly view each of these results for the first six observations in our test dataset:
<b>#view predicted class for first six observations in test set
head(predicted$class)
[1] setosa setosa setosa setosa setosa setosa
Levels: setosa versicolor virginica
#view posterior probabilities for first six observations in test set
head(predicted$posterior)
   setosa   versicolor    virginica
4       1 7.224770e-20 1.642236e-29
6       1 6.209196e-26 8.550911e-38
7       1 1.248337e-21 8.132700e-32
15      1 2.319705e-35 5.094803e-50
17      1 1.396840e-29 9.586504e-43
18      1 7.581165e-25 8.611321e-37
</b>
<h3>Step 6: Evaluate the Model</h3>
We can use the following code to see what percentage of observations the QDA model correctly predicted the Species for:
<b>#find accuracy of model
mean(predicted$class==test$Species)
[1] 1</b>
It turns out that the model correctly predicted the Species for <b>100%</b> of the observations in our test dataset.
In the real-world an QDA model will rarely predict every class outcome correctly, but this iris dataset is simply built in a way that machine learning algorithms tend to perform very well on it.
You can find the complete R code used in this tutorial  here .
<h2><span class="orange">Introduction to Quadratic Discriminant Analysis</span></h2>
When we have a set of predictor variables and we’d like to classify a  response variable  into one of two classes, we typically use  logistic regression .
However, when a response variable has more than two possible classes then we typically use  linear discriminant analysis , often referred to as LDA.
LDA assumes that <b>(1)</b> observations from each class are  normally distributed  and <b>(2)</b> observations from each class share the same covariance matrix. Using these assumptions, LDA then finds the following values:
<b>μ<sub>k</sub></b>: The mean of all training observations from the k<sup>th</sup> class.
<b>σ<sup>2</sup></b>: The weighted average of the sample variances for each of the <em>k</em> classes.
<b>π<sub>k</sub></b>: The proportion of the training observations that belong to the k<sup>th</sup> class.
LDA then plugs these numbers into the following formula and assigns each observation X = x to the class for which the formula produces the largest value:
<b>D<sub>k</sub>(x) = x * (μ<sub>k</sub>/σ<sup>2</sup>) – (μ<sub>k</sub><sup>2</sup>/2σ<sup>2</sup>) + log(π<sub>k</sub>)</b>
LDA has <em>linear</em> in its name because the value produced by the function above comes from a result of <em>linear functions</em> of x.
An extension of linear discriminant analysis is <b>quadratic discriminant analysis</b>, often referred to as QDA.
This method is similar to LDA and also assumes that the observations from each class are normally distributed, but it does not assume that each class shares the same covariance matrix. Instead, QDA assumes that each class has its own covariance matrix.
That is, it assumes that an observation from the k<sup>th</sup> class is of the form X ~ N(μ<sub>k</sub>, Σ<sub>k</sub>).
Using this assumption, QDA then finds the following values:
<b>μ<sub>k</sub></b>: The mean of all training observations from the k<sup>th</sup> class.
<b>Σ<sub>k</sub>:</b> The covariance matrix of the k<sup>th</sup> class.
<b>π<sub>k</sub></b>: The proportion of the training observations that belong to the k<sup>th</sup> class.
QDA then plugs these numbers into the following formula and assigns each observation X = x to the class for which the formula produces the largest value:
<b>D<sub>k</sub>(x) = -1/2*(x-μ<sub>k</sub>)<sup>T</sup> Σ<sub>k</sub><sup>-1</sup>(x-μ<sub>k</sub>) – 1/2*log|Σ<sub>k</sub>| + log(π<sub>k</sub>)</b>
Note that QDA has <em>quadratic</em> in its name because the value produced by the function above comes from a result of <em>quadratic functions</em> of x.
<h3>LDA vs. QDA: When to Use One vs. the Other</h3>
The main difference between LDA and QDA is that LDA assumes each class shares a covariance matrix, which makes it a much less flexible classifier than QDA.
This inherently means it has low variance – that is, it will perform similarly on different training datasets. The drawback is that if the assumption that the <em>K </em>classes have the same covariance is untrue, then LDA can suffer from  high bias .
QDA is generally preferred to LDA in the following situations:
<b>(1)</b> The training set is large.
<b>(2)</b> It’s unlikely that the <em>K </em>classes share a common covariance matrix.
When these conditions hold, QDA tends to perform better since it is more flexible and can provide a better fit to the data.
<h3>How to Prepare Data for QDA</h3>
Make sure your data meets the following requirements before applying a QDA model to it:
<b>1. The response variable is categorical</b>. QDA models are designed to be used for  classification problems , i.e. when the response variable can be placed into classes or categories.
<b>2. The observations in each class follow a normal distribution</b>. First, check that each the distribution of values in each class is roughly normally distributed. If this is not the case, you may choose to first  transform the data  to make the distribution more normal.
<b>3. Account for extreme outliers.</b> Be sure to check for extreme outliers in the dataset before applying LDA. Typically you can check for outliers visually by simply using  boxplots  or  scatterplots .
<h3>QDA in R & Python</h3>
The following tutorials provide step-by-step examples of how to perform quadratic discriminant analysis in R and Python:
 Quadratic Discriminant Analysis in R (Step-by-Step) 
 Quadratic Discriminant Analysis in Python (Step-by-Step) 
<h2><span class="orange">How to Solve a Quadratic Equation in Excel (Step-by-Step)</span></h2>
A quadratic equation takes the following form:
<b>ax<sup>2</sup> + bx + c = y</b>
Often you will be given the value for <b>y</b> and will be asked to solve for the value of <b>x</b>.
For example, suppose we have the following quadratic equation:
<b>4x<sup>2</sup> – 20x + 16 = -8</b>
It turns out that setting x = <b>3</b> or x = <b>2</b> will solve this equation.
To solve quadratic equations in Excel, you can use the <b>Goal Seek</b> function.
The following step-by-step example shows how to use the Goal Seek function in practice.
<h3>Step 1: Enter the Equation</h3>
First, let’s enter some random value for x and the formula for the quadratic equation for y:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad1.jpg"454">
<h3>Step 2: Find the First X Value Using Goal Seek</h3>
Next, click the <b>Data</b> tab along the top ribbon, then click the <b>What-If Analysis</b> button, then <b>Goal Seek</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad2.jpg"479">
In the new window that appears, specify that you’d like to set cell <b>B2</b> equal to <b>-8</b> by changing the value in cell <b>A2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad3.jpg"474">
Once we click <b>OK</b>, the Goal Seek function will automatically find the value for x that solves the equation:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad4.jpg"432">
Goal Seek finds that the value <b>x=2</b> (assuming 1.9999 rounds to 2) solves the quadratic equation.
<h3>Step 3: Find the Second X Value Using Goal Seek</h3>
To find the second x value that solves the quadratic equation, set the initial x-value to a different number.
For example, we could choose to set the initial x-value to 4:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad5.jpg"452">
We can then run the <b>Goal Seek</b> function again and see that it finds a new solution of <b>x=3</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/quad6.jpg"460">
Thus, the two x-values that can solve this quadratic equation are <b>x=2</b> and <b>x=3</b>.
<h2><span class="orange">Quadratic Regression Calculator</span></h2>
This calculator produces a quadratic regression equation based on values for a predictor variable and a response variable.
Simply enter a list of values for a predictor variable and a response variable in the boxes below, then click the “Calculate” button:
<b>Predictor values:</b>
<textarea id="x" rows="5" cols="40">6, 7, 7, 8, 12, 14, 15, 16, 16, 19</textarea>
<b>Response values:</b>
<textarea id="y" rows="5" cols="40">14, 15, 15, 17, 18, 18, 16, 14, 11, 8</textarea>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>Quadratic Regression Equation:</b>
<b><U+0177> = -2.5475 + (3.7516)x + (-0.1704)x<sup>2</sup></b>
<script>
function calc() {
//get input data
var x = document.getElementById('x').value.split(',').map(Number);
var y = document.getElementById('y').value.split(',').map(Number);
//check that both lists are equal length
if (x.length - y.length == 0) {
document.getElementById('error_msg').innerHTML = '';
var xbar = math.mean(x);
var ybar = math.mean(y);
let xbar2_hold = 0
for (let i = 0; i < x.length; i++) {
xbar2_hold += Math.pow(x[i], 2);
}
var xbar2 = xbar2_hold / x.length;
let sxx = 0
for (let i = 0; i < x.length; i++) {
sxx += Math.pow(x[i] - xbar, 2);
}
let sxy = 0
for (let i = 0; i < x.length; i++) {
sxy += (x[i] - xbar)*(y[i]-ybar);
}
let sxx2 = 0
for (let i = 0; i < x.length; i++) {
sxx2 += (x[i] - xbar)*(Math.pow(x[i], 2)-xbar2);
}
let sx2x2 = 0
for (let i = 0; i < x.length; i++) {
sx2x2 += Math.pow((Math.pow(x[i], 2)-xbar2), 2);
}
let sx2y = 0
for (let i = 0; i < x.length; i++) {
sx2y += (Math.pow(x[i], 2)-xbar2)*(y[i]-ybar);
}
var b = ((sxy*sx2x2)-(sx2y*sxx2)) / ((sxx*sx2x2)-Math.pow(sxx2, 2));
var c = ((sx2y*sxx)-(sxy*sxx2)) / ((sxx*sx2x2)-Math.pow(sxx2, 2));
var a = ybar - (b*xbar) - (c*xbar2);
document.getElementById('a').innerHTML = a.toFixed(4);
document.getElementById('b').innerHTML = b.toFixed(4);
document.getElementById('c').innerHTML = c.toFixed(4);
}
//output error message if boths lists are not equal
else {
 //document.getElementById('out').innerHTML = '';
 document.getElementById('error_msg').innerHTML = 'The two lists must be of equal length.';
}
  
} //end calc function
</script>
<h2><span class="orange">How to Perform Quadratic Regression in Excel</span></h2>
<b>Regression </b>is a statistical technique we can use to explain the relationship between one or more predictor variables and a response variable. The most common type of regression is  linear regression , which we use when the relationship between the predictor variable and the response variable is <em>linear</em>. 
That is, when the predictor variable increases, the response variable tends to increase as well. For example, we may use a linear regression model to describe the relationship between the number of hours studied (predictor variable) and the score that a student receives on an exam (response variable).
However, sometimes the relationship between a predictor variable and a response variable is <em>non-linear</em>. One common type of non-linear relationship is a <b>quadratic relationship</b>, which may look like a U or an upside-down U on a graph. 
That is, when the predictor variable increases the response variable tends to increase as well, but after a certain point the response variable begins to decrease as the predictor variable keeps increasing.
For example, we may use a quadratic regression model to describe the relationship between the number of hours spent working and a person’s reported happiness levels. Perhaps the more a person works, the more fulfilled they feel, but once they reach a certain threshold, more work actually leads to stress and decreased happiness. In this case, a quadratic regression model would fit the data better than a linear regression model.
Let’s walk through an example of how to perform quadratic regression in Excel.
<h2>Quadratic Regression in Excel</h2>
Suppose we have data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 16 different people:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel1.jpg" alt="">
First, let’s create a scatterplot to see if linear regression is an appropriate model to fit to the data.
Highlight cells <b>A2:B17</b>. Next, click the INSERT tab along the top ribbon, then click <em>Scatter </em>in the <em>Charts </em>area. This will produce a  scatterplot  of the data:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel2.jpg">
It’s easy to see that the relationship between hours worked and reported happiness is <em>not </em>linear. In fact, it follows a “U” shape, which makes it a perfect candidate for <b>quadratic regression</b>.
Before we fit the quadratic regression model to the data, we need to create a new column for the squared values of our predictor variable. 
First, highlight all of the values in column B and drag them to column C.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel3.jpg" alt="">
Next, type in the formula <b>=A2^2 </b>in cell B2. This produces the value <b>36</b>. Next, click on the bottom right corner of cell B2 and drag the formula down to fill in the remaining cells in column B. 
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel4.jpg" alt="">
Next, we will fit the quadratic regression model. 
Click on DATA along the top ribbon, then click the <em>Data Analysis</em> option on the far right. If you do not see this option, then you first need to  install the free Analysis ToolPak .
Once you click <em>Data Analysis</em>, a box will pop up. Click <em>Regression </em>and then click <em>OK</em>.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel5.jpg" alt="">
Next, fill in the following values in the <em>Regression </em>box that pops up. Then click <em>OK</em>.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel6.jpg" alt="">
The following results will be displayed:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/quadRegExcel7.jpg">
Here is how to interpret various numbers from the output:
<b>R Square: </b>Also known as the <em>coefficient of determination, </em>this is the proportion of the variance in the response variable that can be explained by the predictor variables. In this example,the R-square is <b>0.9092</b>, which indicates that 90.92% of the variance in the reported happiness levels can be explained by the number of hours worked and the number of hours worked ^2. 
<b>Standard error: </b>The standard error of the regression is the average distance that the observed values fall from the regression line. In this example, the observed values fall an average of<b> 9.519 units </b>from the regression line.
<b>F Statistic: </b>The F statistic is calculated as regression MS / residual MS. This statistic indicates whether the regression model provides a better fit to the data than a model that contains no independent variables. In essence, it tests if the regression model as a whole is useful. Generally if none of the predictor variables in the model are statistically significant, the overall F statistic is also not statistically significant. In this example, the F statistic is <b>65.09 </b>and the corresponding p-value is &lt;0.0001. Since this p-value is less than 0.05, the regression model as a whole is significant. 
<b>Regression coefficients: </b>The regression coefficients in the last table give us the numbers necessary to write the estimated regression equation:
<b>y<sub>hat</sub> = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>1</sub><sup>2</sup></b>
In this example, the estimated regression equation is:
<b>reported happiness level = -30.252 + 7.173(Hours worked) -0.106(Hours worked)<sup>2</sup></b>
We can use this equation to calculate the expected happiness level of an individual based on their hours worked. For example, the expected happiness level of someone who works 30 hours per week is:
reported happiness level = -30.252 + 7.173(30) -0.106(30)<sup>2</sup> =<b> 88.649</b>.
<h2>Additional Resources</h2>
<b> How to Add a Quadratic Trendline in Excel 
 How to Read and Interpret a Regression Table </b>
<b> What is a Good R-squared Value? 
 Understanding the Standard Error of the Regression 
 A Simple Guide to Understanding the F-Test of Overall Significance in Regression </b>
<h2><span class="orange">How to Perform Quadratic Regression in Python</span></h2>
<b>Quadratic regression</b> is a type of regression we can use to quantify the relationship between a predictor variable and a response variable when the true relationships is quadratic, which may look like a “U” or an upside-down “U” on a graph.
That is, when the predictor variable increases the response variable tends to increase as well, but after a certain point the response variable begins to decrease as the predictor variable keeps increasing.
This tutorial explains how to perform quadratic regression in Python.
<h2>Example: Quadratic Regression in Python</h2>
Suppose we have data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 16 different people:
<b>import numpy as np
import scipy.stats as stats
#define variables
hours = [6, 9, 12, 12, 15, 21, 24, 24, 27, 30, 36, 39, 45, 48, 57, 60]
happ = [12, 18, 30, 42, 48, 78, 90, 96, 96, 90, 84, 78, 66, 54, 36, 24]</b>
If we make a simple scatterplot of this data we can see that the relationship between the two variables is “U” shaped:
<b>import matplotlib.pyplot as plt
#create scatterplot
plt.scatter(hours, happ)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/quadRegPython1.png">
As hours worked increases, happiness also increases but once hours worked passes around 35 hours per week happiness starts to decline.
Because of this “U” shape, this means quadratic regression is likely a good candidate to quantify the relationship between the two variables.
To actually perform quadratic regression, we can fit a polynomial regression model with a degree of 2 using the  numpy.polyfit()  function:
<b>import numpy as np
#polynomial fit with degree = 2
model = np.poly1d(np.polyfit(hours, happ, 2))
#add fitted polynomial line to scatterplot
polyline = np.linspace(1, 60, 50)
plt.scatter(hours, happ)
plt.plot(polyline, model(polyline))
plt.show()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/quadRegPython2.png">
We can obtain the fitted polynomial regression equation by printing the model coefficients:
<b>print(model)
-0.107x<sup>2</sup> + 7.173x - 30.25
</b>
The fitted quadratic regression equation is:
<b>Happiness = -0.107(hours)<sup>2</sup> + 7.173(hours) – 30.25</b>
We can use this equation to calculate the expected happiness level of an individual based on their hours worked. For example, the expected happiness level of someone who works 30 hours per week is:
Happiness = -0.107(30)<sup>2</sup> + 7.173(30) – 30.25 = <b>88.64</b>.
We can also write a short function to obtain the R-squared of the model, which is the proportion of the variance in the response variable that can be explained by the predictor variables.
<b>#define function to calculate r-squared
def polyfit(x, y, degree):
    results = {}
    coeffs = np.polyfit(x, y, degree)
    p = np.poly1d(coeffs)
    #calculate r-squared
    yhat = p(x)
    ybar = np.sum(y)/len(y)
    ssreg = np.sum((yhat-ybar)**2)
    sstot = np.sum((y - ybar)**2)
    results['r_squared'] = ssreg / sstot
    return results
#find r-squared of polynomial model with degree = 3
polyfit(hours, happ, 2)
{'r_squared': 0.9092114182131691}
</b>
In this example, the R-squared of the model is <b>0.9092</b>.
This means that 90.92% of the variation in the reported happiness levels can be explained by the predictor variables.
<h2>Additional Resources</h2>
 How to Perform Polynomial Regression in Python 
 How to Perform Quadratic Regression in R 
 How to Perform Quadratic Regression in Excel 
<h2><span class="orange">How to Perform Quadratic Regression in R</span></h2>
When two variables have a linear relationship, we can often use  simple linear regression  to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata1.png"(max-width: 442px) 100vw, 442px">
However, when two variables have a quadratic relationship, we can instead use <b>quadratic regression</b> to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata2.png"(max-width: 441px) 100vw, 441px">
This tutorial explains how to perform quadratic regression in R.
<h3>Example: Quadratic Regression in R</h3>
Suppose we are interested in understanding the relationship between number of hours worked and reported happiness. We have the following data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 11 different people:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI1.png"(max-width: 150px) 100vw, 150px">
Use the following steps to fit a quadratic regression model in R.
<b>Step 1: Input the data.</b>
First, we’ll create a data frame that contains our data:
<b>#create data
data &lt;- data.frame(hours=c(6, 9, 12, 14, 30, 35, 40, 47, 51, 55, 60),   happiness=c(14, 28, 50, 70, 89, 94, 90, 75, 59, 44, 27))
#view data 
data
   hours happiness
1      6        14
2      9        28
3     12        50
4     14        70
5     30        89
6     35        94
7     40        90
8     47        75
9     51        59
10    55        44
11    60        27
</b>
<b>Step 2: Visualize the data.</b>
Next, we’ll create a simple scatterplot to visualize the data.
<b>#create scatterplot
plot(data$hours, data$happiness, pch=16)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/quadraticR1.png">
We can clearly see that the data does not follow a linear pattern.
<b>Step 3: Fit a simple linear regression model.</b>
Next, we will fit a simple linear regression model to see how well it fits the data:
<b>#fit linear model
linearModel &lt;- lm(happiness ~ hours, data=data)
#view model summary
summary(linearModel)
Call:
lm(formula = happiness ~ hours)
Residuals:
   Min     1Q Median     3Q    Max 
-39.34 -21.99  -2.03  23.50  35.11 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept)  48.4531    17.3288   2.796   0.0208 *
hours         0.2981     0.4599   0.648   0.5331  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 28.72 on 9 degrees of freedom
Multiple R-squared:  0.0446,Adjusted R-squared:  -0.06156 
F-statistic: 0.4201 on 1 and 9 DF,  p-value: 0.5331
</b>
The total variance in happiness explained by the model is just <b>4.46%</b>, as shown by the value for Multiple R-squared.
<b>Step 4: Fit a quadratic regression model.</b>
Next, we will fit a quadratic regression model.
<b>#create a new variable for hours<sup>2</sup>
data$hours2 &lt;- data$hours^2
#fit quadratic regression model
quadraticModel &lt;- lm(happiness ~ hours + hours2, data=data)
#view model summary
summary(quadraticModel)
Call:
lm(formula = happiness ~ hours + hours2, data = data)
Residuals:
    Min      1Q  Median      3Q     Max 
-6.2484 -3.7429 -0.1812  1.1464 13.6678 
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -18.25364    6.18507  -2.951   0.0184 *  
hours         6.74436    0.48551  13.891 6.98e-07 ***
hours2       -0.10120    0.00746 -13.565 8.38e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 6.218 on 8 degrees of freedom
Multiple R-squared:  0.9602,Adjusted R-squared:  0.9502 
F-statistic: 96.49 on 2 and 8 DF,  p-value: 2.51e-06
</b>
The total variance in happiness explained by the model jumped to <b>96.02%</b>.
We can use the following code to visualize how well the model fits the data:
<b>#create sequence of hour values
hourValues &lt;- seq(0, 60, 0.1)
#create list of predicted happines levels using quadratic model
happinessPredict &lt;- predict(quadraticModel,list(hours=hourValues, hours2=hourValues^2))
#create scatterplot of original data values
plot(data$hours, data$happiness, pch=16)
#add predicted lines based on quadratic regression model
lines(hourValues, happinessPredict, col='blue')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/quadraticR2.png">
We can see that the quadratic regression line fits the data values quite well.
<b>Step 5: Interpret the quadratic regression model.</b>
In the previous step we saw that the output of the quadratic regression model was as follows:
<b>Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -18.25364    6.18507  -2.951   0.0184 *  
hours         6.74436    0.48551  13.891 6.98e-07 ***
hours2       -0.10120    0.00746 -13.565 8.38e-07 ***
</b>
Based on the coefficients shown here, the fitted quadratic regression would be:
<b>Happiness = -0.1012(hours)<sup>2</sup> + 6.7444(hours) – 18.2536</b>
We can use this equation to find the predicted happiness of an individual, given the number of hours they work per week.
For example, an individual that works 60 hours per week is predicted to have a happiness level of <b>22.09</b>:
Happiness = -0.1012(60)<sup>2</sup> + 6.7444(60) – 18.2536 = 22.09
Conversely, an individual that works 30 hours perk week is predicted to have a happiness level of <b>92.99</b>:
Happiness = -0.1012(30)<sup>2</sup> + 6.7444(30) – 18.2536 = 92.99
<h2><span class="orange">How to Perform Quadratic Regression in SPSS</span></h2>
When two variables have a linear relationship, you can often use <b> simple linear regression </b> to quantify their relationship.
However, simple linear regression doesn’t work well when two variables have a non-linear relationship. In these cases, you can try using <b>quadratic regression</b>. 
This tutorial explains how to perform quadratic regression in SPSS.
<h3>Example: Quadratic Regression in SPSS</h3>
Suppose we are interested in understanding the relationship between number of hours worked and happiness. We have the following data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 16 different people:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS1.png">
Use the following steps to perform a quadratic regression in SPSS.
<b>Step 1: Visualize the data.</b>
Before we perform quadratic regression, let’s make a scatterplot to visualize the relationship between hours worked and happiness to verify that the two variables actually have a quadratic relationship.
Click the <b>Graphs </b>tab, then <b>Chart Builder</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS2.png">
In the new window that pops up, choose <b>Scatter/Dot </b>in the <b>Choose from </b>list. Then drag the chart titled <b>Simple Scatter </b>into the main editing window. Drag the variable <b>hours </b>onto the x-axis and <b>happiness </b>onto the y-axis. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS3.png">
The following scatterplot will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS4.png">
We can clearly see that a non-linear relationship exists between hours worked and happiness. This tells us that quadratic regression is an appropriate technique to use in this situation.
<b>Step 2: Create a new variable.</b>
Before we can perform quadratic regression, we need to create a predictor variable for hours<sup>2</sup>.
Click the <b>Transform </b>tab, then <b>Compute variable</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS5.png">
In the new window that pops up, name the target variable <b>hours2 </b>and define it as <b>hours*hours</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS6.png">
Once you click <b>OK</b>, the variable <b>hours2 </b>will appear in a new column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS7.png">
<b>Step 3: Perform quadratic regression.</b>
Next, we will perform quadratic regression. Click on the <b>Analyze </b>tab, then <b>Regression</b>, then <b>Linear</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS8.png">
In the new window that pops up, drag <b>happiness </b>into the boxed labeled Dependent. Drag <b>hours</b> and <b>hours2</b> into the box labeled Independent(s). Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS9.png">
<b>Step 4: Interpret the results.</b>
Once you click <b>OK</b>, the results of the quadratic regression will appear in a new window.
The first table we’re interested in is titled <b>Model Summary</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS10.png">
Here is how to interpret the most relevant numbers in this table:
<b>R Square: </b>This is the proportion of the variance in the response variable that can be explained by the explanatory variables. In this example, <b>90.9%</b> of the variation in happiness can be explained by the variables <b>hours </b>and <b>hours<sup>2</sup></b>.
<b>Std. Error of the Estimate: </b>The  standard error  is the average distance that the observed values fall from the regression line. In this example, the observed values fall an average of <b>9.519 </b>units from the regression line.
The next table we’re interested in is titled <b>ANOVA</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS11.png">
Here is how to interpret the most relevant numbers in this table:
<b>F: </b>This is the overall F statistic for the regression model, calculated as Mean Square Regression / Mean Square Residual.
<b>Sig: </b>This is the p-value associated with the overall F statistic. It tells us whether or not the regression model as a whole is statistically significant. In this case the p-value is equal to 0.000, which indicates that the explanatory variables <b>hours</b> and <b>hours<sup>2</sup></b> combined have a statistically significant association with exam score.
The next table we’re interested in is titled <b>Coefficients</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/quadregSPSS12.png">
We can use the values in the column <b>Unstandardized B </b>to form the estimated regression equation for this dataset:
Estimated happiness level = -30.253 + 7.173*(hours) – .107*(hours<sup>2</sup>)
We can use this equation to find the estimated happiness level for an individual based on the number of hours they work per week. For example, an individual that works 60 hours per week is expected to have a happiness level of 14.97:
Estimated happiness level = -30.253 + 7.173*(60) – .107*(60<sup>2</sup>) = <b>14.97</b>.
Conversely, an individual that works 30 hours perk week is predicted to have a happiness level of 88.65:
Estimated happiness level = -30.253 + 7.173*(30) – .107*(30<sup>2</sup>) = <b>88.65</b>.
<b>Step 5: Report the results.</b>
Lastly, we want to report the results of our quadratic regression. Here is an example of how to do so:
A quadratic regression was performed to quantify the relationship between the number of hours worked by an individual and their corresponding happiness level (measured from 0 to 100). A sample of 16 individuals was used in the analysis.
 
Results showed that there was a statistically significant relationship between the explanatory variables <em>hours </em>and <em>hours<sup>2 </sup></em>and the response variable <em>happiness</em> (F(2, 13) = 65.095, p &lt; 0.000).
 
Combined, these two explanatory variables accounted for 90.9% of variability in happiness. 
 
The regression equation was found to be:
 
Estimated happiness level  = -30.253 + 7.173(hours) – .107(hours<sup>2</sup>)
<h2><span class="orange">How to Perform Quadratic Regression in Stata</span></h2>
When two variables have a linear relationship, you can often use <b> simple linear regression </b> to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata1.png">
However, when two variables have a quadratic relationship, you can instead use <b>quadratic regression</b> to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata2.png">
This tutorial explains how to perform quadratic regression in Stata.
<h2>Example: Quadratic Regression in Stata</h2>
Suppose we are interested in understanding the relationship between number of hours worked and happiness. We have the following data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 16 different people:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata3.png">
<em>You can replicate this example by typing in this exact data into Stata using <b>Data > Data Editor > Data Editor (Edit) </b>along the top menu.</em>
Use the following steps to perform a quadratic regression in Stata.
<b>Step 1: Visualize the data.</b>
Before we can use quadratic regression, we need to make sure that the relationship between the explanatory variable (hours) and response variable (happiness) is actually quadratic. So, let’s visualize the data using a scatterplot by typing the following into the Command box:
<b>scatter happiness hours</b>
This produces the following scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata4.png">
We can see that happiness tends to increase as number of hours worked increases from zero up to a certain point, but then begins to drop lower as the number of hours worked exceeds about 30.
This upside down “U” shape in the scatterplot indicates that there is a quadratic relationship between hours worked and happiness, which means we should use quadratic regression to quantify this relationship.
<b>Step 2: Perform quadratic regression.</b>
Before we fit the quadratic regression model to the data, we need to create a new variable for the squared values of our predictor variable <em>hours</em>. We can do so by typing the following into the Command box:
<b>gen hours2 = hours*hours</b>
We can view this new variable by going to <em><b>Data > Data Editor > Data Editor (Browse) </b>along the top menu.</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata5.png">
We can see that hours2 is simply hours squared. Now we can perform quadratic regression using <em>hours </em>and <em>hours2 </em>as our explanatory variables and <em>happiness </em>as our response variable. To perform quadratic regression, type the following into the Command box:
<b>regress happiness hours hours2</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata6.png">
Here is how to interpret the most interesting numbers in the output:
<b>Prob > F:</b> 0.000. This is the p-value for the overall regression. Since this value is less than 0.05, it means that the predictor variables <em>hours </em>and <em>hours<sup>2</sup></em> combined have a statistically significant relationship with the response variable <em>happiness</em>.
<b>R-squared:</b> 0.9092. This is the proportion of the variance in the response variable that can be explained by the explanatory variable. In this example, 90.92% of the variation in happiness can be explained by <em>hours </em>and <em>hours<sup>2</sup></em>.
<b>Regression Equation: </b>We can form a regression equation using the coefficient values reported in the output table. In this case, the equation would be:
predicted happiness  = -30.25287 + 7.173061(hours) – .1069887(hours<sup>2</sup>)
We can use this equation to find the predicted happiness of an individual, given the number of hours they work per week.
For example, an individual that works 60 hours per week is predicted to have a happiness level of 14.97:
predicted happiness  = -30.25287 + 7.173061(60) – .1069887(60<sup>2</sup>) = <b>14.97</b>.
Conversely, an individual that works 30 hours perk week is predicted to have a happiness level of 88.65:
predicted happiness  = -30.25287 + 7.173061(30) – .1069887(30<sup>2</sup>) = <b>88.65</b>.
<b>Step 3: Report the results.</b>
Lastly, we want to report the results of our quadratic regression. Here is an example of how to do so:
A quadratic regression was performed to quantify the relationship between the number of hours worked by an individual and their corresponding happiness level (measured from 0 to 100). A sample of 16 individuals was used in the analysis.
 
Results showed that there was a statistically significant relationship between the explanatory variables <em>hours </em>and <em>hours<sup>2 </sup></em>and the response variable <em>happiness</em> (F(2, 13) = 65.09, p &lt; 0.0001).
 
Combined, these two explanatory variables accounted for 90.92% of explained variability in happiness. 
 
The regression equation was found to be:
 
predicted happiness  = -30.25287 + 7.173061(hours) – .1069887(hours<sup>2</sup>)
<h2><span class="orange">How to Perform Quadratic Regression on a TI-84 Calculator</span></h2>
When two variables have a linear relationship, we can often use <b> simple linear regression </b> to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata1.png"(max-width: 442px) 100vw, 442px">
However, when two variables have a quadratic relationship, we can instead use <b>quadratic regression</b> to quantify their relationship.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quadRegStata2.png"(max-width: 441px) 100vw, 441px">
This tutorial explains how to perform quadratic regression on a TI-84 Calculator.
<h3>Example: Quadratic Regression on a TI-84 Calculator</h3>
Suppose we are interested in understanding the relationship between number of hours worked and happiness. We have the following data on the number of hours worked per week and the reported happiness level (on a scale of 0-100) for 11 different people:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI1.png">
Use the following steps to perform a quadratic regression on a TI-84 calculator.
<b>Step 1: Visualize the data.</b>
Before we can use quadratic regression, we need to make sure that the relationship between the explanatory variable (hours) and response variable (happiness) is actually quadratic.
First, we will input the data values for both the explanatory and the response variable. Press  Stat  and then press  EDIT . Enter the following values for the explanatory variable (hours worked) in column L1 and the values for the response variable (happiness) in column L2:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI2.png">
Next, press  2nd  and then press  y= to access the <b>statplot </b>menu. Highlight Plot1 and press  Enter. Make sure the plot is on and that L1 and L2 are selected for Xlist and Ylist, respectively:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI3.png">
Next,  press  zoom and then press 9:ZoomStat. This will automatically produce the following scatterplot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI5.png">
We can see that happiness tends to increase as number of hours worked increases from zero up to a certain point, but then begins to drop lower as the number of hours worked increases further.
This upside down “U” shape in the scatterplot indicates that there is a quadratic relationship between hours worked and happiness, which means we should use quadratic regression to quantify this relationship.
<b>Step 2: Perform quadratic regression.</b>
Next, we will perform quadratic regression. Press Stat and then scroll over to <b>CALC</b>. Then scroll down to <b>5: QuadReg</b> and press Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI6.png">
For Xlist and Ylist, make sure L1 and L2 are selected since these are the columns we used to input our data. Leave <b>FreqList </b>blank. Scroll down to <b>Calculate </b>and press Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI7.png">
The following output will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/quadTI8.png">
<b>Step 3: Interpret the output.</b>
From the results, we can see that the estimated regression equation is as follows:
<b>happiness = -0.1012(hours)<sup>2</sup> + 6.7444(hours) – 18.2536</b>
We can use this equation to find the predicted happiness of an individual, given the number of hours they work per week.
For example, an individual that works 60 hours per week is predicted to have a happiness level of <b>22.09</b>:
happiness = -0.1012(60)<sup>2</sup> + 6.7444(60) – 18.2536 = 22.09
Conversely, an individual that works 30 hours perk week is predicted to have a happiness level of <b>92.99</b>:
happiness = -0.1012(30)<sup>2</sup> + 6.7444(30) – 18.2536 = 92.99
We can also see that the r-squared for the regression model is r<sup>2</sup> = <b>0.9602</b>. This is the proportion of the variance in the response variable that can be explained by the explanatory variables. In this example, 96.02% of the variation in happiness can be explained by <em>hours </em>and <em>hours<sup>2</sup></em>.
<h2><span class="orange">How to Add a Quadratic Trendline in Excel (Step-by-Step)</span></h2>
If the relationship between two variables is quadratic, then you can use a quadratic trendline to capture their relationship in a plot.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend5.png">
This tutorial provides a step-by-step example of how to add a quadratic trendline to a scatterplot in Excel.
<h3>Step 1: Create the Data</h3>
First, let’s create some data to work with:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend1.png">
<h3>Step 2: Create a Scatterplot</h3>
Next, highlight cells <b>A2:B17</b>. Click the <b>Insert</b> tab along the top ribbon, then click the first chart option under <b>Insert Scatter</b> in the <b>Charts</b> group.
The following scatterplot will automatically be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend2.png">
<h3>Step 3: Add the Quadratic Trendline</h3>
Next, click the green plus “<b>+</b>” sign in the top right corner of the plot. Click the arrow to the right of <b>Trendline</b>, then click <b>More Options</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend3.png">
In the window that appears to the right, click <b>Polynomial</b> and select <b>2</b> for Order:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend4.png">
The following quadratic trendline will automatically be displayed on the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quadraticTrend5.png">
Feel free to click on the trendline itself to change the style or color.
<h2><span class="orange">Qualitative vs. Quantitative Variables: What’s the Difference?</span></h2>
In statistics, there are two types of variables:
<b>1.</b> <b>Quantitative Variables: </b>Sometimes referred to as “numeric” variables, these are variables that represent a measurable quantity. Examples include:
Number of students in a class
Number of square feet in a house
Population size of a city
Age of an individual
Height of an individual
<b>2. Qualitative Variables:</b> Sometimes referred to as “categorical” variables, these are variables that take on names or labels and can fit into categories. Examples include:
Eye color (e.g. “blue”, “green”, “brown”)
Gender (e.g. “male”, “female”)
Breed of dog (e.g. “lab”, “bulldog”, “poodle”)
Level of education (e.g. “high school”, “Associate’s degree”, “Bachelor’s degree”)
Marital status (e.g. “married”, “single”, “divorced”)
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/qual1.png">
Every single variable you will ever encounter in statistics can be classified as either quantitative or qualitative.
<h3>Example: Classifying Quantitative & Qualitative Variables</h3>
Consider the following dataset with information about 10 different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/qual2.png">
There are five total variables in this dataset. Two of them are qualitative variables and three of them are quantitative variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/qual3.png">
<h3>Summarizing Quantitative & Qualitative Variables</h3>
We can use many different metrics to summarize <b>quantitative variables</b>, including:
 Measures of central tendency  like the mean, median, and mode.
 Measures of dispersion  like the range, interquartile range, and standard deviation.
However, we can only use frequency tables and relative frequency tables to summarize <b>qualitative variables</b>.
To illustrate this, let’s once again consider the dataset from the previous example:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/qual3.png">
For the quantiative variable <em><b>Seasons Played</b></em>, we can calculate the following metrics:
<b>Mean: </b>11.5
<b>Median: </b>12
<b>Mode: </b>12
<b>Range: </b>8
<b>Interquartile Range: </b>4.5
<b>Standard Deviation: </b>2.915
These metrics give us a good idea of where the center value is located as well as how spread out the values are for this variable.
And for the qualitative variable <b><em>Position</em></b>, we can create a frequency table to describe how often different values occur:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/qual4.png">
This table lets us quickly see how frequently each position (G=guard, F=forward, C=center) occurred in the dataset.
<h2><span class="orange">How to Use the quantile() Function in R</span></h2>
In statistics, <b>quantiles</b> are values that divide a ranked dataset into equal groups.
The <b>quantile()</b> function in R can be used to calculate sample quantiles of a dataset.
This function uses the following basic syntax:
<b>quantile(x, probs = seq(0, 1, 0.25), na.rm = FALSE)</b>
where:
<b>x</b>: Name of vector
<b>probs</b>: Numeric vector of probabilities
<b>na.rm</b>: Whether to remove NA values
The following examples show how to use this function in practice.
<h3>Example 1: Calculate Quantiles of a Vector</h3>
The following code shows how to calculate quantiles of a vector in R:
<b>#define vector of data 
data = c(1, 3, 3, 4, 5, 7, 8, 9, 12, 13, 13, 15, 18, 20, 22, 23, 24, 28)
#calculate quartiles
quantile(data, probs = seq(0, 1, 1/4))
 0%  25%  50%  75% 100% 
1.0  5.5 12.5 19.5 28.0 
#calculate quintiles
quantile(data, probs = seq(0, 1, 1/5))
 0%  20%  40%  60%  80% 100% 
1.0  4.4  8.8 13.4 21.2 28.0 
#calculate deciles
quantile(data, probs = seq(0, 1, 1/10))
 0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
1.0  3.0  4.4  7.1  8.8 12.5 13.4 17.7 21.2 23.3 28.0 
#calculate random quantiles of interest
quantile(data, probs = c(.2, .5, .9))
20%  50%  90% 
4.4 12.5 23.3
</b>
<h3>Example 2: Calculate Quantiles of Columns in Data Frame</h3>
The following code shows how to calculate the quantiles of a specific column in a data frame:
<b>#create data frame
df &lt;- data.frame(var1=c(1, 3, 3, 4, 5, 7, 7, 8, 12, 14, 18), var2=c(7, 7, 8, 3, 2, 6, 8, 9, 11, 11, 16), var3=c(3, 3, 6, 6, 8, 4, 4, 7, 10, 10, 11))
#calculate quartiles of column 'var2'
quantile(df$var2, probs = seq(0, 1, 1/4))
  0%  25%  50%  75% 100% 
 2.0  6.5  8.0 10.0 16.0 </b>
We can also use the <b>sapply()</b> function to calculate the quantiles of multiple columns at once:
<b>#calculate quartiles of every column
sapply(df, function(x) quantile(x, probs = seq(0, 1, 1/4)))
     var1 var2 var3
0%    1.0  2.0    3
25%   3.5  6.5    4
50%   7.0  8.0    6
75%  10.0 10.0    9
100% 18.0 16.0   11
</b>
<h3>Example 3: Calculate Quantiles by Group</h3>
The following code shows how to use functions from the  dplyr  package to calculate quantiles by a grouping variable:
<b>library(dplyr)
#define data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C'), points=c(1, 3, 3, 4, 5, 7, 7, 8, 12, 14, 18))
#define quantiles of interest
q = c(.25, .5, .75)
#calculate quantiles by grouping variable
df %>%
  group_by(team) %>%
  summarize(quant25 = quantile(points, probs = q[1]), 
            quant50 = quantile(points, probs = q[2]),
            quant75 = quantile(points, probs = q[3]))
# A tibble: 3 x 4
  team  quant25 quant50 quant75
           
1 A         2.5       3    3.25
2 B         6.5       7    7.25
3 C          13      14      16   
</b>
<h2><span class="orange">How to Perform Quantile Normalization in R</span></h2>
In statistics,  quantile normalization  is a method that makes two distributions identical in statistical properties.
The following example shows how to perform quantile normalization in R.
<h3>Example: Quantile Normalization in R</h3>
Suppose we create the following data frame in R that contains two columns:
<b>#make this example reproducible
set.seed(0)
#create data frame with two columns
df &lt;- data.frame(x=rnorm(1000), y=rnorm(1000))
#view first six rows of data frame
head(df)
           x           y
1  1.2629543 -0.28685156
2 -0.3262334  1.84110689
3  1.3297993 -0.15676431
4  1.2724293 -1.38980264
5  0.4146414 -1.47310399
6 -1.5399500 -0.06951893</b>
We can use the  sapply()  and  quantile()  functions to calculate the quantiles for both x and y:
<b>#calculate quantiles for x and y
sapply(df, function(x) quantile(x, probs = seq(0, 1, 1/4)))
               x           y
0%   -3.23638573 -3.04536393
25%  -0.70845589 -0.73331907
50%  -0.05887078 -0.03181533
75%   0.68763873  0.71755969
100%  3.26641452  3.03903341
</b>
Notice that x and y have similar values for the quantiles, but not identical values.
For example, the value at the 25th percentile for x is <b>-0.708</b> and the value at the 25th percentile for y is <b>-0.7333</b>.
To perform quantile normalization, we can use the<b> normalize.quantiles()</b> function from the  preprocessCore  package in R:
<b>library(preprocessCore)
#perform quantile normalization
df_norm &lt;- as.data.frame(normalize.quantiles(as.matrix(df)))
#rename data frame columns
names(df_norm) &lt;- c('x', 'y')
#view first six row of new data frame
head(df_norm)
           x           y
1  1.2632137 -0.28520228
2 -0.3469744  1.82440519
3  1.3465807 -0.16471644
4  1.2692599 -1.34472394
5  0.4161133 -1.43717759
6 -1.6269731 -0.07906793
</b>
We can then use the following code to calculate the quantiles for both x and y again:
<b>#calculate quantiles for x and y
sapply(df_norm, function(x) quantile(x, probs = seq(0, 1, 1/4)))
               x           y
0%   -3.14087483 -3.14087483
25%  -0.72088748 -0.72088748
50%  -0.04534305 -0.04534305
75%   0.70259921  0.70259921
100%  3.15272396  3.15272396
</b>
Notice that the quantiles are identical for x and y now.
We would say that x and y have been quantile normalized. That is, the two distributions are now identical in statistical properties.
<h2><span class="orange">How to Perform Quantile Regression in Python</span></h2>
Linear regression is a method we can use to understand the relationship between one or more predictor variables and a  response variable .
Typically when we perform linear regression, we’re interested in estimating the mean value of the response variable.
However, we could instead use a method known as <b>quantile regression</b> to estimate <em>any</em> quantile or percentile value of the response value such as the 70th percentile, 90th percentile, 98th percentile, etc.
This tutorial provides a step-by-step example of how to use this function to perform quantile regression in Python.
<h3>Step 1: Load the Necessary Packages</h3>
First, we’ll load the necessary packages and functions:
<b>import numpy as np
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt
</b>
<h3>Step 2: Create the Data</h3>
For this example we’ll create a dataset that contains the hours studied and the exam score received for 100 students at some university:
<b>#make this example reproducible
np.random.seed(0)
#create dataset
obs = 100
hours = np.random.uniform(1, 10, obs)
score = 60 + 2*hours + np.random.normal(loc=0, scale=.45*hours, size=100)
df = pd.DataFrame({'hours': hours, 'score': score})
#view first five rows
df.head()
hoursscore
05.93932268.764553
17.43670477.888040
26.42487074.196060
35.90394967.726441
44.81289372.849046</b>
<h3>Step 3: Perform Quantile Regression</h3>
Next, we’ll fit a quantile regression model using hours studied as the predictor variable and exam score as the response variable.
We’ll use the model to predict the expected 90th percentile of exam scores based on the number of hours studied:
<b>#fit the model
model = smf.quantreg('score ~ hours', df).fit(q=0.9)
#view model summary
print(model.summary())
         QuantReg Regression Results                          
==============================================================================
Dep. Variable:                  score   Pseudo R-squared:               0.6057
Model:                       QuantReg   Bandwidth:                       3.822
Method:                 Least Squares   Sparsity:                        10.85
Date:                Tue, 29 Dec 2020   No. Observations:                  100
Time:                        15:41:44   Df Residuals:                       98                        Df Model:                            1
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     59.6104      0.748     79.702      0.000      58.126      61.095
hours          2.8495      0.128     22.303      0.000       2.596       3.103
==============================================================================</b>
From the output, we can see the estimated regression equation:
90th percentile of exam score = 59.6104 + 2.8495*(hours)
For example, the 90th percentile of scores for all students who study 8 hours is expected to be 82.4:
90th percentile of exam score = 59.6104 + 2.8495*(8) = <b>82.4</b>.
The output also displays the upper and lower confidence limits for the intercept and the predictor variable hours.
<h3>Step 4: Visualize the Results</h3>
We can also visualize the results of the regression by creating a  scatterplot  with the fitted quantile regression equation overlaid on the plot:
<b>#define figure and axis
fig, ax = plt.subplots(figsize=(8, 6))
#get y values
get_y = lambda a, b: a + b * hours
y = get_y(model.params['Intercept'], model.params['hours'])
#plot data points with quantile regression equation overlaid
ax.plot(hours, y, color='black')
ax.scatter(hours, score, alpha=.3)
ax.set_xlabel('Hours Studied', fontsize=14)
ax.set_ylabel('Exam Score', fontsize=14)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/quantRegPython1.png">
Unlike a simple linear regression line, notice that this fitted line doesn’t represent the “line of best fit” for the data. Instead, it goes through the estimated 90th percentile at each level of the predictor variable.
<h2><span class="orange">How to Perform Quantile Regression in R</span></h2>
Linear regression is a method we can use to understand the relationship between one or more predictor variables and a  response variable .
Typically when we perform linear regression, we’re interested in estimating the mean value of the response variable.
However, we could instead use a method known as <b>quantile regression</b> to estimate <em>any</em> quantile or percentile value of the response value such as the 70th percentile, 90th percentile, 98th percentile, etc.
To perform quantile regression in R we can use the <b>rq()</b> function from the  quantreg  package, which uses the following syntax:
<b>library(quantreg)
model &lt;- rq(y ~ x, data = dataset, tau = 0.5)
</b>
where:
<b>y:</b> The response variable
<b>x:</b> The predictor variable(s)
<b>data:</b> The name of the dataset
<b>tau:</b> The percentile to find. The default is the median (tau = 0.5) but you can set this to any number between 0 and 1.
This tutorial provides a step-by-step example of how to use this function to perform quantile regression in R.
<h2>Step 1: Enter the Data</h2>
For this example we’ll create a dataset that contains the hours studied and the exam score received for 100 different students at some university:
<b>#make this example reproducible
set.seed(0)
#create data frame 
hours &lt;- runif(100, 1, 10)
score &lt;- 60 + 2*hours + rnorm(100, mean=0, sd=.45*hours)
df &lt;- data.frame(hours, score)
#view first six rows
head(df)
     hours    score
1 9.070275 79.22682
2 3.389578 66.20457
3 4.349115 73.47623
4 6.155680 70.10823
5 9.173870 78.12119
6 2.815137 65.94716
</b>
<h2>Step 2: Perform Quantile Regression</h2>
Next, we’ll fit a quantile regression model using hours studied as the predictor variable and exam score as the response variable.
We’ll use the model to predict the expected 90th percentile of exam scores based on the number of hours studied:
<b>library(quantreg)
#fit model
model &lt;- rq(score ~ hours, data = df, tau = 0.9)
#view summary of model
summary(model)
Call: rq(formula = score ~ hours, tau = 0.9, data = df)
tau: [1] 0.9
Coefficients:
            coefficients lower bd upper bd
(Intercept) 60.25185     59.27193 62.56459
hours        2.43746      1.98094  2.76989
</b>
From the output, we can see the estimated regression equation:
90th percentile of exam score = 60.25 + 2.437*(hours)
For example, the 90th percentile of scores for all students who study 8 hours is expected to be 79.75:
90th percentile of exam score = 60.25 + 2.437*(8) = <b>79.75</b>.
The output also displays the upper and lower confidence limits for the intercept and the predictor variable hours.
<h2>Step 3: Visualize the Results</h2>
We can also visualize the results of the regression by creating a  scatterplot  with the fitted quantile regression equation overlaid on the plot:
<b>library(ggplot2)
#create scatterplot with quantile regression line
ggplot(df, aes(hours,score)) +
  geom_point() + 
  geom_abline(intercept=coef(model)[1], slope=coef(model)[2])</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/quantileRegR1.png">
Unlike a traditional linear regression line, notice that this fitted line doesn’t go through the heart of the data. Instead, it goes through the estimated 90th percentile at each level of the predictor variable.
We can view the difference between the fitted quantile regression equation and the simple linear regression equation by adding the <b>geom_smooth()</b> argument:
<b>library(ggplot2)
#create scatterplot with quantile regression line <em>and</em> simple linear regression line
ggplot(df, aes(hours,score)) +
  geom_point() + 
  geom_abline(intercept=coef(model)[1], slope=coef(model)[2]) +
  geom_smooth(method="lm", se=F)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/quantileRegR2.png">
The black line displays the fitted quantile regression line for the 90th percentile and the blue line displays the simple linear regression line, which estimates the mean value for the response variable.
As expected, the simple linear regression line goes straight through the data and shows us the mean estimated value of exam scores at each level of hours. 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Perform Simple Linear Regression in R 
 How to Perform Multiple Linear Regression in R 
 How to Perform Quadratic Regression in R 
<h2><span class="orange">How to Perform Quantile Regression in SAS</span></h2>
Linear regression is a method we can use to understand the relationship between one or more predictor variables and a  response variable .
Typically when we perform linear regression, we’re interested in estimating the mean value of the response variable.
However, we could instead use a method known as <b>quantile regression</b> to estimate <em>any</em> percentile value of the response value such as the 30th percentile, 90th percentile, 98th percentile, etc.
To perform quantile regression in SAS we can use the <b>proc quantreg</b> statement.
The following example shows how to perform quantile regression in SAS in practice.
<h2>Example: Performing Quantile Regression in SAS</h2>
Suppose we have the following dataset in SAS that shows the number of hours studied and corresponding exam score for students in some class:
<b>/*create dataset*/
data original_data;
    input hours score;
    datalines;
1 75
1 79
2 78
2 83
2 85
3 84
3 84
3 89
4 93
4 88
4 79
4 94
5 96
5 98
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/quant1.jpg"169">
Next, we’ll fit a quantile regression model using hours studied as the predictor variable and exam score as the response variable.
We’ll use the model to predict the expected 90th percentile of exam scores based on the number of hours studied:
<b>/*perform quantile regression*/
proc quantreg data=original_data;
    model score = hours / quantile = 0.9;
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/quant2.jpg">
From the output, we can see the estimated regression equation:
90th percentile of exam score = 76 + 4.5(hours)
For example, the 90th percentile of scores for all students who study 2 hours is expected to be 85:
90th percentile of exam score = 76 + 4.5*(2) = <b>85</b>.
The output also displays a scatter plot of the raw data with the fitted regression line overlaid on the plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/quant3.jpg"583">
Unlike a typical regression model, the fitted line for this regression model goes through the 90th percentile of each value of the predictor variable instead of the mean value.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Perform Simple Linear Regression in R 
 How to Perform Multiple Linear Regression in R 
 How to Perform Quadratic Regression in R 
<h2><span class="orange">How to Perform Quantile Regression in Stata</span></h2>
<b>Linear regression</b> is a method we can use to understand the relationship between one or more explanatory variables and a response variable.
Typically when we perform linear regression, we’re interested in estimating the mean value of the response variable based on the value of the explanatory variable. But we could instead estimate the median, or the 0.25 percentile, or the 0.90 percentile, or any percentile we’d like.
This is where <b>quantile regression</b> comes into play. Similar to ordinary linear regression, quantile regression creates a regression equation that predicts some value (e.g. the median, 0.25 percentile, 0.90 percentile, etc.) for a response variable based on the value of the explanatory variable.
This tutorial explains how to perform quantile regression in Stata.
<h2>Example: Quantile Regression in Stata</h2>
For this example we will use the built-in Stata dataset called <em>auto</em>. First we’ll fit a linear regression model using weight as a predictor variable and mpg as a response variable. This will tell us the expected <em>average </em>mpg of a car, based on its weight. Then we’ll fit a quantile regression model to predict the 0.90 percentile of mpg of a car, based on its weight.
<b>Step 1: Load and view the data.</b>
Use the following command to load the data:
<b>sysuse auto</b>
Use the following command to get a summary of the variables mpg and weight:
<b>summarize mpg weight</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quantileRegressionStata1.png">
<b>Step 2: Perform a simple linear regression.</b>
Use the following command to perform simple linear regression, using weight as the explanatory variable and mpg as the response variable:
<b>regress mpg weight</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/simpleRegressionStata3.png"(max-width: 605px) 100vw, 605px">
From the output table we can see that the estimated regression equation is:
predicted mpg = 39.44028 – 0.0060087*(weight)
We can use this equation to find the estimated <i>average </i>mpg for a car, given its weight. For example, a car that weighs 4,000 pounds is estimated to have mpg of 15.405:
predicted mpg = 39.44028 – 0.0060087*(4000) = <b>15.405</b>
<b>Step 3: Perform quantile regression.</b>
Next, let’s perform quantile regression to get the estimated 90<sup>th</sup> percentile of a car’s mpg, based on its weight.
Use the <b>qreg </b>command along with <b>quantile(0.90) </b>to perform this quantile regression:
<b>qreg mpg weight, quantile(0.90)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quantileRegressionStata2.png">
From the output table we can see that the estimated regression equation is:
predicted 90<sup>th</sup> percentile of mpg = 47.02632 – 0.0072368*(weight)
We can use this equation to find the estimated<i> </i>mpg for a car in the 90<sup>th</sup> percentile, given its weight. For example, the 90<sup>th</sup> percentile of mpg for a car that weighs 4,000 pounds is estimated to be 18.709:
predicted 90<sup>th</sup> percentile of mpg = 47.02632 – 0.0072368*(4000) = <b>18.079</b>
Recall that our previous linear regression model told us that a car that weighs 4,000 pounds has an estimated <em>average </em>mpg of 15.405. Thus, it makes sense that this quantile regression model tells us that a car that weighs 4,000 pounds would need an mpg of <b>18.079 </b>to be in the 90<sup>th</sup> percentile of all cars with that particular weight.
<h3>Multiple Quantile Regressions at Once in Stata</h3>
It’s also possible to perform multiple quantile regressions at once in Stata. For example, suppose we are interested in estimating the 25<sup>th</sup> percentile, the median (e.g. 50<sup>th</sup> percentile), and the 90<sup>th</sup> percentile all at once.
To do so, we can use the <b>sqreg </b>command along with the <b>q() </b>command to specify which quantiles to estimate:
<b>sqreg mpg weight, q(0.25, 0.50, 0.90)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/quantileRegressionStata3.png">
Using this output, we can construct the estimated regression equations for each quantile regression:
<b>(1) </b>predicted 25<sup>th</sup> percentile of mpg = 35.22414 – 0.0051724*(weight)
<b>(2) </b>predicted 50<sup>th</sup> percentile of mpg = 36.94667 – 0.0053333*(weight)
<b>(3) </b>predicted 90<sup>th</sup> percentile of mpg = 47.02632 – 0.0072368*(weight)
<h2><span class="orange">QUARTILE.EXC vs. QUARTILE.INC in Excel: What’s the Difference?</span></h2>
<b>Quartiles</b> are values that split up a dataset into four equal parts.
There are three different functions you can use to calculate quartiles in Excel:
<b>1. QUARTILE.EXC:</b> This function uses the following process to calculate the quartiles of a dataset:
Use the median to separate the dataset into two halves.
Calculate Q1 as the median value in the lower half and Q3 as the median value in the upper half. Be sure to <b>exclude</b> the median of the dataset when calculating Q1 and Q3.
<b>2. QUARTILE.INC:</b> This function uses the following process to calculate the quartiles of a dataset:
Use the median to separate the dataset into two halves.
Calculate Q1 as the median value in the lower half and Q3 as the median value in the upper half. Be sure to <b>include </b>the median of the dataset when calculating Q1 and Q3.
<b>3. QUARTILE:</b> This function calculates the quartiles of a dataset as well. It will return the exact same value as the <b>QUARTILE.INC</b> function.
For example, suppose we have the following dataset:
Dataset: 4, 6, 6, 7, 8, 12, 15, 17, 20, 21, 21, 23, 24, 27, 28
The <b>QUARTILE.EXC</b> function will use the median to separate the dataset into two halves and calculate Q1 and Q3 as 7 and 23, respectively:
Q1: Median of 4, 6, 6, 7, 8, 12, 15 =<b> 7</b>
Q3: Median of 20, 21, 21, 23, 24, 27, 28 = <b>23</b>
The <b>QUARTILE.INC</b> function will use the median to separate the dataset into two halves and calculate Q1 and Q3 as 7.5 and 22, respectively:
Q1: Median of 4, 6, 6, 7, 8, 12, 15, 17 =<b> 7.5</b>
Q3: Median of 17, 20, 21, 21, 23, 24, 27, 28 = <b>22</b>
The following example shows how to use the various QUARTILE functions in Excel.
<h3>Example: QUARTILE.EXC vs. QUARTILE.INC in Excel</h3>
Suppose we have the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quartileExcel1.png">
The following screenshot shows how to calculate the quartiles for the dataset using the three different quartile formulas:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/quartileExcel2.png">
Using the <b>QUARTILE</b> or <b>QUARTILE.INC</b> functions, we calculate the lower and upper quartiles as:
<b>Q1</b>: 7.5
<b>Q3</b>: 22
Conversely, using the <b>QUARTILE.EXC</b> function we calculate the lower and upper quartiles as:
<b>Q1</b>: 7
<b>Q3</b>: 23
<h3>When to Use QUARTILE.EXC vs. QUARTILE.INC</h3>
There is no universally “correct” way to calculate the quartiles in a dataset.
In fact, different statistical softwares use different default formulas to calculate quartiles.
The R programming language uses a formula that matches the <b>QUARTILE.INC</b> function in Excel.
 How to Calculate Interquartile Range in R 
The Python programming language uses a formula that matches the <b>QUARTILE.INC</b> function in Excel.
 How to Calculate Interquartile Range in Python 
TI-84 calculators use a formula that matches the <b>QUARTILE.EXC</b> function in Excel.
 How to Calculate Interquartile Range on a TI-84 Calculator 
Fortunately, no matter which function you use to calculate quartiles the difference between the values calculated by <b>QUARTILE.INC</b> and <b>QUARTILE.EXC</b> will be very similar in most cases.
In some cases, it’s even possible that the two functions will return the same values depending on the sequence of numbers in the dataset.
<h2><span class="orange">How to Calculate Quartiles for Grouped Data</span></h2>
<b>Quartiles</b> are values that split up a dataset into four equal parts.
You can use the following formula to calculate quartiles for grouped data:
<b>Q<sub>i</sub> = L + (C/F) * (iN/4 – M)</b>
where:
<b>L</b>: The lower bound of the interval that contains the i<sup>th</sup> quartile
<b>C</b>: The class width
<b>F</b>: The frequency of the interval that contains the i<sup>th</sup> quartile
<b>N</b>: The total frequency
<b>M</b>: The cumulative frequency leading up to the interval that contains the i<sup>th</sup> quartile
The following example shows how to use this formula in practice.
<h2>Example: Calculate Quartiles for Grouped Data</h2>
Suppose we have the following frequency distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/percentGrouped1.jpg"478">
Now suppose we’d like to calculate the value at the third quartile (Q<sub>3</sub>) of this distribution.
The value at the third quartile will be located at position (iN/4) in the distribution.
Thus, (iN/4) = (3*92/4) = 69.
The interval that contains the third quartile will be the <b>21-25</b> interval since 69 is between the cumulative frequencies of 58 and 70.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/qgroup1.jpg"652">
Knowing this, we can find each of the values necessary to plug into our formula:
<b>L</b>: The lower bound of the interval that contains the i<sup>th</sup> quartile
The lower bound of the interval is <b>21</b>.
<b>C</b>: The class width
The class width is calculated as 25 – 21 = <b>4</b>.
<b>F</b>: The frequency of the interval that contains the i<sup>th</sup> quartile
The frequency of the 21-25 class is <b>12</b>
<b>N</b>: The total frequency
The total cumulative frequency in the table is <b>92</b>.
<b>M</b>: The cumulative frequency leading up to the interval that contains the i<sup>th</sup> quartile
The cumulative frequency leading up to the 21-25 class is <b>58</b>.
We can then plug in all of these values into the formula from earlier to find the value at the third quartile:
Q<sub>i</sub> = L + (C/F) * (iN/4 – M)
Q<sub>3</sub> = 21 + (4/12) * ((3)(92)/4 – 58)
Q<sub>3</sub> = 24.67
The value at the third quartile is <b>24.67</b>.
You can use a similar approach to calculate the values for the first and second quartiles.
<h2>Additional Resources</h2>
The following tutorials provide additional information for working with grouped data:
 How to Find Mean & Standard Deviation of Grouped Data 
 How to Find the Mode of Grouped Data 
 How to Find the Median of Grouped Data 
 Grouped vs. Ungrouped Frequency Distributions 
<h2><span class="orange">How to Find and Visualize Quartiles in R</span></h2>
<b>Quartiles</b> are values that split up a dataset into four equal parts.
The <b>first quartile </b>represents the 25th percentile of a dataset.
The <b>second quartile </b>represents the 50th percentile of a dataset. This value is equivalent to the  median value  of the dataset.
The <b>third quartile </b>represents the 75th percentile of a dataset.
We can easily calculate the quartiles of a given dataset in R by using the <b>quantile()</b> function.
This tutorial provides examples of how to use this function in practice.
<h2>Calculating Quartiles in R</h2>
The following code shows how to calculate the quartiles of a given dataset in R:
<b>#define dataset
data = c(4, 7, 12, 13, 14, 15, 15, 16, 19, 23, 24, 25, 27, 28, 33)
#calculate quartiles of dataset
quantile(data)
  0%  25%  50%  75% 100% 
 4.0 13.5 16.0 24.5 33.0 
</b>
Here’s how to interpret the output:
The first value displays the minimum value in the dataset: <b>4.0</b>
The second value displays the first quartile of the dataset: <b>13.5</b>
The third value displays the second quartile of the dataset: <b>16.0</b>
The fourth value displays the third quartile of the dataset: <b>24.5</b>
The fifth value displays the maximum value in the dataset: <b>33.0</b>
<b>Related: </b> How to Easily Calculate Percentiles in R 
<h2>Visualizing Quartiles in R</h2>
We can use the <b>boxplot()</b> function to create a boxplot to visualize the quartiles of this dataset in R:
<b>#create boxplot 
boxplot(data)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/boxR1.png">
Here’s how to interpret the boxplot:
The bottom “whisker” displays the minimum value of <b>4</b>.
The bottom line of the box displays the first quartile value of <b>13.5</b>.
The black bar in the middle of the box displays the second quartile value of <b>16.0</b>.
The top line of the box displays the third quartile value of <b>24.5</b>.
The top “whisker” displays the maximum value of <b>33.0</b>.
This single plot helps us quickly visualize the distribution of values in the dataset.
<b>Related:</b>  How to Plot Multiple Boxplots in One Chart in R 
<h2><span class="orange">Quick Normal CDF Calculator</span></h2>
This calculator finds the area under the normal distribution curve for a specified upper and lower bound.
<label for="mean"><b>μ</b> (population mean)</label>
<input type="number" id="mean" value="0">
<label for="sd"><b>σ</b> (population standard deviation)</label>
<input type="number" id="sd" value="1">
<label for="z"><b>lower bound</b></label>
<input type="number" id="lower" value="-1">
<label for="z"><b>upper bound</b></label>
<input type="number" id="upper" value="1.2">
<input type="button" id="button" onclick="calc()" value="Calculate">
<div>
Area (probability) = <b>0.7263</b>
<script>
function calc() {
//get input values
var mean = document.getElementById('mean').value;
var sd = document.getElementById('sd').value;
var lower = document.getElementById('lower').value;
var upper = document.getElementById('upper').value;
//calculate area
var area = jStat.normal.cdf(upper, mean, sd)-jStat.normal.cdf(lower, mean, sd);
//output probabilities
document.getElementById('area').innerHTML = area.toFixed(4);
}
</script>
<h2><span class="orange">How to Calculate Quintiles in Excel (With Examples)</span></h2>
In statistics, <b>quintiles</b> are numbers that split a dataset into five groups of equal frequency.
The first quintile is the point where 20% of all data values lie below it. The second quintile is the point where 40% of all data values lie below it, and so forth.
We can use the following function to calculate the quintiles for a dataset in Excel:
<b>=PERCENTILE(CELL RANGE, QUINTILE)
</b>
The following example shows how to use this function in practice.
<h3>Example: Calculate Quintiles in Excel</h3>
Suppose we have the following dataset with 20 values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/quintileExcel1.png">
The following image shows how to calculate the quintiles for the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/quintileExcel2.png">
The way to interpret the quintiles is as follows:
20% of all data values lie below <b>6.8</b>.
40% of all data values lie below <b>14</b>.
60% of all data values lie below <b>20.8</b>.
80% of all data values lie below <b>26.2</b>.
We can also use the following formula to calculate each quintile at the same time:
<b>=PERCENTILE(CELL RANGE, {0.2, 0.4, 0.6, 0.8})
</b>
The following image shows how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/quintileExcel3.png">
Notice that the quintiles calculated here match the quintiles we calculated earlier.
<h2><span class="orange">How to Calculate Quintiles in Google Sheets</span></h2>
In statistics, <b>quintiles</b> are numbers that split a dataset into five groups of equal frequency.
The first quintile is the point where 20% of all data values lie below it.
The second quintile is the point where 40% of all data values lie below it.
The third quintile is the point where 60% of all data values lie below it.
The fourth quintile is the point where 80% of all data values lie below it.
We can use the following basic formula to calculate the quintiles for a dataset in Google Sheets:
<b>=PERCENTILE(CELL RANGE, QUINTILE)
</b>
For example, we can use the following formula to calculate the first quantile in the range <b>A1:A10</b>:
<b>=PERCENTILE(A1:A10, 0.2)</b>
The following example shows how to use this function in practice.
<h3>Example: Calculate Quintiles in Google Sheets</h3>
Suppose we have the following dataset in Google Sheets with 20 values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/quintile1.jpg"538">
The following screenshot shows how to calculate the quintiles for the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/quintile2.jpg">
Here is how to interpret the quintile values:
20% of all data values lie below <b>6.8</b>.
40% of all data values lie below <b>14</b>.
60% of all data values lie below <b>20.8</b>.
80% of all data values lie below <b>26.2</b>.
We can also use the following formula to calculate each quintile at the same time:
<b>=ArrayFormula(PERCENTILE($A$2:$A$21, {0.2, 0.4, 0.6, 0.8}))
</b>
The following image shows how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/quintile3.jpg"624">
Notice that these quintile values match the ones we calculated earlier.
<h2><span class="orange">What is Quota Sampling? (Definition & Example)</span></h2>
<b>Quota sampling</b> is a  non-probability sampling method  that uses the following steps to obtain a sample from a  population :
<b>Step 1</b>: Divide a population into mutually exclusive groups based on some characteristic.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota1.png">
<b>Step 2:</b> Determine a proportion of each group to include in the sample.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota2.png">
<b>Step 3:</b> Survey individuals from each group that are convenient to reach.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota3.png">
The following example provides a scenario where quota sampling may be used in the real world.
<h3>Example: Quota Sampling</h3>
Suppose a tech company wants to know the opinion of customers about a new product. They decide to collect data from 1,000 customers from the following age groups in the corresponding proportions:
Age 18 – 30: 40%
Age 31 – 50: 40%
Age 51-70: 20%
They can use the following steps to perform quota sampling:
<b>Step 1</b>: Divide the entire population of customers into three age brackets.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota4.png">
<b>Step 2:</b> Determine the number of individuals to include from each age group.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota5.png">
<b>Step 3:</b> Survey individuals from each group that are convenient to reach.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/quota6.png">
<h3>Quota Sampling vs. Stratified Sampling</h3>
Quota sampling and stratified sampling are similar because they both split a population into groups or <em>stratum</em>.
However, stratified sampling performs simple random sampling to select individuals to survey in each group while quota sampling uses convenience sampling to select individuals to survey in each group.
In technical terms, stratified sampling is a <b>probability sampling method</b> because each individual in the population has an equal chance of being included in the sample.
However, quota sampling is a <b>non-probability sampling method</b> because not every individual in the population has an equal chance of being included in the sample.
In this regard, stratified sampling has a higher likelihood of producing a representative sample but it tends to be more time-intensive and costly.
<h3>Pros & Cons of Quota Sampling</h3>
Quota sampling offers the following <b>pros</b>:
It offers a more convenient way to gather data compared to other probability sampling methods since researchers can simply collect data on individuals that are convenient to reach.
It offers a cheaper way to gather data compared to other probability sampling methods since researchers can spend less time and money on traveling to reach individuals.
However, quota sampling comes with the following <b>con</b>:
It is not guaranteed to produce a  representative sample  since not every member of the population has an equal chance of being included in the sample. This means it may not be valid to generalize the findings from our sample to the overall population.
<h3>When to Use Quota Sampling</h3>
In practice, quota sampling is used most often when a research budget is limited or when data needs to be collected very quickly.
Since quota sampling allows researchers to survey individuals who are convenient to reach, only a minimal research budget is needed and data can often be gathered quickly using this method.
<h2><span class="orange">How to Add a Column to a Data Frame in R (With Examples)</span></h2>
There are three common ways to add a new column to a data frame in R:
<b>1. Use the $ Operator</b>
<b>df$new &lt;- c(3, 3, 6, 7, 8, 12)
</b>
<b>2. Use Brackets</b>
<b>df['new'] &lt;- c(3, 3, 6, 7, 8, 12)</b>
<b>3. Use Cbind</b>
<b>df_new &lt;- cbind(df, new)</b>
This tutorial provides examples of how to use each of these methods in practice using the following data frame:
<b>#create data frame
df &lt;- data.frame(a = c('A', 'B', 'C', 'D', 'E'), b = c(45, 56, 54, 57, 59))
#view data frame
df
  a  b
1 A 45
2 B 56
3 C 54
4 D 57
5 E 59</b>
<h3>Example 1: Use the $ Operator</h3>
The following code shows how to add a column to a data frame by using the $ operator:
<b>#define new column to add
new &lt;- c(3, 3, 6, 7, 8)
#add column called 'new'
df$new &lt;- new
#view new data frame
df 
  a  b new
1 A 45   3
2 B 56   3
3 C 54   6
4 D 57   7
5 E 59   8
</b>
<h3>Example 2: Use Brackets</h3>
The following code shows how to add a column to a data frame by using brackets:
<b>#define new column to add
new &lt;- c(3, 3, 6, 7, 8)
#add column called 'new'
df['new'] &lt;- new
#view new data frame
df 
  a  b new
1 A 45   3
2 B 56   3
3 C 54   6
4 D 57   7
5 E 59   8
</b>
<h3>Example 3: Use Cbind</h3>
The following code shows how to add a column to a data frame by using the  cbind  function, which is short for <em>column-bind</em>:
<b>#define new column to add
new &lt;- c(3, 3, 6, 7, 8)
#add column called 'new'
df_new &lt;- cbind(df, new)
#view new data frame
df_new
  a  b new
1 A 45   3
2 B 56   3
3 C 54   6
4 D 57   7
5 E 59   8
</b>
You can actually use the cbind function to add multiple new columns at once:
<b>#define new columns to add
new1 &lt;- c(3, 3, 6, 7, 8)
new2 &lt;- c(13, 14, 16, 17, 20) 
#add columns called 'new1' and 'new2'
df_new &lt;- cbind(df, new1, new2)
#view new data frame
df_new
  a  b new1 new2
1 A 45    3   13
2 B 56    3   14
3 C 54    6   16
4 D 57    7   17
5 E 59    8   20
</b>
<h3>Bonus: Set Column Names</h3>
After adding one or more columns to a data frame, you can use the <b>colnames()</b> function to specify the column names of the new data frame:
<b>#create data frame
df &lt;- data.frame(a = c('A', 'B', 'C', 'D', 'E'), b = c(45, 56, 54, 57, 59), new1 = c(3, 3, 6, 7, 8), new2 = c(13, 14, 16, 17, 20))
#view data frame
df
  a  b new1 new2
1 A 45    3   13
2 B 56    3   14
3 C 54    6   16
4 D 57    7   17
5 E 59    8   20
#specify column names
colnames(df) &lt;- c('a', 'b', 'c', 'd')
#view data frame
df
  a  b c  d
1 A 45 3 13
2 B 56 3 14
3 C 54 6 16
4 D 57 7 17
5 E 59 8 20
</b>
You can find more R tutorials  here .
<h2><span class="orange">How to Add Column If It Does Not Exist in R</span></h2>
You can use the following custom function to add one or more columns to a data frame in R if they do not already exist:
<b>add_cols &lt;- function(df, cols) {
  add &lt;- cols[!cols %in% names(df)]
  if(length(add) != 0) df[add] &lt;- NA
  return(df)
}
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Add Column If It Does Not Exist in R</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B'), position=c('Gu', 'Fo', 'Fo', 'Fo', 'Gu', 'Gu', 'Fo'), points=c(18, 22, 19, 14, 14, 11, 20))
#view data frame
df
  team position points
1    A       Gu     18
2    A       Fo     22
3    A       Fo     19
4    A       Fo     14
5    B       Gu     14
6    B       Gu     11
7    B       Fo     20</b>
Suppose we would like to add the following columns to the data frame if they do not already exist:
points
assists
rebounds
We can use a custom function called <b>add_cols</b> to do so:
<b>#define custom function to add columns to data frame if they do not exist
add_cols &lt;- function(df, cols) {
  add &lt;- cols[!cols %in% names(df)]
  if(length(add) !=0 ) df[add] &lt;- NA
  return(df)
}
#add three columns if they don't already exist
df &lt;- add_cols(df, c('points', 'assists', 'rebounds'))
#view updated data frame
df
  team position points assists rebounds
1    A       Gu     18      NA       NA
2    A       Fo     22      NA       NA
3    A       Fo     19      NA       NA
4    A       Fo     14      NA       NA
5    B       Gu     14      NA       NA
6    B       Gu     11      NA       NA
7    B       Fo     20      NA       NA
</b>
Notice that the <b>assists</b> and <b>rebounds</b> columns were added to the data frame while the <b>points</b> column was not since it already existed.
Also note that R simply fills in each value in the new columns with NA values.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Add Column to Data Frame Based on Other Columns in R 
 How to Add an Index (numeric ID) Column to a Data Frame in R 
 How to Add an Empty Column to a Data Frame in R 
<h2><span class="orange">R: How to Add Column to Data Frame Based on Other Columns</span></h2>
You can use the following basic syntax to add a column to a data frame in R based on the values in other columns:
<b>#add new column 'col3' with values based on columns 1 and 2
df$col3 &lt;- with(df, ifelse(col1 > col2, value_if_true, value_if_false))
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Add Character Column Based on Other Columns</h3>
The following code shows how to add a new character column based on the values in other columns of the data frame:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Cavs', 'Spurs', 'Nets'), scored=c(99, 90, 84, 96), allowed=c(95, 80, 87, 95))
#view data frame
df
   team scored allowed
1  Mavs     99      95
2  Cavs     90      80
3 Spurs     84      87
4  Nets     96      95
#add 'result' column based on values in 'scored' and 'allowed' columns
df$result &lt;- with(df, ifelse(scored > allowed, 'Win', 'Loss'))
#view updated data frame
df
   team scored allowed result
1  Mavs     99      95    Win
2  Cavs     90      80    Win
3 Spurs     84      87   Loss
4  Nets     96      95    Win
</b>
And the following code shows how to add a new character column that combines two <b>ifelse()</b> functions to produce three potential values in a new column:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Cavs', 'Spurs', 'Nets'), scored=c(99, 90, 84, 96), allowed=c(95, 80, 87, 95))
#view data frame
df
   team scored allowed
1  Mavs     99      95
2  Cavs     90      80
3 Spurs     84      87
4  Nets     96      95
#add 'quality' column based on values in 'scored' and 'allowed' columns
df$quality &lt;- with(df, ifelse(scored > 95, 'great',         ifelse(scored > 85, 'good', 'bad')))
#view updated data frame
df
   team scored allowed quality
1  Mavs     99      95   great
2  Cavs     90      80    good
3 Spurs     84      87     bad
4  Nets     96      95   great
</b>
<h3>
<b>Example 2: Add Numeric Column Based on Other Columns</b>
</h3>
The following code shows how to add a new numeric column to a data frame based on the values in other columns:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Cavs', 'Spurs', 'Nets'), scored=c(99, 90, 84, 96), allowed=c(95, 80, 87, 95))
#view data frame
df
   team scored allowed
1  Mavs     99      95
2  Cavs     90      80
3 Spurs     84      87
4  Nets     96      95
#add 'lower_score' column based on values in 'scored' and 'allowed' columns
df$lower_score &lt;- with(df, ifelse(scored > allowed, allowed, scored))
#view updated data frame
df
   team scored allowed lower_score
1  Mavs     99      95          95
2  Cavs     90      80          80
3 Spurs     84      87          84
4  Nets     96      95          95
</b>
<h2><span class="orange">How to Add a Count Column to a Data Frame in R</span></h2>
You can use the following basic syntax to add a ‘count’ column to a data frame in R:
<b>df %>%
  group_by(var1) %>%
  mutate(var1_count = n())
</b>
This particular syntax adds a column called <b>var1_count</b> to the data frame that contains the count of values in the column called <b>var1</b>.
The following example shows how to use this syntax in practice.
<h2>Example: Add Count Column in R</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#define data frama
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'B', 'B'), position=c('G', 'F', 'F', 'F', 'G', 'G', 'F', 'F'), points=c(18, 22, 19, 14, 14, 11, 20, 28))
#view data frame
df
  team position points
1    A        G     18
2    A        F     22
3    A        F     19
4    B        F     14
5    B        G     14
6    B        G     11
7    B        F     20
8    B        F     28
</b>
We can use the following code to add a column called <b>team_count</b> that contains the count of each team:
<b>library(dplyr)
#add column that shows total count of each team
df %>%
  group_by(team) %>%
  mutate(team_count = n())
# A tibble: 8 x 4
# Groups:   team [2]
  team  position points team_count
              
1 A     G            18          3
2 A     F            22          3
3 A     F            19          3
4 B     F            14          5
5 B     G            14          5
6 B     G            11          5
7 B     F            20          5
8 B     F            28          5
</b>
There are <b>3</b> rows with a team value of A and <b>5</b> rows with a team value of B.
Thus:
For each row where the team is equal to A, the value in the <b>team_count</b> column is <b>3</b>.
For each row where the team is equal to B, the value in the <b>team_count</b> column is <b>5</b>.
You can also add a ‘count’ column that groups by multiple variables.
For example, the following code shows how to add a ‘count’ column that groups by the <b>team</b> and <b>position</b> variables:
<b>library(dplyr)
#add column that shows total count of each team and position
df %>%
  group_by(team, position) %>%
  mutate(team_pos_count = n())
# A tibble: 8 x 4
# Groups:   team, position [4]
  team  position points team_pos_count  
1 A     G            18              1
2 A     F            22              2
3 A     F            19              2
4 B     F            14              3
5 B     G            14              2
6 B     G            11              2
7 B     F            20              3
8 B     F            28              3</b>
From the output we can see:
There is <b>1</b> row that contains A in the <b>team</b> column and G in the <b>position</b> column.
There are <b>2</b> rows that contain A in the <b>team</b> column and F in the <b>position</b> column.
There are <b>3</b> rows that contain B in the <b>team</b> column and F in the <b>position</b> column.
There are <b>2</b> rows that contain B in the <b>team</b> column and F in the <b>position</b> column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Group By and Count with Condition in R 
 How to Count Number of Elements in List in R 
 How to Select Unique Rows in a Data Frame in R 
<h2><span class="orange">How to Add Days to Date in R (With Examples)</span></h2>
You can use one of the following methods to add a certain number of days to a date in R:
<b>Method 1: Use Base R</b>
<b>#create new column that adds 5 days to date column
df$date_plus5 &lt;- as.Date(df$date) + 5
</b>
<b>Method 2: Use lubridate Package</b>
<b>library(lubridate)
#create new column that adds 5 days to date column
df$date_plus5 &lt;- ymd(df$date) + days(5)
</b>
The following examples show how to use each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(date=c('2022-01-03', '2022-02-15', '2022-05-09',        '2022-08-10', '2022-10-14', '2022-12-30'), sales=c(130, 98, 120, 88, 94, 100))
#view data frame
df
        date sales
1 2022-01-03   130
2 2022-02-15    98
3 2022-05-09   120
4 2022-08-10    88
5 2022-10-14    94
6 2022-12-30   100</b>
<b>Note</b>: To subtract days from a date, simply change the addition sign to a subtraction sign in either of the formulas above.
<h2>Example 1: Add Days to Date Using Base R</h2>
The following code shows how to create a new column called <b>date_plus5</b> that adds five days to each of the dates in the <b>date</b> column:
<b>#create new column that adds 5 days to date column
df$date_plus5 &lt;- as.Date(df$date) + 5
#view updated data frame
df
        date sales date_plus5
1 2022-01-03   130 2022-01-08
2 2022-02-15    98 2022-02-20
3 2022-05-09   120 2022-05-14
4 2022-08-10    88 2022-08-15
5 2022-10-14    94 2022-10-19
6 2022-12-30   100 2023-01-04
</b>
Notice that the values in the new <b>date_plus5</b> column are equal to the values in the <b>date</b> column with five days added to them.
We can also use the <b>class()</b> function to confirm that the new column is in a date format:
<b>#display class of date_plus5 column
class(df$date_plus5)
[1] "Date"
</b>
<h2>
<b>Example 2: Add Days to Date Using lubridate Package</b>
</h2>
The following code shows how to use the <b>ymd()</b> and<b> days()</b> functions from the <b>lubridate </b>package to create a new column called <b>date_plus5</b> that adds five days to each of the dates in the <b>date</b> column:
<b>library(lubridate)
#create new column that adds 5 days to date column
df$date_plus5 &lt;- ymd(df$date) + days(5)
#view updated data frame
df
        date sales date_plus5
1 2022-01-03   130 2022-01-08
2 2022-02-15    98 2022-02-20
3 2022-05-09   120 2022-05-14
4 2022-08-10    88 2022-08-15
5 2022-10-14    94 2022-10-19
6 2022-12-30   100 2023-01-04
</b>
The values in the new <b>date_plus5</b> column are equal to the values in the <b>date</b> column with five days added to them.
<b>Note</b>: The <b>ymd()</b> function tells the <b>lubridate</b> package that the values in the date column are currently in a year-month-date format.
Refer to the lubridate  documentation page  for more date formatting options.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Convert Date to Numeric in R 
 How to Extract Month from Date in R 
 How to Add and Subtract Months from a Date in R 
<h2><span class="orange">How to Add New Column to Matrix in R (With Examples)</span></h2>
You can use the following methods to add a new column to a matrix in R:
<b>Method 1: Add New Column to End of Matrix</b>
<b>my_matrix &lt;- cbind(my_matrix, c(2, 7, 7, 8))
</b>
<b>Method 2: Add New Column to Beginning of Matrix</b>
<b>my_matrix &lt;- cbind(c(2, 7, 7, 8), my_matrix)</b>
Note that both methods use the  cbind()  function in R to column-bind a new column to the matrix.
The following examples show how to use each method in practice.
<h2>Example 1: Add New Column to End of Matrix</h2>
The following code shows how to use the <b>cbind()</b> function to add a new column to the last position of a matrix that contains the values 2, 7, 7, and 8:
<b>#create matrix
my_matrix &lt;- matrix(c(14, 0, 12, 5, 7, 4, 1, 3, 9, 5, 5, 8), nrow=4)
#view matrix
my_matrix
     [,1] [,2] [,3]
[1,]   14    7    9
[2,]    0    4    5
[3,]   12    1    5
[4,]    5    3    8
#add new column to end of matrix
my_matrix &lt;- cbind(my_matrix, c(2, 7, 7, 8))
#view updated matrix
my_matrix
     [,1] [,2] [,3] [,4]
[1,]   14    7    9    2
[2,]    0    4    5    7
[3,]   12    1    5    7
[4,]    5    3    8    8</b>
Notice that one new column has been added to the end of the matrix.
<h2>Example 2: Add New Column to Beginning of Matrix</h2>
The following code shows how to use the <b>cbind()</b> function to add a new column to the first position of a matrix that contains the values 2, 7, 7, and 8:
<b>#create matrix
my_matrix &lt;- matrix(c(14, 0, 12, 5, 7, 4, 1, 3, 9, 5, 5, 8), nrow=4)
#view matrix
my_matrix
     [,1] [,2] [,3]
[1,]   14    7    9
[2,]    0    4    5
[3,]   12    1    5
[4,]    5    3    8
#add new column to beginning of matrix
my_matrix &lt;- cbind(c(2, 7, 7, 8), my_matrix)
#view updated matrix
my_matrix
     [,1] [,2] [,3] [,4]
[1,]    2   14    7    9
[2,]    7    0    4    5
[3,]    7   12    1    5
[4,]    8    5    3    8</b>
Notice that one new column has been added to the beginning of the matrix.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Sort a Matrix in R 
 How to Remove NA from Matrix in R 
 How to Convert Data Frame to Matrix in R 
 How to Convert a Table to a Matrix in R 
<h2><span class="orange">How to Add New Level to Factor in R (With Example)</span></h2>
You can use the following basic syntax to add a new level to a factor variable in R:
<b>levels(df$my_factor) &lt;- c(levels(df$my_factor), 'new_level')
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Add New Level to Factor in R</h2>
Suppose we have the following data frame in R that shows the number of sales made in different regions for some retail store:
<b>#create data frame
df &lt;- data.frame(region=factor(c('A', 'B', NA, 'D', NA, 'F')), sales=c(12, 18, 21, 14, 34, 40))
#view data frame
df
  region sales
1      A    12
2      B    18
3   &lt;NA>    21
4      D    14
5   &lt;NA>    34
6      F    40
</b>
Notice that the <b>region</b> variable is a factor.
To view the levels for this factor, we can use the <b>levels()</b> function:
<b>#view factor levels for region
levels(df$region)
[1] "A" "B" "D" "F"
</b>
We can use the following syntax to add a new factor level called “no region”:
<b>#add factor level called 'no region'
levels(df$region) &lt;- c(levels(df$region), 'no region')
#convert each NA to 'no region'
df$region[is.na(df$region)] &lt;- 'no region'
#view factor levels for region
levels(df$region)
[1] "A" "B" "D" "F" "no region"
</b>
The new level called “no region” has been added as a factor level.
If we’d like, we can use the <b>table()</b> function to count the occurrence of each factor level:
<b>#view occurrences of each factor level
table(df$region)
A         B         D         F no region 
1         1         1         1         2 
</b>
From the output we can see that the new factor level called “no region” occurs twice in the <b>region</b> column of the data frame.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Convert Factor to Numeric in R 
 How to Convert Factor to Character in R 
 How to Reorder Factor Levels in R 
<h2><span class="orange">How to Add Points to an Existing Plot in R</span></h2>
You can use the <b>points()</b> function to add points to an existing plot in R.
This function uses the following basic syntax:
<b>points(df2$x, df2$y, col='red')
</b>
This particular syntax adds red points to an existing scatter plot in R using the variables called <b>x</b> and <b>y</b> from a data frame called <b>df2</b>.
The following example shows how to use this syntax in practice.
<h2>Example: Add Points to an Existing Plot in R</h2>
Suppose we use the <b>plot()</b> function to create the following scatter plot in R:
<b>#create data frame
df1 &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),  y=c(4, 5, 5, 4, 6, 8, 12, 15, 19, 22)) 
#create scatterplot
plot(df1$x, df1$y, col='blue', pch=16)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/points1.jpg"455">
<b>Note</b>: The <b>col</b> argument specifies the color of the points in the plot and the <b>pch</b> argument specifies the symbol to use. A value of 16 represents a filled-in circle.
Now suppose that we would like to add points from another data frame to the plot.
We can use the <b>points()</b> function to do so:
<b>#create second data frame
df2 &lt;- data.frame(x=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),  y=c(14, 12, 9, 9, 8, 5, 4, 5, 3, 2)) 
#add points from df2 to the existing scatter plot
points(df2$x, df2$y, col='red', pch=16)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/points2.jpg">
Notice that the points from the second data frame have been added to the existing plot and are represented by a red color.
If we’d like, we can also use the <b>legend()</b> function to add a legend to the plot so that we can distinguish which points came from which data frame:
<b>#add legend to plot
legend(x=1, y=22, legend=c('df1', 'df2'), fill=c('blue', 'red'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/points3.jpg"481">
<b>Note</b>: You can use the <b>points()</b> function as many times as you’d like to add points from as many data frames as you’d like to an existing plot.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Label Points on a Scatterplot in R 
 How to Add Text Outside of a Plot in R 
 How to Create a Scatterplot with a Regression Line in R 
<h2><span class="orange">How to Add Prefix to Column Names in R (With Examples)</span></h2>
You can use the following methods to add a prefix to column names in R:
<b>Method 1: Add Prefix to All Column Names</b>
<b>colnames(df) &lt;- paste('my_prefix', colnames(df), sep = '_')
</b>
<b>Method 2: Add Prefix to Specific Column Names</b>
<b>colnames(df)[c(1, 3)] &lt;- paste('my_prefix', colnames(df)[c(1, 3)], sep = '_')</b>
The following examples show how to use each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  points assists rebounds
1     99      33       30
2     90      28       28
3     86      31       24
4     88      39       24
5     95      34       28
</b>
<b>Related:</b>  How to Add Suffix to Column Names in R 
<h2>Example 1: Add Prefix to All Column Names</h2>
The following code shows how to add the prefix ‘<b>total_</b>‘ to all column names:
<b>#add prefix 'total_' to all column names
colnames(df) &lt;- paste('total', colnames(df), sep = '_') 
#view updated data frame
df
  total_points total_assists total_rebounds
1           99            33             30
2           90            28             28
3           86            31             24
4           88            39             24
5           95            34             28
</b>
Notice that the prefix ‘<b>total_</b>‘ has been added to each column name.
<h2>Example 2: Add Prefix to Specific Column Names</h2>
The following code shows how to add the prefix ‘<b>total_</b>‘ to specific column names:
<b>#add prefix 'total_' to column names in index positions 1 and 3
colnames(df)[c(1, 3)] &lt;- paste('total', colnames(df)[c(1, 3)], sep = '_') 
#view updated data frame
df
  total_points assists total_rebounds
1           99      33             30
2           90      28             28
3           86      31             24
4           88      39             24
5           95      34             28
</b>
Notice that the prefix ‘<b>total_</b>‘ has only been added to the columns in index positions <b>1</b> and <b>3</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Loop Through Column Names in R 
 How to Rename a Single Column in R 
 How to Check if Column Exists in Data Frame in R 
<h2><span class="orange">How to Add Suffix to Column Names in R (With Examples)</span></h2>
You can use the following methods to add a suffix to column names in R:
<b>Method 1: Add Suffix to All Column Names</b>
<b>colnames(df) &lt;- paste(colnames(df), 'my_suffix', sep = '_')
</b>
<b>Method 2: Add Suffix to Specific Column Names</b>
<b>colnames(df)[c(1, 3)] &lt;- paste(colnames(df)[c(1, 3)], 'my_suffix', sep = '_')</b>
The following examples show how to use each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  points assists rebounds
1     99      33       30
2     90      28       28
3     86      31       24
4     88      39       24
5     95      34       28
</b>
<h2>Example 1: Add Suffix to All Column Names</h2>
The following code shows how to add the suffix ‘<b>_total</b>‘ to all column names:
<b>#add suffix '_total' to all column names
colnames(df) &lt;- paste(colnames(df), 'total', sep = '_') 
#view updated data frame
df
  points_total assists_total rebounds_total
1           99            33             30
2           90            28             28
3           86            31             24
4           88            39             24
5           95            34             28
</b>
Notice that the suffix ‘<b>_total</b>‘ has been appended to the end of each column name.
<h2>Example 2: Add Suffix to Specific Column Names</h2>
The following code shows how to add the suffix ‘<b>_total</b>‘ to specific column names:
<b>#add suffix '_total' to column names in index positions 1 and 3
colnames(df)[c(1, 3)] &lt;- paste(colnames(df)[c(1, 3)], 'total', sep = '_') 
#view updated data frame
df
  points_total assists rebounds_total
1           99      33             30
2           90      28             28
3           86      31             24
4           88      39             24
5           95      34             28
</b>
Notice that the suffix ‘<b>_total</b>‘ has only been appended to the columns in index positions <b>1</b> and <b>3</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Loop Through Column Names in R 
 How to Rename a Single Column in R 
 How to Check if Column Exists in Data Frame in R 
<h2><span class="orange">How to Add Text Outside of a Plot in R</span></h2>
You can use the following basic syntax to add text outside of a plot in R:
<b>text(x=8, y=-0.5, 'Some Text', xpd=NA)
</b>
This particular example adds the text ‘Some Text’ to the (x, y) location of (8, -0.5).
Note that the <b>xpd</b> argument takes on three potential values for where to place your text:
<b>FALSE</b>: Inside the plot only
<b>TRUE</b>: In the outer plotting area
<b>NA</b>: Anywhere on plotting device
By specifying <b>xpd=NA</b>, we’re able to add text outside of our plot.
The following examples show how to use this syntax in practice.
<h2>Example 1: Add One Text Element Outside of Plot</h2>
The following code shows how to add one text element outside of the plot in the bottom right corner:
<b>#define variables
x &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
y &lt;- c(4, 5, 5, 4, 6, 8, 12, 15, 19, 22) 
#create scatterplot
plot(x, y)
#add text outside of plot
text(x=8, y=-0.5, 'Some Text', xpd=NA)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/addtext1.jpg">
Notice that our text element has been added to the (x, y) coordinates of (8, -0.5) in the plot.
Since the value for the y-coordinate is less than the lower limit of the y-axis, the text element ends up being placed below the plot.
<h2>Example 2: Add Multiple Text Elements Outside of Plot</h2>
The following code shows how to add multiple text elements outside of the plot by using the <b>text()</b> function multiple times:
<b>#define variables
x &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
y &lt;- c(4, 5, 5, 4, 6, 8, 12, 15, 19, 22) 
#create scatterplot
plot(x, y)
#add multiple text elements outside of plot
text(x=8, y=-0.5, 'Below Plot', xpd=NA)
text(x=8, y=25, 'Above Plot', xpd=NA)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/addtext2.jpg">
By using the<b> text()</b> function multiple times, we’re able to add multiple text elements outside of the plot.
Feel free to play around with the <b>x</b> and <b>y</b> arguments within the <b>text()</b> function to place text in the exact position you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Draw a Legend Outside of a Plot in R 
 How to Change Legend Position in Base R Plots 
 How to Print String and Variable on Same Line in R 
<h2><span class="orange">How to Add a Total Row to a Data Frame in R</span></h2>
You can use the following methods to add a ‘total’ row to the bottom of a data frame in R:
<b>Method 1: Use Base R</b>
<b>rbind(df, data.frame(team='Total', t(colSums(df[, -1]))))
</b>
<b>Method 2: Use dplyr</b>
<b>library(dplyr)
df %>%
  bind_rows(summarise(., across(where(is.numeric), sum),         across(where(is.character), ~'Total')))
</b>
The following example shows how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F'), assists=c(5, 7, 7, 9, 12, 9), rebounds=c(11, 8, 10, 6, 6, 5), blocks=c(6, 6, 3, 2, 7, 9))
#view data frame
df
  team assists rebounds blocks
1    A       5       11      6
2    B       7        8      6
3    C       7       10      3
4    D       9        6      2
5    E      12        6      7
6    F       9        5      9
</b>
<h2>Example 1: Add Total Row Using Base R</h2>
We can use the <b>rbind</b> and <b>colSums</b> functions from base R to add a total row to the bottom of the data frame:
<b>#add total row to data frame
df_new &lt;- rbind(df, data.frame(team='Total', t(colSums(df[, -1]))))
#view new data frame
df_new
   team assists rebounds blocks
1     A       5       11      6
2     B       7        8      6
3     C       7       10      3
4     D       9        6      2
5     E      12        6      7
6     F       9        5      9
7 Total      49       46     33</b>
Notice that a row has been added to the bottom of the data frame that shows the sum of the values in each column.
<h2>Example 2: Add Total Row Using dplyr</h2>
The following code shows how to use functions from the  dplyr  package in R to add a total row to the bottom of the data frame:
<b>library(dplyr)
#add total row to data frame
df_new &lt;- df %>%
            bind_rows(summarise(., across(where(is.numeric), sum),                   across(where(is.character), ~'Total')))
#view new data frame
df_new
   team assists rebounds blocks
1     A       5       11      6
2     B       7        8      6
3     C       7       10      3
4     D       9        6      2
5     E      12        6      7
6     F       9        5      9
7 Total      49       46     33</b>
Notice that a row has been added to the bottom of the data frame that shows the sum of the values in each column.
Also notice that this method produces the same results as the base R method.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Use rbind in R 
 How to Remove Rows in R 
 How to Calculate Difference Between Rows in R 
<h2><span class="orange">How to Add Vertical Line to Histogram in R</span></h2>
You can use the following methods to add a vertical line to a histogram in R:
<b>Method 1: Add Solid Vertical Line at Specific Location</b>
<b>abline(v=2)
</b>
This syntax adds one vertical line to the histogram at x=2.
<b>Method 2: Add Customized Vertical Line at Specific Location</b>
<b>abline(v=mean(data), col='red', lwd=3, lty='dashed')</b>
This syntax adds one vertical red dashed line with a width of 3 at the mean value of the histogram.
<b>Method 3: Add Multiple Customized Vertical Lines</b>
<b>abline(v=quantile(data, .25), col='red', lwd=3)</b>
<b>abline(v=quantile(data, .75), col='blue', lwd=3)</b>
This syntax adds a red vertical line at the first quartile and a blue vertical line at the third quartile of the histogram.
The following examples show how to use each method in practice.
<h2>Example 1: Add Solid Vertical Line at Specific Location</h2>
The following code shows how to create a histogram and add a vertical line at x=2:
<b>#make this example reproducible
set.seed(1)
#create data
data &lt;- rnorm(n=1000, mean=5, sd=2)
#create histogram to visualize distribution of data
hist(data)
#add vertical line at x=2
abline(v=2)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/vert1.jpg"474">
<h2>Example 2: Add Customized Vertical Line at Specific Location</h2>
The following code shows how to create a histogram and add one vertical red dashed line with a width of 3 at the mean value of the histogram:
<b>#make this example reproducible
set.seed(1)
#create data
data &lt;- rnorm(n=1000, mean=5, sd=2)
#create histogram to visualize distribution of data
hist(data)
#add vertical line at mean value
abline(v=mean(data), col='red', lwd=3, lty='dashed')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/vert2.jpg">
<h2>Example 3: Add Multiple Customized Vertical Lines</h2>
The following code shows how to create a histogram and add a red vertical line at the first quartile and a blue vertical line at the third quartile of the histogram.
<b>#make this example reproducible
set.seed(1)
#create data
data &lt;- rnorm(n=1000, mean=5, sd=2)
#create histogram to visualize distribution of data
hist(data)
#add vertical lines at 1st and third quartiles
abline(v=quantile(data, .25), col='red', lwd=3)
abline(v=quantile(data, .75), col='blue', lwd=3)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/vert3.jpg">
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Create a Relative Frequency Histogram in R 
 How to Overlay Normal Curve on Histogram in R 
 How to Use abline() Function in R 
<h2><span class="orange">How to Fix in R: aggregate function missing, defaulting to ‘length’</span></h2>
One error you may encounter when using R is:
<b>Aggregation function missing: defaulting to length
</b>
This error occurs when you use the <b>dcast</b> function from the <b>reshape2</b> package to convert a data frame from a  long to wide format , but more than one value could be placed in the individual cells of the wide data frame.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R that contains information about the sales of various products:
<b>#create data frame
df &lt;- data.frame(store=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), promotion=c('Y', 'Y', 'N', 'N', 'Y', 'Y', 'N', 'N'), product=c(1, 2, 1, 2, 1, 2, 1, 2), sales=c(12, 18, 29, 20, 30, 11, 15, 22))
#view data frame
df
  store promotion product sales
1     A         Y       1    12
2     A         Y       2    18
3     A         N       1    29
4     A         N       2    20
5     B         Y       1    30
6     B         Y       2    11
7     B         N       1    15
8     B         N       2    22</b>
Now suppose we attempt to use the <b>dcast</b> function to convert the data frame from a long to a wide format:
<b>library(reshape2)
#convert data frame to wide format
df_wide &lt;- dcast(df, store ~ product, value.var="sales")
#view result
df_wide
Aggregation function missing: defaulting to length
  store 1 2
1     A 2 2
2     B 2 2</b>
Notice that the dcast function works but we receive the warning message of<b> Aggregation function missing</b>.
<h3>How to Fix the Error</h3>
The reason we receive a warning message is because for each combination of <b>store</b> and <b>product</b>, there are two potential values we could use for <b>sales</b>.
For example, for store A and product 1, the sales value could be 12 or 29.
Thus, the <b>dcast</b> function defaults to using “length” as the aggregate function.
For example, the wide data frame tells us that for store A and product 1, there are a total of <b>2</b> sales values.
If you’d instead like to use a different aggregation function, you can use <b>fun.aggregate</b>.
For example, we can use the following syntax to calculate the sum of sales by <b>store</b> and <b>product</b>:
<b>library(reshape2)
#convert data frame to wide format
df_wide &lt;- dcast(df, store ~ product, value.var="sales", fun.aggregate=sum)
#view result
df_wide
  store  1  2
1     A 41 38
2     B 45 33
</b>
Here’s how to interpret the values in the wide data frame:
The sum of sales for store A and product 1 is <b>41</b>.
The sum of sales for store A and product 2 is <b>38</b>.
The sum of sales for store B and product 1 is <b>45</b>.
The sum of sales for store B and product 2 is <b>33</b>.
Notice that we don’t receive any warning message this time because we used the <b>fun.aggregate</b> argument.
<h2><span class="orange">How to Aggregate Multiple Columns in R (With Examples)</span></h2>
We can use the <b>aggregate()</b> function in R to produce summary statistics for one or more variables in a data frame.
This function uses the following basic syntax:
<b>aggregate(sum_var ~ group_var, data = df, FUN = mean)</b>
where:
<b>sum_var:</b> The variable to summarize
<b>group_var:</b> The variable to group by
<b>data:</b> The name of the data frame
<b>FUN:</b> The summary statistic to compute
This tutorial provides several examples of how to use this function to aggregate one or more columns at once in R, using the following data frame as an example:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C'), conf=c('E', 'E', 'W', 'W', 'W', 'W', 'W', 'W'), points=c(1, 3, 3, 4, 5, 7, 7, 9), rebounds=c(7, 7, 8, 3, 2, 7, 14, 13))
#view data frame
df
  team conf points rebounds
1    A    E      1        7
2    A    E      3        7
3    A    W      3        8
4    B    W      4        3
5    B    W      5        2
6    B    W      7        7
7    C    W      7       14
8    C    W      9       13</b>
<h3>Example 1: Summarize One Variable & Group by One Variable</h3>
The following code shows how to find the mean points scored, grouped by team:
<b>#find mean points scored, grouped by team
aggregate(points ~ team, data = df, FUN = mean, na.rm = TRUE)
  team   points
1    A 2.333333
2    B 5.333333
3    C 8.000000</b>
<h3>Example 2: Summarize One Variable & Group by Multiple Variables</h3>
The following code shows how to find the mean points scored, grouped by team and conference:
<b>#find mean points scored, grouped by team and conference
aggregate(points ~ team + conf, data = df, FUN = mean, na.rm = TRUE)
  team conf   points
1    A    E 2.000000
2    A    W 3.000000
3    B    W 5.333333
4    C    W 8.000000</b>
<h3>Example 3: Summarize Multiple Variables & Group by One Variable</h3>
The following code shows how to find the mean points and the mean rebounds, grouped by team:
<b>#find mean points scored, grouped by team and conference
aggregate(cbind(points,rebounds) ~ team, data = df, FUN = mean, na.rm = TRUE)
  team   points  rebounds
1    A 2.333333  7.333333
2    B 5.333333  4.000000
3    C 8.000000 13.500000</b>
<h3>Example 4: Summarize Multiple Variables & Group by Multiple Variables</h3>
The following code shows how to find the mean points and the mean rebounds, grouped by team and conference:
<b>#find mean points scored, grouped by team and conference
aggregate(cbind(points,rebounds) ~ team + conf, data = df, FUN = mean, na.rm = TRUE)
  team conf   points rebounds
1    A    E 2.000000      7.0
2    A    W 3.000000      8.0
3    B    W 5.333333      4.0
4    C    W 8.000000     13.5</b>
<h2><span class="orange">How to Fix in R: there are aliased coefficients in the model</span></h2>
One error you may encounter in R is:
<b>Error in vif.default(model) : there are aliased coefficients in the model
</b>
This error typically occurs when  multicollinearity  exists in a regression model. That is, two or more predictor variables in the model are highly (or perfectly) correlated.
When this occurs, we say that one variable is an ‘alias’ of another variable, which causes problems when fitting a regression model.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we fit the following  regression model  in R:
<b>#make this example reproducible
set.seed(0)
#define data
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100)
x3 &lt;- x2*3
y &lt;- rnorm(100)
#fit regression model
model &lt;- lm(y~x1+x2+x3)
</b>
We can use the <b>vif()</b> function from the <b>car</b> package to calculate the VIF values for each predictor variable in the model to determine if multicollinearity is a problem:
<b>library(car)
#calculate VIF values for predictor variables
vif(model)
Error in vif.default(model) : there are aliased coefficients in the model
</b>
We receive an error that “<b>there are aliased coefficients in the model.</b>“
This tells us that two or more predictor variables in the model are perfectly correlated.
<h3>How to Fix the Error</h3>
To determine which predictor variables are perfectly correlated, we can use the <b>cor()</b> function to create a  correlation matrix  for the variables:
<b>#place variables in data frame
df &lt;- data.frame(x1, x2, x3, y)
#create correlation matrix for data frame
cor(df)
           x1           x2           x3            y
x1 1.00000000  0.126886263  0.126886263  0.065047543
x2 0.12688626  1.000000000  1.000000000 -0.009107573
x3 0.12688626  1.000000000  1.000000000 -0.009107573
y  0.06504754 -0.009107573 -0.009107573  1.000000000
</b>
We can see that the variables <b>x2</b> and <b>x3</b> have a  correlation coefficient  of 1. This tells us that these two variables are causing the error because they’re perfectly correlated.
To fix this error, we simply need to fit the regression model again and leave out one of these two variables.
It doesn’t matter which variable we leave out since they both provide the exact same information in the regression model.
For simplicity, let’s remove <b>x3</b> and fit the regression model again:
<b>library(car)
#make this example reproducible
set.seed(0)
#define data
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100)
x3 &lt;- x2*3
y &lt;- rnorm(100)
#fit regression model
model &lt;- lm(y~x1+x2)
#calculate VIF values for predictor variables in model
vif(model)
      x1       x2 
1.016364 1.016364 
</b>
Note that we don’t receive any error this time when calculating the VIF values for the model because multicollinearity is no longer an issue.
<b>Related:</b>  How to Calculate and Interpret VIF Values in R 
<h2><span class="orange">How to Append Rows to a Data Frame in R (With Examples)</span></h2>
You can quickly append one or more rows to a data frame in R by using one of the following methods:
<b>Method 1: Use rbind() to append data frames.</b>
<b>rbind(df1, df2)
</b>
<b>Method 2: Use nrow() to append a row.</b>
<b>df[nrow(df) + 1,] = c(value1, value2, ...)</b>
This tutorial provides examples of how to use each of these methods in practice.
<h3>Method 1: Use rbind() to Append Data Frames</h3>
This first method assumes that you have two data frames with the same column names. By using the <b>rbind()</b> function, we can easily append the rows of the second data frame to the end of the first data frame.
For example:
<b>#define data frame
df1 &lt;- data.frame(var1=c(4, 13, 7, 8),  var2=c(15, 9, 9, 13),  var3=c(12, 12, 7, 5))
df1
  var1 var2 var3
1    4   15   12
2   13    9   12
3    7    9    7
4    8   13    5
#define second data frame
df2 &lt;- data.frame(var1=c(4, 13),  var2=c(9, 12),  var3=c(6, 6))
df2
  var1 var2 var3
1    4    9    6
2   13   12    6
#append the rows of the second data frame to end of first data frame
df3 &lt;- rbind(df1, df2)
df3
  var1 var2 var3
1    4   15   12
2   13    9   12
3    7    9    7
4    8   13    5
5    4    9    6
6   13   12    6
</b>
<h3>Method 2: Use nrow() to Append a Row </h3>
This method uses the <b>nrow()</b> function to append a row to the end of a given data frame.
For example:
<b>#define first data frame
df1 &lt;- data.frame(var1=c(4, 13, 7, 8),  var2=c(15, 9, 9, 13),  var3=c(12, 12, 7, 5))
df1
  var1 var2 var3
1    4   15   12
2   13    9   12
3    7    9    7
4    8   13    5
#append row to end of data frame 
df1[nrow(df1) + 1,] = c(5, 5, 3)
df1
  var1 var2 var3
1    4   15   12
2   13    9   12
3    7    9    7
4    8   13    5
5    5    5    3</b>
In order for this method to work, the vector of values that you’re appending needs to be the same length as the number of columns in the data frame.
<h2><span class="orange">How to Append Values to List in R (With Examples)</span></h2>
You can use the following syntax to append a single value to a list in R:
<b>#get length of list called <em>my_list
</em>len &lt;- length(my_list)
#append value of 12 to end of list
my_list[[len+1]] &lt;- 12
</b>
And you can use the following syntax to append multiple values to a list in R:
<b>#get length of list called <em>my_list
</em>len &lt;- length(my_list)
#define values to append to list
new &lt;- c(3, 5, 12, 14)
#append values to list
i = 1
while(i &lt;= length(new)) {
    my_list[[i+len]] &lt;- new[i]
    i &lt;- i + 1
}</b>
The following examples show how to use each of these functions in practice.
<h3>Example 1: Append a Single Value to a List</h3>
Suppose we have the following list in R:
<b>#create list
my_list &lt;- list(7, 14, c(1, 2, 3))
#view list
my_list
[[1]]
[1] 7
[[2]]
[1] 14
[[3]]
[1] 1 2 3
</b>
We can use the following syntax to append the value 12 to the end of the list:
<b>#get length of list
len &lt;- length(my_list)
#append value to end of list
my_list[[len+1]] &lt;- 12
#view list
my_list
[[1]]
[1] 7
[[2]]
[1] 14
[[3]]
[1] 1 2 3
[[4]]
[1] 12
</b>
<h3>Example 2: Append Multiple Values to a List</h3>
Suppose we have the following list in R:
<b>#create list
my_list &lt;- list(7, 14, c(1, 2, 3))
#view list
my_list
[[1]]
[1] 7
[[2]]
[1] 14
[[3]]
[1] 1 2 3
</b>
We can use the following syntax to append several values to the end of the list:
<b>#get length of list
len &lt;- length(my_list)
#define values to append to list
new &lt;- c(3, 5, 12, 14)
#append values to list
i = 1
while(i &lt;= length(new)) {
    my_list[[i+len]] &lt;- new[i]
    i &lt;- i + 1
}
#display updated list
my_list
[[1]]
[1] 7
[[2]]
[1] 14
[[3]]
[1] 1 2 3
[[4]]
[1] 3
[[5]]
[1] 5
[[6]]
[1] 12
[[7]]
[1] 14
</b>
<h2><span class="orange">How to Append Values to a Vector Using a Loop in R</span></h2>
To append values to a vector using a loop in R, you can use the following basic syntax:
<b>for(i in 1:10) {
  data &lt;- c(data, i)
}
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Append Values to Empty Vector</h3>
The following code shows how to append values to an empty vector in R:
<b>#define empty vector
data &lt;- c()
#use for loop to add integers from 1 to 10 to vector 
for(i in 1:10) {
  data &lt;- c(data, i)
}
#view resulting vector
data
[1]  1  2  3  4  5  6  7  8  9 10
</b>
<h3>Example 2: Perform Operation & Append Values to Vector</h3>
The following code shows how to perform an operation and append values to an empty vector:
<b>#define empty vector
data &lt;- c()
#use for loop to add square root of integers from 1 to 10 to vector 
for(i in 1:10) {
  data &lt;- c(data, sqrt(i))
}
#view resulting vector
data
[1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
[9] 3.000000 3.162278
</b>
<h3>Example 3: Append Values to Existing Vector</h3>
The following code shows how to append values to an existing vector in R:
<b>#define vector of data
data &lt;- c(4, 5, 12)
#define new data to add
new &lt;- c(16, 16, 17, 18)
#use for loop to append new data to vector
for(i in 1:length(new)) {
  data &lt;- c(data, new[i])
}
#view resulting vector
data
[1] 4 5 12 16 16 17 18
</b>
<h3>Example 4: Append a Single Value to Vector</h3>
If you simply want to append a single value to the end of an existing vector, you can use the following code without a for loop:
<b>#define vector of data
data &lt;- c(4, 5, 12)
#append the value "19" to the end of the vector
new &lt;- c(data, 19)
#display resulting vector
new
[1] 4 5 12 19
</b>
You can find more R tutorials on  this page .
<h2><span class="orange">R: How to Use apply() Function on Specific Columns</span></h2>
Often you may want to use the <b>apply()</b> function to apply a function to specific columns in a data frame in R.
However, the <b>apply()</b> function first forces all columns in a data frame to have the same object type before applying a function, which can sometimes have unintended consequences.
A better choice is the <b>lapply()</b> function, which uses the following basic syntax:
<b>df[c('col1', 'col2')] &lt;- lapply(df[c('col1', 'col2')], my_function)
</b>
This particular example applies the function <b>my_function</b> to only <b>col1</b> and <b>col2</b> in the data frame.
The following example shows how to use this syntax in practice.
<h2>Example: Apply Function to Specific Columns of Data Frame</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(19, 22, 15, NA, 14, 25, 25, 25), rebounds=c(10, 6, 3, 7, 11, 13, 9, 12), assists=c(4, 4, 3, 6, 7, 5, 10, 8))
#view data frame
df
  team points rebounds assists
1    A     19       10       4
2    A     22        6       4
3    A     15        3       3
4    A     NA        7       6
5    B     14       11       7
6    B     25       13       5
7    B     25        9      10
8    B     25       12       8</b>
Now suppose we define the following function that multiplies values by 2 and then adds 1:
<b>#define function
my_function &lt;- function(x) x*2 + 1</b>
We can use the following <b>lapply()</b> function to apply this function only to the <b>points</b> and <b>rebounds</b> columns in the data frame:
<b>#apply function to specific columns
df[c('points', 'rebounds')] &lt;- lapply(df[c('points', 'rebounds')], my_function)
#view updated data frame
df
  team points rebounds assists
1    A     39       21       4
2    A     45       13       4
3    A     31        7       3
4    A     NA       15       6
5    B     29       23       7
6    B     51       27       5
7    B     51       19      10
8    B     51       25       8
</b>
From the output we can see that we multiplied each value in the <b>points</b> and <b>rebounds</b> columns by 2 and then added 1.
Also notice that the <b>team</b> and <b>assists</b> columns remained unchanged.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 A Guide to apply(), lapply(), sapply(), and tapply() in R 
 How to Use the transform Function in R 
<h2><span class="orange">How to Apply Function to Each Row in Matrix or Data Frame in R</span></h2>
You can use the <b>apply()</b> function to apply a function to each row in a matrix or data frame in R.
This function uses the following basic syntax:
<b>apply(X, MARGIN, FUN)</b>
where:
<b>X:</b> Name of the matrix or data frame.
<b>MARGIN:</b> Dimension to perform operation across. Use 1 for row, 2 for column.
<b>FUN:</b> The function to apply.
The following examples show how to use this syntax in practice.
<h3>Example 1: Apply Function to Each Row in Matrix</h3>
Suppose we have the following matrix in R:
<b>#create matrix
mat &lt;- matrix(1:15, nrow=3)
#view matrix
mat
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    4    7   10   13
[2,]    2    5    8   11   14
[3,]    3    6    9   12   15
</b>
We can use the <b>apply()</b> function to apply different functions to the rows of the matrix:
<b>#find mean of each row
apply(mat, 1, mean)
[1] 7 8 9
#find sum of each row
apply(mat, 1, sum)
[1] 35 40 45
#find standard deviation of each row
apply(mat, 1, sd)
[1] 4.743416 4.743416 4.743416
#multiply the value in each row by 2 (using t() to transpose the results)
t(apply(mat, 1, function(x) x * 2))
     [,1] [,2] [,3] [,4] [,5]
[1,]    2    8   14   20   26
[2,]    4   10   16   22   28
[3,]    6   12   18   24   30
#normalize every row to 1 (using t() to transpose the results)
t(apply(mat, 1, function(x) x / sum(x) ))
           [,1]      [,2] [,3]      [,4]      [,5]
[1,] 0.02857143 0.1142857  0.2 0.2857143 0.3714286
[2,] 0.05000000 0.1250000  0.2 0.2750000 0.3500000
[3,] 0.06666667 0.1333333  0.2 0.2666667 0.3333333</b>
Note that if you’d like to find the mean or sum of each row, it’s faster to use the built-in <b>rowMeans()</b> or <b>rowSums()</b> functions:
<b>#find mean of each row
rowMeans(mat)
[1] 7 8 9
#find sum of each row
rowSums(mat)
[1] 35 40 45</b>
<h3>Example 2: Apply Function to Each Row in Data Frame</h3>
Suppose we have the following matrix in R:
<b>#create data frame
df &lt;- data.frame(var1=1:3, var2=4:6, var3=7:9, var4=10:12, var5=13:15)
#view data frame
df
  var1 var2 var3 var4 var5
1    1    4    7   10   13
2    2    5    8   11   14
3    3    6    9   12   15
</b>
We can use the <b>apply()</b> function to apply different functions to the rows of the data frame:
<b>#find mean of each row
apply(df, 1, mean)
[1] 7 8 9
#find sum of each row
apply(df, 1, sum)
[1] 35 40 45
#find standard deviation of each row
apply(df, 1, sd)
[1] 4.743416 4.743416 4.743416
#multiply the value in each row by 2 (using t() to transpose the results)
t(apply(df, 1, function(x) x * 2))
     var1 var2 var3 var4 var5
[1,]    2    8   14   20   26
[2,]    4   10   16   22   28
[3,]    6   12   18   24   30
#normalize every row to 1 (using t() to transpose the results)
t(apply(df, 1, function(x) x / sum(x) ))
           var1      var2 var3      var4      var5
[1,] 0.02857143 0.1142857  0.2 0.2857143 0.3714286
[2,] 0.05000000 0.1250000  0.2 0.2750000 0.3500000
[3,] 0.06666667 0.1333333  0.2 0.2666667 0.3333333</b>
Similar to matrices, if you’d like to find the mean or sum of each row, it’s faster to use the built-in <b>rowMeans()</b> or <b>rowSums()</b> functions:
<b>#find mean of each row
rowMeans(df)
[1] 7 8 9
#find sum of each row
rowSums(df)
[1] 35 40 45</b>
<h2><span class="orange">How to Fix in R: argument is not numeric or logical: returning na</span></h2>
One warning you may encounter in R is:
<b>Warning message:
In mean.default(df) : argument is not numeric or logical: returning NA
</b>
This warning occurs when you attempt to calculate the mean of some object in R that is not numerical or logical.
This tutorial shares exactly how to handle this warning in practice.
<h3>How to Reproduce the Warning</h3>
Suppose we create the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      28       28
3    C     86      31       24
4    D     88      39       24
5    E     95      34       28
</b>
If we attempt to calculate the mean of a character column or if we attempt to calculate the mean of the entire data frame, we’ll receive a warning:
<b>#attempt to calculate mean of character column
mean(df$team)
Warning message:
In mean.default(df$team) : argument is not numeric or logical: returning NA
#attempt to calculate mean of entire data frame
mean(df)
Warning message:
In mean.default(df) : argument is not numeric or logical: returning NA
</b>
The <b>mean()</b> function only takes a numeric vector as an argument, which explains why we receive a warning in both scenarios.
<h3>How to Handle the Warning</h3>
The way to handle this warning is to only use the <b>mean()</b> function with numeric vectors.
For example, we could calculate the mean of the points column since it’s numeric:
<b>#calculate mean of points column
mean(df$points)
[1] 91.6
</b>
Or we could use the <b>sapply()</b> function to calculate the mean of every column in the data frame:
<b>#calculate mean of every column in data frame
sapply(df, mean, 2)
    team   points  assists rebounds 
      NA       90       33       28 
Warning message:
In mean.default(X[[i]], ...) :
  argument is not numeric or logical: returning NA</b>
We’re able to calculate the mean of each numeric column, but still receive a warning message since we attempted to calculate the mean of the ‘team’ character column.
To avoid this warning entirely, we could use the <b>sapply()</b> function with just the three numeric columns:
<b>#calculate mean of each numeric column
sapply(df[c('points', 'assists', 'rebounds')], mean, 2)
  points  assists rebounds 
      90       33       28</b>
Notice that the mean of each numeric column is successfully shown and we receive no warning message.
<h2><span class="orange">How to Fix in R: argument is of length zero</span></h2>
One error message you may encounter when using R is:
<b>Error in if (x &lt; 10) { : argument is of length zero
</b>
This error usually occurs when you attempt to make some logical comparison within an if statement in R, but the variable that you’re using in the comparison is of length zero.
Two examples of variables with length zero are<b> numeric()</b> or <b>character(0)</b>.
The following example shows how to resolve this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following numeric variable in R with a length of zero:
<b>#create numeric variable with length of zero
x &lt;- numeric()
</b>
Now suppose we attempt to use this variable in an if statement:
<b>#if x is less than 10, print x to console
if(x &lt; 10) {
  x
}
Error in if (x &lt; 10) { : argument is of length zero
</b>
We receive an error because the variable that we defined has a length of zero.
If we simply created a numeric variable with an actual value, we would never receive this error when using the if statement:
<b>#create numeric variable
y &lt;- 5
#if y is less than 10, print y to console
if(y &lt; 10) {
  y
}
[1] 5
</b>
<h3>How to Avoid the Error</h3>
To avoid the <b>argument is of length zero</b> error, we must include an <b>isTRUE</b> function, which uses the following logic:
<b>is.logical(x) && length(x) == 1 && !is.na(x) && x</b>
If we use this function in the if statement, we won’t receive an error when comparing our variable to some value:
<b>if(isTRUE(x) && x &lt; 10) {
  x
}
</b>
Instead of receiving an error, we simply receive no output because the <b>isTRUE(x)</b> function evaluates to <b>FALSE</b>, which means the value of x is never printed.
<h2><span class="orange">How to Fix in R: argument “no” is missing, with no default</span></h2>
One error you may encounter in R is:
<b>Error in ifelse(df$team == "B", "Boston") : 
  argument "no" is missing, with no default
</b>
This error occurs when you use the <b>ifelse()</b> function in R but forget to include a third argument to specify the value that should be returned if the logical test returns false.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('B', 'B', 'B', 'B', 'C', 'C', 'C', 'D'), points=c(12, 22, 35, 34, 20, 28, 30, 18), assists=c(4, 10, 11, 12, 12, 8, 6, 10))
#view data frame
df
  team points assists
1    B     12       4
2    B     22      10
3    B     35      11
4    B     34      12
5    C     20      12
6    C     28       8
7    C     30       6
8    D     18      10
</b>
Now suppose we attempt to use the <b>ifelse()</b> function to create a new column called <b>city</b> that contains “Boston” if the value in the <b>team</b> column is equal to “B”:
<b>#attempt to create new column with team city
df$city &lt;- ifelse(df$team=='B', 'Boston')
Error in ifelse(df$team == "B", "Boston") : 
  argument "no" is missing, with no default</b>
We receive an error because we failed to provide a third argument in the <b>ifelse()</b> function that specifies the value we should return if the value in the <b>team</b> column is not equal to “B”.
<h2>How to Fix the Error</h2>
The way to fix this error is to simply provide a third argument in the <b>ifelse()</b> function that specifies the value we should return if the value in the <b>team</b> column is not equal to “B”.
The following syntax shows how to do so:
<b>#create new column with team city
df$city &lt;- ifelse(df$team=='B', 'Boston', 'Other')
#view updated data frame
df
  team points assists   city
1    B     12       4 Boston
2    B     22      10 Boston
3    B     35      11 Boston
4    B     34      12 Boston
5    C     20      12  Other
6    C     28       8  Other
7    C     30       6  Other
8    D     18      10  Other
</b>
Notice that we don’t receive  any error this time since we provided a third argument to the <b>ifelse()</b> function.
In this example, the<b> ifelse()</b> function returns a value of “Boston” if the value in the <b>team</b> column is equal to “B” or a value of “Other” if the value in the <b>team</b> column is anything else.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in R:
 How to Fix in R: NAs Introduced by Coercion 
 How to Fix in R: Subscript out of bounds 
 How to Fix in R: longer object length is not a multiple of shorter object length 
 How to Fix in R: number of items to replace is not a multiple of replacement length 
<h2><span class="orange">How to Fix in R: Arguments imply differing number of rows</span></h2>
One error you may encounter in R is:
<b>arguments imply differing number of rows: 6, 5
</b>
This error occurs when you attempt to create a data frame and the number of rows in each column of the data frame is not the same.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a data frame in R using three vectors:
<b>#define vectors
x1 &lt;- c(1, 2, 3, 4, 5, 6)
x2 &lt;- c(8, 8, 8, 7, 5)
y &lt;- c(9, 11, 12, 13, 14, 16)
#attempt to create data frame using vectors as columns
df &lt;- data.frame(x1=x1, x2=x2, y=y)
Error in data.frame(x1 = x1, x2 = x2, y = y) : 
  arguments imply differing number of rows: 6, 5
</b>
We receive an error because each vector does not have the same length, so each column in the resulting data frame does not have the same number of rows.
We can verify this by printing the length of each vector:
<b>#print length of each vector
length(x1)
[1] 6
length(x2)
[1] 5
length(y)
[1] 6
</b>
We can see that the vector <b>x2</b> has a length of 5, which does not match the length of vectors <b>x1</b> and <b>y</b>.
<h3>How to Fix the Error</h3>
To fix this error, we simply need to make sure that each vector has the same length so that each column in the resulting data frame has the same number of rows.
For example, we could pad the shortest vector with NA values so that each vector has the same length:
<b>#define vectors
x1 &lt;- c(1, 2, 3, 4, 5, 6)
x2 &lt;- c(8, 8, 8, 7, 5)
y &lt;- c(9, 11, 12, 13, 14, 16)
#pad shortest vector with NA's to have same length as longest vector
length(x2) &lt;- length(y)
#create data frame using vectors as columns
df &lt;- data.frame(x1=x1, x2=x2, y=y)
#view resulting data frame
df
  x1 x2  y
1  1  8  9
2  2  8 11
3  3  8 12
4  4  7 13
5  5  5 14
6  6 NA 16
</b>
Notice that we don’t receive an error because each column in the resulting data frame has the same number of rows.
<h2><span class="orange">How to Use attach() in R (With Examples)</span></h2>
You can use the <b>attach() </b>function in R to make objects in data frames accessible without actually typing the name of the data frame.
This function uses the following basic syntax:
<b>attach(data)
</b>
The following examples show how to use this function in different scenarios with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      28       28
3    C     86      31       24
4    D     88      39       24
5    E     95      34       28
</b>
<h3>Example 1: Use attach() to Perform Calculations</h3>
Normally if we would like to calculate the mean, median, range, etc. of a column in a data frame, we would use the following syntax:
<b>#calculate mean of rebounds column
mean(df$rebounds)
[1] 26.8
#calculate median of rebounds column
median(df$rebounds)
[1] 28
#calculate range of rebounds column
range(df$rebounds)
[1] 24 30
</b>
However, if we use <b>attach()</b> then we don’t even have to type out the data frame name to perform these calculations:
<b>attach(df)
#calculate mean of rebounds column
mean(rebounds)
[1] 26.8
#calculate median of rebounds column
median(rebounds)
[1] 28
#calculate range of rebounds column
range(rebounds)
[1] 24 30
</b>
By using <b>attach()</b>, we’re able to reference the column name directly and R knows which data frame we’re trying to use.
<h3>Example 2: Use attach() to Fit Regression Models</h3>
Normally if we would like to fit a linear regression model in R, we would use the following syntax:
<b>#fit regression model
fit &lt;- lm(points ~ assists + rebounds, data=df)
#view coefficients of regression model
summary(fit)$coef
              Estimate Std. Error  t value   Pr(>|t|)
(Intercept) 18.7071984 13.2030474 1.416885 0.29222633
assists      0.5194553  0.2162095 2.402555 0.13821408
rebounds     2.0802529  0.3273034 6.355733 0.02387244</b>
However, if we use<b> attach() </b>then we don’t even have to use the <b>data</b> argument within the <b>lm()</b> function to fit the regression model:
<b>#fit regression model
fit &lt;- lm(points ~ assists + rebounds)
#view coefficients of regression model
summary(fit)$coef
              Estimate Std. Error  t value   Pr(>|t|)
(Intercept) 18.7071984 13.2030474 1.416885 0.29222633
assists      0.5194553  0.2162095 2.402555 0.13821408
rebounds     2.0802529  0.3273034 6.355733 0.02387244</b>
Notice that the regression results are the exact same.
<h3>Bonus: Use detach() and search()</h3>
You can use the <b>search()</b> function to display all of the objects that are attached in the current R environment:
<b>#show all attached objects
search()
 [1] ".GlobalEnv"        "df"                "package:stats"    
 [4] "package:graphics"  "package:grDevices" "package:utils"    
 [7] "package:datasets"  "package:methods"   "Autoloads"        
[10] "package:base"  
</b>
And you can use the <b>detach()</b> function to detach an object that is currently detached:
<b>#detach data frame
detach(df)</b>
<h2><span class="orange">How to Fix in R: Error: attempt to apply non-function</span></h2>
One error you may encounter in R is:
<b>Error: attempt to apply non-function
</b>
This error usually occurs when you attempt to multiply values in R but forget to include a multiplication (<b>*</b>) sign.
This tutorial shares exactly how to handle this error in two different scenarios.
<h3>Scenario 1: Resolve Error in Data Frame Multiplication</h3>
Suppose we create the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 6, 7), y=c(3, 5, 5, 8))
#view data frame
df
  x y
1 1 3
2 2 5
3 6 5
4 7 8</b>
Now suppose we attempt to create a new column that is equals to column x multiplied by 10:
<b>#attempt to create new column
df$x_times_10 &lt;- df$x(10)
Error: attempt to apply non-function
</b>
We receive an error because we forgot to include a multiplication (<b>*</b>) sign.
To resolve this error, we must include a multiplication sign:
<b>#create new column
df$x_times_10 &lt;- df$x*(10)
#view updated data frame
df
  x y x_times_10
1 1 3         10
2 2 5         20
3 6 5         60
4 7 8         70
</b>
<h3>Scenario 2: Resolve Error in Vector Multiplication</h3>
Suppose we create two vectors in R and attempt to multiply together their corresponding elements:
<b>#create two vectors
x &lt;- c(1, 2, 2, 2, 4, 5, 6)
y &lt;- c(5, 6, 8, 7, 8, 8, 9)
#attempt to multiply corresponding elements in vectors
(x)(y)
Error: attempt to apply non-function
</b>
We receive an error because we did not include a multiplication sign.
To resolve this error, we must include a multiplication sign:
<b>#multiply corresponding elements in vectors
(x)*(y)
[1]  5 12 16 14 32 40 54
</b>
Notice that no error is produced this time.
<h2><span class="orange">How to Change Axis Labels of Boxplot in R (With Examples)</span></h2>
You can use one of the following methods to change the x-axis labels on a boxplot in R:
<b>Method 1: Change Axis Labels of Boxplot in Base R</b>
<b>boxplot(df, names=c('Label 1', 'Label 2', 'Label 3'))
</b>
<b>Method 2: Change Axis Labels of Boxplot in ggplot2</b>
<b>levels(df_long$variable) &lt;- c('Label 1', 'Label 2', 'Label 3')
ggplot(df_long, aes(variable, value)) + 
  geom_boxplot()</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(A=rnorm(1000, mean=5), B=rnorm(1000, mean=10), C=rnorm(1000, mean=15))
#view head of data frame
head(df)
         A         B        C
1 6.262954  9.713148 15.44435
2 4.673767 11.841107 15.01193
3 6.329799  9.843236 14.99072
4 6.272429  8.610197 14.69762
5 5.414641  8.526896 15.49236
6 3.460050  9.930481 14.39728</b>
<h2>Example 1: Change Axis Labels of Boxplot in Base R</h2>
If we use the <b>boxplot()</b> function to create boxplots in base R, the column names of the data frame will be used as the x-axis labels by default:
<b>#create boxplots
boxplot(df)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/xnames1.jpg"486">
However, we can use the <b>names</b> argument to specify the x-axis labels to use:
<b>#create boxplots with specific x-axis names
boxplot(df, names=c('Team A', 'Team B', 'Team C'))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/xnames2.jpg"485">
Notice that the labels we specified in the <b>names</b> argument are now used as the x-axis labels.
<h2>Example 2: Change Axis Labels of Boxplot in ggplot2</h2>
Before we can create boxplots in ggplot2, we must use the <b>melt()</b> function from the <b>reshape2</b> package to “melt” the data frame into a long format:
<b>library(reshape2)
#reshape data frame to long format
df_long &lt;- melt(df)
#view head of long data frame
head(df_long)
  variable    value
1        A 6.262954
2        A 4.673767
3        A 6.329799
4        A 6.272429
5        A 5.414641
6        A 3.460050</b>
We can then use the <b>levels()</b> function to specify the x-axis labels and the<b> geom_boxplot()</b> function to actually create the boxplot in ggplot2:
<b>library(ggplot2)
#specify x-axis names to use
levels(df_long$variable) &lt;- c('Team A', 'Team B', 'Team C')
#create box plot with specific x-axis labels
ggplot(df_long, aes(variable, value)) + 
  geom_boxplot()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/xnames3.jpg"491">
Notice that the labels we specified using the <b>levels</b> function are now used as the x-axis labels.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Reorder Boxplots in R 
 How to Create a Grouped Boxplot in R 
 How to Label Outliers in Boxplots in R 
 How to Draw Boxplots with Mean Values in R 
<h2><span class="orange">How to Calculate Business Days in R (With Examples)</span></h2>
You can use functions from the <b>bizdays</b> package in R to quickly add, subtract, and count the number of business days between two dates in R.
The following examples show how to use these functions in practice.
<h2>Example 1: Count Number of Business Days Between Two Dates in R</h2>
To count the number of business days between two dates in R, you must first use the <b>create.calendar()</b> function from the <b>bizdays</b> package to create a calendar that contains a list of business days:
<b>library(bizdays)
#create business calendar
business_calendar &lt;- create.calendar('my_calendar', weekdays = c('saturday','sunday'))
</b>
Note that the <b>weekdays</b> argument specifies which days of the week are <em>not</em> business days.
We can then use the <b>bizdays()</b> function to count the number of business days between two specific dates:
<b>library(bizdays)
#calculate number of business days between two dates
bizdays(from = '2022-01-01', to = '2022-12-31', cal = business_calendar)
[1] 259
</b>
From the output we can see that there are <b>259</b> business days between 2022-01-01 and 2022-12-31.
<h2>Example 2: Add & Subtract Business Days from Date in R</h2>
Suppose we have the following data frame in R that contains information about the total sales made at some store on various dates:
<b>#make this example reproducible
set.seed(1)
#create data frame
df &lt;- data.frame(date = as.Date('2022-01-01') + 0:249, sales = runif(n=250, min=1, max=30))
#view head of data frame
head(df)
        date     sales
1 2022-01-01  8.699751
2 2022-01-02 11.791593
3 2022-01-03 17.612748
4 2022-01-04 27.338026
5 2022-01-05  6.848776
6 2022-01-06 27.053301
</b>
We can use the <b>offset()</b> function from the <b>bizdays</b> package to add 10 business days to each date:
<b>library(bizdays) 
#create business calendar
business_calendar &lt;- create.calendar('my_calendar', weekdays = c('saturday','sunday'))
#add 10 business days to each date
df$date &lt;- bizdays::offset(df$date, 10, cal = business_calendar)
#view updated head of data frame
head(df)
        date     sales
1 2022-01-14  8.699751
2 2022-01-14 11.791593
3 2022-01-17 17.612748
4 2022-01-18 27.338026
5 2022-01-19  6.848776
6 2022-01-20 27.053301
</b>
Notice that 10 business days have been added to each date.
To subtract business days, simply use a negative number in the <b>offset()</b> function.
For example, the following code shows how to subtract 10 business days from each date:
<b>library(bizdays) 
#create business calendar
business_calendar &lt;- create.calendar('my_calendar', weekdays = c('saturday','sunday'))
#subtract 10 business days to each date
df$date &lt;- bizdays::offset(df$date, -10, cal = business_calendar)
#view updated head of data frame
head(df)
        date     sales
1 2021-12-20  8.699751
2 2021-12-20 11.791593
3 2021-12-20 17.612748
4 2021-12-21 27.338026
5 2021-12-22  6.848776
6 2021-12-23 27.053301
</b>
Notice that 10 business days have been subtracted from each date.
<b>Note</b>: You can find the complete documentation for the <b>bizdays</b> package  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Convert Date to Numeric in R 
 How to Extract Month from Date in R 
 How to Add and Subtract Months from a Date in R 
<h2><span class="orange">How to Calculate Mode by Group in R (With Examples)</span></h2>
The  mode  of a dataset represents the most frequently occurring value.
The statistical software R does not have a built-in function to calculate the mode of a dataset, but you can use the following function to calculate the mode:
<b>find_mode &lt;- function(x) {
  u &lt;- unique(x)
  tab &lt;- tabulate(match(x, u))
  u[tab == max(tab)]
}
</b>
The following examples show how to use this function to calculate the mode by group in R.
<h2>Example 1: Calculate Mode by Group in R (One Mode)</h2>
Suppose we have the following data frame in R that shows the points scored by basketball players on various teams:
<b>#define data frama
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(5, 7, 7, 9, 12, 12, 10, 14))
#view data frame
df
  team points
1    A      5
2    A      7
3    A      7
4    A      9
5    B     12
6    B     12
7    B     10
8    B     14
</b>
We can use the following code to calculate the mode of <b>points</b>, grouped by <b>team</b>:
<b>library(dplyr)
#define function to calculate mode
find_mode &lt;- function(x) {
  u &lt;- unique(x)
  tab &lt;- tabulate(match(x, u))
  u[tab == max(tab)]
}
#calculate mode of 'points' by 'team'
df %>%
  group_by(team) %>%
  summarize(mode_points = find_mode(points))
# A tibble: 2 x 2
  team  mode_points
         
1 A               7
2 B              12
</b>
From the results we can see:
The mode of points for team A is <b>7</b>.
The mode of points for team B is <b>12</b>.
<h2>Example 2: Calculate Mode by Group in R (Multiple Modes)</h2>
Suppose we have the following data frame in R:
<b>#define data frama
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(5, 7, 7, 9, 12, 12, 10, 10))
#view data frame
df
  team points
1    A      5
2    A      7
3    A      7
4    A      9
5    B     12
6    B     12
7    B     10
8    B     10
</b>
We can use the following code to calculate the mode of <b>points</b>, grouped by <b>team</b>:
<b>library(dplyr)
#define function to calculate mode
find_mode &lt;- function(x) {
  u &lt;- unique(x)
  tab &lt;- tabulate(match(x, u))
  u[tab == max(tab)]
}
#calculate mode of 'points' by 'team'
df %>%
  group_by(team) %>%
  summarize(mode_points = find_mode(points))
# A tibble: 3 x 2
# Groups:   team [2]
  team  mode_points
         
1 A               7
2 B              12
3 B              10
</b>
From the results we can see:
The mode of points for team A is <b>7</b>.
The mode of points for team B is <b>12</b> and <b>10</b>.
In this example, there were two points values that occurred most frequently for team B, so each of these mode values is returned on a separate line for team B in the output.
<h2>Additional Resources</h2>
The following tutorials explain how to calculate other descriptive statistics in R:
 How to Calculate Five Number Summary in R 
 How to Create Summary Tables in R 
 How to Use the mean() Function in R 
<h2><span class="orange">How to Fix in R: Cannot add ggproto objects together</span></h2>
One error you may encounter in R is:
<b>Error: Cannot add ggproto objects together.
       Did you forget to add this object to a ggplot object? 
</b>
This error typically occurs when you attempt to create a visualization using the  ggplot2  package but forget to add a plus (<b>+</b>) sign somewhere in the syntax.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R that shows the number of total sales and customers that a store receives during 10 different days:
<b>#create data frame
df &lt;- data.frame(day = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales = c(8, 8, 7, 6, 7, 8, 9, 12, 14, 18), customers = c(4, 6, 6, 4, 6, 7, 8, 9, 12, 13))
#view data frame
df
   day sales customers
1    1     8         4
2    2     8         6
3    3     7         6
4    4     6         4
5    5     7         6
6    6     8         7
7    7     9         8
8    8    12         9
9    9    14        12
10  10    18        13</b>
Now suppose we attempt to create a line chart to visualize the sales and customers during each of the 10 days:
<b>library(ggplot2)
#attempt to create plot with two lines
ggplot(df, aes(x = day))
  geom_line(aes(y = sales, color = 'sales')) + 
  geom_line(aes(y = customers, color = 'customers'))
Error: Cannot add ggproto objects together.
       Did you forget to add this object to a ggplot object?
</b>
We receive an error that tell us we <b>cannot add ggproto objects together</b>.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply add a plus sign (<b>+</b>) at the end of the first line, which we forgot to do the first time:
<b>library(ggplot2)
#create plot with two lines
ggplot(df, aes(x = day)) +
  geom_line(aes(y = sales, color = 'sales')) + 
  geom_line(aes(y = customers, color = 'customers'))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/twoLines1.png">
The result is a plot with two lines that shows the total customers and sales during this 10-day period.
Notice that we don’t receive an error this time because we used a plus sign (<b>+</b>) at the end of the first line.
<h2><span class="orange">How to Fix in R: cannot change working directory</span></h2>
One error you may encounter in R is:
<b>Error in setwd("C:/Users/UserName/Desktop") : 
  cannot change working directory
</b>
This error occurs when you attempt to set the working directory in R, but you misspell some part of the file path.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose I attempt to set the following working directory in R:
<b>#attempt to set working directory
setwd("C:/Users/Bob/Documents/My Folder Name")
Error in setwd("C:/Users/Bob/Documents/My Folder Name") : 
  cannot change working directory
</b>
I receive an error because this folder does not exist on my computer.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to change the file path to point to the correct folder:
<b>#set working directory
setwd("C:/Users/Bob/Documents/Correct Folder Name")
</b>
Notice that I don’t receive an error because R was able to successfully change the working directory.
I can confirm that the working directory successfully changed by using the <b>getwd()</b> function to get the current working directory:
<b>#get current working directory
getwd()
"C:/Users/Bob/Documents/Correct Folder Name"
</b>
<h3>Common Reasons for Errors</h3>
There are several reasons for why you may receive this error message in R. Common reasons include:
You simply misspelled the file path.
You included invalid characters in the file path.
You do not have permission to access the file path.
If you run into this error, make sure to check these three common issues and fix them if necessary.
<h2><span class="orange">How to Use the cat() Function in R to Concatenate Objects</span></h2>
The <b>cat()</b> function in R can be used to concatenate together several objects in R.
This function uses the following basic syntax:
<b>cat(..., file = "", sep = " ", append = FALSE))</b>
where:
<b>…</b>: Objects to concatenate
<b>file</b>: File name to send output to
<b>sep</b>: Separator to use between objects
<b>append</b>: Whether to append output to existing file or create new file
The following examples show how to use this function in different ways.
<h3>Example 1: Use cat() to Concatenate Objects</h3>
We can use the <b>cat()</b> function to concatenate three strings in R:
<b>#concatenate three strings
cat("hey", "there", "everyone")
hey there everyone
</b>
The three strings are concatenated together, with each string separated by a space.
<h3>Example 2: Use cat() to Concatenate Objects with Custom Separator</h3>
We can use the <b>cat()</b> function to concatenate three strings in R, using a dash as the separator:
<b>#concatenate three strings, using dash as separator
cat("hey", "there", "everyone", sep="-")
hey-there-everyone
</b>
Or we could use “\n” as the separator, which species that each string should be separated by a new line:
<b>#concatenate three strings, using new line as separator
cat("hey", "there", "everyone", sep="\n")
hey
there
everyone</b>
<h3>Example 3: Use cat() to Concatenate Objects and Output Results to File</h3>
We can use the <b>cat()</b> function to concatenate three strings in R and output the results to a text file:
<b>#concatenate three strings and output results to txt file
cat("hey", "there", "everyone", sep="\n", file="my_data.txt")
</b>
I can then navigate to my  current working directory  and view the contents of this text file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/cat11.jpg"386">
We could also output the results to a CSV file:
<b>#concatenate three strings and output results to CSV file
cat("hey", "there", "everyone", sep="\n", file="my_data.csv")
</b>
I can then navigate to my  current working directory  and view the contents of this text file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/cat12.jpg"455">
<h3>Example 4: Use cat() to Concatenate Objects and Append Results to File</h3>
We can use the <b>cat()</b> function to concatenate three strings in R and append the results to an existing CSV file:
<b>#concatenate three strings and output results to CSV file
cat("hey", "there", "everyone", sep="\n", file="my_data.csv")
#append results of this concatenation to first file
cat("how", "are", "you", sep="\n", file="my_data.csv", append=TRUE)
</b>
I can then navigate to my  current working directory  and view the contents of this CSV file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/cat13.jpg"449">
Notice that the results of the second <b>cat()</b> function have been appended to the file created by the first <b>cat()</b> function.
<h2><span class="orange">The Difference Between cat() and paste() in R</span></h2>
The <b>cat()</b> and <b>paste()</b> functions in R can both be used to concatenate strings together, but they’re slightly different in the following way:
The <b>cat()</b> function will output the concatenated string to the console, but it won’t store the results in a variable.
The <b>paste()</b> function will output the concatenated string to the console and <b>it will store</b> the results in a character variable.
In general, the <b>cat()</b> function is used more often for debugging.
By contrast, the <b>paste()</b> function is used when you’d like to store the results of the concatenation in a character variable and reference that variable later on in your code.
The following examples show how to use each function in practice.
<h2>Example: How to Use the cat() Function</h2>
The following code shows how to use the <b>cat()</b> function to concatenate together several strings:
<b>#concatenate several strings together
cat("hey", "there", "everyone")
hey there everyone</b>
Notice that the <b>cat()</b> function concatenates the three strings into a single string and outputs the results to the console.
However, if we attempt to store the results of the concatenation in a variable and then view that variable, we’ll receive a <b>NULL</b> value as a result:
<b>#concatenate several strings together
results &lt;- cat("hey", "there", "everyone")
hey there everyone
#attempt to view concatenated string
results
NULL</b>
This is because the <b>cat()</b> function does not store results.
It merely outputs the results to the console.
<h2>Example: How to Use the paste() Function</h2>
The following code shows how to use the <b>paste()</b> function to concatenate together several strings:
<b>#concatenate several strings together
paste("hey", "there", "everyone")
[1] "hey there everyone"
</b>
Notice that the <b>paste()</b> function concatenates the three strings into a single string and outputs the results to the console.
If we store the results of the concatenation in a variable, we can then reference that variable to view the concatenated string:
<b>#concatenate several strings together
results &lt;- paste("hey", "there", "everyone")
#view concatenated string
results
[1] "hey there everyone"
</b>
We’re able to view the concatenated string because the <b>paste()</b> function stores the results in a character variable.
We can also use functions like<b> nchar()</b> to view the length of the concatenated string:
<b>#display number of characters in concatenated string
nchar(results)
[1] 18</b>
We can see that the concatenated string contains <b>18</b> characters (including spaces).
We would not be able to use the <b>nchar()</b> function with <b>cat()</b> since <b>cat()</b> doesn’t store the results in a variable.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Use paste & paste0 Functions in R 
 How to Use the dim() Function in R 
 How to Use the map() Function in R 
<h2><span class="orange">R: How to Rename Columns When Using cbind</span></h2>
There are two ways to rename columns when using the  cbind  function in R:
<b>Method 1: Rename Columns After Using cbind</b>
<b>#cbind two vectors into a matrix
new_matrix &lt;- cbind(vec1, vec2)
#rename column names of matrix
colnames(new_matrix) &lt;- c('new_vec1', 'new_vec2')
</b>
<b>Method 2: Rename Columns During cbind</b>
<b>#cbind two vectors into matrix and rename columns
new_matrix &lt;- cbind(new_vec1 = vec1, new_vec2 = vec2)
</b>
The following examples show how to use each method in practice.
<h2>Example 1: Rename Columns After Using cbind</h2>
The following code shows how to use <b>cbind</b> to bind together two vectors into a matrix and then rename the columns of the matrix afterwards:
<b>#create two vectors
vec1 &lt;- c(1, 3, 3, 4, 5)
vec2 &lt;- c(7, 7, 8, 3, 2)
#cbind the two vectors into a matrix
new_matrix &lt;- cbind(vec1, vec2)
#view matrix
new_matrix
     vec1 vec2
[1,]    1    7
[2,]    3    7
[3,]    3    8
[4,]    4    3
[5,]    5    2
#rename columns
colnames(new_matrix) &lt;- c('new_vec1', 'new_vec2')
#view matrix
new_matrix
     new_vec1 new_vec2
[1,]        1        7
[2,]        3        7
[3,]        3        8
[4,]        4        3
[5,]        5        2
</b>
Using this method, we’re able to <b>cbind</b> together the two vectors into a matrix and then use the <b>colnames()</b> function to rename the columns of the resulting matrix.
<h2>Example 2: Rename Columns During cbind</h2>
The following code shows how to use <b>cbind</b> to bind together two vectors into a matrix and simultaneously rename the columns:
<b>#create two vectors
vec1 &lt;- c(1, 3, 3, 4, 5)
vec2 &lt;- c(7, 7, 8, 3, 2)
#cbind two vectors into matrix and rename columns
new_matrix &lt;- cbind(new_vec1 = vec1, new_vec2 = vec2)
#view matrix
new_matrix
     new_vec1 new_vec2
[1,]        1        7
[2,]        3        7
[3,]        3        8
[4,]        4        3
[5,]        5        2 </b>
Using this method, we’re able to rename the columns of the resulting data frame during the <b>cbind</b> function.
The benefit of using this method is that we’re able to use the <b>cbind</b> function and rename the columns using a single line of code.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Use cbind in R (With Examples) 
 How to Use rbind in R (With Examples) 
<h2><span class="orange">R: How to Use cbind with Vectors of Different Lengths</span></h2>
The easiest way to use  cbind  in R with vectors of different lengths is to set the vectors to equal lengths using the <b>length()</b> function.
The following example shows how to do so.
<h2>Example: Using cbind with Vectors of Different Lengths in R</h2>
Suppose we use <b>cbind</b> to column-bind together two vectors of different lengths in R:
<b>#define two vectors
vec1 &lt;- c(3, 4, 5)
vec2 &lt;- c(1, 6, 4, 4, 7, 6, 9, 8, 7)
#cbind the two vectors together
cbind(vec1, vec2)
      vec1 vec2
 [1,]    3    1
 [2,]    4    6
 [3,]    5    4
 [4,]    3    4
 [5,]    4    7
 [6,]    5    6
 [7,]    3    9
 [8,]    4    8
 [9,]    5    7</b>
The <b>cbind</b> function works with the two vectors, but notice that the values of the first vector simply repeat over and over again.
This is known as “recycling” in R.
To instead fill in the missing values for the shorter vector with NA values, you can use the following syntax:
<b>#define two vectors
vec1 &lt;- c(3, 4, 5)
vec2 &lt;- c(1, 6, 4, 4, 7, 6, 9, 8, 7)
#calculate max length of vectors
max_length &lt;- max(length(vec1), length(vec2))
#set length of each vector equal to max length
length(vec1) &lt;- max_length                      
length(vec2) &lt;- max_length 
#cbind the two vectors together
cbind(vec1, vec2)
      vec1 vec2
 [1,]    3    1
 [2,]    4    6
 [3,]    5    4
 [4,]   NA    4
 [5,]   NA    7
 [6,]   NA    6
 [7,]   NA    9
 [8,]   NA    8
 [9,]   NA    7
</b>
Notice that the missing values for the shorter vector are now filled in with NA values.
<b>Note</b>: In this example, we used <b>cbind</b> with two vectors but you can use similar syntax to use <b>cbind</b> with more than two vectors.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Use cbind in R (With Examples) 
 How to Use rbind in R (With Examples) 
 How to Rename Columns When Using cbind in R 
<h2><span class="orange">How to Check Data Type in R (With Examples)</span></h2>
You can use the following functions to check the data type of variables in R:
<b>#check data type of one variable
class(x)
#check data type of every variable in data frame
str(df)
#check if a variable is a specific data type
is.factor(x)
is.numeric(x)
is.logical(x)</b>
The following examples show how to use these functions in practice.
<h3>Example 1: Check Data Type of One Variable</h3>
The following code shows how to check the data type of one variable in R:
<b>#define variable <em>x
</em>x &lt;- c("Andy", "Bob", "Chad", "Dave", "Eric", "Frank")
#check data type of <em>x</em>
class(x)
[1] "character"
</b>
We can see that <em>x</em> is a <b>character</b> variable.
<h3>Example 2: Check Data Type of Every Variable in Data Frame</h3>
The following code shows how to check the data type of every variable in a data frame:
<b>#create data frame
df &lt;- data.frame(x=c(1, 3, 4, 4, 6), y=c("A", "B", "C", "D", "E"), z=c(TRUE, TRUE, FALSE, TRUE, FALSE))
#view data frame
df
  x y     z
1 1 A  TRUE
2 3 B  TRUE
3 4 C FALSE
4 4 D  TRUE
5 6 E FALSE
#find data type of every variable in data frame
str(df)
'data.frame':5 obs. of  3 variables:
 $ x: num  1 3 4 4 6
 $ y: chr  "A" "B" "C" "D" ...
 $ z: logi  TRUE TRUE FALSE TRUE FALSE</b>
From the output we can see:
Variable x is a <b>numeric</b> variable.
Variable y is a <b>character</b> variable.
Variably z is a <b>logical</b> variable.
<h3>Example 3: Check if Variable is Specific Data Type</h3>
The following code shows how to check the if a specific variable in a data frame is a numeric variable:
<b>#create data frame
df &lt;- data.frame(x=c(1, 3, 4, 4, 6), y=c("A", "B", "C", "D", "E"), z=c(TRUE, TRUE, FALSE, TRUE, FALSE))
#check if x column is numeric
is.numeric(df$x)
[1] TRUE
</b>
Since the output returned <b>TRUE</b>, this indicates that the x column in the data frame is numeric.
We can also use the  sapply()  function to check if every column in the data frame is numeric:
<b>#check if every column in data frame is numeric
sapply(df, is.numeric)
    x     y     z 
 TRUE FALSE FALSE 
</b>
We can see that column x is numeric, while columns y and z are not.
<h2><span class="orange">R: How to Check if Character is in String</span></h2>
You can use the following methods to check if a character is in a string in R:
<b>Method 1: Check if Character is in String Using Base R</b>
<b>grepl(my_character, my_string, fixed=TRUE)
</b>
<b>Method 2: Check if Character is in String Using stringr Package</b>
<b>library(stringr) 
str_detect(my_string, my_character)
</b>
The following examples show how to use each method in practice.
<h2>Example 1: Check if Character is in String Using Base R</h2>
The following code shows how to check if “Doug” exists in a particular string in R:
<b>#define character to look for
my_character &lt;- "Doug"
#define string
my_string &lt;- "Hey my name is Douglas"
#check if "Doug" is in string
grepl(my_character, my_string, fixed=TRUE)
[1] TRUE
</b>
Since “Doug” does exist in the string, the<b> grepl()</b> function returns <b>TRUE</b>.
Suppose we instead check if “Steve” exists in the string:
<b>#define character to look for
my_character &lt;- "Steve"
#define string
my_string &lt;- "Hey my name is Douglas"
#check if "Steve" is in string
grepl(my_character, my_string, fixed=TRUE)
[1] FALSE</b>
Since “Steve” does not exist in the string, the<b> grepl()</b> function returns <b>FALSE</b>.
<h2>Example 2: Check if Character is in String Using stringr Package</h2>
The following code shows how to use the <b>str_detect()</b> function from the <b>stringr</b> package to check if the string “Doug” exists in a particular string:
<b>library(stringr)
#define character to look for
my_character &lt;- "Doug"
#define string
my_string &lt;- "Hey my name is Douglas"
#check if "Doug" is in string
str_detect(my_string, my_character)
[1] TRUE</b>
The <b>str_detect()</b> function returns <b>TRUE</b> since “Doug” is in the string.
Note that we can also use the following syntax to check if several characters exist in the string:
<b>library(stringr)
#define vector of characters to look for
my_characters &lt;- c("Doug", "Steve", "name", "He")
#define string 
my_string &lt;- "Hey my name is Douglas"
#check if each character is in string
str_detect(my_string, my_characters)
[1]  TRUE FALSE  TRUE  TRUE
</b>
From the output we can see:
“Doug” exists in the string.
“Steve” does not exist in the string.
“name” exists in the string.
“He” exists in the string.
<b>Related:</b>  How to Use str_detect() Function in R (3 Examples) 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Remove Last Character from String in R 
 How to Find Location of Character in a String in R 
 How to Select Columns Containing a Specific String in R 
<h2><span class="orange">R: How to Check if Column Contains String</span></h2>
You can use the following methods to check if a column of a data frame in R contains a string:
<b>Method 1: Check if Exact String Exists in Column</b>
<b>sum(str_detect(df$column_name, '^exact_string$')) > 0</b>
<b>Method 2: Check if Partial String Exists in Column</b>
<b>sum(str_detect(df$column_name, 'partial_string')) > 0
</b>
<b>Method 3: Count Occurrences of Partial String in Column</b>
<b>sum(str_detect(df$column_name, 'partial_string'))</b>
This tutorial explains how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'C'), conf=c('East', 'East', 'South', 'West', 'West', 'East'), points=c(11, 14, 15, 15, 14, 19))
#view data frame
df
  team  conf points
1    A  East     11
2    A  East     14
3    A South     15
4    B  West     15
5    B  West     14
6    C  East     19</b>
<h2>Example 1: Check if Exact String Exists in Column</h2>
The following code shows how to check if the exact string ‘Eas’ exists in the <b>conf</b> column of the data frame:
<b>#check if exact string 'Eas' exists in conf column
sum(str_detect(df$conf, '^Eas$')) > 0
[1] FALSE</b>
The output returns <b>FALSE</b>.
This tells us that the exact string ‘Eas’ does not exist in the <b>conf </b>column.
<b>Note</b>: We used regex symbols to indicate the start ( <b>^</b> ) and end ( <b>$</b> ) characters of the string we were looking for.
<h2>Example 2: Check if Partial String Exists in Column</h2>
The following code shows how to check if the partial string ‘Eas’ exists in the conf</b> column of the data frame:
<b>#check if partial string 'Eas' exists in conf column
sum(str_detect(df$conf, 'Eas')) > 0
[1] TRUE</b>
The output returns <b>TRUE</b>.
This tells us that the partial string ‘Eas’ does exist in the <b>conf </b>column of the data frame.
<h2>Example 3: Count Occurrences of Partial String in Column</h2>
The following code shows how to count the number of times the partial string ‘Eas’ occurs in the <b>conf</b> column of the data frame:
<b>#count occurrences of partial string 'Eas' in conf column
sum(str_detect(df$conf, 'Eas'))
[1] 3</b>
The output returns <b>3</b>.
This tells us that the partial string ‘Eas’ occurs 3 times in the <b>conf</b> column of the data frame.
<b>Related:</b>  How to Use str_detect() Function in R 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Select Columns Containing a Specific String in R 
 How to Remove Characters from String in R 
 How to Find Location of Character in a String in R 
<h2><span class="orange">How to Check if Column Exists in Data Frame in R</span></h2>
You can use the following methods to check if a column exists in a data frame in R:
<b>Method 1: Check if Exact Column Name Exists in Data Frame</b>
<b>'this_column' %in% names(df)</b>
<b>Method 2: Check if Partial Column Name Exists in Data Frame</b>
<b>any(grepl('partial_name', names(df)))
</b>
<b>Method 3: Check if Several Exact Column Names All Exist in Data Frame</b>
<b>all(c('this_column', 'that_column', 'another_column') %in% names(df))</b>
This tutorial explains how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      28       28
3    C     86      31       24
4    D     88      39       24
5    E     95      34       28
</b>
<h2>Example 1: Check if Exact Column Name Exists in Data Frame</h2>
The following code shows how to check if the exact column name ‘rebounds’ exists in the data frame:
<b>#check if exact column name 'rebounds' exists in data frame
'rebounds' %in% names(df)
[1] TRUE</b>
The output returns <b>TRUE</b>.
This tells us that the exact column name ‘rebounds’ does exist in the data frame.
<b>Note</b>: This syntax is case-sensitive. This means if we used ‘Rebounds’ then we would receive a value of FALSE since the name ‘Rebounds’ with a capital letter does not exist in the data frame.
<h2>Example 2: Check if Partial Column Name Exists in Data Frame</h2>
The following code shows how to check if the partial column name ‘tea’ exists in the data frame:
<b>#check if partial column name 'tea' exists in data frame
any(grepl('tea', names(df)))
[1] TRUE</b>
The output returns <b>TRUE</b>.
This tells us that the partial column name ‘tea’ does exist in the data frame.
<h2>Example 3: Check if Several Exact Column Names All Exist in Data Frame</h2>
The following code shows how to check if the names ‘team’, ‘points’, and ‘blocks’ all exist in the data frame:
<b>#check if three column names all exist in data frame
all(c('team', 'points', 'blocks') %in% names(df))
[1] FALSE</b>
The output returns <b>FALSE</b>.
This tells us that all three column names we checked do not all exist in the data frame.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Select Columns Containing a Specific String in R 
 How to Remove Characters from String in R 
 How to Find Location of Character in a String in R 
<h2><span class="orange">How to Check if Data Frame is Empty in R (With Example)</span></h2>
The fastest way to check if a data frame is empty in R is to use the <b>nrow()</b> function:
<b>nrow(df)</b>
This function returns the number of a rows in a data frame.
If the function returns 0, then the data frame is empty.
If you’d like to check if a data frame is empty in an if else function, you can use the following syntax to do so:
<b>#create if else statement that checks if data frame is empty
if(nrow(df) == 0){
  print("This data frame is empty")
}else{
  print("This data frame is not empty")
}
</b>
The following example shows how to check if a data frame is empty in practice.
<b>Related:</b>  An Introduction to the nrow Function in R (With Examples) 
<h2>Example: Check if Data Frame is Empty in R</h2>
Suppose we create the following data frame in R that has three columns but is completely empty:
<b>#create empty data frame
df &lt;- data.frame(player = character(), points = numeric(), assists = numeric())
#view data frame
df
[1] player  points  assists
&lt;0 rows> (or 0-length row.names)</b>
We can use the <b>nrow()</b> function to check how many rows are in the data frame:
<b>#display number of rows in data frame
nrow(df)
[1] 0
</b>
Since the function returns 0, this tells us that the data frame is empty.
We can also use the following if else statement to tell us whether or not the data frame is empty:
<b>#create if else statement that checks if data frame is empty
if(nrow(df) == 0){
  print("This data frame is empty")
}else{
  print("This data frame is not empty")
}
[1] "This data frame is empty"
</b>
From the output we can see that the data frame is indeed empty.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Create an Empty Data Frame in R 
 How to Add an Empty Column to a Data Frame in R 
 How to Remove Empty Rows from Data Frame in R 
<h2><span class="orange">How to Check if a Directory Exists in R (With Example)</span></h2>
You can use the following methods to check if a directory exists in R:
<b>Method 1: Check If Directory Exists</b>
<b>dir.exists(file.path(main_dir, sub_dir))
</b>
This function will return <b>TRUE</b> if the directory exists and <b>FALSE</b> if it does not.
<b>Method 2: Create Directory If It Doesn’t Exist</b>
<b>#define directory
my_directory &lt;- file.path(main_dir, sub_dir)
#create directory if it doesn't exist
if (!dir.exists(my_directory)) {dir.create(my_directory)}  </b>
Note that <b>main_dir</b> and <b>sub_dir</b> are strings that specify main directory and sub directory paths.
The following examples show how to use each method in practice.
<h2>Example 1: Check If Directory Exists</h2>
Suppose we would like to check if the following directories exist:
“C:/Users/bob/”
“C:/Users/bob/Documents”
“C:/Users/bob/Data_Science_Documents”
We can use the following syntax to do so:
<b>#define main directory
main_dir &lt;- "C:/Users/bob/"
#define various sub directories
sub_dir1 &lt;- "Documents"
sub_dir2 &lt;- "Data_Science_Documents"
#check if main directory exists
dir.exists(file.path(main_dir))
[1] TRUE
#check if main directory and sub directory 1 exists
dir.exists(file.path(main_dir, sub_dir1))
[1] TRUE
#check if main directory and sub directory2 exists
dir.exists(file.path(main_dir, sub_dir2))
[1] FALSE
</b>
From the output we can see:
“C:/Users/bob/” – <b>Exists</b>
“C:/Users/bob/Documents” – <b>Exists</b>
“C:/Users/bob/Data_Science_Documents” – <b>Does Not Exist</b>
<h2>Method 2: Create Directory If It Doesn’t Exist</h2>
Suppose we would like to create the following directory if it doesn’t already exist:
“C:/Users/bob/Data_Science_Documents”
We can use the following syntax to do so:
<b>#define main directory
main_dir &lt;- "C:/Users/bob/"
#define sub directory
sub_dir &lt;- "Data_Science_Documents"
#define directory
my_directory &lt;- file.path(main_dir, sub_dir)
#create directory if it doesn't exist
if (!dir.exists(my_directory)) {dir.create(my_directory)}  </b>
If we navigate to this folder on our computer, we can see that this directory did not exist but has now been created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/drive1.jpg"661">
Note that if this directory already existed, a new one would not be created.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Load Multiple Packages in R 
 How to Check if a Package is Installed in R 
 How to Clear the Environment in R 
<h2><span class="orange">How to Check if File Exists in R (With Examples)</span></h2>
You can use the following basic syntax to check if a file exists in your current working directory in R:
<b>file.exists('my_data.csv')</b>
This function will return <b>TRUE</b> if the file exists or <b>FALSE</b> if it does not.
You can also use an if else statement to read a file into R only if it exists:
<b>data &lt;- 'my_data.csv'
if(file.exists(data)){</b>
<b>  df &lt;- read.csv(data)</b>
<b>} else {</b>
<b>  print('Does not exist')</b>
<b>}</b>
The following example shows how to use these functions in practice.
<h2>Example: Check if File Exists in R</h2>
Suppose my current  working directory  in R is a folder called <b>test_data</b> with three CSV files:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/check1.jpg"426">
I can use <b>list.files()</b> to list out the names of every file in the working directory:
<b>#display the names of every file in current working directory
list.files()
[1] "my_data.csv"       "my_new_data.csv"   "some_old_data.csv"
</b>
I can use <b>file.exists()</b> to check if a given file exists in the current working directory:
<b>#check if file 'my_data.csv' exists in current working directory
file.exists('my_data.csv')
[1] TRUE</b>
The function returns <b>TRUE</b>, which tells us that the file ‘my_data.csv’ does indeed exist in the current working directory.
We can then use the following <b>if else</b> statement to import a file only if it exists:
<b>#define file name
data &lt;- 'my_data.csv'
#import file only if it exists
if(file.exists(data)){</b>
<b>  df &lt;- read.csv(data)</b>
<b>} else {</b>
<b>  print('Does not exist')</b>
<b>}
#view contents of CSV file
df
  team points assists
1    A     14       4
2    B     26       7
3    C     29       8
4    D     20       3
</b>
Since the file exists, we’re able to import it successfully.
However, suppose we attempt to import a file that does not exist:
<b>#define file name
data &lt;- 'this_data.csv'
#import file only if it exists
if(file.exists(data)){</b>
<b>  df &lt;- read.csv(data)</b>
<b>} else {</b>
<b>  print('Does not exist')</b>
<b>}
[1] "Does not exist"
</b>
We receive the message “Does not exist”, which tells us that a file called <b>this_data.csv</b> does not exist in the current working directory.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Read Zip Files in R 
 How to Import CSV Files into R 
 How to Import Excel Files into R 
 How to Rename Files in R 
<h2><span class="orange">How to Check if a Package is Installed in R (With Example)</span></h2>
You can use the following methods to check if a package is installed in R:
<b>Method 1: Check if Particular Package is Installed</b>
<b>#check if ggplot2 is installed
system.file(package='ggplot2')
</b>
<b>Method 2: Install All Packages in a Vector that are Not Already Installed</b>
<b>install.packages(setdiff(packages, rownames(installed.packages())))  </b>
In this example, <b>packages</b> represents a vector of package names you’d like to have installed.
The following examples show how to use each method in practice.
<h2>Example 1: Check if Particular Package is Installed</h2>
We can use the <b>system.file()</b> function to check if a particular package is installed in current R environment.
For example, we can use the following syntax to check if the package  ggplot2  is installed in the current R environment:
<b>#check if ggplot2 is installed
system.file(package='ggplot2')
[1] "C:/Users/bob/Documents/R/win-library/4.0/ggplot2"</b>
Since ggplot2 is installed, the function simply returns the file path to where the package is installed.
Now suppose we check if a package called <b>this_package</b> is installed:
<b>#check if this_package is installed
system.file(package='this_package')
[1] ""
</b>
The function returns an empty string, which tells us that the package called <b>this_package</b> (which doesn’t even exist) is not installed in our current environment.
<h2>Method 2: Install All Packages in a Vector that are Not Already Installed</h2>
Suppose we would like to check if the following three packages are installed in our current environment and automatically install them if they are not:
ggplot2
dplyr
lattice
The following code shows how to do so:
<b>#define packages to install
packages &lt;- c('ggplot2', 'dplyr', 'lattice')
#install all packages that are not already installed
install.packages(setdiff(packages, rownames(installed.packages())))</b>
If any of the packages that we specified are not already installed, the <b>install.packages()</b> function will automatically install them.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Load Multiple Packages in R 
 How to Clear the Environment in R 
 How to Clear All Plots in RStudio 
<h2><span class="orange">How to Check if a Vector Contains a Given Element in R</span></h2>
You can use the following methods to check if a vector contains a given element in R:
<b>Method 1: Check if Vector Contains Element</b>
<b>'some_element' %in% my_vector
</b>
<b>Method 2: Find Position of First Occurrence of Element</b>
<b>match('some_element', my_vector)</b>
<b>Method 3: Find Position of All Occurrences of Element</b>
<b>which('some_element' == my_vector)</b>
The following examples show how to use each method in practice.
<h2>Example 1: Check if Vector Contains Element</h2>
The following code shows how to check if ‘Andy’ exists in a given vector:
<b>#create vector
my_vector &lt;- c('Andy', 'Bert', 'Chad', 'Doug', 'Bert', 'Frank')
#check if vector contains 'Andy'
'Andy' %in% my_vector
[1] TRUE
</b>
The output displays <b>TRUE</b> since the element ‘Andy’ does exist in the vector.
 However, suppose we check if ‘Arnold’ exists in the vector:
<b>#create vector
my_vector &lt;- c('Andy', 'Bert', 'Chad', 'Doug', 'Bert', 'Frank')
#check if vector contains 'Arnold'
'Arnold' %in% my_vector
[1] FALSE
</b>
The output displays <b>FALSE</b> since the element ‘Arnold’ does not exist in the vector.
<h2>Example 2: Find Position of First Occurrence of Element</h2>
The following code shows how to find the position of the first occurrence of ‘Bert’ in a given vector:
<b>#create vector
my_vector &lt;- c('Andy', 'Bert', 'Chad', 'Doug', 'Bert', 'Frank')
#find first occurrence of 'Bert'
match('Bert', my_vector)
[1] 2
</b>
The output displays <b>2</b> since the element ‘Bert’ occurs first in position 2 of the vector.
And the following code shows how to find the position of the first occurrence of ‘Carl’ in the vector:
<b>#create vector
my_vector &lt;- c('Andy', 'Bert', 'Chad', 'Doug', 'Bert', 'Frank')
#find first occurrence of 'Carl'
match('Carl', my_vector)
[1] NA
</b>
The output displays <b>NA</b> since the element ‘Carl’ never occurs in the vector.
<h2>Example 3: Find Position of All Occurrences of Element</h2>
The following code shows how to find all occurrences of ‘Bert’ in a given vector:
<b>#create vector
my_vector &lt;- c('Andy', 'Bert', 'Chad', 'Doug', 'Bert', 'Frank')
#find all occurrences of 'Bert'
which('Bert' == my_vector)
[1] 2 5
</b>
The output displays <b>2</b> and <b>5</b> since these are the positions in the vector where ‘Bert’ occurs.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter a Vector in R 
 How to Remove NA Values from Vector in R 
 How to Remove Specific Elements from Vector in R 
<h2><span class="orange">R: How to Collapse Text by Group in Data Frame</span></h2>
You can use the following methods to collapse text by group in a data frame in R:
<b>Method 1: Collapse Text by Group Using Base R</b>
<b>aggregate(text_var ~ group_var, data=df, FUN=paste, collapse='')</b>
<b>Method 2: Collapse Text by Group Using dplyr</b>
<b>library(dplyr)
df %>%
  group_by(group_var) %>%
  summarise(text=paste(text_var, collapse=''))
</b>
<b>Method 3: Collapse Text by Group Using data.table</b>
<b>library(data.table)
dt &lt;- as.data.table(df)
dt[, list(text_var=paste(text_var, collapse='')), by=group_var]</b>
This tutorial explains how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), position=c('Guard', 'Guard', 'Forward',            'Guard', 'Forward', 'Center'))
#view data frame
df
  team position
1    A    Guard
2    A    Guard
3    A  Forward
4    B    Guard
5    B  Forward
6    B   Center
</b>
<h2>Example 1: Collapse Text by Group Using Base R</h2>
The following code shows how to collapse the text in the <b>position</b> column, grouped by the <b>team</b> column using the <b>aggregate()</b> function from base R:
<b>#collapse position values by team 
aggregate(position ~ team, data=df, FUN=paste, collapse='')
  team           position
1    A  GuardGuardForward
2    B GuardForwardCenter
</b>
Notice that each of the text values in the <b>position</b> column has been collapsed into one value, grouped by the values in the <b>team</b> column.
<h2>Example 2: Collapse Text by Group Using dplyr</h2>
The following code shows how to collapse the text in the <b>position</b> column, grouped by the <b>team</b> column using the <b>summarise()</b> function from the dplyr package:
<b>library(dplyr)
#collapse position values by team
df %>%
  group_by(group_var) %>%
  summarise(text=paste(text_var, collapse=''))
# A tibble: 2 x 2
  team  text              
                
1 A     GuardGuardForward 
2 B     GuardForwardCenter
</b>
Notice that each of the text values in the <b>position</b> column has been collapsed into one value, grouped by the values in the <b>team</b> column.
<h2>Example 3: Collapse Text by Group Using data.table</h2>
The following code shows how to collapse the text in the <b>position</b> column, grouped by the <b>team</b> column using functions from the data.table package:
<b>library(data.table)
#convert data frame to data table
dt &lt;- as.data.table(df)
#collapse position values by team 
dt[, list(text_var=paste(text_var, collapse='')), by=group_var]
   team           position
1:    A  GuardGuardForward
2:    B GuardForwardCenter
</b>
Each of the text values in the <b>position</b> column has been collapsed into one value, grouped by the values in the <b>team</b> column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Select Columns Containing a Specific String in R 
 How to Remove Characters from String in R 
 How to Find Location of Character in a String in R 
<h2><span class="orange">How to Combine Rows with Same Column Values in R</span></h2>
You can use the following basic syntax to combine rows with the same column values in a data frame in R:
<b>library(dplyr)
df %>%
  group_by(group_var1, group_var2) %>%
  summarise(across(c(values_var1, values_var2), sum))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Combine Rows with Same Column Values in R</h2>
Suppose we have the following data frame that contains information about sales and returns made by various employees at a company:
<b>#create data frame
df &lt;- data.frame(id=c(101, 101, 102, 103, 103, 103), employee=c('Dan', 'Dan', 'Rick', 'Ken', 'Ken', 'Ken'), sales=c(4, 1, 3, 2, 5, 3), returns=c(1, 2, 2, 1, 3, 2))
#view data frame
df
   id employee sales returns
1 101      Dan     4       1
2 101      Dan     1       2
3 102     Rick     3       2
4 103      Ken     2       1
5 103      Ken     5       3
6 103      Ken     3       2</b>
We can use the following syntax to combine rows that have the same value in the <b>id</b> and <b>employee</b> columns and then aggregate the remaining columns:
<b>library(dplyr)
#combine rows with same value for id and employee and aggregate remaining columns
df %>%
  group_by(id, employee) %>%
  summarise(across(c(sales, returns), sum))
# A tibble: 3 x 4
# Groups:   id [3]
     id employee sales returns
          
1   101 Dan          5       3
2   102 Rick         3       2
3   103 Ken         10       6</b>
The result is a data frame that combines all of the rows in the original data frame that had the same value in the <b>id</b> and <b>employee</b> columns and then calculates the sum of values in the <b>sales</b> and <b>returns</b> columns.
<b>Note</b>: We chose to aggregate the sales and returns columns using the <b>sum</b> function, but you can aggregate by another metric such as the <b>mean</b> if you’d like.
<b>Related:</b>  How to Use the across() Function in dplyr 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Combine Lists in R 
 How to Combine Two Vectors in R 
 How to Combine Two Data Frames in R with Different Columns 
<h2><span class="orange">How to Combine Two Columns into One in R (With Examples)</span></h2>
Often you may want to combine two columns into one in R. For example, suppose you have a data frame with three columns:
<b>  month year  value
   10   2019   15
   10   2020   13
   11   2020   13
   11   2021   19
   12   2021   22
</b>
You may wish to combine the month and year column into a single column called <em>date</em>:
<b>    date   value
   2019_10   15
   2020_10   13
   2020_11   13
   2021_11   19
   2021_12   22</b>
This tutorial explains two ways to quickly do this in R.
<h3>Method 1: Use the Paste Function from Base R</h3>
The following code shows how to use the <b>paste</b> function from base R to combine the columns <em>month</em> and <em>year</em> into a single column called <em>date</em>:
<b>#create data frame
data &lt;- data.frame(month=c(10, 10, 11, 11, 12),   year=c(2019, 2020, 2020, 2021, 2021),   value=c(15, 13, 13, 19, 22))
#view data frame
data
#combine year and month into one column
data$date &lt;- paste(data$year, data$month, sep="_")
#view new data frame 
data
  month year value    date
1    10 2019    15 2019_10
2    10 2020    13 2020_10
3    11 2020    13 2020_11
4    11 2021    19 2021_11
5    12 2021    22 2021_12
</b>
Once we’ve combined the two columns, we can remove the old ones if we’d like:
<b>data_new &lt;- data[c("date", "value")]
data_new
     date value
1 2019_10    15
2 2020_10    13
3 2020_11    13
4 2021_11    19
5 2021_12    22
</b>
<h3>Method 2: Use the Unite Function from Tidyr</h3>
The following code shows how to use the <b>unite </b>function from the tiydr package to combine the columns <em>month</em> and <em>year</em> into a single column called <em>date</em>:
<b>#load tidyr package
library(tidyr)
#create data frame
data &lt;- data.frame(month=c(10, 10, 11, 11, 12),   year=c(2019, 2020, 2020, 2021, 2021),   value=c(15, 13, 13, 19, 22))
#combine year and month into one column
unite(data, date, c(year, month))
     date value
1 2019_10    15
2 2020_10    13
3 2020_11    13
4 2021_11    19
5 2021_12    22</b>
Notice that both methods produce identical results.
<em>You can find the complete documentation for the unite function  here .</em>
<h2><span class="orange">How to Combine Two Data Frames in R with Different Columns</span></h2>
You can use the <b>bind_rows()</b> function from the  dplyr  package in R to quickly combine two data frames that have different columns:
<b>library(dplyr)
bind_rows(df1, df2)</b>
The following example shows how to use this function in practice.
<h3>Example: Combine Two Data Frames with Different Columns</h3>
Suppose we have the following two data frames in R:
<b>#define first data frame
df1 &lt;- data.frame(A=c(1, 6, 3, 7, 5),  B=c(7, 9, 8, 3, 2),  C=c(3, 5, 2, 9, 9))
df1
  A B C
1 1 7 3
2 6 9 5
3 3 8 2
4 7 3 9
5 5 2 9
#define second data frame
df2 &lt;- data.frame(B=c(1, 3, 3, 4, 5),  C=c(7, 7, 8, 3, 2),  D=c(3, 3, 6, 6, 8))
df2
  B C D
1 1 7 3
2 3 7 3
3 3 8 6
4 4 3 6
5 5 2 8</b>
Note that df1 has the following column names:
A
B
C
And note that df2 has the following column names:
B
C
D
The column names don’t match, so the  rbind()  function in R will throw an error if we attempt to use it.
<b>#attempt to use rbind to row bind data frames
rbind(df1, df2)
Error in match.names(clabs, names(xi)) : 
  names do not match previous names
</b>
Instead, we can use the <b>bind_rows()</b> function from the dplyr package to combine these two data frames and simply fill in missing values in the resulting data frame with NA values:
<b>library(dplyr)
#combine df1 and df2
bind_rows(df1, df2)
    A B C  D
1   1 7 3 NA
2   6 9 5 NA
3   3 8 2 NA
4   7 3 9 NA
5   5 2 9 NA
6  NA 1 7  3
7  NA 3 7  3
8  NA 3 8  6
9  NA 4 3  6
10 NA 5 2  8
</b>
<h2><span class="orange">How to Concatenate Strings in R (With Examples)</span></h2>
You can use the <b>paste()</b> function in R to quickly concatenate multiple strings together:
<b>paste(string1, string2, string3 , sep = " ")</b>
The following examples show how to use this function in practice.
<h3>Example 1: Concatenate String Vectors</h3>
Suppose we have the following strings in R:
<b>#create three string variables
a &lt;- "hey"
b &lt;- "there"
c &lt;- "friend"
</b>
We can use the <b>paste()</b> function to quickly concatenate these three strings into one string:
<b>#concatenate the three strings into one string
d &lt;- paste(a, b, c)
#view result
d
[1] "hey there friend"
</b>
The three strings have been concatenated into one string, separated by spaces.
We can also use a different value for the separator by supplying a different value to the <b>sep</b> argument:
<b>#concatenate the three strings into one string, separated by dashes
d &lt;- paste(a, b, c, sep = "-")
[1] "hey-there-friend"
</b>
<h3>Example 2: Concatenate String Columns in Data Frame</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(first=c('Andy', 'Bob', 'Carl', 'Doug'), last=c('Smith', 'Miller', 'Johnson', 'Rogers'), points=c(99, 90, 86, 88))
#view data frame
df
  first    last points
1  Andy   Smith     99
2   Bob  Miller     90
3  Carl Johnson     86
4  Doug  Rogers     88
</b>
We can use the <b>paste()</b> function to concatenate the “first” and “last” columns into a new column called “name”:
<b>#concatenate 'first' and 'last' name columns into one column
df$name = paste(df$first, df$last)
#view updated data frame
df
  first    last points         name
1  Andy   Smith     99   Andy Smith
2   Bob  Miller     90   Bob Miller
3  Carl Johnson     86 Carl Johnson
4  Doug  Rogers     88  Doug Rogers
</b>
Notice that the strings in the “first” and “last” columns have been concatenated in the “name” column.
<h2><span class="orange">How to Concatenate Vector of Strings in R (With Examples)</span></h2>
You can use one of the following methods in R to concatenate a vector of strings together:
<b>Method 1: Use paste() in  Base R</b>
<b>paste(vector_of_strings, collapse=' ')</b>
<b>Method 2: Use stri_paste() from stringi Package</b>
<b>library(stringi)
stri_paste(vector_of_strings, collapse=' ')</b>
Both methods will produce the same result but the <b>stri_paste()</b> method will be faster, especially if you’re working with extremely large vectors.
The following examples show how to use each method in practice.
<h2>Example 1: Concatenate Vector of Strings Using paste() in Base R</h2>
The following code shows how to concatenate together a vector of strings using the <b>paste()</b> function from base R:
<b>#create vector of strings
vector_of_strings &lt;- c('This', 'is', 'a', 'vector', 'of', 'strings')
#concatenate strings
paste(vector_of_strings, collapse=' ')
[1] "This is a vector of strings"</b>
Note that the <b>collapse</b> argument specifies the delimiter to place in between each string.
In the example above, we used a space. However, we could use any delimiter we’d like such as a dash:
<b>#create vector of strings
vector_of_strings &lt;- c('This', 'is', 'a', 'vector', 'of', 'strings')
#concatenate strings using dash as delimiter
paste(vector_of_strings, collapse='-')
[1] "This-is-a-vector-of-strings"</b>
We can even use no delimiter if we’d like each of the strings to be concatenated with no spaces in between:
<b>#create vector of strings
vector_of_strings &lt;- c('This', 'is', 'a', 'vector', 'of', 'strings')
#concatenate strings using no delimiter
paste(vector_of_strings, collapse='')
[1] "Thisisavectorofstrings"</b>
<h2>
<b>Example 2: Concatenate Vector of Strings Using str_paste() from stringi Package</b>
</h2>
The following code shows how to concatenate together a vector of strings using the <b>stri_paste()</b> function from the <b>stringi</b> package in R:
<b>library(stringi)
#create vector of strings
vector_of_strings &lt;- c('This', 'is', 'a', 'vector', 'of', 'strings')
#concatenate strings
stri_paste(vector_of_strings, collapse=' ')
[1] "This is a vector of strings"</b>
Notice that this produces the same result as the <b>paste()</b> function from base R.
The only difference is that this method will be faster.
Depending on the size of the string vectors you’re working with, the difference in speed may or may not matter to you.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in R:
 How to Convert a Vector to String in R 
 How to Convert Strings to Lowercase in R 
 How to Perform Partial String Matching in R 
<h2><span class="orange">How to Fix in R: the condition has length > 1 and only the first element will be used</span></h2>
One error you may encounter in R is:
<b>Warning message:
In if (x > 1) { :
  the condition has length > 1 and only the first element will be used 
</b>
This error occurs when you attempt to use an <b>if()</b> function to check for some condition, but pass a vector to the <b>if()</b> function instead of individual elements.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following vector in R:
<b>#define data
x &lt;- c(2, 3, 1, 1, 5, 7)
</b>
Now suppose we attempt to use an <b>if()</b> function to check if each value in vector x is greater than 1, then multiply those values by 2:
<b>#if value in vector x is greater than 1, multiply it by 2
if (x>1) {
  x*2
}
Warning message:
In if (x > 1) { :
  the condition has length > 1 and only the first element will be used
</b>
We receive a warning message because we passed a vector to the <b>if()</b> statement.
An <b>if()</b> statement can only check one element in a vector at one time, but using this code we attempted to check every element in the vector at once.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to use an <b>ifelse()</b> function instead:
<b>#if value in vector x is greater than 1, multiply it by 2
ifelse(x>1, x*2, x)
[1]  4  6  1  1 10 14
</b>
By default, an <b>ifelse()</b> function checks each element in a vector one at a time. This allows us to avoid the error we encountered earlier.
Here’s how the <b>ifelse()</b> function produce the output values that it did:
The first element (2) was greater than 1, so we multiplied it by 2 to get 2*2 = <b>4</b>
The second element (3) was greater than 1, so we multiplied it by 2 to get 3*2 = <b>6</b>
The third element (1) was not greater than 1, so we left it as is: <b>1</b>
The fourth element (1) was not greater than 1, so we left it as is: <b>1</b>
And so on.
<b>Related:</b>  How to Write a Nested For Loop in R 
<h2><span class="orange">How to Convert Data Frame to Matrix in R (With Examples)</span></h2>
You can use one of the following methods to convert a data frame to a matrix in R:
<b>Method 1: Convert Data Frame of Numeric Columns to Matrix</b>
<b>mat &lt;- as.matrix(df)</b>
<b>Method 2: Convert Data Frame with Characters / Factors to Matrix</b>
<b>mat &lt;- data.matrix(df)</b>
Note that both methods use functions from base R, so you don’t have to install any external packages to use these methods.
The following examples show how to use each method in practice.
<h3>Method 1: Convert Data Frame of Numeric Columns to Matrix</h3>
Suppose we have the following data frame in R that only contains numeric columns:
<b>#create data frame
df &lt;- data.frame(points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  points assists rebounds
1     99      33       30
2     90      28       28
3     86      31       24
4     88      39       24
5     95      34       28
</b>
We can use the <b>as.matrix()</b> function to quickly convert this data frame to a numeric matrix:
<b>#convert data frame to matrix
mat &lt;- as.matrix(df)
#view matrix
mat
     points assists rebounds
[1,]     99      33       30
[2,]     90      28       28
[3,]     86      31       24
[4,]     88      39       24
[5,]     95      34       28
#view class of mat
class(mat)
[1] "matrix" "array"
</b>
By using the <b>class()</b> function, we confirm that the new object is indeed a matrix.
<h3>Method 2: Convert Data Frame with Characters / Factors to Matrix</h3>
Suppose we have the following data frame in R that contains both character and numeric columns:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34))
#view data frame
df
  team points assists
1    A     99      33
2    A     90      28
3    B     86      31
4    B     88      39
5    C     95      34
</b>
We can use the <b>data.matrix()</b> function to quickly convert this data frame to a numeric matrix:
<b>#convert data frame to matrix
mat &lt;- data.matrix(df)
#view matrix
mat
     team points assists
[1,]    1     99      33
[2,]    1     90      28
[3,]    2     86      31
[4,]    2     88      39
[5,]    3     95      34
#view class of mat
class(mat)
[1] "matrix" "array"
</b>
By using the <b>class()</b> function, we confirm that the new object is indeed a matrix.
We can also type the following:
<b>?data.matrix
</b>
Which tells us:
<b>Description:
     Return the matrix obtained by converting all the variables in a
     data frame to numeric mode and then binding them together as the
     columns of a matrix.  Factors and ordered factors are replaced by
     their internal codes.</b>
This explains why the team names A, A, B, B, C were converted to the values 1, 1, 2, 2, 3.
<h2><span class="orange">How to Convert Data Frame to Time Series in R</span></h2>
The easiest way to convert a data frame to a time series object in R is to use the <b>read.zoo()</b> function from the <b>zoo</b> package:
<b>tseries &lt;- read.zoo(df)
</b>
The following example shows how to use this function in practice.
<h2>Example: Convert Data Frame to Time Series in R</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(date = as.Date('2022-01-01') + 0:9, sales = runif(10, 10, 500) + seq(50, 59)^2)
#view data frame
df
         date    sales
1  2022-01-01 2797.159
2  2022-01-02 2782.148
3  2022-01-03 2801.773
4  2022-01-04 3257.546
5  2022-01-05 3415.920
6  2022-01-06 3267.564
7  2022-01-07 3577.496
8  2022-01-08 3627.193
9  2022-01-09 3509.547
10 2022-01-10 3670.815
</b>
We can use the <b>class()</b> function to confirm that df is currently a data frame:
<b>#display class of df
class(df)
[1] "data.frame"
</b>
To convert the data frame to a time series object, we can use the <b>read.zoo()</b> function from the <b>zoo </b>package:
<b>library(zoo)
#convert data frame to time series
tseries &lt;- read.zoo(df)
#view time series
tseries
2022-01-01 2022-01-02 2022-01-03 2022-01-04 2022-01-05 2022-01-06 2022-01-07 
  2797.159   2782.148   2801.773   3257.546   3415.920   3267.564   3577.496 
2022-01-08 2022-01-09 2022-01-10 
  3627.193   3509.547   3670.815 </b>
And we can use the <b>class()</b> function to confirm that tseries has a “zoo” time series class.
<b>#display class of tseries
class(tseries)
[1] "zoo"
</b>
We can use also use the <b>as.ts()</b> function to convert the “zoo” time series object to a “ts” time series object:
<b>#convert to ts object
tseries_ts &lt;- as.ts(tseries)
#view time series object
tseries_ts
Time Series:
Start = 18993 
End = 19002 
Frequency = 1 
 [1] 2797.159 2782.148 2801.773 3257.546 3415.920 3267.564 3577.496 3627.193
 [9] 3509.547 3670.815
#view class
class(tseries_ts)
[1] "ts"
</b>
Depending on your end goal, it might make more sense to convert the data frame to a “zoo” time series object or a “ts” time series object.
<h2>
<b>Additional Resources</b>
</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Plot a Time Series in R 
 How to Convert a String to Datetime in R 
 How to Use difftime in R to Calculate Time Differences 
<h2><span class="orange">How to Convert Date to Numeric in R (With Examples)</span></h2>
There are two methods you can use to convert date values to numeric values in R:
<b>Method 1: Use as.numeric()</b>
<b>as.numeric(my_date)
</b>
This will return the number of seconds that have passed between your date object and 1/1/1970.
<b>Method 2: Use Functions from the lubridate package</b>
<b>library(lubridate)
#get seconds value in date object
second(my_date)
#get minutes value in date object
minute(my_date)
...
#get year value in date object
year(my_date)
</b>
This will return the value for the seconds, minutes, years, etc. from your date object.
The following examples show how to use each method in practice.
<h3>Method 1: Use as.numeric()</h3>
The following code shows how to convert a date object to numeric using the <b>as.numeric()</b> function:
<b>#create date object
my_date &lt;- as.POSIXct("10/14/2021  5:35:00 PM", format="%m/%d/%Y  %H:%M:%S %p")
#view date object
my_date
[1] "2021-10-14 05:35:00 UTC"
#convert date object to number of seconds since 1/1/1970
as.numeric(my_date)
[1] 1634189700
#convert date object to number of days since 1/1/1970
as.numeric(my_date) / 86400
[1] 18914.23
#convert date object to number of years since 1/1/1970
as.numeric(my_date) / 86400 / 365
[1] 51.81982
</b>
Based on the output we can see:
There is a difference of <b>1,634,189,700 seconds</b> between our date object and 1/1/1970.
There is a difference of <b>18,914.23 days </b>between our date object and 1/1/1970.
There is a difference of <b>51.81982 years</b> between our date object and 1/1/1970.
<h3>Method 2: Use Functions from the lubridate Package</h3>
The following code shows how to convert a date object to numeric using functions from the  lubridate  package in R:
<b>library(lubridate)
#create date object
my_date &lt;- as.POSIXct("10/14/2021  5:35:00 PM", format="%m/%d/%Y  %H:%M:%S %p")
#view date object
my_date
[1] "2021-10-14 05:35:00 UTC"
#extract various numerical values from date object
second(my_date)
[1] 0
minute(my_date)
[1] 35
hour(my_date)
[1] 5
day(my_date)
[1] 14
month(my_date)
[1] 10
year(my_date)
[1] 2021
</b>
Using these functions, we can extract the seconds, minutes, hours, days, months, and year values from our date object.
Refer to  this online cheat sheet  to gain a complete understanding of the most commonly used functions in the lubridate package.
<h2><span class="orange">R: How to Convert Date to Quarter and Year</span></h2>
You can use one of the following two methods to quickly convert a date to a quarter and year format in R:
<b>Method 1: Use zoo Package</b>
<b>library(zoo)
#convert date to year/quarter format
#df$date &lt;- as.yearqtr(df$date, format = '%Y-%m-%d')
</b>
<b>Method 2: Use lubridate Package</b>
<b>library(lubridate)
library(dplyr)
df %>% mutate(date = quarter(date, with_year = TRUE))
</b>
The following examples show how to use each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(date=c('2022-01-03', '2022-02-15', '2022-05-09',        '2022-08-10', '2022-10-14', '2022-12-30'), sales=c(130, 98, 120, 88, 94, 100))
#view data frame
df
        date sales
1 2022-01-03   130
2 2022-02-15    98
3 2022-05-09   120
4 2022-08-10    88
5 2022-10-14    94
6 2022-12-30   100</b>
<h2>Example 1: Use zoo Package</h2>
The following code shows how to use the <b>as.yearqtr()</b> function from the <b>zoo</b> package to format dates in a year/quarter format:
<b>library(zoo)
#convert date to year/quarter format
df$date &lt;- as.yearqtr(df$date, format = '%Y-%m-%d')
#view updated data frame
df
     date sales
1 2022 Q1   130
2 2022 Q1    98
3 2022 Q2   120
4 2022 Q3    88
5 2022 Q4    94
6 2022 Q4   100</b>
Each date has been converted to a quarter and year format.
<h2>Example 2: Use lubridate Package</h2>
The following code shows how to use the <b>quarter()</b> function from the <b>lubridate </b>package to format dates in a year/quarter format:
<b>library(lubridate)
library(dplyr) 
#convert date to year/quarter format
df %>% mutate(date = quarter(date, with_year = TRUE))
    date sales
1 2022.1   130
2 2022.1    98
3 2022.2   120
4 2022.3    88
5 2022.4    94
6 2022.4   100</b>
Each date has been converted to a quarter and year format.
You can also leave out the <b>with_year</b> argument to only display the quarter without the year:
<b>library(lubridate)
library(dplyr) 
#convert date to quarter format
df %>% mutate(date = quarter(date))
  date sales
1    1   130
2    1    98
3    2   120
4    3    88
5    4    94
6    4   100</b>
The dates now display the quarter without the year.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common conversions in R:
 How to Convert Date to Numeric in R 
 How to Convert Numeric to Character in R 
 How to Convert Categorical Variables to Numeric in R 
<h2><span class="orange">How to Convert Matrix to Data Frame in R (With Examples)</span></h2>
You can use one of the following two methods to convert a matrix to a data frame in R:
<b>Method 1: Convert Matrix to Data Frame Using Base R</b>
<b>#convert matrix to data frame
df &lt;- as.data.frame(mat)
#specify column names
colnames(df) &lt;- c('first', 'second', 'third', ...)
</b>
<b>Method 2: Convert Matrix to Data Frame Using Tibble Package</b>
<b>library(tibble)
#convert matrix to data frame and specify column names
df &lt;- mat %>%
  as_tibble() %>%
  setNames(c('first', 'second', 'third', ...))
</b>
The following examples show how to use each method in practice with the following matrix in R:
<b>#create matrix
mat &lt;- matrix(1:21, nrow=7)
#view matrix
mat
     [,1] [,2] [,3]
[1,]    1    8   15
[2,]    2    9   16
[3,]    3   10   17
[4,]    4   11   18
[5,]    5   12   19
[6,]    6   13   20
[7,]    7   14   21
</b>
<h3>Example 1: Convert Matrix to Data Frame Using Base R</h3>
The following code shows how to convert a matrix to a data frame using base R:
<b>#convert matrix to data frame
df &lt;- as.data.frame(mat)
#specify columns of data frame
colnames(df) &lt;- c('first', 'second', 'third')
#view structure of data frame
str(df)
'data.frame':7 obs. of  3 variables:
 $ first : int  1 2 3 4 5 6 7
 $ second: int  8 9 10 11 12 13 14
 $ third : int  15 16 17 18 19 20 21</b>
From the output we can see that the matrix has been converted to a data frame with seven observations (rows) and 3 variables (columns).
<h3>Example 2: Convert Matrix to Data Frame Using Tibble Package</h3>
The following code shows how to convert a matrix to a  tibble  in R:
<b>library(tibble)
#convert matrix to tibble
df &lt;- mat %>%
  as_tibble() %>%
  setNames(c('first', 'second', 'third'))
#view tibble
df
# A tibble: 7 x 3
  first second third
     
1     1      8    15
2     2      9    16
3     3     10    17
4     4     11    18
5     5     12    19
6     6     13    20
7     7     14    21
</b>
From the output we can see that the matrix has been converted to a tibble with 7 rows and 3 columns.
<b>Note</b>: There are many benefits to using tibbles instead of data frames, especially with extremely large datasets. Read about some of the benefits  here .
<h2><span class="orange">How to Convert Numeric to Factor in R (With Examples)</span></h2>
There are two methods you can use to convert a numeric variable to a factor variable in R:
<b>Method 1: Use as.factor()</b>
<b>df$factor_variable &lt;- as.factor(df$numeric_variable)
</b>
This will convert the numeric variable to a factor variable with the number of levels equal to the number of unique values in the original numeric variable.
<b>Method 2: Use cut()</b>
<b>df$factor_variable &lt;- cut(df$numeric_variable, 3, labels=c('lab1', 'lab2', 'lab3'))
</b>
This particular example will convert the numeric variable to a factor variable by “cutting” the numeric variable at 3 equally distanced values.
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'C', 'D'), points=c(12, 15, 22, 29, 35, 24, 11, 24))
#view data frame
df
  team points
1    A     12
2    A     15
3    B     22
4    B     29
5    C     35
6    C     24
7    C     11
8    D     24
#view structure of data frame
str(df)
'data.frame':8 obs. of  2 variables:
 $ team  : chr  "A" "A" "B" "B" ...
 $ points: num  12 15 22 29 35 24 11 24</b>
<h2>Example 1: Convert Numeric to Factor Using as.factor()</h2>
The following code shows how to use <b>as.factor()</b> to convert the <b>points</b> column from numeric to factor:
<b>#convert points column from numeric to factor
df$points &lt;- as.factor(df$points)
#view updated data frame
df
  team points
1    A     12
2    A     15
3    B     22
4    B     29
5    C     35
6    C     24
7    C     11
8    D     24
#view updated structure of data frame
str(df)
'data.frame':8 obs. of  2 variables:
 $ team  : chr  "A" "A" "B" "B" ...
 $ points: Factor w/ 7 levels "11","12","15",..: 2 3 4 6 7 5 1 5</b>
By using the  str()  function to view the structure of the data frame, we can see that the <b>points</b> column is now a factor with 7 different levels representing the 7 unique numeric values in the column.
<h2>Example 2: Convert Numeric to Factor Using cut()</h2>
The following code shows how to use <b>cut()</b> to convert the <b>points</b> column from a numeric variable to a factor variable with 3 levels:
<b>#convert points column from numeric to factor with three levels
df$points &lt;- cut(df$points, 3, labels=c('OK', 'Good', 'Great'))
#view updated data frame
df
  team points
1    A     OK
2    A     OK
3    B   Good
4    B  Great
5    C  Great
6    C   Good
7    C     OK
8    D   Good
#view updated structure of data frame
str(df)
'data.frame':8 obs. of  2 variables:
 $ team  : chr  "A" "A" "B" "B" ...
 $ points: Factor w/ 3 levels "OK","Good","Great": 1 1 2 3 3 2 1 2
</b>
From the output we can see that the <b>points</b> variable has been converted from a numeric variable to a factor variable with three levels and the following labels:
“OK”
“Good”
“Great”
Note that we chose to use three levels in this example, but feel free to cut the numeric variable into as many levels as you’d like by changing the <b>3</b> in the <b>cut()</b> function to another value.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Convert Numeric to Character in R 
 How to Convert Factor to Numeric in R 
 How to Convert Factor to Character in R 
<h2><span class="orange">How to Convert a Table to a Matrix in R (With Example)</span></h2>
You can use the following basic syntax to convert a table to a matrix in R:
<b>my_matrix &lt;- matrix(my_table, ncol=ncol(my_table), dimnames=dimnames(my_table))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Convert Table to Matrix in R</h2>
First, let’s create the following data frame in R that shows the team and position of various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'C', 'G', 'F', 'C', 'C'))
#view data frame
df
  team position
1    A        G
2    A        G
3    A        F
4    A        C
5    B        G
6    B        F
7    B        C
8    B        C</b>
Next, let’s create a table that displays the frequency of each combination of <b>team</b> and <b>position</b>:
<b>#create frequency table of values for team and position
my_table &lt;- table(df$team, df$position)
#view table
my_table
    C F G
  A 1 1 2
  B 2 1 1</b>
We can use the <b>class()</b> function to confirm that the object called <b>my_table</b> is indeed a table:
<b>#display class of my_table
class(my_table)
[1] "table"
</b>
Next, we can use the following syntax to convert the table to a matrix:
<b>#convert table to matrix
my_matrix &lt;- matrix(my_table, ncol=ncol(my_table), dimnames=dimnames(my_table))
#view matrix
my_matrix
    C F G
  A 1 1 2
  B 2 1 1
</b>
And we can use the <b>class()</b> function to confirm that the object called <b>my_matrix</b> is indeed a matrix:
<b>#display class of my_matrix
class(my_matrix)
[1] "matrix" "array"
</b>
<b>Note #1</b>: The <b>ncol</b> argument ensures that the number of columns in the matrix match the number of columns in the table.
<b>Note #2</b>: The <b>dimnames</b> argument ensures that the row names and column names match the ones from the table.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in R:
 How to Convert Table to Data Frame in R 
 How to Convert Matrix to Vector in R 
 How to Convert List to Matrix in R 
 How to Convert Data Frame Column to Vector in R 
<h2><span class="orange">How to Convert Tibble to Data Frame in R (With Example)</span></h2>
A <b>tibble</b> is a data frame in R that has a refined print method that only shows the first 10 rows of a data frame.
This makes it much easier to work with large data and prevents R from attempting to display every row if you accidently print a large data frame in the console.
However, occasionally you may want to convert a tibble to a data frame.
You can use the following syntax to do so:
<b>my_df &lt;- as.data.frame(my_tibble)</b>
The following example shows how to use this syntax in practice.
<h3>Example: Convert Tibble to Data Frame in R</h3>
Suppose we use the <b>read_csv()</b> function to read a CSV file into R:
<b>library(tidyverse)
#import CSV file into tibble
my_tibble &lt;- read_csv('my_data.csv')
#view tibble
print(my_tibble)
# A tibble: 7 x 3
  points assists rebounds
          
1     24       4        8
2     29       4        8
3     33       6        5
4     34       7        5
5     20       5        9
6     18       9       12
7     19      10       10
#view class
class(my_tibble)
[1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame" 
</b>
By default, the <b>read_csv()</b> function imports the CSV file as a tibble.
However, we can use the following syntax to convert this tibble to a data frame:
<b>#convert tibble to data frame
my_df &lt;- as.data.frame(my_tibble)
#view class of my_df
class(my_df)
[1] "data.frame"
</b>
We can see that the tibble has been successfully converted to a data frame.
We can also confirm that the data frame contains the exact same values as the tibble:
<b>#view data frame
print(my_df)
  points assists rebounds
1     24       4        8
2     29       4        8
3     33       6        5
4     34       7        5
5     20       5        9
6     18       9       12
7     19      10       10
</b>
The values in the data frame are identical to those in the tibble.
<h2><span class="orange">How to Convert TRUE and FALSE to 1 and 0 in R</span></h2>
You can use the following basic syntax to convert a column with <b>TRUE</b> and <b>FALSE</b> values to a column with <b>1</b> and <b>0</b> values in R:
<b>df$my_column &lt;- as.integer(as.logical(df$my_column))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Convert TRUE and FALSE to 1 and 0 in R</h2>
 Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(5, 7, 8, 0, 12, 14), assists=c(0, 2, 2, 4, 4, 3), all_star=c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE))
#view data frame
df
  points assists all_star
1      5       0     TRUE
2      7       2     TRUE
3      8       2    FALSE
4      0       4    FALSE
5     12       4    FALSE
6     14       3     TRUE
</b>
We can use the following basic syntax to convert the <b>TRUE</b> and <b>FALSE</b> values in the <b>all_star</b> column to <b>1</b> and <b>0</b> values:
<b>#convert all_star column to 1s and 0s
df$all_star &lt;- as.integer(as.logical(df$all_star))
#view updated data frame
df
  points assists all_star
1      5       0        1
2      7       2        1
3      8       2        0
4      0       4        0
5     12       4        0
6     14       3        1
</b>
Each <b>TRUE</b> value has been converted to <b>1</b> and each <b>FALSE</b> value has been converted to <b>0</b>.
The other columns (points and assists) have remained unchanged.
Note that you can also use the <b>as.logical()</b> function to convert a column of <b>1</b> and <b>0</b> values back to <b>TRUE</b> and <b>FALSE</b> values:
<b>#convert 1s and 0s back to TRUE and FALSE in all_star column
df$all_star &lt;- as.logical(df$all_star)
#view updated data frame
df
  points assists all_star
1      5       0     TRUE
2      7       2     TRUE
3      8       2    FALSE
4      0       4    FALSE
5     12       4    FALSE
6     14       3     TRUE
</b>
The <b>1</b> and <b>0</b> values have been converted back to <b>TRUE</b> and <b>FALSE</b> values in the <b>all_star</b> column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Remove Empty Rows from Data Frame in R 
 How to Remove Columns with NA Values in R 
 How to Remove Duplicate Rows in R 
<h2><span class="orange">How to Convert Vector to List in R (With Examples)</span></h2>
You can use the <b>as.list()</b> function to quickly convert a vector to a list in R.
This function uses the following basic syntax:
<b>my_list &lt;- as.list(my_vector)
</b>
The following example shows how to use this function in practice.
<h3>Example: Convert Vector to List in R</h3>
The following code shows how to use the <b>as.list()</b> function to convert a vector to a list:
<b>#create vector
my_vector &lt;- c('A', 'B', 'C', 'D')
#convert vector to list
my_list &lt;- as.list(my_vector)
#view list
my_list
[[1]]
[1] "A"
[[2]]
[1] "B"
[[3]]
[1] "C"
[[4]]
[1] "D"
</b>
We can use the <b>class()</b> function to confirm that the new object indeed has a class of list:
<b>#view class of list
class(my_list)
[1] "list"
</b>
<h3>Bonus: Append Vector to List</h3>
You might think that you could use the following syntax to append the elements of a vector to a list in R:
<b>#attempt to create list with 6 elements
some_list &lt;- list('A', 'B', as.list(c('C', 'D', 'E', 'F')))
#view list
some_list
[[1]]
[1] "A"
[[2]]
[1] "B"
[[3]]
[[3]][[1]]
[1] "C"
[[3]][[2]]
[1] "D"
[[3]][[3]]
[1] "E"
[[3]][[4]]
[1] "F"</b>
Rather than a list with six elements, the list has three elements and the third element has four sub-elements.
To append the elements of a vector to a list, we must use the following code:
<b>#define vector
my_vector &lt;- c('C', 'D', 'E', 'F')
#define first list
list1 &lt;- list('A', 'B')
#convert vector to second list
list2 &lt;- as.list(my_vector)
#create long list by combining first list and second list
list3 &lt;- c(list1, list2)
#view result
list3
[[1]]
[1] "A"
[[2]]
[1] "B"
[[3]]
[1] "C"
[[4]]
[1] "D"
[[5]]
[1] "E"
[[6]]
[1] "F"
</b>
The result is a list with six elements.
<h2><span class="orange">How to Convert a Vector to String in R (With Examples)</span></h2>
There are two basic ways to convert a vector to a string in R:
<b>Method 1: Use paste()</b>
<b>paste(vector_name, collapse = " ")
</b>
<b>Method 2: Use toString()</b>
<b>toString(vector_name)</b>
The following examples show how to use each of these methods in practice.
<h3>Method 1: Convert Vector to String Using paste()</h3>
The following code shows how to use the <b>paste()</b> function to convert a vector to a string:
<b>#create vector
x &lt;- c("Andy", "Bernard", "Caleb", "Dan", "Eric", "Frank", "Greg")
#convert vector to string
new_string &lt;- paste(x, collapse = " ")
#view string
new_string
[1] "Andy Bernard Caleb Dan Eric Frank Greg"
</b>
You can use the <b>collapse</b> argument to specify the delimiter between each word in the vector. For example, we could remove the space between the words entirely:
<b>#create vector
x &lt;- c("Andy", "Bernard", "Caleb", "Dan", "Eric", "Frank", "Greg")
#convert vector to string
new_string &lt;- paste(x, collapse = "")
#view string
new_string
[1] "AndyBernardCalebDanEricFrankGreg"
</b>
Or we could add a dash between each word:
<b>#create vector
x &lt;- c("Andy", "Bernard", "Caleb", "Dan", "Eric", "Frank", "Greg")
#convert vector to string
new_string &lt;- paste(x, collapse = "-")
#view string
new_string
[1] "Andy-Bernard-Caleb-Dan-Eric-Frank-Greg"
</b>
<h3>Method 2: Convert Vector to String Using toString()</h3>
The following code shows how to use the <b>toString()</b> function to convert a vector to a string:
<b>#create vector
x &lt;- c("Andy", "Bernard", "Caleb", "Dan", "Eric", "Frank", "Greg")
#convert vector to string
new_string &lt;- toString(x)
#view string
new_string
[1] "Andy, Bernard, Caleb, Dan, Eric, Frank, Greg"
</b>
Note that the <b>toString()</b> function always adds commas in between each element in the vector. Thus, you should only use this function if you want commas between each element.
<h2><span class="orange">How to Use cor() to Calculate Correlation Coefficients in R</span></h2>
You can use the <b>cor()</b> function in R to calculate correlation coefficients between variables.
Here are the most common ways to use this function:
<b>Method 1: Calculate Pearson Correlation Coefficient Between Two Variables</b>
<b>cor(df$x, df$y)</b>
Use the Pearson correlation coefficient when calculating the correlation between two continuous variables. (e.g. height and weight)
<b>Method 2: Calculate Pearson Correlation Coefficient Between All Numeric Variables in Data Frame</b>
<b>cor(df)</b>
This method will return a  correlation matrix  that contains the Pearson correlation coefficient between each pairwise combination of numeric variables in a data frame.
<b>Method 3: Calculate Spearman Correlation Coefficient Between Two Variables</b>
<b>cor(df$x, df$y, method='spearman')</b>
Use the Spearman correlation coefficient when calculating the correlation between two ranked variables. (e.g. rank of a student’s math exam score vs. rank of their science exam score in a class)
<b>Method 4: Calculate Kendall’s Correlation Coefficient Between Two Variables</b>
<b>cor(df$x, df$y, method='kendall')</b>
Use the Kendall correlation coefficient when when you wish to use Spearman Correlation but the sample size is small and there are many tied ranks.
The following examples show how to use each method in practice with the following data frame in R that shows the number of hours spent studying, number of practice exams taken, and final exam score for eight different students:
<b>#create data frame
df &lt;- data.frame(hours=c(1, 1, 3, 2, 4, 3, 5, 6), prac_exams=c(4, 3, 3, 2, 3, 2, 1, 4), score=c(69, 74, 74, 70, 89, 85, 99, 90))
#view data frame
df
  hours prac_exams score
1     1          4    69
2     1          3    74
3     3          3    74
4     2          2    70
5     4          3    89
6     3          2    85
7     5          1    99
8     6          4    90
</b>
<h2>Example 1: Calculate Pearson Correlation Coefficient Between Two Variables</h2>
The following code shows how to use the <b>cor()</b> function to calculate the Pearson correlation coefficient between the <b>hours</b> and <b>score</b> variables:
<b>#calculate Pearson correlation coefficient between hours and score
cor(df$hours, df$score)
[1] 0.8600528
</b>
The Pearson correlation coefficient between <b>hours</b> and <b>score</b> turns out to be <b>0.86.</b>
Note that if there are NA values in your data frame, you can use the argument <b>use=’complete.obs’</b> to only use the rows where there are no NA values:
<b>#calculate Pearson correlation coefficient and ignore any rows with NA
cor(df$hours, df$score, use='complete.obs')</b>
<h2>Example 2: Calculate Pearson Correlation Coefficient Between All Numeric Variables</h2>
The following code shows how to use the <b>cor()</b> function to create a correlation matrix that contains the Pearson correlation coefficient between all numeric variables in the data frame:
<b>#calculate Pearson correlation coefficient between all numeric variables
cor(df)
                hours prac_exams      score
hours       1.0000000 -0.1336063  0.8600528
prac_exams -0.1336063  1.0000000 -0.3951028
score       0.8600528 -0.3951028  1.0000000
</b>
Here’s how to interpret the output:
The Pearson correlation coefficient between <b>hours</b> and <b>prac_exams </b>is <b>-.13</b>.
The Pearson correlation coefficient between <b>hours</b> and <b>score</b> is <b>.86</b>.
The Pearson correlation coefficient between <b>prac_exams </b>and <b>score</b> is <b>-.39</b>.
<b>Note</b>: The Pearson correlation coefficient between each individual variable and itself is always 1, which is why each value along the diagonal of the correlation matrix is 1.
<h2>Example 3: Calculate Spearman Correlation Coefficient Between Two Variables</h2>
The following code shows how to use the <b>cor()</b> function to calculate the Spearman correlation coefficient between the <b>hours</b> and <b>prac_exams </b>variables:
<b>#calculate Spearman correlation coefficient between hours and prac_exams
cor(df$hours, df$prac_exams, method='spearman')
[1] -0.1250391
</b>
The Spearman correlation coefficient between <b>hours</b> and <b>prac_exams </b>turns out to be <b>-.125.</b>
<h2>Example 4: Calculate Kendall’s Correlation Coefficient Between Two Variables</h2>
The following code shows how to use the <b>cor()</b> function to calculate Kendall’s correlation coefficient between the <b>hours</b> and <b>prac_exams </b>variables:
<b>#calculate Kendall's correlation coefficient between hours and prac_exams
cor(df$hours, df$prac_exams, method='kendall')
[1] -0.1226791
</b>
Kendall’s correlation coefficient between <b>hours</b> and <b>prac_exams </b>turns out to be <b>-.123.</b>
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Calculate Rolling Correlation in R 
 How to Calculate Autocorrelation in R 
 How to Calculate Partial Correlation in R 
<h2><span class="orange">How to Fix in R: could not find function “ggplot”</span></h2>
One error you may encounter in R is:
<b>Error in ggplot(df, aes(x = x, y = y)) : could not find function "ggplot"
</b>
This error occurs when you attempt to create a plot using the  ggplot2  data visualization package, but have failed to load the package first.
This tutorial explains five potential ways to fix this error.
<h3>How to Reproduce this Error</h3>
Suppose we run the following code in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 4, 5, 7, 8, 9, 10), y=c(12, 17, 27, 39, 50, 57, 66, 80))
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()
Error in ggplot(df, aes(x = x, y = y)) : could not find function "ggplot"
</b>
We receive an error because we haven’t loaded the ggplot2 package in our current R environment.
<h3>Potential Fix #1: Load the ggplot2 Package</h3>
The most common way to fix this error is to simply load the ggplot2 package using the <b>library()</b> function:
<b>library(ggplot2)
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()</b>
In many cases, this will fix the error.
<h3>Potential Fix #2: Install ggplot2</h3>
If fix #1 doesn’t work, you may need to install ggplot2 using the <b>install.packages()</b> function:
<b>#install ggplot2
install.packages("ggplot2")
#load ggplot2
library(ggplot2)
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()
</b>
<h3>Potential Fix #3: Install ggplot2 with Dependencies</h3>
If the previous fixes don’t work, you may need to install ggplot2 and also specify to install any packages that ggplot2 depends on:
<b>#install ggplot2 and all dependencies
install.packages("ggplot2", dependencies=TRUE)
#load ggplot2
library(ggplot2)
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()</b>
<h3>Potential Fix #4: Remove & Re-Install ggplot2</h3>
If the previous fixes don’t work, you may need to remove the current version of ggplot2 completely and re-install it:
<b>#remove ggplot2
remove.packages("ggplot2")
#install ggplot2
install.packages("ggplot2")
#load ggplot2
library(ggplot2)
#create scatterplot of x vs. y
ggplot(df, aes(x=x, y=y)) +
  geom_point()</b>
<h3>Potential Fix #5: Run the Correct Code Chunk</h3>
If none of the previous fixes work, you may need to simply verify that you’re running the correct code chunk in R that actually installs and loads the ggplot2 package.
In many circumstances, you may simply forget to run both lines that install <em>and</em> load ggplot2 in R.
<h2><span class="orange">How to Count Duplicates in R (With Examples)</span></h2>
You can use the following methods to count duplicates in a data frame in R:
<b>Method 1: Count Duplicate Values in One Column</b>
<b>sum(duplicated(df$my_column))
</b>
<b>Method 2: Count Duplicate Rows</b>
<b>nrow(df[duplicated(df), ])</b>
<b>Method 3: Count Duplicates for Each Unique Row</b>
<b>library(dplyr)
df %>% group_by_all() %>% count</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df = data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'),
                position=c('G', 'G', 'G', 'F', 'G', 'G', 'F', 'F'),
                points=c(5, 5, 8, 10, 5, 7, 10, 10))
#view data frame
df
  team position points
1    A        G      5
2    A        G      5
3    A        G      8
4    A        F     10
5    B        G      5
6    B        G      7
7    B        F     10
8    B        F     10
</b>
<h2>Example 1: Count Duplicate Values in One Column</h2>
The following code shows how to count the number of duplicate values in the <b>points</b> column:
<b>#count number of duplicate values in points column
sum(duplicated(df$points))
[1] 4</b>
We can see that there are <b>4</b> duplicate values in the <b>points</b> column.
<h2>Example 2: Count Duplicate Rows</h2>
The following code shows how to count the number of duplicate rows in the data frame:
<b>#count number of duplicate rows
nrow(df[duplicated(df), ])
[1] 2</b>
We can see that there are <b>2</b> duplicate rows in the data frame.
We can use the following syntax to view these 2 duplicate rows:
<b>#display duplicated rows
df[duplicated(df), ]
  team position points
2    A        G      5
8    B        F     10
</b>
<h2>Example 3: Count Duplicates for Each Unique Row</h2>
The following code shows how to count the number of duplicates for each unique row in the data frame:
<b>library(dplyr)
#count number of duplicate rows in data frame
df %>% group_by_all() %>% count
# A tibble: 6 x 4
# Groups:   team, position, points [6]
  team  position points     n
         
1 A     F            10     1
2 A     G             5     2
3 A     G             8     1
4 B     F            10     2
5 B     G             5     1
6 B     G             7     1</b>
The <b>n </b>column displays the number of duplicates for each unique row.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Find Duplicate Elements Using dplyr 
 How to Remove Duplicate Rows in R 
 How to Remove Duplicate Rows in R so None are Left 
<h2><span class="orange">R: Count Number of NA Values in Each Column</span></h2>
You can use the following methods to count the number of NA values in each column of a data frame in R:
<b>Method 1: Count NA Values in Each Column Using Base R</b>
<b>sapply(df, function(x) sum(is.na(x)))
</b>
<b>Method 2: Count NA Values in Each Column Using dplyr</b>
<b>library(dplyr)
df %>% summarise(across(everything(), ~ sum(is.na(.))))</b>
The following examples show how to use each method with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, NA), assists=c(33, NA, NA, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      NA       28
3    C     86      NA       24
4    D     88      39       24
5    E     NA      34       28
</b>
<h2>Example 1: Count NA Values in Each Column Using Base R</h2>
The following code shows how to count the number of NA values in each column using the <b>sapply()</b> function from base R:
<b>#count NA values in each column
sapply(df, function(x) sum(is.na(x)))
    team   points  assists rebounds 
       0        1        2        0 </b>
From the output we can see:
The <b>team</b> column has 0 NA values.
The <b>points</b> column has 1 NA value.
The <b>assists</b> column has 2 NA values.
The <b>rebounds</b> column has 0 NA values.
<b>Note</b>: The <b>sapply()</b> function can be used to apply a function to each column in the data frame. In this example, we apply a function that counts the total number of elements equal to NA.
<h2>Example 2: Count NA Values in Each Column Using dplyr</h2>
The following code shows how to count the number of NA values in each column using the <b>summarise()</b> function from the  dplyr  package:
<b>#count NA values in each column
sapply(df, function(x) sum(is.na(x)))
    team   points  assists rebounds 
       0        1        2        0 </b>
From the output we can see:
The <b>team</b> column has 0 NA values.
The <b>points</b> column has 1 NA value.
The <b>assists</b> column has 2 NA values.
The <b>rebounds</b> column has 0 NA values.
These results match the ones from the previous example.
<b>Note</b>: The dplyr method tends to be faster than the base R method when working with extremely large data frames.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Use na.omit in R 
 How to Use complete.cases in R 
 How to Remove Empty Rows from Data Frame in R 
<h2><span class="orange">How to Count Non-NA Values in R (3 Examples)</span></h2>
You can use the following methods to count non-NA values in R:
<b>Method 1: Count Non-NA Values in Entire Data Frame</b>
<b>sum(!is.na(df))
</b>
<b>Method 2: Count Non-NA Values in Each Column of Data Frame</b>
<b>colSums(!is.na(df))</b>
<b>Method 3: Count Non-NA Values by Group in Data Frame</b>
<b>library(dplyr)
df %>%
  group_by(var1) %>%
  summarise(total_non_na = sum(!is.na(var2)))</b>
The following example shows how to use each of these methods in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(12, NA, 30, 32, 20, 22, 17, NA), rebounds=c(10, 8, 9, 13, NA, 20, 8, 7))
#view data frame
df
  team points rebounds
1    A     12       10
2    A     NA        8
3    A     30        9
4    A     32       13
5    B     20       NA
6    B     22       20
7    B     17        8
8    B     NA        7
</b>
<h3>Method 1: Count Non-NA Values in Entire Data Frame</h3>
The following code shows how to count the total non-NA values in the entire data frame:
<b>#count non-NA values in entire data frame
sum(!is.na(df))
[1] 21</b>
From the output we can see that there are <b>21</b> non-NA values in the entire data frame.
<h3>Method 2: Count Non-NA Values in Each Column of Data Frame</h3>
The following code shows how to count the total non-NA values in each column of the data frame:
<b>#count non-NA values in each column
colSums(!is.na(df))
    team   points rebounds 
       8        6        7
</b>
From the output we can see:
There are <b>8</b> non-NA values in the team column.
There are <b>6</b> non-NA values in the points column.
There are <b>7</b> non-NA values in the rebounds column.
<h3>Method 3: Count Non-NA Values by Group</h3>
The following code shows how to count the total non-NA values in the <b>points</b> column, grouped by the <b>team</b> column:
<b>library(dplyr)
df %>%
  group_by(team) %>%
  summarise(total_non_na = sum(!is.na(points)))
# A tibble: 2 x 2
  team  total_non_na
          
1 A                3
2 B                3
</b>
From the output we can see:
There are <b>3</b> non-NA values in the points column for team A.
There are <b>3</b> non-NA values in the points column for team B.
<h2><span class="orange">How to Count Number of Elements in List in R (With Example)</span></h2>
You can use the following methods to count the number of elements in a list in R:
<b>Method 1: Count Number of Elements in List</b>
<b>length(my_list)</b>
<b>Method 2: Count Number of Elements in Specific Component of List</b>
<b>length(my_list[[3]])</b>
<b>Method 3: Count Number of Elements in Each Component of List</b>
<b>lengths(my_list)</b>
The following examples show how to use each method in practice with the following list in R:
<b>#define list
my_list &lt;- list(x=c(1, 4, 4, 5, 7, 8),
                y='Hey',
                z=factor(c('A', 'B', 'C', 'D')))
#view list
my_list
$x
[1] 1 4 4 5 7 8
$y
[1] "Hey"
$z
[1] A B C D
Levels: A B C D
</b>
<h3>Example 1: Count Number of Elements in List</h3>
We can use the<b> length()</b> function to simply count how many elements are in the list:
<b>#count number of elements in list
length(my_list)
[1] 3
</b>
We can see that there are <b>3</b> elements in the list.
<h3>Example 2: Count Number of Elements in Specific Component of List</h3>
We can use the<b> length()</b> function combined with double brackets to count the number of elements in a  specific component of the list.
For example, we can use the following code to count how many elements are in the third component of the list:
<b>#count number of elements in third component of list
length(my_list[[3]])
[1] 4
</b>
We can see that there are <b>4</b> elements in the third component of the list.
Specifically, the four values are A, B, C, and D.
<h3>Example 3: Count Number of Elements in Each Component of List</h3>
We can use the<b> lengths()</b> function to count the number of elements in each individual component of the list:
<b>#count number of elements in each component of list
lengths(my_list)
x y z 
6 1 4 
</b>
From the output we can see:
x has <b>6</b> elements (1, 4, 4, 5, 7, 8)
y has <b>1</b> element (‘hey’)
z has <b>4</b> elements (‘A’, ‘B’, ‘C’, ‘D’)
Note that we could also use the <b>sum()</b> function with the <b>length()</b> function to count the total number of individual elements in the entire list:
<b>#count total number of individual elements in entire list
sum(lengths(my_list))
[1] 11 </b>
We can see that there are <b>11</b> total elements in the entire list.
<h2><span class="orange">How to Count Number of Occurrences in Columns in R</span></h2>
You can use the following syntax in R to count the number of occurrences of certain values in columns of a data frame:
<b>#count number of occurrences of each value in column
table(df$column_name)
#count number of occurrences of each value (including NA values) in column
table(df$column_name, useNA = 'always')
#count number of occurrences of specific value
length(which(df$column_name==value))
</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'B', 'C', 'D', 'E', 'F'), team=c('Mavs', 'Mavs', 'Suns', 'Nets', 'Nets', 'Nets'), points=c(20, 22, 26, 30, 30, NA))
#view data frame
df
  player team points
1      A Mavs     20
2      B Mavs     22
3      C Suns     26
4      D Nets     30
5      E Nets     30
6      F Nets     NA
</b>
<h3>Example 1: Count Occurrences of Values in Column</h3>
The following code shows how to count the number of occurrences of each value in the ‘team’ column:
<b>#count number of occurrences of each team
table(df$team)
Mavs Nets Suns 
   2    3    1 
</b>
This tells us:
The team name ‘Mavs’ appears 2 times.
The team name ‘Nets’ appears 3 times.
The team name ‘Suns’ appears 1 time.
<h3>Example 2: Count Occurrences of Values in Column (Including NA Values)</h3>
The following code shows how to count the number of occurrences of each value (including NA values) in the ‘points’ column:
<b>#count number of occurrences of each value in 'points', including NA occurrences
table(df$points, useNA = 'always')
  20   22   26   30 &lt;NA>
   1    1    1    2    1 </b>
This tells us:
The value 20 appears 1 time.
The value 22 appears 1 time.
The value 26 appears 1 time.
The value 30 appears 2 times.
The value NA (missing value) appears 1 time.
<h3>Example 3: Count Occurrences of Specific Value in Column</h3>
The following code shows how to count the number of occurrences of the value 30 in the ‘points’ column:
<b>#count number of occurrences of the value 30 in 'points' column
length(which(df$points == 30))
[1] 2</b>
This tells us that the value 30 appears 2 times in the ‘points’ column.
You can also use the following syntax to count the number of occurrences of several different values in the ‘points’ column:
<b>#count number of occurrences of the value 30 or 26 in 'points' column
length(which(df$points == 30 | df$points == 26))
[1] 3</b>
This tells us that the value 30 or 26 appear a total of 3 times in the ‘points’ column.
<h2><span class="orange">R: How to Count TRUE Values in Logical Vector</span></h2>
You can use the following methods to count the number of TRUE values in a logical vector in R:
<b>Method 1: Use sum()</b>
<b>sum(x, na.rm=TRUE)
</b>
This method will return the count of TRUE values in a vector.
<b>Method 2: Use summary()</b>
<b>summary(x)</b>
This method will return the count of TRUE, FALSE, and NA values in a vector.
The following examples show how to use each method in practice.
<h2>Example 1: Count TRUE Values Using sum()</h2>
The following code shows how to use <b>sum()</b> to count the number of TRUE values in a logical vector:
<b>#create logical vector
x &lt;- c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, NA, TRUE)
#count TRUE values in vector
sum(x, na.rm=TRUE)
[1] 3</b>
From the output we can see that there are <b>3</b> TRUE values in the vector.
<b>Note</b>: If there are NA values in the vector and we don’t use the argument <b>na.rm=TRUE</b>, then the function will return NA.
<h2>Example 2: Count TRUE Values Using summary()</h2>
The following code shows how to use <b>summary()</b> to count the number of TRUE, FALSE, and NA values in a logical vector:
<b>#create logical vector
x &lt;- c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, NA, TRUE)
#count TRUE, FALSE, and NA values in vector
summary(x)
   Mode   FALSE    TRUE    NA's 
logical       4       3       1 </b>
From the output we can see:
There are <b>4</b> FALSE values in the vector.
There are <b>3</b> TRUE values in the vector.
There is <b>1</b> NA value in the vector.
The <b>summary()</b> function is particularly useful if you’d like to know the occurrence of each type of value in a logical vector.
If you’d like to only return the number of TRUE values from the<b> summary()</b> function, you can use the following syntax:
<b>#create logical vector
x &lt;- c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, NA, TRUE)
#count TRUE values in vector
summary(x)['TRUE']
TRUE 
   3
</b>
From the output we can see that there are <b>3</b> TRUE values in the vector.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Count Values in Column with Condition in R 
 How to Count Observations by Group in R 
 How to Select Top N Values by Group in R 
<h2><span class="orange">How to Count Unique Values by Group in R (With Examples)</span></h2>
You can use the following methods to count the number of unique values by group in R:
<b>Method 1: Using Base R</b>
<b>results &lt;- aggregate(data=df, values_var~group_var, function(x) length(unique(x)))
</b>
<b>Method 2: Using dplyr</b>
<b>library(dplyr)
results &lt;- df %>%
  group_by(group_var) %>%
  summarize(count = n_distinct(values_var))
</b>
<b>Method 3: Using data.table</b>
<b>library(data.table)
df &lt;- data.table(df)
results &lt;- df[ , .(count = length(unique(values_var))), by = group_var]</b>
Each method returns the exact same result, but the base R method tends to be significantly slower when working with large data frames.
The following examples show how to use each of these methods in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'C', 'C', 'C'), points=c(10, 10, 14, 14, 18, 19, 20, 20, 20))
#view data frame
df
  team points
1    A     10
2    A     10
3    A     14
4    A     14
5    B     18
6    B     19
7    C     20
8    C     20
9    C     20
</b>
<h3>Method 1: Count Unique Values by Group Using Base R</h3>
The following code shows how to count the number of distinct points values for each team using base R:
<b>#count unique points values by team
results &lt;- aggregate(data=df, points~team, function(x) length(unique(x)))
#view results
results
  team points
1    A      2
2    B      2
3    C      1</b>
From the output we can see:
There are <b>2</b> unique points values for team A.
There are <b>2</b> unique points values for team B.
There is <b>1</b> unique points value for team C.
<h3>
<b>Method 2: Count Unique Values by Group Using dplyr</b>
</h3>
The following code shows how to count the number of distinct points values for each team using dplyr:
<b>library(dplyr)
#count unique points values by team
results &lt;- df %>%
  group_by(team) %>%
  summarize(count = n_distinct(points))
#view results
results
# A tibble: 3 x 2
  team  count
1 A         2
2 B         2
3 C         1
</b>
Notice that these results match the ones from the base R method.
<h3>
<b>Method 3: Count Unique Values by Group Using data.table</b>
</h3>
The following code shows how to count the number of distinct points values for each team using data.table:
<b>library(data.table)
#convert data frame to data table
df &lt;- data.table(df)
#count unique points values by team 
results &lt;- df[ , .(count = length(unique(points))), by = team]
#view results
results
   team count
1:    A     2
2:    B     2
3:    C     1
</b>
Notice that these results match the ones from the previous two methods.
<h2><span class="orange">R: How to Count Values in Column with Condition</span></h2>
You can use the following methods to count the number of values in a column of a data frame in R with a specific condition:
<b>Method 1: Count Values in One Column with Condition</b>
<b>nrow(df[df$column1 == 'value1', ])
</b>
<b>Method 2: Count Values in Multiple Columns with Conditions</b>
<b>nrow(df[df$column1 == 'value1' & df$column2 == 'value2', ]) </b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'F', 'G', 'G', 'F', 'F'), points=c(10, 12, 3, 14, 22, 15, 17, 17))
#view data frame
df
  team position points
1    A        G     10
2    A        G     12
3    A        F      3
4    A        F     14
5    B        G     22
6    B        G     15
7    B        F     17
8    B        F     17
</b>
<h2>Example 1: Count Values in One Column with Condition</h2>
The following code shows how to count the number of values in the <b>team</b> column where the value is equal to ‘<b>A</b>‘:
<b>#count number of rows where team is equal to 'B'
nrow(df[df$team == 'B', ])
[1] 4</b>
We can see that there are <b>4</b> values in the <b>team</b> column where the value is equal to ‘B.’
<h2>Example 2: Count Values in Multiple Columns with Conditions</h2>
The following code shows how to count the number of rows in the data frame where the <b>team</b> column is equal to ‘B’ and the <b>position</b> column is equal to ‘F’:
<b>#count number of rows where team is equal to 'B' and position is equal to 'F'
nrow(df[df$team == 'B' & df$position == 'F', ])
[1] 2</b>
We can see there are <b>2</b> rows in the data frame that meet both of these conditions.
We can use similar syntax to count the number of rows that meet any number of conditions we’d like.
For example, the following code shows how to count the number of rows that meet three conditions:
<b>team</b> is equal to ‘B’
<b>position</b> is equal to ‘G’
<b>points</b> is greater than 20
<b>#count rows where team is 'B' and position is 'G' and points > 20
nrow(df[df$team == 'B' & df$position == 'G' & df$points > 20, ])
[1] 1</b>
We can see that only <b>1</b> row in the data frame meets all three of these conditions.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Count Number of Rows in R 
 How to Select Unique Rows in a Data Frame in R 
<h2><span class="orange">How to Create Categorical Variable from Continuous in R</span></h2>
You can use the <b>cut()</b> function in R to create a categorical variable from a continuous one.
This function uses the following basic syntax:
<b>df$cat_variable &lt;- cut(df$continuous_variable,       breaks=c(5, 10, 15, 20, 25),       labels=c('A', 'B', 'C', 'D'))
</b>
Note that <b>breaks</b> specifies the values to split the continuous variable on and <b>labels</b> specifies the label to give to the values of the new categorical variable.
The following example shows how to use this syntax in practice.
<h3>Example: Create Categorical Variable from Continuous in R</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'), points=c(78, 82, 86, 94, 99, 104, 109, 110))
#view data frame
df
  team points
1    A     78
2    B     82
3    C     86
4    D     94
5    E     99
6    F    104
7    G    109
8    H    110
</b>
Currently <b>points</b> is a continuous variable.
We can use the <b>cut()</b> function to cut it into a categorical variable:
<b>#add new column that cuts 'points' into categories
df$cat &lt;- cut(df$points,
              breaks=c(70, 80, 90, 100, 110),
              labels=c('Bad', 'OK', 'Good', 'Great'))
#view updated data frame
df
  team points   cat
1    A     78   Bad
2    B     82    OK
3    C     86    OK
4    D     94  Good
5    E     99  Good
6    F    104 Great
7    G    109 Great
8    H    110 Great</b>
We created a new categorical variable called <b>cat</b> that classifies each team in the data frame as Bad, OK, Good, or Great based on their <b>points</b>.
We can use the <b>class()</b> function to check the class of this new variable:
<b>#check class of 'cat' column
class(df$cat)
[1] "factor"
</b>
We can see that the <b>cat</b> variable is a factor.
We can also use the <b>table()</b> function to count the occurrences of each category in the <b>cat</b> variable:
<b>#count occurrences of each category in 'cat' variable
table(df$cat)
  Bad    OK  Good Great 
    1     2     2     3 </b>
Note that if you don’t provide a <b>labels</b> argument to the <b>cut()</b> function, R will simply use the interval range of values as the labels:
<b>#add new column that cuts 'points' into categories
df$cat &lt;- cut(df$points, breaks=c(70, 80, 90, 100, 110))
#view updated data frame
df
  team points       cat
1    A     78   (70,80]
2    B     82   (80,90]
3    C     86   (80,90]
4    D     94  (90,100]
5    E     99  (90,100]
6    F    104 (100,110]
7    G    109 (100,110]
8    H    110 (100,110]
</b>
In some cases, you may actually prefer this to using custom labels.
<h2><span class="orange">R: Create New Data Frame from Existing Data Frame</span></h2>
There are two common ways to create a new data frame from an existing data frame in R:
<b>Method 1: Select Column Names from Existing Data Frame</b>
<b>new_df &lt;- df[c('var1', 'var3', 'var4')]
</b>
<b>Method 2: Select & Rename Column Names from Existing Data Frame</b>
<b>new_df &lt;- data.frame('new_var1' = df$var1,      'new_var2' = df$var2,      'new_var3' = df$var3)
</b>
The following examples show how to use each method with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), points=c(19, 14, 14, 29, 25, 30), assists=c(4, 5, 5, 4, 12, 10), rebounds=c(9, 7, 7, 6, 10, 11))
#view data frame
df
  team points assists rebounds
1    A     19       4        9
2    A     14       5        7
3    A     14       5        7
4    B     29       4        6
5    B     25      12       10
6    B     30      10       11</b>
<h2>Example 1: Select Column Names from Existing Data Frame</h2>
The following code shows how to create a new data frame by selecting several column names from an existing data frame:
<b>#define new data frame
new_df &lt;- df[c('team', 'assists', 'points')]
#view new data frame
new_df
  team assists points
1    A       4     19
2    A       5     14
3    A       5     14
4    B       4     29
5    B      12     25
6    B      10     30</b>
The new data frame contains three columns (team, assists, points) from the existing data frame.
<h2>Example 2: Select & Rename Column Names from Existing Data Frame</h2>
The following code shows how to create a new data frame by selecting and renaming several columns from an existing data frame:
<b>#define new data frame
new_df &lt;- data.frame('team_name' = df$team,      'total_assists' = df$assists,      'total_points' = df$points)
#view new data frame
new_df
  team_name total_assists total_points
1         A             4           19
2         A             5           14
3         A             5           14
4         B             4           29
5         B            12           25
6         B            10           30</b>
The new data frame contains three columns (team, assists, points) from the existing data frame, but we have specified new names for each of the columns in the new data frame.
This approach is particularly useful if you know ahead of time that you want to rename the columns in the new data frame.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Append Rows to a Data Frame in R 
 How to Keep Certain Columns in R 
 How to Select Only Numeric Columns in R 
<h2><span class="orange">How to Create a Matrix from Vectors in R (With Examples)</span></h2>
You can use one of the following two methods to quickly create a matrix from vectors in R:
<b>Method 1: Use cbind() to bind vectors into matrix by columns</b>
<b>my_matrix &lt;- cbind(vector1, vector2, vector3)
</b>
<b>Method 2: Use rbind() to bind vectors into matrix by rows</b>
<b>my_matrix &lt;- rbind(vector1, vector2, vector3)</b>
The following examples show how to use each method in practice.
<h3>Method 1: Use cbind() to Bind Vectors into Matrix by Columns</h3>
The following code shows how to use <b>cbind()</b> to bind together three vectors into a matrix by columns:
<b>#define vectors
vector1 &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
vector2 &lt;- c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)
vector3 &lt;- c(3, 6, 9, 12, 15, 18, 21, 24, 27, 30)
#column-bind vectors together into matrix
my_matrix &lt;- cbind(vector1, vector2, vector3)
#view resulting matrix
my_matrix
      vector1 vector2 vector3
 [1,]       1       2       3
 [2,]       2       4       6
 [3,]       3       6       9
 [4,]       4       8      12
 [5,]       5      10      15
 [6,]       6      12      18
 [7,]       7      14      21
 [8,]       8      16      24
 [9,]       9      18      27
[10,]      10      20      30
#view dimensions of matrix
dim(my_matrix)
[1] 10  3
</b>
We can see that the result is a matrix with 10 rows and 3 columns, with each of the three original vectors representing a unique column.
<h3>Method 2: Use rbind() to Bind Vectors into Matrix by Rows</h3>
The following code shows how to use <b>rbind()</b> to bind together three vectors into a matrix by columns:
<b>#define vectors
vector1 &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
vector2 &lt;- c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)
vector3 &lt;- c(3, 6, 9, 12, 15, 18, 21, 24, 27, 30)
#row-bind vectors together into matrix
my_matrix &lt;- rbind(vector1, vector2, vector3)
#view resulting matrix
my_matrix
        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
vector1    1    2    3    4    5    6    7    8    9    10
vector2    2    4    6    8   10   12   14   16   18    20
vector3    3    6    9   12   15   18   21   24   27    30
#view dimensions of matrix
dim(my_matrix)
[1]  3 10
</b>
We can see that the result is a matrix with 3 rows and 10 columns, with each of the three original vectors representing a unique row.
<b>Note</b>: In these examples, we chose to bind together three vectors into a matrix, but we can use this exact syntax to bind together any number of vectors we’d like into a matrix.
<h2><span class="orange">How to Calculate Cumulative Sum by Group in R</span></h2>
You can use the following methods to calculate a cumulative sum by group in R:
<b>Method 1: Use Base R</b>
<b>df$cum_sum &lt;- ave(df$values_var, df$group_var, FUN=cumsum)
</b>
<b>Method 2: Use dplyr</b>
<b>library(dplyr)
df %>% group_by(group_var) %>% mutate(cum_sum = cumsum(values_var))
</b>
<b>Method 3: Use data.table</b>
<b>library(data.table)
setDT(df)[, cum_sum := cumsum(values_var), group_var] 
</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(store=rep(c('A', 'B', 'C'), each=4), sales=c(3, 4, 4, 2, 5, 8, 9, 7, 6, 8, 3, 2))
#view data frame
df
   store sales
1      A     3
2      A     4
3      A     4
4      A     2
5      B     5
6      B     8
7      B     9
8      B     7
9      C     6
10     C     8
11     C     3
12     C     2
</b>
<h2>Example 1: Calculate Cumulative Sum by Group Using Base R</h2>
The following code shows how to use the <b>ave()</b> function from base R to calculate the cumulative sum of <b>sales</b>, grouped by <b>store</b>:
<b>#add column to show cumulative sales by store
df$cum_sales &lt;- ave(df$sales, df$store, FUN=cumsum)
#view updated data frame
df
   store sales cum_sales
1      A     3         3
2      A     4         7
3      A     4        11
4      A     2        13
5      B     5         5
6      B     8        13
7      B     9        22
8      B     7        29
9      C     6         6
10     C     8        14
11     C     3        17
12     C     2        19</b>
The new column called <b>cum_sales</b> displays the cumulative sum of <b>sales</b>, grouped by <b>store</b>.
<h2>Example 2: Calculate Cumulative Sum by Group Using dplyr</h2>
The following code shows how to use various functions from the dplyr package in R to calculate the cumulative sum of <b>sales</b>, grouped by <b>store</b>:
<b>library(dplyr)
#add column to show cumulative sales by store
df %>% group_by(store) %>% mutate(cum_sales = cumsum(sales))
#view updated data frame
df
# A tibble: 12 x 3
# Groups:   store [3]
   store sales cum_sales
         
 1 A         3         3
 2 A         4         7
 3 A         4        11
 4 A         2        13
 5 B         5         5
 6 B         8        13
 7 B         9        22
 8 B         7        29
 9 C         6         6
10 C         8        14
11 C         3        17
12 C         2        19
</b>
The new column called <b>cum_sales</b> displays the cumulative sum of <b>sales</b>, grouped by <b>store</b>.
<h2>Example 3: Calculate Cumulative Sum by Group Using data.table</h2>
The following code shows how to use various functions from the data.table package in R to calculate the cumulative sum of <b>sales</b>, grouped by <b>store</b>:
<b>library(data.table)
#add column to show cumulative sales by store
setDT(df)[, cum_sales := cumsum(sales), store] 
#view updated data frame
df
    store sales cum_sales
 1:     A     3         3
 2:     A     4         7
 3:     A     4        11
 4:     A     2        13
 5:     B     5         5
 6:     B     8        13
 7:     B     9        22
 8:     B     7        29
 9:     C     6         6
10:     C     8        14
11:     C     3        17
12:     C     2        19</b>
The new column called <b>cum_sales</b> displays the cumulative sum of <b>sales</b>, grouped by <b>store</b>.
<b>Note</b>: All three methods produce the same result. However, the dplyr and data.table methods will tend to be quicker when working with extremely large data frames.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common calculations in R:
 How to Calculate the Sum by Group in R 
 How to Calculate the Mean by Group in R 
 How to Calculate Standard Deviation by Group in R 
<h2><span class="orange">How to Set Data Frame Column as Index in R (With Example)</span></h2>
Data frames in R do not have an “index” column like data frames in pandas might.
However, data frames in R do have <b>row names</b>, which act similar to an index column.
You can use one of the following methods to set an existing data frame column as the row names for a data frame in R:
<b>Method 1: Set Row Names Using Base R</b>
<b>#set specific column as row names
rownames(df) &lt;- df$my_column
#remove original column from data frame
df$my_column &lt;- NULL</b>
<b>Method 2: Set Row Names Using Tidyverse Package</b>
<b>library(tidyverse)
#set specific column as row names
df &lt;- df %>% column_to_rownames(., var = 'my_column')
</b>
<b>Method 3: Set Row Names When Importing Data</b>
<b>#import CSV file and specify column to use as row names
df &lt;- read.csv('my_data.csv', row.names='my_column')</b>
The following examples show how to use each method in practice.
<h3>Example 1: Set Row Names Using Base R</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(ID=c(101, 102, 103, 104, 105), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
   ID points assists rebounds
1 101     99      33       30
2 102     90      28       28
3 103     86      31       24
4 104     88      39       24
5 105     95      34       28</b>
We can use the following code to set the ID column as the row names:
<b>#set ID column as row names
rownames(df) &lt;- df$ID
#remove original ID column from data frame
df$ID &lt;- NULL
#view updated data frame
df
    points assists rebounds
101     99      33       30
102     90      28       28
103     86      31       24
104     88      39       24
105     95      34       28
</b>
The values from the ID column are now the row names for the data frame.
<h3>Example 2: Set Row Names Using Tidyverse Package</h3>
The following code shows how to use the <b>column_to_rownames()</b> function from the <b>tidyverse</b> package to set the row names equal to the ID column in the data frame:
<b>library(tidyverse)
#create data frame
df &lt;- data.frame(ID=c(101, 102, 103, 104, 105), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#set ID column as row names
df &lt;- df %>% column_to_rownames(., var = 'ID')
#view updated data frame
df
    points assists rebounds
101     99      33       30
102     90      28       28
103     86      31       24
104     88      39       24
105     95      34       28
</b>
Notice that this result matches the one from the previous example.
<h3>Example 3: Set Row Names When Importing Data</h3>
Suppose we have the following CSV file called <b>my_data.csv</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/indexcol1.jpg"496">
We can use the following code to import the CSV file and set the row names to be equal to the ID column when importing:
<b>#import CSV file and specify ID column to use as row names
df &lt;- read.csv('my_data.csv', row.names='ID')
#view data frame
df
    points assists rebounds
101     99      33       30
102     90      28       28
103     86      31       24
104     88      39       24
105     95      34       28
</b>
Notice that the values from the ID column are used as the row names in the data frame.
<h2><span class="orange">The Complete Guide to Date Formats in R</span></h2>
The following table shows a variety of symbols that you can use to format dates in R:
<table><tbody>
<tr>
<th style="text-align: center;"><b>Symbol</b></th>
<th style="text-align: center;"><b>Definition</b></th>
<th style="text-align: center;"><b>Example</b></th>
</tr>
<tr>
<td style="text-align: center;"><b>%d</b></td>
<td style="text-align: center;">Day as a number</td>
<td style="text-align: center;">19</td>
</tr>
<tr>
<td style="text-align: center;"><b>%a</b></td>
<td style="text-align: center;">Abbreviated weekday</td>
<td style="text-align: center;">Sun</td>
</tr>
<tr>
<td style="text-align: center;"><b>%A</b></td>
<td style="text-align: center;">Unabbreviated weekday</td>
<td style="text-align: center;">Sunday</td>
</tr>
<tr>
<td style="text-align: center;"><b>%m</b></td>
<td style="text-align: center;">Month as a number</td>
<td style="text-align: center;">04</td>
</tr>
<tr>
<td style="text-align: center;"><b>%b</b></td>
<td style="text-align: center;">Abbreviated month</td>
<td style="text-align: center;">Feb</td>
</tr>
<tr>
<td style="text-align: center;"><b>%B</b></td>
<td style="text-align: center;">Unabbreviated month</td>
<td style="text-align: center;">February</td>
</tr>
<tr>
<td style="text-align: center;"><b>%y</b></td>
<td style="text-align: center;">2-digit year</td>
<td style="text-align: center;">14</td>
</tr>
<tr>
<td style="text-align: center;"><b>%Y</b></td>
<td style="text-align: center;">4-digit year</td>
<td style="text-align: center;">2014</td>
</tr>
</tbody></table>
The following examples show how to use each of these formats in practice.
<h3>Example 1: Format Date with Day, Month, Year</h3>
The following code shows how to format a date using a month/day/year format:
<b>#define date
date &lt;- as.Date("2021-01-25")
#format date
formatted_date &lt;- format(date, format="%m/%d/%y")
#display formatted date
formatted_date
[1] "01/25/21"</b>
Note that we can use whatever separators we’d like in between each value.
For example, we could use dashes instead:
<b>#define date
date &lt;- as.Date("2021-01-25")
#format date
formatted_date &lt;- format(date, format="%m-%d-%y")
#display formatted date
formatted_date
[1] "01-25-21"</b>
<h3>Example 2: Format Date as Weekday</h3>
The following code shows how to format a date using a weekday format:
<b>#define date
date &lt;- as.Date("2021-01-25")
#format date as abbreviated weekday
format(date, format="%a")
[1] "Mon"
#format date as unabbreviated weekday
format(date, format="%A")
[1] "Monday"
</b>
<h3>Example 3: Format Date as Month</h3>
The following code shows how to format a date as a month:
<b>#define date
date &lt;- as.Date("2021-01-25")
#format date as abbreviated month
format(date, format="%b")
[1] "Jan"
#format date as unabbreviated month
format(date, format="%B")
[1] "January"</b>
We can also format the date as a month and a day:
<b>#define date
date &lt;- as.Date("2021-01-25")
#format date as abbreviated month
format(date, format="%b %d")
[1] "Jan 25"</b>
<h2><span class="orange">How to Find Day of the Week in R (With Examples)</span></h2>
You can use the following functions from the  lubridate  package in R to quickly find the day of the week:
<b>Method 1: Find Numeric Day of Week (Assuming Week Starts on Sunday)</b>
<b>wday(df$date_column)
</b>
<b>Method 2: Find Numeric Day of Week (Assuming Week Starts on Monday)</b>
<b>wday(df$date_column, week_start=1)</b>
<b>Method 3: Find Character Day of Week (Using Abbreviated Labels)</b>
<b>wday(df$date_column, label=TRUE)</b>
<b>Method 4: Find Character Day of Week (Using Full Weekday Labels)</b>
<b>wday(df$date_column, label=TRUE, abbr=FALSE)</b>
The following examples show how to use each method in practice with the following data frame:
<b>library(lubridate)
#create data frame
df &lt;- data.frame(date=c('2020-10-11', '2020-10-19', '2020-10-31'), sales=c(435, 768, 945))
#view data frame
df
        date sales
1 2020-10-11   435
2 2020-10-19   768
3 2020-10-31   945</b>
<h3>Method 1: Find Numeric Day of Week (Assuming Week Starts on Sunday)</h3>
The following code shows how to find the numeric day of the week of the values in the ‘date’ column:
<b>#find day of week
df$weekday &lt;- wday(df$date)
#view updated data frame
df
        date sales weekday
1 2020-10-11   435       1
2 2020-10-19   768       2
3 2020-10-31   945       7
</b>
Note that <b>1</b> indicates a Sunday, <b>2</b> indicates a Monday, and so on.
<h3>Method 2: Find Numeric Day of Week (Assuming Week Starts on Monday)</h3>
The following code shows how to find the numeric day of the week (assuming a week starts on Monday) of the values in the ‘date’ column:
<b>#find day of week
df$weekday &lt;- wday(df$date, week_start=1)
#view updated data frame
df
        date sales weekday
1 2020-10-11   435       7
2 2020-10-19   768       1
3 2020-10-31   945       6
</b>
In this scenario, a <b>1</b> indicates a Monday, <b>2</b> indicates a Tuesday, and so on.
<h3>Method 3: Find Character Day of Week (Using Abbreviated Labels)</h3>
The following code shows how to find the abbreviated character day of the week of the values in the ‘date’ column:
<b>#find day of week
df$weekday &lt;- wday(df$date, label=TRUE)
#view updated data frame
df
        date sales weekday
1 2020-10-11   435     Sun
2 2020-10-19   768     Mon
3 2020-10-31   945     Sat
</b>
<h3>Method 4: Find Character Day of Week (Using Full Weekday Labels)</h3>
The following code shows how to find the character day of the week (using full weekday labels) of the values in the ‘date’ column:
<b>#find day of week
df$weekday &lt;- wday(df$date, label=TRUE, abbr=FALSE)
#view updated data frame
df
        date sales  weekday
1 2020-10-11   435   Sunday
2 2020-10-19   768   Monday
3 2020-10-31   945 Saturday</b>
<b>Note</b>: You can find the complete documentation for the lubridate <b>wday()</b> function  here .
<h2><span class="orange">How to Calculate Difference Between Rows in R</span></h2>
You can use the <b>diff()</b> function to calculate the difference between rows of a data frame in R:
<b>#find difference between rows in every column of data frame
diff(as.matrix(df))
#find difference between rows of specific column
diff(df$column_name)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Find Difference Between Rows of Every Column</h3>
The following code shows how to calculate the difference between rows for every column in a data frame:
<b>#create data frame
df &lt;- data.frame(day=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales=c(7, 8, 8, 12, 10, 9, 13, 16, 11, 7))
#view data frame
df
   day sales
1    1     7
2    2     8
3    3     8
4    4    12
5    5    10
6    6     9
7    7    13
8    8    16
9    9    11
10  10     7
#calculate difference between rows for each column
diff(as.matrix(df))
      day sales
 [1,]   1     1
 [2,]   1     0
 [3,]   1     4
 [4,]   1    -2
 [5,]   1    -1
 [6,]   1     4
 [7,]   1     3
 [8,]   1    -5
 [9,]   1    -4
</b>
<h3>Example 2: Find Difference Between Rows of Specific Column</h3>
The following code shows how to calculate the difference between rows for a specific column in a data frame:
<b>#create data frame
df &lt;- data.frame(day=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales=c(7, 8, 8, 12, 10, 9, 13, 16, 11, 7))
#calculate difference between rows in 'sales' column
diff(df$sales)
[1]  1  0  4 -2 -1  4  3 -5 -4
</b>
<h3>Example 3: Find Difference Between Rows & Append New Column</h3>
The following code shows how to calculate the difference between rows for a specific column in a data frame and then append those differences as a new column at the end of the data frame:
<b>#create data frame
df &lt;- data.frame(day=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), sales=c(7, 8, 8, 12, 10, 9, 13, 16, 11, 7))
#calculate difference between rows in 'sales' column
sales_diff &lt;- diff(df$sales)
#append NA to beginning of differences vector
sales_diff &lt;- c(NA, sales_diff)
#append differences vector as new column
df$sales_diff &lt;- sales_diff
#view updated data frame
df
   day sales sales_diff
1    1     7         NA
2    2     8          1
3    3     8          0
4    4    12          4
5    5    10         -2
6    6     9         -1
7    7    13          4
8    8    16          3
9    9    11         -5
10  10     7         -4</b>
<h2><span class="orange">How to Use difftime in R to Calculate Time Differences</span></h2>
You can use the <b>difftime()</b> function to calculate the time difference between two dates or datetimes in R.
This function uses the following basic syntax:
<b>difftime(time1, time2, units="days")
</b>
where:
<b>time1, time2</b>: The two dates or datetimes
<b>units</b>: The units to use for time difference (default is “days”, but other options include “secs”, “mins”, “hours”, and “weeks”)
The following examples show how to use the <b>difftime()</b> function in different scenarios.
<h3>Example 1: Use difftime() to Calculate Time Difference in Various Units</h3>
The following code shows how to use the <b>difftime()</b> function to calculate the time difference between two datetimes using various units:
<b>#define two datetimes
first &lt;- "2022-08-20 08:15:22"
second &lt;- "2022-01-01 20:04:48"
#calculate time difference in days
difftime(first, second)
Time difference of 230.5073 days
#calculate time difference in seconds
difftime(first, second, units="secs")
Time difference of 19915834 secs
#calculate time difference in minutes
difftime(first, second, units="mins")
Time difference of 331930.6 mins
#calculate time difference in hours
difftime(first, second, units="hours")
Time difference of 5532.176 hours
#calculate time difference in weeks
difftime(first, second, units="weeks")
Time difference of 32.92962 weeks
</b>
By using the <b>units</b> argument, we can calculate the time difference between the two datetimes in different units.
<h3>Example 2: Calculate Time Difference in HH:MM:SS Format</h3>
We can also use the <b>as_hms()</b> function from the <b>hms</b> library to calculate the time difference between two datetimes, formatted as HH:MM:SS.
<b>library(hms)
#define two datetimes
first &lt;- "2022-01-01 20:15:22"
second &lt;- "2022-01-01 08:04:48"
#calculate difference between datetimes in hours, minutes, seconds
as_hms(difftime(first, second))
12:10:34</b>
The output shows the time difference between the two datetimes, formatted in terms of hours, minutes, and seconds.
In this scenario, the difference between the two times is <b>12</b> hours, <b>10</b> minutes, and <b>34</b> seconds.
<h2><span class="orange">How to Use the dim() Function in R</span></h2>
The <b>dim()</b> function in R can be used to either get or set the dimensions of an array, matrix or data frame.
The following examples show how to use this function in practice.
<h3>Example 1: Use dim() to Get Dimensions of Data Frame</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      28       28
3    C     86      31       24
4    D     88      39       24
5    E     95      34       28</b>
We can use the <b>dim()</b> function to retrieve the number of rows and columns in the data frame:
<b>#get dimensions of data frame
dim(df)
[1] 5 4
</b>
From the output we can see that the data frame has <b>5</b> rows and <b>4</b> columns.
<h3>
<b>Example 2: Use dim() to Get Dimensions of Matrix</b>
</h3>
Suppose we have the following matrix in R:
<b>#create matrix
mat &lt;- matrix(c(1, 4, 4, 8, 5, 4, 3, 8), nrow=4)
#view matrix
mat
     [,1] [,2]
[1,]    1    5
[2,]    4    4
[3,]    4    3
[4,]    8    8
</b>
We can use the <b>dim()</b> function to retrieve the number of rows and columns in the matrix:
<b>#get dimensions of matrix
dim(mat)
[1] 4 2
</b>
From the output we can see that the matrix has <b>4</b> rows and <b>2</b> columns.
<h3>
<b>Example 3: Use dim() to Set Dimensions of Matrix</b>
</h3>
We can also use <b>dim()</b> to set the dimensions of a matrix:
<b>#create vector of values
x &lt;- c(1, 4, 4, 8, 5, 4, 3, 8)
#define dimensions for values 
dim(x) &lt;- c(4, 2)
#view result
x
     [,1] [,2]
[1,]    1    5
[2,]    4    4
[3,]    4    3
[4,]    8    8
#view class
class(x)
[1] "matrix" "array" 
</b>
The result is a matrix (and an array) with <b>4</b> rows and <b>2</b> columns.
<h3>
<b>Example 4: Use dim() to Get One Dimension</b>
</h3>
We can also use <b>dim(x)[1]</b> and <b>dim(x)[2]</b> to retrieve just the number of rows or just the number of columns of an object.
For example, suppose we have the following matrix: 
<b>#create matrix
x &lt;- matrix(c(1, 4, 4, 8, 5, 4, 3, 8), nrow=4)
#view matrix
x
     [,1] [,2]
[1,]    1    5
[2,]    4    4
[3,]    4    3
[4,]    8    8</b>
We can use <b>dim(x)[1]</b> to only get the number of rows:
<b>#display number of rows in matrix
dim(x)[1]
[1] 4
</b>
And we can use <b>dim(x)[2]</b> to only get the number of columns:
<b>#display number of columns in matrix
dim(x)[2]
[1] 2
</b>
<h2><span class="orange">How to Fix in R: Don’t know how to automatically pick scale for object of type function</span></h2>
One error you may encounter in R is:
<b>Don't know how to automatically pick scale for object of type function.
  Defaulting to continuous. 
</b>
This error occurs when you attempt to create a plot using <b>ggplot2</b> but provide the name of a built-in R function (such as mean, median, max, sample, range, etc.) to the <b>aes()</b> argument.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we have the following data frame in R that shows the mean number of points scored by players on different basketball teams:
<b>#create data frame
df &lt;- data.frame(Team=c('A', 'B', 'C', 'D'), Mean=c(12, 22, 30, 31))
#view data frame
df
  Team Mean
1    A   12
2    B   22
3    C   30
4    D   31
</b>
Now suppose we attempt to create a bar plot to visualize this data using ggplot2:
<b>library(ggplot2)
#attempt to create bar plot
ggplot(df, aes(Team, mean)) +
  geom_bar(stat='identity')
Don't know how to automatically pick scale for object of type function.
  Defaulting to continuous.
</b>
We receive an error because we used <b>mean</b> within the <b>aes()</b> argument, which is the name of a default function in R.
<h2>How to Fix the Error</h2>
The way to fix this error is to simply spell the variable name exactly as it is spelled in our data frame: <b>Mean</b>.
When we spell the variable name this way, we don’t receive any error when creating the bar plot:
<b>library(ggplot2)
#create bar plot
ggplot(df, aes(Team, Mean)) +
  geom_bar(stat='identity')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/statbar.jpg"460">
Notice that we’re able to create the bar plot successfully without any error this time.
<h2><span class="orange">How to Use dplyr transmute Function in R (With Examples)</span></h2>
You can use the <b>transmute() </b>function in R to add new calculated variables to a data frame and drop all existing variables.
This function uses the following basic syntax:
<b>df %>% transmute(var_new = var1 * 2)
</b>
In this example, a new variable called <b>var_new</b> will be created by multiplying an existing variable called <b>var1</b> by 2.
The following examples show how to use the <b>transmute()</b> function with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    B     90      28       28
3    C     86      31       24
4    D     88      39       24
5    E     95      34       28
</b>
<h3>Example 1: Use transmute() to Create One New Variable</h3>
The following code shows how to use <b>transmute()</b> to create one new variable:
<b>library(dplyr)
#create new variable called points2
df %>% transmute(points2 = points * 2)
  points2
1     198
2     180
3     172
4     176
5     190</b>
The values of <b>points2</b> are equal to the original values in the points column multiplied by two.
Note that the <b>transmute()</b> function doesn’t actually modify the original data frame.
To save the results of the <b>transmute()</b> function in a new data frame, you must store them in a variable:
<b>library(dplyr)
#store results of transmute in variable
df_points2 &lt;- df %>% transmute(points2 = points * 2)
#view results
df_points2
  points2
1     198
2     180
3     172
4     176
5     190</b>
The results of <b>transmute()</b> are now stored in a new data frame.
<h3>Example 2: Use transmute() to Create Multiple New Variables</h3>
The following code shows how to use <b>transmute()</b> to create multiple new variables from existing variables:
<b>library(dplyr)
#create multiple new variables
df %>%
 transmute(
  points2 = points * 2,
  rebounds_squared = rebounds^2,
  assists_half = assists / 2,
  team_name= paste0('team_', team)
)
  points2 rebounds_squared assists_half team_name
1     198              900         16.5    team_A
2     180              784         14.0    team_B
3     172              576         15.5    team_C
4     176              576         19.5    team_D
5     190              784         17.0    team_E
</b>
Notice that four new variables have been created.
<h2><span class="orange">How to Drop Columns from Data Frame in R (With Examples)</span></h2>
The easiest way to drop columns from a data frame in R is to use the <b>subset()</b> function, which uses the following basic syntax:
<b>#remove columns var1 and var3
new_df &lt;- subset(df, select = -c(var1, var3))</b>
The following examples show how to use this function in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(var1=c(1, 3, 3, 4, 5), var2=c(7, 7, 8, 3, 2), var3=c(3, 3, 6, 10, 12), var4=c(14, 16, 22, 19, 18))
#view data frame
df
  var1 var2 var3 var4
1    1    7    3   14
2    3    7    3   16
3    3    8    6   22
4    4    3   10   19
5    5    2   12   18</b>
<h3>Example 1: Drop Columns by Name</h3>
The following code shows how to drop columns from the data frame by name:
<b>#remove columns var1 and var3
new_df &lt;- subset(df, select = -c(var1, var3))
#view updated data frame
new_df
  var2 var4
1    7   14
2    7   16
3    8   22
4    3   19
5    2   18
</b>
<h3>Example 2: Drop Columns by Index</h3>
The following code shows how to drop columns from the data frame by index:
<b>#remove first and fourth columns
new_df &lt;- subset(df, select = -c(1, 4))
#view updated data frame
new_df
  var2 var3
1    7    3
2    7    3
3    8    6
4    3   10
5    2   12</b>
<h3>Example 3: Drop Columns in List</h3>
The following code shows how to drop columns from the data frame that belong to a certain list:
<b>#define list of columns to remove
remove_cols &lt;- c('var1', 'var4')
#remove columns in list
new_df = subset(df, select = !(names(df) %in% remove_cols)) 
#view updated data frame
new_df
  var2 var3
1    7    3
2    7    3
3    8    6
4    3   10
5    2   12</b>
<h3>Example 4: Drop Columns in Range</h3>
The following code shows how to drop columns from the data frame in a certain range:
<b>#remove columns in range of 1 to 3
new_df = subset(df, select = -c(1:3)) 
#view updated data frame
new_df
  var4
1   14
2   16
3   22
4   19
5   18</b>
<h2><span class="orange">How to Drop Columns by Name in R (With Examples)</span></h2>
There are three common ways to drop columns from a data frame in R by name:
<b>Method 1: Use Base R</b>
<b>#drop col2 and col4 from data frame
df_new &lt;- subset(df, select = -c(col2, col4))
</b>
<b>Method 2: Use dplyr</b>
<b>library(dplyr)
#drop col2 and col4 from data frame
df_new &lt;- df %>% select(-c(col2, col4))
</b>
<b>Method 3: Use data.table</b>
<b>library(data.table)
#convert data frame to data table
dt &lt;- setDT(df)
#drop col2 and col4 from data frame
dt[, c('col2', 'col4'):=NULL]
</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'C', 'D'), points=c(12, 15, 22, 29, 35, 24, 11, 24), rebounds=c(10, 4, 4, 15, 14, 9, 12, 8), assists=c(7, 7, 5, 8, 19, 14, 11, 10))
#view data frame
df
  team points rebounds assists
1    A     12       10       7
2    A     15        4       7
3    B     22        4       5
4    B     29       15       8
5    C     35       14      19
6    C     24        9      14
7    C     11       12      11
8    D     24        8      10
</b>
<h2>Example 1: Drop Columns by Name Using Base R</h2>
The following code shows how to drop the <b>points</b> and <b>assists</b> columns from the data frame by using the <b>subset()</b> function in base R:
<b>#create new data frame by dropping points and assists columns
df_new &lt;- subset(df, select = -c(points, assists))
#view new data frame
df_new
  team rebounds
1    A       10
2    A        4
3    B        4
4    B       15
5    C       14
6    C        9
7    C       12
8    D        8
</b>
Notice that the <b>points</b> and <b>assists</b> columns have both been dropped from the new data frame.
<h2>Example 2: Drop Columns by Name Using dplyr</h2>
The following code shows how to drop the <b>points</b> and <b>assists</b> columns from the data frame by using the <b>select()</b> function in the dplyr package:
<b>library(dplyr)
#create new data frame by dropping points and assists columns
df_new &lt;- df %>% select(-c(points, assists))
#view new data frame
df_new
  team rebounds
1    A       10
2    A        4
3    B        4
4    B       15
5    C       14
6    C        9
7    C       12
8    D        8</b>
Notice that the <b>points</b> and <b>assists</b> columns have both been dropped from the new data frame.
<h2>Example 3: Drop Columns by Name Using data.table</h2>
The following code shows how to drop the <b>points</b> and <b>assists</b> columns from the data frame by setting both columns equal to NULL using the data.table package:
<b>library(data.table)
#convert data frame to data table
dt &lt;- setDT(df)
#drop points and assists columns
dt[, c('points', 'assists'):=NULL]
#view updated data table
dt
   team rebounds
1:    A       10
2:    A        4
3:    B        4
4:    B       15
5:    C       14
6:    C        9
7:    C       12
8:    D        8
</b>
Notice that the <b>points</b> and <b>assists</b> columns have both been dropped from the new data table.
<b>Note</b>: All three methods produce the same result, but the <b>dplyr</b> and <b>data.table</b> methods will tend to be faster when working with extremely large datasets.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Remove Columns with NA Values in R 
 How to Reorder Columns in R 
 How to Rename Columns in R 
<h2><span class="orange">R: How to Drop Rows that Contain a Specific String</span></h2>
You can use the following syntax to drop rows that contain a certain string in a data frame in R:
<b>df[!grepl('string', df$column),]
</b>
This tutorial provides several examples of how to use this syntax in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'C'), conference=c('East', 'East', 'East', 'West', 'West', 'East'), points=c(11, 8, 10, 6, 6, 5))
#view data frame
df
  team conference points
1    A       East     11
2    A       East      8
3    A       East     10
4    B       West      6
5    B       West      6
6    C       East      5
</b>
<h3>Example 1: Drop Rows that Contain a Specific String</h3>
The following code shows how to drop all rows in the data frame that contain ‘A’ in the team column:
<b>df[!grepl('A', df$team),]
  team conference points
4    B       West      6
5    B       West      6
6    C       East      5
</b>
Or we could drop all rows in the data frame that contain ‘West’ in the conference column:
<b>df[!grepl('West', df$conference),]
  team conference points
1    A       East     11
2    A       East      8
3    A       East     10
6    C       East      5</b>
<h3>Example 2: Drop Rows that Contain a String in a List</h3>
The following code shows how to drop all rows in the data frame that contain ‘A’ or ‘B’ in the team column:
<b>df[!grepl('A|B', df$team),]
6    C       East      5
</b>
We could also define a vector of strings and then remove all rows in the data frame that contain any of the strings in the vector in the team column:
<b>#define vector of strings
remove &lt;- c('A', 'B')
#remove rows that contain any string in the vector in the team column
df[!grepl(paste(remove, collapse='|'), df$team),]
6    C       East      5</b>
Notice that both methods lead to the same result.
<h2><span class="orange">How to Fix in R: duplicate ‘row.names’ are not allowed</span></h2>
One error you may encounter in R is:
<b>Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  duplicate 'row.names' are not allowed 
</b>
This error usually occurs when you attempt to read a CSV file into R that contains commas at the end of every row in the file <em>except</em> the header row.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following CSV file called <b>my_data.csv</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/duplicaterow1.jpg"492">
Notice that there are commas at the end of every row in the file <em>except</em> the header row.
Now suppose we attempt to import this file into R:
<b>#attempt to import CSV into data frame
df &lt;- read.csv('my_data.csv')
Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  duplicate 'row.names' are not allowed
</b>
We receive an error because there are commas at the end of every row in the file <em>except</em> the header row, which causes R to think that the first column of values are the row names.
Since two of the rows have the same starting value (4), R thinks that there are duplicate row names.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply use <b>row.names=NULL</b> when importing the file:
<b>#import CSV file into data frame
df &lt;- read.csv('my_data.csv', row.names=NULL)
#view data frame
df
  row.names column1 column2 column3
1         4       5       7      NA
2         4       2       1      NA
3         7       9       0      NA
</b>
We are able to successfully import the CSV file, but the column names are off.
To fix this, we can modify the column names and then drop the last column:
<b>#modify column names
colnames(df) &lt;- colnames(df)[2:ncol(df)]
#drop last column
df &lt;- df[1:(ncol(df)-1)]
#view updated data frame
df
  column1 column2 column3
1       4       5       7
2       4       2       1
3       7       9       0</b>
The data frame is now in the correct format.
<b>Related:</b>  How to Use ncol Function in R 
<h2><span class="orange">How to Fix: attempt to set ‘colnames’ on an object with less than two dimensions</span></h2>
One error message you may encounter when using R is:
<b>Error in `colnames&lt;-`(`*tmp*`, value = c("var1", "var2", "var3")) : 
  attempt to set 'colnames' on an object with less than two dimensions
</b>
This error usually occurs when you attempt to use the <b>colnames()</b> function to set the column names on an object that is not a data frame or matrix.
The following example shows how to resolve this error in practice.
<h2>How to Reproduce the Error</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'C', 'B', 'C', 'B', 'B', 'C', 'A'), points=c(12, 8, 26, 25, 38, 30, 24, 24, 15), rebounds=c(10, 4, 5, 5, 4, 3, 8, 18, 22))
#view data frame
df
  team points rebounds
1    A     12       10
2    A      8        4
3    C     26        5
4    B     25        5
5    C     38        4
6    B     30        3
7    B     24        8
8    C     24       18
9    A     15       22
</b>
Now suppose we attempt to add a new row to the end of the data frame:
<b>#define new row to add to end of data frame
new_row &lt;- c('D', 15, 11)
#attempt to define column names for new row
colnames(new_row) &lt;- colnames(df)
Error in `colnames&lt;-`(`*tmp*`, value = c("team", "points", "rebounds")) : 
  attempt to set 'colnames' on an object with less than two dimensions
</b>
We receive an error because we used the <b>colnames()</b> function on a vector instead of a data frame or matrix.
<h2>How to Fix the Error</h2>
To avoid this error, we need to make sure that we’re using the <b>colnames()</b> function with a data frame:
For example, we can use the following code to add a new row to the end of the data frame
<b>#define new row to add to end of data frame
new_row &lt;- data.frame('D', 15, 11)
#define column names for new row
colnames(new_row) &lt;- colnames(df)
#add new row to end of data frame
df &lt;- rbind(df, new_row)
#view updated data frame
df
   team points rebounds
1     A     12       10
2     A      8        4
3     C     26        5
4     B     25        5
5     C     38        4
6     B     30        3
7     B     24        8
8     C     24       18
9     A     15       22
10    D     15       11
</b>
This time we don’t receive any error because we used the<b> colnames()</b> function to define the column names of a data frame instead of a vector.
We’re then able to successfully use  rbind()  to bind the new row to the end of the existing data frame.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in R:
 How to Fix in R: Arguments imply differing number of rows 
 How to Fix in R: error in select unused arguments 
 How to Fix in R: replacement has length zero 
<h2><span class="orange">How to Fix: Error in colMeans(x, na.rm = TRUE) : ‘x’ must be numeric</span></h2>
One error message you may encounter when using R is:
<b>Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
</b>
This error usually occurs when you attempt to use the <b>prcomp()</b> function to perform  principal components analysis in R , yet one or more of the columns in the data frame you’re using is not numeric.
There are two ways to get around this error:
<b>Method 1:</b> Convert Non-Numeric Columns to Numeric
<b>Method 2:</b> Remove Non-Numeric Columns from Data Frame
The following examples show how to use each method in practice.
<h2>How to Reproduce the Error</h2>
Suppose we attempt to perform principal components analysis on the following data frame that contains a character column:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'C', 'B', 'C', 'B', 'B', 'C', 'A'), points=c(12, 8, 26, 25, 38, 30, 24, 24, 15), rebounds=c(10, 4, 5, 5, 4, 3, 8, 18, 22))
#view data frame
df
  team points rebounds
1    A     12       10
2    A      8        4
3    C     26        5
4    B     25        5
5    C     38        4
6    B     30        3
7    B     24        8
8    C     24       18
9    A     15       22
#attempt to calculate principal components
prcomp(df)
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
</b>
The <b>team</b> column is a character column, which causes an error when we attempt to use the <b>prcomp()</b> function.
<h2>Method 1: Convert Non-Numeric Columns to Numeric</h2>
One way to avoid the error is to convert the <b>team</b> column to a numeric column before using the <b>prcomp()</b> function:
<b>#convert character column to numeric
df$team &lt;- as.numeric(as.factor(df$team))
#view updated data frame
df
  team points rebounds
1    1     12       10
2    1      8        4
3    3     26        5
4    2     25        5
5    3     38        4
6    2     30        3
7    2     24        8
8    3     24       18
9    1     15       22
#calculate principal components
prcomp(df)
Standard deviations (1, .., p=3):
[1] 9.8252704 6.0990235 0.4880538
Rotation (n x k) = (3 x 3): PC1        PC2         PC3
team     -0.06810285 0.04199272  0.99679417
points   -0.91850806 0.38741460 -0.07907512
rebounds  0.38949319 0.92094872 -0.01218661</b>
This time we don’t receive any error because each column in the data frame is numeric.
<h2>Method 2: Remove Non-Numeric Columns from Data Frame</h2>
Another way to avoid the error is to simply remove any non-numeric columns from the data frame before using the prcomp()</b> function:
<b>#remove non-numeric columns from data frame
df_new &lt;- df[ , unlist(lapply(df, is.numeric))]
#view new data frame
df_new
  points rebounds
1     12       10
2      8        4
3     26        5
4     25        5
5     38        4
6     30        3
7     24        8
8     24       18
9     15       22
#calculate principal components
prcomp(df_new)
Standard deviations (1, .., p=2):
[1] 9.802541 6.093638
Rotation (n x k) = (2 x 2):
                PC1       PC2
points    0.9199431 0.3920519
rebounds -0.3920519 0.9199431
</b>
Once again, we we don’t receive any error because each column in the data frame is numeric.
<b>Note</b>: In most cases, the first method is the preferred solution because it allows you to use all of the data rather than removing some of the columns.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in R:
 How to Fix in R: Arguments imply differing number of rows 
 How to Fix in R: error in select unused arguments 
 How to Fix in R: replacement has length zero 
<h2><span class="orange">How to Fix in R: Error in as.Date.numeric(x) : ‘origin’ must be supplied</span></h2>
One error you may encounter in R is:
<b>Error in as.Date.numeric(x) : 'origin' must be supplied 
</b>
This error usually occurs when you attempt to convert a number to a date in R, but fail to provide an origin date.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R that shows the total sales made during various days by some company:
<b>#create data frame
df &lt;- data.frame(date=c(27, 140, 180, 200), sales=c(12, 22, 30, 31))
#view data frame
df
  date sales
1   27    12
2  140    22
3  180    30
4  200    31</b>
We can use the  str()  function to view the structure of the data frame:
<b>#view structure of data frame</b>
<b>str(df)
'data.frame':4 obs. of  2 variables:
 $ date : num  27 140 180 200
 $ sales: num  12 22 30 31
</b>
We can see that the <b>date</b> and <b>sales</b> columns are both numeric.
Now suppose we attempt to convert the <b>date</b> column to a date format:
<b>#attempt to convert date column to date format</b>
<b>df$date &lt;- as.Date(df$date)
Error in as.Date.numeric(df$date) : 'origin' must be supplied
</b>
We receive an error because we we did not use the <b>origin</b> argument within the <b>as.Date()</b> function.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply provide an origin date so that R knows how to convert the numbers to dates:
<b>#convert date column to date format, using 2020-01-01 as origin date
df$date &lt;- as.Date(df$date, origin="2020-01-01")
#view updated data frame
df
        date sales
1 2020-01-28    12
2 2020-05-20    22
3 2020-06-29    30
4 2020-07-19    31</b>
By supplying an origin date, R converted the numbers to dates by adding the number of days to the origin supplied.
For example:
The first date value of <b>27</b> was converted to <b>2020-01-28</b> by adding 27 days to the origin date of 2020-01-01.
The second date value of <b>140 </b>was converted to <b>2020-05-20</b> by adding 140 days to the origin date of 2020-01-01.
And so on.
We can also use the <b>class()</b> function to confirm that the new column is indeed a date:
<b>#display class of date column
class(df$date)
[1] "Date"
</b>
The new column is now a date instead of a number.
<h2><span class="orange">How to Fix in R: dim(X) must have a positive length</span></h2>
One error you may encounter in R is:
<b>Error in apply(df$var1, 2, mean) : dim(X) must have a positive length 
</b>
This error occurs when you attempt to use the <b>apply()</b> function to calculate some metric for a column of a data frame or matrix, yet provide a vector as an argument instead of a data frame or matrix.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(99, 97, 104, 79, 84, 88, 91, 99), rebounds=c(34, 40, 41, 38, 29, 30, 22, 25), blocks=c(12, 8, 8, 7, 8, 11, 6, 7))
#view data frame
df
  points rebounds blocks
1     99       34     12
2     97       40      8
3    104       41      8
4     79       38      7
5     84       29      8
6     88       30     11
7     91       22      6
8     99       25      7</b>
Now suppose we attempt to use the <b>apply()</b> function to calculate the mean value in the ‘points’ column:
<b>#attempt to calculate mean of 'points' column
apply(df$points, 2, mean)
Error in apply(df$points, 2, mean) : dim(X) must have a positive length
</b>
An error occurs because the <b>apply()</b> function must be applied to a data frame or matrix, yet in this example we attempt to apply it to a specific column in the data frame.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply provide the name of the data frame to the <b>apply()</b> function as follows:
<b>#calculate mean of every column in data frame
apply(df, 2, mean)
  points rebounds   blocks 
  92.625   32.375    8.375 
</b>
From the output, we can see the  mean value of each column in the data frame. For example, the mean value of the ‘points’ column is <b>92.625</b>.
We can also use this function to only find the mean of specific values in the data frame:
<b>#calculate mean of 'points' and 'blocks' column in data frame
apply(df[c('points', 'blocks')], 2, mean)
points blocks 
92.625  8.375</b>
Lastly, if we’d like to find the mean of just one column then we can use the <b>mean()</b> function without using the <b>apply()</b> function at all:
<b>#calculate mean of 'points' column
mean(df$points)
[1] 92.625
</b>
<h2><span class="orange">How to Fix R Error: Discrete value supplied to continuous scale</span></h2>
One error you may encounter in R is:
<b>Error: Discrete value supplied to continuous scale
</b>
This error occurs when you attempt to apply a continuous scale to an axis in ggplot2, yet the variable on that axis is not numeric.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df = data.frame(x = 1:12,
                y = rep(c('1', '2', '3', '4'), times=3))
#view data frame
df
    x y
1   1 1
2   2 2
3   3 3
4   4 4
5   5 1
6   6 2
7   7 3
8   8 4
9   9 1
10 10 2
11 11 3
12 12 4</b>
Now suppose we attempt to create a scatterplot with a custom y-axis scale using the <b>scale_y_continuous()</b> argument:
<b>library(ggplot2)
#attempt to create scatterplot with custom y-axis scale
ggplot(df, aes(x, y)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 10))
Error: Discrete value supplied to continuous scale
</b>
We receive an error because our y-axis variable is a character instead of a numeric variable.
We can confirm this by using the <b>class(</b>) function:
<b>#check class of y variable
class(df$y)
[1] "character"
</b>
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to convert the y-axis variable to a numeric variable before creating the scatterplot:
<b>library(ggplot2) 
#convert y variable to numeric
df$y &lt;- as.numeric(df$y)
#create scatterplot with custom y-axis scale
ggplot(df, aes(x, y)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 10))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/scaleerror1.png">
Notice that we don’t receive any error because we used <b>scale_y_continuous()</b> with a numeric variable instead of a character variable.
You can find the complete online documentation for the scale_y_continuous() function  here .
<h2><span class="orange">How to Fix in R: Error: Duplicate identifiers for rows</span></h2>
One error you may encounter in R is:
<b>Error: Duplicate identifiers for rows
</b>
This error occurs when you attempt to use the <b>spread()</b> function to spread the values in one or more columns in a data frame into their own columns.
However, an error can occur if there is no unique ID for each row so there is no way to determine which values belong with which observations when performing the spread.
The following example shows how to fix this error in practice.
<h2>Example: How to Fix the Error</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(player=rep(c('A', 'B'), each=4), year=rep(1:4, times=2), assists=c(4, 10, 4, 4, 3, 7, 7, 6), points=c(14, 6, 18, 7, 22, 9, 38, 4))
#view data frame
df
  player year assists points
1      A    1       4     14
2      A    2      10      6
3      A    3       4     18
4      A    4       4      7
5      B    1       3     22
6      B    2       7      9
7      B    3       7     38
8      B    4       6      4
</b>
Now suppose we would like to transform the data frame so that we have the <b>year</b> column as the id column and create new columns called <b>assists_A</b>, <b>assists_B</b>, <b>points_A</b>, and <b>points_B</b> to represent the assists and points values for players A and B during each year.
Since the values in the year column will not be unique (there will be two 1’s, two 2’s, etc.) the <b>spread() </b> function will produce an error.
However, we can use the <b>pivot_wider()</b> function with the following syntax to produce the desired data frame:
<b>library(tidyr)
#spread the values in the points and assists columns
pivot_wider(data = df, 
            id_cols = year, 
            names_from = player, 
            values_from = c('assists', 'points'))
# A tibble: 4 x 5
   year assists_A assists_B points_A points_B    
1     1         4         3       14       22
2     2        10         7        6        9
3     3         4         7       18       38
4     4         4         6        7        4</b>
Notice that we don’t receive any error and we’re able to successfully create the new columns that display the points and assists values for players A and B during each of the four years.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in R:
 How to Fix in R: NAs Introduced by Coercion 
 How to Fix in R: Subscript out of bounds 
 How to Fix in R: longer object length is not a multiple of shorter object length 
 How to Fix in R: number of items to replace is not a multiple of replacement length 
<h2><span class="orange">How to Fix: error in FUN(newx[, i], …) : invalid ‘type’ (character) of argument</span></h2>
One error you may encounter in R is:
<b>Error in sum(x) : invalid 'type' (character) of argument
</b>
This error occurs when you attempt to perform some mathematical operation (like taking the sum, mean, count, etc.) on a character vector.
This tutorial shares how to resolve this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), points=c(10, 12, 15, 20, 26, 25), rebounds=c(7, 8, 8, 14, 10, 12))
#view data frame
df
  team points rebounds
1    A     10        7
2    A     12        8
3    A     15        8
4    B     20       14
5    B     26       10
6    B     25       12</b>
Now suppose we attempt to calculate the sum of the ‘team’ column:
<b>#attempt to calculate sum of values in 'team' column
sum(df$team)
Error in sum(df$team) : invalid 'type' (character) of argument
</b>
We receive an error because the ‘team’ column is a character column.
We can confirm this by using the<b> class()</b> function:
<b>#view class of 'team' column
class(df$team)
[1] "character"
</b>
<h3>How to Fix the Error</h3>
The way to get around this error is to only use mathematical operations with numeric vectors.
For example, we could use the <b>sum()</b> function to calculate the sum of the values in the ‘points’ column:
<b>#calculate sum of values in 'points' column
sum(df$points)
[1] 108
</b>
We could also calculate the sum of the points values, grouped by team:
<b>#calculate sum of points, grouped by team
aggregate(points ~ team, df, sum)
  team points
1    A     37
2    B     71
</b>
We could even calculate the sum of the points <em>and</em> rebounds values, grouped by team:
<b>#calculate sum of points and sum of rebounds, grouped by team
aggregate(. ~ team, df, sum)
  team points rebounds
1    A     37       23
2    B     71       36
</b>
Notice that we don’t receive an error with any of these operations because we’re only attempting to calculate the sum for numeric variables.
<h2><span class="orange">How to Fix: error in file(file, “rt”) : cannot open the connection</span></h2>
One common error you may encounter in R is:
<b>Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'data.csv': No such file or directory 
</b>
This error occurs when you attempt to  read in a CSV file in R , but the file name or directory you’re attempting to access does not exist.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose I have a CSV file called <b>data.csv</b> saved in the following location:
<b>C:\Users\Bob\Desktop\data.csv</b>
And suppose the CSV file contains the following data:
<b>team, points, assists
'A', 78, 12
'B', 85, 20
'C', 93, 23
'D', 90, 8
'E', 91, 14
</b>
Suppose I use the following syntax to read in this CSV file into R:
<b>#attempt to read in CSV file
df &lt;- read.csv('data.csv')
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'data2.csv': No such file or directory</b>
I receive an error because this file doesn’t exist in the current working directory.
<h3>How to Fix the Error</h3>
I can use the <b>getwd()</b> function to actually find the working directory I’m in:
<b>#display current directory
getwd()
[1] "C:/Users/Bob/Documents"
</b>
Since my CSV file is located on my desktop, I need to change the working directory using <b>setwd()</b> and then use <b>read.csv()</b> to read in the file:
<b>#set current directory
setwd('C:\\Users\\Bob\\Desktop')
#read in CSV file
df &lt;- read.csv('data.csv', header=TRUE, stringsAsFactors=FALSE)
#view data
df
  team points assists
1    A     78      12
2    B     85      20
3    C     93      23
4    D     90       8
5    E     91      14
</b>
It worked!
Another way to import the CSV without setting the working directory would be to specify the entire file path in R when importing:
<b>#read in CSV file using entire file path
df &lt;- read.csv('C:\\Users\\Bob\\Desktop\\data.csv', header=TRUE, stringsAsFactors=FALSE)
#view data
df
  team points assists
1    A     78      12
2    B     85      20
3    C     93      23
4    D     90       8
5    E     91      14</b>
<h2><span class="orange">How to Fix: error in lm.fit(x, y, offset = offset, …) : na/nan/inf in ‘y’</span></h2>
One error you may encounter when using R is:
<b>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
  NA/NaN/Inf in 'y'
</b>
This error occurs when you attempt to use the  lm()  function to fit a linear regression model in R, but either the predictor or response variable contains <b>NaN</b> or <b>Inf</b> values.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R that contains information about minutes played and points scored for various basketball players:
<b>#create data frame with some NA, NaN, Inf values
df &lt;- data.frame(minutes=c(4, NA, 28, 12, 30, 21, 14), points=c(12, NaN, 30, Inf, 43, 25, 17))
#view data frame
df
  minutes points
1       4     12
2      NA    NaN
3      28     30
4      12    Inf
5      30     43
6      21     25
7      14     17
</b>
Notice that the data frame contains some <b>NaN</b> and <b>Inf</b> values.
Now suppose we attempt to fit a linear regression model using “minutes” as the predictor variable and “points” as the response variable:
<b>#attempt to fit regression model
lm(points ~ minutes, data=df)
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
  NA/NaN/Inf in 'y'
</b>
We receive an error because there are <b>NaN</b> and <b>Inf</b> values present in the data frame.
<h3>How to Fix the Error</h3>
It’s worth noting that the <b>NA</b> values in the data frame are not an issue. In fact, R simply ignores the <b>NA</b> values when fitting the linear regression model.
The real issue is caused by the <b>NaN</b> and <b>Inf</b> values.
The easiest way to resolve this issue is to replace the <b>NaN</b> and <b>Inf</b> values with <b>NA</b> values:
<b>#Replace NaN & Inf with NA
df[is.na(df) | df=="Inf"] = NA
#view updated data frame
df
  minutes points
1       4     12
2      NA     NA
3      28     30
4      12     NA
5      30     43
6      21     25
7      14     17</b>
Now we can fit the regression model:
<b>#fit regression model
lm(points ~ minutes, data=df)
Call:
lm(formula = points ~ minutes, data = df)
Coefficients:
(Intercept)      minutes  
      5.062        1.048  </b>
The output shows the  coefficients  of the regression model.
Notice that we don’t receive any error since we replaced the <b>NaN</b> and <b>Inf</b> values in the data frame.
<h2><span class="orange">How to Handle R Error: $ operator is invalid for atomic vectors</span></h2>
One common error you may encounter in R is:
<b>$ operator is invalid for atomic vectors
</b>
This error occurs when you attempt to access an element of an atomic vector using the <b>$</b> operator.
An “atomic vector” is any one-dimensional data object created by using the <b>c()</b> or <b>vector()</b> functions in R.
Unfortunately, the <b>$</b> cannot be used to access elements in atomic vectors. Instead, you must use double brackets <b>[[]]</b> or the <b>getElement()</b> function.
This tutorial shares examples of how to deal with this error in practice.
<h3>How to Reproduce the Error Message</h3>
Suppose we attempt to use the <b>$</b>  operator  to access an element in the following vector in R:
<b>#define vector
x &lt;- c(1, 3, 7, 6, 2)
#provide names
names(x) &lt;- c('a', 'b', 'c', 'd', 'e')
#display vector
x
a b c d e 
1 3 7 6 2
#attempt to access value in 'e'
x$e
Error in x$e : $ operator is invalid for atomic vectors
</b>
We receive an error because it’s not valid to use the <b>$</b> operator to access elements in atomic vectors. We can also verify that our vector is indeed atomic:
<b>#check if vector is atomic
is.atomic(x)
[1] TRUE
</b>
<h3>Method #1: Access Elements Using Double Brackets</h3>
One way to access elements by name in a vector is to use the <b>[[]]</b> notation:
<b>#define vector
x &lt;- c(1, 3, 7, 6, 2)
#provide names
names(x) &lt;- c('a', 'b', 'c', 'd', 'e')
#access value for 'e'
x[['e']]
[1] 2</b>
<h3>Method #2: Access Elements Using getElement()</h3>
Another way to access elements by name in a vector is to use the <b>getElement()</b> notation:
<b>#define vector
x &lt;- c(1, 3, 7, 6, 2)
#provide names
names(x) &lt;- c('a', 'b', 'c', 'd', 'e')
#access value for 'e'
getElement(x, 'e')
[1] 2</b>
<h3>Method #3 Convert Vector to Data Frame & Use $ Operator</h3>
Yet another way to access elements by name in a vector is to first convert the vector to a data frame, then use the <b>$</b> operator to access the value:
<b>#define vector
x &lt;- c(1, 3, 7, 6, 2)
#provide names
names(x) &lt;- c('a', 'b', 'c', 'd', 'e')
#convert vector to data frame
data_x &lt;- as.data.frame(t(x))
#display data frame
data_x
  a b c d e
1 1 3 7 6 2
#access value for 'e'
data_x$e
[1] 2</b>
<h2><span class="orange">How to Fix in R: error in rep(1, n) : invalid ‘times’ argument</span></h2>
One error you may encounter in R is:
<b>Error in rep(1, times = -4) : invalid 'times' argument
</b>
This error occurs when you provide one of the following values to the <b>times</b> argument within the<b> rep()</b> function:
A negative value
NA value
A vector of values
Since the  rep()  function replicates elements a certain number of times, only a non-negative value in the <b>times</b> argument is valid to use.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we attempt to replicate the value “1” -4 times:
<b>#attempt to replicate "1" -4 times
rep(1, times = -4)
Error in rep(1, times = -4) : invalid 'times' argument
</b>
Or suppose we attempt to replicate the value “1” NA times:
<b>#attempt to replicate "1" NA times
rep(1, times = NA)
Error in rep(1, times = NA) : invalid 'times' argument</b>
Or suppose we attempt to replicate the value “1” both 2 times and 3 times:
<b>#attempt to replicate "1" 2 times and 3 times
rep(1, times = c(2, 3))
Error in rep(1, times = c(2, 3)) : invalid 'times' argument</b>
We receive an error in each scenario because we failed to provide a non-negative value to the <b>times</b> argument in each scenario.
<h2>How to Fix the Error</h2>
The way to fix this error is to simply provide a non-negative value to the <b>times</b> argument in the <b>rep()</b> function.
For example, the following code shows how to replicate the value “1” 7 times:
<b>#replicate 1 7 times
rep(1, times = 7)
[1] 1 1 1 1 1 1 1
</b>
The value “1” is replicated 7 times and we don’t receive any error because we provided a valid value to the <b>times</b> argument.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in R:
 How to Fix in R: NAs Introduced by Coercion 
 How to Fix in R: Subscript out of bounds 
 How to Fix in R: longer object length is not a multiple of shorter object length 
 How to Fix in R: number of items to replace is not a multiple of replacement length 
<h2><span class="orange">How to Fix in R: replacement has X rows, data has Y</span></h2>
One error message you may encounter when using R is:
<b>Error in `$&lt;-.data.frame`(`*tmp*`, conf_full, value = c("West", "West",  : 
  replacement has 3 rows, data has 5
</b>
This error occurs when you attempt to add a new column to a data frame whose values are based on an existing column, but you fail to first create the new column.
The following example shows how to resolve this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following data frame in R:
<b>#create data frame
df &lt;- data.frame(conference=c('W', 'W', 'W', 'E', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34))
#view data frame
df
  conference points assists
1          W     99      33
2          W     90      28
3          W     86      31
4          E     88      39
5          E     95      34</b>
Now suppose we attempt to add a new column to the data frame called <b>conf_full</b>:
<b>#attempt to create new column based on conference name
df$conf_full[which(df$conference=='W')] &lt;- 'West'
df$conf_full[which(df$conference=='E')] &lt;- 'East'
Error in `$&lt;-.data.frame`(`*tmp*`, conf_full, value = c("West", "West",  : 
  replacement has 3 rows, data has 5</b>
We receive an error because the variable name <b>conf_full</b> doesn’t yet exist, which means we can’t assign values to that column yet.
<h3>How to Avoid the Error</h3>
To avoid this error, we can first create the <b>conf_full</b> variable and simply assign values of NA to it:
<b>#create conf_full variable
df$conf_full &lt;- NA</b>
Now that the variable exists, we can assign values to it:
<b>#create new column based on conference
df$conf_full[which(df$conference=='W')] &lt;- 'West'
df$conf_full[which(df$conference=='E')] &lt;- 'East'
#view updated data frame
df
  conference points assists conf_full
1          W     99      33      West
2          W     90      28      West
3          W     86      31      West
4          E     88      39      East
5          E     95      34      East</b>
Notice that we don’t receive any error this time because we first created the <b>conf_full</b> variable before attempting to assign values to it.
<h2><span class="orange">How to Fix: Error in stripchart.default(x1, …) : invalid plotting method</span></h2>
One error you may encounter in R is:
<b>Error in stripchart.default(x1, ...) : invalid plotting method 
</b>
This error usually occurs when you attempt to create a scatter plot using a data frame instead of a vector.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 4, 7, 8, 9), y=c(5, 5, 8, 10, 13, 13, 18))
#view data frame
df
  x  y
1 1  5
2 2  5
3 2  8
4 4 10
5 7 13
6 8 13
7 9 18</b>
Now suppose we attempt to use the following syntax to create a scatter plot:
<b>#attempt to create scatter plot
plot(df[1], df[2])
Error in stripchart.default(x1, ...) : invalid plotting method
</b>
We receive an error because both <b>df[1]</b> and <b>df[2]</b> are actually data frames and the <b>plot()</b> function only accepts vectors as input.
We can use the <b>class()</b> function to verify that <b>df[1]</b> and<b> df[2]</b> are both data frames:
<b>#display class of df[1] and df[2]
class(df[1]);class(df[2])
[1] "data.frame"
[1] "data.frame"
</b>
<h3>How to Fix the Error</h3>
The way to fix this error is to make sure that we use vectors as inputs for the <b>plot()</b> function.
For example, we can use the following syntax to create a scatter plot:
<b>#create scatter plot
plot(df[, 1], df[, 2])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/schart1.jpg"454">
Or we could use the following syntax to create a scatter plot:
<b>#create scatter plot
plot(df$x, df$y)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/schart2.jpg"461">
Notice that we’re able to create a scatter plot using either method without any errors because we used vectors as inputs to the <b>plot()</b> function each time.
<h2><span class="orange">How to Fix: error in strsplit(unitspec, ” “) : non-character argument</span></h2>
One error you may encounter in R is:
<b>Error in strsplit(df$my_column, split = "1") : non-character argument 
</b>
This error usually occurs when you attempt to use the <b>strsplit()</b> function in R to split up a string, yet the object you’re working with is not a string.
This tutorial shares exactly how to fix this error.
<h2>How to Reproduce the Error</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C'), points=c(91910, 14015, 120215))
#view data frame
df
  team points
1    A  91910
2    B  14015
3    C 120215</b>
Now suppose we attempt to use the <b>strsplit()</b> function to split the values in the “points” column based on where the number 1 occurs:
<b>#attempt to split values in points column
strsplit(df$points, split="1")
Error in strsplit(df$points, split = "1") : non-character argument
</b>
We receive an error because the variable “points” is not a character.
We can confirm this by checking the class of this variable:
<b>#display class of "points" variable
class(df$points)
[1] "numeric"
</b>
We can see that this variable has a class of numeric.
<h2>How to Fix the Error</h2>
The way to fix this error is to use <b>as.character()</b> to convert the “points” variable to a character before attempting to use the <b>strsplit()</b> function:
<b>#split values in points column based on where 1 appears
strsplit(as.character(df$points), split="1")
[[1]]
[1] "9" "9" "0"
[[2]]
[1] ""   "40" "5" 
[[3]]
[1] ""    "202" "5"  </b>
This time we’re able to successfully split each value in the “points” column because we first used the <b>as.character()</b> function to convert “points” to a character.
<h2>Additional Resources</h2>
The following tutorials explain how to troubleshoot other common errors in R:
 How to Fix in R: names do not match previous names 
 How to Fix in R: more columns than column names 
 How to Fix in R: replacement has X rows, data has Y 
<h2><span class="orange">How to Fix in R: Subscript out of bounds</span></h2>
One common error you may encounter in R is:
<b>Error in x[, 4] : subscript out of bounds
</b>
This error occurs when you attempt to access a column or row in a matrix that does not exist.
This tutorial shares the exact steps you can use to troubleshoot this error, using the following matrix as an example:
<b>#make this example reproducible
set.seed(0)
#create matrix with 10 rows and 3 columns
x = matrix(data = sample.int(100, 30), nrow = 10, ncol = 3)
#print matrix
print(x)
      [,1] [,2] [,3]
 [1,]   14   51   96
 [2,]   68   85   44
 [3,]   39   21   33
 [4,]    1   54   35
 [5,]   34   74   70
 [6,]   87    7   86
 [7,]   43   73   42
 [8,]  100   79   38
 [9,]   82   37   20
[10,]   59   92   28
</b>
<h3>Example #1: Subscript out of bounds (with rows)</h3>
The following code attempts to access the 11th row of the matrix, which does not exist:
<b>#attempt to display 11th row of matrix
x[11, ]
Error in x[11, ] : subscript out of bounds
</b>
Since the 11th row of the matrix does not exist, we get the <b>subscript out of bounds</b> error.
If we’re unaware of how many rows are in the matrix, we can use the <b>nrow()</b> function to find out:
<b>#display number of rows in matrix
nrow(x)
[1] 10
</b>
We can see that there are only 10 rows in the matrix. Thus, we can only use numbers less than or equal to 10 when accessing the rows.
For example, we can use the following syntax to display the 10th row of the matrix:
<b>#display 10th row of matrix
x[10, ]
[1] 59 92 28
</b>
<h3>Example #2: Subscript out of bounds (with columns)</h3>
The following code attempts to access the 4th column of the matrix, which does not exist:
<b>#attempt to display 4th column of matrix
x[, 4]
Error in x[, 4] : subscript out of bounds
</b>
Since the 4th column of the matrix does not exist, we get the <b>subscript out of bounds</b> error.
If we’re unaware of how many columns are in the matrix, we can use the <b>ncol()</b> function to find out:
<b>#display number of columns in matrix
ncol(x)
[1] 3
</b>
We can see that there are only 3 columns in the matrix. Thus, we can only use numbers less than or equal to 3 when accessing the columns.
For example, we can use the following syntax to display the 3rd column of the matrix:
<b>#display 3rd column of matrix
x[, 3]
[1] 96 44 33 35 70 86 42 38 20 28</b>
<h3>Example #3: Subscript out of bounds (rows & columns)</h3>
The following code attempts to access the value in the 11th row and the 4th column of the matrix, which does not exist:
<b>#attempt to display value in 11th row and 4th column
x[11, 4]
Error in x[11, 4] : subscript out of bounds
</b>
Since neither the 11th row nor the 4th column of the matrix exist, we get the <b>subscript out of bounds</b> error.
If we’re unaware of how many rows and columns are in the matrix, we can use the <b>dim()</b> function to find out:
<b>#display number of rows and columns in matrix
dim(x)
[1] 10  3
</b>
We can see that there are only 10 rows and 3 columns in the matrix. Thus, we can only use numbers less than or equal to these values when accessing the rows and columns.
For example, we can use the following syntax to display the value in the 10th row and the 3rd column of the matrix:
<b>#display value in 10th row and 3rd column of matrix
x[10, 3]
[1] 28
</b>

<script src='https://williamkpchan.github.io/LibDocs/readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>
