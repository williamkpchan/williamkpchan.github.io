<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width"/>
<link rel="stylesheet" href="..\maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script>
$(document).ready(function(){
    $('h1, h2, h3, h4, h5, .goldword, .tftitle, div.title').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
<style>
body{width:80%;margin-left: 10%}
h1, h2 {color: gold;}
li{list-style-type:none;}
.tftitle{color: gold;}
.returns{margin: 2%;}
.symfunction{margin: 3%;}
.source-link{font-size: xx-small;}
.symfunction{border-color: darkgrey; border-width: 1px; border-style: solid; padding: 10px;}
</style>
</head><body>
<center><h1>Tensors Reference</h1>
<div id="toc"></div></center>
<br>
<br>
<br>

        <div class="heading">
          <div class="tftitle">
              Tensors
            </div>
          <div class="description">
             <p>Tensors are the core datastructure of TensorFlow.js
        They are a generalization of vectors and matrices to potentially
        higher dimensions.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Tensors / Creation
              
                </div>
            <div class="description">
              <p>We have utility functions for common cases like Scalar, 1D,
          2D, 3D and 4D tensors, as well a number of functions to initialize
          tensors in ways useful for machine learning.</p>
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor" href="#tensor">
tf.tensor</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L54-L79" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass an array of values to create a vector.</span>
tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array of values to make a matrix or a higher</span>
<span class="hljs-comment">// dimensional tensor.</span>
tf.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape yourself.</span>
tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The shape of the tensor. Optional. If not provided,
              it is inferred from <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="scalar" href="#scalar">
tf.scalar</a>
    <span class="signature">(value, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L94-L102" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-0 <a href="#class:Tensor">tf.Tensor</a> (scalar) with the provided value and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#scalar">tf.scalar()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js">tf.scalar(<span class="hljs-number">3.14</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">value</span>
                <span class="param-type">(number|boolean)</span>
                <span class="param-docs">The value of the scalar.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Scalar</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor1d" href="#tensor1d">
tf.tensor1d</a>
    <span class="signature">(values, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L118-L126" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-1 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor1d">tf.tensor1d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js">tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be array of numbers,
              or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor2d" href="#tensor2d">
tf.tensor2d</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L149-L169" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-2 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor2d">tf.tensor2d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array.</span>
tf.tensor2d([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape.</span>
tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">([number, number])</span>
                <span class="param-docs">The shape of the tensor. If not provided, it is inferred from
              <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor3d" href="#tensor3d">
tf.tensor3d</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L192-L212" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-3 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor3d">tf.tensor3d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array.</span>
tf.tensor3d([[[<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]], [[<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>]]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape.</span>
tf.tensor3d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">([number, number, number])</span>
                <span class="param-docs">The shape of the tensor. If not provided,  it is inferred from
              <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor4d" href="#tensor4d">
tf.tensor4d</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L235-L255" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-4 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor4d">tf.tensor4d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array.</span>
tf.tensor4d([[[[<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]], [[<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>]]]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape.</span>
tf.tensor4d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">([number, number, number, number])</span>
                <span class="param-docs">The shape of the tensor. Optional. If not provided,
              it is inferred from <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor5d" href="#tensor5d">
tf.tensor5d</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L278-L299" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-5 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor5d">tf.tensor5d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array.</span>
tf.tensor5d([[[[[<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]], [[<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>]]]]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape.</span>
tf.tensor5d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">([number, number, number, number, number])</span>
                <span class="param-docs">The shape of the tensor. Optional. If not provided,
              it is inferred from <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor5D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="buffer" href="#buffer">
tf.buffer</a>
    <span class="signature">(shape, dtype?, values?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L953-L958" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates an empty <a href="#class:TensorBuffer">tf.TensorBuffer</a> with the specified <code>shape</code> and <code>dtype</code>.</p>
<p>The values are stored in cpu as <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>. Fill the buffer using
<code>buffer.set()</code>, or by modifying directly <code>buffer.values</code>.</p>
<p>When done, call <code>buffer.toTensor()</code> to get an immutable <a href="#class:Tensor">tf.Tensor</a> with
those values.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Create a buffer and set values at particular indices.</span>
<span class="hljs-keyword">const</span> buffer = tf.buffer([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);
buffer.set(<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);
buffer.set(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>);

<span class="hljs-comment">// Convert the buffer back to a tensor.</span>
buffer.toTensor().print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The dtype of the buffer. Defaults to 'float32'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>)</span>
                <span class="param-docs">The values of the buffer as <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>. Defaults to
              zeros.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:TensorBuffer">tf.TensorBuffer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="clone" href="#clone">
tf.clone</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L47-L59" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a new tensor with the same values and shape as the specified
tensor.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);

x.clone().print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor to clone.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="eye" href="#eye">
tf.eye</a>
    <span class="signature">(numRows, numColumns?, batchShape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L73-L106" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Create an identity matrix.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">numRows</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of rows.</span>
            </li>
            <li class="parameter">
                <span class="param-name">numColumns</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of columns. Defaults to <code>numRows</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">batchShape</span>
                <span class="param-type">([number]|[number, number])</span>
                <span class="param-docs">If provided, will add the batch shape to the beginning
              of the shape of the returned <a href="#class:Tensor">tf.Tensor</a> by repeating the identity
              matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">Data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="fill" href="#fill">
tf.fill</a>
    <span class="signature">(shape, value, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L394-L401" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> filled with a scalar value.</p>
<pre class="hljs"><code class="hljs language-js">tf.fill([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], <span class="hljs-number">4</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">value</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The scalar value to fill the tensor with.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The type of an element in the resulting tensor. Defaults to
              'float'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="fromPixels" href="#fromPixels">
tf.fromPixels</a>
    <span class="signature">(pixels, numChannels?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L330-L340" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> from an image.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> image = <span class="hljs-keyword">new</span> ImageData(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>);
image.data[<span class="hljs-number">0</span>] = <span class="hljs-number">100</span>;
image.data[<span class="hljs-number">1</span>] = <span class="hljs-number">150</span>;
image.data[<span class="hljs-number">2</span>] = <span class="hljs-number">200</span>;
image.data[<span class="hljs-number">3</span>] = <span class="hljs-number">255</span>;

tf.fromPixels(image).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">pixels</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageData">ImageData</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLImageElement">HTMLImageElement</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement">HTMLCanvasElement</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement">HTMLVideoElement</a>)</span>
                <span class="param-docs">The input image to construct the tensor from. The
              supported image types are all 4-channel.</span>
            </li>
            <li class="parameter">
                <span class="param-name">numChannels</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of channels of the output tensor. A
              numChannels value less than 4 allows you to ignore channels. Defaults to
              3 (ignores alpha channel of input image).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="linspace" href="#linspace">
tf.linspace</a>
    <span class="signature">(start, stop, num)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L446-L461" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Return an evenly spaced sequence of numbers over the given interval.</p>
<pre class="hljs"><code class="hljs language-js">tf.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">start</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The start value of the sequence.</span>
            </li>
            <li class="parameter">
                <span class="param-name">stop</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The end value of the sequence.</span>
            </li>
            <li class="parameter">
                <span class="param-name">num</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of values to generate.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="oneHot" href="#oneHot">
tf.oneHot</a>
    <span class="signature">(indices, depth, onValue?, offValue?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L295-L309" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a one-hot <a href="#class:Tensor">tf.Tensor</a>. The locations represented by <code>indices</code> take
value <code>onValue</code> (defaults to 1), while all other locations take value
<code>offValue</code> (defaults to 0).</p>
<pre class="hljs"><code class="hljs language-js">tf.oneHot(tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">'int32'</span>), <span class="hljs-number">3</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">indices</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor1D</a> of indices with dtype <code>int32</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depth</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The depth of the one hot dimension.</span>
            </li>
            <li class="parameter">
                <span class="param-name">onValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A number used to fill in output when the index matches
              the location.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">offValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A number used to fill in the output when the index does
              not match the location.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="ones" href="#ones">
tf.ones</a>
    <span class="signature">(shape, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L357-L362" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with all elements set to 1.</p>
<pre class="hljs"><code class="hljs language-js">tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The type of an element in the resulting tensor. Defaults to
              'float'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="onesLike" href="#onesLike">
tf.onesLike</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L413-L417" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with all elements set to 1 with the same shape as the
given tensor.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
tf.onesLike(x).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="print" href="#print">
tf.print</a>
    <span class="signature">(x, verbose?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L971-L974" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Prints information about the <a href="#class:Tensor">tf.Tensor</a> including its data.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> verbose = <span class="hljs-literal">true</span>;
tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print(verbose);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The tensor to be printed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">verbose</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to print verbose information about the <code>Tensor</code>,
              including dtype and size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="range" href="#range">
tf.range</a>
    <span class="signature">(start, stop, step?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L479-L511" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a new <a href="#class:Tensor">tf.Tensor1D</a> filled with the numbers in the range provided.</p>
<p>The tensor is a is half-open interval meaning it includes start, but
excludes stop. Decrementing ranges and negative step values are also
supported.</p>
<pre class="hljs"><code class="hljs language-js">tf.range(<span class="hljs-number">0</span>, <span class="hljs-number">9</span>, <span class="hljs-number">2</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">start</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">An integer start value</span>
            </li>
            <li class="parameter">
                <span class="param-name">stop</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">An integer stop value</span>
            </li>
            <li class="parameter">
                <span class="param-name">step</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">An integer increment (will default to 1 or -1)</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32')</span>
                <span class="param-docs">The data type of the output tensor. Defaults to 'float32'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tensor6d" href="#tensor6d">
tf.tensor6d</a>
    <span class="signature">(values, shape?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L322-L344" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates rank-6 <a href="#class:Tensor">tf.Tensor</a> with the provided values, shape and dtype.</p>
<p>The same functionality can be achieved with <a href="#tensor">tf.tensor()</a>, but in general
we recommend using <a href="#tensor6d">tf.tensor6d()</a> as it makes the code more readable.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a nested array.</span>
tf.tensor6d([[[[[[<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>]],[[<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>]]],[[[<span class="hljs-number">5</span>],[<span class="hljs-number">6</span>]],[[<span class="hljs-number">7</span>],[<span class="hljs-number">8</span>]]]]]]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Pass a flat array and specify a shape.</span>
tf.tensor6d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">values</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The values of the tensor. Can be nested array of numbers,
              or a flat array, or a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">([number, number, number, number, number, number])</span>
                <span class="param-docs">The shape of the tensor. Optional. If not provided,
              it is inferred from <code>values</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor6D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="truncatedNormal" href="#truncatedNormal">
tf.truncatedNormal</a>
    <span class="signature">(shape, mean?, stdDev?, dtype?, seed?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L156-L171" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with values sampled from a truncated normal
distribution.</p>
<pre class="hljs"><code class="hljs language-js">tf.truncatedNormal([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

<p>The generated values follow a normal distribution with specified mean and
standard deviation, except that values whose magnitude is more than 2
standard deviations from the mean are dropped and re-picked.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">mean</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The mean of the normal distribution.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">stdDev</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The standard deviation of the normal distribution.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32')</span>
                <span class="param-docs">The data type of the output tensor.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The seed for the random number generator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="variable" href="#variable">
tf.variable</a>
    <span class="signature">(initialValue, trainable?, name?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L1211-L1219" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a new variable with the provided initial value.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.variable(tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]));
x.assign(tf.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]));

x.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">initialValue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">Initial value for the tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, optimizers are allowed to update it.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name of the variable. Defaults to a unique id.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">If set, initialValue will be converted to the given type.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Variable">tf.Variable</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="zeros" href="#zeros">
tf.zeros</a>
    <span class="signature">(shape, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L375-L380" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with all elements set to 0.</p>
<pre class="hljs"><code class="hljs language-js">tf.zeros([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The type of an element in the resulting tensor. Can
              be 'float32', 'int32' or 'bool'. Defaults to 'float'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="zerosLike" href="#zerosLike">
tf.zerosLike</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/tensor_ops.ts#L430-L434" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with all elements set to 0 with the same shape as the
given tensor.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
tf.zerosLike(x).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor of required shape.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Tensors / Classes
              
                </div>
            <div class="description">
              <p>
          This section shows the main Tensor related classes in TensorFlow.js and
          the methods we expose on them.
          </p>
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:Tensor" href="#class:Tensor">tf.Tensor</a>
    <span class="signature">
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L344-L1154" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A <a href="#class:Tensor">tf.Tensor</a> object represents an immutable, multidimensional array of numbers
that has a shape and a data type.</p>
<p>See <a href="#tensor">tf.tensor()</a> for details on how to create a <a href="#class:Tensor">tf.Tensor</a>.</p>
</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.flatten" href="#tf.Tensor.flatten">
flatten</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L404-L408" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Flatten a Tensor to a 1D array.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.asScalar" href="#tf.Tensor.asScalar">
asScalar</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L411-L416" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Converts a size-1 <a href="#class:Tensor">tf.Tensor</a> to a <a href="#class:Tensor">tf.Scalar</a>.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Scalar</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.as1D" href="#tf.Tensor.as1D">
as1D</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L419-L423" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Converts a <a href="#class:Tensor">tf.Tensor</a> to a <a href="#class:Tensor">tf.Tensor1D</a>.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.as2D" href="#tf.Tensor.as2D">
as2D</a>
    <span class="signature">(rows, columns)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L431-L435" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Converts a <a href="#class:Tensor">tf.Tensor</a> to a <a href="#class:Tensor">tf.Tensor2D</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">rows</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of rows in <a href="#class:Tensor">tf.Tensor2D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">columns</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of columns in <a href="#class:Tensor">tf.Tensor2D</a>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.as3D" href="#tf.Tensor.as3D">
as3D</a>
    <span class="signature">(rows, columns, depth)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L444-L448" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Converts a <a href="#class:Tensor">tf.Tensor</a> to a <a href="#class:Tensor">tf.Tensor3D</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">rows</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of rows in <a href="#class:Tensor">tf.Tensor3D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">columns</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of columns in <a href="#class:Tensor">tf.Tensor3D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depth</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Depth of <a href="#class:Tensor">tf.Tensor3D</a>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.as4D" href="#tf.Tensor.as4D">
as4D</a>
    <span class="signature">(rows, columns, depth, depth2)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L458-L462" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Converts a <a href="#class:Tensor">tf.Tensor</a> to a <a href="#class:Tensor">tf.Tensor4D</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">rows</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of rows in <a href="#class:Tensor">tf.Tensor4D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">columns</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of columns in <a href="#class:Tensor">tf.Tensor4D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depth</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Depth of <a href="#class:Tensor">tf.Tensor4D</a>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depth2</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">4th dimension of <a href="#class:Tensor">tf.Tensor4D</a>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.asType" href="#tf.Tensor.asType">
asType</a>
    <span class="signature">(dtype)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L469-L473" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Casts a <a href="#class:Tensor">tf.Tensor</a> to a specified dtype.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">Data-type to cast the tensor to.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">this</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.buffer" href="#tf.Tensor.buffer">
buffer</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L502-L505" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a <a href="#class:TensorBuffer">tf.TensorBuffer</a> that holds the underlying data.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:TensorBuffer">tf.TensorBuffer</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.data" href="#tf.Tensor.data">
data</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L511-L515" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Asynchronously downloads the values from the <a href="#class:Tensor">tf.Tensor</a>. Returns a promise of
<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a> that resolves when the computation has finished.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.dataSync" href="#tf.Tensor.dataSync">
dataSync</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L521-L525" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Synchronously downloads the values from the <a href="#class:Tensor">tf.Tensor</a>. This blocks the UI
thread until the values are ready, which can cause performance issues.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.dispose" href="#tf.Tensor.dispose">
dispose</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L530-L537" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Disposes <a href="#class:Tensor">tf.Tensor</a> from memory.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.toFloat" href="#tf.Tensor.toFloat">
toFloat</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L551-L554" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Casts the array to type <code>float32</code></p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">this</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.toInt" href="#tf.Tensor.toInt">
toInt</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L557-L560" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Casts the array to type <code>int32</code></p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">this</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.toBool" href="#tf.Tensor.toBool">
toBool</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L563-L566" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Casts the array to type <code>bool</code></p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">this</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.print" href="#tf.Tensor.print">
print</a>
    <span class="signature">(verbose?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L574-L577" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Prints the <a href="#class:Tensor">tf.Tensor</a>. See <a href="#print">tf.print()</a> for details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">verbose</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to print verbose information about the tensor,
              including dtype and size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.reshape" href="#tf.Tensor.reshape">
reshape</a>
    <span class="signature">(newShape)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L585-L589" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Reshapes the tensor into the provided shape.
See <a href="#reshape">tf.reshape()</a> for more details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">newShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.reshapeAs" href="#tf.Tensor.reshapeAs">
reshapeAs</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L596-L600" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Reshapes the tensor into the shape of the provided tensor.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The tensor of required shape.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.expandDims" href="#tf.Tensor.expandDims">
expandDims</a>
    <span class="signature">(axis?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L609-L612" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a <a href="#class:Tensor">tf.Tensor</a> that has expanded rank, by inserting a dimension
into the tensor's shape. See <a href="#expandDims">tf.expandDims()</a> for details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension index at which to insert shape of 1. Defaults to
              0 (the first dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.cumsum" href="#tf.Tensor.cumsum">
cumsum</a>
    <span class="signature">(axis?, exclusive?, reverse?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L625-L628" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the cumulative sum of the <a href="#class:Tensor">tf.Tensor</a> along <code>axis</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis along which to sum. Optional. Defaults to 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">exclusive</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to perform exclusive cumulative sum. Defaults to
              false. If set to true then the sum of each tensor entry does not include
              its own value, but only the values previous to it along the specified
              axis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reverse</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to sum in the opposite direction. Defaults to
              false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.squeeze" href="#tf.Tensor.squeeze">
squeeze</a>
    <span class="signature">(axis?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L638-L642" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a <a href="#class:Tensor">tf.Tensor</a> with dimensions of size 1 removed from the shape.
See <a href="#squeeze">tf.squeeze()</a> for more details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">A list of numbers. If specified, only squeezes the
              dimensions listed. The dimension index starts at 0. It is an error to
              squeeze a dimension that is not 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.clone" href="#tf.Tensor.clone">
clone</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L645-L649" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a copy of the tensor. See <a href="#clone">tf.clone()</a> for details.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Tensor.toString" href="#tf.Tensor.toString">
toString</a>
    <span class="signature">(verbose?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L652-L656" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a human-readable description of the tensor. Useful for logging.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">verbose</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">string</span>
  </div>
</div>

  </div>
</div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:Variable" href="#class:Variable">tf.Variable</a>
    <span class="signature">
        <span>extends <a href="#class:Tensor">tf.Tensor</a></span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L1174-L1243" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A mutable <a href="#class:Tensor">tf.Tensor</a>, useful for persisting state, e.g. for training.</p>
</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Variable.assign" href="#tf.Variable.assign">
assign</a>
    <span class="signature">(newValue)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L1227-L1242" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Assign a new <a href="#class:Tensor">tf.Tensor</a> to this variable. The new <a href="#class:Tensor">tf.Tensor</a> must have the
same shape and dtype as the old <a href="#class:Tensor">tf.Tensor</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">newValue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">New tensor to be assigned to this variable.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

  </div>
</div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:TensorBuffer" href="#class:TensorBuffer">tf.TensorBuffer</a>
    <span class="signature">
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L36-L134" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A mutable object, similar to <a href="#class:Tensor">tf.Tensor</a>, that allows users to set values
at locations before converting to an immutable <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>See <a href="#buffer">tf.buffer()</a> for creating a tensor buffer.</p>
</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.TensorBuffer.set" href="#tf.TensorBuffer.set">
set</a>
    <span class="signature">(value, locs)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L65-L76" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Sets a value in the buffer at a given location.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">value</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The value to set.</span>
            </li>
            <li class="parameter">
                <span class="param-name">locs</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The location indices.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.TensorBuffer.get" href="#tf.TensorBuffer.get">
get</a>
    <span class="signature">(locs)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L83-L93" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the value in the buffer at the provided location.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">locs</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The location indices.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">number</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.TensorBuffer.toTensor" href="#tf.TensorBuffer.toTensor">
toTensor</a>
    <span class="signature">()</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/tensor.ts#L130-L133" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates an immutable <a href="#class:Tensor">tf.Tensor</a> object from the buffer.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

  </div>
</div>
          <div class="subheading">
            <div class="tftitle">
              
                Tensors / Transformations
              
                </div>
            <div class="description">
              <p>This section describes some common Tensor
          transformations for reshaping and type-casting.</p>
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="cast" href="#cast">
tf.cast</a>
    <span class="signature">(x, dtype)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L513-L523" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Casts a <a href="#class:Tensor">tf.Tensor</a> to a new dtype.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1.5</span>, <span class="hljs-number">2.5</span>, <span class="hljs-number">3</span>]);
tf.cast(x, <span class="hljs-string">'int32'</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to be casted.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The dtype to cast the input tensor to.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="expandDims" href="#expandDims">
tf.expandDims</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L917-L927" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a <a href="#class:Tensor">tf.Tensor</a> that has expanded rank, by inserting a dimension
into the tensor's shape.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.expandDims(axis).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor whose dimensions to be expanded.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension index at which to insert shape of <code>1</code>. Defaults
              to 0 (the first dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="pad" href="#pad">
tf.pad</a>
    <span class="signature">(x, paddings, constantValue?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L691-L710" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Pads a <a href="#class:Tensor">tf.Tensor</a> with a given value and paddings.</p>
<p>This operation currently only implements the <code>CONSTANT</code> mode.</p>
<p>Also available are stricter rank-specific methods with the same signature
as this method that assert that <code>paddings</code> is of given length.</p>
<ul>
<li><code>tf.pad1d</code></li>
<li><code>tf.pad2d</code></li>
<li><code>tf.pad3d</code></li>
<li><code>tf.pad4d</code></li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
x.pad([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor to pad.</span>
            </li>
            <li class="parameter">
                <span class="param-name">paddings</span>
                <span class="param-type">(Array)</span>
                <span class="param-docs">An array of length <code>R</code> (the rank of the tensor), where
              each element is a length-2 tuple of ints <code>[padBefore, padAfter]</code>,
              specifying how much to pad along each dimension of the tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">constantValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The pad value to use. Defaults to 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="reshape" href="#reshape">
tf.reshape</a>
    <span class="signature">(x, shape)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L466-L481" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Reshapes a <a href="#class:Tensor">tf.Tensor</a> to a given shape.</p>
<p>Given a input tensor, returns a new tensor with the same values as the
input tensor with shape <code>shape</code>.</p>
<p>If one component of shape is the special value -1, the size of that
dimension is computed so that the total size remains constant. In
particular, a shape of [-1] flattens into 1-D. At most one component of
shape can be -1.</p>
<p>If shape is 1-D or higher, then the operation returns a tensor with shape
shape filled with the values of tensor. In this case, the number of
elements implied by shape must be the same as the number of elements in
tensor.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
x.reshape([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to be reshaped.</span>
            </li>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="squeeze" href="#squeeze">
tf.squeeze</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L496-L501" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Removes dimensions of size 1 from the shape of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>]);
x.squeeze().print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to be squeezed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An optional list of numbers. If specified, only
              squeezes the dimensions listed. The dimension index starts at 0. It
              is an error to squeeze a dimension that is not 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Tensors / Slicing and Joining
              
                </div>
            <div class="description">
              <p>TensorFlow.js provides several operations
          to slice or extract parts of a tensor, or join multiple
          tensors together.
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="concat" href="#concat">
tf.concat</a>
    <span class="signature">(tensors, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/concat.ts#L158-L174" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Concatenates a list of <a href="#class:Tensor">tf.Tensor</a>s along a given axis.</p>
<p>The tensors ranks and types must match, and their sizes must match in all
dimensions except <code>axis</code>.</p>
<p>Also available are stricter rank-specific methods that assert that
<code>tensors</code> are of the given rank:</p>
<ul>
<li><code>tf.concat1d</code></li>
<li><code>tf.concat2d</code></li>
<li><code>tf.concat3d</code></li>
<li><code>tf.concat4d</code></li>
</ul>
<p>Except <code>tf.concat1d</code> (which does not have axis param), all methods have
same signature as this method.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
a.concat(b).print();  <span class="hljs-comment">// or a.concat(b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> c = tf.tensor1d([<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]);
tf.concat([a, b, c]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]]);
<span class="hljs-keyword">const</span> b = tf.tensor2d([[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">30</span>, <span class="hljs-number">40</span>]]);
<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
tf.concat([a, b], axis).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">tensors</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[]|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array[])</span>
                <span class="param-docs">A list of tensors to concatenate.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis to concate along. Defaults to 0 (the first dim).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="gather" href="#gather">
tf.gather</a>
    <span class="signature">(x, indices, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/segment_ops.ts#L93-L142" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Gather slices from tensor <code>x</code>'s axis <code>axis</code> according to <code>indices</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> indices = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>], <span class="hljs-string">'int32'</span>);

x.gather(indices).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> indices = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], <span class="hljs-string">'int32'</span>);

x.gather(indices).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor whose slices to be gathered.</span>
            </li>
            <li class="parameter">
                <span class="param-name">indices</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The indices of the values to extract.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis over which to select values. Defaults to 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="reverse" href="#reverse">
tf.reverse</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reverse.ts#L111-L126" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Reverses a <a href="#class:Tensor">tf.Tensor</a> along a specified axis.</p>
<p>Also available are stricter rank-specific methods that assert that <code>x</code> is
of the given rank:</p>
<ul>
<li><code>tf.reverse1d</code></li>
<li><code>tf.reverse2d</code></li>
<li><code>tf.reverse3d</code></li>
<li><code>tf.reverse4d</code></li>
</ul>
<p>Except <code>tf.reverse1d</code> (which does not have axis param), all methods have
same signature as this method.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

x.reverse().print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.reverse(axis).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to be reversed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The set of dimensions to reverse. Must be in the
              range [-rank(x), rank(x)). Defaults to all axes.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="slice" href="#slice">
tf.slice</a>
    <span class="signature">(x, begin, size?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/slice.ts#L115-L168" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Extracts a slice from a <a href="#class:Tensor">tf.Tensor</a> starting at coordinates <code>begin</code>
and is of size <code>size</code>.</p>
<p>Also available are stricter rank-specific methods with the same signature
as this method that assert that <code>x</code> is of the given rank:</p>
<ul>
<li><code>tf.slice1d</code></li>
<li><code>tf.slice2d</code></li>
<li><code>tf.slice3d</code></li>
<li><code>tf.slice4d</code></li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

x.slice([<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

x.slice([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input <a href="#class:Tensor">tf.Tensor</a> to slice from.</span>
            </li>
            <li class="parameter">
                <span class="param-name">begin</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The coordinates to start the slice from. The length can be
              less than the rank of x - the rest of the axes will have implicit 0 as
              start. Can also be a single number, in which case it specifies the
              first axis.</span>
            </li>
            <li class="parameter">
                <span class="param-name">size</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The size of the slice. The length can be less than the rank of
              x - the rest of the axes will have implicit -1. A value of -1 requests
              the rest of the dimensions in the axis. Can also be a single number,
              in which case it specifies the size of the first axis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="split" href="#split">
tf.split</a>
    <span class="signature">(x, numOrSizeSplits, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L825-L853" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Splits a <a href="#class:Tensor">tf.Tensor</a> into sub tensors.</p>
<p>If <code>numOrSizeSplits</code> is a number, splits <code>x</code> along dimension <code>axis</code>
into <code>numOrSizeSplits</code> smaller tensors.
Requires that <code>numOrSizeSplits</code> evenly divides <code>x.shape[axis]</code>.</p>
<p>If <code>numOrSizeSplits</code> is a number array, splits <code>x</code> into
<code>(numOrSizeSplits.length</code> pieces. The shape of the <code>i</code>-th piece has the
same size as <code>x</code> except along dimension <code>axis</code> where the size is
<code>numOrSizeSplits[i]</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> [a, b] = tf.split(x, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>);
a.print();
b.print();

<span class="hljs-keyword">const</span> [c, d, e] = tf.split(x, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], <span class="hljs-number">1</span>);
c.print();
d.print();
e.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to split.</span>
            </li>
            <li class="parameter">
                <span class="param-name">numOrSizeSplits</span>
                <span class="param-type">(number[]|number)</span>
                <span class="param-docs">Either an integer indicating the number of
              splits along the axis or an array of integers containing the sizes of
              each output tensor along the axis. If a number then it must evenly divide
              <code>x.shape[axis]</code>; otherwise the sum of sizes must match <code>x.shape[axis]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension along which to split. Defaults to 0 (the first
              dim).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="stack" href="#stack">
tf.stack</a>
    <span class="signature">(tensors, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L725-L753" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Stacks a list of rank-<code>R</code> <a href="#class:Tensor">tf.Tensor</a>s into one rank-<code>(R+1)</code> <a href="#class:Tensor">tf.Tensor</a>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> c = tf.tensor1d([<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]);
tf.stack([a, b, c]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">tensors</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[]|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array[])</span>
                <span class="param-docs">A list of tensor objects with the same shape and dtype.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis to stack along. Defaults to 0 (the first dim).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tile" href="#tile">
tf.tile</a>
    <span class="signature">(x, reps)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L548-L609" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Construct an tensor by repeating it the number of times given by reps.</p>
<p>This operation creates a new tensor by replicating <a href="#input">tf.input()</a> <code>reps</code>
times. The output tensor's i'th dimension has <code>input.shape[i] * reps[i]</code> elements, and the values of <a href="#input">tf.input()</a> are replicated
<code>reps[i]</code> times along the i'th dimension. For example, tiling
<code>[a, b, c, d]</code> by <code>[2]</code> produces <code>[a, b, c, d, a, b, c, d]</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);

a.tile([<span class="hljs-number">2</span>]).print();    <span class="hljs-comment">// or a.tile([2])</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.tile([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]).print();  <span class="hljs-comment">// or a.tile([1, 2])</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor to tile.</span>
            </li>
            <li class="parameter">
                <span class="param-name">reps</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Determines the number of replications per dimension.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="unstack" href="#unstack">
tf.unstack</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L767-L791" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Unstacks a <a href="#class:Tensor">tf.Tensor</a> of rank-<code>R</code> into a list of rank-<code>(R-1)</code> <a href="#class:Tensor">tf.Tensor</a>s.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

tf.unstack(a).forEach(<span class="hljs-function"><span class="hljs-params">tensor</span> =&gt;</span> tensor.print());
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A tensor object.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis to unstack along. Defaults to 0 (the first dim).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Tensors / Random
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="multinomial" href="#multinomial">
tf.multinomial</a>
    <span class="signature">(logits, numSamples, seed?, normalized?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L253-L277" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with values drawn from a multinomial distribution.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> probs = tf.tensor([<span class="hljs-number">.75</span>, <span class="hljs-number">.25</span>]);
tf.multinomial(probs, <span class="hljs-number">3</span>).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">logits</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">1D array with unnormalized log-probabilities, or
              2D array of shape <code>[batchSize, numOutcomes]</code>. See the <code>normalized</code>
              parameter.</span>
            </li>
            <li class="parameter">
                <span class="param-name">numSamples</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of samples to draw for each row slice.</span>
            </li>
            <li class="parameter">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The seed number.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">normalized</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the provided <code>logits</code> are normalized true
              probabilities (sum to 1). Defaults to false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a>|<a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="randomNormal" href="#randomNormal">
tf.randomNormal</a>
    <span class="signature">(shape, mean?, stdDev?, dtype?, seed?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L121-L136" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with values sampled from a normal distribution.</p>
<pre class="hljs"><code class="hljs language-js">tf.randomNormal([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">mean</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The mean of the normal distribution.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">stdDev</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The standard deviation of the normal distribution.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32')</span>
                <span class="param-docs">The data type of the output.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The seed for the random number generator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="randomUniform" href="#randomUniform">
tf.randomUniform</a>
    <span class="signature">(shape, minval?, maxval?, dtype?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L191-L201" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Tensor">tf.Tensor</a> with values sampled from a uniform distribution.</p>
<p>The generated values follow a uniform distribution in the range [minval,
maxval). The lower bound minval is included in the range, while the upper
bound maxval is excluded.</p>
<pre class="hljs"><code class="hljs language-js">tf.randomUniform([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">An array of integers defining the output tensor shape.</span>
            </li>
            <li class="parameter">
                <span class="param-name">minval</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The lower bound on the range of random values to generate.
              Defaults to 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">maxval</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The upper bound on the range of random values to generate.
              Defaults to 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dtype</span>
                <span class="param-type">('float32'|'int32'|'bool')</span>
                <span class="param-docs">The data type of the output tensor. Defaults to 'float32'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Models
            </div>
          <div class="description">
             <p>Models are one of the primary abstractions used in
        TensorFlow.js Layers.  Models can be trained, evaluated, and used
        for prediction.  A model's state (topology, and optionally, trained
        weights) can be restored from various formats.</p>
        <p>Models are a collection of Layers, see Model Creation for
        details about how Layers can be connected.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Models / Creation
              
                </div>
            <div class="description">
              <p>There are two primary ways of creating models.</p>
          <ul><li>Sequential &mdash; Easiest, works if the models is a
          simple stack of each layer's input resting on the top of the
          previous layer's output.</li>
          <li>Model &mdash; Offers more control if the layers need to be
          wired together in graph-like ways &mdash; multiple 'towers',
          layers that skip a layer, etc.</li></ul>
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sequential" href="#sequential">
tf.sequential</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L147-L150" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a <a href="#class:Sequential">tf.Sequential</a> model.  A sequential model is any model where the
outputs of one layer are the inputs to the next layer, i.e. the model
topology is a simple 'stack' of layers, with no branching or skipping.</p>
<p>This means that the first layer passed to a Sequential model should have a
defined input shape. What that means is that it should have received an
<code>inputShape</code> or <code>batchInputShape</code> argument, or for some type of layers
(recurrent, Dense...) an <code>inputDim</code> argument.</p>
<p>The key difference between <a href="#model">tf.model()</a> and <a href="#sequential">tf.sequential()</a> is that <a href="#sequential">tf.sequential()</a>
is less generic, supporting only a linear stack of layers. <a href="#model">tf.model()</a> is
more generic and supports an arbitrary graph (without cycles) of layers.</p>
<p>Examples:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential();

<span class="hljs-comment">// First layer must have an input shape defined.</span>
model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">32</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">50</span>]}));
<span class="hljs-comment">// Afterwards, TF.js does automatic shape inference.</span>
model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}));

<span class="hljs-comment">// Inspect the inferred shape of the model's output, which equals</span>
<span class="hljs-comment">// `[null, 4]`. The 1st dimension is the undetermined batch dimension; the</span>
<span class="hljs-comment">// 2nd is the output size of the model's last layer.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(model.outputs[<span class="hljs-number">0</span>].shape));
</code></pre>

<p>It is also possible to specify a batch size (with potentially undetermined
batch dimension, denoted by &quot;null&quot;) for the first layer using the
<code>batchInputShape</code> key. The following example is equivalent to the above:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential();

<span class="hljs-comment">// First layer must have a defined input shape</span>
model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">32</span>, <span class="hljs-attr">batchInputShape</span>: [<span class="hljs-literal">null</span>, <span class="hljs-number">50</span>]}));
<span class="hljs-comment">// Afterwards, TF.js does automatic shape inference.</span>
model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}));

<span class="hljs-comment">// Inspect the inferred shape of the model's output.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(model.outputs[<span class="hljs-number">0</span>].shape));
</code></pre>

<p>You can also use an <code>Array</code> of already-constructed <code>Layer</code>s to create
a <a href="#class:Sequential">tf.Sequential</a> model:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">32</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">50</span>]}),
            tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>})]
});
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(model.outputs[<span class="hljs-number">0</span>].shape));
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">layers</span>
                <span class="param-type">(<a href="#class:layers.Layer">tf.layers.Layer</a>[])</span>
                <span class="param-docs">Stack of layers for the model.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">The name of this model.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Sequential">tf.Sequential</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="model" href="#model">
tf.model</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L85-L88" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A model is a data structure that consists of <code>Layers</code> and defines inputs
and outputs.</p>
<p>The key difference between <a href="#model">tf.model()</a> and <a href="#sequential">tf.sequential()</a> is that <a href="#model">tf.model()</a>
is more generic, supporting an arbitrary graph (without cycles) of layers.
<a href="#sequential">tf.sequential()</a> is less generic and supports only a linear stack of layers.</p>
<p>When creating a <a href="#class:Model">tf.Model</a>, specify its input(s) and output(s). Layers
are used to wire input(s) to output(s).</p>
<p>For example, the following code snippet defines a model consisting of
two <code>dense</code> layers, with 10 and 4 units, respectively.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Define input, which has a size of 5 (not including batch dimension).</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">5</span>]});

<span class="hljs-comment">// First dense layer uses relu activation.</span>
<span class="hljs-keyword">const</span> denseLayer1 = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">10</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'relu'</span>});
<span class="hljs-comment">// Second dense layer uses softmax activation.</span>
<span class="hljs-keyword">const</span> denseLayer2 = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">2</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'softmax'</span>});

<span class="hljs-comment">// Obtain the output symbolic tensor by applying the layers on the input.</span>
<span class="hljs-keyword">const</span> output = denseLayer2.apply(denseLayer1.apply(input));

<span class="hljs-comment">// Create the model based on the inputs.</span>
<span class="hljs-keyword">const</span> model = tf.model({<span class="hljs-attr">inputs</span>: input, <span class="hljs-attr">outputs</span>: output});

<span class="hljs-comment">// The model can be used for training, evaluation and prediction.</span>
<span class="hljs-comment">// For example, the following line runs prediction with the model on</span>
<span class="hljs-comment">// some fake data.</span>
model.predict(tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">5</span>])).print();
</code></pre>

<p>See also:
<a href="#sequential">tf.sequential()</a>, <a href="#loadModel">tf.loadModel()</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputs</span>
                <span class="param-type">(<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>[])</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">outputs</span>
                <span class="param-type">(<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>[])</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Model">tf.Model</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Models / Inputs
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="input" href="#input">
tf.input</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L161-L169" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Used to instantiate an input to a model as a <a href="#class:SymbolicTensor">tf.SymbolicTensor</a>.</p>
<p>Users should call the <a href="#input">tf.input()</a> factory function for
consistency with other generator functions.</p>
<p>Example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Defines a simple logistic regression model with 32 dimensional input</span>
<span class="hljs-comment">// and 3 dimensional output.</span>
<span class="hljs-keyword">const</span> x = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">32</span>]});
<span class="hljs-keyword">const</span> y = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">3</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'softmax'</span>}).apply(x);
<span class="hljs-keyword">const</span> model = tf.model({<span class="hljs-attr">inputs</span>: x, <span class="hljs-attr">outputs</span>: y});
model.predict(tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">32</span>])).print();
</code></pre>

<p>Note: <a href="#input">tf.input()</a> is only necessary when using <a href="#model">tf.model()</a>. When using
<a href="#sequential">tf.sequential()</a>, specify <code>inputShape</code> for the first layer or use <code>inputLayer</code>
as the first layer.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(InputConfig)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">shape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">A shape, not including the batch size. For instance, <code>shape=[32]</code>
              indicates that the expected input will be batches of 32-dimensional
              vectors.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">A shape tuple (integer), including the batch size. For instance,
              <code>batchShape=[10, 32]</code> indicates that the expected input will be batches of
              10 32-dimensional vectors. <code>batchShape=[null, 32]</code> indicates batches of an
              arbitrary number of 32-dimensional vectors.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">An optional name string for the layer. Should be unique in a model (do not
              reuse the same name twice). It will be autogenerated if it isn't provided.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sparse</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">A boolean specifying whether the placeholder to be created is sparse.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:SymbolicTensor">tf.SymbolicTensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Models / Loading
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="loadModel" href="#loadModel">
tf.loadModel</a>
    <span class="signature">(pathOrIOHandler)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L152-L159" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Load a model, including its topology and optionally weights.  See the
Tutorial named &quot;How to import a Keras Model&quot; for usage examples.</p>
<p>Example 1: Save <a href="#model">tf.model()</a>'s topology and weights to browser <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage">local
storage</a>;
then load it back.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from original model:'</span>);
model.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();

<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://my-model-1'</span>);

<span class="hljs-keyword">const</span> loadedModel = <span class="hljs-keyword">await</span> tf.loadModel(<span class="hljs-string">'localstorage://my-model-1'</span>);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from loaded model:'</span>);
loadedModel.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();
</code></pre>

<p>Example 2. Saving <a href="#model">tf.model()</a>'s topology and weights to browser
<a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API">IndexedDB</a>;
then load it back.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from original model:'</span>);
model.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();

<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'indexeddb://my-model-1'</span>);

<span class="hljs-keyword">const</span> loadedModel = <span class="hljs-keyword">await</span> tf.loadModel(<span class="hljs-string">'indexeddb://my-model-1'</span>);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from loaded model:'</span>);
loadedModel.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();
</code></pre>

<p>Example 3. Load a model from user-selected files from HTML
<a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/file">file input
elements</a>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Note: this code snippet will not work without the HTML elements in the</span>
<span class="hljs-comment">//   page</span>
<span class="hljs-keyword">const</span> jsonUpload = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'json-upload'</span>);
<span class="hljs-keyword">const</span> weightsUpload = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'weights-upload'</span>);

<span class="hljs-keyword">const</span> model = <span class="hljs-keyword">await</span> tf.loadModel(
     tf.io.browserFiles([jsonUpload.files[<span class="hljs-number">0</span>], weightsUpload.files[<span class="hljs-number">0</span>]]));
</code></pre>

<p>Example 4. Load a model from an HTTP server.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = <span class="hljs-keyword">await</span>
     tf.loadModel(<span class="hljs-string">'https://storage.googleapis.com/tfjs-models/tfjs/iris_v1/model.json'</span>)
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">pathOrIOHandler</span>
                <span class="param-type">(string|
              io.IOHandler)</span>
                <span class="param-docs">Can be either of the two formats</p>
              <ol>
              <li>A string path to the <code>ModelAndWeightsConfig</code> JSON describing
              the model in the canonical TensorFlow.js format. This path will be
              interpreted as a relative HTTP path, to which <code>fetch</code> will be used to
              request the model topology and weight manifest JSON.
              The content of the JSON file is assumed to be a JSON object with the
              following fields and values:</li>
              </ol>
              <ul>
              <li>'modelTopology': A JSON object that can be either of:</li>
              </ul>
              <ol>
              <li>a model architecture JSON consistent with the format of the return
              value of <code>keras.Model.to_json()</code></li>
              <li>a full model JSON in the format of <code>keras.models.save_model()</code>.</li>
              </ol>
              <ul>
              <li>'weightsManifest': A TensorFlow.js weights manifest.
              See the Python converter function <code>save_model()</code> for more details.
              It is also assumed that model weights can be accessed from relative
              paths described by the <code>paths</code> fields in weights manifest.</li>
              </ul>
              <ol start="2">
              <li>An <code>tf.io.IOHandler</code> object that loads model artifacts with its <code>load</code>
              method.</li>
              </ol>
              </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Models / Management
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="io.copyModel" href="#io.copyModel">
tf.io.copyModel</a>
    <span class="signature">(sourceURL, destURL)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/io/model_management.ts#L280-L285" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Copy a model from one URL to another.</p>
<p>This function supports:</p>
<ol>
<li>Copying within a storage medium, e.g.,
<code>tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')</code></li>
<li>Copying between two storage mediums, e.g.,
<code>tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')</code></li>
</ol>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// First create and save a model.</span>
<span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.dense(
     {<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>], <span class="hljs-attr">activation</span>: <span class="hljs-string">'sigmoid'</span>}));
<span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// Then list existing models.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Copy the model, from Local Storage to IndexedDB.</span>
<span class="hljs-keyword">await</span> tf.io.copyModel(
     <span class="hljs-string">'localstorage://demo/management/model1'</span>,
     <span class="hljs-string">'indexeddb://demo/management/model1'</span>);

<span class="hljs-comment">// List models again.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Remove both models.</span>
<span class="hljs-keyword">await</span> tf.io.removeModel(<span class="hljs-string">'localstorage://demo/management/model1'</span>);
<span class="hljs-keyword">await</span> tf.io.removeModel(<span class="hljs-string">'indexeddb://demo/management/model1'</span>);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">sourceURL</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Source URL of copying.</span>
            </li>
            <li class="parameter">
                <span class="param-name">destURL</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Destination URL of copying.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="io.listModels" href="#io.listModels">
tf.io.listModels</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/io/model_management.ts#L192-L205" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>List all models stored in registered storage mediums.</p>
<p>For a web browser environment, the registered mediums are Local Storage and
IndexedDB.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// First create and save a model.</span>
<span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.dense(
     {<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>], <span class="hljs-attr">activation</span>: <span class="hljs-string">'sigmoid'</span>}));
<span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// Then list existing models.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Delete the model.</span>
<span class="hljs-keyword">await</span> tf.io.removeModel(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// List models again.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));
</code></pre>

</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="io.moveModel" href="#io.moveModel">
tf.io.moveModel</a>
    <span class="signature">(sourceURL, destURL)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/io/model_management.ts#L326-L331" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Move a model from one URL to another.</p>
<p>This function supports:</p>
<ol>
<li>Moving within a storage medium, e.g.,
<code>tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')</code></li>
<li>Moving between two storage mediums, e.g.,
<code>tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')</code></li>
</ol>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// First create and save a model.</span>
<span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.dense(
     {<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>], <span class="hljs-attr">activation</span>: <span class="hljs-string">'sigmoid'</span>}));
<span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// Then list existing models.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Move the model, from Local Storage to IndexedDB.</span>
<span class="hljs-keyword">await</span> tf.io.moveModel(
     <span class="hljs-string">'localstorage://demo/management/model1'</span>,
     <span class="hljs-string">'indexeddb://demo/management/model1'</span>);

<span class="hljs-comment">// List models again.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Remove the moved model.</span>
<span class="hljs-keyword">await</span> tf.io.removeModel(<span class="hljs-string">'indexeddb://demo/management/model1'</span>);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">sourceURL</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Source URL of moving.</span>
            </li>
            <li class="parameter">
                <span class="param-name">destURL</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Destination URL of moving.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="io.removeModel" href="#io.removeModel">
tf.io.removeModel</a>
    <span class="signature">(url)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/io/model_management.ts#L233-L238" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Remove a model specified by URL from a reigstered storage medium.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// First create and save a model.</span>
<span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.dense(
     {<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>], <span class="hljs-attr">activation</span>: <span class="hljs-string">'sigmoid'</span>}));
<span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// Then list existing models.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));

<span class="hljs-comment">// Delete the model.</span>
<span class="hljs-keyword">await</span> tf.io.removeModel(<span class="hljs-string">'localstorage://demo/management/model1'</span>);

<span class="hljs-comment">// List models again.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(<span class="hljs-keyword">await</span> tf.io.listModels()));
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">url</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">A URL to a stored model, with a scheme prefix, e.g.,
              'localstorage://my-model-1', 'indexeddb://my/model/2'.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Models / Classes
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:Model" href="#class:Model">tf.Model</a>
    <span class="signature">
        <span>extends Container|tfc.InferenceModel</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L622-L1940" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A <a href="#class:Model">tf.Model</a> is a directed, acyclic graph of <code>Layer</code>s plus methods for
training, evaluation, prediction and saving.</p>
<p><a href="#class:Model">tf.Model</a> is the basic unit of training, inference and evaluation in
TensorFlow.js. To create a <a href="#class:Model">tf.Model</a>, use <a href="#model">tf.model()</a>.</p>
<p>See also:
<a href="#class:Sequential">tf.Sequential</a>, <a href="#loadModel">tf.loadModel()</a>.</p>
</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.summary" href="#tf.Model.summary">
summary</a>
    <span class="signature">(lineLength?, positions?, printFn?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L692-L705" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Print a text summary of the model's layers.</p>
<p>The summary includes</p>
<ul>
<li>Name and type of all layers that comprise the model.</li>
<li>Output shape(s) of the layers</li>
<li>Number of weight parameters of each layer</li>
<li>If the model has non-sequential-like topology, the inputs each layer
receives</li>
<li>The total number of trainable and non-trainable parameters of the model.</li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> dense1 = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}).apply(input1);
<span class="hljs-keyword">const</span> dense2 = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>}).apply(input2);
<span class="hljs-keyword">const</span> concat = tf.layers.concatenate().apply([dense1, dense2]);
<span class="hljs-keyword">const</span> output =
     tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">3</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'softmax'</span>}).apply(concat);

<span class="hljs-keyword">const</span> model = tf.model({<span class="hljs-attr">inputs</span>: [input1, input2], <span class="hljs-attr">outputs</span>: output});
model.summary();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">lineLength</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Custom line length, in number of characters.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">positions</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Custom widths of each of the columns, as either
              fractions of <code>lineLength</code> (e.g., <code>[0.5, 0.75, 1]</code>) or absolute number
              of characters (e.g., <code>[30, 50, 65]</code>). Each number corresponds to
              right-most (i.e., ending) position of a column.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">printFn</span>
                <span class="param-type">((message?: <a href="#any">tf.any()</a>, ...optionalParams: <a href="#any">tf.any()</a>[]) =&gt; void)</span>
                <span class="param-docs">Custom print function. Can be used to replace the default
              <code>console.log</code>. For example, you can use <code>x =&gt; {}</code> to mute the printed
              messages in the console.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.compile" href="#tf.Model.compile">
compile</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L715-L915" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Configures and prepares the model for training and evaluation.  Compiling
outfits the model with an optimizer, loss, and/or metrics.  Calling <code>fit</code>
or <code>evaluate</code> on an un-compiled model will throw an error.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">a <code>ModelCompileConfig</code> specifying the loss, optimizer, and
              metrics to be used for fitting and evaluating this model.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">optimizer</span>
                <span class="param-type">(string|<a href="#class:train.Optimizer">tf.train.Optimizer</a>)</span>
                <span class="param-docs">An instance of <code>tf.train.Optimizer</code> or a string name for an Optimizer.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">loss</span>
                <span class="param-type">(string|string[]|{[outputName: string]: string}|LossOrMetricFn|
              LossOrMetricFn[]|{[outputName: string]: LossOrMetricFn})</span>
                <span class="param-docs">Object function(s) or name(s) of object function(s).
              If the model has multiple outputs, you can use a different loss
              on each output by passing a dictionary or an Array of losses.
              The loss value that will be minimized by the model will then be the sum
              of all individual losses.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">metrics</span>
                <span class="param-type">(string[]|{[outputName: string]: string})</span>
                <span class="param-docs">List of metrics to be evaluated by the model during training and testing.
              Typically you will use <code>metrics=['accuracy']</code>.
              To specify different metrics for different outputs of a multi-output
              model, you could also pass a dictionary.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.evaluate" href="#tf.Model.evaluate">
evaluate</a>
    <span class="signature">(x, y, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L968-L985" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Loss and metrics are specified during <code>compile()</code>, which needs to happen
before calls to <code>evaluate()</code>.</p>
<p>Computation is done in batches.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.compile({<span class="hljs-attr">optimizer</span>: <span class="hljs-string">'sgd'</span>, <span class="hljs-attr">loss</span>: <span class="hljs-string">'meanSquaredError'</span>});
<span class="hljs-keyword">const</span> result = model.evaluate(
     tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>]), tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">1</span>]), {<span class="hljs-attr">batchSize</span>: <span class="hljs-number">4</span>});
result.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of test data, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if the model has
              multiple inputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">y</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of target data, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if the model
              has multiple outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">A <code>ModelEvaluateConfig</code>, containing optional fields.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Batch size (Integer). If unspecified, it will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(ModelLoggingVerbosity)</span>
                <span class="param-docs">Verbosity mode.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sampleWeight</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">Tensor of weights to weight the contribution of different samples to the
              loss and metrics.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">steps</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">integer: total number of steps (batches of samples)
              before declaring the evaluation round finished. Ignored with the default
              value of <code>undefined</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Scalar</a>|<a href="#class:Tensor">tf.Scalar</a>[]</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.predict" href="#tf.Model.predict">
predict</a>
    <span class="signature">(x, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L1204-L1214" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches.</p>
<p>Note: the &quot;step&quot; mode of predict() is currently not supported.
This is because the TensorFlow.js core backend is imperative only.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.predict(tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>]), {<span class="hljs-attr">batchSize</span>: <span class="hljs-number">4</span>}).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">The input data, as an Tensor, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if
              the model has multiple inputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">A <code>ModelPredictConfig</code> object containing optional fields.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Optional. Batch size (Integer). If unspecified, it will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Optional. Verbosity mode. Defaults to false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>
|<a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.predictOnBatch" href="#tf.Model.predictOnBatch">
predictOnBatch</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L1228-L1234" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns predictions for a single batch of samples.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.predictOnBatch(tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>])).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">: Input samples, as an Tensor</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.fit" href="#tf.Model.fit">
fit</a>
    <span class="signature">(x, y, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L1605-L1802" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
     <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.compile({<span class="hljs-attr">optimizer</span>: <span class="hljs-string">'sgd'</span>, <span class="hljs-attr">loss</span>: <span class="hljs-string">'meanSquaredError'</span>});
<span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> i = <span class="hljs-number">1</span>; i &lt; <span class="hljs-number">5</span> ; ++i) {
   <span class="hljs-keyword">const</span> h = <span class="hljs-keyword">await</span> model.fit(tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>]), tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">1</span>]), {
       <span class="hljs-attr">batchSize</span>: <span class="hljs-number">4</span>,
       <span class="hljs-attr">epochs</span>: <span class="hljs-number">3</span>
   });
   <span class="hljs-built_in">console</span>.log(<span class="hljs-string">"Loss after Epoch "</span> + i + <span class="hljs-string">" : "</span> + h.history.loss[<span class="hljs-number">0</span>]);
}
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[inputName: string]: <a href="#class:Tensor">tf.Tensor</a>})</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of training data, or an array of <a href="#class:Tensor">tf.Tensor</a>s if the model
              has multiple inputs. If all inputs in the model are named, you can also
              pass a dictionary mapping input names to <a href="#class:Tensor">tf.Tensor</a>s.</span>
            </li>
            <li class="parameter">
                <span class="param-name">y</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[inputName: string]: <a href="#class:Tensor">tf.Tensor</a>})</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of target (label) data, or an array of <a href="#class:Tensor">tf.Tensor</a>s if the
              model has multiple outputs. If all outputs in the model are named, you
              can also pass a dictionary mapping output names to <a href="#class:Tensor">tf.Tensor</a>s.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">A <code>ModelFitConfig</code>, containing optional fields.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of samples per gradient update. If unspecified, it
              will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">epochs</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of times to iterate over the training data arrays.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(ModelLoggingVerbosity)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">callbacks</span>
                <span class="param-type">(BaseCallback[]|CustomCallbackConfig|CustomCallbackConfig[])</span>
                <span class="param-docs">List of callbacks to be called during training.
              Can consist of one or more of the following fields: <code>onTrainBegin</code>,
              <code>onTrainEnd</code>, <code>onEpochBegin</code>, <code>onEpochEnd</code>, <code>onBatchBegin</code>, <code>onBatchEnd</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationSplit</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float between 0 and 1: fraction of the training data
              to be used as validation data. The model will set apart this fraction of
              the training data, will not train on it, and will evaluate the loss and
              any model metrics on this data at the end of each epoch.
              The validation data is selected from the last samples in the <code>x</code> and <code>y</code>
              data provided, before shuffling.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationData</span>
                <span class="param-type">([
              <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]
              ]|[<a href="#class:Tensor">tf.Tensor</a> | <a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]])</span>
                <span class="param-docs">Data on which to evaluate the loss and any model
              metrics at the end of each epoch. The model will not be trained on this
              data. This could be a tuple [xVal, yVal] or a tuple [xVal, yVal,
              valSampleWeights]. The model will not be trained on this data.
              <code>validationData</code> will override <code>validationSplit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">shuffle</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to shuffle the training data before each epoch. Has
              no effect when <code>stepsPerEpoch</code> is not <code>null</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">classWeight</span>
                <span class="param-type">({[classIndex: string]: number})</span>
                <span class="param-docs">Optional dictionary mapping class indices (integers) to
              a weight (float) to apply to the model's loss for the samples from this
              class during training. This can be useful to tell the model to &quot;pay more
              attention&quot; to samples from an under-represented class.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sampleWeight</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">Optional array of the same length as x, containing
              weights to apply to the model's loss for each sample. In the case of
              temporal data, you can pass a 2D array with shape (samples,
              sequenceLength), to apply a different weight to every timestep of every
              sample. In this case you should make sure to specify
              sampleWeightMode=&quot;temporal&quot; in compile().</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">initialEpoch</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Epoch at which to start training (useful for resuming a previous training
              run).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">stepsPerEpoch</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Total number of steps (batches of samples) before
              declaring one epoch finished and starting the next epoch. When training
              with Input Tensors such as TensorFlow data tensors, the default <code>null</code> is
              equal to the number of unique samples in your dataset divided by the
              batch size, or 1 if that cannot be determined.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationSteps</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Only relevant if <code>stepsPerEpoch</code> is specified. Total number of steps
              (batches of samples) to validate before stopping.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.save" href="#tf.Model.save">
save</a>
    <span class="signature">(handlerOrURL, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/training.ts#L1905-L1939" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Save the configuration and/or weights of the Model.</p>
<p>An <code>IOHandler</code> is an object that has a <code>save</code> method of the proper
signature defined. The <code>save</code> method manages the storing or transmission
of serialized data (&quot;artifacts&quot;) that represent the model's topology and
weights onto or via a specific medium, such as file downloads, local
storage, IndexedDB in the web browser and HTTP requests to a server.
TensorFlow.js provides <code>IOHandler</code> implementations for a number of
frequently used saving mediums, such as <code>tf.io.browserDownloads</code> and
<code>tf.io.browserLocalStorage</code>. See <code>tf.io</code> for more details.</p>
<p>This method also allows you to refer to certain types of <code>IOHandler</code>s as
URL-like string shortcuts, such as 'localstorage://' and 'indexeddb://'.</p>
<p>Example 1: Save <a href="#model">tf.model()</a>'s topology and weights to browser <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage">local
storage</a>;
then load it back.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from original model:'</span>);
model.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();

<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'localstorage://my-model-1'</span>);

<span class="hljs-keyword">const</span> loadedModel = <span class="hljs-keyword">await</span> tf.loadModel(<span class="hljs-string">'localstorage://my-model-1'</span>);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from loaded model:'</span>);
loadedModel.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();
</code></pre>

<p>Example 2. Saving <a href="#model">tf.model()</a>'s topology and weights to browser
<a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API">IndexedDB</a>;
then load it back.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from original model:'</span>);
model.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();

<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'indexeddb://my-model-1'</span>);

<span class="hljs-keyword">const</span> loadedModel = <span class="hljs-keyword">await</span> tf.loadModel(<span class="hljs-string">'indexeddb://my-model-1'</span>);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Prediction from loaded model:'</span>);
loadedModel.predict(tf.ones([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])).print();
</code></pre>

<p>Example 3. Saving <a href="#model">tf.model()</a>'s topology and weights as two files
(<code>my-model-1.json</code> and <code>my-model-1.weights.bin</code>) downloaded from browser.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'downloads://my-model-1'</span>);
</code></pre>

<p>Example 4. Send  <a href="#model">tf.model()</a>'s topology and weights to an HTTP server.
See the documentation of <code>tf.io.browserHTTPRequests</code> for more details
including specifying request parameters and implementation of the server.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential(
     {<span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">3</span>]})]});
<span class="hljs-keyword">const</span> saveResults = <span class="hljs-keyword">await</span> model.save(<span class="hljs-string">'http://my-server/model/upload'</span>);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">handlerOrURL</span>
                <span class="param-type">(io.IOHandler|string)</span>
                <span class="param-docs">An instance of <code>IOHandler</code> or a URL-like,
              scheme-based string shortcut for <code>IOHandler</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">Options for saving the model.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Model.getLayer" href="#tf.Model.getLayer">
getLayer</a>
    <span class="signature">(name?, index?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/topology.ts#L2449-L2476" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Retrieves a layer based on either its name (unique) or index.</p>
<p>Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p>If both <code>name</code> and <code>index</code> are specified, <code>index</code> takes precedence.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name of layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">index</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Index of layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

  </div>
</div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:Sequential" href="#class:Sequential">tf.Sequential</a>
    <span class="signature">
        <span>extends <a href="#class:Model">tf.Model</a></span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L293-L767" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A model with a stack of layers, feeding linearly from one to the next.</p>
<p><a href="#sequential">tf.sequential()</a> is a factory function that creates an instance of
<a href="#class:Sequential">tf.Sequential</a>.</p>
<pre class="hljs"><code class="hljs language-js">  <span class="hljs-comment">// Define a model for linear regression.</span>
  <span class="hljs-keyword">const</span> model = tf.sequential();
  model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">1</span>]}));

  <span class="hljs-comment">// Prepare the model for training: Specify the loss and the optimizer.</span>
  model.compile({<span class="hljs-attr">loss</span>: <span class="hljs-string">'meanSquaredError'</span>, <span class="hljs-attr">optimizer</span>: <span class="hljs-string">'sgd'</span>});

  <span class="hljs-comment">// Generate some synthetic data for training.</span>
  <span class="hljs-keyword">const</span> xs = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">1</span>]);
  <span class="hljs-keyword">const</span> ys = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">1</span>]);

  <span class="hljs-comment">// Train the model using the data then do inference on a data point the</span>
  <span class="hljs-comment">// model hasn't seen:</span>
  <span class="hljs-keyword">await</span> model.fit(xs, ys);
  model.predict(tf.tensor2d([<span class="hljs-number">5</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])).print();
</code></pre>

</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Sequential.add" href="#tf.Sequential.add">
add</a>
    <span class="signature">(layer)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L336-L437" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Adds a layer instance on top of the layer stack.</p>
<pre class="hljs"><code class="hljs language-js">  <span class="hljs-keyword">const</span> model = tf.sequential();
  model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">1</span>]}));
  model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'relu6'</span>}));
  model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'relu6'</span>}));
  <span class="hljs-comment">// Note that the untrained model is random at this point.</span>
  model.predict(tf.randomNormal([<span class="hljs-number">10</span>, <span class="hljs-number">1</span>])).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">layer</span>
                <span class="param-type">(<a href="#class:layers.Layer">tf.layers.Layer</a>)</span>
                <span class="param-docs">Layer instance.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Sequential.summary" href="#tf.Sequential.summary">
summary</a>
    <span class="signature">(lineLength?, positions?, printFn?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L542-L552" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Print a text summary of the Sequential model's layers.</p>
<p>The summary includes</p>
<ul>
<li>Name and type of all layers that comprise the model.</li>
<li>Output shape(s) of the layers</li>
<li>Number of weight parameters of each layer</li>
<li>The total number of trainable and non-trainable parameters of the model.</li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential();
model.add(
     tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">100</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>], <span class="hljs-attr">activation</span>: <span class="hljs-string">'relu'</span>}));
model.add(tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">activation</span>: <span class="hljs-string">'sigmoid'</span>}));

model.summary();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">lineLength</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Custom line length, in number of characters.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">positions</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Custom widths of each of the columns, as either
              fractions of <code>lineLength</code> (e.g., <code>[0.5, 0.75, 1]</code>) or absolute number
              of characters (e.g., <code>[30, 50, 65]</code>). Each number corresponds to
              right-most (i.e., ending) position of a column.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">printFn</span>
                <span class="param-type">((message?: <a href="#any">tf.any()</a>, ...optionalParams: <a href="#any">tf.any()</a>[]) =&gt; void)</span>
                <span class="param-docs">Custom print function. Can be used to replace the default
              <code>console.log</code>. For example, you can use <code>x =&gt; {}</code> to mute the printed
              messages in the console.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Sequential.evaluate" href="#tf.Sequential.evaluate">
evaluate</a>
    <span class="signature">(x, y, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L608-L617" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Loss and metrics are specified during <code>compile()</code>, which needs to happen
before calls to <code>evaluate()</code>.</p>
<p>Computation is done in batches.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.compile({<span class="hljs-attr">optimizer</span>: <span class="hljs-string">'sgd'</span>, <span class="hljs-attr">loss</span>: <span class="hljs-string">'meanSquaredError'</span>});
<span class="hljs-keyword">const</span> result = model.evaluate(tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>]), tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">1</span>]), {
   <span class="hljs-attr">batchSize</span>: <span class="hljs-number">4</span>,
});
result.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of test data, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if the model
              has multiple inputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">y</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of target data, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if the model
              has multiple outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">A <code>ModelEvaluateConfig</code>, containing optional fields.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Batch size (Integer). If unspecified, it will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(ModelLoggingVerbosity)</span>
                <span class="param-docs">Verbosity mode.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sampleWeight</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">Tensor of weights to weight the contribution of different samples to the
              loss and metrics.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">steps</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">integer: total number of steps (batches of samples)
              before declaring the evaluation round finished. Ignored with the default
              value of <code>undefined</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Scalar</a>|<a href="#class:Tensor">tf.Scalar</a>[]</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Sequential.predict" href="#tf.Sequential.predict">
predict</a>
    <span class="signature">(x, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L644-L651" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches.</p>
<p>Note: the &quot;step&quot; mode of predict() is currently not supported.
This is because the TensorFow.js core backend is imperative only.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.predict(tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">10</span>])).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">The input data, as an Tensor, or an <code>Array</code> of <a href="#class:Tensor">tf.Tensor</a>s if
              the model has multiple inputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Optional. Batch size (Integer). If unspecified, it will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Optional. Verbosity mode. Defaults to false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>
|<a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.Sequential.fit" href="#tf.Sequential.fit">
fit</a>
    <span class="signature">(x, y, config?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/models.ts#L714-L725" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential({
   <span class="hljs-attr">layers</span>: [tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>]})]
});
model.compile({<span class="hljs-attr">optimizer</span>: <span class="hljs-string">'sgd'</span>, <span class="hljs-attr">loss</span>: <span class="hljs-string">'meanSquaredError'</span>});
<span class="hljs-keyword">const</span> history = <span class="hljs-keyword">await</span> model.fit(tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">10</span>]), tf.ones([<span class="hljs-number">8</span>, <span class="hljs-number">1</span>]), {
   <span class="hljs-attr">batchSize</span>: <span class="hljs-number">4</span>,
   <span class="hljs-attr">epochs</span>: <span class="hljs-number">3</span>
});
<span class="hljs-built_in">console</span>.log(history.history.loss[<span class="hljs-number">0</span>]);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[inputName: string]: <a href="#class:Tensor">tf.Tensor</a>})</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of training data, or an array of <a href="#class:Tensor">tf.Tensor</a>s if the model
              has multiple inputs. If all inputs in the model are named, you can also
              pass a dictionary mapping input names to <a href="#class:Tensor">tf.Tensor</a>s.</span>
            </li>
            <li class="parameter">
                <span class="param-name">y</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[inputName: string]: <a href="#class:Tensor">tf.Tensor</a>})</span>
                <span class="param-docs"><a href="#class:Tensor">tf.Tensor</a> of target (label) data, or an array of <a href="#class:Tensor">tf.Tensor</a>s if the
              model has multiple outputs. If all outputs in the model are named, you
              can also pass a dictionary mapping output names to <a href="#class:Tensor">tf.Tensor</a>s.</span>
            </li>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs">A <code>ModelFitConfig</code>, containing optional fields.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number of samples per gradient update. If unspecified, it
              will default to 32.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">epochs</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of times to iterate over the training data arrays.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">verbose</span>
                <span class="param-type">(ModelLoggingVerbosity)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">callbacks</span>
                <span class="param-type">(BaseCallback[]|CustomCallbackConfig|CustomCallbackConfig[])</span>
                <span class="param-docs">List of callbacks to be called during training.
              Can consist of one or more of the following fields: <code>onTrainBegin</code>,
              <code>onTrainEnd</code>, <code>onEpochBegin</code>, <code>onEpochEnd</code>, <code>onBatchBegin</code>, <code>onBatchEnd</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationSplit</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float between 0 and 1: fraction of the training data
              to be used as validation data. The model will set apart this fraction of
              the training data, will not train on it, and will evaluate the loss and
              any model metrics on this data at the end of each epoch.
              The validation data is selected from the last samples in the <code>x</code> and <code>y</code>
              data provided, before shuffling.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationData</span>
                <span class="param-type">([
              <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]
              ]|[<a href="#class:Tensor">tf.Tensor</a> | <a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[], <a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]])</span>
                <span class="param-docs">Data on which to evaluate the loss and any model
              metrics at the end of each epoch. The model will not be trained on this
              data. This could be a tuple [xVal, yVal] or a tuple [xVal, yVal,
              valSampleWeights]. The model will not be trained on this data.
              <code>validationData</code> will override <code>validationSplit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">shuffle</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to shuffle the training data before each epoch. Has
              no effect when <code>stepsPerEpoch</code> is not <code>null</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">classWeight</span>
                <span class="param-type">({[classIndex: string]: number})</span>
                <span class="param-docs">Optional dictionary mapping class indices (integers) to
              a weight (float) to apply to the model's loss for the samples from this
              class during training. This can be useful to tell the model to &quot;pay more
              attention&quot; to samples from an under-represented class.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sampleWeight</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">Optional array of the same length as x, containing
              weights to apply to the model's loss for each sample. In the case of
              temporal data, you can pass a 2D array with shape (samples,
              sequenceLength), to apply a different weight to every timestep of every
              sample. In this case you should make sure to specify
              sampleWeightMode=&quot;temporal&quot; in compile().</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">initialEpoch</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Epoch at which to start training (useful for resuming a previous training
              run).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">stepsPerEpoch</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Total number of steps (batches of samples) before
              declaring one epoch finished and starting the next epoch. When training
              with Input Tensors such as TensorFlow data tensors, the default <code>null</code> is
              equal to the number of unique samples in your dataset divided by the
              batch size, or 1 if that cannot be determined.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">validationSteps</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Only relevant if <code>stepsPerEpoch</code> is specified. Total number of steps
              (batches of samples) to validate before stopping.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

  </div>
</div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:SymbolicTensor" href="#class:SymbolicTensor">tf.SymbolicTensor</a>
    <span class="signature">
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/topology.ts#L100-L148" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p><a href="#class:SymbolicTensor">tf.SymbolicTensor</a> is a placeholder for a Tensor without any concrete value.</p>
<p>They are most often encountered when building a graph of <code>Layer</code>s for a
a <a href="#class:Model">tf.Model</a> and the input data's shape, but not values are known.</p>
</div>

  <div class="method-list">
  </div>
</div>
      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Layers
            </div>
          <div class="description">
             <p>Layers are the primary building block for 
        constructing a Model.  Each layer will typically perform some
        computation to transform its input to its output.</p>
        <p>Layers will automatically take care of creating and initializing
        the various internal variables/weights they need to function.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Layers / Advanced Activation
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.elu" href="#layers.elu">
tf.layers.elu</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L198-L207" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Exponetial Linear Unit (ELU).</p>
<p>It follows:
<code>f(x) = alpha * (exp(x) - 1.) for x &lt; 0</code>,
<code>f(x) = x for x &gt;= 0</code>.</p>
<p>Input shape:
Arbitrary. Use the configuration <code>inputShape</code> when using this layer as the
first layer in a model.</p>
<p>Output shape:
Same shape as the input.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/abs/1511.07289v1">Fast and Accurate Deep Network Learning by Exponential Linear Units
(ELUs)</a></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">alpha</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float <code>&gt;= 0</code>. Negative slope coefficient. Defaults to <code>1.0</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.leakyReLU" href="#layers.leakyReLU">
tf.layers.leakyReLU</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L209-L218" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Leaky version of a rectified linear unit.</p>
<p>It allows a small gradient when the unit is not active:
<code>f(x) = alpha * x for x &lt; 0.</code>
<code>f(x) = x for x &gt;= 0.</code></p>
<p>Input shape:
Arbitrary. Use the configuration <code>inputShape</code> when using this layer as the
first layer in a model.</p>
<p>Output shape:
Same shape as the input.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">alpha</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float <code>&gt;= 0</code>. Negative slope coefficient. Defaults to <code>0.3</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.softmax" href="#layers.softmax">
tf.layers.softmax</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L220-L229" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Softmax activation layer.</p>
<p>Input shape:
Arbitrary. Use the configuration <code>inputShape</code> when using this layer as the
first layer in a model.</p>
<p>Output shape:
Same shape as the input.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Integer, axis along which the softmax normalization is applied.
              Defaults to <code>-1</code> (i.e., the last axis).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.thresholdedReLU" href="#layers.thresholdedReLU">
tf.layers.thresholdedReLU</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L231-L240" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Thresholded Rectified Linear Unit.</p>
<p>It follows:
<code>f(x) = x for x &gt; theta</code>,
<code>f(x) = 0 otherwise</code>.</p>
<p>Input shape:
Arbitrary. Use the configuration <code>inputShape</code> when using this layer as the
first layer in a model.</p>
<p>Output shape:
Same shape as the input.</p>
<p>References:</p>
<ul>
<li><a href="http://arxiv.org/abs/1402.3337">Zero-Bias Autoencoders and the Benefits of Co-Adapting
Features</a></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">theta</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float &gt;= 0. Threshold location of activation.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Basic
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.activation" href="#layers.activation">
tf.layers.activation</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L324-L333" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Applies an activation function to an output.</p>
<p>This layer applies element-wise activation function.  Other layers, notably
<code>dense</code> can also apply activation functions.  Use this isolated activation
function to extract the values before and after the
activation. For instance:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">5</span>]});
<span class="hljs-keyword">const</span> denseLayer = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>});
<span class="hljs-keyword">const</span> activationLayer = tf.layers.activation({<span class="hljs-attr">activation</span>: <span class="hljs-string">'relu6'</span>});

<span class="hljs-comment">// Obtain the output symbolic tensors by applying the layers in order.</span>
<span class="hljs-keyword">const</span> denseOutput = denseLayer.apply(input);
<span class="hljs-keyword">const</span> activationOutput = activationLayer.apply(denseOutput);

<span class="hljs-comment">// Create the model based on the inputs.</span>
<span class="hljs-keyword">const</span> model = tf.model({
     <span class="hljs-attr">inputs</span>: input,
     <span class="hljs-attr">outputs</span>: [denseOutput, activationOutput]
});

<span class="hljs-comment">// Collect both outputs and print separately.</span>
<span class="hljs-keyword">const</span> [denseOut, activationOut] = model.predict(tf.randomNormal([<span class="hljs-number">6</span>, <span class="hljs-number">5</span>]));
denseOut.print();
activationOut.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activation</span>
                <span class="param-type">('elu'|'hardSigmoid'|'linear'|'relu'|'relu6'|
              'selu'|'sigmoid'|'softmax'|'softplus'|'softsign'|'tanh'|string)</span>
                <span class="param-docs">Name of the activation function to use.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.dense" href="#layers.dense">
tf.layers.dense</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L335-L344" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Creates a dense (fully connected) layer.</p>
<p>This layer implements the operation:
<code>output = activation(dot(input, kernel) + bias)</code></p>
<p><code>activation</code> is the element-wise activation function
passed as the <code>activation</code> argument.</p>
<p><code>kernel</code> is a weights matrix created by the layer.</p>
<p><code>bias</code> is a bias vector created by the layer (only applicable if <code>useBias</code>
is <code>true</code>).</p>
<p><strong>Input shape:</strong></p>
<p>nD <a href="#class:Tensor">tf.Tensor</a> with shape: <code>(batchSize, ..., inputDim)</code>.</p>
<p>The most common situation would be
a 2D input with shape <code>(batchSize, inputDim)</code>.</p>
<p><strong>Output shape:</strong></p>
<p>nD tensor with shape: <code>(batchSize, ..., units)</code>.</p>
<p>For instance, for a 2D input with shape <code>(batchSize, inputDim)</code>,
the output would have shape <code>(batchSize, units)</code>.</p>
<p>Note: if the input to the layer has a rank greater than 2, then it is
flattened prior to the initial dot product with the kernel.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">units</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Positive integer, dimensionality of the output space.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activation</span>
                <span class="param-type">('elu'|'hardSigmoid'|'linear'|'relu'|'relu6'|
              'selu'|'sigmoid'|'softmax'|'softplus'|'softsign'|'tanh'|string)</span>
                <span class="param-docs">Activation function to use.</p>
              <p>If unspecified, no activation is applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">useBias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to apply a bias.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the dense kernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDim</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If specified, defines inputShape as <code>[inputDim]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint for the kernel weights.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint for the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the dense kernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activityRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the activation.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.dropout" href="#layers.dropout">
tf.layers.dropout</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L346-L355" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Applies
<a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">dropout</a> to
the input.</p>
<p>Dropout consists in randomly setting a fraction <code>rate</code> of input units to 0 at
each update during training time, which helps prevent overfitting.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">rate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float between 0 and 1. Fraction of the input units to drop.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">noiseShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Integer array representing the shape of the binary dropout mask that will
              be multiplied with the input.</p>
              <p>For instance, if your inputs have shape <code>(batchSize, timesteps, features)</code>
              and you want the dropout mask to be the same for all timesteps, you can use
              <code>noise_shape=(batch_size, 1, features)</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">An integer to use as random seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.embedding" href="#layers.embedding">
tf.layers.embedding</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L390-L399" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Maps positive integers (indices) into dense vectors of fixed size.
eg. [[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]]</p>
<p><strong>Input shape:</strong> 2D tensor with shape: <code>[batchSize, sequenceLength]</code>.</p>
<p><strong>Output shape:</strong> 3D tensor with shape: <code>[batchSize, sequenceLength, outputDim]</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDim</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Integer &gt; 0. Size of the vocabulary, i.e. maximum integer index + 1.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">outputDim</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Integer &gt;= 0. Dimension of the dense embedding.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">embeddingsInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the <code>embeddings</code> matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">embeddingsRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the <code>embeddings</code> matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activityRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the activation.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">embeddingsConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the <code>embeddings</code> matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">maskZero</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the input value 0 is a special &quot;padding&quot; value that should be
              masked out. This is useful when using recurrent layers which may take
              variable length input.</p>
              <p>If this is <code>True</code> then all subsequent layers in the model need to support
              masking or an exception will be raised. If maskZero is set to <code>True</code>, as a
              consequence, index 0 cannot be used in the vocabulary (inputDim should
              equal size of vocabulary + 1).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputLength</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">Length of input sequences, when it is constant.</p>
              <p>This argument is required if you are going to connect <code>flatten</code> then
              <code>dense</code> layers upstream (without it, the shape of the dense outputs cannot
              be computed).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.flatten" href="#layers.flatten">
tf.layers.flatten</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L357-L366" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Flattens the input. Does not affect the batch size.</p>
<p>A <code>Flatten</code> layer flattens each batch in its inputs to 1D (making the output
2D).</p>
<p>For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>]});
<span class="hljs-keyword">const</span> flattenLayer = tf.layers.flatten();
<span class="hljs-comment">// Inspect the inferred output shape of the flatten layer, which</span>
<span class="hljs-comment">// equals `[null, 12]`. The 2nd dimension is 4 * 3, i.e., the result of the</span>
<span class="hljs-comment">// flattening. (The 1st dimension is the undermined batch size.)</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(flattenLayer.apply(input).shape));
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.repeatVector" href="#layers.repeatVector">
tf.layers.repeatVector</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L368-L377" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Repeats the input n times in a new dimension.</p>
<pre class="hljs"><code class="hljs language-js">  <span class="hljs-keyword">const</span> model = tf.sequential();
  model.add(tf.layers.repeatVector({<span class="hljs-attr">n</span>: <span class="hljs-number">4</span>, <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">2</span>]}));
  <span class="hljs-keyword">const</span> x = tf.tensor2d([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]]);
  <span class="hljs-comment">// Use the model to do inference on a data point the model hasn't see</span>
  model.predict(x).print();
  <span class="hljs-comment">// output shape is now [batch, 2, 4]</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">n</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The integer number of times to repeat the input.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.reshape" href="#layers.reshape">
tf.layers.reshape</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L379-L388" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Reshapes an input to a certain shape.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>]});
<span class="hljs-keyword">const</span> reshapeLayer = tf.layers.reshape({<span class="hljs-attr">targetShape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">6</span>]});
<span class="hljs-comment">// Inspect the inferred output shape of the Reshape layer, which</span>
<span class="hljs-comment">// equals `[null, 2, 6]`. (The 1st dimension is the undermined batch size.)</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(reshapeLayer.apply(input).shape));
</code></pre>

<p>Input shape:
Arbitrary: although all dimensions in the input shape must be fixed.
Use the ReshapeLayerConfig field <code>input_shape</code> when using this layer
as the first layer in a model.</p>
<p>Output shape:
[batchSize, targetShape[0], targetShape[1], ...,
targetShape[targetShape.length - 1]].</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">targetShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The target shape. Does not include the batch axis.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Convolutional
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.conv1d" href="#layers.conv1d">
tf.layers.conv1d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L244-L253" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>1D convolution layer (e.g., temporal convolution).</p>
<p>This layer creates a convolution kernel that is convolved
with the layer input over a single spatial (or temporal) dimension
to produce a tensor of outputs.</p>
<p>If <code>use_bias</code> is True, a bias vector is created and added to the outputs.</p>
<p>If <code>activation</code> is not <code>null</code>, it is applied to the outputs as well.</p>
<p>When using this layer as the first layer in a model, provide an
<code>inputShape</code> argument <code>Array</code> or <code>null</code>.</p>
<p>For example, <code>inputShape</code> would be:</p>
<ul>
<li><code>[10, 128]</code> for sequences of 10 vectors of 128-dimensional vectors</li>
<li><code>[null, 128]</code> for variable-length sequences of 128-dimensional vectors.</li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">filters</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimensionality of the output space (i.e. the number of filters in the
              convolution).</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.conv2d" href="#layers.conv2d">
tf.layers.conv2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L255-L264" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>2D convolution layer (e.g. spatial convolution over images).</p>
<p>This layer creates a convolution kernel that is convolved
with the layer input to produce a tensor of outputs.</p>
<p>If <code>useBias</code> is True, a bias vector is created and added to the outputs.</p>
<p>If <code>activation</code> is not <code>null</code>, it is applied to the outputs as well.</p>
<p>When using this layer as the first layer in a model,
provide the keyword argument <code>inputShape</code>
(Array of integers, does not include the sample axis),
e.g. <code>inputShape=[128, 128, 3]</code> for 128x128 RGB pictures
in <code>dataFormat='channelsLast'</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">filters</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimensionality of the output space (i.e. the number of filters in the
              convolution).</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.conv2dTranspose" href="#layers.conv2dTranspose">
tf.layers.conv2dTranspose</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L266-L275" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Transposed convolutional layer (sometimes called Deconvolution).</p>
<p>The need for transposed convolutions generally arises
from the desire to use a transformation going in the opposite direction of
a normal convolution, i.e., from something that has the shape of the output
of some convolution to something that has the shape of its input while
maintaining a connectivity pattern that is compatible with said
convolution.</p>
<p>When using this layer as the first layer in a model, provide the
configuration <code>inputShape</code> (<code>Array</code> of integers, does not include the
sample axis), e.g., <code>inputShape: [128, 128, 3]</code> for 128x128 RGB pictures in
<code>dataFormat: 'channelsLast'</code>.</p>
<p>Input shape:
4D tensor with shape:
<code>[batch, channels, rows, cols]</code> if <code>dataFormat</code> is <code>'channelsFirst'</code>.
or 4D tensor with shape
<code>[batch, rows, cols, channels]</code> if <code>dataFormat</code> is <code>'channelsLast</code>.</p>
<p>Output shape:
4D tensor with shape:
<code>[batch, filters, newRows, newCols]</code> if <code>dataFormat</code> is
<code>'channelsFirst'</code>. or 4D tensor with shape:
<code>[batch, newRows, newCols, filters]</code> if <code>dataFormat</code> is <code>'channelsLast'</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/abs/1603.07285v1">A guide to convolution arithmetic for deep
learning</a></li>
<li><a href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">Deconvolutional
Networks</a></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">filters</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimensionality of the output space (i.e. the number of filters in the
              convolution).</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.cropping2D" href="#layers.cropping2D">
tf.layers.cropping2D</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L288-L297" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Cropping layer for 2D input (e.g., image).</p>
<p>This layer can crop an input
at the top, bottom, left and right side of an image tensor.</p>
<p>Input shape:
4D tensor with shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, rows, cols, channels]</code></li>
<li>If <code>data_format</code> is <code>&quot;channels_first&quot;</code>:
<code>[batch, channels, rows, cols]</code>.</li>
</ul>
<p>Output shape:
4D with shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, croppedRows, croppedCols, channels]</code></li>
<li>If <code>dataFormat</code> is <code>&quot;channelsFirst&quot;</code>:
<code>[batch, channels, croppedRows, croppedCols]</code>.</li>
</ul>
<p>Examples</p>
<pre class="hljs"><code class="hljs language-js">
<span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.cropping2D({<span class="hljs-attr">cropping</span>:[[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]],
                                <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>]}));
<span class="hljs-comment">//now output shape is [batch, 124, 124, 3]</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">cropping</span>
                <span class="param-type">(number|[number, number]|[[number, number], [number, number]])</span>
                <span class="param-docs">Dimension of the cropping along the width and the height.</p>
              <ul>
              <li>If integer: the same symmetric cropping
              is applied to width and height.</li>
              <li>If list of 2 integers:
              interpreted as two different
              symmetric cropping values for height and width:
              <code>[symmetric_height_crop, symmetric_width_crop]</code>.</li>
              <li>If a list of 2 list of 2 integers:
              interpreted as
              <code>[[top_crop, bottom_crop], [left_crop, right_crop]]</code></li>
              </ul>
              </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">Format of the data, which determines the ordering of the dimensions in
              the inputs.</p>
              <p><code>channels_last</code> corresponds to inputs with shape
              <code>(batch, ..., channels)</code></p>
              <p><code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, ...)</code>.</p>
              <p>Defaults to <code>channels_last</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.depthwiseConv2d" href="#layers.depthwiseConv2d">
tf.layers.depthwiseConv2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L312-L321" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Depthwise separable 2D convolution.</p>
<p>Depthwise Separable convolutions consists in performing just the first step
in a depthwise spatial convolution (which acts on each input channel
separately). The <code>depthMultplier</code> argument controls how many output channels
are generated per input channel in the depthwise step.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelSize</span>
                <span class="param-type">(number|[number, number])</span>
                <span class="param-docs">An integer or Array of 2 integers, specifying the width and height of the
              2D convolution window. Can be a single integer to specify the same value
              for all spatial dimensions.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthMultiplier</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of depthwise convolution output channels for each input
              channel.
              The total number of depthwise convolution output channels will be equal to
              <code>filtersIn * depthMultiplier</code>.
              Default: 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the depthwise kernel matrix.
              Default: GlorotNormal.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint for the depthwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regulzarizer function for the depthwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.separableConv2d" href="#layers.separableConv2d">
tf.layers.separableConv2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L277-L286" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Depthwise separable 2D convolution.</p>
<p>Separable convolution consists of first performing
a depthwise spatial convolution
(which acts on each input channel separately)
followed by a pointwise convolution which mixes together the resulting
output channels. The <code>depthMultiplier</code> argument controls how many
output channels are generated per input channel in the depthwise step.</p>
<p>Intuitively, separable convolutions can be understood as
a way to factorize a convolution kernel into two smaller kernels,
or as an extreme version of an Inception block.</p>
<p>Input shape:
4D tensor with shape:
<code>[batch, channels, rows, cols]</code> if data_format='channelsFirst'
or 4D tensor with shape:
<code>[batch, rows, cols, channels]</code> if data_format='channelsLast'.</p>
<p>Output shape:
4D tensor with shape:
<code>[batch, filters, newRows, newCols]</code> if data_format='channelsFirst'
or 4D tensor with shape:
<code>[batch, newRows, newCols, filters]</code> if data_format='channelsLast'.
<code>rows</code> and <code>cols</code> values might have changed due to padding.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthMultiplier</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of depthwise convolution output channels for each input
              channel.
              The total number of depthwise convolution output channels will be equal
              to <code>filtersIn * depthMultiplier</code>. Default: 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the depthwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">pointwiseInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the pointwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the depthwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">pointwiseRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the pointwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">depthwiseConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the depthwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">pointwiseConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the pointwise kernel matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.upSampling2d" href="#layers.upSampling2d">
tf.layers.upSampling2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L299-L308" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Upsampling layer for 2D inputs.</p>
<p>Repeats the rows and columns of the data
by size[0] and size[1] respectively.</p>
<p>Input shape:
4D tensor with shape:
- If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, rows, cols, channels]</code>
- If <code>dataFormat</code> is <code>&quot;channelsFirst&quot;</code>:
<code>[batch, channels, rows, cols]</code></p>
<p>Output shape:
4D tensor with shape:
- If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, upsampledRows, upsampledCols, channels]</code>
- If <code>dataFormat</code> is <code>&quot;channelsFirst&quot;</code>:
<code>[batch, channels, upsampledRows, upsampledCols]</code></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">size</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The upsampling factors for rows and columns.</p>
              <p>Defaults to <code>[2, 2]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">Format of the data, which determines the ordering of the dimensions in
              the inputs.</p>
              <p><code>&quot;channelsLast&quot;</code> corresponds to inputs with shape
              <code>[batch, ..., channels]</code></p>
              <p><code>&quot;channelsFirst&quot;</code> corresponds to inputs with shape <code>[batch, channels, ...]</code>.</p>
              <p>Defaults to <code>&quot;channelsLast&quot;</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Merge
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.add" href="#layers.add">
tf.layers.add</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L403-L412" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that performs element-wise addition on an <code>Array</code> of inputs.</p>
<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape). The inputs are specified as an
<code>Array</code> when the <code>apply</code> method of the <code>Add</code> layer instance is called. For
example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> addLayer = tf.layers.add();
<span class="hljs-keyword">const</span> sum = addLayer.apply([input1, input2]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(sum.shape));
<span class="hljs-comment">// You get [null, 2, 2], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension.</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.average" href="#layers.average">
tf.layers.average</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L414-L423" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that performs element-wise averaging on an <code>Array</code> of inputs.</p>
<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape). For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> averageLayer = tf.layers.average();
<span class="hljs-keyword">const</span> average = averageLayer.apply([input1, input2]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(average.shape));
<span class="hljs-comment">// You get [null, 2, 2], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension.</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.concatenate" href="#layers.concatenate">
tf.layers.concatenate</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L425-L434" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that concatenates an <code>Array</code> of inputs.</p>
<p>It takes a list of tensors, all of the same shape except for the
concatenation axis, and returns a single tensor, the concatenation
of all inputs. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]});
<span class="hljs-keyword">const</span> concatLayer = tf.layers.concatenate();
<span class="hljs-keyword">const</span> output = concatLayer.apply([input1, input2]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// You get [null, 2, 5], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension. The last dimension (5) is the result of concatenating the</span>
<span class="hljs-comment">// last dimensions of the inputs (2 and 3).</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Axis along which to concatenate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.maximum" href="#layers.maximum">
tf.layers.maximum</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L436-L445" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that computes the element-wise maximum an <code>Array</code> of inputs.</p>
<p>It takes as input a list of tensors, all of the same shape and returns a
single tensor (also of the same shape). For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> maxLayer = tf.layers.maximum();
<span class="hljs-keyword">const</span> max = maxLayer.apply([input1, input2]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(max.shape));
<span class="hljs-comment">// You get [null, 2, 2], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension.</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.minimum" href="#layers.minimum">
tf.layers.minimum</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L447-L456" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that computes the element-wise minimum of an <code>Array</code> of inputs.</p>
<p>It takes as input a list of tensors, all of the same shape and returns a
single tensor (also of the same shape). For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> minLayer = tf.layers.minimum();
<span class="hljs-keyword">const</span> min = minLayer.apply([input1, input2]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(min.shape));
<span class="hljs-comment">// You get [null, 2, 2], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension.</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.multiply" href="#layers.multiply">
tf.layers.multiply</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L458-L467" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Layer that multiplies (element-wise) an <code>Array</code> of inputs.</p>
<p>It takes as input an Array of tensors, all of the same
shape, and returns a single tensor (also of the same shape).
For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> input1 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input2 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> input3 = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> multiplyLayer = tf.layers.multiply();
<span class="hljs-keyword">const</span> product = multiplyLayer.apply([input1, input2, input3]);
<span class="hljs-built_in">console</span>.log(product.shape);
<span class="hljs-comment">// You get [null, 2, 2], with the first dimension as the undetermined batch</span>
<span class="hljs-comment">// dimension.</span></code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Normalization
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.batchNormalization" href="#layers.batchNormalization">
tf.layers.batchNormalization</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L471-L480" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Batch normalization layer (Ioffe and Szegedy, 2014).</p>
<p>Normalize the activations of the previous layer at each batch,
i.e. applies a transformation that maintains the mean activation
close to 0 and the activation standard deviation close to 1.</p>
<p>Input shape:
Arbitrary. Use the keyword argument <code>inputShape</code> (Array of integers, does
not include the sample axis) when calling the constructor of this class,
if this layer is used as a first layer in a model.</p>
<p>Output shape:
Same shape as input.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift</a></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The integer axis that should be normalized (typically the features axis).
              Defaults to -1.</p>
              <p>For instance, after a <code>Conv2D</code> layer with <code>data_format=&quot;channels_first&quot;</code>,
              set <code>axis=1</code> in <a href="#batchNormalization">tf.batchNormalization()</a>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">momentum</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Momentum of the moving average. Defaults to 0.99.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Small float added to the variance to avoid dividing by zero. Defaults to
              1e-3.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">center</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If <code>true</code>, add offset of <code>beta</code> to normalized tensor.
              If <code>false</code>, <code>beta</code> is ignored.
              Defaults to <code>true</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">scale</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If <code>true</code>, multiply by <code>gamma</code>.
              If <code>false</code>, <code>gamma</code> is not used.
              When the next layer is linear (also e.g. <code>nn.relu</code>),
              this can be disabled since the scaling will be done by the next layer.
              Defaults to <code>true</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">betaInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the beta weight.
              Defaults to 'zeros'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">gammaInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the gamma weight.
              Defaults to <a href="#ones">tf.ones()</a>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">movingMeanInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the moving mean.
              Defaults to <a href="#zeros">tf.zeros()</a></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">movingVarianceInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the moving variance.
              Defaults to 'Ones'.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">betaConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint for the beta weight.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">gammaConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint for gamma weight.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">betaRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer for the beta weight.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">gammaRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer for the gamma weight.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Pooling
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.averagePooling1d" href="#layers.averagePooling1d">
tf.layers.averagePooling1d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L496-L505" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Average pooling operation for spatial data.</p>
<p>Input shape: <code>[batchSize, inLength, channels]</code></p>
<p>Output shape: <code>[batchSize, pooledLength, channels]</code></p>
<p><code>tf.avgPool1d</code> is an alias.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">poolSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Size of the window to pool over, should be an integer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">strides</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Period at which to sample the pooled values.</p>
              <p>If <code>null</code>, defaults to <code>poolSize</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">padding</span>
                <span class="param-type">('valid'|'same'|'causal')</span>
                <span class="param-docs">How to fill in data that's not an integer multiple of poolSize.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.averagePooling2d" href="#layers.averagePooling2d">
tf.layers.averagePooling2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L515-L524" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Average pooling operation for spatial data.</p>
<p>Input shape:</p>
<ul>
<li>If <code>dataFormat === CHANNEL_LAST</code>:
4D tensor with shape:
<code>[batchSize, rows, cols, channels]</code></li>
<li>If <code>dataFormat === CHANNEL_FIRST</code>:
4D tensor with shape:
<code>[batchSize, channels, rows, cols]</code></li>
</ul>
<p>Output shape</p>
<ul>
<li>If <code>dataFormat === CHANNEL_LAST</code>:
4D tensor with shape:
<code>[batchSize, pooleRows, pooledCols, channels]</code></li>
<li>If <code>dataFormat === CHANNEL_FIRST</code>:
4D tensor with shape:
<code>[batchSize, channels, pooleRows, pooledCols]</code></li>
</ul>
<p><code>tf.avgPool2d</code> is an alias.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">poolSize</span>
                <span class="param-type">(number|[number, number])</span>
                <span class="param-docs">Factors by which to downscale in each dimension [vertical, horizontal].
              Expects an integer or an array of 2 integers.</p>
              <p>For example, <code>[2, 2]</code> will halve the input in both spatial dimension.
              If only one integer is specified, the same window length
              will be used for both dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">strides</span>
                <span class="param-type">(number|[number, number])</span>
                <span class="param-docs">The size of the stride in each dimension of the pooling window. Expects
              an integer or an array of 2 integers. Integer, tuple of 2 integers, or
              None.</p>
              <p>If <code>null</code>, defaults to <code>poolSize</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">padding</span>
                <span class="param-type">('valid'|'same'|'causal')</span>
                <span class="param-docs">The padding type to use for the pooling layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">The data format to use for the pooling layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.globalAveragePooling1d" href="#layers.globalAveragePooling1d">
tf.layers.globalAveragePooling1d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L534-L543" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Global average pooling operation for temporal data.</p>
<p>Input Shape: 3D tensor with shape: <code>[batchSize, steps, features]</code>.</p>
<p>Output Shape:2D tensor with shape: <code>[batchSize, features]</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.globalAveragePooling2d" href="#layers.globalAveragePooling2d">
tf.layers.globalAveragePooling2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L545-L554" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Global average pooling operation for spatial data.</p>
<p>Input shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>CHANNEL_LAST</code>:
4D tensor with shape: <code>[batchSize, rows, cols, channels]</code>.</li>
<li>If <code>dataFormat</code> is <code>CHANNEL_FIRST</code>:
4D tensor with shape: <code>[batchSize, channels, rows, cols]</code>.</li>
</ul>
<p>Output shape:
2D tensor with shape: <code>[batchSize, channels]</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">One of <code>CHANNEL_LAST</code> (default) or <code>CHANNEL_FIRST</code>.</p>
              <p>The ordering of the dimensions in the inputs. <code>CHANNEL_LAST</code> corresponds
              to inputs with shape <code>[batch, height, width, channels[</code> while
              <code>CHANNEL_FIRST</code> corresponds to inputs with shape
              <code>[batch, channels, height, width]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.globalMaxPooling1d" href="#layers.globalMaxPooling1d">
tf.layers.globalMaxPooling1d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L556-L565" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Global max pooling operation for temporal data.</p>
<p>Input Shape: 3D tensor with shape: <code>[batchSize, steps, features]</code>.</p>
<p>Output Shape:2D tensor with shape: <code>[batchSize, features]</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">If defined, will be used to create an input layer to insert before this
              layer. If both <code>inputShape</code> and <code>batchInputShape</code> are defined,
              <code>batchInputShape</code> will be used. This argument is only applicable to input
              layers (the first layer of a model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">If <code>inputShape</code> is specified and <code>batchInputShape</code> is <em>not</em> specifiedd,
              <code>batchSize</code> is used to construct the <code>batchInputShape</code>: <code>[batchSize, ...inputShape]</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">The data-type for this layer. Defaults to 'float32'.
              This argument is only applicable to input layers (the first layer of a
              model).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name for this layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">trainable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether this layer is trainable. Defaults to true.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">updatable</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the weights of this layer are updatable by <code>fit</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>[])</span>
                <span class="param-docs">Initial weight values of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputDType</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Legacy support. Do not use for new code.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.globalMaxPooling2d" href="#layers.globalMaxPooling2d">
tf.layers.globalMaxPooling2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L567-L576" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Global max pooling operation for spatial data.</p>
<p>Input shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>CHANNEL_LAST</code>:
4D tensor with shape: <code>[batchSize, rows, cols, channels]</code>.</li>
<li>If <code>dataFormat</code> is <code>CHANNEL_FIRST</code>:
4D tensor with shape: <code>[batchSize, channels, rows, cols]</code>.</li>
</ul>
<p>Output shape:
2D tensor with shape: <code>[batchSize, channels]</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">One of <code>CHANNEL_LAST</code> (default) or <code>CHANNEL_FIRST</code>.</p>
              <p>The ordering of the dimensions in the inputs. <code>CHANNEL_LAST</code> corresponds
              to inputs with shape <code>[batch, height, width, channels[</code> while
              <code>CHANNEL_FIRST</code> corresponds to inputs with shape
              <code>[batch, channels, height, width]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.maxPooling1d" href="#layers.maxPooling1d">
tf.layers.maxPooling1d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L578-L587" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Max pooling operation for temporal data.</p>
<p>Input shape:  <code>[batchSize, inLength, channels]</code></p>
<p>Output shape: <code>[batchSize, pooledLength, channels]</code></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">poolSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Size of the window to pool over, should be an integer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">strides</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Period at which to sample the pooled values.</p>
              <p>If <code>null</code>, defaults to <code>poolSize</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">padding</span>
                <span class="param-type">('valid'|'same'|'causal')</span>
                <span class="param-docs">How to fill in data that's not an integer multiple of poolSize.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.maxPooling2d" href="#layers.maxPooling2d">
tf.layers.maxPooling2d</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L589-L598" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Max pooling operation for spatial data.</p>
<p>Input shape</p>
<ul>
<li>If <code>dataFormat === CHANNEL_LAST</code>:
4D tensor with shape:
<code>[batchSize, rows, cols, channels]</code></li>
<li>If <code>dataFormat === CHANNEL_FIRST</code>:
4D tensor with shape:
<code>[batchSize, channels, rows, cols]</code></li>
</ul>
<p>Output shape</p>
<ul>
<li>If <code>dataFormat=CHANNEL_LAST</code>:
4D tensor with shape:
<code>[batchSize, pooleRows, pooledCols, channels]</code></li>
<li>If <code>dataFormat=CHANNEL_FIRST</code>:
4D tensor with shape:
<code>[batchSize, channels, pooleRows, pooledCols]</code></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">poolSize</span>
                <span class="param-type">(number|[number, number])</span>
                <span class="param-docs">Factors by which to downscale in each dimension [vertical, horizontal].
              Expects an integer or an array of 2 integers.</p>
              <p>For example, <code>[2, 2]</code> will halve the input in both spatial dimension.
              If only one integer is specified, the same window length
              will be used for both dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">strides</span>
                <span class="param-type">(number|[number, number])</span>
                <span class="param-docs">The size of the stride in each dimension of the pooling window. Expects
              an integer or an array of 2 integers. Integer, tuple of 2 integers, or
              None.</p>
              <p>If <code>null</code>, defaults to <code>poolSize</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">padding</span>
                <span class="param-type">('valid'|'same'|'causal')</span>
                <span class="param-docs">The padding type to use for the pooling layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">The data format to use for the pooling layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Recurrent
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.gru" href="#layers.gru">
tf.layers.gru</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L602-L611" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Gated Recurrent Unit - Cho et al. 2014.</p>
<p>This is an <code>RNN</code> layer consisting of one <code>GRUCell</code>. However, unlike
the underlying <code>GRUCell</code>, the <code>apply</code> method of <code>SimpleRNN</code> operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> rnn = tf.layers.gru({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = rnn.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the `GRUCell`'s number of units.</span></code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentActivation</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Activation function to use for the recurrent step.</p>
              <p>Defaults to hard sigmoid (<code>hardSigomid</code>).</p>
              <p>If <code>null</code>, no activation is applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">implementation</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Implementation mode, either 1 or 2.</p>
              <p>Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.</p>
              <p>Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.gruCell" href="#layers.gruCell">
tf.layers.gruCell</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L613-L622" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Cell class for <code>GRU</code>.</p>
<p><code>GRUCell</code> is distinct from the <code>RNN</code> subclass <code>GRU</code> in that its
<code>apply</code> method takes the input data of only a single time step and returns
the cell's output at the time step, while <code>GRU</code> takes the input data
over a number of time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cell = tf.layers.gruCell({<span class="hljs-attr">units</span>: <span class="hljs-number">2</span>});
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>]});
<span class="hljs-keyword">const</span> output = cell.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10]: This is the cell's output at a single time step. The 1st</span>
<span class="hljs-comment">// dimension is the unknown batch size.</span>
</code></pre>

<p>Instance(s) of <code>GRUCell</code> can be used to construct <code>RNN</code> layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., <code>StackedRNNCell</code> internally) and use it to create an
RNN. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cells = [
   tf.layers.gruCell({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}),
   tf.layers.gruCell({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>}),
];
<span class="hljs-keyword">const</span> rnn = tf.layers.rnn({<span class="hljs-attr">cell</span>: cells, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps and a length-20 vector at each step.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = rnn.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the last `gruCell`'s number of units.</span>
</code></pre>

<p>To create an <code>RNN</code> consisting of only <em>one</em> <code>GRUCell</code>, use the
<code>tf.layers.gru</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentActivation</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Activation function to use for the recurrent step.</p>
              <p>Defaults to hard sigmoid (<code>hardSigomid</code>).</p>
              <p>If <code>null</code>, no activation is applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">implementation</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Implementation mode, either 1 or 2.</p>
              <p>Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.</p>
              <p>Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:RNNCell">tf.RNNCell</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.lstm" href="#layers.lstm">
tf.layers.lstm</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L624-L633" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Long-Short Term Memory layer - Hochreiter 1997.</p>
<p>This is an <code>RNN</code> layer consisting of one <code>LSTMCell</code>. However, unlike
the underlying <code>LSTMCell</code>, the <code>apply</code> method of <code>LSTM</code> operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> lstm = tf.layers.lstm({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = lstm.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the `LSTMCell`'s number of units.</span></code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentActivation</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Activation function to use for the recurrent step.</p>
              <p>Defaults to hard sigmoid (<code>hardSigomid</code>).</p>
              <p>If <code>null</code>, no activation is applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">unitForgetBias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If <code>true</code>, add 1 to the bias of the forget gate at initialization.
              Setting it to <code>true</code> will also force <code>biasInitializer = 'zeros'</code>.
              This is recommended in
              <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et
              al.</a>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">implementation</span>
                <span class="param-type">(1|2)</span>
                <span class="param-docs">Implementation mode, either 1 or 2.
              Mode 1 will structure its operations as a larger number of
              smaller dot products and additions, whereas mode 2 will
              batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.lstmCell" href="#layers.lstmCell">
tf.layers.lstmCell</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L635-L644" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Cell class for <code>LSTM</code>.</p>
<p><code>LSTMCell</code> is distinct from the <code>RNN</code> subclass <code>LSTM</code> in that its
<code>apply</code> method takes the input data of only a single time step and returns
the cell's output at the time step, while <code>LSTM</code> takes the input data
over a number of time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cell = tf.layers.lstmCell({<span class="hljs-attr">units</span>: <span class="hljs-number">2</span>});
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>]});
<span class="hljs-keyword">const</span> output = cell.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10]: This is the cell's output at a single time step. The 1st</span>
<span class="hljs-comment">// dimension is the unknown batch size.</span>
</code></pre>

<p>Instance(s) of <code>LSTMCell</code> can be used to construct <code>RNN</code> layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., <code>StackedRNNCell</code> internally) and use it to create an
RNN. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cells = [
   tf.layers.lstmCell({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}),
   tf.layers.lstmCell({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>}),
];
<span class="hljs-keyword">const</span> rnn = tf.layers.rnn({<span class="hljs-attr">cell</span>: cells, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps and a length-20 vector at each step.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = rnn.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the last `lstmCell`'s number of units.</span>
</code></pre>

<p>To create an <code>RNN</code> consisting of only <em>one</em> <code>LSTMCell</code>, use the
<code>tf.layers.lstm</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentActivation</span>
                <span class="param-type">('elu'|'hardSigmoid'|'linear'|'relu'|'relu6'|
              'selu'|'sigmoid'|'softmax'|'softplus'|'softsign'|'tanh'|string)</span>
                <span class="param-docs">Activation function to use for the recurrent step.</p>
              <p>Defaults to hard sigmoid (<code>hardSigomid</code>).</p>
              <p>If <code>null</code>, no activation is applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">unitForgetBias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If <code>true</code>, add 1 to the bias of the forget gate at initialization.
              Setting it to <code>true</code> will also force <code>biasInitializer = 'zeros'</code>.
              This is recommended in
              <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et
              al.</a>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">implementation</span>
                <span class="param-type">(1|2)</span>
                <span class="param-docs">Implementation mode, either 1 or 2.</p>
              <p>Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.</p>
              <p>Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:RNNCell">tf.RNNCell</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.rnn" href="#layers.rnn">
tf.layers.rnn</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L668-L677" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Base class for recurrent layers.</p>
<p>Input shape:
3D tensor with shape <code>[batchSize, timeSteps, inputDim]</code>.</p>
<p>Output shape:</p>
<ul>
<li>if <code>returnState</code>, an Array of tensors (i.e., <a href="#class:Tensor">tf.Tensor</a>s). The first
tensor is the output. The remaining tensors are the states at the
last time step, each with shape <code>[batchSize, units]</code>.</li>
<li>if <code>returnSequences</code>, the output will have shape
<code>[batchSize, timeSteps, units]</code>.</li>
<li>else, the output will have shape <code>[batchSize, units]</code>.</li>
</ul>
<p>Masking:
This layer supports masking for input data with a variable number
of timesteps. To introduce masks to your data,
use an embedding layer with the <code>mask_zero</code> parameter
set to <code>True</code>.</p>
<p>Notes on using statefulness in RNNs:
You can set RNN layers to be 'stateful', which means that the states
computed for the samples in one batch will be reused as initial states
for the samples in the next batch. This assumes a one-to-one mapping
between samples in different successive batches.</p>
<p>To enable statefulness:
- specify <code>stateful: true</code> in the layer constructor.
- specify a fixed batch size for your model, by passing
if sequential model:
<code>batchInputShape=[...]</code> to the first layer in your model.
else for functional model with 1 or more Input layers:
<code>batchShape=[...]</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a tuple of integers, e.g. <code>(32, 10, 100)</code>.
- specify <code>shuffle=False</code> when calling fit().</p>
<p>To reset the states of your model, call <code>.reset_states()</code> on either
a specific layer, or on your entire model.</p>
<p>Note on specifying the initial state of RNNs
You can specify the initial state of RNN layers symbolically by
calling them with the option <code>initialState</code>. The value of
<code>initialState</code> should be a tensor or list of tensors representing
the initial state of the RNN layer.</p>
<p>You can specify the initial state of RNN layers numerically by
calling <code>resetStates</code> with the keyword argument <code>states</code>. The value of
<code>states</code> should be a numpy array or list of numpy arrays representing
the initial state of the RNN layer.</p>
<p>Note on passing external constants to RNNs
You can pass &quot;external&quot; constants to the cell using the <code>constants</code>
keyword argument of <code>RNN.call</code> method. This requires that the <code>cell.call</code>
method accepts the same keyword argument <code>constants</code>. Such constants
can be used to conditon the cell transformation on additional static inputs
(not changing over time), a.k.a an attention mechanism.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">cell</span>
                <span class="param-type">(<a href="#class:RNNCell">tf.RNNCell</a>|<a href="#class:RNNCell">tf.RNNCell</a>[])</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.simpleRNN" href="#layers.simpleRNN">
tf.layers.simpleRNN</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L646-L655" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Fully-connected RNN where the output is to be fed back to input.</p>
<p>This is an <code>RNN</code> layer consisting of one <code>SimpleRNNCell</code>. However, unlike
the underlying <code>SimpleRNNCell</code>, the <code>apply</code> method of <code>SimpleRNN</code> operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> rnn = tf.layers.simpleRNN({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = rnn.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the `SimpleRNNCell`'s number of units.</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">units</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Positive integer, dimensionality of the output space.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activation</span>
                <span class="param-type">('elu'|'hardSigmoid'|'linear'|'relu'|'relu6'|
              'selu'|'sigmoid'|'softmax'|'softplus'|'softsign'|'tanh'|string)</span>
                <span class="param-docs">Activation function to use.</p>
              <p>Defaults to  hyperbolic tangent (<a href="#tanh">tf.tanh()</a>)</p>
              <p>If you pass <code>null</code>, no activation will be applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">useBias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the layer uses a bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the <code>kernel</code> weights matrix, used for the linear
              transformation of the inputs.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the <code>recurrentKernel</code> weights matrix, used for
              linear transformation of the recurrent state.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the kernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the recurrentKernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the kernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the recurrentKernel weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dropout</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number between 0 and 1. Fraction of the units to drop for the linear
              transformation of the inputs.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentDropout</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Number between 0 and 1. Fraction of the units to drop for the linear
              transformation of the recurrent state.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.simpleRNNCell" href="#layers.simpleRNNCell">
tf.layers.simpleRNNCell</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L657-L666" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Cell class for <code>SimpleRNN</code>.</p>
<p><code>SimpleRNNCell</code> is distinct from the <code>RNN</code> subclass <code>SimpleRNN</code> in that its
<code>apply</code> method takes the input data of only a single time step and returns
the cell's output at the time step, while <code>SimpleRNN</code> takes the input data
over a number of time steps. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cell = tf.layers.simpleRNNCell({<span class="hljs-attr">units</span>: <span class="hljs-number">2</span>});
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>]});
<span class="hljs-keyword">const</span> output = cell.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10]: This is the cell's output at a single time step. The 1st</span>
<span class="hljs-comment">// dimension is the unknown batch size.</span>
</code></pre>

<p>Instance(s) of <code>SimpleRNNCell</code> can be used to construct <code>RNN</code> layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., <code>StackedRNNCell</code> internally) and use it to create an
RNN. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cells = [
   tf.layers.simpleRNNCell({<span class="hljs-attr">units</span>: <span class="hljs-number">4</span>}),
   tf.layers.simpleRNNCell({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>}),
];
<span class="hljs-keyword">const</span> rnn = tf.layers.rnn({<span class="hljs-attr">cell</span>: cells, <span class="hljs-attr">returnSequences</span>: <span class="hljs-literal">true</span>});

<span class="hljs-comment">// Create an input with 10 time steps and a length-20 vector at each step.</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>]});
<span class="hljs-keyword">const</span> output = rnn.apply(input);

<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output.shape));
<span class="hljs-comment">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the</span>
<span class="hljs-comment">// same as the sequence length of [tf.input()](#input), due to `returnSequences`: `true`;</span>
<span class="hljs-comment">// 3rd dimension is the last `SimpleRNNCell`'s number of units.</span>
</code></pre>

<p>To create an <code>RNN</code> consisting of only <em>one</em> <code>SimpleRNNCell</code>, use the
<code>tf.layers.simpleRNN</code>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">units</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">units: Positive integer, dimensionality of the output space.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">activation</span>
                <span class="param-type">('elu'|'hardSigmoid'|'linear'|'relu'|'relu6'|
              'selu'|'sigmoid'|'softmax'|'softplus'|'softsign'|'tanh'|string)</span>
                <span class="param-docs">Activation function to use.
              Default: hyperbolic tangent ('tanh').
              If you pass <code>null</code>,  'linear' activation will be applied.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">useBias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the layer uses a bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the <code>kernel</code> weights matrix, used for the linear
              transformation of the inputs.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the <code>recurrentKernel</code> weights matrix, used for
              linear transformation of the recurrent state.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasInitializer</span>
                <span class="param-type">('constant'|'glorotNormal'|'glorotUniform'|
              'heNormal'|'identity'|'leCunNormal'|'ones'|'orthogonal'|'randomNormal'|
              'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string|<a href="#class:initializers.Initializer">tf.initializers.Initializer</a>)</span>
                <span class="param-docs">Initializer for the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the <code>kernel</code> weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the <code>recurrent_kernel</code> weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasRegularizer</span>
                <span class="param-type">('l1l2'|string|Regularizer)</span>
                <span class="param-docs">Regularizer function applied to the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">kernelConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the <code>kernel</code> weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraint function applied to the <code>recurrentKernel</code> weights matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">biasConstraint</span>
                <span class="param-type">('maxNorm'|'minMaxNorm'|'nonNeg'|'unitNorm'|string|<a href="#class:constraints.Constraint">tf.constraints.Constraint</a>)</span>
                <span class="param-docs">Constraintfunction applied to the bias vector.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dropout</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float number between 0 and 1. Fraction of the units to drop for the linear
              transformation of the inputs.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">recurrentDropout</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Float number between 0 and 1. Fraction of the units to drop for the linear
              transformation of the recurrent state.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:RNNCell">tf.RNNCell</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.stackedRNNCells" href="#layers.stackedRNNCells">
tf.layers.stackedRNNCells</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L679-L688" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Base class for recurrent layers.</p>
<p>Input shape:
3D tensor with shape <code>[batchSize, timeSteps, inputDim]</code>.</p>
<p>Output shape:</p>
<ul>
<li>if <code>returnState</code>, an Array of tensors (i.e., <a href="#class:Tensor">tf.Tensor</a>s). The first
tensor is the output. The remaining tensors are the states at the
last time step, each with shape <code>[batchSize, units]</code>.</li>
<li>if <code>returnSequences</code>, the output will have shape
<code>[batchSize, timeSteps, units]</code>.</li>
<li>else, the output will have shape <code>[batchSize, units]</code>.</li>
</ul>
<p>Masking:
This layer supports masking for input data with a variable number
of timesteps. To introduce masks to your data,
use an embedding layer with the <code>mask_zero</code> parameter
set to <code>True</code>.</p>
<p>Notes on using statefulness in RNNs:
You can set RNN layers to be 'stateful', which means that the states
computed for the samples in one batch will be reused as initial states
for the samples in the next batch. This assumes a one-to-one mapping
between samples in different successive batches.</p>
<p>To enable statefulness:
- specify <code>stateful: true</code> in the layer constructor.
- specify a fixed batch size for your model, by passing
if sequential model:
<code>batchInputShape=[...]</code> to the first layer in your model.
else for functional model with 1 or more Input layers:
<code>batchShape=[...]</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a tuple of integers, e.g. <code>(32, 10, 100)</code>.
- specify <code>shuffle=False</code> when calling fit().</p>
<p>To reset the states of your model, call <code>.reset_states()</code> on either
a specific layer, or on your entire model.</p>
<p>Note on specifying the initial state of RNNs
You can specify the initial state of RNN layers symbolically by
calling them with the option <code>initialState</code>. The value of
<code>initialState</code> should be a tensor or list of tensors representing
the initial state of the RNN layer.</p>
<p>You can specify the initial state of RNN layers numerically by
calling <code>resetStates</code> with the keyword argument <code>states</code>. The value of
<code>states</code> should be a numpy array or list of numpy arrays representing
the initial state of the RNN layer.</p>
<p>Note on passing external constants to RNNs
You can pass &quot;external&quot; constants to the cell using the <code>constants</code>
keyword argument of <code>RNN.call</code> method. This requires that the <code>cell.call</code>
method accepts the same keyword argument <code>constants</code>. Such constants
can be used to conditon the cell transformation on additional static inputs
(not changing over time), a.k.a an attention mechanism.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">cells</span>
                <span class="param-type">(<a href="#class:RNNCell">tf.RNNCell</a>[])</span>
                <span class="param-docs">A <code>Array</code> of <a href="#class:RNNCell">tf.RNNCell</a> instances.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:RNNCell">tf.RNNCell</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Wrapper
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.bidirectional" href="#layers.bidirectional">
tf.layers.bidirectional</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L692-L701" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">layer</span>
                <span class="param-type">(RNN)</span>
                <span class="param-docs">The instance of an <code>RNN</code> layer to be wrapped.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">mergeMode</span>
                <span class="param-type">(BidirectionalMergeMode)</span>
                <span class="param-docs">Mode by which outputs of the forward and backward RNNs are combinied.
              If <code>null</code> or <code>undefined</code>, the output will not be combined, they will be
              returned as an <code>Array</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Wrapper</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.timeDistributed" href="#layers.timeDistributed">
tf.layers.timeDistributed</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L703-L712" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>This wrapper applies a layer to every temporal slice of an input.</p>
<p>The input should be at least 3D,  and the dimension of the index <code>1</code> will be
considered to be the temporal dimension.</p>
<p>Consider a batch of 32 samples, where each sample is a sequence of 10 vectors
of 16 dimensions. The batch input shape of the layer is then <code>[32, 10, 16]</code>, and the <code>inputShape</code>, not including the sample dimension, is
<code>[10, 16]</code>.</p>
<p>You can then use <code>TimeDistributed</code> to apply a <code>Dense</code> layer to each of the 10
timesteps, independently:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.timeDistributed({
   <span class="hljs-attr">layer</span>: tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">8</span>}),
   <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">16</span>],
}));

<span class="hljs-comment">// Now model.outputShape = [null, 10, 8].</span>
<span class="hljs-comment">// The output will then have shape `[32, 10, 8]`.</span>

<span class="hljs-comment">// In subsequent layers, there is no need for `inputShape`:</span>
model.add(tf.layers.timeDistributed({<span class="hljs-attr">layer</span>: tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">32</span>})}));
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(model.outputs[<span class="hljs-number">0</span>].shape));
<span class="hljs-comment">// Now model.outputShape = [null, 10, 32].</span>
</code></pre>

<p>The output will then have shape <code>[32, 10, 32]</code>.</p>
<p><code>TimeDistributed</code> can be used with arbitrary layers, not just <code>Dense</code>, for
instance a <code>Conv2D</code> layer.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> model = tf.sequential();
model.add(tf.layers.timeDistributed({
   <span class="hljs-attr">layer</span>: tf.layers.conv2d({<span class="hljs-attr">filters</span>: <span class="hljs-number">64</span>, <span class="hljs-attr">kernelSize</span>: [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>]}),
   <span class="hljs-attr">inputShape</span>: [<span class="hljs-number">10</span>, <span class="hljs-number">299</span>, <span class="hljs-number">299</span>, <span class="hljs-number">3</span>],
}));
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(model.outputs[<span class="hljs-number">0</span>].shape));
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">layer</span>
                <span class="param-type">(<a href="#class:layers.Layer">tf.layers.Layer</a>)</span>
                <span class="param-docs">The layer to be wrapped.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Classes
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:layers.Layer" href="#class:layers.Layer">tf.layers.Layer</a>
    <span class="signature">
        <span>extends serialization.Serializable</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/topology.ts#L390-L1358" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>A layer is a grouping of operations and weights that can be composed to
create a <a href="#class:Model">tf.Model</a>.</p>
<p>Layers are constructed by using the functions under the
<a href="#Layers-Basic">tf.layers</a> namespace.</p>
</div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.layers.Layer.apply" href="#tf.layers.Layer.apply">
apply</a>
    <span class="signature">(inputs, kwargs?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/engine/topology.ts#L893-L1024" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Builds or executes a `Layer's logic.</p>
<p>When called with <a href="#class:Tensor">tf.Tensor</a>(s), execute the <code>Layer</code>s computation and
return Tensor(s). For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> denseLayer = tf.layers.dense({
   <span class="hljs-attr">units</span>: <span class="hljs-number">1</span>,
   <span class="hljs-attr">kernelInitializer</span>: <span class="hljs-string">'zeros'</span>,
   <span class="hljs-attr">useBias</span>: <span class="hljs-literal">false</span>
});

<span class="hljs-comment">// Invoke the layer's apply() method with a [tf.Tensor](#class:Tensor) (with concrete</span>
<span class="hljs-comment">// numeric values).</span>
<span class="hljs-keyword">const</span> input = tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> output = denseLayer.apply(input);

<span class="hljs-comment">// The output's value is expected to be [[0], [0]], due to the fact that</span>
<span class="hljs-comment">// the dense layer has a kernel initialized to all-zeros and does not have</span>
<span class="hljs-comment">// a bias.</span>
output.print();
</code></pre>

<p>When called with <a href="#class:SymbolicTensor">tf.SymbolicTensor</a>(s), this will prepare the layer for
future execution.  This entails internal book-keeping on shapes of
expected Tensors, wiring layers together, and initializing weights.</p>
<p>Calling <code>apply</code> with <a href="#class:SymbolicTensor">tf.SymbolicTensor</a>s are typically used during the
building of non-<a href="#class:Sequential">tf.Sequential</a> models. For example:</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> flattenLayer = tf.layers.flatten();
<span class="hljs-keyword">const</span> denseLayer = tf.layers.dense({<span class="hljs-attr">units</span>: <span class="hljs-number">1</span>});

<span class="hljs-comment">// Use tf.layers.input() to obtain a SymbolicTensor as input to apply().</span>
<span class="hljs-keyword">const</span> input = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]});
<span class="hljs-keyword">const</span> output1 = flattenLayer.apply(input);

<span class="hljs-comment">// output1.shape is [null, 4]. The first dimension is the undetermined</span>
<span class="hljs-comment">// batch size. The second dimension comes from flattening the [2, 2]</span>
<span class="hljs-comment">// shape.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output1.shape));

<span class="hljs-comment">// The output SymbolicTensor of the flatten layer can be used to call</span>
<span class="hljs-comment">// the apply() of the dense layer:</span>
<span class="hljs-keyword">const</span> output2 = denseLayer.apply(output1);

<span class="hljs-comment">// output2.shape is [null, 1]. The first dimension is the undetermined</span>
<span class="hljs-comment">// batch size. The second dimension matches the number of units of the</span>
<span class="hljs-comment">// dense layer.</span>
<span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">JSON</span>.stringify(output2.shape));

<span class="hljs-comment">// The input and output and be used to construct a model that consists</span>
<span class="hljs-comment">// of the flatten and dense layers.</span>
<span class="hljs-keyword">const</span> model = tf.model({<span class="hljs-attr">inputs</span>: input, <span class="hljs-attr">outputs</span>: output2});
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">inputs</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>[])</span>
                <span class="param-docs">a <a href="#class:Tensor">tf.Tensor</a> or <a href="#class:SymbolicTensor">tf.SymbolicTensor</a> or an Array of them.</span>
            </li>
            <li class="parameter">
                <span class="param-name">kwargs</span>
                <span class="param-type">(Kwargs)</span>
                <span class="param-docs">Additional keyword arguments to be passed to <code>call()</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>|<a href="#class:SymbolicTensor">tf.SymbolicTensor</a>[]</span>
  </div>
</div>

  </div>
</div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:RNNCell" href="#class:RNNCell">tf.RNNCell</a>
    <span class="signature">
        <span>extends Layer</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/layers/recurrent.ts#L777-L784" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>An RNNCell layer.</p>
</div>

  <div class="method-list">
  </div>
</div>
          <div class="subheading">
            <div class="tftitle">
              
                Layers / Inputs
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.inputLayer" href="#layers.inputLayer">
tf.layers.inputLayer</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L182-L191" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>An input layer is an entry point into a <a href="#class:Model">tf.Model</a>.</p>
<p><code>InputLayer</code> is generated automatically for <a href="#class:Sequential">tf.Sequential</a> models by specifying
the <code>inputshape</code> or <code>batchInputShape</code> for the first layer.  It should not be
specified explicitly.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Define a model which simply adds two inputs.</span>
<span class="hljs-keyword">const</span> inputA = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">3</span>]});
<span class="hljs-keyword">const</span> inputB = tf.input({<span class="hljs-attr">shape</span>: [<span class="hljs-number">3</span>]});
<span class="hljs-keyword">const</span> sum = tf.layers.add().apply([inputA, inputB]);
<span class="hljs-keyword">const</span> model = tf.model({<span class="hljs-attr">inputs</span>: [inputA, inputB], <span class="hljs-attr">outputs</span>: sum});
<span class="hljs-keyword">const</span> batchSize = <span class="hljs-number">2</span>;
model.predict([tf.ones([batchSize, <span class="hljs-number">3</span>]), tf.ones([batchSize, <span class="hljs-number">3</span>])]).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">inputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Input shape, not including the batch axis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchSize</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Optional input batch size (integer or null).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">batchInputShape</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">Batch input shape, including the batch axis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dtype</span>
                <span class="param-type">(DataType)</span>
                <span class="param-docs">Datatype of the input.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">sparse</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether the placeholder created is meant to be sparse.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">name</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">Name of the layer.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Layers / Padding
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="layers.zeroPadding2d" href="#layers.zeroPadding2d">
tf.layers.zeroPadding2d</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L484-L493" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Zero-padding layer for 2D input (e.g., image).</p>
<p>This layer can add rows and columns of zeros
at the top, bottom, left and right side of an image tensor.</p>
<p>Input shape:
4D tensor with shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, rows, cols, channels]</code></li>
<li>If <code>data_format</code> is <code>&quot;channels_first&quot;</code>:
<code>[batch, channels, rows, cols]</code>.</li>
</ul>
<p>Output shape:
4D with shape:</p>
<ul>
<li>If <code>dataFormat</code> is <code>&quot;channelsLast&quot;</code>:
<code>[batch, paddedRows, paddedCols, channels]</code></li>
<li>If <code>dataFormat</code> is <code>&quot;channelsFirst&quot;</code>:
<code>[batch, channels, paddedRows, paddedCols]</code>.</li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">padding</span>
                <span class="param-type">(number|[number, number]|[[number, number], [number, number]])</span>
                <span class="param-docs">Integer, or <code>Array</code> of 2 integers, or <code>Array</code> of 2 <code>Array</code>s, each of
              which is an <code>Array</code> of 2 integers.</p>
              <ul>
              <li>If integer, the same symmetric padding is applied to width and height.</li>
              <li>If Array<code>of 2 integers, interpreted as two different symmetric values for height and width:</code>[symmetricHeightPad, symmetricWidthPad]`.</li>
              <li>If <code>Array</code> of 2 <code>Array</code>s, interpreted as:
              <code>[[topPad, bottomPad], [leftPad, rightPad]]</code>.</li>
              </ul>
              </span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('channelsFirst'|'channelsLast')</span>
                <span class="param-docs">One of <code>'channelsLast'</code> (default) and <code>'channelsFirst'</code>.</p>
              <p>The ordering of the dimensions in the inputs.
              <code>channelsLast</code> corresponds to inputs with shape
              <code>[batch, height, width, channels]</code> while <code>channelsFirst</code>
              corresponds to inputs with shape
              <code>[batch, channels, height, width]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:layers.Layer">tf.layers.Layer</a></span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Operations
            </div>
          <div class="description">
             
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Operations / Arithmetic
              
                </div>
            <div class="description">
              <p>To perform mathematical computation on Tensors, we use
          operations. Tensors are immutable, so all operations always return
          new Tensors and never modify input Tensors.</p>
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="add" href="#add">
tf.add</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L54-L85" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Adds two <a href="#class:Tensor">tf.Tensor</a>s element-wise, A + B. Supports broadcasting.</p>
<p>We also expose <code>addStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>]);

a.add(b).print();  <span class="hljs-comment">// or tf.add(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast add a with b.</span>
<span class="hljs-keyword">const</span> a = tf.scalar(<span class="hljs-number">5</span>);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>]);

a.add(b).print();  <span class="hljs-comment">// or tf.add(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first <a href="#class:Tensor">tf.Tensor</a> to add.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second <a href="#class:Tensor">tf.Tensor</a> to add. Must have the same type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sub" href="#sub">
tf.sub</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L125-L156" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Subtracts two <a href="#class:Tensor">tf.Tensor</a>s element-wise, A - B. Supports broadcasting.</p>
<p>We also expose <code>subStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

a.sub(b).print();  <span class="hljs-comment">// or tf.sub(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast subtract a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.sub(b).print();  <span class="hljs-comment">// or tf.sub(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first <a href="#class:Tensor">tf.Tensor</a> to subtract from.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second <a href="#class:Tensor">tf.Tensor</a> to be subtracted. Must have the same dtype as
              <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="mul" href="#mul">
tf.mul</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L274-L305" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Multiplies two <a href="#class:Tensor">tf.Tensor</a>s element-wise, A * B. Supports broadcasting.</p>
<p>We also expose <code>mulStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]);

a.mul(b).print();  <span class="hljs-comment">// or tf.mul(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast mul a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.mul(b).print();  <span class="hljs-comment">// or tf.mul(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor to multiply.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor to multiply. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="div" href="#div">
tf.div</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L347-L384" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Divides two <a href="#class:Tensor">tf.Tensor</a>s element-wise, A / B. Supports broadcasting.</p>
<p>We also expose <code>divStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

a.div(b).print();  <span class="hljs-comment">// or tf.div(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast div a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">2</span>);

a.div(b).print();  <span class="hljs-comment">// or tf.div(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor as the numerator.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor as the denominator. Must have the same dtype as
              <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="floorDiv" href="#floorDiv">
tf.floorDiv</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L410-L442" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Divides two <a href="#class:Tensor">tf.Tensor</a>s element-wise, A / B. Supports broadcasting.
The result is rounded with floor function.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

a.floorDiv(b).print();  <span class="hljs-comment">// or tf.div(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast div a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">2</span>);

a.floorDiv(b).print();  <span class="hljs-comment">// or tf.floorDiv(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor as the numerator.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor as the denominator. Must have the same dtype as
              <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="maximum" href="#maximum">
tf.maximum</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L614-L636" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the max of a and b (<code>a &gt; b ? a : b</code>) element-wise.
Supports broadcasting.</p>
<p>We also expose <code>maximumStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>]);

a.maximum(b).print();  <span class="hljs-comment">// or tf.maximum(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast maximum a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.maximum(b).print();  <span class="hljs-comment">// or tf.maximum(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor. Must have the same type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="minimum" href="#minimum">
tf.minimum</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L552-L574" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the min of a and b (<code>a &lt; b ? a : b</code>) element-wise.
Supports broadcasting.</p>
<p>We also expose <code>minimumStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>]);

a.minimum(b).print();  <span class="hljs-comment">// or tf.minimum(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast minimum a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.minimum(b).print();  <span class="hljs-comment">// or tf.minimum(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor. Must have the same type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="mod" href="#mod">
tf.mod</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L483-L512" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the mod of a and b element-wise.
<code>floor(x / y) * y + mod(x, y) = x</code>
Supports broadcasting.</p>
<p>We also expose <code>modStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>]);

a.mod(b).print();  <span class="hljs-comment">// or tf.mod(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast a mod b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.mod(b).print();  <span class="hljs-comment">// or tf.mod(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor. Must have the same type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="pow" href="#pow">
tf.pow</a>
    <span class="signature">(base, exp)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L199-L234" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the power of one <a href="#class:Tensor">tf.Tensor</a> to another. Supports broadcasting.</p>
<p>Given a <a href="#class:Tensor">tf.Tensor</a> x and a <a href="#class:Tensor">tf.Tensor</a> y, this operation computes x^y for
corresponding elements in x and y. The result's dtype will be the upcasted
type of the <code>base</code> and <a href="#exp">tf.exp()</a> dtypes.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>]])
<span class="hljs-keyword">const</span> b = tf.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>]]).toInt();

a.pow(b).print();  <span class="hljs-comment">// or tf.pow(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])
<span class="hljs-keyword">const</span> b = tf.tensor(<span class="hljs-number">2</span>).toInt();

a.pow(b).print();  <span class="hljs-comment">// or tf.pow(a, b)</span>
</code></pre>

<p>We also expose <code>powStrict</code> which has the same signature as this op and
asserts that <code>base</code> and <a href="#exp">tf.exp()</a> are the same shape (does not broadcast).</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">base</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The base <a href="#class:Tensor">tf.Tensor</a> to pow element-wise.</span>
            </li>
            <li class="parameter">
                <span class="param-name">exp</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The exponent <a href="#class:Tensor">tf.Tensor</a> to pow element-wise.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="squaredDifference" href="#squaredDifference">
tf.squaredDifference</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L677-L695" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns (a - b) * (a - b) element-wise.
Supports broadcasting.</p>
<p>We also expose <code>squaredDifferenceStrict</code> which has the same signature as
this op and asserts that <code>a</code> and <code>b</code> are the same shape (does not
broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>]);

a.squaredDifference(b).print();  <span class="hljs-comment">// or tf.squaredDifference(a, b)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Broadcast squared difference  a with b.</span>
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]);
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-number">5</span>);

a.squaredDifference(b).print();  <span class="hljs-comment">// or tf.squaredDifference(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor. Must have the same type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Basic math
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="abs" href="#abs">
tf.abs</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L329-L338" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes absolute value element-wise: <code>abs(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);

x.abs().print();  <span class="hljs-comment">// or tf.abs(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input <a href="#class:Tensor">tf.Tensor</a>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="acos" href="#acos">
tf.acos</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L539-L553" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes acos of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>acos(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.acos().print();  <span class="hljs-comment">// or tf.acos(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="acosh" href="#acosh">
tf.acosh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L679-L691" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the inverse hyperbolic cos of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>acosh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">10</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5.7</span>]);

x.acosh().print();  <span class="hljs-comment">// or tf.acosh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="asin" href="#asin">
tf.asin</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L515-L527" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes asin of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>asin(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.asin().print();  <span class="hljs-comment">// or tf.asin(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="asinh" href="#asinh">
tf.asinh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L654-L666" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes inverse hyperbolic sin of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>asinh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.asinh().print();  <span class="hljs-comment">// or tf.asinh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="atan" href="#atan">
tf.atan</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L565-L576" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes atan of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>atan(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.atan().print();  <span class="hljs-comment">// or tf.atan(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="atan2" href="#atan2">
tf.atan2</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/binary_ops.ts#L728-L762" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="atanh" href="#atanh">
tf.atanh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L704-L715" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes inverse hyperbolic tan of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>atanh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">.1</span>, <span class="hljs-number">-.1</span>, <span class="hljs-number">.7</span>]);

x.atanh().print();  <span class="hljs-comment">// or tf.atanh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="ceil" href="#ceil">
tf.ceil</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L60-L70" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes ceiling of input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>ceil(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">.6</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">-3.3</span>]);

x.ceil().print();  <span class="hljs-comment">// or tf.ceil(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input Tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="clipByValue" href="#clipByValue">
tf.clipByValue</a>
    <span class="signature">(x, clipValueMin, clipValueMax)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L352-L373" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Clips values element-wise. <code>max(min(x, clipValueMax), clipValueMin)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);

x.clipByValue(<span class="hljs-number">-2</span>, <span class="hljs-number">3</span>).print();  <span class="hljs-comment">// or tf.clipByValue(x, -2, 3)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">clipValueMin</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Lower-bound of range to be clipped to.</span>
            </li>
            <li class="parameter">
                <span class="param-name">clipValueMax</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Upper-bound of range to be clipped to.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="cos" href="#cos">
tf.cos</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L473-L482" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes cos of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>cos(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-built_in">Math</span>.PI / <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.PI * <span class="hljs-number">3</span> / <span class="hljs-number">4</span>]);

x.cos().print();  <span class="hljs-comment">// or tf.cos(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="cosh" href="#cosh">
tf.cosh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L609-L618" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes hyperbolic cos of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>cosh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.cosh().print();  <span class="hljs-comment">// or tf.cosh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="elu" href="#elu">
tf.elu</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/relu_ops.ts#L66-L80" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes exponential linear element-wise, <code>x &gt; 0 ? e ^ x - 1 : 0</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">2</span>]);

x.elu().print();  <span class="hljs-comment">// or tf.elu(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="erf" href="#erf">
tf.erf</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L728-L747" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes gause error function of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>erf(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">.1</span>, <span class="hljs-number">-.1</span>, <span class="hljs-number">.7</span>]);

x.erf().print(); <span class="hljs-comment">// or tf.erf(x);</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="exp" href="#exp">
tf.exp</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L150-L161" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes exponential of the input <a href="#class:Tensor">tf.Tensor</a> element-wise. <code>e ^ x</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>]);

x.exp().print();  <span class="hljs-comment">// or tf.exp(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="expm1" href="#expm1">
tf.expm1</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L174-L183" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes exponential of the input <a href="#class:Tensor">tf.Tensor</a> minus one element-wise.
<code>e ^ x - 1</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>]);

x.expm1().print();  <span class="hljs-comment">// or tf.expm1(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="floor" href="#floor">
tf.floor</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L82-L93" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes floor of input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>floor(x)</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">.6</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">-3.3</span>]);

x.floor().print();  <span class="hljs-comment">// or tf.floor(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="leakyRelu" href="#leakyRelu">
tf.leakyRelu</a>
    <span class="signature">(x, alpha?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/relu_ops.ts#L133-L139" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes leaky rectified linear element-wise.</p>
<p>See
<a href="http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf">http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf</a></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);

x.leakyRelu(<span class="hljs-number">0.1</span>).print();  <span class="hljs-comment">// or tf.leakyRelu(x, 0.1)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">alpha</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The scaling factor for negative values, defaults to 0.2.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="log" href="#log">
tf.log</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L195-L204" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes natural logarithm of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>ln(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.E]);

x.log().print();  <span class="hljs-comment">// or tf.log(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="log1p" href="#log1p">
tf.log1p</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L217-L226" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes natural logarithm of the input <a href="#class:Tensor">tf.Tensor</a> plus one
element-wise: <code>ln(1 + x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.E - <span class="hljs-number">1</span>]);

x.log1p().print();  <span class="hljs-comment">// or tf.log1p(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logSigmoid" href="#logSigmoid">
tf.logSigmoid</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L409-L419" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes log sigmoid of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>logSigmoid(x)</code>. For numerical stability, we use <code>-tf.softplus(-x)</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.logSigmoid().print();  <span class="hljs-comment">// or tf.logSigmoid(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="neg" href="#neg">
tf.neg</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L39-L48" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes <code>-1 * x</code> element-wise.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

x.neg().print();  <span class="hljs-comment">// or tf.neg(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="prelu" href="#prelu">
tf.prelu</a>
    <span class="signature">(x, alpha)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/relu_ops.ts#L155-L164" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes leaky rectified linear element-wise with parametric alphas.</p>
<p><code>x &lt; 0 ? alpha * x : f(x) = x</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> alpha = tf.scalar(<span class="hljs-number">0.1</span>);

x.prelu(alpha).print();  <span class="hljs-comment">// or tf.prelu(x, alpha)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">alpha</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Scaling factor for negative values.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="reciprocal" href="#reciprocal">
tf.reciprocal</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L308-L317" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes reciprocal of x element-wise: <code>1 / x</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);

x.reciprocal().print();  <span class="hljs-comment">// or tf.reciprocal(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="relu" href="#relu">
tf.relu</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/relu_ops.ts#L41-L54" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes rectified linear element-wise: <code>max(x, 0)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);

x.relu().print();  <span class="hljs-comment">// or tf.relu(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor. If the dtype is <code>bool</code>, the output dtype will be
              `int32'.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="round" href="#round">
tf.round</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L127-L138" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes round of input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>round(x)</code>.
It implements banker's rounding.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">.6</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">-3.3</span>]);

x.round().print();  <span class="hljs-comment">// or tf.round(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="rsqrt" href="#rsqrt">
tf.rsqrt</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L262-L275" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes reciprocal of square root of the input <a href="#class:Tensor">tf.Tensor</a> element-wise:
<code>y = 1 / sqrt(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">-1</span>]);

x.rsqrt().print();  <span class="hljs-comment">// or tf.rsqrt(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="selu" href="#selu">
tf.selu</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/relu_ops.ts#L94-L116" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes scaled exponential linear element-wise.</p>
<p><code>x &lt; 0 ? scale * alpha * (exp(x) - 1) : x</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">4</span>]);

x.selu().print();  <span class="hljs-comment">// or tf.selu(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sigmoid" href="#sigmoid">
tf.sigmoid</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L385-L396" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes sigmoid element-wise, <code>1 / (1 + exp(-x))</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-3</span>]);

x.sigmoid().print();  <span class="hljs-comment">// or tf.sigmoid(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sign" href="#sign">
tf.sign</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L105-L114" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns an element-wise indication of the sign of a number.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">.6</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">-3.3</span>, <span class="hljs-literal">NaN</span>, <span class="hljs-number">0</span>]);

x.sign().print();  <span class="hljs-comment">// or tf.sign(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input Tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sin" href="#sin">
tf.sin</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L452-L461" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes sin of the input Tensor element-wise: <code>sin(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-built_in">Math</span>.PI / <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.PI * <span class="hljs-number">3</span> / <span class="hljs-number">4</span>]);

x.sin().print();  <span class="hljs-comment">// or tf.sin(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sinh" href="#sinh">
tf.sinh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L588-L597" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes hyperbolic sin of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>sinh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.sinh().print();  <span class="hljs-comment">// or tf.sinh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="softplus" href="#softplus">
tf.softplus</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L431-L440" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes softplus of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>log(exp(x) + 1)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">.7</span>]);

x.softplus().print();  <span class="hljs-comment">// or tf.softplus(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sqrt" href="#sqrt">
tf.sqrt</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L238-L249" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes square root of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>y = sqrt(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">-1</span>]);

x.sqrt().print();  <span class="hljs-comment">// or tf.sqrt(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="square" href="#square">
tf.square</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L287-L296" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes square of <code>x</code> element-wise: <code>x ^ 2</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.sqrt(<span class="hljs-number">2</span>), <span class="hljs-number">-1</span>]);

x.square().print();  <span class="hljs-comment">// or tf.square(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input Tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="step" href="#step">
tf.step</a>
    <span class="signature">(x, alpha?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L760-L771" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes step of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>x &gt; 0 ? 1 : alpha * x</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-3</span>]);

x.step(<span class="hljs-number">.5</span>).print();  <span class="hljs-comment">// or tf.step(x, .5)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">alpha</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The gradient when input is negative.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tan" href="#tan">
tf.tan</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L494-L503" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes tan of the input <a href="#class:Tensor">tf.Tensor</a> element-wise, <code>tan(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-built_in">Math</span>.PI / <span class="hljs-number">2</span>, <span class="hljs-built_in">Math</span>.PI * <span class="hljs-number">3</span> / <span class="hljs-number">4</span>]);

x.tan().print();  <span class="hljs-comment">// or tf.tan(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tanh" href="#tanh">
tf.tanh</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/unary_ops.ts#L630-L641" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes hyperbolic tangent of the input <a href="#class:Tensor">tf.Tensor</a> element-wise: <code>tanh(x)</code></p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">70</span>]);

x.tanh().print();  <span class="hljs-comment">// or tf.tanh(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Matrices
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="dot" href="#dot">
tf.dot</a>
    <span class="signature">(t1, t2)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/matmul.ts#L201-L231" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the dot product of two matrices and/or vectors, t1 and t2.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor2d([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]);
<span class="hljs-keyword">const</span> c = tf.tensor2d([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]]);

a.dot(b).print();  <span class="hljs-comment">// or tf.dot(a, b)</span>
b.dot(a).print();
b.dot(c).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">t1</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first tensor in the dot operation.</span>
            </li>
            <li class="parameter">
                <span class="param-name">t2</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second tensor in the dot operation.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="matMul" href="#matMul">
tf.matMul</a>
    <span class="signature">(a, b, transposeA?, transposeB?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/matmul.ts#L41-L90" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the dot product of two matrices, A * B. These must be matrices.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.matMul(b).print();  <span class="hljs-comment">// or tf.matMul(a, b)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">First matrix in dot product operation.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Second matrix in dot product operation.</span>
            </li>
            <li class="parameter">
                <span class="param-name">transposeA</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, <code>a</code> is transposed before multiplication.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">transposeB</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, <code>b</code> is transposed before multiplication.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="norm" href="#norm">
tf.norm</a>
    <span class="signature">(x, ord?, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/norm.ts#L63-L77" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the norm of scalar, vectors, and matrices.
This function can compute several different vector norms (the 1-norm, the
Euclidean or 2-norm, the inf-norm, and in general the p-norm for p &gt; 0)
and matrix norms (Frobenius, 1-norm, and inf-norm).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);

x.norm().print();  <span class="hljs-comment">// or tf.norm(x)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input array.</span>
            </li>
            <li class="parameter">
                <span class="param-name">ord</span>
                <span class="param-type">(number|'euclidean'|'fro')</span>
                <span class="param-docs">Optional. Order of the norm. Supported norm types are
              following:</p>
              <table>
              <thead>
              <tr>
              <th>ord</th>
              <th>norm for matrices</th>
              <th>norm for vectors</th>
              </tr>
              </thead>
              <tbody>
              <tr>
              <td>'euclidean'</td>
              <td>Frobenius norm</td>
              <td>2-norm</td>
              </tr>
              <tr>
              <td>'fro'</td>
              <td>Frobenius norm</td>
              <td></td>
              </tr>
              <tr>
              <td>Infinity</td>
              <td>max(sum(abs(x), axis=1))</td>
              <td>max(abs(x))</td>
              </tr>
              <tr>
              <td>-Infinity</td>
              <td>min(sum(abs(x), axis=1))</td>
              <td>min(abs(x))</td>
              </tr>
              <tr>
              <td>1</td>
              <td>max(sum(abs(x), axis=0))</td>
              <td>sum(abs(x))</td>
              </tr>
              <tr>
              <td>2</td>
              <td></td>
              <td>sum(abs(x)^2)^1/2*</td>
              </tr>
              </tbody>
              </table>
              </span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">Optional. If axis is null (the default), the input is
              considered a vector and a single vector norm is computed over the entire
              set of values in the Tensor, i.e. norm(x, ord) is equivalent
              to norm(x.reshape([-1]), ord). If axis is a integer, the input
              is considered a batch of vectors, and axis determines the axis in x
              over which to compute vector norms. If axis is a 2-tuple of integer it is
              considered a batch of matrices and axis determines the axes in NDArray
              over which to compute a matrix norm.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Optional. If true, the norm have the same dimensionality
              as the input.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="outerProduct" href="#outerProduct">
tf.outerProduct</a>
    <span class="signature">(v1, v2)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/matmul.ts#L171-L184" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the outer product of two vectors, v1 and v2.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]);

tf.outerProduct(a, b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">v1</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first vector in the outer product operation.</span>
            </li>
            <li class="parameter">
                <span class="param-name">v2</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second vector in the dot product operation.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="transpose" href="#transpose">
tf.transpose</a>
    <span class="signature">(x, perm?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/transpose.ts#L45-L74" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Transposes the <a href="#class:Tensor">tf.Tensor</a>. Permutes the dimensions according to <code>perm</code>.</p>
<p>The returned <a href="#class:Tensor">tf.Tensor</a>'s dimension <code>i</code> will correspond to the input
dimension <code>perm[i]</code>. If <code>perm</code> is not given, it is set to <code>[n-1...0]</code>,
where <code>n</code> is the rank of the input <a href="#class:Tensor">tf.Tensor</a>. Hence by default, this
operation performs a regular matrix transpose on 2-D input <a href="#class:Tensor">tf.Tensor</a>s.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

a.transpose().print();  <span class="hljs-comment">// or tf.transpose(a)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor to transpose.</span>
            </li>
            <li class="parameter">
                <span class="param-name">perm</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The permutation of the dimensions of a.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Convolution
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="avgPool" href="#avgPool">
tf.avgPool</a>
    <span class="signature">(x, filterSize, strides, pad, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/pool.ts#L165-L205" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the 2D average pooling of an image.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 4 or rank 3 of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filterSize</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The filter size, a tuple <code>[filterHeight, filterWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the pooling: <code>[strideHeight, strideWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm:</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="conv1d" href="#conv1d">
tf.conv1d</a>
    <span class="signature">(x, filter, stride, pad, dataFormat?, dilation?, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/conv.ts#L55-L114" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes a 1D convolution over the input x.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="#class:Tensor">tf.Tensor3D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 3 or rank 2, of shape
              <code>[batch, width, inChannels]</code>. If rank 2, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The filter, rank 3, of shape
              <code>[filterWidth, inDepth, outDepth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">stride</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of entries by which the filter is moved right at
              each step.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm.</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('NWC'|'NCW')</span>
                <span class="param-docs">An optional string from &quot;NWC&quot;, &quot;NCW&quot;. Defaults to &quot;NWC&quot;,
              the data is stored in the order of [batch, in_width, in_channels]. Only
              &quot;NWC&quot; is currently supported.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dilation</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dilation rate in which we sample input values in
              atrous convolution. Defaults to <code>1</code>. If it is greater than 1, then
              stride must be <code>1</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor2D</a>|<a href="#class:Tensor">tf.Tensor3D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="conv2d" href="#conv2d">
tf.conv2d</a>
    <span class="signature">(x, filter, strides, pad, dataFormat?, dilations?, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/conv.ts#L147-L215" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes a 2D convolution over the input x.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is
              assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The filter, rank 4, of shape
              <code>[filterHeight, filterWidth, inDepth, outDepth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the convolution: <code>[strideHeight, strideWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm.</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('NHWC'|'NCHW')</span>
                <span class="param-docs">: An optional string from: &quot;NHWC&quot;, &quot;NCHW&quot;. Defaults to
              &quot;NHWC&quot;. Specify the data format of the input and output data. With the
              default format &quot;NHWC&quot;, the data is stored in the order of: [batch,
              height, width, channels]. Only &quot;NHWC&quot; is currently supported.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dilations</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The dilation rates: <code>[dilationHeight, dilationWidth]</code>
              in which we sample input values across the height and width dimensions
              in atrous convolution. Defaults to <code>[1, 1]</code>. If <code>dilations</code> is a single
              number, then <code>dilationHeight == dilationWidth</code>. If it is greater than
              1, then all values of <code>strides</code> must be 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="conv2dTranspose" href="#conv2dTranspose">
tf.conv2dTranspose</a>
    <span class="signature">(x, filter, outputShape, strides, pad, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/conv.ts#L383-L395" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the transposed 2D convolution of an image, also known as a
deconvolution.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input image, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inDepth]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The filter, rank 4, of shape
              <code>[filterHeight, filterWidth, outDepth, inDepth]</code>.
              <code>inDepth</code> must match <code>inDepth</code> in <code>x</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">outputShape</span>
                <span class="param-type">([number, number, number, number]|[number, number, number])</span>
                <span class="param-docs">Output shape, of rank 4 or rank 3:
              <code>[batch, height, width, outDepth]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the original convolution:
              <code>[strideHeight, strideWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm used in the non-transpose version
              of the op.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="depthwiseConv2d" href="#depthwiseConv2d">
tf.depthwiseConv2d</a>
    <span class="signature">(x, filter, strides, pad, dataFormat?, dilations?, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/conv.ts#L441-L509" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Depthwise 2D convolution.</p>
<p>Given a 4D <a href="#input">tf.input()</a> array and a <code>filter</code> array of shape
<code>[filterHeight, filterWidth, inChannels, channelMultiplier]</code> containing
<code>inChannels</code> convolutional filters of depth 1, this op applies a
different filter to each input channel (expanding from 1 channel to
<code>channelMultiplier</code> channels for each), then concatenates the results
together. The output has <code>inChannels * channelMultiplier</code> channels.</p>
<p>See
<a href="https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d">https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d</a>
for more details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is
              assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The filter tensor, rank 4, of shape
              <code>[filterHeight, filterWidth, inChannels, channelMultiplier]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the convolution: <code>[strideHeight, strideWidth]</code>. If strides is a single number, then <code>strideHeight == strideWidth</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm.</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('NHWC'|'NCHW')</span>
                <span class="param-docs">: An optional string from: &quot;NHWC&quot;, &quot;NCHW&quot;. Defaults to
              &quot;NHWC&quot;. Specify the data format of the input and output data. With the
              default format &quot;NHWC&quot;, the data is stored in the order of: [batch,
              height, width, channels]. Only &quot;NHWC&quot; is currently supported.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dilations</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The dilation rates: <code>[dilationHeight, dilationWidth]</code>
              in which we sample input values across the height and width dimensions
              in atrous convolution. Defaults to <code>[1, 1]</code>. If <code>rate</code> is a single
              number, then <code>dilationHeight == dilationWidth</code>. If it is greater than
              1, then all values of <code>strides</code> must be 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="maxPool" href="#maxPool">
tf.maxPool</a>
    <span class="signature">(x, filterSize, strides, pad, dimRoundingMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/pool.ts#L47-L88" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the 2D max pooling of an image.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 4 or rank 3 of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">filterSize</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The filter size, a tuple <code>[filterHeight, filterWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the pooling: <code>[strideHeight, strideWidth]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same'|number)</span>
                <span class="param-docs">The type of padding algorithm.</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dimRoundingMode</span>
                <span class="param-type">('floor'|'round'|'ceil')</span>
                <span class="param-docs">The rounding mode used when computing output
              dimensions if pad is a number. If none is provided, it will not round
              and error if the output is of fractional size.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="separableConv2d" href="#separableConv2d">
tf.separableConv2d</a>
    <span class="signature">(x, depthwiseFilter, pointwiseFilter, strides, pad, dilation?, dataFormat?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/conv.ts#L554-L618" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>2-D convolution with separable filters.</p>
<p>Performs a depthwise convolution that acts separately on channels followed
by a pointwise convolution that mixes channels. Note that this is
separability between dimensions [1, 2] and 3, not spatial separability
between dimensions 1 and 2.</p>
<p>See
<a href="https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d">https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d</a>
for more details.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is
              assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depthwiseFilter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The depthwise filter tensor, rank 4, of shape
              <code>[filterHeight, filterWidth, inChannels, channelMultiplier]</code>. This is
              the filter used in the first step.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pointwiseFilter</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The pointwise filter tensor, rank 4, of shape
              <code>[1, 1, inChannels * channelMultiplier, outChannels]</code>. This is
              the filter used in the second step.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs">The strides of the convolution: <code>[strideHeight, strideWidth]</code>. If strides is a single number, then <code>strideHeight == strideWidth</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">pad</span>
                <span class="param-type">('valid'|'same')</span>
                <span class="param-docs">The type of padding algorithm.</p>
              <ul>
              <li><code>same</code> and stride 1: output will be of same size as input,
              regardless of filter size.</li>
              <li><code>valid</code>: output will be smaller than input if filter is larger
              than 1x1.</li>
              <li>For more info, see this guide:
              <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">https://www.tensorflow.org/api_guides/python/nn#Convolution</a></li>
              </ul>
              </span>
            </li>
            <li class="parameter">
                <span class="param-name">dilation</span>
                <span class="param-type">([number, number]|number)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">dataFormat</span>
                <span class="param-type">('NHWC'|'NCHW')</span>
                <span class="param-docs">: An optional string from: &quot;NHWC&quot;, &quot;NCHW&quot;. Defaults to
              &quot;NHWC&quot;. Specify the data format of the input and output data. With the
              default format &quot;NHWC&quot;, the data is stored in the order of: [batch,
              height, width, channels]. Only &quot;NHWC&quot; is currently supported.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Reduction
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="all" href="#all">
tf.all</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L419-L441" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the logical and of elements across dimensions of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>Reduces the input along the dimensions given in <code>axes</code>. Unless <code>keepDims</code>
is true, the rank of the <a href="#class:Tensor">tf.Tensor</a> is reduced by 1 for each entry in <code>axes</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axes</code> has no entries, all dimensions are reduced, and an <a href="#class:Tensor">tf.Tensor</a> with
a single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]);

x.all().print();  <span class="hljs-comment">// or tf.all(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], <span class="hljs-string">'bool'</span>);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.all(axis).print();  <span class="hljs-comment">// or tf.all(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="any" href="#any">
tf.any</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L470-L492" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the logical or of elements across dimensions of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>Reduces the input along the dimensions given in <code>axes</code>. Unless <code>keepDims</code>
is true, the rank of the <a href="#class:Tensor">tf.Tensor</a> is reduced by 1 for each entry in <code>axes</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axes</code> has no entries, all dimensions are reduced, and an <a href="#class:Tensor">tf.Tensor</a> with
a single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]);

x.any().print();  <span class="hljs-comment">// or tf.any(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], <span class="hljs-string">'bool'</span>);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.any(axis).print();  <span class="hljs-comment">// or tf.any(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="argMax" href="#argMax">
tf.argMax</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L374-L390" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the indices of the maximum values along an <code>axis</code>.</p>
<p>The result has the same shape as <a href="#input">tf.input()</a> with the dimension along <code>axis</code>
removed.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.argMax().print();  <span class="hljs-comment">// or tf.argMax(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.argMax(axis).print();  <span class="hljs-comment">// or tf.argMax(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension to reduce. Defaults to 0 (outer-most dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="argMin" href="#argMin">
tf.argMin</a>
    <span class="signature">(x, axis?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L334-L350" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the indices of the minimum values along an <code>axis</code>.</p>
<p>The result has the same shape as <a href="#input">tf.input()</a> with the dimension along <code>axis</code>
removed.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.argMin().print();  <span class="hljs-comment">// or tf.argMin(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.argMin(axis).print();  <span class="hljs-comment">// or tf.argMin(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension to reduce. Defaults to 0 (outer-most dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logSumExp" href="#logSumExp">
tf.logSumExp</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L57-L76" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the log(sum(exp(elements across the reduction dimensions)).</p>
<p>Reduces the input along the dimensions given in <code>axis</code>. Unless <code>keepDims</code>
is true, the rank of the array is reduced by 1 for each entry in <code>axis</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axis</code> has no entries, all dimensions are reduced, and an array with a
single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.logSumExp().print();  <span class="hljs-comment">// or tf.logSumExp(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.logSumExp(axis).print();  <span class="hljs-comment">// or tf.logSumExp(a, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. If null (the default),
              reduces all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with length
              of 1. Defaults to false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="max" href="#max">
tf.max</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L290-L309" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the maximum of elements across dimensions of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>Reduces the input along the dimensions given in <code>axes</code>. Unless <code>keepDims</code>
is true, the rank of the <a href="#class:Tensor">tf.Tensor</a> is reduced by 1 for each entry in <code>axes</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axes</code> has no entries, all dimensions are reduced, and an <a href="#class:Tensor">tf.Tensor</a> with
a single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.max().print();  <span class="hljs-comment">// or tf.max(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.max(axis).print();  <span class="hljs-comment">// or tf.max(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="mean" href="#mean">
tf.mean</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L177-L213" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the mean of elements across dimensions of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>Reduces <code>x</code> along the dimensions given in <code>axis</code>. Unless <code>keepDims</code> is
true, the rank of the <a href="#class:Tensor">tf.Tensor</a> is reduced by 1 for each entry in <code>axis</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axis</code> has no entries, all dimensions are reduced, and a <a href="#class:Tensor">tf.Tensor</a> with
a single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.mean().print();  <span class="hljs-comment">// or tf.mean(a)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.mean(axis).print();  <span class="hljs-comment">// or tf.mean(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="min" href="#min">
tf.min</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L242-L261" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the minimum value from the input.</p>
<p>Reduces the input along the dimensions given in <code>axes</code>. Unless <code>keepDims</code>
is true, the rank of the array is reduced by 1 for each entry in <code>axes</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If <code>axes</code> has no entries, all dimensions are reduced, and an array with a
single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.min().print();  <span class="hljs-comment">// or tf.min(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.min(axis).print();  <span class="hljs-comment">// or tf.min(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input Tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sum" href="#sum">
tf.sum</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L106-L148" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the sum of elements across dimensions of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<p>Reduces the input along the dimensions given in <code>axes</code>. Unless <code>keepDims</code>
is true, the rank of the <a href="#class:Tensor">tf.Tensor</a> is reduced by 1 for each entry in <code>axes</code>.
If <code>keepDims</code> is true, the reduced dimensions are retained with length 1.
If axes has no entries, all dimensions are reduced, and a <a href="#class:Tensor">tf.Tensor</a> with a
single element is returned.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

x.sum().print();  <span class="hljs-comment">// or tf.sum(x)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor2d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

<span class="hljs-keyword">const</span> axis = <span class="hljs-number">1</span>;
x.sum(axis).print();  <span class="hljs-comment">// or tf.sum(x, axis)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to compute the sum over. If the dtype is <code>bool</code>
              it will be converted to <code>int32</code> and the output dtype will be <code>int32</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) to reduce. By default it reduces
              all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, retains reduced dimensions with size 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Normalization
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="batchNormalization" href="#batchNormalization">
tf.batchNormalization</a>
    <span class="signature">(x, mean, variance, varianceEpsilon?, scale?, offset?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/batchnorm.ts#L229-L347" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Batch normalization.</p>
<p>As described in
<a href="http://arxiv.org/abs/1502.03167">http://arxiv.org/abs/1502.03167</a>.</p>
<p>Mean, variance, scale, and offset can be of two
shapes:</p>
<ul>
<li>The same shape as the input.</li>
<li>In the common case, the depth dimension is the last dimension of x, so
the values would be an <a href="#class:Tensor">tf.Tensor1D</a> of shape [depth].</li>
</ul>
<p>Also available are stricter rank-specific methods with the same signature
as this method that assert that parameters passed are of given rank</p>
<ul>
<li><code>tf.batchNormalization2d</code></li>
<li><code>tf.batchNormalization3d</code></li>
<li><code>tf.batchNormalization4d</code></li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input Tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">mean</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A mean Tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">variance</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A variance Tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">varianceEpsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A small float number to avoid dividing by 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">scale</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A scale Tensor.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">offset</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">An offset Tensor.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="localResponseNormalization" href="#localResponseNormalization">
tf.localResponseNormalization</a>
    <span class="signature">(x, depthRadius?, bias?, alpha?, beta?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/lrn.ts#L40-L69" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Normalizes the activation of a local neighborhood across or within
channels.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor. The 4-D input tensor is treated as a 3-D array
              of 1D vectors (along the last dimension), and each vector is
              normalized independently.</span>
            </li>
            <li class="parameter">
                <span class="param-name">depthRadius</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of adjacent channels in the 1D normalization
              window.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">bias</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A constant bias term for the basis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">alpha</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A scale factor, usually positive.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">beta</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">An exponent.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="moments" href="#moments">
tf.moments</a>
    <span class="signature">(x, axis?, keepDims?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/reduction_ops.ts#L506-L521" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Calculates the mean and variance of <code>x</code>. The mean and variance are
calculated by aggregating the contents of <code>x</code> across <code>axes</code>. If <code>x</code> is
1-D and <code>axes = [0]</code> this is just the mean and variance of a vector.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number|number[])</span>
                <span class="param-docs">The dimension(s) along with to compute mean and
              variance. By default it reduces all dimensions.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">keepDims</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, the moments have the same dimensionality as the
              input.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">{mean: <a href="#class:Tensor">tf.Tensor</a>, variance: <a href="#class:Tensor">tf.Tensor</a>}</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="softmax" href="#softmax">
tf.softmax</a>
    <span class="signature">(logits, dim?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/softmax.ts#L49-L81" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the softmax normalized vector given the logits.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

a.softmax().print();  <span class="hljs-comment">// or tf.softmax(a)</span>
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor2d([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

a.softmax().print();  <span class="hljs-comment">// or tf.softmax(a)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">logits</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The logits array.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dim</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension softmax would be performed on. Defaults to <code>-1</code>
              which indicates the last dimension.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Images
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="image.resizeBilinear" href="#image.resizeBilinear">
tf.image.resizeBilinear</a>
    <span class="signature">(images, size, alignCorners?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/image_ops.ts#L40-L80" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Bilinear resize a batch of 3D images to a new shape.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">images</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The images, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">size</span>
                <span class="param-type">([number, number])</span>
                <span class="param-docs">The new shape <code>[newHeight, newWidth]</code> to resize the
              images to. Each channel is resized individually.</span>
            </li>
            <li class="parameter">
                <span class="param-name">alignCorners</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Defaults to False. If true, rescale
              input by <code>(new_height - 1) / (height - 1)</code>, which exactly aligns the 4
              corners of images and resized images. If false, rescale by
              <code>new_height / height</code>. Treat similarly the width dimension.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="image.resizeNearestNeighbor" href="#image.resizeNearestNeighbor">
tf.image.resizeNearestNeighbor</a>
    <span class="signature">(images, size, alignCorners?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/image_ops.ts#L94-L139" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>NearestNeighbor resize a batch of 3D images to a new shape.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">images</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The images, of rank 4 or rank 3, of shape
              <code>[batch, height, width, inChannels]</code>. If rank 3, batch of 1 is assumed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">size</span>
                <span class="param-type">([number, number])</span>
                <span class="param-docs">The new shape <code>[newHeight, newWidth]</code> to resize the
              images to. Each channel is resized individually.</span>
            </li>
            <li class="parameter">
                <span class="param-name">alignCorners</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Defaults to False. If true, rescale
              input by <code>(new_height - 1) / (height - 1)</code>, which exactly aligns the 4
              corners of images and resized images. If false, rescale by
              <code>new_height / height</code>. Treat similarly the width dimension.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor3D</a>|<a href="#class:Tensor">tf.Tensor4D</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / RNN
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="basicLSTMCell" href="#basicLSTMCell">
tf.basicLSTMCell</a>
    <span class="signature">(forgetBias, lstmKernel, lstmBias, data, c, h)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/lstm.ts#L87-L119" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the next state and output of a BasicLSTMCell.</p>
<p>Returns <code>[newC, newH]</code>.</p>
<p>Derived from tf.contrib.rnn.BasicLSTMCell.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">forgetBias</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Scalar</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Forget bias for the cell.</span>
            </li>
            <li class="parameter">
                <span class="param-name">lstmKernel</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The weights for the cell.</span>
            </li>
            <li class="parameter">
                <span class="param-name">lstmBias</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The bias for the cell.</span>
            </li>
            <li class="parameter">
                <span class="param-name">data</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input to the cell.</span>
            </li>
            <li class="parameter">
                <span class="param-name">c</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Previous cell state.</span>
            </li>
            <li class="parameter">
                <span class="param-name">h</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Previous cell output.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">[<a href="#class:Tensor">tf.Tensor2D</a>, <a href="#class:Tensor">tf.Tensor2D</a>]</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="multiRNNCell" href="#multiRNNCell">
tf.multiRNNCell</a>
    <span class="signature">(lstmCells, data, c, h)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/lstm.ts#L46-L71" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the next states and outputs of a stack of LSTMCells.</p>
<p>Each cell output is used as input to the next cell.</p>
<p>Returns <code>[cellState, cellOutput]</code>.</p>
<p>Derived from tf.contrib.rn.MultiRNNCell.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">lstmCells</span>
                <span class="param-type">((data: <a href="#class:Tensor">tf.Tensor2D</a>, c: <a href="#class:Tensor">tf.Tensor2D</a>, h: <a href="#class:Tensor">tf.Tensor2D</a>): [<a href="#class:Tensor">tf.Tensor2D</a>, <a href="#class:Tensor">tf.Tensor2D</a>][])</span>
                <span class="param-docs">Array of LSTMCell functions.</span>
            </li>
            <li class="parameter">
                <span class="param-name">data</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input to the cell.</span>
            </li>
            <li class="parameter">
                <span class="param-name">c</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>[]|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array[])</span>
                <span class="param-docs">Array of previous cell states.</span>
            </li>
            <li class="parameter">
                <span class="param-name">h</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>[]|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array[])</span>
                <span class="param-docs">Array of previous cell outputs.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">[<a href="#class:Tensor">tf.Tensor2D</a>[], <a href="#class:Tensor">tf.Tensor2D</a>[]]</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Logical
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="equal" href="#equal">
tf.equal</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L129-L140" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a == b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>equalStrict</code> which has the same signature as this op
and asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.equal(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="greater" href="#greater">
tf.greater</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L204-L215" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a &gt; b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>greaterStrict</code> which has the same signature as this
op and asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.greater(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="greaterEqual" href="#greaterEqual">
tf.greaterEqual</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L241-L252" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a &gt;= b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>greaterEqualStrict</code> which has the same signature as this
op and asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.greaterEqual(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="less" href="#less">
tf.less</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L86-L95" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a &lt; b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>lessStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.less(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="lessEqual" href="#lessEqual">
tf.lessEqual</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L166-L177" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a &lt;= b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>lessEqualStrict</code> which has the same signature as this op
and asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]);

a.lessEqual(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logicalAnd" href="#logicalAnd">
tf.logicalAnd</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/logical_ops.ts#L63-L76" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of a AND b element-wise. Supports broadcasting.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);

a.logicalAnd(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must be of dtype bool.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logicalNot" href="#logicalNot">
tf.logicalNot</a>
    <span class="signature">(x)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/logical_ops.ts#L41-L48" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of <code>NOT x</code> element-wise.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);

a.logicalNot().print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor. Must be of dtype 'bool'.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logicalOr" href="#logicalOr">
tf.logicalOr</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/logical_ops.ts#L90-L103" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of <code>a OR b</code> element-wise. Supports broadcasting.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);

a.logicalOr(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must be of dtype bool.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="logicalXor" href="#logicalXor">
tf.logicalXor</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/logical_ops.ts#L118-L132" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of <code>a XOR b</code> element-wise. Supports broadcasting.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);

a.logicalXor(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must be of dtype bool.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="notEqual" href="#notEqual">
tf.notEqual</a>
    <span class="signature">(a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/compare.ts#L43-L53" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the truth value of (a != b) element-wise. Supports broadcasting.</p>
<p>We also expose <code>notEqualStrict</code> which has the same signature as this op and
asserts that <code>a</code> and <code>b</code> are the same shape (does not broadcast).</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);

a.notEqual(b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The first input tensor.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The second input tensor. Must have the same dtype as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="where" href="#where">
tf.where</a>
    <span class="signature">(condition, a, b)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/logical_ops.ts#L152-L189" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the elements, either <code>a</code> or <code>b</code> depending on the <code>condition</code>.</p>
<p>If the condition is true, select from <code>a</code>, otherwise select from <code>b</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> cond = tf.tensor1d([<span class="hljs-literal">false</span>, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>], <span class="hljs-string">'bool'</span>);
<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">1</span> , <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">-3</span>]);

a.where(cond, b).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">condition</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input condition. Must be of dtype bool.</span>
            </li>
            <li class="parameter">
                <span class="param-name">a</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">If <code>condition</code> is rank 1, <code>a</code> may have a higher rank but
              its first dimension must match the size of <code>condition</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">b</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A tensor with the same shape and type as <code>a</code>.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Scan
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="cumsum" href="#cumsum">
tf.cumsum</a>
    <span class="signature">(x, axis?, exclusive?, reverse?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L876-L901" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the cumulative sum of a <a href="#class:Tensor">tf.Tensor</a> along <code>axis</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
x.cumsum().print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]);
x.cumsum().print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The input tensor to be summed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The axis along which to sum. Optional. Defaults to 0.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">exclusive</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to perform exclusive cumulative sum. Optional.
              Defaults to false. If set to true then the sum of each tensor entry
              does not include its own value, but only the values previous to it
              along the specified axis.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reverse</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to sum in the opposite direction. Optional.
              Defaults to false.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Linear Algebra
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="gramSchmidt" href="#gramSchmidt">
tf.gramSchmidt</a>
    <span class="signature">(xs)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/linalg_ops.ts#L50-L97" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Gram-Schmidt orthogonalization.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">xs</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>[]|<a href="#class:Tensor">tf.Tensor2D</a>)</span>
                <span class="param-docs">The vectors to be orthogonalized, in one of the two following
              formats:</p>
              <ul>
              <li>An Array of <a href="#class:Tensor">tf.Tensor1D</a>.</li>
              <li>A <a href="#class:Tensor">tf.Tensor2D</a>, i.e., a matrix, in which case the vectors are the rows
              of <code>xs</code>.
              In each case, all the vectors must have the same length and the length
              must be greater than or equal to the number of vectors.</li>
              </ul>
              </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor1D</a>[]|<a href="#class:Tensor">tf.Tensor2D</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="qr" href="#qr">
tf.qr</a>
    <span class="signature">(x, fullMatrices?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/linalg_ops.ts#L125-L158" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Compute QR decomposition of m-by-n matrix using Householder transformation.</p>
<p>Implementation based on
[http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]
(http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The <a href="#class:Tensor">tf.Tensor</a> to be QR-decomposed. Must have rank &gt;= 2. Suppose
              it has the shape <code>[..., M, N]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">fullMatrices</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">An optional boolean parameter. Defaults to <code>false</code>.
              If <code>true</code>, compute full-sized <code>Q</code>. If <code>false</code> (the default),
              compute only the leading N columns of <code>Q</code> and <code>R</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">[<a href="#class:Tensor">tf.Tensor</a>, <a href="#class:Tensor">tf.Tensor</a>]</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Moving Average
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="movingAverage" href="#movingAverage">
tf.movingAverage</a>
    <span class="signature">(v, x, decay, step?, zeroDebias?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/moving_average.ts#L55-L79" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Compute the moving average of a variable.</p>
<p>Without zeroDebias, the moving average operation is defined by:
<code>v += delta</code>
where
<code>delta = (1 - decay) * (x - v)</code></p>
<p>With zeroDebias (default), the <code>delta</code> term is scaled to debias the
effect of the (assumed) zero-initialization of <code>v</code>.
<code>delta /= (1 - decay ^ step)</code></p>
<p>For more details on the zero-debiasing algorithm, see:
https://arxiv.org/abs/1412.6980</p>
<p>Note that this function is completely stateless and does not keep track of
step count. The step count needs to be maintained by the caller and passed
in as <a href="#step">tf.step()</a>.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">v</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The current moving average value.</span>
            </li>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">New input value, must have the same shape and dtype as <code>v</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">decay</span>
                <span class="param-type">(number|<a href="#class:Tensor">tf.Scalar</a>)</span>
                <span class="param-docs">The decay factor. Typical values are 0.95 and 0.99.</span>
            </li>
            <li class="parameter">
                <span class="param-name">step</span>
                <span class="param-type">(number|<a href="#class:Tensor">tf.Scalar</a>)</span>
                <span class="param-docs">Step count.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">zeroDebias</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">: Whether zeroDebias is to be performed (default: <code>true</code>).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Segment
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="unsortedSegmentSum" href="#unsortedSegmentSum">
tf.unsortedSegmentSum</a>
    <span class="signature">(x, segmentIds, numSegments)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/segment_ops.ts#L49-L71" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the sum along segments of a <a href="#class:Tensor">tf.Tensor</a>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]);
<span class="hljs-keyword">const</span> segmentIds = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">'int32'</span>);
<span class="hljs-keyword">const</span> numSegments = <span class="hljs-number">3</span>;

x.unsortedSegmentSum(segmentIds, numSegments).print()
<span class="hljs-comment">//or tf.unsortedSegmentSum(x, segmentIds, numSegments)</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The <a href="#class:Tensor">tf.Tensor</a> that will be summed along its segments</span>
            </li>
            <li class="parameter">
                <span class="param-name">segmentIds</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor1D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A <a href="#class:Tensor">tf.Tensor1D</a> whose rank is equal to the rank of <code>x</code>'s
              dimension along the <code>axis</code>.  Maps each element of <code>x</code> to a segment.</span>
            </li>
            <li class="parameter">
                <span class="param-name">numSegments</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The number of distinct <code>segmentIds</code></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Cross Entropy
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="sigmoidCrossEntropyWithLogits" href="#sigmoidCrossEntropyWithLogits">
tf.sigmoidCrossEntropyWithLogits</a>
    <span class="signature">(labels, logits)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/sigmoid_cross_entropy.ts#L32-L69" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes sigmoid cross entropy given logits.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A Tensor of the same type and shape as logits.</span>
            </li>
            <li class="parameter">
                <span class="param-name">logits</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A Tensor of type float32 or float64.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Operations / Slicing and Joining
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="stridedSlice" href="#stridedSlice">
tf.stridedSlice</a>
    <span class="signature">(x, begin, end, strides, beginMask?, endMask?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/strided_slice.ts#L54-L64" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Extracts a strided slice of a tensor.</p>
<p>Roughly speaking, this op extracts a slice of size (end-begin)/stride from
the given input_ tensor. Starting at the location specified by begin the
slice continues by adding stride to the index until all dimensions are not
less than end. Note that a stride can be negative, which causes a reverse
slice.</p>
<pre class="hljs"><code class="hljs language-js">t = tf.tensor3d([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span> ,<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>],
    [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
t.stridedSlice([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]).print()  <span class="hljs-comment">// [[[3, 3, 3]]]</span>
t.stridedSlice([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]).print()  <span class="hljs-comment">// [[[3, 3, 3],</span>
                                                     <span class="hljs-comment">// [4, 4, 4]]]</span>
t.stridedSlice([<span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">-3</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">1</span>]).print() <span class="hljs-comment">// [[[4, 4, 4],</span>
                                                     <span class="hljs-comment">// [3, 3, 3]]]</span>
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">x</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The tensor to stride slice.</span>
            </li>
            <li class="parameter">
                <span class="param-name">begin</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">The coordinates to start the slice from.</span>
            </li>
            <li class="parameter">
                <span class="param-name">end</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">: The coordinates to end the slice at.</span>
            </li>
            <li class="parameter">
                <span class="param-name">strides</span>
                <span class="param-type">(number[])</span>
                <span class="param-docs">: The size of the slice.</span>
            </li>
            <li class="parameter">
                <span class="param-name">beginMask</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">: If the ith bit of begin_mask is set, begin[i] is ignored
              and the fullest possible range in that dimension is used instead.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">endMask</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">: If the ith bit of end_mask is set, end[i] is ignored
              and the fullest possible range in that dimension is used instead.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Training
            </div>
          <div class="description">
             <p>We also provide an API to do perform training, and
        compute gradients. We compute gradients eagerly, users provide a function
        that is a combination of operations and we automatically differentiate
        that function's output with respect to its inputs.
        <p>For those familiar with TensorFlow, the API we expose exactly mirrors
        the TensorFlow Eager API.
        </p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Training / Gradients
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="grad" href="#grad">
tf.grad</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L74-L97" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Provided <code>f(x)</code>, returns another function <code>g(x, dy?)</code>, which gives the
gradient of <code>f(x)</code> with respect to <code>x</code>.</p>
<p>If <code>dy</code> is provided, the gradient of <code>f(x).mul(dy).sum()</code> with respect to
<code>x</code> is computed instead. <code>f(x)</code> must take a single tensor <code>x</code> and return a
single tensor <code>y</code>. If <code>f()</code> takes multiple inputs, use <a href="#grads">tf.grads()</a> instead.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// f(x) = x ^ 2</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> x.square();
<span class="hljs-comment">// f'(x) = 2x</span>
<span class="hljs-keyword">const</span> g = tf.grad(f);

<span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
g(x).print();
</code></pre>

<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// f(x) = x ^ 3</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> x.pow(tf.scalar(<span class="hljs-number">3</span>, <span class="hljs-string">'int32'</span>));
<span class="hljs-comment">// f'(x) = 3x ^ 2</span>
<span class="hljs-keyword">const</span> g = tf.grad(f);
<span class="hljs-comment">// f''(x) = 6x</span>
<span class="hljs-keyword">const</span> gg = tf.grad(g);

<span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
gg(x).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">((x: <a href="#class:Tensor">tf.Tensor</a>) =&gt; <a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The function f(x), to compute gradient for.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">(x: <a href="#class:Tensor">tf.Tensor</a>, dy?: <a href="#class:Tensor">tf.Tensor</a>) =&gt; <a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="grads" href="#grads">
tf.grads</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L126-L150" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Provided <code>f(x1, x2,...)</code>, returns another function <code>g([x1, x2,...], dy?)</code>,
which gives an array of gradients of <code>f()</code> with respect to each input
[<code>x1</code>,<code>x2</code>,...].</p>
<p>If <code>dy</code> is passed when calling <code>g()</code>, the gradient of
<code>f(x1,...).mul(dy).sum()</code> with respect to each input is computed instead.
The provided <code>f</code> must take one or more tensors and return a single tensor
<code>y</code>. If <code>f()</code> takes a single input, we recommend using <a href="#grad">tf.grad()</a> instead.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// f(a, b) = a * b</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function">(<span class="hljs-params">a, b</span>) =&gt;</span> a.mul(b);
<span class="hljs-comment">// df / da = b, df / db = a</span>
<span class="hljs-keyword">const</span> g = tf.grads(f);

<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">-2</span>, <span class="hljs-number">-3</span>]);
<span class="hljs-keyword">const</span> [da, db] = g([a, b]);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'da'</span>);
da.print();
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'db'</span>);
db.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">((...args: <a href="#class:Tensor">tf.Tensor</a>[]) =&gt; <a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The function <code>f(x1, x2,...)</code> to compute gradients for.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">(args: <a href="#class:Tensor">tf.Tensor</a>[], dy?: <a href="#class:Tensor">tf.Tensor</a>) =&gt; <a href="#class:Tensor">tf.Tensor</a>[]</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="customGrad" href="#customGrad">
tf.customGrad</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L353-L357" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Overrides the gradient computation of a function <code>f</code>.</p>
<p>Takes a function
<code>f(...inputs) =&gt; {value: Tensor, gradFunc: dy =&gt; Tensor[]}</code> and returns
another function <code>g(...inputs)</code> which takes the same inputs as <code>f</code>. When
called, <code>g</code> returns <code>f().value</code>. In backward mode, custom gradients with
respect to each input of <code>f</code> are computed using <code>f().gradFunc</code>.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> customOp = tf.customGrad(<span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> {
   <span class="hljs-comment">// Override gradient of our custom x ^ 2 op to be dy * abs(x);</span>
   <span class="hljs-keyword">return</span> {<span class="hljs-attr">value</span>: x.square(), <span class="hljs-attr">gradFunc</span>: <span class="hljs-function"><span class="hljs-params">dy</span> =&gt;</span> [dy.mul(x.abs())]};
});

<span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> dx = tf.grad(<span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> customOp(x));

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">`f(x):`</span>);
customOp(x).print();
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">`f'(x):`</span>);
dx(x).print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">((a: <a href="#class:Tensor">tf.Tensor</a>, b: <a href="#class:Tensor">tf.Tensor</a>,...) =&gt; {
              value: <a href="#class:Tensor">tf.Tensor</a>, * gradFunc: (dy: <a href="#class:Tensor">tf.Tensor</a>) =&gt; <a href="#class:Tensor">tf.Tensor</a> | <a href="#class:Tensor">tf.Tensor</a>[] * })</span>
                <span class="param-docs">The function to evaluate in forward mode, which should return
              <code>{value: Tensor, gradFunc: (dy) =&gt; Tensor[]}</code>, where <code>gradFunc</code> returns
              the custom gradients of <code>f</code> with respect to its inputs.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">(...args: <a href="#class:Tensor">tf.Tensor</a>[]) =&gt; <a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="valueAndGrad" href="#valueAndGrad">
tf.valueAndGrad</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L175-L195" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Like <a href="#grad">tf.grad()</a>, but also returns the value of <code>f()</code>. Useful when <code>f()</code>
returns a metric you want to show.</p>
<p>The result is a rich object with the following properties:</p>
<ul>
<li>grad: The gradient of <code>f(x)</code> w.r.t <code>x</code> (result of <a href="#grad">tf.grad()</a>).</li>
<li>value: The value returned by <code>f(x)</code>.</li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// f(x) = x ^ 2</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> x.square();
<span class="hljs-comment">// f'(x) = 2x</span>
<span class="hljs-keyword">const</span> g = tf.valueAndGrad(f);

<span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> {value, grad} = g(x);

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'value'</span>);
value.print();
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'grad'</span>);
grad.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">((x: <a href="#class:Tensor">tf.Tensor</a>) =&gt; <a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">(x: <a href="#class:Tensor">tf.Tensor</a>, dy?: <a href="#class:Tensor">tf.Tensor</a>) =&gt; {
value: <a href="#class:Tensor">tf.Tensor</a>;
grad: <a href="#class:Tensor">tf.Tensor</a>;
}</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="valueAndGrads" href="#valueAndGrads">
tf.valueAndGrads</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L226-L252" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Like <a href="#grads">tf.grads()</a>, but returns also the value of <code>f()</code>. Useful when <code>f()</code>
returns a metric you want to show.</p>
<p>The result is a rich object with the following properties:</p>
<ul>
<li>grads: The gradients of <code>f()</code> w.r.t each input (result of <a href="#grads">tf.grads()</a>).</li>
<li>value: The value returned by <code>f(x)</code>.</li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// f(a, b) = a * b</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function">(<span class="hljs-params">a, b</span>) =&gt;</span> a.mul(b);
<span class="hljs-comment">// df/da = b, df/db = a</span>
<span class="hljs-keyword">const</span> g = tf.valueAndGrads(f);

<span class="hljs-keyword">const</span> a = tf.tensor1d([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> b = tf.tensor1d([<span class="hljs-number">-2</span>, <span class="hljs-number">-3</span>]);
<span class="hljs-keyword">const</span> {value, grads} = g([a, b]);

<span class="hljs-keyword">const</span> [da, db] = grads;

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'value'</span>);
value.print();

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'da'</span>);
da.print();
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'db'</span>);
db.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">((...args: <a href="#class:Tensor">tf.Tensor</a>[]) =&gt; <a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">(args: <a href="#class:Tensor">tf.Tensor</a>[], dy?: <a href="#class:Tensor">tf.Tensor</a>) =&gt; {
grads: <a href="#class:Tensor">tf.Tensor</a>[];
value: <a href="#class:Tensor">tf.Tensor</a>;
}</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="variableGrads" href="#variableGrads">
tf.variableGrads</a>
    <span class="signature">(f, varList?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/gradients.ts#L275-L323" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes and returns the gradient of f(x) with respect to the list of
trainable variables provided by <code>varList</code>. If no list is provided, it
defaults to all trainable variables.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> a = tf.variable(tf.tensor1d([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]));
<span class="hljs-keyword">const</span> b = tf.variable(tf.tensor1d([<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]));
<span class="hljs-keyword">const</span> x = tf.tensor1d([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]);

<span class="hljs-comment">// f(a, b) = a * x ^ 2 + b * x</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> a.mul(x.square()).add(b.mul(x)).sum();
<span class="hljs-comment">// df/da = x ^ 2, df/db = x</span>
<span class="hljs-keyword">const</span> {value, grads} = tf.variableGrads(f);

<span class="hljs-built_in">Object</span>.keys(grads).forEach(<span class="hljs-function"><span class="hljs-params">varName</span> =&gt;</span> grads[varName].print());
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">(() =&gt; <a href="#class:Tensor">tf.Scalar</a>)</span>
                <span class="param-docs">The function to execute. f() should return a scalar.</span>
            </li>
            <li class="parameter">
                <span class="param-name">varList</span>
                <span class="param-type">(<a href="#class:Variable">tf.Variable</a>[])</span>
                <span class="param-docs">The list of trainable variables. Defaults to all variables.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">{value: <a href="#class:Tensor">tf.Scalar</a>, grads: {[name: string]: <a href="#class:Tensor">tf.Tensor</a>}}</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Training / Optimizers
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.sgd" href="#train.sgd">
tf.train.sgd</a>
    <span class="signature">(learningRate)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L64-L67" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <a href="#class:train.Optimizer">tf.SGDOptimizer</a> that uses stochastic gradient descent.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// Fit a quadratic function by learning the coefficients a, b, c.</span>
<span class="hljs-keyword">const</span> xs = tf.tensor1d([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);
<span class="hljs-keyword">const</span> ys = tf.tensor1d([<span class="hljs-number">1.1</span>, <span class="hljs-number">5.9</span>, <span class="hljs-number">16.8</span>, <span class="hljs-number">33.9</span>]);

<span class="hljs-keyword">const</span> a = tf.scalar(<span class="hljs-built_in">Math</span>.random()).variable();
<span class="hljs-keyword">const</span> b = tf.scalar(<span class="hljs-built_in">Math</span>.random()).variable();
<span class="hljs-keyword">const</span> c = tf.scalar(<span class="hljs-built_in">Math</span>.random()).variable();

<span class="hljs-comment">// y = a * x^2 + b * x + c.</span>
<span class="hljs-keyword">const</span> f = <span class="hljs-function"><span class="hljs-params">x</span> =&gt;</span> a.mul(x.square()).add(b.mul(x)).add(c);
<span class="hljs-keyword">const</span> loss = <span class="hljs-function">(<span class="hljs-params">pred, label</span>) =&gt;</span> pred.sub(label).square().mean();

<span class="hljs-keyword">const</span> learningRate = <span class="hljs-number">0.01</span>;
<span class="hljs-keyword">const</span> optimizer = tf.train.sgd(learningRate);

<span class="hljs-comment">// Train the model.</span>
<span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {
   optimizer.minimize(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> loss(f(xs), ys));
}

<span class="hljs-comment">// Make predictions.</span>
<span class="hljs-built_in">console</span>.log(
     <span class="hljs-string">`a: <span class="hljs-subst">${a.dataSync()}</span>, b: <span class="hljs-subst">${b.dataSync()}</span>, c: <span class="hljs-subst">${c.dataSync()}</span>`</span>);
<span class="hljs-keyword">const</span> preds = f(xs).dataSync();
preds.forEach(<span class="hljs-function">(<span class="hljs-params">pred, i</span>) =&gt;</span> {
   <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`x: <span class="hljs-subst">${i}</span>, pred: <span class="hljs-subst">${pred}</span>`</span>);
});
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the SGD algorithm.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:train.Optimizer">tf.SGDOptimizer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.momentum" href="#train.momentum">
tf.train.momentum</a>
    <span class="signature">(learningRate, momentum, useNesterov?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L82-L86" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <a href="#class:train.Optimizer">tf.MomentumOptimizer</a> that uses momentum gradient
descent.</p>
<p>See
<a href="http://proceedings.mlr.press/v28/sutskever13.pdf">http://proceedings.mlr.press/v28/sutskever13.pdf</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the Momentum gradient
              descent algorithm.</span>
            </li>
            <li class="parameter">
                <span class="param-name">momentum</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The momentum to use for the momentum gradient descent
              algorithm.</span>
            </li>
            <li class="parameter">
                <span class="param-name">useNesterov</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:train.Optimizer">tf.MomentumOptimizer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.adagrad" href="#train.adagrad">
tf.train.adagrad</a>
    <span class="signature">(learningRate, initialAccumulatorValue?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L179-L183" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <a href="#class:train.Optimizer">tf.AdagradOptimizer</a> that uses the Adagrad algorithm.
See
<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf</a>
or
<a href="http://ruder.io/optimizing-gradient-descent/index.html#adagrad">http://ruder.io/optimizing-gradient-descent/index.html#adagrad</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the Adagrad gradient
              descent algorithm.</span>
            </li>
            <li class="parameter">
                <span class="param-name">initialAccumulatorValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Starting value for the accumulators, must be
              positive.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:train.Optimizer">tf.AdagradOptimizer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.adadelta" href="#train.adadelta">
tf.train.adadelta</a>
    <span class="signature">(learningRate?, rho?, epsilon?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L141-L145" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <a href="#class:train.Optimizer">tf.AdadeltaOptimizer</a> that uses the Adadelta algorithm.
See <a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the Adadelta gradient
              descent algorithm.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">rho</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate decay over each update.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A constant epsilon used to better condition the grad
              update.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:train.Optimizer">tf.AdadeltaOptimizer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.adam" href="#train.adam">
tf.train.adam</a>
    <span class="signature">(learningRate?, beta1?, beta2?, epsilon?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L124-L129" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <code>AdamOptimizer</code> that uses the Adam algorithm.
See <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the Adam gradient
              descent algorithm.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">beta1</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The exponential decay rate for the 1st moment estimates.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">beta2</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The exponential decay rate for the 2nd moment estimates.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A small constant for numerical stability.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">AdamOptimizer</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.adamax" href="#train.adamax">
tf.train.adamax</a>
    <span class="signature">(learningRate?, beta1?, beta2?, epsilon?, decay?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L158-L163" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <code>AdamaxOptimizer</code> that uses the Adamax algorithm.
See <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the Adamax gradient
              descent algorithm.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">beta1</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The exponential decay rate for the 1st moment estimates.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">beta2</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The exponential decay rate for the 2nd moment estimates.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A small constant for numerical stability.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">decay</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate decay over each update.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">AdamaxOptimizer</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="train.rmsprop" href="#train.rmsprop">
tf.train.rmsprop</a>
    <span class="signature">(learningRate, decay?, momentum?, epsilon?, centered?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer_constructors.ts#L106-L112" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constructs a <a href="#class:train.Optimizer">tf.RMSPropOptimizer</a> that uses RMSProp gradient
descent. This implementation uses plain momentum and is not centered
version of RMSProp.</p>
<p>See
<a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">learningRate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The learning rate to use for the RMSProp gradient
              descent algorithm.</span>
            </li>
            <li class="parameter">
                <span class="param-name">decay</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The discounting factor for the history/coming gradient.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">momentum</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The momentum to use for the RMSProp gradient descent
              algorithm.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Small value to avoid zero denominator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">centered</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">If true, gradients are normalized by the estimated
              variance of the gradient.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:train.Optimizer">tf.RMSPropOptimizer</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Training / Losses
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.absoluteDifference" href="#losses.absoluteDifference">
tf.losses.absoluteDifference</a>
    <span class="signature">(labels, predictions, weights?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L95-L113" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the absolute difference loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.computeWeightedLoss" href="#losses.computeWeightedLoss">
tf.losses.computeWeightedLoss</a>
    <span class="signature">(losses, weights?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L44-L80" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the weighted loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">losses</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor of shape <code>[batch_size, d1, ... dN]</code>.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>losses</code>, and must be broadcastable to <code>losses</code> (i.e., all
              dimensions must be either <code>1</code>, or the same as the corresponding
              <code>losses</code> dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.cosineDistance" href="#losses.cosineDistance">
tf.losses.cosineDistance</a>
    <span class="signature">(labels, predictions, axis, weights?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L162-L181" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the cosine distance loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension along which the cosine distance is computed.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.hingeLoss" href="#losses.hingeLoss">
tf.losses.hingeLoss</a>
    <span class="signature">(labels, predictions, weights?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L196-L217" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the Hinge loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.huberLoss" href="#losses.huberLoss">
tf.losses.huberLoss</a>
    <span class="signature">(labels, predictions, weights?, delta?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L270-L295" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the huber loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">delta</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Point where huber loss changes from quadratic to linear.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.logLoss" href="#losses.logLoss">
tf.losses.logLoss</a>
    <span class="signature">(labels, predictions, weights?, epsilon?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L233-L254" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the log loss between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">epsilon</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">A small increment to avoid taking log of zero</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.meanSquaredError" href="#losses.meanSquaredError">
tf.losses.meanSquaredError</a>
    <span class="signature">(labels, predictions, weights?, reduction?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/loss_ops.ts#L128-L146" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes the mean squared error between two tensors.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The ground truth output tensor, same dimensions as
              'predictions'.</span>
            </li>
            <li class="parameter">
                <span class="param-name">predictions</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The predicted outputs.</span>
            </li>
            <li class="parameter">
                <span class="param-name">weights</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">Tensor whose rank is either 0, or the same rank as
              <code>labels</code>, and must be broadcastable to <code>labels</code> (i.e., all dimensions
              must be either <code>1</code>, or the same as the corresponding <code>losses</code>
              dimension).</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">reduction</span>
                <span class="param-type">(Reduction)</span>
                <span class="param-docs">Type of reduction to apply to loss. Should be of type
              <code>Reduction</code></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="losses.softmaxCrossEntropy" href="#losses.softmaxCrossEntropy">
tf.losses.softmaxCrossEntropy</a>
    <span class="signature">(labels, logits, dim?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/softmax.ts#L107-L143" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Computes softmax cross entropy between logits and labels.</p>
<p>Measures the probability error in discrete classification tasks in which
the classes are mutually exclusive (each entry is in exactly one class).
For example, each CIFAR-10 image is labeled with one and only one label: an
image can be a dog or a truck, but not both.</p>
<p><code>NOTE</code>: While the classes are mutually exclusive, their probabilities need
not be. All that is required is that each row of labels is a valid
probability distribution. If they are not, the computation of the gradient
will be incorrect.</p>
<p><code>WARNING</code>: This op expects unscaled logits, since it performs a softmax on
logits internally for efficiency. Do not call this op with the output of
softmax, as it will produce incorrect results.</p>
<p>logits and labels must have the same shape, e.g. [batch_size, num_classes]
and the same dtype.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">labels</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The labels array.</span>
            </li>
            <li class="parameter">
                <span class="param-name">logits</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">The logits array.</span>
            </li>
            <li class="parameter">
                <span class="param-name">dim</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The dimension softmax would be performed on. Defaults to <code>-1</code>
              which indicates the last dimension.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Training / Classes
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:train.Optimizer" href="#class:train.Optimizer">tf.train.Optimizer</a>
    <span class="signature">
        <span>extends Serializable</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer.ts#L24-L76" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  <div class="method-list">
<div class="symfunction method">
  <div class="symbol-header">
    <a class="symbol-link" name="tf.train.Optimizer.minimize" href="#tf.train.Optimizer.minimize">
minimize</a>
    <span class="signature">(f, returnCost?, varList?)</span>
      <span class="symbol-marker">method</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/optimizers/optimizer.ts#L37-L54" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Executes <code>f()</code> and minimizes the scalar output of <code>f()</code> by computing
gradients of y with respect to the list of trainable variables provided by
<code>varList</code>. If no list is provided, it defaults to all trainable variables.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">(() =&gt; <a href="#class:Tensor">tf.Scalar</a>)</span>
                <span class="param-docs">The function to execute and whose output to minimize.</span>
            </li>
            <li class="parameter">
                <span class="param-name">returnCost</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Whether to return the scalar cost value produced by
              executing <code>f()</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">varList</span>
                <span class="param-type">(<a href="#class:Variable">tf.Variable</a>[])</span>
                <span class="param-docs">An optional list of variables to update. If specified, only
              the trainable variables in varList will be updated by minimize. Defaults to
              all trainable variables.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Scalar</a>
|null</span>
  </div>
</div>

  </div>
</div>
      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Performance
            </div>
          <div class="description">
             
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Performance / Memory
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="tidy" href="#tidy">
tf.tidy</a>
    <span class="signature">(nameOrFn, fn?, gradMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L151-L155" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Executes the provided function <code>fn</code> and after it is executed, cleans up all
intermediate tensors allocated by <code>fn</code> except those returned by <code>fn</code>.
<code>f</code> must not return a Promise (async functions not allowed).
The returned result can be a complex object, however tidy only walks the
top-level properties (depth 1) of that object to search for tensors, or
lists of tensors that need to be tracked in the parent scope.</p>
<p>Using this method helps avoid memory leaks. In general, wrap calls to
operations in <a href="#tidy">tf.tidy()</a> for automatic memory cleanup.</p>
<p>When in safe mode, you must enclose all <a href="#class:Tensor">tf.Tensor</a> creation and ops
inside a <a href="#tidy">tf.tidy()</a> to prevent memory leaks.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-comment">// y = 2 ^ 2 + 1</span>
<span class="hljs-keyword">const</span> y = tf.tidy(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> {
   <span class="hljs-comment">// a, b, and one will be cleaned up when the tidy ends.</span>
   <span class="hljs-keyword">const</span> one = tf.scalar(<span class="hljs-number">1</span>);
   <span class="hljs-keyword">const</span> a = tf.scalar(<span class="hljs-number">2</span>);
   <span class="hljs-keyword">const</span> b = a.square();

   <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'numTensors (in tidy): '</span> + tf.memory().numTensors);

   <span class="hljs-comment">// The value returned inside the tidy function will return</span>
   <span class="hljs-comment">// through the tidy, in this case to the variable y.</span>
   <span class="hljs-keyword">return</span> b.add(one);
});

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'numTensors (outside tidy): '</span> + tf.memory().numTensors);
y.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">nameOrFn</span>
                <span class="param-type">(string|Function)</span>
                <span class="param-docs">The name of the closure, or the function to execute.
              If a name is provided, the 2nd argument should be the function.
              If debug mode is on, the timing and the memory usage of the function
              will be tracked and displayed on the console using the provided name.</span>
            </li>
            <li class="parameter">
                <span class="param-name">fn</span>
                <span class="param-type">(Function)</span>
                <span class="param-docs">The function to execute.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter">
                <span class="param-name">gradMode</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void|number|string|<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[key:
string]:<a href="#class:Tensor">tf.Tensor</a>|number|string}</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="dispose" href="#dispose">
tf.dispose</a>
    <span class="signature">(container)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L166-L170" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Disposes any <a href="#class:Tensor">tf.Tensor</a>s found within the provided object.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">container</span>
                <span class="param-type">(void|number|string|<a href="#class:Tensor">tf.Tensor</a>|<a href="#class:Tensor">tf.Tensor</a>[]|{[key:
              string]:<a href="#class:Tensor">tf.Tensor</a>|number|string})</span>
                <span class="param-docs">an object that may be a <a href="#class:Tensor">tf.Tensor</a> or may directly contain
              <a href="#class:Tensor">tf.Tensor</a>s, such as a <code>Tensor[]</code> or <code>{key: Tensor, ...}</code>.  If the
              object is not a <a href="#class:Tensor">tf.Tensor</a> or does not contain <code>Tensors</code>, nothing
              happens. In general it is safe to pass any object here, except that
              <code>Promise</code>s are not supported.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="keep" href="#keep">
tf.keep</a>
    <span class="signature">(result)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L202-L205" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Keeps a <a href="#class:Tensor">tf.Tensor</a> generated inside a <a href="#tidy">tf.tidy()</a> from being disposed
automatically.</p>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">let</span> b;
<span class="hljs-keyword">const</span> y = tf.tidy(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> {
   <span class="hljs-keyword">const</span> one = tf.scalar(<span class="hljs-number">1</span>);
   <span class="hljs-keyword">const</span> a = tf.scalar(<span class="hljs-number">2</span>);

   <span class="hljs-comment">// b will not be cleaned up by the tidy. a and one will be cleaned up</span>
   <span class="hljs-comment">// when the tidy ends.</span>
   b = tf.keep(a.square());

   <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'numTensors (in tidy): '</span> + tf.memory().numTensors);

   <span class="hljs-comment">// The value returned inside the tidy function will return</span>
   <span class="hljs-comment">// through the tidy, in this case to the variable y.</span>
   <span class="hljs-keyword">return</span> b.add(one);
});

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'numTensors (outside tidy): '</span> + tf.memory().numTensors);
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'y:'</span>);
y.print();
<span class="hljs-built_in">console</span>.log(<span class="hljs-string">'b:'</span>);
b.print();
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">result</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs">The tensor to keep from being disposed.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="memory" href="#memory">
tf.memory</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L107-L110" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns memory info at the current time in the program. The result is an
object with the following properties:</p>
<ul>
<li><code>numBytes</code>: Number of bytes allocated (undisposed) at this time.</li>
<li><code>numTensors</code>: Number of unique tensors allocated.</li>
<li><code>numDataBuffers</code>: Number of unique data buffers allocated
(undisposed) at this time, which is  the number of tensors
(e.g. <code>a.reshape(newShape)</code> makes a new Tensor that shares the same
data buffer with <code>a</code>).</li>
<li><code>unreliable</code>: <code>Optional</code> <code>boolean</code>:
<ul>
<li>On WebGL, not present (always reliable).</li>
<li>On CPU, true. Due to automatic garbage collection, these numbers
represent undisposed tensors, i.e. not wrapped in <code>tidy()</code>, or
lacking a call to <code>tensor.dispose()</code>.</li>
</ul>
</li>
</ul>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">MemoryInfo</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Performance / Timing
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="time" href="#time">
tf.time</a>
    <span class="signature">(f)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L228-L231" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Executes <code>f()</code> and returns a promise that resolves with timing
information.</p>
<p>The result is an object with the following properties:</p>
<ul>
<li><code>wallMs</code>: Wall execution time.</li>
<li><code>kernelMs</code>: Kernel execution time, ignoring data transfer.</li>
<li>On <code>WebGL</code> The following additional properties exist:
<ul>
<li><code>uploadWaitMs</code>: CPU blocking time on texture uploads.</li>
<li><code>downloadWaitMs</code>: CPU blocking time on texture downloads (readPixels).</li>
</ul>
</li>
</ul>
<pre class="hljs"><code class="hljs language-js"><span class="hljs-keyword">const</span> x = tf.randomNormal([<span class="hljs-number">20</span>, <span class="hljs-number">20</span>]);
<span class="hljs-keyword">const</span> time = <span class="hljs-keyword">await</span> tf.time(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> x.matMul(x));

<span class="hljs-built_in">console</span>.log(<span class="hljs-string">`kernelMs: <span class="hljs-subst">${time.kernelMs}</span>, wallTimeMs: <span class="hljs-subst">${time.wallMs}</span>`</span>);
</code></pre>

</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">f</span>
                <span class="param-type">(() =&gt; void)</span>
                <span class="param-docs">The function to execute and time.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="nextFrame" href="#nextFrame">
tf.nextFrame</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/browser_util.ts#L26-L29" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns a promise that resolve when a requestAnimationFrame has completed.</p>
<p>This is simply a sugar method so that users can do the following:
<code>await tf.nextFrame();</code></p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Environment
            </div>
          <div class="description">
             <p>TensorFlow.js can run mathematical operations on
        different backends. Currently, we support WebGL and JavaScript
        CPU. By default, we choose the 'best' backend available, but
        allow users to customize their backend.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Environment / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="setBackend" href="#setBackend">
tf.setBackend</a>
    <span class="signature">(backendType, safeMode?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L65-L71" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Sets the backend (cpu, webgl, etc) responsible for creating tensors and
executing operations on those tensors.</p>
<p>Note this disposes the current backend, if any, as well as any tensors
associated with it.  A new backend is initialized, even if it is of the
same type as the previous one.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">backendType</span>
                <span class="param-type">(string)</span>
                <span class="param-docs">The backend type. Currently supports <code>'webgl'|'cpu'</code> in
              the browser, and <code>'tensorflow'</code> under node.js (requires tfjs-node).</span>
            </li>
            <li class="parameter">
                <span class="param-name">safeMode</span>
                <span class="param-type">(boolean)</span>
                <span class="param-docs">Defaults to false. In safe mode, you are forced to
              construct tensors and call math operations inside a <code>tidy()</code> which
              will automatically clean up intermediate tensors.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="disposeVariables" href="#disposeVariables">
tf.disposeVariables</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L86-L89" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Dispose all variables kept in backend engine.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">void</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="getBackend" href="#getBackend">
tf.getBackend</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/environment.ts#L77-L81" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Returns the current backend (cpu, webgl, etc). The backend is responsible
for creating tensors and executing operations on those tensors.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">string</span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Constraints
            </div>
          <div class="description">
             <p>Constraints are added to attributes
        of a Layer (such as weights, kernels, or biases) at
        construction time to clamp, or otherwise enforce an allowed range,
        of values for different components of the Layer.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Constraints / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="constraints.maxNorm" href="#constraints.maxNorm">
tf.constraints.maxNorm</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L716-L724" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>MaxNorm weight constraint.</p>
<p>Constrains the weights incident to each hidden unit
to have a norm less than or equal to a desired value.</p>
<p>References
- <a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from Overfitting
Srivastava, Hinton, et al.
2014</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">maxValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Maximum norm for incoming weights</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Axis along which to calculate norms.</p>
              <p>For instance, in a <code>Dense</code> layer the weight matrix
              has shape <code>[inputDim, outputDim]</code>,
              set <code>axis</code> to <code>0</code> to constrain each weight vector
              of length <code>[inputDim,]</code>.
              In a <code>Conv2D</code> layer with <code>dataFormat=&quot;channels_last&quot;</code>,
              the weight tensor has shape
              <code>[rows, cols, inputDepth, outputDepth]</code>,
              set <code>axis</code> to <code>[0, 1, 2]</code>
              to constrain the weights of each filter tensor of size
              <code>[rows, cols, inputDepth]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:constraints.Constraint">tf.constraints.Constraint</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="constraints.minMaxNorm" href="#constraints.minMaxNorm">
tf.constraints.minMaxNorm</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L742-L750" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">minValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Minimum norm for incoming weights</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">maxValue</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Maximum norm for incoming weights</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Axis along which to calculate norms.
              For instance, in a <code>Dense</code> layer the weight matrix
              has shape <code>[inputDim, outputDim]</code>,
              set <code>axis</code> to <code>0</code> to constrain each weight vector
              of length <code>[inputDim,]</code>.
              In a <code>Conv2D</code> layer with <code>dataFormat=&quot;channels_last&quot;</code>,
              the weight tensor has shape
              <code>[rows, cols, inputDepth, outputDepth]</code>,
              set <code>axis</code> to <code>[0, 1, 2]</code>
              to constrain the weights of each filter tensor of size
              <code>[rows, cols, inputDepth]</code>.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">rate</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Rate for enforcing the constraint: weights will be rescaled to yield:
              <code>(1 - rate) * norm + rate * norm.clip(minValue, maxValue)</code>.
              Effectively, this means that rate=1.0 stands for strict
              enforcement of the constraint, while rate&lt;1.0 means that
              weights will be rescaled at each step to slowly move
              towards a value inside the desired interval.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:constraints.Constraint">tf.constraints.Constraint</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="constraints.nonNeg" href="#constraints.nonNeg">
tf.constraints.nonNeg</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L736-L740" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constains the weight to be non-negative.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:constraints.Constraint">tf.constraints.Constraint</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="constraints.unitNorm" href="#constraints.unitNorm">
tf.constraints.unitNorm</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L726-L734" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Constrains the weights incident to each hidden unit to have unit norm.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">axis</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Axis along which to calculate norms.</p>
              <p>For instance, in a <code>Dense</code> layer the weight matrix
              has shape <code>[inputDim, outputDim]</code>,
              set <code>axis</code> to <code>0</code> to constrain each weight vector
              of length <code>[inputDim,]</code>.
              In a <code>Conv2D</code> layer with <code>dataFormat=&quot;channels_last&quot;</code>,
              the weight tensor has shape
              [rows, cols, inputDepth, outputDepth]<code>, set</code>axis<code>to</code>[0, 1, 2]<code>to constrain the weights of each filter tensor of size</code>[rows, cols, inputDepth]`.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:constraints.Constraint">tf.constraints.Constraint</a></span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Constraints / Classes
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:constraints.Constraint" href="#class:constraints.Constraint">tf.constraints.Constraint</a>
    <span class="signature">
        <span>extends serialization.Serializable</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/constraints.ts#L32-L39" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Base class for functions that impose constraints on weight values</p>
</div>

  <div class="method-list">
  </div>
</div>
      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Initializers
            </div>
          <div class="description">
             <p>Initializers are used in Layers
        to establish the starting the values of weights, biases, kernels, 
        etc.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Initializers / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.constant" href="#initializers.constant">
tf.initializers.constant</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L769-L778" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates values initialized to some constant.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">value</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">The value for each element in the variable.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.glorotNormal" href="#initializers.glorotNormal">
tf.initializers.glorotNormal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L846-L855" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Glorot normal initializer, also called Xavier normal initializer.
It draws samples from a truncated normal distribution centered on 0
with <code>stddev = sqrt(2 / (fan_in + fan_out))</code>
where <code>fan_in</code> is the number of input units in the weight tensor
and <code>fan_out</code> is the number of output units in the weight tensor.</p>
<p>Reference:
Glorot &amp; Bengio, AISTATS 2010
http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Random number generator seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.glorotUniform" href="#initializers.glorotUniform">
tf.initializers.glorotUniform</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L835-L844" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Glorot uniform initializer, also called Xavier uniform initializer.
It draws samples from a uniform distribution within [-limit, limit]
where <code>limit</code> is <code>sqrt(6 / (fan_in + fan_out))</code>
where <code>fan_in</code> is the number of input units in the weight tensor
and <code>fan_out</code> is the number of output units in the weight tensor</p>
<p>Reference:
Glorot &amp; Bengio, AISTATS 2010
http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Random number generator seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.heNormal" href="#initializers.heNormal">
tf.initializers.heNormal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L857-L866" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>He normal initializer.</p>
<p>It draws samples from a truncated normal distribution centered on 0
with <code>stddev = sqrt(2 / fanIn)</code>
where <code>fanIn</code> is the number of input units in the weight tensor.</p>
<p>Reference:
He et al., http://arxiv.org/abs/1502.01852</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Random number generator seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.identity" href="#initializers.identity">
tf.initializers.identity</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L813-L822" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates the identity matrix.
Only use for square 2D matrices.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">gain</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Multiplicative factor to apply to the identity matrix.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.leCunNormal" href="#initializers.leCunNormal">
tf.initializers.leCunNormal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L868-L877" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>LeCun normal initializer.</p>
<p>It draws samples from a truncated normal distribution centered on 0
with <code>stddev = sqrt(1 / fanIn)</code>
where <code>fanIn</code> is the number of input units in the weight tensor.</p>
<p>References:
<a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>
<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient Backprop</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Random number generator seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.ones" href="#initializers.ones">
tf.initializers.ones</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L763-L767" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates tensors initialized to 1.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.orthogonal" href="#initializers.orthogonal">
tf.initializers.orthogonal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L879-L887" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates a random orthogonal matrix.</p>
<p>Reference:
<a href="http://arxiv.org/abs/1312.6120">Saxe et al., http://arxiv.org/abs/1312.6120</a></p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">gain</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.randomNormal" href="#initializers.randomNormal">
tf.initializers.randomNormal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L791-L800" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates random values initialized to a normal
distribution.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">mean</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Mean of the random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">stddev</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Standard deviation of the random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Used to seed the random generator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.randomUniform" href="#initializers.randomUniform">
tf.initializers.randomUniform</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L780-L789" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates random values initialized to a uniform
distribution.</p>
<p>Values will be distributed uniformly between the configured minval and
maxval.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">minval</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Lower bound of the range of random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">maxval</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Upper bound of the range of random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Used to seed the random generator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.truncatedNormal" href="#initializers.truncatedNormal">
tf.initializers.truncatedNormal</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L802-L811" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates random values initialized to a truncated normal.
distribution.</p>
<p>These values are similar to values from a <code>RandomNormal</code> except that values
more than two standard deviations from the mean are discarded and re-drawn.
This is the recommended initializer for neural network weights and filters.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">mean</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Mean of the random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">stddev</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Standard deviation of the random values to generate.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Used to seed the random generator.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.varianceScaling" href="#initializers.varianceScaling">
tf.initializers.varianceScaling</a>
    <span class="signature">(config)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L824-L833" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer capable of adapting its scale to the shape of weights.
With distribution=NORMAL, samples are drawn from a truncated normal
distribution centered on zero, with <code>stddev = sqrt(scale / n)</code> where n is:</p>
<ul>
<li>number of input units in the weight tensor, if mode = FAN_IN.</li>
<li>number of output units, if mode = FAN_OUT.</li>
<li>average of the numbers of input and output units, if mode = FAN_AVG.
With distribution=UNIFORM,
samples are drawn from a uniform distribution
within [-limit, limit], with <code>limit = sqrt(3 * scale / n)</code>.</li>
</ul>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">scale</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Scaling factor (positive float).</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">mode</span>
                <span class="param-type">('fanIn'|'fanOut'|'fanAvg')</span>
                <span class="param-docs">Fanning mode for inputs and outputs.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">distribution</span>
                <span class="param-type">('normal'|'uniform')</span>
                <span class="param-docs">Probabilistic distribution of the values.</span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">seed</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">Random number generator seed.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:initializers.Initializer">tf.initializers.Initializer</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="initializers.zeros" href="#initializers.zeros">
tf.initializers.zeros</a>
    <span class="signature">()</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L754-L761" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer that generates tensors initialized to 0.</p>
</div>

  
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Zeros</span>
  </div>
</div>

          <div class="subheading">
            <div class="tftitle">
              
                Initializers / Classes
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:initializers.Initializer" href="#class:initializers.Initializer">tf.initializers.Initializer</a>
    <span class="signature">
        <span>extends serialization.Serializable</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/initializers.ts#L41-L58" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Initializer base class.</p>
</div>

  <div class="method-list">
  </div>
</div>
      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Regularizers
            </div>
          <div class="description">
             <p>Regularizers can be attached to various components
        of a Layer to add a 'scoring' function to help drive weights, or 
        other trainable values, away from excessively large values.  They're
        typically used to promote a notion that a 'simpler' model is better
        than a complicated model, assuming equal performance.</p>
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Regularizers / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symbol class">
  <div class="symbol-header">
    <a class="symbol-link" name="class:regularizers.L1L2" href="#class:regularizers.L1L2">tf.regularizers.L1L2</a>
    <span class="signature">
        <span>extends Regularizer</span>
    </span>
    <span class="symbol-marker">class</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/regularizers.ts#L52-L99" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Regularizer for L1 and L2 regularization.</p>
<p>Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x)) + sum(l2 * x^2)</p>
</div>

  <div class="method-list">
  </div>
</div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="regularizers.l1" href="#regularizers.l1">
tf.regularizers.l1</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L988-L996" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Regularizer for L1 and L2 regularization.</p>
<p>Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x)) + sum(l2 * x^2)</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">l1</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">L1 regularization rate. Defaults to 0.01.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Regularizer</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="regularizers.l1l2" href="#regularizers.l1l2">
tf.regularizers.l1l2</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L978-L986" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Regularizer for L1 and L2 regularization.</p>
<p>Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x)) + sum(l2 * x^2)</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">l1</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">L1 regularization rate. Defaults to 0.01.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">l2</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">L2 regularization rate. Defaults to 0.01.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Regularizer</span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="regularizers.l2" href="#regularizers.l2">
tf.regularizers.l2</a>
    <span class="signature">(config?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L998-L1006" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Regularizer for L1 and L2 regularization.</p>
<p>Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x)) + sum(l2 * x^2)</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">config</span>
                <span class="param-type">(Object)</span>
                <span class="param-docs"></span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
            <li class="parameter config-param">
                <span class="param-name">l2</span>
                <span class="param-type">(number)</span>
                <span class="param-docs">L2 regularization rate. Defaults to 0.01.</span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Regularizer</span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Visualization
            </div>
          <div class="description">
             
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Visualization / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="toPixels" href="#toPixels">
tf.toPixels</a>
    <span class="signature">(img, canvas?)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-core/blob/v0.12.0/src/ops/array_ops.ts#L359-L440" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"><p>Draws a <a href="#class:Tensor">tf.Tensor</a> of pixel values to a byte array or optionally a
canvas.</p>
<p>When the dtype of the input is 'float32', we assume values in the range
[0-1]. Otherwise, when input is 'int32', we assume values in the range
[0-255].</p>
<p>Returns a promise that resolves when the canvas has been drawn to.</p>
</div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">img</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor2D</a>|<a href="#class:Tensor">tf.Tensor3D</a>|<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray">TypedArray</a>|Array)</span>
                <span class="param-docs">A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If
              rank-3, must have depth of 1, 3 or 4. When depth of 1, draws
              grayscale. When depth of 3, we draw with the first three components of
              the depth dimension corresponding to r, g, b and alpha = 1. When depth of
              4, all four components of the depth dimension correspond to r, g, b, a.</span>
            </li>
            <li class="parameter">
                <span class="param-name">canvas</span>
                <span class="param-type">(<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement">HTMLCanvasElement</a>)</span>
                <span class="param-docs">The canvas to draw to.</span>
                  <span class="chip">
                    Optional
                  </span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type">Promise</span>
  </div>
</div>

      </div>
      <div class="api-section">
        <div class="heading">
          <div class="tftitle">
              Metrics
            </div>
          <div class="description">
             
          </div>
        </div>
          <div class="subheading">
            <div class="tftitle">
              
                Metrics / 
              
                </div>
            <div class="description">
              
            </div>
          </div>
<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.binaryAccuracy" href="#metrics.binaryAccuracy">
tf.metrics.binaryAccuracy</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L891-L895" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.binaryCrossentropy" href="#metrics.binaryCrossentropy">
tf.metrics.binaryCrossentropy</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L897-L904" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.categoricalAccuracy" href="#metrics.categoricalAccuracy">
tf.metrics.categoricalAccuracy</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L906-L913" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.categoricalCrossentropy" href="#metrics.categoricalCrossentropy">
tf.metrics.categoricalCrossentropy</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L915-L922" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.cosineProximity" href="#metrics.cosineProximity">
tf.metrics.cosineProximity</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L924-L931" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

<div class="symfunction ">
  <div class="symbol-header">
    <a class="symbol-link" name="metrics.meanSquaredError" href="#metrics.meanSquaredError">
tf.metrics.meanSquaredError</a>
    <span class="signature">(yTrue, yPred)</span>
      <span class="symbol-marker">function</span>
    <span class="source-link">
      <a href="https://github.com/tensorflow/tfjs-layers/blob/v0.7.0/src/exports.ts#L959-L966" target=_blank>Source</a>
    </span>
  </div>

  <div class="documentation"></div>

  
  <div class="parameter-list">
    <div class="heading">Parameters:</div>
    <ul>
            <li class="parameter">
                <span class="param-name">yTrue</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
            <li class="parameter">
                <span class="param-name">yPred</span>
                <span class="param-type">(<a href="#class:Tensor">tf.Tensor</a>)</span>
                <span class="param-docs"></span>
            </li>
    </ul>
  </div>
  

  <div class="returns">
    <span class="returns-header">Returns:</span>
    <span class="return-type"><a href="#class:Tensor">tf.Tensor</a></span>
  </div>
</div>

      </div>
  </div>
</div>

    </div>
    <br>
<br>
<br>
<br>

<script>
  $(function() {
    var toc = $('#toc');

    function makeLi(text, href) {
      return $('<a href="' + href + '" target="_self">' + text + '</a><br>');
    }

    $('.tftitle').each(function(i) {
      var chapter = $(this), chapterNumber = i + 1;
      toc.append(
        makeLi(chapter.text(), '#chapter-' + chapterNumber));
      chapter.attr('id', 'chapter-' + chapterNumber);
    });

  });
</script>
</body>
</html>
