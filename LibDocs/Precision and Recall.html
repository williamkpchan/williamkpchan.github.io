<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width"/>
<link rel="stylesheet" href="..\maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script>
$(document).ready(function(){
    $('h1, h2, h3, h4, h5, .goldword, .apply, div.title').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
<style>
body{width:80%;margin-left: 10%}
h1, h2 {color: gold;}
</style>
</head><body>
<center><h1>Beyond Accuracy: Precision and Recall</h1>
<div id="toc"></div></center>
<br>
<br>
<br>


<p name="5739" id="5739" class="graf graf--p graf-after--h3">
	<strong class="markup--strong markup--p-strong">Choosing the right metrics for classification tasks
</strong>
</p>
<p name="5008" id="5008" class="graf graf--p graf-after--p">Would you believe someone who claimed to create a model entirely in their head to identify terrorists trying to board flights with greater than 99% accuracy? Well, here is the model: simply label every single person flying from a US airport as not a terrorist. Given the 
	<a href="https://www.rita.dot.gov/bts/press_releases/bts018_16" data-href="https://www.rita.dot.gov/bts/press_releases/bts018_16" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">800 million average passengers on US flights per year
</a> and the 
<a href="https://en.wikipedia.org/wiki/List_of_aircraft_hijackings#2000s" data-href="https://en.wikipedia.org/wiki/List_of_aircraft_hijackings#2000s" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">19 (confirmed) terrorists who boarded US flights from 2000–2017
</a>, this model achieves an astounding accuracy of 99.9999999%! That might sound impressive, but I have a suspicion the US Department of Homeland Security will not be calling anytime soon to buy this model. While this solution has nearly-perfect accuracy, this problem is one in which accuracy is clearly not an adequate metric!
</p>
<p name="d359" id="d359" class="graf graf--p graf-after--p graf--trailing">The terrorist detection task is an 
	<a href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/" data-href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">imbalanced classification problem
</a>: we have two classes we need to identify — terrorists and not terrorists — with one category representing the overwhelming majority of the data points. Another imbalanced classification problem occurs in disease detection when the rate of the disease in the public is very low. In both these cases the positive class — disease or terrorist — is greatly outnumbered by the negative class. These types of problems are examples of the fairly common case in data science when accuracy is not a good measure for assessing model performance.
</p>
</div>
</div>
</section>
<section name="7608" class="section section--body section--last">
	<div class="section-divider">
	<hr class="section-divider">
</div>
<div class="section-content">
	<div class="section-inner sectionLayout--insetColumn">
	<p name="7c44" id="7c44" class="graf graf--p graf--leading">Intuitively, we know that proclaiming all data points as negative in the terrorist detection problem is not helpful and, instead, we should focus on identifying the positive cases. The metric our intuition tells us we should maximize is known in statistics as 
	<a href="https://en.wikipedia.org/wiki/Precision_and_recall" data-href="https://en.wikipedia.org/wiki/Precision_and_recall" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">
	<strong class="markup--strong markup--p-strong">recall
</strong>
</a>, or the ability of a model to find all the relevant cases within a dataset. The precise definition of recall is the number of true positives divided by the number of true positives plus the number of false negatives. True positives are data point classified as positive by the model that actually are positive (meaning they are correct), and false negatives are data points the model identifies as negative that actually are positive (incorrect). In the terrorism case, true positives are correctly identified terrorists, and false negatives would be individuals the model labels as 
<em class="markup--em markup--p-em">not
</em> terrorists that 
<em class="markup--em markup--p-em">actually were 
</em>terrorists. Recall can be thought as of a model’s ability to find all the data points of interest in a dataset.
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="c976" id="c976" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 64px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 6.4%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*gscG4JdjnyU5QkqNDqBg_w.png" data-width="1703" data-height="109" data-action="zoom" data-action-value="1*gscG4JdjnyU5QkqNDqBg_w.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*gscG4JdjnyU5QkqNDqBg_w.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*gscG4JdjnyU5QkqNDqBg_w.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*gscG4JdjnyU5QkqNDqBg_w.png">
</noscript>
</div>
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="3888" id="3888" class="graf graf--p graf-after--figure">You might notice something about this equation: if we label all individuals as terrorists, then our recall goes to 1.0! We have a perfect classifier right? Well, not exactly. As with most concepts in data science, there is a trade-off in the metrics we choose to maximize. In the case of recall, when we increase the recall, we decrease the precision. Again, we intuitively know that a model that labels 100% of passengers as terrorists is probably not useful because we would then have to ban every single person from flying. Statistics provides us with the vocabulary to express our intuition: this new model would suffer from low 
	<a href="https://en.wikipedia.org/wiki/Precision_and_recall" data-href="https://en.wikipedia.org/wiki/Precision_and_recall" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">
	<strong class="markup--strong markup--p-strong">precision
</strong>
</a>, or the ability of a classification model to identify only the relevant data points.
</p>
<p name="00ef" id="00ef" class="graf graf--p graf-after--p">Precision is defined as the number of true positives divided by the number of true positives plus the number of false positives. False positives are cases the model incorrectly labels as positive that are actually negative, or in our example, individuals the model classifies as terrorists that are not. While recall expresses the ability to find all relevant instances in a dataset, precision expresses the proportion of the data points our model says was relevant actually were relevant.
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="3b8c" id="3b8c" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 62px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 6.2%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*FKXzF6DYSP2mV4HUBftRgg.png" data-width="1752" data-height="108" data-action="zoom" data-action-value="1*FKXzF6DYSP2mV4HUBftRgg.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*FKXzF6DYSP2mV4HUBftRgg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*FKXzF6DYSP2mV4HUBftRgg.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*FKXzF6DYSP2mV4HUBftRgg.png">
</noscript>
</div>
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="f0bc" id="f0bc" class="graf graf--p graf-after--figure">Now, we can see that our first model which labeled all individuals as 
	<em class="markup--em markup--p-em">not 
</em>terrorists wasn’t very useful. Although it had near-perfect accuracy, it had 0 precision and 0 recall because there were no true positives! Say we modify the model slightly, and identify a single individual correctly as a terrorist. Now, our precision will be 1.0 (no false positives) but our recall will be very low because we will still have many false negatives. If we go to the other extreme and classify all passengers as terrorists, we will have a recall of 1.0 — we’ll catch every terrorist — but our precision will be very low and we’ll detain many innocent individuals. In other words, as we increase precision we decrease recall and vice-versa.
</p>
<figure name="6d12" id="6d12" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 583px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 83.2%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="0*XEO3pwAee7tBT_D1.png" data-width="900" data-height="749" data-action="zoom" data-action-value="0*XEO3pwAee7tBT_D1.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/0*XEO3pwAee7tBT_D1.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/0*XEO3pwAee7tBT_D1.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/0*XEO3pwAee7tBT_D1.png">
</noscript>
</div>
</div>
<figcaption class="imageCaption">The Precision-Recall Trade-off (
	<a href="http://computingengineering.asmedigitalcollection.asme.org/article.aspx?articleid=2610217" data-href="http://computingengineering.asmedigitalcollection.asme.org/article.aspx?articleid=2610217" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Source
</a>)
</figcaption>
</figure>
<h3 name="9849" id="9849" class="graf graf--h3 graf-after--figure">Combining Precision and Recall
</h3>
<p name="01fe" id="01fe" class="graf graf--p graf-after--h3">In some situations, we might know that we want to maximize either recall or precision at the expense of the other metric. For example, in preliminary disease screening of patients for follow-up examinations, we would probably want a recall near 1.0 — we want to find all patients who actually have the disease — and we can accept a low precision if the cost of the follow-up examination is not significant. However, in cases where we want to find an optimal blend of precision and recall we can combine the two metrics using what is called the
	<a href="https://en.wikipedia.org/wiki/F1_score" data-href="https://en.wikipedia.org/wiki/F1_score" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> F1 score
</a>.
</p>
<p name="2104" id="2104" class="graf graf--p graf-after--p">The F1 score is the harmonic mean of precision and recall taking both metrics into account in the following equation:
</p>
<figure name="68cc" id="68cc" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 376px; max-height: 127px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 33.800000000000004%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*UJxVqLnbSj42eRhasKeLOA.png" data-width="376" data-height="127">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*UJxVqLnbSj42eRhasKeLOA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*UJxVqLnbSj42eRhasKeLOA.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*UJxVqLnbSj42eRhasKeLOA.png">
</noscript>
</div>
</div>
</figure>
<p name="e5f5" id="e5f5" class="graf graf--p graf-after--figure">We use the 
	<a href="https://stackoverflow.com/questions/26355942/why-is-the-f-measure-a-harmonic-mean-and-not-an-arithmetic-mean-of-the-precision" data-href="https://stackoverflow.com/questions/26355942/why-is-the-f-measure-a-harmonic-mean-and-not-an-arithmetic-mean-of-the-precision" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">harmonic mean instead of a simple average because it punishes extreme values
</a>. A classifier with a precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but an F1 score of 0. The F1 score gives equal weight to both measures and is a specific example of the general Fβ metric where β can be adjusted to give more weight to either recall or precision. (There are other metrics for combining precision and recall, such as the 
<a href="https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index" data-href="https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Geometric Mean of precision and recall
</a>, but the F1 score is the most commonly used.) If we want to create a balanced classification model with the optimal balance of recall and precision, then we try to maximize the F1 score.
</p>
<h3 name="ce9e" id="ce9e" class="graf graf--h3 graf-after--p">Visualizing Precision and Recall
</h3>
<p name="728f" id="728f" class="graf graf--p graf-after--h3">I’ve thrown a couple new terms at you and we’ll walk through an example to show how they are used in practice. Before we can get there though we need to briefly talk about tw concepts used for showing precision and recall.
</p>
<p name="5d18" id="5d18" class="graf graf--p graf-after--p">First up is the 
	<a href="http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/" data-href="http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">confusion matrix
</a> which is useful for quickly calculating precision and recall given the predicted labels from a model. A confusion matrix for binary classification shows the four different outcomes: true positive, false positive, true negative, and false negative. The actual values form the columns, and the predicted values (labels) form the rows. The intersection of the rows and columns show one of the four outcomes. For example, if we predict a data point is positive, but it actually is negative, this is a false positive.
</p>
<figure name="aac0" id="aac0" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 255px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 36.4%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*CPnO_bcdbE8FXTejQiV2dg.png" data-width="797" data-height="290" data-action="zoom" data-action-value="1*CPnO_bcdbE8FXTejQiV2dg.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*CPnO_bcdbE8FXTejQiV2dg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*CPnO_bcdbE8FXTejQiV2dg.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*CPnO_bcdbE8FXTejQiV2dg.png">
</noscript>
</div>
</div>
</figure>
<p name="d93e" id="d93e" class="graf graf--p graf-after--figure">Going from the confusion matrix to the recall and precision requires finding the respective values in the matrix and applying the equations:
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="dc9d" id="dc9d" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 120px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 12%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*6NkN_LINs2erxgVJ9rkpUA.png" data-width="1354" data-height="162" data-action="zoom" data-action-value="1*6NkN_LINs2erxgVJ9rkpUA.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*6NkN_LINs2erxgVJ9rkpUA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*6NkN_LINs2erxgVJ9rkpUA.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*6NkN_LINs2erxgVJ9rkpUA.png">
</noscript>
</div>
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="9fa8" id="9fa8" class="graf graf--p graf-after--figure">The other main visualization technique for showing the performance of a classification model is the 
	<a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html" data-href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Receiver Operating Characteristic (ROC) curve
</a>. Don’t let the complicated name scare you off! The idea is relatively simple: the ROC curve shows how the recall vs precision relationship changes as we vary the threshold for identifying a positive in our model. The threshold represents the value above which a data point is considered in the positive class. If we have a model for identifying a disease, our model might output a score for each patient between 0 and 1 and we can set a threshold in this range for labeling a patient as having the disease (a positive label). By altering the threshold, we can try to achieve the right precision vs recall balance.
</p>
<p name="0616" id="0616" class="graf graf--p graf-after--p">An ROC curve plots the true positive rate on the y-axis versus the false positive rate on the x-axis. The true positive rate (TPR) is the recall and the false positive rate (FPR) is the probability of a false alarm. Both of these can be calculated from the confusion matrix:
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="7270" id="7270" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 111px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 11.1%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*Uh9YUp632ktSd75bZDeB0Q.png" data-width="1202" data-height="134" data-action="zoom" data-action-value="1*Uh9YUp632ktSd75bZDeB0Q.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*Uh9YUp632ktSd75bZDeB0Q.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*Uh9YUp632ktSd75bZDeB0Q.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*Uh9YUp632ktSd75bZDeB0Q.png">
</noscript>
</div>
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="e8f7" id="e8f7" class="graf graf--p graf-after--figure">A typical ROC curve is shown below:
</p>
<figure name="473c" id="473c" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 492px; max-height: 352px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 71.5%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="0*2iHR8dFXev5GWo_f.png" data-width="492" data-height="352">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/0*2iHR8dFXev5GWo_f.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/0*2iHR8dFXev5GWo_f.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/0*2iHR8dFXev5GWo_f.png">
</noscript>
</div>
</div>
<figcaption class="imageCaption">Receiver Operating Characteristic Curve (
	<a href="http://www.statisticshowto.com/c-statistic/" data-href="http://www.statisticshowto.com/c-statistic/" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Source
</a>)
</figcaption>
</figure>
<p name="03c3" id="03c3" class="graf graf--p graf-after--figure">The black diagonal line indicates a random classifier and the red and blue curves show two different classification models. For a given model, we can only stay on one curve, but we can move along the curve by adjusting our threshold for classifying a positive case. Generally, as we decrease the threshold, we move to the right and upwards along the curve. With a threshold of 1.0, we would be in the lower left of the graph because we identify no data points as positives leading to no
	<em class="markup--em markup--p-em"> true positives
</em> and no 
<em class="markup--em markup--p-em">false positives 
</em>(TPR = FPR = 0). As we decrease the threshold, we identify more data points as positive, leading to more true positives, but also more false positives (the TPR and FPR increase). Eventually, at a threshold of 0.0 we identify all data points as positive and find ourselves in the upper right corner of the ROC curve (TPR = FPR = 1.0).
</p>
<p name="0730" id="0730" class="graf graf--p graf-after--p">Finally, we can quantify a model’s ROC curve by calculating the total 
	<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" data-href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Area Under the Curve (AUC)
</a>, a metric which falls between 0 and 1 with a higher number indicating better classification performance. In the graph above, the AUC for the blue curve will be greater than that for the red curve, meaning the blue model is better at achieving a blend of precision and recall. A random classifier (the black line) achieves an AUC of 0.5.
</p>
<h3 name="29f6" id="29f6" class="graf graf--h3 graf-after--p">Recap
</h3>
<p name="747e" id="747e" class="graf graf--p graf-after--h3">We’ve covered a few terms, none of which are difficult on their own, but which combined can be a little overwhelming! Let’s do a quick recap and then walk through an example to solidly the new ideas we learned.
</p>
<p name="1cf2" id="1cf2" class="graf graf--p graf-after--p">
	<strong class="markup--strong markup--p-strong">Four Outcomes of Binary Classification
</strong>
</p>
<ul class="postList">
	<li name="ca12" id="ca12" class="graf graf--li graf-after--p">
	<strong class="markup--strong markup--li-strong">True positives: 
</strong>data points labeled as positive that are actually positive
</li>
<li name="984d" id="984d" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">False positives: 
</strong>data points labeled as positive that are actually negative
</li>
<li name="8fd9" id="8fd9" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">True negatives: 
</strong>data points labeled as negative that are actually negative
</li>
<li name="8903" id="8903" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">False negatives: 
</strong>data points labeled as negative that are actually positive
</li>
</ul>
<p name="da70" id="da70" class="graf graf--p graf-after--li">
	<strong class="markup--strong markup--p-strong">Recall and Precision Metrics
</strong>
</p>
<ul class="postList">
	<li name="a79d" id="a79d" class="graf graf--li graf-after--p">
	<strong class="markup--strong markup--li-strong">Recall:
</strong> ability of a classification model to identify all relevant instances
</li>
<li name="d3b3" id="d3b3" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">Precision: 
</strong>ability of a classification model to return only relevant instances
</li>
<li name="b385" id="b385" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">F1 score:
</strong> single metric that combines recall and precision using the harmonic mean
</li>
</ul>
<p name="3652" id="3652" class="graf graf--p graf-after--li">
	<strong class="markup--strong markup--p-strong">Visualizing Recall and Precision
</strong>
</p>
<ul class="postList">
	<li name="556c" id="556c" class="graf graf--li graf-after--p">
	<strong class="markup--strong markup--li-strong">Confusion matrix: 
</strong>shows the actual and predicted labels from a classification problem
</li>
<li name="ff4c" id="ff4c" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">Receiver operating characteristic (ROC) curve: 
</strong>plots the true positive rate (TPR) versus the false positive rate (FPR) as a function of the model’s threshold for classifying a positive
</li>
<li name="8f81" id="8f81" class="graf graf--li graf-after--li">
	<strong class="markup--strong markup--li-strong">Area under the curve (AUC): 
</strong>metric to calculate the overall performance of a classification model based on area under the ROC curve
</li>
</ul>
<h3 name="a9f0" id="a9f0" class="graf graf--h3 graf-after--li">Example Application
</h3>
<p name="62d4" id="62d4" class="graf graf--p graf-after--h3">Our task will be to diagnose 100 patients with a disease present in 50% of the general population. We will assume a black box model, where we put in information about patients and receive a score between 0 and 1. We can alter the threshold for labeling a patient as positive (has the disease) to maximize the classifier performance. We will evaluate thresholds from 0.0 to 1.0 in increments of 0.1, at each step calculating the precision, recall, F1, and location on the ROC curve. Following are the classification outcomes at each threshold:
</p>
<figure name="bc45" id="bc45" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 411px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 58.699999999999996%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*3SjX3LaLUfJ3Yf7xU1QhmA.png" data-width="1129" data-height="663" data-action="zoom" data-action-value="1*3SjX3LaLUfJ3Yf7xU1QhmA.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*3SjX3LaLUfJ3Yf7xU1QhmA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*3SjX3LaLUfJ3Yf7xU1QhmA.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*3SjX3LaLUfJ3Yf7xU1QhmA.png">
</noscript>
</div>
</div>
<figcaption class="imageCaption">Outcome of model at each threshold
</figcaption>
</figure>
<p name="00ad" id="00ad" class="graf graf--p graf-after--figure">We’ll do one sample calculation of the recall, precision, true positive rate, and false positive rate at athreshold of 0.5. First we make the confusion matrix:
</p>
<figure name="a52d" id="a52d" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 99px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 14.099999999999998%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*gdLd_wAhNfJKH49NSfq72Q.png" data-width="899" data-height="127" data-action="zoom" data-action-value="1*gdLd_wAhNfJKH49NSfq72Q.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*gdLd_wAhNfJKH49NSfq72Q.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*gdLd_wAhNfJKH49NSfq72Q.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*gdLd_wAhNfJKH49NSfq72Q.png">
</noscript>
</div>
</div>
<figcaption class="imageCaption">Confusion Matrix for Threshold of 0.5
</figcaption>
</figure>
<p name="87d9" id="87d9" class="graf graf--p graf-after--figure">We can use the numbers in the matrix to calculate the recall, precision, and F1 score:
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="df71" id="df71" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 52px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 5.2%;">
</div>
<img class="graf-image" data-image-id="1*XQOYd2mheHyVVR9H-ENtIQ.png" data-width="1601" data-height="84" data-action="zoom" data-action-value="1*XQOYd2mheHyVVR9H-ENtIQ.png" src="https://cdn-images-1.medium.com/max/1000/1*XQOYd2mheHyVVR9H-ENtIQ.png">
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="3340" id="3340" class="graf graf--p graf-after--figure">Then we calculate the true positive and false positive rate to find the y and x coordinates for the ROC curve.
</p>
</div>
<div class="section-inner sectionLayout--outsetColumn">
	<figure name="b733" id="b733" class="graf graf--figure graf--layoutOutsetCenter graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 85px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 8.5%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*HzWxvbikCtiB-QtFb48WoQ.png" data-width="1511" data-height="128" data-action="zoom" data-action-value="1*HzWxvbikCtiB-QtFb48WoQ.png">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*HzWxvbikCtiB-QtFb48WoQ.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*HzWxvbikCtiB-QtFb48WoQ.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*HzWxvbikCtiB-QtFb48WoQ.png">
</noscript>
</div>
</div>
</figure>
</div>
<div class="section-inner sectionLayout--insetColumn">
	<p name="72e4" id="72e4" class="graf graf--p graf-after--figure">To make the entire ROC curve, we carry out this process at each threshold. As you might think, this is pretty tedious, so instead of doing it by hand, we use a language like Python to do it for us! The 
	<a href="https://github.com/WillKoehrsen/Data-Analysis/blob/master/recall_precision/recall_precision_example.ipynb" data-href="https://github.com/WillKoehrsen/Data-Analysis/blob/master/recall_precision/recall_precision_example.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Jupyter Notebook
</a> with the calculations is on GitHub for anyone to see the implementation. The final ROC curve is shown below with the thresholds above the points.
</p>
<figure name="dca6" id="dca6" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 617px; max-height: 506px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 82%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*ZAH33g5FD9xYZRadgmqWVw.png" data-width="617" data-height="506">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*ZAH33g5FD9xYZRadgmqWVw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*ZAH33g5FD9xYZRadgmqWVw.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*ZAH33g5FD9xYZRadgmqWVw.png">
</noscript>
</div>
</div>
</figure>
<p name="211c" id="211c" class="graf graf--p graf-after--figure">Here we can see all the concepts come together! At a threshold of 1.0, we classify no patients as having the disease and hence have a recall and precision of 0.0. As the threshold decreases, the recall increases because we identify more patients that have the disease. However, as our recall increases, our precision decreases because in addition to increasing the 
	<em class="markup--em markup--p-em">true 
</em>positives, we increase the 
<em class="markup--em markup--p-em">false 
</em>positives. At a threshold of 0.0, our recall is perfect — we find all patients with the disease — but our precision is low because we have many false positives. We can move along the curve for a given model by changing the threshold and select the threshold that maximizes the F1 score. To shift the entire curve, we would need to build a different model.
</p>
<p name="8ef5" id="8ef5" class="graf graf--p graf-after--p">Final model statistics at each threshold are below:
</p>
<figure name="5efa" id="5efa" class="graf graf--figure graf-after--p">
	<div class="aspectRatioPlaceholder is-locked" style="max-width: 588px; max-height: 514px;">
	<div class="aspectRatioPlaceholder-fill" style="padding-bottom: 87.4%;">
</div>
<div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*TESjAFBurN7RVXyb5KDOxg.png" data-width="588" data-height="514">
	<img src="https://cdn-images-1.medium.com/freeze/max/30/1*TESjAFBurN7RVXyb5KDOxg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail">
<canvas class="progressiveMedia-canvas js-progressiveMedia-canvas">
</canvas>
<img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*TESjAFBurN7RVXyb5KDOxg.png">
<noscript class="js-progressiveMedia-inner">
	<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*TESjAFBurN7RVXyb5KDOxg.png">
</noscript>
</div>
</div>
</figure>
<p name="4639" id="4639" class="graf graf--p graf-after--figure">Based on the F1 score, the overall best model occurs at a threshold of 0.5. If we wanted to emphasize precision or recall to a greater extent, we could choose the corresponding model that performs best on those measures.
</p>
<h3 name="e11e" id="e11e" class="graf graf--h3 graf-after--p">Conclusions
</h3>
<p name="1b15" id="1b15" class="graf graf--p graf-after--h3">We tend to use accuracy because everyone has an idea of what it means rather than because it is the best tool for the task! Although better-suited metrics such as recall and precision may seem foreign, we already have an intuitive sense of why they work better for some problems such as imbalanced classification tasks. Statistics provides us with the formal definitions and the equations to calculate these measures. 
	<a href="https://www.datacamp.com/community/podcast/data-science-astronomy" data-href="https://www.datacamp.com/community/podcast/data-science-astronomy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Data science
</a> is about knowing the right tools to use for a job, and often we need to go beyond accuracy when developing classification models. Knowing about recall, precision, F1, and the ROC curve allows us to assess classification models and should make us think skeptically about anyone touting only the accuracy of a model, especially for imbalanced problems. As we have seen, accuracy does not provide a useful assessment on several crucial problems, but now we know how to employ smarter metrics!
</p>
<br>
<br>
<br>
<br>

<script>
  $(function() {
    var toc = $('#toc');

    function makeLi(text, href) {
      return $('<a href="' + href + '" target="_self">' + text + '</a><br>');
    }

    $('h2').each(function(i) {
      var chapter = $(this), chapterNumber = i + 1;
      toc.append(
        makeLi(chapter.text(), '#chapter-' + chapterNumber)
      );
      chapter.attr('id', 'chapter-' + chapterNumber);
    });

  });
</script>
</body>
</html>
