
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="content-language" content="zh-CN">

<base target=_blank><style>body { margin: 10%; font-size: 24px; background-color: #000000; color: #109030;}a { text-decoration: none; color: #28B8B8;}a:visited { color: #389898;}A:hover { color: yellow;}A:focus { color: red;}code { color: pink; background-color: #001500}pre { color: gray; background-color: #001010}.redrose { color: #cc0099} .redword { color: red} .yellowword { color: yellow} .greenword { color: lightgreen} .limeword { color: .00ff00} .orangeword { color: orange} .cyanword { color: cyan} .whiteword { color: white} .grayword { color: gray} .brownword { color: #ff8000} .yellowgreen { color: #bfff00} .palered { color: #ffcccc} .blueword { color: dodgerblue} .purpleword { color: darkorchid} .goldword { color: GoldenRod} .silverword { color: silver} </style>
</head><body>

<h3 class='post-title entry-title' itemprop='name'>
Machine Learning. Linear Regression Full Example (Boston Housing).
</h3>


<br />

We will develop a linear regression example, including simple
 linear regression, multiple linear regression, linear regression with 
term interaction, linear regression with higher order terms, and finally
 with a transformation.
<br />

The example we will develop is about predicting the median house value on the Boston Housing dataset. <br />

<br />


We will carry out the exercise verbatim as published in the aforementioned reference and only with slight changes in the coding style.<br />

<br />

For more details on the models, algorithms and parameters interpretation, it is recommended to check the aforementioned reference or any other bibliography of your choice.<br />

<br />

<br />
<br />
### install and load required packages
<br />
#install.packages("ISLR")<br />
#install.packages("car")<br />
<br />
library(ISLR)<br />
library(car)<br />
&nbsp;<br />

### MASS library contains the Boston dataset 
<br />
library(MASS)<br />
<br />
### explore dataset
<br />
#fix(Boston)<br />
str(Boston)<br />
summary(Boston)<br />
names(Boston)<br />
<br />
### we will seek to predict target: medv (median house value)<br />
	### using 13 predictors<br />
<br />
### we will start with $medv as target and $lstat as predictor<br />
### create the model
<br />
lm.fit &lt;- lm(medv~lstat, data=Boston)<br />
<br />
	### explore the model parameters
	<br />
lm.fit<br />
summary(lm.fit)<br />
names(lm.fit)<br />
coef(lm.fit)<br />
<br />
	### explore confidence interval for the coefficient estimates
	<br />
confint(lm.fit)<br />
<br />
### use predict() to produce confidence intervals and prediction<br />
	### intervals for the prediction of $medv for a given value of<br />
### $lstat
<br />
predict (lm.fit , data.frame(lstat = c(5 ,10 ,15) ),<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; interval = "confidence")<br />
predict (lm.fit , data.frame(lstat = c(5 ,10 ,15) ),<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; interval = "prediction")<br />
&nbsp;<br />

### 95% confidence interval associated with $lstat=10 is<br />
	### (24.47, 25.63)<br />
### 95% prediction interval is (12.828, 37.28)<br />
### center around a predicted value of 25.05 for $medv when<br />
### $lstat = 10<br />
<br />
### now plot $medv and lstat along with least squares regression<br />
### line
<br />
plot(Boston$lstat , Boston$medv, main="Boston Housing Data",<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; xlab="Percent of households with low<br />
&nbsp;&nbsp;&nbsp;&nbsp; socioeconomic status", ylab= "Median house value")<br />
<br />
abline(lm.fit, col = "red", lwd = 3)<br />

<br />

<br />

<div class="separator" style="clear: both; text-align: center;">
<a href="https://2.bp.blogspot.com/-unPiJifdOP0/WRX_5-HLzkI/AAAAAAAAC-8/_k5kCdsV-_MVRVKybFGhpOgxa-wDY8pSQCLcB/s1600/housing_1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="265" src="https://2.bp.blogspot.com/-unPiJifdOP0/WRX_5-HLzkI/AAAAAAAAC-8/_k5kCdsV-_MVRVKybFGhpOgxa-wDY8pSQCLcB/s400/housing_1.png" width="400"></a></div>
<br />

<br />

<br />
### explore some diagnostic plots
<br />
par(mfrow = c(2, 2))<br />
plot(lm.fit)<br />
<br />
plot(predict(lm.fit), residuals(lm.fit))<br />
plot(predict(lm.fit), rstudent(lm.fit))<br />

<div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-ihmZgswShfM/WRYABxpagfI/AAAAAAAAC_A/FL6g3zYnUx41Tq7ZlFSv8TU9ICsLdW8eQCLcB/s1600/housing_2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="356" src="https://3.bp.blogspot.com/-ihmZgswShfM/WRYABxpagfI/AAAAAAAAC_A/FL6g3zYnUx41Tq7ZlFSv8TU9ICsLdW8eQCLcB/s400/housing_2.png" width="400"></a></div>
<br />
&nbsp;
<br />

### leverage statistics hatvalues()
<br />
plot(hatvalues(lm.fit))<br />
which.max(hatvalues(lm.fit))<br />

<br />

<div class="separator" style="clear: both; text-align: center;">
<a href="https://1.bp.blogspot.com/-8c1vhQ9ZUnY/WRYAKuEedJI/AAAAAAAAC_E/vIp2Lgecre8-3n5sO9E6IxVbTGxkM045ACLcB/s1600/housing_3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="356" src="https://1.bp.blogspot.com/-8c1vhQ9ZUnY/WRYAKuEedJI/AAAAAAAAC_E/vIp2Lgecre8-3n5sO9E6IxVbTGxkM045ACLcB/s400/housing_3.png" width="400"></a></div>
<br />

### multiple linear regression<br />
	### two predictors
	<br />
lm.fit &lt;- lm(medv ~ lstat + age , data = Boston)<br />
summary(lm.fit)<br />
<br />
### all 13 predictors
<br />
lm.fit &lt;- lm(medv ~. , data = Boston)<br />
summary(lm.fit)<br />
<br />
### R^2
<br />
summary(lm.fit)$r.sq<br />
### RSE
<br />
summary(lm.fit)$sigma<br />
<br />
	### use vif() to compute variance inflation factors<br />
### vif is part of car library
<br />
vif(lm.fit)<br />
<br />
	### in the last regression $age has a high p-value<br />
### run regression using all predictors but one: $age
<br />
lm.fit1 &lt;- lm(medv ~. -age, data = Boston)<br />
summary(lm.fit1)<br />
<br />
### interaction terms
<br />
summary(lm(medv ~ lstat*age , data = Boston ))<br />
<br />
	### non-linear transformation of the predictors
	<br />
lm.fit2 &lt;- lm(medv ~lstat + I(lstat ^2), data = Boston)<br />
summary(lm.fit2)<br />
<br />
### a near cero p-value associated with the quadratic term<br />
	### leads to an improved model
	<br />
<br />
### use anova() to further quantify the extent to which quadratic<br />
	### fit is superior to the linear fit
	<br />
lm.fit &lt;- lm(medv ~ lstat, data = Boston)<br />
anova(lm.fit, lm.fit2)<br />
<br />
### null hypothesis is that the two models fit data equally well<br />
	### alternative hypothesis is that the full model is superior<br />
### F-statistic is 135 and p-value ~ 0 is clear evidence&nbsp;
<br />

### that model containing the predictors lstat and lstat^2<br />
	### is far superior<br />
### we saw in the above plots evidence of nonlinearity
<br />
<br />
<br />
	### now use higher order polynomials with poly()
	<br />
lm.fit5 = lm(medv ~ poly(lstat, 5), data = Boston)<br />
summary(lm.fit5)<br />
<br />
	### additional polynomial terms leads to an improvement in the<br />
### model fit<br />
<br />
### now try a log transformation for $rm
<br />
summary (lm(medv ~ log(rm) , data = Boston ) )<br />

<br />

<br />


</body>
</html>