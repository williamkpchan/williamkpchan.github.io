<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width"/>
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script type='text/javascript' src='../mainscript.js'></script>

<script>
$(document).ready(function(){
    $('h1, h2, h3, h4, h5, .goldword, strong,  div.title').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
<style>
body{width:60%;margin-left: 20%; font-size:22px;}
strong, h1, h2 {color: gold;}
img {width:90%; display: inline-block; margin-top: 2%;margin-bottom: 1%;}
</style>
</head>
<body onkeypress="chkKey()">
<center><h1>Text Mining in Python: Steps and Examples</h1>
<div id="toc"></div></center>
<br>
<br>
<br>
<pre>

In today’s scenario, one way of people’s success identified by how they are communicating and sharing information to others. 
That’s where the concepts of language come into picture. 
However, there are many languages in the world. 
Each has many standards and alphabets, and the combination of these words arranged meaningfully resulted in the formation of a sentence. 
Each language has its own rules while developing these sentences and these set of rules are also known as grammar.

<img src="https://miro.medium.com/max/3534/1*iZbht7SBvznG6p3jWJUPJQ.png">

In today’s world, according to the industry estimates, only 20 percent of the data is being generated in the structured format as we speak, as we tweet, as we send messages on WhatsApp, Email, Facebook, Instagram or any text messages. 
And, the majority of this data exists in the textual form which is highly unstructured format. 
In order to produce meaningful insights from the text data then we need to follow a method called Text Analysis.
<h2>What is Text Mining?</h2><blockquote><strong>Text Mining is the process of deriving meaningful information from natural language text.</strong>
</blockquote>

<img src="https://miro.medium.com/max/2900/1*KNTY9V9VyT3qs4hm2GPLdg.png">
</blockquote>In other words, NLP is a component of text mining that performs a special kind of linguistic analysis that essentially <strong>helps a machine “read” text</strong>. 
It uses a different methodology to<strong> decipher the ambiguities in human language</strong>, including the following: automatic summarization, part-of-speech tagging, disambiguation, chunking, as well as disambiguation and natural language understanding and recognition. 
We will see all the processes in step by step manner using Python.

<img src="https://miro.medium.com/max/1000/1*cXlPOwhc6A3Skp9GQ1gVFQ.png">First, we need to install the NLTK library that is the natural language toolkit for building Python programs to work with human language data and it also provides easy to use interface.
<h2>Terminologies in NLP</h2>
<h3>Tokenization</h3>Tokenization is the first step in NLP. 
It is the process of breaking strings into tokens which in turn are small structures or units. 
Tokenization involves three steps which are breaking a complex sentence into words, understanding the importance of each word with respect to the sentence and finally produce structural description on an input sentence.

<h3><strong>Code:</strong></h3><pre><span># Importing necessary library<br/>import pandas as pd<br/>import numpy as np<br/>import nltk<br/>import os<br/>import nltk.corpus</span><span># sample text for performing tokenization<br/>text = “In Brazil they drive on the right-hand side of the road. 
Brazil has a large coastline on the eastern<br/>side of South America&quot;</span><span># importing word_tokenize from nltk<br/>from nltk.tokenize import word_tokenize</span><span># Passing the string text into word tokenize for breaking the sentences<br/>token = word_tokenize(text)<br/>token</span></pre>
<h3>Output</h3><pre><span>[&#x27;In&#x27;,&#x27;Brazil&#x27;,&#x27;they&#x27;,&#x27;drive&#x27;, &#x27;on&#x27;,&#x27;the&#x27;, &#x27;right-hand&#x27;, &#x27;side&#x27;, &#x27;of&#x27;, &#x27;the&#x27;, &#x27;road&#x27;, &#x27;.&#x27;, &#x27;Brazil&#x27;, &#x27;has&#x27;, &#x27;a&#x27;, &#x27;large&#x27;, &#x27;coastline&#x27;, &#x27;on&#x27;, &#x27;the&#x27;, &#x27;eastern&#x27;, &#x27;side&#x27;, &#x27;of&#x27;, &#x27;South&#x27;, &#x27;America&#x27;]</span></pre>From the above output, we can see the text split into tokens. 
Words, comma, punctuations are called tokens.
<h2>Finding frequency distinct in the text</h2>
<h3>Code 1</h3><pre><span># finding the frequency distinct in the tokens<br/># Importing FreqDist library from nltk and passing token into FreqDist<br/>from nltk.probability import FreqDist<br/>fdist = FreqDist(token)<br/>fdist</span></pre>
<h3>Output</h3><pre><span>FreqDist({&#x27;the&#x27;: 3, &#x27;Brazil&#x27;: 2, &#x27;on&#x27;: 2, &#x27;side&#x27;: 2, &#x27;of&#x27;: 2, &#x27;In&#x27;: 1, &#x27;they&#x27;: 1, &#x27;drive&#x27;: 1, &#x27;right-hand&#x27;: 1, &#x27;road&#x27;: 1, ...})</span></pre>‘the’ is found 3 times in the text, ‘Brazil’ is found 2 times in the text etc.

<h3>Code 2</h3><pre><span># To find the frequency of top 10 words<br/>fdist1 = fdist.most_common(10)<br/>fdist1</span></pre>
<h3>Output</h3><pre><span>[(&#x27;the&#x27;, 3),<br/> (&#x27;Brazil&#x27;, 2),<br/> (&#x27;on&#x27;, 2),<br/> (&#x27;side&#x27;, 2),<br/> (&#x27;of&#x27;, 2),<br/> (&#x27;In&#x27;, 1),<br/> (&#x27;they&#x27;, 1),<br/> (&#x27;drive&#x27;, 1),<br/> (&#x27;right-hand&#x27;, 1),<br/> (&#x27;road&#x27;, 1)]</span></pre><h2>Stemming</h2><blockquote>Stemming usually refers to normalizing words into its base form or root form.
</blockquote>


<img src="https://miro.medium.com/max/546/0*TIYLCwlI6rundRHb">Here, we have words waited, waiting and waits. 
Here the root word is ‘wait’. 
There are two methods in Stemming namely, Porter Stemming (removes common morphological and inflectional endings from words) and Lancaster Stemming (a more aggressive stemming algorithm).

<h3>Code 1</h3><pre><span># Importing Porterstemmer from nltk library<br/># Checking for the word ‘giving’ <br/>from nltk.stem import PorterStemmer<br/>pst = PorterStemmer()<br/>pst.stem(“waiting”)</span></pre>
<h3>Output</h3><pre><span>&#x27;wait&#x27;</span></pre>
<h3>Code 2</h3><pre><span># Checking for the list of words<br/>stm = [&quot;waited&quot;, &quot;waiting&quot;, &quot;waits&quot;]<br/>for word in stm :<br/>   print(word+ &quot;:&quot; +pst.stem(word))</span></pre>
<h3>Output</h3><pre><span>waited:wait<br/>waiting:wait<br/>waits:wait</span></pre>
<h3>Code 3</h3><pre><span># Importing LancasterStemmer from nltk<br/>from nltk.stem import LancasterStemmer<br/>lst = LancasterStemmer()<br/>stm = [“giving”, “given”, “given”, “gave”]<br/>for word in stm :<br/> print(word+ “:” +lst.stem(word))</span></pre>
<h3>Output</h3><pre><span>giving:giv<br/>given:giv<br/>given:giv<br/>gave:gav</span></pre>Lancaster is more aggressive than Porter stemmer
<h2>Lemmatization</h2>

<img src="https://miro.medium.com/max/2502/1*Kt9AbfaCIHCG2QjBckRVLg.png">
For example, lemmatization would correctly identify the base form of ‘caring’ to ‘care’, whereas, stemming would cutoff the ‘ing’ part and convert it to car.
Lemmatization can be implemented in python by using Wordnet Lemmatizer, Spacy Lemmatizer, TextBlob, Stanford CoreNLP

<h3>Code</h3><pre><span># Importing Lemmatizer library from nltk<br/>from nltk.stem import WordNetLemmatizer<br/>lemmatizer = WordNetLemmatizer() <br/> <br/>print(“rocks :”, lemmatizer.lemmatize(“rocks”)) <br/>print(“corpora :”, lemmatizer.lemmatize(“corpora”))</span></pre>
<h3>Output</h3><pre><span>rocks : rock<br/>corpora : corpus</span></pre><h2>Stop Words</h2>“Stop words” are the most common words in a language like “the”, “a”, “at”, “for”, “above”, “on”, “is”, “all”. 
These words do not provide any meaning and are usually removed from texts. 
We can remove these stop words using nltk library

<h3>Code</h3><pre><span># importing stopwors from nltk library<br/>from nltk import word_tokenize<br/>from nltk.corpus import stopwords<br/>a = set(stopwords.words(‘english’))</span><span>text = “Cristiano Ronaldo was born on February 5, 1985, in Funchal, Madeira, Portugal.”<br/>text1 = word_tokenize(text.lower())<br/>print(text1)</span><span>stopwords = [x for x in text1 if x not in a]<br/>print(stopwords)</span></pre>
<h3>Output</h3><pre><span>Output of text:<br/>[&#x27;cristiano&#x27;, &#x27;ronaldo&#x27;, &#x27;was&#x27;, &#x27;born&#x27;, &#x27;on&#x27;, &#x27;february&#x27;, &#x27;5&#x27;, &#x27;,&#x27;, &#x27;1985&#x27;, &#x27;,&#x27;, &#x27;in&#x27;, &#x27;funchal&#x27;, &#x27;,&#x27;, &#x27;madeira&#x27;, &#x27;,&#x27;, &#x27;portugal&#x27;, &#x27;.&#x27;]</span><span>Output of stopwords:<br/>[&#x27;cristiano&#x27;, &#x27;ronaldo&#x27;, &#x27;born&#x27;, &#x27;february&#x27;, &#x27;5&#x27;, &#x27;,&#x27;, &#x27;1985&#x27;, &#x27;,&#x27;, &#x27;funchal&#x27;, &#x27;,&#x27;, &#x27;madeira&#x27;, &#x27;,&#x27;, &#x27;portugal&#x27;, &#x27;.&#x27;]</span></pre><h2>Part of speech tagging (POS)</h2>

<img src="https://miro.medium.com/max/1688/1*JRej3tXz1qjoW_ZFSpfJNQ.png">Part-of-speech tagging is used to assign parts of speech to each word of a given text (such as nouns, verbs, pronouns, adverb, conjunction, adjectives, interjection) based on its definition and its context. 
There are many tools available for POS taggers and some of the widely used taggers are NLTK, Spacy, TextBlob, Standford CoreNLP etc.

<h3>Code</h3><pre><span>text = “vote to choose a particular man or a group (party) to represent them in parliament”<br/>#Tokenize the text<br/>tex = word_tokenize(text)<br/>for token in tex:<br/>print(nltk.pos_tag([token]))</span></pre>
<h3>Output</h3><pre><span>[(&#x27;vote&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;to&#x27;, &#x27;TO&#x27;)]<br/>[(&#x27;choose&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;a&#x27;, &#x27;DT&#x27;)]<br/>[(&#x27;particular&#x27;, &#x27;JJ&#x27;)]<br/>[(&#x27;man&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;or&#x27;, &#x27;CC&#x27;)]<br/>[(&#x27;a&#x27;, &#x27;DT&#x27;)]<br/>[(&#x27;group&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;(&#x27;, &#x27;(&#x27;)]<br/>[(&#x27;party&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;)&#x27;, &#x27;)&#x27;)]<br/>[(&#x27;to&#x27;, &#x27;TO&#x27;)]<br/>[(&#x27;represent&#x27;, &#x27;NN&#x27;)]<br/>[(&#x27;them&#x27;, &#x27;PRP&#x27;)]<br/>[(&#x27;in&#x27;, &#x27;IN&#x27;)]<br/>[(&#x27;parliament&#x27;, &#x27;NN&#x27;)]</span></pre><h2>Named entity recognition</h2>It is the process of detecting the named entities such as the person name, the location name, the company name, the quantities and the monetary value.

<img src="https://miro.medium.com/max/1054/1*jdt9-0S1lJm-caVKXNdyfQ.png"

<h3>Code</h3><pre><span>text = “Google’s CEO Sundar Pichai introduced the new Pixel at Minnesota Roi Centre Event”</span><span>#importing chunk library from nltk<br/>from nltk import ne_chunk</span><span># tokenize and POS Tagging before doing chunk<br/>token = word_tokenize(text)<br/>tags = nltk.pos_tag(token)<br/>chunk = ne_chunk(tags)<br/>chunk</span></pre>
<h3><strong>Output</strong></h3><pre><span>Tree(&#x27;S&#x27;, [Tree(&#x27;GPE&#x27;, [(&#x27;Google&#x27;, &#x27;NNP&#x27;)]), (&quot;&#x27;s&quot;, &#x27;POS&#x27;), Tree(&#x27;ORGANIZATION&#x27;, [(&#x27;CEO&#x27;, &#x27;NNP&#x27;), (&#x27;Sundar&#x27;, &#x27;NNP&#x27;), (&#x27;Pichai&#x27;, &#x27;NNP&#x27;)]), (&#x27;introduced&#x27;, &#x27;VBD&#x27;), (&#x27;the&#x27;, &#x27;DT&#x27;), (&#x27;new&#x27;, &#x27;JJ&#x27;), (&#x27;Pixel&#x27;, &#x27;NNP&#x27;), (&#x27;at&#x27;, &#x27;IN&#x27;), Tree(&#x27;ORGANIZATION&#x27;, [(&#x27;Minnesota&#x27;, &#x27;NNP&#x27;), (&#x27;Roi&#x27;, &#x27;NNP&#x27;), (&#x27;Centre&#x27;, &#x27;NNP&#x27;)]), (&#x27;Event&#x27;, &#x27;NNP&#x27;)])</span></pre><h2>Chunking</h2>Chunking means picking up individual pieces of information and grouping them into bigger pieces. 
In the context of NLP and text mining, chunking means grouping of words or tokens into chunks.


<img src="https://miro.medium.com/max/3950/0*0sID7SOM5aDE6Lwq.png">
<h3>Code</h3><pre><span>text = “We saw the yellow dog”<br/>token = word_tokenize(text)<br/>tags = nltk.pos_tag(token)</span><span>reg = “NP: {&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;}” <br/>a = nltk.RegexpParser(reg)<br/>result = a.parse(tags)<br/>print(result)</span></pre>
<h3>Output</h3><pre><span>(S We/PRP saw/VBD (NP the/DT yellow/JJ dog/NN))</span></pre>This blog summarizes text preprocessing and covers the NLTK steps including Tokenization, Stemming, Lemmatization, POS tagging, Named entity recognition and Chunking.
Thanks for reading. 
Keep learning and stay tuned for more!

<h3>Reference:</h3><ol class=""><li><a href="https://www.expertsystem.com/natural-language-processing-and-text-mining/" target="_blank" rel="noopener nofollow">https://www.expertsystem.com/natural-language-processing-and-text-mining/</a></li><li><a href="https://www.nltk.org" target="_blank" rel="noopener nofollow">https://www.nltk.org</a></li><li><a href="https://www.geeksforgeeks.org/nlp-chunk-tree-to-text-and-chaining-chunk-transformation/" target="_blank" rel="noopener nofollow">https://www.edureka.co</a></li><li><a href="https://www.geeksforgeeks.org/nlp-chunk-tree-to-text-and-chaining-chunk-transformation/" target="_blank" rel="noopener nofollow">https://www.geeksforgeeks.org/nlp-chunk-tree-to-text-and-chaining-chunk-transformation/</a></li><li><a href="https://www.learntek.org/blog/categorizing-pos-tagging-nltk-python/" target="_blank" rel="noopener nofollow">https://www.geeksforgeeks.org/part-speech-tagging-stop-words-using-nltk-python/</a></li></ol>
<br>
<br>
<br>
<br>

<script>
	var toc = $('#toc');
	$('h2').each(function(i) {
		var topic = $(this), topicNumber = i + 1;
		toc.append('<a href="#topic-'+topicNumber+'" target="_self">'+topic.text()+'</a><br>');
		topic.attr('id', 'topic-' + topicNumber);
	});
</script>

</body>
</html>
