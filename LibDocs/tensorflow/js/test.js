//[31012.922, 31188.932, 31332.42, 31521.129, 31435.262, 31134.029, 31242.861, 31023.73, 30777.959, 30519.289, 30012.039, 29944.301, 29882.27, 29436.838, 29403.359, 29034.23, 28988.828, 28567.289, 28962.291, 28616.998, 28642.34, 28320.898, 28554.211, 28821.539, 28981.93, 28365.721, 28614.531, 28715.359, 28699.209, 28460.871, 28386.381, 28329.98, 28294.738, 28391.58, 28718, 28964.791, 29083.398, 28816.691, 28839.238, 28682.311, 28772.801, 28218.279, 27786.15, 28074.531, 28266.682, 28473.479, 28728.17, 28665.9, 28085.172, 27946.551, 27727.27, 27405.252, 27450.842, 27609.799, 27771.299, 27954.521, 28051.65, 27830.908, 28289.059, 28579.641],
//[30743.182, 30896.109, 31161.369, 31369.279, 30874.1, 30898.57, 30944.969, 30688.26, 30349.959, 30259.111, 29332.281, 29406.201, 29285.709, 29089.389, 28895.398, 28505.092, 28342.818, 28169.102, 28463.85, 27990.451, 28141.279, 27830.748, 27925.332, 28518.521, 28682.25, 28013.721, 28217.309, 28500.51, 28327.002, 28137.949, 28045.469, 27998.361, 27745.85, 28091.059, 28282.301, 28764.35, 28625.082, 28572.791, 28539.559, 28538.029, 28219.971, 27578.09, 27604.561, 27730.42, 27843.162, 28224.461, 28192.811, 28296.988, 27823.209, 27522.818, 27249.082, 26871.111, 27101.102, 27209.219, 27526.301, 27579.801, 27659.209, 27532.061, 27956.039, 28293.158],
//[30997.98, 31093.449, 31259.102, 31512.631, 30958.211, 31063.699, 31103.059, 30725.148, 30440.17, 30309.49, 29468.15, 29696.17, 29296.051, 29338.701, 28961.389, 28881.402, 28356.26, 28497.318, 28955.111, 28545.57, 28241.67, 28182.09, 28315.619, 28688.5, 28682.25, 28311.689, 28480.828, 28525.439, 28539.66, 28181.68, 28117.42, 28010.861, 28224.48, 28256.121, 28662.57, 28920.898, 28781.139, 28804.281, 28733.129, 28583.012, 28340.738, 27714.561, 27676.32, 27819.559, 28248.881, 28359.139, 28607.299, 28366.621, 27936.57, 27752.932, 27323.59, 27100.061, 27213.412, 27598.02, 27752.791, 27927.58, 27790.461, 27671.869, 28271.27, 28350.1]

const trainY = [31012.922, 31188.932, 31332.42, 31521.129, 31435.262, 31134.029, 31242.861, 31023.73, 30777.959, 30519.289, 30012.039, 29944.301, 29882.27, 29436.838, 29403.359, 29034.23, 28988.828, 28567.289, 28962.291, 28616.998, 28642.34, 28320.898, 28554.211, 28821.539, 28981.93, 28365.721, 28614.531, 28715.359, 28699.209, 28460.871, 28386.381, 28329.98, 28294.738, 28391.58, 28718, 28964.791, 29083.398, 28816.691, 28839.238, 28682.311, 28772.801, 28218.279, 27786.15, 28074.531, 28266.682, 28473.479, 28728.17, 28665.9, 28085.172, 27946.551, 27727.27, 27405.252, 27450.842, 27609.799, 27771.299, 27954.521, 28051.65, 27830.908, 28289.059, 28579.641];
const trainX = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60];

const m = tf.variable(tf.scalar(Math.random()));
const b = tf.variable(tf.scalar(Math.random()));

function predict(x) { return tf.tidy(function() { return m.mul(x).add(b); });}
function loss(prediction, labels) { return prediction.sub(labels).square().mean();}

function train() {
  const learningRate = 0.001;
  const optimizer = tf.train.sgd(learningRate);

  optimizer.minimize(function() {
	const predsYs = predict(tf.tensor1d(trainX));
	stepLoss = loss(predsYs, tf.tensor1d(trainY));
	themsg = "the error is " + stepLoss.dataSync()[0] +"&emsp;"+ " m = " + m.dataSync()[0] +"&emsp;"+ " b = " + b.dataSync()[0] + "<br>"
	+ "the endpoint is x: "+ trainX[trainX.length-1] + "&emsp;"+"y: " +(trainY[trainX.length-1] * m.dataSync()[0] + b.dataSync()[0]) + "<br><br>"
	$("#report").prepend(themsg);
	return stepLoss;
	plot(); 
  });
}
