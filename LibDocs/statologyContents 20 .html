<base target="_blank"><html><head><title>statologyContents 20</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://williamkpchan.github.io/lazyload.min.js"></script>
<script src='https://williamkpchan.github.io/mainscript.js'></script>
<script src="https://williamkpchan.github.io/commonfunctions.js"></script>
<script>
  var showTopicNumber = true;
  var topicEnd = "<br>";
  var bookid = "statologyContents 20"
  var markerName = "h2, h3"
</script>
<style>
body{width:70%;margin-left: 15%; font-size:20px;}
h1, h2 {color: gold;}
strong {color: orange;}
b {color: brown;}
img {max-width:60%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>statologyContents 20</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a><br><br>
<div id="toc"></div></center><br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br></div>
<pre><br><br>
<h2><span class="orange">Triangular Distribution Calculator</span></h2>
The <b> triangular distribution </b> is a continuous probability distribution with a probability density function shaped like a triangle. It is defined by three values: the minimum value <i>a</i>, the maximum value <i>b</i>, and the peak value <i>c</i>.
This calculator finds the probability for a given value of x, as well as the mean, median, mode, and variance of the distribution.
Simply fill in the values below, then click the “Calculate” button.
<label for="a"><b>Minimum value (a)</b></label>
<input type="number" id="a" value="2">
<label for="b"><b>Maximum value (b)</b></label>
<input type="number" id="b" value="8">
<label for="c"><b>Peak value (c)</b></label>
<input type="number" id="c" value="6">
<label for="x"><b>Random variable value (x)</b></label>
<input type="number" id="x" value="4">
<input type="button" id="button_calc" onclick="calc()" value="Calculate">
P(x): <b>0.16667</b>
Mean: <b>5.33333</b>
Median: <b>5.46410</b>
Mode: <b>6.00000</b>
Variance: <b>1.55556</b>
<script>
function calc() {
//get input values and calculate WHIP
var a = document.getElementById('a').value*1;
var b = document.getElementById('b').value*1;
var c = document.getElementById('c').value*1;
var x = document.getElementById('x').value*1;
//find stuff
var pdf = jStat.triangular.pdf( x, a, b, c );
var mean = jStat.triangular.mean( a, b, c );
var median = jStat.triangular.median( a, b, c );
var mode = jStat.triangular.mode( a, b, c );
var variance = jStat.triangular.variance( a, b, c );
//output
document.getElementById('pdf').innerHTML = pdf.toFixed(5);
document.getElementById('mean').innerHTML = mean.toFixed(5);
document.getElementById('median').innerHTML = median.toFixed(5);
document.getElementById('mode').innerHTML = mode.toFixed(5);
document.getElementById('variance').innerHTML = variance.toFixed(5);
}
</script>
<h2><span class="orange">How to Use the Triangular Distribution in Excel (With Examples)</span></h2>
The  triangular distribution  is a continuous probability distribution with a probability density function shaped like a triangle.
It is defined by three values:
The minimum value <em>a</em>
The maximum value <em>b</em>
The peak value <em>c</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular1-1.png">
The name of the distribution comes from the fact that the probability density function is shaped like a triangle.
The triangular distribution has the following  PDF and CDF :
<b>PDF:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular3.png">
<b>CDF:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/trianglular4.png">
The following examples show how to use the Triangular distribution to calculate probabilities in Excel.
<h3>Example 1: Restaurant Sales</h3>
Suppose a restaurant estimates that their total sales for the upcoming week will be a minimum of $10,000, a maximum of $30,000, and most likely $25,000.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular2.png">
<b>What is the probability that the restaurant makes less than $20,000 total sales?</b>
According to the CDF, we can use the following formula to find the probability that total sales will be less than $20,000:
P(X &lt; x) = (x-a)<sup>2</sup> / ((b-a)(c-a))
Here’s how to calculate this probability in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/triangleExcel1.png">
The probability that the restaurant makes less than $20,000 total sales is <b>.333</b>.
<h3>Example 2: Number of Customers</h3>
Suppose a shop estimates that the number of customers that will enter in a given week will be a minimum of 500, a maximum of 2,000, and most likely 1,200.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/triangleExcel2.png">
<b>What is the probability that more than 1,500 customers enter the shop in a given week?</b>
According to the CDF, we can use the following formula to find the probability that the total number of customers will be greater than 1,500:
P(X > x) = 1 – [1 – (b-x)<sup>2</sup> / ((b-a)(b-c))]
Here’s how to calculate this probability in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/triangleExcel3.png">
The probability that more than 1,500 customers enter the shop is <b>.208.</b>
<h2><span class="orange">How to Use the Triangular Distribution in R (With Examples)</span></h2>
The  triangular distribution  is a continuous probability distribution with a probability density function shaped like a triangle.
It is defined by three values:
The minimum value <em>a</em>
The maximum value <em>b</em>
The peak value <em>c</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular1-1.png">
To calculate probabilities for the triangular distribution in R we can use the <b>ptri(</b>) function from the <b>EnvStats</b> package, which uses the following syntax:
<b>ptri(q, min = 0, max = 1, mode = 1/2)</b>
where:
<b>q</b>: Quantile of interest
<b>min</b>: The minimum value of the distribution
<b>max</b>: The maximum value of the distribution
<b>mode</b>: The peak value of the distribution
The following examples show how to use this function in practice in R.
<h3>Example 1: Calculating Probability Less Than Some Value</h3>
Suppose a restaurant estimates that their total sales for the upcoming week will be a minimum of $10,000, a maximum of $30,000, and most likely $25,000.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular2.png">
<b>What is the probability that the restaurant makes less than $20,000 total sales?</b>
We can use the following code to calculate this probability:
<b>library(EnvStats)
#calculate probability
ptri(q = 20000, min = 10000, max = 30000, mode = 25000)
[1] 0.3333333</b>
The probability that the restaurant makes less than $20,000 total sales is <b>.333</b>.
<h3>
<b>Example 2: Calculating Probability Greater Than Some Value</b>
</h3>
Suppose a shop estimates that the number of customers that will enter in a given week will be a minimum of 500, a maximum of 2,000, and most likely 1,200.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/triangleExcel2.png">
<b>What is the probability that more than 1,500 customers enter the shop in a given week?</b>
We can use the following code to calculate this probability:
<b>library(EnvStats)
#calculate probability
1 - ptri(q = 1500, min = 500, max = 2000, mode = 1200)
[1] 0.2083333
</b>
The probability that more than 1,500 customers enter the shop is about <b>.208.</b>
<b>Note</b>: You can find the complete documentation for the <b>ptri()</b> function  here .
<h2><span class="orange">An Introduction to the Triangular Distribution</span></h2>
The <b>triangular distribution</b> is a continuous probability distribution with a probability density function shaped like a triangle.
It is defined by three values:
The minimum value <em>a</em>
The maximum value <em>b</em>
The peak value <em>c</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular1-1.png">
The name of the distribution comes from the fact that the probability density function is shaped like a triangle.
It turns out that this distribution is extremely useful in the real world because we can often estimate the minimum value (a), the maximum value (b), and the most likely value (c) that a  random variable  will take on, so we can often model the behavior of random variables by using a triangular distribution with the knowledge of just these three values.
For example, a restaurant might estimate that their total sales for the upcoming week will be a minimum of $10,000, a maximum of $30,000, and most likely $25,000.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular2.png">
Using just these three numbers, they could use a triangular distribution to find the probability that they’ll achieve a certain number of sales.
<h3>Properties of the Triangular Distribution</h3>
The triangular distribution has the following properties:
<b>PDF:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular3.png">
<b>CDF:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/trianglular4.png">
<b>Mean:</b> (a + b + c) / 3
<b>Mode:</b> c
<b>Variance:</b> (a<sup>2</sup> + b<sup>2</sup> + c<sup>2</sup> – ab – ac – bc) / 18
<h3>Example of Using the Triangular Distribution</h3>
Let’s return to the example from earlier. Suppose a restaurant estimates that their total sales for the upcoming week will be a minimum of $10,000, a maximum of $30,000, and most likely $25,000.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/trianglular2.png">
<b>What is the probability that the restaurant makes less than $20,000 total sales?</b>
To answer this, we can let x = total sales. We know that x is between the minimum value <em>a</em> of $10k and the peak value <em>c</em> of $25k.
Thus, according to the PDF we can use the following equation to find the probability that the restaurant makes less than $20,000 total sales:
P(X &lt; $20,000) = (x-a)<sup>2</sup> / ((b-a)(c-a))
P(X &lt; $20,000) = (20,000-10,000)<sup>2</sup> / ((30,000-10,000)(25,000-10,000))
P(X &lt; $20,000) = .333
The probability that the restaurant makes less than $20,000 total sales is <b>.333</b>.
<b>What is the mean expected sales for the restaurant?</b>
We can calculate the mean expected sales using the formula for the mean given earlier:
Mean = (a + b + c) / 3
Mean = ($10,000 + $30,000 + $25,000) / 3
Mean = $21,667
The mean expected sales is <b>21,667</b>.
<h2><span class="orange">Trimmed Mean Calculator</span></h2>
A <b>trimmed mean</b> is the mean of a dataset that has been calculated after removing a specific percentage of the smallest and largest values from the dataset.
To find the trimmed mean of a dataset, simply enter a list of the comma-separated values for the dataset along with the percentage of values to trim, then click the “Calculate” button:
<b>Dataset values:</b>
<textarea id="x" rows="5" cols="40">14, 15, 15, 17, 22, 23, 23, 24, 25, 25, 26, 30, 31, 31, 32, 33, 34, 36, 38, 41</textarea>
<b>Trimmed Mean Percentage (%):</b>
<input type="number" id="perc" value="20">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>Trimmed Mean: 27.0833</b>
<script>
function calc() {
var x = document.getElementById('x').value.split(',').map(Number);
var perc = +document.getElementById('perc').value; 
var g = Math.round(perc/100*x.length);
x.sort(function(a, b){return a - b});
x.splice(0,g);
x.splice(x.length-g, g);
var mean = jStat(x).mean();
//output results
document.getElementById('mean').innerHTML = mean.toFixed(4);
  
} //end calc function
</script>
<h2><span class="orange">How to Calculate a Trimmed Mean in Excel</span></h2>
A <b>trimmed mean</b> is the mean of a dataset that has been calculated after removing a specific percentage of the smallest and largest values from the dataset.
For example, a 10% trimmed mean would represent the mean of a dataset after the 10% of values from the extremities of the dataset have been removed.
To calculate a trimmed mean in Excel you can use the <b>TRIMMEAN</b> function, which uses the following basic syntax:
<b>TRIMMEAN(array, percent)</b>
where:
<b>array</b>: Range containing the dataset
<b>percent</b>: Percent of data to exclude (between 0 and 1)
The following example shows how to use this function to calculate a trimmed mean in practice.
<h2>Example: Calculate Trimmed Mean in Excel</h2>
Suppose we have the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/trim2.jpg"477">
We can use the following formula to calculate a 10% trimmed mean for this dataset:
<b>TRIMMEAN(A2:A21, 0.1)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/trim3.jpg"513">
The 10% trimmed mean of the dataset is <b>7.61</b>.
In this particular dataset there are 20 total values. Thus, 10% of 20 is 2.
So, to calculate a 10% trimmed mean in this example Excel must remove two values from the extremities of the dataset.
This means Excel removed the one smallest value (2) and one largest value (15) from the dataset and then calculated the mean.
We can confirm the formula is correct by manually calculating this trimmed mean ourselves:
10% Trimmed Mean: (2+3+3+4+5+6+7+7+7+7+8+8+9+10+11+12+14+14) / 18 = <b>7.61</b>.
Note that in this particular example, the values that were removed from the extremities were clearly not outliers.
However, a trimmed mean is most useful in practice when there are extreme outliers in the dataset and you’d like to calculate the mean value without allowing these outliers to  influence the calculation .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate Conditional Mean in Excel 
 How to Calculate the Standard Error of the Mean in Excel 
 How to Calculate Mean Absolute Percentage Error (MAPE) in Excel 
<h2><span class="orange">How to Calculate a Trimmed Mean in Google Sheets</span></h2>
A <b>trimmed mean</b> is the mean of a dataset that has been calculated after removing a specific percentage of the smallest and largest values from the dataset.
For example, a 10% trimmed mean would represent the mean of a dataset after the 10% of values from the extremities of the dataset have been removed.
To calculate a trimmed mean in Google Sheets you can use the <b>TRIMMEAN</b> function, which uses the following basic syntax:
<b>TRIMMEAN(data, exclude_proportion)</b>
where:
<b>data</b>: Range containing the dataset
<b>exclude_proportion</b>: Proportion of data to exclude (between 0 and 1)
The following example shows how to use this function to calculate a trimmed mean in practice.
<h2>Example: Calculate Trimmed Mean in Google Sheets</h2>
Suppose we have the following dataset in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/histbins1.jpg"447">
We can use the following formula to calculate a 10% trimmed mean for this dataset:
<b>TRIMMEAN(A2:A21, 0.1)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/trim1.jpg"462">
The 10% trimmed mean of the dataset is <b>7.61</b>.
In this particular example, there are 20 total values in the dataset. Thus, 10% of 20 is 2.
So, to calculate a 10% trimmed mean in this example, Google Sheets needs to remove two values from the extremities of the dataset.
This means Google Sheets removed the one smallest value (2) and one largest value (15) from the dataset and then calculated the mean.
We can confirm the formula is correct by manually calculating this trimmed mean ourselves:
10% Trimmed Mean: (2+3+3+4+5+6+7+7+7+7+8+8+9+10+11+12+14+14) / 18 = <b>7.61</b>.
Note that in this particular example, the values that were removed from the extremities were clearly not outliers.
However, a trimmed mean is most useful in practice when there are extreme outliers in the dataset and you’d like to calculate the mean value without allowing these outliers to  influence the calculation .
<h2>Additional Resources</h2>
The following tutorials provide additional information about trimmed means:
 How to Calculate a Trimmed Mean by Hand 
 How to Calculate a Trimmed Mean in Python 
 Trimmed Mean Calculator 
<h2><span class="orange">How to Calculate a Trimmed Mean in Python (With Examples)</span></h2>
A <b>trimmed mean</b> is the mean of a dataset that has been calculated after removing a specific percentage of the smallest and largest values from the dataset.
The easiest way to calculate a trimmed mean in Python is to use the <b>trim_mean()</b> function from the SciPy library.
This function uses the following basic syntax:
<b>from scipy import stats
#calculate 10% trimmed mean
stats.trim_mean(data, 0.1)
</b>
The following examples show how to use this function to calculate a trimmed mean in practice.
<h3>Example 1: Calculate Trimmed Mean of Array</h3>
The following code shows how to calculate a 10% trimmed mean for an array of data:
<b>from scipy import stats
#define data
data = [22, 25, 29, 11, 14, 18, 13, 13, 17, 11, 8, 8, 7, 12, 15, 6, 8, 7, 9, 12]
#calculate 10% trimmed mean
stats.trim_mean(data, 0.1)
12.375
</b>
The 10% trimmed mean is <b>12.375</b>.
This is the mean of the dataset after the smallest 10% and largest 10% of values have been removed from the dataset.
<h3>Example 2: Calculate Trimmed Mean of Column in Pandas</h3>
The following code shows how to calculate a 5% trimmed mean for a specific column in a pandas DataFrame:
<b>from scipy import stats
import pandas as pd
#define DataFrame
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#calculate 5% trimmed mean of points
stats.trim_mean(df.points, 0.05) 
20.25</b>
The 5% trimmed mean of the values in the ‘points’ column is <b>20.25</b>.
This is the mean of the ‘points’ column after the smallest 5% and largest 5% of values have been removed.
<h3>Example 3: Calculate Trimmed Mean of Multiple Columns</h3>
The following code shows how to calculate a 5% trimmed mean for multiple columns in a pandas DataFrame:
<b>from scipy import stats
import pandas as pd
#define DataFrame
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#calculate 5% trimmed mean of 'points' and 'assists' columns
stats.trim_mean(df[['points', 'assists']], 0.05)
array([20.25,  7.75])
</b>
From the output we can see:
The 5% trimmed mean of the ‘points’ column is <b>20.25</b>.
The 5% trimmed mean of the ‘assists’ column is <b>7.75</b>.
<b>Note</b>: You can find the complete documentation for the <b>trim_mean()</b> function  here .
<h2><span class="orange">How to Calculate a Trimmed Mean in R (With Examples)</span></h2>
A <b>trimmed mean</b> is the mean of a dataset that has been calculated after removing a specific percentage of the smallest and largest values from the dataset.
For example, a 10% trimmed mean would represent the mean of a dataset after the 10% smallest values and 10% largest values have been removed.
The easiest way to calculate a trimmed mean in R is to use the following basic syntax:
<b>#calculate 10% trimmed mean
mean(x, trim=0.1)
</b>
The following examples show how to use this function to calculate a trimmed mean in practice.
<h3>Example 1: Calculate Trimmed Mean of Vector</h3>
The following code shows how to calculate a 10% trimmed mean for a vector of data:
<b>#define data
data = c(22, 25, 29, 11, 14, 18, 13, 13, 17, 11, 8, 8, 7, 12, 15, 6, 8, 7, 9, 12)
#calculate 10% trimmed mean
mean(data, trim=0.1)
[1] 12.375
</b>
The 10% trimmed mean is <b>12.375</b>.
This is the mean of the dataset after the smallest 10% and largest 10% of values have been removed from the dataset.
<h3>Example 2: Calculate Trimmed Mean of Column in Data Frame</h3>
The following code shows how to calculate a 5% trimmed mean for a specific column in a data frame:
<b>#create data frame
df = data.frame(points=c(25, 12, 15, 14, 19, 23, 25, 29),
                assists=c(5, 7, 7, 9, 12, 9, 9, 4),
                rebounds=c(11, 8, 10, 6, 6, 5, 9, 12))
#calculate 5% trimmed mean of points
mean(df$points, trim=0.05)
[1] 20.25
</b>
The 5% trimmed mean of the values in the ‘points’ column is <b>20.25</b>.
This is the mean of the ‘points’ column after the smallest 5% and largest 5% of values have been removed.
<h3>Example 3: Calculate Trimmed Mean of Multiple Columns</h3>
The following code shows how to calculate a 5% trimmed mean for multiple columns in a data frame:
<b>#create data frame
df = data.frame(points=c(25, 12, 15, 14, 19, 23, 25, 29),
                assists=c(5, 7, 7, 9, 12, 9, 9, 4),
                rebounds=c(11, 8, 10, 6, 6, 5, 9, 12))
#calculate 5% trimmed mean of points and assists
sapply(df[c('points', 'assists')], function(x) mean(x, trim=0.05))
 points assists 
  20.25    7.75 
</b>
From the output we can see:
The 5% trimmed mean of the ‘points’ column is <b>20.25</b>.
The 5% trimmed mean of the ‘assists’ column is <b>7.75</b>.
<b>Related:</b>  A Guide to apply(), lapply(), sapply(), and tapply() in R 
<h2>Additional Resources</h2>
The following tutorials provide additional information about trimmed means:
 How to Calculate a Trimmed Mean by Hand 
 How to Calculate a Trimmed Mean in Python 
 Trimmed Mean Calculator 
<h2><span class="orange">Truncated & Censored Data: Definition + Examples</span></h2>
Often when collecting data, researchers may decide to <b>censor</b> or <b>truncate</b> certain values.
To <b>censor</b> data values means to only collect partial information about values that fall below or above a certain value.
For example, we may know that an individual earns less than $25,000 per year but we may not know their exact annual income.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/censor1.png">
To <b>truncate</b> data values means to remove values from a dataset that fall below or above a certain value.
For example, a researcher may only be interested in studying individuals who earn more than $25,000 per year. Thus, any individuals who earn less than $25,000 are simply removed from the dataset.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/censor2.png">
This tutorial provides several examples of when data may be either censored or truncated.
<h3>Censoring Data</h3>
To <b>censor</b> data values means to only collect partial information about values that fall below or above a certain value.
The following examples illustrate scenarios where we may decide to censor data values.
<b>Example 1: Annual Income</b>
Suppose a researcher is collecting survey data about annual income. If an individual earns less than $25,000 per year he decides to report this income as “&lt;$25,000” in a database rather than specifying their exact annual income.
This represents an example of censoring data because we know that an individual earns less than a certain amount but we don’t know their <em>exact</em> annual income.
<b>Example 2: Pollution Levels</b>
Suppose a biologist uses a certain tool to measure the pollution levels in different bodies of water. Her tool is incapable of measuring pollution below .002 parts per million. Thus, any body of water that has pollution levels below this threshold will simply be reported as “&lt;.002” rather than the exact amount.
This represents an example of censoring data because we know that certain bodies of water have pollution levels below .002 parts per million, but we don’t know their <em>exact</em> pollution levels.
<h3>Truncating Data</h3>
To <b>truncate</b> data values means to remove values from a dataset that fall below or above a certain value.
The following examples illustrate scenarios where we may decide to truncate data values.
<b>Example 1: Number of Crimes</b>
Suppose a law enforcement officer is researching the types of of crimes committed by individuals in a certain area. By default, any individual who has committed 0 crimes will not be included in the dataset because they haven’t committed any type of crime.
This represents an example of truncating data because any individual who has committed 0 crimes is simply excluded from the dataset entirely.
<b>Example 2: Education Level</b>
Suppose a professor wants to study the relationship between a certain study program and student achievement.
Because of the intensity of the study program, the professor only wants to monitor students who currently have a GPA greater than 3.5. Thus, any student who applies to the program but has a GPA less than  3.5 will simply not be included in the program
This represents an example of truncating data because any individual who has a GPA below a certain threshold is simply excluded from the dataset.
<h3>Summary</h3>
To <b>censor</b> data means to only collect partial information about data values and to <b>truncate</b> data means to remove data values from a dataset entirely.
Both censoring and truncating lead to loss of information in a dataset, but truncating results in greater information loss because it involves excluding certain data values entirely.
<h2><span class="orange">How to Perform a Tukey-Kramer Post Hoc Test in Excel</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
The  hypotheses  used in an ANOVA are as follows:
The null hypothesis (H<sub>0</sub>): μ<sub>1</sub> = μ<sub>2</sub> = μ<sub>3 </sub>= … = μ<sub>k  </sub>(the means are equal for each group)
The alternative hypothesis: (Ha): at least one of the means is different from the others
If the  p-value  from the ANOVA is less than the significance level, we can reject the null hypothesis and conclude that we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal. In order to find out exactly which groups are different from each other, we must conduct a post hoc test. 
The most commonly used post hoc test is the <b>Tukey-Kramer test</b>, which compares the mean between each pairwise combination of groups.
The following example shows how to perform the Tukey-Kramer test in Excel.
<h3>Example: Tukey-Kramer Test in Excel</h3>
Suppose we perform a one-way ANOVA on three groups: A, B, and C. The results of the one-way ANOVA are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel1.png">
<b>Related: </b> How to Perform a One-Way ANOVA in Excel 
The p-value from the ANOVA table is <b>0.000588</b>. Since this p-value is less than .05, we can reject the null hypothesis and conclude that the means between the three groups are <em>not </em>equal.
To determine exactly <em>which </em>group means are different, we can perform a Tukey-Kramer post hoc test using the following steps:
<b>Step 1: Find the absolute mean difference between each group.</b>
First, we’ll find the absolute mean difference between each group using the averages listed in the first table of the ANOVA output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel2.png">
<b>Step 2: Find the Q critical value.</b>
Next, we need to find the Q critical value using the following formula:
Q critical value = Q*√(s<sup>2</sup><sub>pooled</sub> / n.)
where:
<b>Q </b>= Value from Studentized Range Q Table
<b>s<sup>2</sup><sub>pooled</sub> = </b>Pooled variance across all groups
<b>n. </b> = Sample size for a given group
To find the Q value, you can refer to the Studentized Range Q Table which looks like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel3.png">
In our example, k = the number of groups, which is k = 3. The degrees of freedom is calculated as n-k = 30 – 3 = 27. Since 27 is not shown in the table above, we can use a conservative estimate of 24. Based on k = 3 and df = 24, we find that Q = <b>3.53</b>.
The pooled variance can be calculated as the average of the variances for the groups, which turns out to be <b>19.056</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel4.png">
Lastly, the sample size of each group is 10.
Thus, our Q critical value can be calculated as:
Q critical value = Q*√(s<sup>2</sup><sub>pooled</sub> / n.) =  3.53*√(19.056/10)  = <b>4.87</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel5.png">
<b>Step 3: Determine which group means are different</b>.
Lastly, we can compare the absolute mean difference between each group to the Q critical value. If the absolute mean difference is larger than the Q critical value, then the difference between the group means is statistically significant:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/tukeyexcel6.png">
Based on the Tukey-Kramer post hoc test, we found the following:
The difference in means between group A and group B is statistically significant.
The difference in means between group B and group C is <em>not </em>statistically significant.
The difference in means between group A and group C is statistically significant.
<h2><span class="orange">How to Perform Tukey’s Test in Python</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
If the overall  p-value  from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal. In order to find out exactly which groups are different from each other, we must conduct a  post hoc test .
One of the most commonly used post hoc tests is <b>Tukey’s Test</b>, which allows us to make pairwise comparisons between the means of each group while controlling for the  family-wise error rate .
This tutorial provides a step-by-step example of how to perform Tukey’s Test in Python.
<h3>Step 1: Load Necessary Packages and Functions</h3>
First, we’ll load the necessary packages and functions in Python:
<b>import pandas as pd
import numpy as np
from scipy.stats import f_oneway
from statsmodels.stats.multicomp import pairwise_tukeyhsd</b>
<h3>Step 2: Fit the ANOVA Model</h3>
The following code shows how to create a fake dataset with three groups (A, B, and C) and fit a one-way ANOVA model to the data to determine if the mean values for each group are equal:
<b>#enter data for three groups
a = [85, 86, 88, 75, 78, 94, 98, 79, 71, 80]
b = [91, 92, 93, 90, 97, 94, 82, 88, 95, 96]
c = [79, 78, 88, 94, 92, 85, 83, 85, 82, 81]
#perform one-way ANOVA
f_oneway(a, b, c)
F_onewayResult(statistic=5.167774552944481, pvalue=0.012582197136592609)</b>
We can see that the overall p-value from the ANOVA table is <b>0.01258</b>.
Since this is less than .05, we have sufficient evidence to say that the mean values across each group are not equal.
Thus, we can proceed to perform Tukey’s Test to determine exactly which group means are different.
<h3>Step 3: Perform Tukey’s Test</h3>
To perform Tukey’s test in Python, we can use the <b>pairwise_tukeyhsd()</b> function from the <b>statsmodels</b> library:
<b>#create DataFrame to hold data
df = pd.DataFrame({'score': [85, 86, 88, 75, 78, 94, 98, 79, 71, 80,             91, 92, 93, 90, 97, 94, 82, 88, 95, 96,             79, 78, 88, 94, 92, 85, 83, 85, 82, 81],   'group': np.repeat(['a', 'b', 'c'], repeats=10)}) 
# perform Tukey's test
tukey = pairwise_tukeyhsd(endog=df['score'],          groups=df['group'],          alpha=0.05)
#display results
print(tukey)
 Multiple Comparison of Means - Tukey HSD, FWER=0.05 
=====================================================
group1 group2 meandiff p-adj   lower    upper  reject
-----------------------------------------------------
     a      b      8.4 0.0158   1.4272 15.3728   True
     a      c      1.3 0.8864  -5.6728  8.2728  False
     b      c     -7.1 0.0453 -14.0728 -0.1272   True
-----------------------------------------------------</b>
Here’s how to interpret the output:
P-value for the difference in means between a and b: <b>.0158</b>
P-value for the difference in means between a and c: <b>.8864</b>
P-value for the difference in means between b and c: <b>.0453</b>
Thus, we would conclude that there is a  statistically significant  difference between the means of groups <em>a</em> and <em>b</em> and groups <em>b</em> and <em>c</em>, but not a statistically significant difference between the means of groups <em>a</em> and <em>c</em>.
<h2><span class="orange">How to Perform Tukey’s Test in R</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
If the overall  p-value  from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal. In order to find out exactly which groups are different from each other, we must conduct a  post hoc test .
One of the most commonly used post hoc tests is <b>Tukey’s Test</b>, which allows us to make pairwise comparisons between the means of each group while controlling for the  family-wise error rate .
This tutorial explains how to perform Tukey’s Test in R.
<em><b>Note: </b>If one of the groups in your study is considered a control group, you should instead use  Dunnett’s Test  as the post-hoc test.</em>
<h3>Example: Tukey’s Test in R</h3>
<b>Step 1: Fit the ANOVA Model.</b>
The following code shows how to create a fake dataset with three groups (A, B, and C) and fit a one-way ANOVA model to the data to determine if the mean values for each group are equal:
<b>#make this example reproducible
set.seed(0)
#create data
data &lt;- data.frame(group = rep(c("A", "B", "C"), each = 30),   values = c(runif(30, 0, 3),                   runif(30, 0, 5),                   runif(30, 1, 7)))
#view first six rows of data
head(data)
  group     values
1     A  2.6900916
2     A  0.7965260
3     A  1.1163717
4     A  1.7185601
5     A  2.7246234
6     A  0.6050458
#fit one-way ANOVA model
model &lt;- aov(values~group, data=data)
#view the model output
summary(model)
            Df Sum Sq Mean Sq F value   Pr(>F)    
group        2  98.93   49.46   30.83 7.55e-11 ***
Residuals   87 139.57    1.60                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</b>
We can see that the overall p-value from the ANOVA table is <b>7.55e-11</b>. Since this is less than .05, we have sufficient evidence to say that the mean values across each group are not equal. Thus, we can proceed to perform Tukey’s Test to determine exactly which group means are different.
<b>Step 2: Perform Tukey’s Test.</b>
The following code shows how to use the <b>TukeyHSD() </b>function to perform Tukey’s Test:
<b>#perform Tukey's Test
TukeyHSD(model, conf.level=.95) 
  Tukey multiple comparisons of means
    95% family-wise confidence level
Fit: aov(formula = values ~ group, data = data)
$group
         diff       lwr      upr     p adj
B-A 0.9777414 0.1979466 1.757536 0.0100545
C-A 2.5454024 1.7656076 3.325197 0.0000000
C-B 1.5676610 0.7878662 2.347456 0.0000199
</b>
The p-value indicates whether or not there is a statistically significant difference between each program. We can see from the output that there is a statistically significant difference between the mean weight loss of each program at the 0.05 significance level.
In particular:
P-value for the difference in means between B and A: <b>.0100545</b>
P-value for the difference in means between C and A: <b>.0000000</b>
P-value for the difference in means between C and B: <b>.0000199</b>
<b>Step 3: Visualize the results.</b>
We can use the <b>plot(TukeyHSD())</b> function to visualize the confidence intervals as well:
<b>#plot confidence intervals
plot(TukeyHSD(model, conf.level=.95), las = 2)
</b>
<em>Note: The <b>las </b>argument specifies that the tick mark labels should be perpendicular (las=2) to the axis.</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/tukey1.png">
We can see that none of the confidence intervals for the mean value between groups contain the value zero, which indicates that there is a statistically significant difference in mean loss between all three groups. This is consistent with the fact that all of the p-values from our hypothesis tests are below 0.05.
For this particular example, we can conclude the following:
The mean values of group C are significantly higher than the mean values of both group A and B.
The mean values of group B are significantly higher than the mean values of group A.
<h2><span class="orange">Tukey vs. Bonferroni vs. Scheffe: Which Test Should You Use?</span></h2>
A  one-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.
If the overall  p-value  from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal.
In order to find out exactly which groups are different from each other, we must conduct a  post-hoc test  that is capable of controlling the  family-wise error rate .
Three of the most commonly used post-hoc tests include:
The Tukey Method
The Scheffe Method
The Bonferroni Method
This tutorial provides an overview of each method along with instructions on which post-hoc test to use depending on the situation.
<h3>The Tukey Method</h3>
The Tukey post-hoc test should be used when you would like to make pairwise comparisons between group means when the sample sizes for each group are equal.
If the sample sizes are <em>not</em> equal, you can use a modified version of the test known as the Tukey-Kramer test.
<em>The term “pairwise” means we only want to compare two group means at a time.</em>
For example, suppose we have three groups – A, B, C.
The Tukey post-hoc test would allow us to make the following pairwise comparisons:
μ<sub>A</sub> = μ<sub>B</sub>
μ<sub>A</sub> = μ<sub>C</sub>
μ<sub>B</sub> = μ<sub>C</sub>
Note that for <em>k</em> groups, there are a total of <em>k</em>(<em>k</em>-1)/2 possible pairwise comparisons.
<h3>The Scheffe Method</h3>
The Scheffe post-hoc test should be used when you would like to make <em>all</em> possible contrasts between group means. This test allows you to compare more than just two means at once, unlike the Tukey post-hoc test.
For example, suppose we have four groups – A, B, C, D.
The Scheffe post-hoc test would allow us to make complex comparisons such as:
μ<sub>A</sub> – μ<sub>B</sub> = μ<sub>C</sub> – μ<sub>D</sub>
μ<sub>A</sub> + μ<sub>D</sub> = μ<sub>B</sub> + μ<sub>C</sub>
While the Scheffe post-hoc test is the most flexible, it is also the most conservative and produces the widest confidence intervals. This means it has the lowest statistical power and the lowest ability to detect true differences between the groups.
Note that the Scheffe post-hoc test can be used whether or not the group sample sizes are equal.
<h3>The Bonferroni Method</h3>
The Bonferroni post-hoc test should be used when you have a set of <em>planned</em> comparisons you would like to make beforehand. 
For example, suppose we have three groups – A, B, C – and we know ahead of time that we’re only interested in the following comparisons:
μ<sub>A</sub> = μ<sub>B</sub>
μ<sub>B</sub> = μ<sub>C</sub>
When we have a specific set of planned comparisons we’d like to make ahead of time like this, the Bonferroni post-hoc test produces the most narrow confidence intervals, which means it has the greatest ability to detect true difference between the groups of interest.
Note that the Bonferroni post-hoc test can also be used whether or not the group sample sizes are equal.
<h3>Which Method Should You Use?</h3>
The following decision tree helps you decide which post-hoc test you should use depending on the situation:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/post1.png">
<h3>Closing Thoughts</h3>
No matter which post-hoc test you choose to use, you should decide on it <em>before</em> conducting the experiment.
This prevents you from choosing a post-hoc test after the experiment that may be more likely to produce significant results, which is considered a dishonest practice in research.
In any case, most statistical software is capable of performing these post-hoc tests so you will rarely have to compute them by hand.
<h2><span class="orange">How to Turn Off Scientific Notation in R (With Examples)</span></h2>
You can use the following methods to turn off scientific notation in R;
<b>Method 1: Turn off scientific notation as global setting</b>
<b>options(scipen=999)
</b>
<b>Method 2: Turn off scientific notation for one variable</b>
<b>format(x, scientific = F)
</b>
The following examples show how to use each of these methods in practice.
<h3>Method 1: Turn Off Scientific Notation as Global Setting</h3>
Suppose we perform the following multiplication in R:
<b>#perform multiplication
x &lt;- 9999999 * 12345
#view results</b>
<b>x
[1] 1.2345e+11
</b>
The output is shown in scientific notation since the number is so large.
The following code shows how to turn off scientific notation as a global setting. This means no variable in any output will be shown in scientific notation.
<b>#turn off scientific notation for all variables
options(scipen=999) 
#perform multiplication
x &lt;- 9999999 * 12345
#view results
x
[1] 123449987655
</b>
Notice that the entire number is displayed since we turned off scientific notation.
Note that the default value for scipen is <b>0</b> so you can reset this global setting by using <b>options(scipen=0)</b> in R:
<b>#turn scientific notation back on
options(scipen=0) 
#perform multiplication again
x &lt;- 9999999 * 12345
#view results
x
[1] 1.2345e+11
</b>
<h3>Method 2: Turn Off Scientific Notation for One Variable</h3>
The following code shows how to turn off scientific notation for just one variable:
<b>#perform multiplication
x &lt;- 9999999 * 12345
#display results and turn of scientific notation
format(x, scientific = F)
[1] "123449987655"
#perform another multiplication
y &lt;- 9999999 * 999999
#view results
y
[1] 9.999989e+12
</b>
Notice that only the first variable is shown without scientific notation since it’s the only variable that we used the <b>format()</b> function on.
<h2><span class="orange">Two Proportion Z-Test Calculator</span></h2>
A <b>two proportion z-test</b> is used to test for a difference between two population proportions. The test statistic is calculated as:
<b>z</b> = (p<sub>1</sub>-p<sub>2</sub>) / √(p(1-p)(1/n<sub>1</sub>+1/n<sub>2</sub>)
where:
p = total pooled proportion
p<sub>1</sub> = sample 1 proportion
p<sub>2</sub> = sample 2 proportion
n<sub>1</sub> = sample 1 size
n<sub>2</sub> = sample 2 size
To perform a two proportion z-test, simply fill in the information below and then click the “Calculate” button.
<label><b>p<sub>1</sub></b> (sample 1 proportion)</label>
<input type="number" id="p1" value="0.64">
<label><b>n<sub>1</sub></b> (sample 1 size)</label>
<input type="number" id="n1" value="30">
<label><b>p<sub>2</sub></b> (sample 2 proportion)</label>
<input type="number" id="p2" value="0.6">
<label><b>n<sub>2</sub></b> (sample 2 size)</label>
<input type="number" id="n2" value="30">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
z-statistic: 0.31917
p-value (one-tailed): 0.37480
p-value (two-tailed): 0.74960
<script>
function calc() {
//get input values
var p1 = +document.getElementById('p1').value;
var n1 = +document.getElementById('n1').value;
var p2 = +document.getElementById('p2').value;
var n2 = +document.getElementById('n2').value;
//calculate stuff
var pool = (p1*n1 - (-p2*n2))/(n1-(-1*n2));
var z = (p1-p2)/(Math.sqrt(pool*(1-pool)*(1/n1-(-1/n2))));
//calculate p-value
if (z<0) {
var p1out = jStat.normal.cdf(z, 0, 1);
var p2out = p1out*2;
} else {
var p1out = 1-jStat.normal.cdf(z, 0, 1);
var p2out = p1out*2;
}
//output probabilities
document.getElementById('z').innerHTML = z.toFixed(5);
document.getElementById('p1out').innerHTML = p1out.toFixed(5);
document.getElementById('p2out').innerHTML = p2out.toFixed(5);
}
</script>
<h2><span class="orange">How to Perform a Two Proportion Z-Test in Excel</span></h2>
A <b> two proportion z-test  </b>is used to test for a difference between two population proportions.
For example, suppose a superintendent of a school district claims that the percentage of students who prefer chocolate milk over regular milk in school cafeterias is the same for school 1 and school 2.
To test this claim, an independent researcher obtains a  simple random sample  of 100 students from each school and surveys them about their preferences. He finds that 70% of students prefer chocolate milk in school 1 and 68% of students prefer chocolate milk in school 2.
We can use a two proportion z-test to test whether or not the percentage of students who prefer chocolate milk over regular milk is the same for both schools.
<h2>Steps to Perform a Two Sample Z-Test</h2>
We can use the following steps to perform the two proportion z-test:
<b>Step 1. State the hypotheses. </b>
The null hypothesis (H0): P<sub>1</sub> = P<sub>2</sub>
The alternative hypothesis: (Ha): P<sub>1</sub> ≠ P<sub>2</sub>
<b>Step 2. Find the test statistic and the corresponding p-value.</b>
First, find the pooled sample proportion p:
p = (p<sub>1</sub> * n<sub>1</sub> + p<sub>2</sub> * n<sub>2</sub>) / (n<sub>1</sub> + n<sub>2</sub>)
p = (.70*100 + .68*100) / (100 + 100) = .69
Then use p in the following formula to find the test statistic z:
z = (p<sub>1</sub>-p<sub>2</sub>) / √p * (1-p) * [ (1/n<sub>1</sub>) + (1/n<sub>2</sub>)]
z = (.70-.68) / √.69 * (1-.69) * [ (1/100) + (1/100)] = .02 / .0654 = <b>.306</b>
Use the  Z Score to P Value Calculator  with a z score of .306 and a two-tailed test to find that the p-value = <b>0.759</b>.
<b>Step 3. Reject or fail to reject the null hypothesis.</b>
First, we need to choose a significance level to use for the test. Common choices are 0.01, 0.05, and 0.10. For this example, let’s use 0.05. Since the p-value is not less than our significance level of .05, we fail to reject the null hypothesis.
Thus, we do not have sufficient evidence to say that the percentage of students who prefer chocolate milk is different for school 1 and school 2.
<h2>How to Perform a Two Sample Z-Test in Excel</h2>
The following examples illustrate how to perform a two sample z-test in Excel.
<h3>Two Sample Z Test (Two-tailed)</h3>
A superintendent of a school district claims that the percentage of students who prefer chocolate milk over regular milk in school cafeterias is the same for school 1 and school 2.
To test this claim, an independent researcher obtains a simple random sample of 100 students from each school and surveys them about their preferences. He finds that 70% of students prefer chocolate milk in school 1 and 68% of students prefer chocolate milk in school 2.
<em><b>Based on these results, can we reject the superintendent’s claim that the percentage of students who prefer chocolate milk is the same for school 1 and school 2? Use a .05 level of significance. </b></em>
The following screenshot shows how to perform a two-tailed two sample z test in Excel, along with the formulas used:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/twoSamp1-1.jpg">
You need to fill in the values for cells <b>B1:B4</b>. Then, the values for cells <b>B6:B8 </b>are automatically calculated using the formulas shown in cells <b>C6:C8</b>.
Note that the formulas shown do the following:
Formula in cell <b>C6</b>: This calculates the pooled sample proportion using the formula <b>p =</b> <b>(p<sub>1</sub> * n<sub>1</sub> + p<sub>2</sub> * n<sub>2</sub>) / (n<sub>1</sub> + n<sub>2</sub>)</b>
Formula in cell <b>C7</b>: This calculates the test statistic <em>z </em>using the formula <b>z = (p<sub>1</sub>-p<sub>2</sub>) / √p * (1-p) * [ (1/n<sub>1</sub>) + (1/n<sub>2</sub>)]</b> where <em>p </em>is the pooled sample proportion.
Formula in cell <b>C8</b>: This calculates the p-value associated with the test statistic calculated in cell <b>B7</b> using the Excel function <b>NORM.S.DIST</b>, which returns the cumulative probability for the normal distribution with mean = 0 and standard deviation = 1. We multiply this value by two since this is a two-tailed test.
Since the p-value (<b>0.759</b>) is not less than our chosen significance level of <b>0.05</b>, we fail to reject the null hypothesis. Thus, we do not have sufficient evidence to say that the percentage of students who prefer chocolate milk is different for school 1 and school 2.
<h3>Two Sample Z Test (One-tailed)</h3>
A superintendent of a school district claims that the percentage of students who prefer chocolate milk over regular milk in school 1 is <b>less than or equal</b> to the percentage in school 2.
To test this claim, an independent researcher obtains a simple random sample of 100 students from each school and surveys them about their preferences. He finds that 70% of students prefer chocolate milk in school 1 and 68% of students prefer chocolate milk in school 2.
<em><b>Based on these results, can we reject the superintendent’s claim that the percentage of students who prefer chocolate milk in school 1 is less than or equal to the percentage in school 2? Use a .05 level of significance. </b></em>
The following screenshot shows how to perform a one-tailed two sample z test in Excel, along with the formulas used:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/06/twoSamp2.jpg">
You need to fill in the values for cells <b>B1:B4</b>. Then, the values for cells <b>B6:B8 </b>are automatically calculated using the formulas shown in cells <b>C6:C8</b>.
Note that the formulas shown do the following:
Formula in cell <b>C6</b>: This calculates the pooled sample proportion using the formula <b>p =</b> <b>(p<sub>1</sub> * n<sub>1</sub> + p<sub>2</sub> * n<sub>2</sub>) / (n<sub>1</sub> + n<sub>2</sub>)</b>
Formula in cell <b>C7</b>: This calculates the test statistic <em>z </em>using the formula <b>z = (p<sub>1</sub>-p<sub>2</sub>) / √p * (1-p) * [ (1/n<sub>1</sub>) + (1/n<sub>2</sub>)]</b> where <em>p </em>is the pooled sample proportion.
Formula in cell <b>C8</b>: This calculates the p-value associated with the test statistic calculated in cell <b>B7</b> using the Excel function <b>NORM.S.DIST</b>, which returns the cumulative probability for the normal distribution with mean = 0 and standard deviation = 1.
Since the p-value (<b>0.379</b>) is not less than our chosen significance level of <b>0.05</b>, we fail to reject the null hypothesis. Thus, we do not have sufficient evidence to say that the percentage of students who prefer chocolate milk in school 2 is greater than that of school 1.
<h2><span class="orange">Two Proportion Z-Test: Definition, Formula, and Example</span></h2>
A <b>two proportion z-test</b> is used to test for a difference between two population proportions.
This tutorial explains the following:
The motivation for performing a two proportion z-test.
The formula to perform a two proportion z-test.
An example of how to perform a two proportion z-test.
<h3>Two Proportion Z-Test: Motivation</h3>
Suppose we want to know if there is a difference in the proportion of residents who support a certain law in county A compared to the proportion who support the law in county B.
Since there are thousands of residents in each county, it would take too long and be too costly to go around and survey every individual resident in each county.
Instead, we might take a  simple random sample  of residents from each county and use the proportion in favor of the law in each sample to estimate the true difference in proportions between the two counties:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/diffProps1.png">
However, it’s virtually guaranteed that the proportion of residents who support the law will be at least a little different between the two samples. <b>The question is whether or not this difference is statistically significant</b>. Fortunately, a two proportion z-test allows us to answer this question.
<h3>
<b>Two Proportion Z-Test: Formula</b>
</h3>
A two proportion z-test always uses the following null hypothesis:
<b>H<sub>0</sub>:</b> μ<sub>1</sub> = μ<sub>2</sub> (the two population proportions are equal)
The alternative hypothesis can be either two-tailed, left-tailed, or right-tailed:
<b>H<sub>1</sub> (two-tailed): </b>π<b><sub>1</sub></b> ≠ π<sub>2</sub> (the two population proportions are not equal)
<b>H<sub>1</sub> (left-tailed): </b>π<sub>1</sub> &lt; π<sub>2</sub> (population 1 proportion is less than population 2 proportion)
<b>H<sub>1</sub> (right-tailed): </b>π<b><sub>1 </sub></b>> π<sub>2</sub> (population 1 proportion is greater than population 2 proportion)
We use the following formula to calculate the test statistic z:
<b>z </b>= (p<sub>1</sub>-p<sub>2</sub>) / √p(1-p)(1/n<sub>1</sub>+1/n<sub>2</sub>)
where p<sub>1</sub> and p<sub>2</sub> are the sample proportions, n<sub>1 </sub>and n<sub>2 </sub>are the sample sizes, and where p is the total pooled proportion calculated as:
p = (p<sub>1</sub>n<sub>1</sub> + p<sub>2</sub>n<sub>2</sub>)/(n<sub>1</sub>+n<sub>2</sub>)
If the p-value that corresponds to the test statistic z is less than your chosen significance level (common choices are 0.10, 0.05, and 0.01) then you can reject the null hpothesis.
<h3>
<b>Two Proportion Z-Test: Example</b>
</h3>
Suppose we want to know if there is a difference in the proportion of residents who support a certain law in county A compared to the proportion who support the law in county B.
To test this, will perform a two proportion z-test at significance level α = 0.05 using the following steps:
<b>Step 1: Gather the sample data.</b>
Suppose we collect a random sample of residents from each county and end up with the following information:
<b>Sample 1:</b>
Sample size n<sub>1</sub> = 50
Proportion in favor of law p<sub>1</sub> = 0.67
<b>Sample 2:</b>
Sample size n<sub>2</sub> = 50
Proportion in favor of law p<sub>2</sub> = 0.57
<b>Step 2: Define the hypotheses.</b>
We will perform the two proportion z-test with the following hypotheses:
<b>H<sub>0</sub>: </b>π<b><sub>1</sub></b> = π<sub>2</sub>  (the two population proportions are equal)
<b>H<sub>1</sub>: </b>π<b><sub>1</sub></b> ≠ π<sub>2</sub>  (the two population proportions are not equal)
<b>Step 3: Calculate the test statistic <em>z</em>.</b>
First, we will calculate the total pooled proportion:
<b>p</b> = (p<sub>1</sub>n<sub>1</sub> + p<sub>2</sub>n<sub>2</sub>)/(n<sub>1</sub>+n<sub>2</sub>) = (0.67(50) + 0.57(50))/(50+50) = <b>0.62</b>
Next, we will calculate the test statistic <em>z</em>:
<b>z </b>= (p<sub>1</sub>-p<sub>2</sub>) / √p(1-p)(1/n<sub>1</sub>+1/n<sub>2</sub>) = (.67-.57) / √.62(1-.62)(1/50+ 1/50) = <b>1.03</b>
<b>Step 4: Calculate the p-value of the test statistic <em>z</em>.</b>
According to the  Z Score to P Value Calculator , the two-tailed p-value associated with z = 1.03 is <b>0.30301</b>.
<b>Step 5: Draw a conclusion.</b>
Since this p-value is not less than our significance level α = 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the proportion of residents who support this law is different between the two counties.
<em><b>Note: </b>You can also perform this entire two proportion z-test by simply using the  Two Proportion Z-Test Calculator .</em>
<h2><span class="orange">Two Sample t-test Calculator</span></h2>
A <b>two sample t-test</b> is used to test whether or not the means of two populations are equal.
This type of test assumes that the two samples have equal variances. If this is not the case, you should instead use the  Welch’s t-test calculator .
To perform a two sample t-test, simply fill in the information below and then click the “Calculate” button.
<label for="raw">Enter raw data</label>
<input type="radio" id="raw" name="tails" onclick="check()" checked><label for="summary">Enter summary data</label>
<input type="radio" id="summary" name="tails" onclick="check()">
<b>Sample 1</b>
<textarea id="rawData1" rows="5" cols="40">301, 298, 295, 297, 304, 305, 309, 298, 291, 299, 293, 304</textarea>
<b>Sample 2</b>
<textarea id="rawData2" rows="5" cols="40">302, 309, 324, 313, 312, 310, 305, 298, 299, 300, 289, 294</textarea>
<label><b>x<sub>1</sub></b> (sample 1 mean)</label>
<input type="number" id="x1" value="300">
<label><b>s<sub>1</sub></b> (sample 1 standard deviation)</label>
<input type="number" id="s1" value="18.5">
<label><b>n<sub>1</sub></b> (sample 1 size)</label>
<input type="number" id="n1" value="40">
<label><b>x<sub>2</sub></b> (sample 2 mean)</label>
<input type="number" id="x2" value="305">
<label><b>s<sub>2</sub></b> (sample 2 standard deviation)</label>
<input type="number" id="s2" value="16.7">
<label><b>n<sub>2</sub></b> (sample 2 size)</label>
<input type="number" id="n2" value="38">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>t = </b> -1.608761
<b>df = </b> 22
<b>p-value (one-tailed) = </b> 0.060963
<b>p-value (two-tailed) = </b> 0.121926
<script>
//set summary table to hidden to start
var summary_display = document.getElementById("summary_table");
summary_display.style.display = "none";
//find which radio button is checked
function check() {
if (document.getElementById('raw').checked) {
var table_display = document.getElementById("words_table");
        table_display.style.display = "block";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "none";
} else {
var table_display = document.getElementById("words_table");
        table_display.style.display = "none";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "block";
}
} //end check
//perform one-sample t-test
function calc() {
if (document.getElementById('summary').checked) {
var x1 = +document.getElementById('x1').value;
var s1 = +document.getElementById('s1').value;
var n1 = +document.getElementById('n1').value;
var x2 = +document.getElementById('x2').value;
var s2 = +document.getElementById('s2').value;
var n2 = +document.getElementById('n2').value;
var df = n1-(-1*n2)-2;
var sp = Math.sqrt(((n1-1)*Math.pow(s1,2) - (-1*((n2-1)*Math.pow(s2,2))))/df);
var t = (x1-x2)/(sp*Math.sqrt(1/n1 - (-1/n2)));
if (t<0) {
var p1 = jStat.studentt.cdf(t, df);
var p2 = p1*2;
} else {
var p1 = 1-jStat.studentt.cdf(t, df);
var p2 = p1*2;
}
document.getElementById('t').innerHTML = t.toFixed(6);
document.getElementById('df').innerHTML = df;
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
} else {
var raw1 = document.getElementById('rawData1').value.split(',').map(Number);
var raw2 = document.getElementById('rawData2').value.split(',').map(Number);
var x1 = math.mean(raw1)
var s1 = math.std(raw1)
var n1 = raw1.length;
var x2 = math.mean(raw2)
var s2 = math.std(raw2)
var n2 = raw2.length;
var df = n1-(-1*n2)-2;
var sp = Math.sqrt(((n1-1)*Math.pow(s1,2) - (-1*((n2-1)*Math.pow(s2,2))))/df);
var t = (x1-x2)/(sp*Math.sqrt(1/n1 - (-1/n2)));
if (t<0) {
var p1 = jStat.studentt.cdf(t, df);
var p2 = p1*2;
} else {
var p1 = 1-jStat.studentt.cdf(t, df);
var p2 = p1*2;
}
document.getElementById('t').innerHTML = t.toFixed(6);
document.getElementById('df').innerHTML = df;
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
}
//output results
}
</script>
<h2><span class="orange">How to Conduct a Two Sample t-Test in Excel</span></h2>
A  <b>two sample t-test</b>  is used to test whether or not the means of two populations are equal.
This tutorial explains how to conduct a two sample t-test in Excel.
<h2>How to Conduct a Two Sample t-Test in Excel</h2>
Suppose researchers want to know whether or not two different species of plants in a particular country have the same mean height. Because it would take too long to go around and measure every single plant, they decide to collect a sample of 20 plants from each species.
The following image shows the height (in inches) for each plant in each sample:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel1.png">
We can conduct a two sample t-test to determine if the two species have the same mean height using the following steps:
<b>Step 1: Determine if the population variances are equal</b>. 
When we conduct a two sample t-test, we must first decide if we will assume that the two populations have equal or unequal variances. As a rule of thumb, we can assume the populations have equal variances if the ratio of the larger sample variance to the smaller sample variance is less than 4:1. 
We can find the variance for each sample using the Excel function <b>=VAR.S(Cell range)</b>, as the following image shows:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel2.png">
The ratio of the larger sample variance to the smaller sample variance is 12.9053 / 8.1342 = <b>1.586</b>, which is less than 4. This means we can assume that the population variances are equal.
<b>Step 2: Open the Analysis ToolPak</b>.
On the Data tab along the top ribbon, click “Data Analysis.”
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see this as an option to click on, you need to first  download the Analysis ToolPak , which is completely free.
<b>Step 3: Select the appropriate test to use.</b>
Select the option that says <em>t-Test: Two-Sample Assuming Equal Variances</em> and then click OK.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel4.png">
<b>Step 4: Enter the necessary info</b>.
Enter the range of values for Variable 1 (our first sample), Variable 2 (our second sample), the hypothesized mean difference (in this case we put “0” because we want to know if the true mean population difference is 0), and the output range where we would like to see the results of the t-test displayed. Then, click OK.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel5.png">
<b>Step 5: Interpret the results</b>.
Once you click OK in the previous step, the results of the t-test will be displayed. 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel6.png">
Here is how to interpret the results:
<b>Mean: </b>This is the mean for each sample. Sample 1 has a mean height of <b>15.15</b> and sample 2 has a mean height of <b>15.8</b>.
<b>Variance: </b>This is the variance for each sample. Sample 1 has a variance of <b>8.13 </b>and sample 2 has a variance of <b>12.90</b>.
<b>Observations: </b>This is the number of observations in each sample. Both samples have <b>20 </b>observations (e.g. 20 individual plants in each sample).
<b>Pooled Variance: </b>A number that is calculated by “pooling” the variances of each sample together using the formula s<sup>2</sup><sub>p</sub> = [ (n<sub>1</sub>-1)s<sup>2</sup><sub>1</sub> + (n<sub>2</sub>-1)s<sup>2</sup><sub>2</sub> ] / (n<sub>1</sub>+n<sub>2</sub>-2), which turns out to be <b>10.51974</b>. This number is later used when calculating the test statistic <em>t</em>.
<b>Hypothesized mean difference: </b>The number that we “hypothesize” is the difference between the two population means. In this case, we chose <b>0</b> because we want to test whether or not the difference between the two populations means is 0, e.g. there is no difference.
<b>df: </b>The degrees of freedom for the t-test, calculated as n<sub>1</sub> + n<sub>2</sub> -2 = 20 + 20 – 2 = <b>38</b>.
<b>t Stat: </b>The test statistic <em>t</em>, calculated as <em>t </em> = [ x<sub>1</sub> – x<sub>2</sub> ] / √ [ s<sup>2</sup><sub>p</sub>(1/n<sub>1</sub> + 1/n<sub>2</sub>) ]
In this case, <em>t </em>= [15.15-15.8] / √ [ 10.51974(1/20+1/20) ] = <b>-0.63374</b>.
<b>P(T&lt;=t) two-tail: </b>The p-value for a two-tailed t-test. In this case, p = <b>0.530047</b>. This is much larger than alpha = 0.05, so we fail to reject the null hypothesis. We do not have sufficient evidence to say that the two population means are different.
<b>t Critical two-tail: </b>This is the critical value of the test, found by identifying the value in the  t Distribution table  that corresponds with a two-tailed test with alpha = 0.05 and df = 38. This turns out to be <b>2.024394</b>. Since our test statistic <em>t </em>is less than this value, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the two population means are different. 
Note that the p-value and the critical value approach will both lead to the same conclusion.
<h2><span class="orange">How to Perform a Two Sample T-Test in R</span></h2>
A  two sample t-test  is used to test whether or not the means of two populations are equal.
You can use the following basic syntax to perform a two sample t-test in R:
<b>t.test(group1, group2, var.equal=TRUE) 
</b>
<b>Note</b>: By specifying <b>var.equal=TRUE</b>, we tell R to assume that the variances are equal between the two samples.
If you don’t want to make this assumption, simply leave out this argument and R will instead perform  Welch’s t-test , which does not assume that the variances are equal between the samples.
The following example shows how to perform a two sample t-test in R in practice.
<h2>Example: Two Sample T-Test in R</h2>
Suppose we want to know if two different species of plants have the same mean height.
To test this, we collect a  simple random sample  of 12 plants from each species.
The following code shows how to perform a two sample t-test in R to determine if the mean height is equal between the two species:
<b>#create vectors to hold plant heights from each sample
group1 &lt;- c(8, 8, 9, 9, 9, 11, 12, 13, 13, 14, 15, 19)
group2 &lt;- c(11, 12, 13, 13, 14, 14, 14, 15, 16, 18, 18, 19)
#perform two sample t-test
t.test(group1, group2, var.equal=TRUE)
Two Sample t-test
data:  group1 and group2
t = -2.5505, df = 22, p-value = 0.01823
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -5.5904820 -0.5761847
sample estimates:
mean of x mean of y 
 11.66667  14.75000 
</b>
Here’s how to interpret the results of the test:
<b>data:</b> The names of the vectors that contain the sample data.
<b>t:</b> The t test-statistic. In this case, it is <b>-2.5505</b>.
<b>df</b>: The degrees of freedom, calculated as n<sub>1</sub> + n<sub>2</sub> – 2 = 12 + 12 – 2 = <b>22</b>.
<b>p-value:</b> The p-value that corresponds to a t test-statistic of -2.5505 and df = 22. The p-value turns out to be <b>.01823</b>. We can confirm this value by using the  T Score to P Value calculator .
<b>95 percent confidence interval:</b> The 95% confidence interval for the true difference in means between the two groups. It turns out to be <b>[-5.59, -.576]</b>.
<b>sample estimates:</b> The  sample mean  of each group. In this case, the sample mean of group 1 was <b>11.667</b> and the sample mean of group 2 was <b>14.75</b>.
The null and alternative hypotheses for this particular two sample t-test are as follows:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠μ<sub>2</sub> (the two population means are <em>not</em> equal)
Because the p-value of our test<b> (.01823) </b>is less than 0.05, we reject the null hypothesis.
This means we have sufficient evidence to conclude that the mean plant height between the two species is not equal.
<h2>Technical Notes</h2>
The <b>t.test()</b> function in R uses the following syntax:
<b>t.test(x, y, alternative="two.sided", mu=0, paired=FALSE, var.equal=FALSE, conf.level=0.95)</b>
where:
<b>x, y:</b> The names of the two vectors that contain the data.
<b>alternative:</b> The alternative hypothesis. Options include “two.sided”, “less”, or “greater.”
<b>mu:</b> The value assumed to be the true difference in means.
<b>paired:</b> Whether or not to use a paired t-test.
<b>var.equal:</b> Whether or not the variances are equal between the two groups.
<b>conf.level:</b> The confidence level to use for the test.
Feel free to change any of these arguments when you conduct your own t-test, depending on the particular test you want to perform.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Perform a One Sample T-Test in R 
 How to Perform Welch’s T-Test in R 
 How to Perform a Paired Samples T-Test in R 
<h2><span class="orange">How to Perform a Two Sample t-Test in SAS</span></h2>
A  two sample t-test  is used to determine whether or not two  population means  are equal.
This tutorial explains how to perform a two sample t-test in SAS.
<h3>Example: Two Sample t-Test in SAS</h3>
Suppose a botanist wants to know if the mean height of two different species of plants is equal. She collects a  random sample  of 12 plants from each species and and records their heights in inches.
The heights are as follows:
<b>Sample 1</b>: 13, 15, 15, 16, 16, 16, 17, 18, 18, 19, 20, 21
<b>Sample 2</b>: 15, 15, 16, 18, 19, 19, 19, 20, 21, 23, 23, 24
Use the following steps to conduct a two sample t-test to determine if the mean height is equal between the two species.
<b>Step 1: Create the data.</b>
First, we’ll use the following code to create the dataset in SAS:
<b>/*create dataset*/
data my_data;
    input Species $ Height;
    datalines;
1 13
1 15
1 15
1 16
1 16
1 16
1 17
1 18
1 18
1 19
1 20
1 21
2 15
2 15
2 16
2 18
2 19
2 19
2 19
2 20
2 21
2 23
2 23
2 24
;
run;</b>
<b>Step 2: Perform a two sample t-test.</b>
Next, we’ll use <b>proc ttest</b> to perform the two sample t-test:
<b>/*perform two sample t-test*/
proc ttest data=my_data sides=2 alpha=0.05  h0=0;
    class Species;
    var Height;
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/twoSample1.jpg"499">
The last table titled <b>Equality of Variances</b> performs an F-test to determine if the variances are equal between the two samples.
Since the p-value (.<b>3577</b>) of this test is not less than .05, we can assume the two sample variances are equal.
Thus, we can refer to the row titled <b>Equal</b> in the second to last table to determine the t value and corresponding p-value to use:
t Value: <b>-2.11</b>
p-value: <b>.0460</b>
Recall that the two sample t-test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub>
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub>
Since the p-value (<b>.0460</b>) is less than .05, we reject the null hypothesis.
This means we have sufficient evidence to say that the mean height between the two species of plants is not equal.
<h2><span class="orange">How to Conduct a Two Sample T-Test in Python</span></h2>
A  two sample t-test  is used to test whether or not the means of two populations are equal.
This tutorial explains how to conduct a two sample t-test in Python.
<h2>Example: Two Sample t-Test in Python</h2>
Researchers want to know whether or not two different species of plants have the same mean height. To test this, they collect a  simple random sample  of 20 plants from each species.
Use the following steps to conduct a two sample t-test to determine if the two species of plants have the same height.
<b>Step 1: Create the data.</b>
First, we’ll create two arrays to hold the measurements of each group of 20 plants:
<b>import numpy as np
group1 = np.array([14, 15, 15, 16, 13, 8, 14, 17, 16, 14, 19, 20, 21, 15, 15, 16, 16, 13, 14, 12])
group2 = np.array([15, 17, 14, 17, 14, 8, 12, 19, 19, 14, 17, 22, 24, 16, 13, 16, 13, 18, 15, 13])</b>
<b>Step 2: Conduct a two sample t-test.</b>
Next, we’ll use the  ttest_ind() function  from the scipy.stats library to conduct a two sample t-test, which uses the following syntax:
<b>ttest_ind(a, b, equal_var=True)</b>
where:
<b>a: </b>an array of sample observations for group 1
<b>b: </b>an array of sample observations for group 2
<b>equal_var: </b>if True, perform a standard independent 2 sample t-test that assumes equal population variances. If False, perform  Welch’s t-test , which does not assume equal population variances. This is True by default.
Before we perform the test, we need to decide if we’ll assume the two populations have equal variances or not. As a rule of thumb, we can assume the populations have equal variances if the ratio of the larger sample variance to the smaller sample variance is less than 4:1. 
<b>#find variance for each group
print(np.var(group1), np.var(group2))
7.73 12.26
</b>
The ratio of the larger sample variance to the smaller sample variance is 12.26 / 7.73 = <b>1.586</b>, which is less than 4. This means we can assume that the population variances are equal.
Thus, we can proceed to perform the two sample t-test with equal variances:
<b>import scipy.stats as stats
#perform two sample t-test with equal variances
stats.ttest_ind(a=group1, b=group2, equal_var=True)
(statistic=-0.6337, pvalue=0.53005)
</b>
The t test statistic is <b>-0.6337 </b>and the corresponding two-sided p-value is <b>0.53005</b>.
<b>Step 3: Interpret the results.</b>
The two hypotheses for this particular two sample t-test are as follows:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠μ<sub>2</sub> (the two population means are <em>not </em>equal)
Because the p-value of our test<b> (0.53005) </b>is greater than alpha = 0.05, we fail to reject the null hypothesis of the test. We do not have sufficient evidence to say that the mean height of plants between the two populations is different.
<h2>Additional Resources</h2>
 How to Conduct a One Sample T-Test in Python 
 How to Conduct a Paired Samples T-Test in Python 
<h2><span class="orange">How to Perform a Two Sample t-test in SPSS</span></h2>
A  two sample t-test  is used to test whether or not the means of two populations are equal.
This tutorial explains how to conduct a two sample t-test in SPSS.
<h3>Example: Two Sample t-test in SPSS</h3>
Researchers want to know if a new fuel treatment leads to a change in the average miles per gallon of a certain car. To test this, they conduct an experiment in which 12 cars receive the new fuel treatment and 12 cars do not.
The following screenshot shows the mpg for each car along with the group they belong to (0 = no fuel treatment, 1 = fuel treatment):
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS1.png">
Use the following steps to perform a two sample t-test to determine if there is a difference in average mpg between these two groups, based on the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<b><sub>1</sub></b> = μ<b><sub>2 </sub></b>(average mpg between the two populations is equal)
<b>H<sub>1</sub>: </b>μ<b><sub>1</sub></b> ≠ μ<b><sub>2 </sub></b>(average mpg between the two populations is not equal)
<em>Use a significance level of α = 0.05.</em>
<b>Step 1: Choose the Independent Samples T Test option.</b>
Click the <b>Analyze </b>tab, then <b>Compare Means</b>, then <b>Independent-Samples T Test</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS2.png">
<b>Step 2: Fill in the necessary values to perform the two sample t-test.</b>
Once you click <b>Independent-Samples T Test</b>, the following window will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS3.png">
Drag the <b>mpg </b>into the box labelled <b>Test Variable(s) </b>and <b>group</b> into the box labelled <b>Grouping Variable</b>. Then click <b>Define Groups </b>and define Group 1 as the rows with value 0 and define Group 2 as the rows with value 1. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS4.png">
<b>Step 3: Interpret the results.</b>
Once you click <b>OK</b>, the results of the two sample t-test will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoSampSPSS5.png">
The first table displays the following summary statistics for both groups:
<b>N: </b>The sample size
<b>Mean: </b>The mean mpg of cars in each group
<b>Std. Deviation: </b>The standard deviation of the mpg of cars in each group
<b>Std. Error Mean: </b>The standard error of the mean mpg, calculated as s/√n
The second table displays the results of the two sample t-test. The first row shows the results of the test if you assume that the variance between the two groups is equal. The second row shows the results of the test if you don’t make this assumption. 
In this case, the two versions of the test produce nearly identical results. Thus, we will simply refer to the results of the first row:
<b>t: </b>The test statistic, found to be -1.428
<b>df: </b>The degrees of freedom, calculated as n<sub>1</sub>+n<sub>2</sub>-2 = 12+12-2 = 22
<b>Sig. (2-tailed): </b>The two-sided p-value that corresponds to a t value of -1.428 with df=22
<b>Mean Difference: </b>The difference between the two sample means
<b>Std. Error Difference: </b>The standard error of the mean difference
<b>95% C.I. of the Difference: </b>The 95%  confidence interval  for the true difference between the two population means
Since the p-value of the test (.167) is not less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the true mean mpg is different between cars that receive treatment and cars that don’t.
<h2><span class="orange">How to Perform a Two Sample t-test in Stata</span></h2>
A  <b>two sample t-test</b>  is used to test whether or not the means of two populations are equal.
This tutorial explains how to conduct a two sample t-test in Stata.
<h2>Example: Two Sample t-test in Stata</h2>
Researchers want to know if a new fuel treatment leads to a change in the average mpg of a certain car. To test this, they conduct an experiment in which 12 cars receive the new fuel treatment and 12 cars do not.
Perform the following steps to conduct a two sample t-test to determine if there is a difference in average mpg between these two groups.
<b>Step 1: Load the data.</b>
First, load the data by typing <b>use http://www.stata-press.com/data/r13/fuel3 </b>in the command box and clicking Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp1.png">
<b>Step 2: View the raw data.</b>
Before we perform a two sample t-test, let’s first view the raw data. Along the top menu bar, go to <b>Data > Data Editor > Data Editor (Browse)</b>. The first column, <em>mpg</em>, shows the mpg for a given car. The second column, <em>treated</em>, indicates whether or not the car received the fuel treatment (0 = no, 1 = yes).
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp2.png">
<b>Step 3: Visualize the data.</b>
Next, let’s visualize the data. We’ll create  boxplots  to view the distribution of mpg values for each group.
Along the top menu bar, go to <b>Graphics > Box plot</b>. Under variables, choose <em>mpg</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp3.png">
Then, in the Categories subheading under Grouping variable, choose <em>treated</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp4.png">
Click <em>OK</em>. A chart with two boxplots will automatically be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp5.png">
Right away we can see that the mpg appears to be higher for the treated group (1) compared to the non-treated group (0), but we need to conduct a two-sample t-test to see if these differences are statistically significant.
<b>Step 4: Perform a two sample t-test.</b>
Along the top menu bar, go to <b>Statistics > Summaries, tables, and tests > Classical tests of hypotheses > t test (mean-comparison test)</b>.
Choose <em>Two-sample using groups</em>. For Variable name, choose <em>mpg</em>. For Group variable name, choose <em>treated</em>. For Confidence level, choose any level you’d like. A value of 95 corresponds to a significance level of 0.05. We will leave this at 95. Lastly, click <em>OK</em>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp6.png">
The results of the two sample t-test will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/stataTwoSamp7.png">
We are given the following information for each group:
Obs: </b>The number of observations. There are 12 observations in each group.
<b>Mean: </b>The mean mpg. In group 0, the mean is 21. In group 1, the mean is 22.75.
<b>Std. Err: </b>The standard error, calculated as σ / √n
<b>Std. Dev: </b>The standard deviation of mpg.
<b>95% Conf. Interval: </b>The 95% confidence interval for the true population mean of mpg.
<b>t: </b>The test statistic of the two-sample t-test.
<b>degrees of freedom: </b>The degrees of freedom to be used for the test, calculated as n-2 = 24-2 = 22.
The p-values for three different two sample t-tests are displayed at the bottom of the results. Since we are interested in understanding if the average mpg is simply different between the two groups, we will look at the results of the middle test (in which the alternative hypothesis is Ha: diff !=0) which has a p-value of <b>0.1673</b>.
Since this value is not smaller than our significance level of 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the true mean mpg is different between the two groups.
<b>Step 5: Report the results.</b>
Lastly, we will report the results of our two sample t-test. Here is an example of how to do so:
A two sample t-test was conducted on 24 cars to determine if a new fuel treatment lead to a difference in mean miles per gallon. Each group contained 12 cars.
 
Results showed that the mean mpg was <em>not </em>different between the two groups (t = -1.428 w/ df=22, p = .1673) at a significance level of 0.05.
 
A 95% confidence interval for the true difference in population means resulted in the interval of (-4.29, .79).
<h2><span class="orange">How to Perform a Two Sample t-test on a TI-84 Calculator</span></h2>
A  <b>two sample t-test</b>  is used to test whether or not the means of two populations are equal.
This tutorial explains how to conduct a two sample t-test on a TI-84 calculator.
<h3>Example: Two Sample t-test on a TI-84 Calculator</h3>
Researchers want to know if a new fuel treatment leads to a change in the average mpg of a certain car. To test this, they conduct an experiment in which 12 cars receive the new fuel treatment and 12 cars do not. For the control group, the mean mpg is 21 mpg and the standard deviation is 2.73 mpg. For the treatment group, the mean mpg is 22.75 mpg and the standard deviation is 3.25 mpg.
Use this data to perform a two sample t-test to determine if the average mpg is different between the two groups.
<b>Step 1: Select 2-SampTTest.</b>
Press Stat. Scroll over to TESTS. Scroll down to 2-SampTTest and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/twoSampTI1.png">
<b>Step 2: Fill in the necessary info.</b>
The calculator will ask for the following information:
<b>Inpt: </b>Choose whether you are working with raw data (Data) or summary statistics (Stats). In this case, we will highlight Stats and press ENTER.
<b>x1:</b> The sample mean of the first group. We will type 21 and press  ENTER.
<b>Sx1: </b>The sample standard deviation of the first group. We will type 2.73 and press ENTER.
<b>n1: </b>The sample size of the first group. We will type 12 and press ENTER.
<b>x2:</b> The sample mean of the second group. We will type 22.75 and press  ENTER.
<b>Sx2: </b>The sample standard deviation of the second group. We will type 3.25 and press ENTER.
<b>n2: </b>The sample size of the second group. We will type 12 and press ENTER.
<b>μ1</b>:The alternative hypothesis to be used. Since we are performing a two-tailed test, we will highlight<b> ≠μ2 </b>and press ENTER. This indicates that our alternative hypothesis is μ1≠μ2. The other two options would be used for left-tailed tests (μ1&lt;μ2) and right-tailed tests (μ1>μ2) .
<b>Pooled: </b>Choose whether you want to pool the variances of the two groups or not. In most cases, we will choose no. Highlight no and press ENTER.
Lastly, highlight Calculate and press ENTER.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/twoSampTI2-1.png">
<b>Step 3: Interpret the results.</b>
Our calculator will automatically produce the results of the two sample t-test:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/twoSampTI3.png">
Here is how to interpret the results:
<b>μ<sub>1</sub>≠μ<sub>2</sub></b>: This is the alternative hypothesis for the test.
<b>t=-1.42825817</b>: This is the t test statistic. 
<b>p=0.1676749174</b>: This is the p-value that corresponds to the test statistic.
<b>df=21.36350678: </b>This is the degrees of freedom used to calculate the test statistic.
<b>x<sub>1</sub>=21</b>. This is the sample mean that we entered for the first group.
<b>x<sub>2</sub>=22.75: </b>This is the sample mean that we entered for the second group.
<b>Sx1=2.73</b>. This is the sample standard deviation that we entered for the first group.
<b>Sx2=3.25</b>: This is the sample standard deviation that we entered for the second group.
<b>n1=12: </b>This is the sample size we entered for the first group.
<b>n2=12: </b>This is the sample size we entered for the second group.
Because the p-value of the test (0.1676749174) is not less than 0.05, we fail to reject the null hypothesis. This means we do not have sufficient evidence to say that the mean mpg is different between the two groups.
<h2><span class="orange">Two Sample t-test: Definition, Formula, and Example</span></h2>
A <b>two sample t-test</b> is used to determine whether or not two  population means  are equal.
This tutorial explains the following:
The motivation for performing a two sample t-test.
The formula to perform a two sample t-test.
The assumptions that should be met to perform a two sample t-test.
An example of how to perform a two sample t-test.
<h2>Two Sample t-test: Motivation</h2>
Suppose we want to know whether or not the mean weight between two different species of turtles is equal. Since there are thousands of turtles in each population, it would be too time-consuming and costly to go around and weigh each individual turtle.
Instead, we might take a  simple random sample  of 15 turtles from each population and use the mean weight in each sample to determine if the mean weight is equal between the two populations:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/confIntmeans1.png">
However, it’s virtually guaranteed that the mean weight between the two samples will be at least a little different. <b>The question is whether or not this difference is statistically significant</b>. Fortunately, a two sample t-test allows us to answer this question.
<h2>
<b>Two Sample t-test: Formula</b>
</h2>
A two-sample t-test always uses the following null hypothesis:
<b>H<sub>0</sub>:</b> μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
The alternative hypothesis can be either two-tailed, left-tailed, or right-tailed:
<b>H<sub>1</sub> (two-tailed): </b>μ<b><sub>1</sub></b> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>H<sub>1</sub> (left-tailed): </b>μ<sub>1</sub> &lt; μ<sub>2</sub> (population 1 mean is less than population 2 mean)
<b>H<sub>1</sub> (right-tailed): </b>μ<b><sub>1</sub></b>> μ<sub>2</sub> (population 1 mean is greater than population 2 mean)
We use the following formula to calculate the test statistic t:
<b>Test statistic:</b> (x<sub>1</sub> – x<sub>2</sub>)  /  s<sub>p</sub>(√1/n<sub>1</sub> + 1/n<sub>2</sub>)
where x<sub>1</sub> and x<sub>2</sub> are the sample means, n<sub>1 </sub>and n<sub>2 </sub>are the sample sizes, and where s<sub>p</sub> is calculated as:
<b>s<sub>p</sub></b> = √ (n<sub>1</sub>-1)s<sub>1</sub><sup>2</sup> +  (n<sub>2</sub>-1)s<sub>2</sub><sup>2</sup> /  (n<sub>1</sub>+n<sub>2</sub>-2)
where s<sub>1</sub><sup>2</sup> and s<sub>2</sub><sup>2</sup> are the sample variances.
If the p-value that corresponds to the test statistic t with (n<sub>1</sub>+n<sub>2</sub>-1) degrees of freedom is less than your chosen significance level (common choices are 0.10, 0.05, and 0.01) then you can reject the null hypothesis.
<h2>Two Sample t-test: Assumptions</h2>
For the results of a two sample t-test to be valid, the following assumptions should be met:
The observations in one sample should be independent of the observations in the other sample.
The data should be approximately normally distributed.
The two samples should have approximately the same variance. If this assumption is not met, you should instead perform  Welch’s t-test .
The data in both samples was obtained using a  random sampling method .
<h2>
<b>Two Sample t-test: Example</b>
</h2>
Suppose we want to know whether or not the mean weight between two different species of turtles is equal. To test this, will perform a two sample t-test at significance level α = 0.05 using the following steps:
<b>Step 1: Gather the sample data.</b>
Suppose we collect a random sample of turtles from each population with the following information:
<b>Sample 1:</b>
Sample size n<sub>1</sub> = 40
Sample mean weight x<sub>1</sub> = 300
Sample standard deviation s<sub>1</sub> = 18.5
<b>Sample 2:</b>
Sample size n<sub>2</sub> = 38
Sample mean weight x<sub>2</sub> = 305
Sample standard deviation s<sub>2</sub> = 16.7
<b>Step 2: Define the hypotheses.</b>
We will perform the two sample t-test with the following hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>1</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>Step 3: Calculate the test statistic <em>t</em>.</b>
First, we will calculate the  pooled standard deviation  s<sub>p</sub>:
<b>s<sub>p</sub></b> = √ (n<sub>1</sub>-1)s<sub>1</sub><sup>2</sup> +  (n<sub>2</sub>-1)s<sub>2</sub><sup>2</sup> /  (n<sub>1</sub>+n<sub>2</sub>-2) = √ (40-1)18.5<sup>2</sup> +  (38-1)16.7<sup>2</sup> /  (40+38-2) = <b>17.647</b>
Next, we will calculate the test statistic <em>t</em>:
<b>t</b> = (x<sub>1</sub> – x<sub>2</sub>)  /  s<sub>p</sub>(√1/n<sub>1</sub> + 1/n<sub>2</sub>) =  (300-305) / 17.647(√1/40 + 1/38) = <b>-1.2508</b>
<b>Step 4: Calculate the p-value of the test statistic <em>t</em>.</b>
According to the  T Score to P Value Calculator , the p-value associated with t = -1.2508 and degrees of freedom = n<sub>1</sub>+n<sub>2</sub>-2 = 40+38-2 = 76 is <b>0.21484</b>.
<b>Step 5: Draw a conclusion.</b>
Since this p-value is not less than our significance level α = 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the mean weight of turtles between these two populations is different.
<em><b>Note: </b>You can also perform this entire two sample t-test by simply using the  Two Sample t-test Calculator .</em>
<h2>Additional Resources</h2>
The following tutorials explain how to perform a two-sample t-test using different statistical programs:
 How to Perform a Two Sample t-test in Excel 
 How to Perform a Two Sample t-test in SPSS 
 How to Perform a Two Sample t-test in Stata 
 How to Perform a Two Sample t-test in R 
 How to Perform a Two Sample t-test in Python 
 How to Perform a Two Sample t-test on a TI-84 Calculator 
<h2><span class="orange">Two Sample Z-Test Calculator</span></h2>
A <b>two sample z-test</b> is used to test whether or not the means of two populations are equal when the population standard deviations are known.
To perform a two sample z-test, simply fill in the information below and then click the “Calculate” button.
<label for="raw">Enter raw data</label>
<input type="radio" id="raw" name="tails" onclick="check()" checked><label for="summary">Enter summary data</label>
<input type="radio" id="summary" name="tails" onclick="check()">
<b>Sample 1</b>
<textarea id="rawData1" rows="5" cols="40">301, 298, 295, 297, 304, 305, 309, 298, 291, 299, 293, 304</textarea>
<b>Sample 2</b>
<textarea id="rawData2" rows="5" cols="40">302, 309, 324, 313, 312, 310, 305, 298, 299, 300, 289, 294</textarea>
<label><b>x<sub>1</sub></b> (sample 1 mean)</label>
<input type="number" id="x1" value="300">
<label><b>n<sub>1</sub></b> (sample 1 size)</label>
<input type="number" id="n1" value="40">
<label><b>x<sub>2</sub></b> (sample 2 mean)</label>
<input type="number" id="x2" value="305">
<label><b>n<sub>2</sub></b> (sample 2 size)</label>
<input type="number" id="n2" value="38">
<label><b>σ<sub>1</sub></b> (population 1 standard deviation)</label>
<input type="number" id="s1" value="18.5">
<label><b>σ<sub>2</sub></b> (population 2 standard deviation)</label>
<input type="number" id="s2" value="16.7">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>z = </b> -1.608761
<b>p-value (one-tailed) = </b> 0.060963
<b>p-value (two-tailed) = </b> 0.121926
<script>
//set summary table to hidden to start
var summary_display = document.getElementById("summary_table");
summary_display.style.display = "none";
//find which radio button is checked
function check() {
if (document.getElementById('raw').checked) {
var table_display = document.getElementById("words_table");
        table_display.style.display = "block";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "none";
} else {
var table_display = document.getElementById("words_table");
        table_display.style.display = "none";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "block";
}
} //end check
//perform one-sample z-test
function calc() {
if (document.getElementById('summary').checked) {
var x1 = +document.getElementById('x1').value;
var s1 = +document.getElementById('s1').value;
var n1 = +document.getElementById('n1').value;
var x2 = +document.getElementById('x2').value;
var s2 = +document.getElementById('s2').value;
var n2 = +document.getElementById('n2').value;
var z = (x1-x2)/(Math.sqrt((s1*s1)/n1 - (-1*(s2*s2)/n2)));
var p1 = jStat.ztest(z)/2;
var p2 = p1*2;
document.getElementById('z').innerHTML = z.toFixed(6);
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
} else {
var raw1 = document.getElementById('rawData1').value.split(',').map(Number);
var raw2 = document.getElementById('rawData2').value.split(',').map(Number);
var x1 = math.mean(raw1)
var s1 = +document.getElementById('s1').value;
var n1 = raw1.length;
var x2 = math.mean(raw2)
var s2 = +document.getElementById('s2').value;
var n2 = raw2.length;
var z = (x1-x2)/(Math.sqrt((s1*s1)/n1 - (-1*(s2*s2)/n2)));
var p1 = jStat.ztest(z)/2;
var p2 = p1*2;
document.getElementById('z').innerHTML = z.toFixed(6);
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
}
//output results
}
</script>
<h2><span class="orange">Two Sample Z-Test: Definition, Formula, and Example</span></h2>
A <b>two sample z-test</b> is used to test whether two population means are equal.
This test assumes that the standard deviation of each population is known.
This tutorial explains the following:
The formula to perform a two sample z-test.
The assumptions of a two sample z-test.
An example of how to perform a two sample z-test.
Let’s jump in!
<h2>Two Sample Z-Test: Formula</h2>
A two sample z-test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub> (the two population means are not equal)
We use the following formula to calculate the z test statistic:
<b>z = (x<sub>1</sub>– x<sub>2</sub>) / √σ<sub>1</sub><sup>2</sup>/n<sub>1</sub> + σ<sub>2</sub><sup>2</sup>/n<sub>2</sub>)</b>
where:
<b>x<sub>1</sub>, x<sub>2</sub>: </b>sample means
<b>σ<sub>1</sub>, σ<sub>2</sub>: </b>population standard deviations
<b>n<sub>1</sub>, n<sub>2</sub>: </b>sample sizes
If the p-value that corresponds to the z test statistic is less than your chosen significance level (common choices are 0.10, 0.05, and 0.01) then you can  reject the null hypothesis .
<h2>Two Sample Z-Test: Assumptions</h2>
For the results of a two sample z-test to be valid, the following assumptions should be met:
The data from each population are continuous (not discrete).
Each sample is a  simple random sample  from the population of interest.
The data in each population is approximately  normally distributed .
The population standard deviations are known.
<h2>Two Sample Z-Test: Example</h2>
Suppose the IQ levels among individuals in two different cities are known to be normally distributed each with population standard deviations of 15.
A scientist wants to know if the mean IQ level between individuals in city A and city B are different, so she selects a simple random sample of  20 individuals from each city and records their IQ levels.
 To test this, she will perform a two sample z-test at significance level α = 0.05 using the following steps:
<b>Step 1: Gather the sample data.</b>
Suppose she collects two simple random samples with the following information:
 <b>x</b><sub>1</sub> (sample 1 mean IQ) = 100.65
<b>n<sub>1</sub></b> (sample 1 size) = 20
<b>x</b><sub>2</sub> (sample 2 mean IQ) = 108.8
<b>n<sub>2</sub></b> (sample 2 size) = 20
<b>Step 2: Define the hypotheses.</b>
She will perform the two sample z-test with the following hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>Step 3: Calculate the z test statistic.</b>
The z test statistic is calculated as:
z = (x<sub>1</sub>– x<sub>2</sub>) / √σ<sub>1</sub><sup>2</sup>/n<sub>1</sub> + σ<sub>2</sub><sup>2</sup>/n<sub>2</sub>)
z = (100.65-108.8) / √15<sup>2</sup>/20 + 15<sup>2</sup>/20)
z = -1.718
<b>Step 4: Calculate the p-value of the z test statistic.</b>
According to the  Z Score to P Value Calculator , the two-tailed p-value associated with z = -1.718 is <b>0.0858</b>.
<b>Step 5: Draw a conclusion.</b>
Since the p-value (0.0858) is not less than the significance level (.05), the scientist will fail to reject the null hypothesis.
There is not sufficient evidence to say that the mean IQ level is different between the two populations.
<b>Note: </b>You can also perform this entire two sample z-test by using the  Two Sample Z-Test Calculator .
<h2>Additional Resources</h2>
The following tutorials explain how to perform a two sample z-test using different statistical software:
 How to Perform Z-Tests in Excel 
 How to Perform Z-Tests in R 
 How to Perform Z-Tests in Python 
<h2><span class="orange">Two-Stage Cluster Sampling: Definition & Example</span></h2>
<b>Cluster sampling</b> is a type of  sampling method  in which we split a  population  into clusters, then randomly select some of the clusters and include all members from those clusters in the sample.
For example, suppose a company that gives whale-watching tours wants to survey its customers. Out of ten tours they give one day, they randomly select four tours and ask every customer about their experience.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/twostage_cluster1.png">
This is an example of <b>cluster sampling</b>.
An extension of this is known as <b>two-stage cluster sampling</b>, which uses the following steps:
<b>Step 1:</b> Split a population into clusters, then randomly select some of the clusters.
<b>Step</b> <b>2:</b> Within each chosen cluster, randomly select some of the members to be included in the survey.
For example, the whale-watching company may randomly select four tours and then within each of those tours they may randomly select a subset of customers to be included in the survey.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/twostage_cluster2.png">
In this particular example, we randomly select four clusters and then within each cluster we randomly select four out of the seven customers to be included in the survey.
<h3>Why Use Two-Stage Cluster Sampling?</h3>
The benefit of <b>cluster sampling</b> is that it offers a far more convenient way to collect a sample compared to other  probability sampling methods , especially when members of a population are spread out across a wide geographical area.
<b>Two-stage cluster sampling</b> takes this a step further by only including some members from each randomly selected cluster to be in the final sample.
For example, suppose we would like to conduct a survey on the opinions of teachers in California about a certain topic.
Since California is so massive, it could be helpful to first break up the state into clusters (perhaps “counties”) and then randomly select teachers from only certain schools within each county to be included in the survey.
This approach allows us to gather a sample much more quickly compared to taking a simple random sample of all teachers in California.
And because cluster sampling is a probability sampling method (i.e. each member of the target population has an equally likely chance of being included in the sample), it has a high probability of producing a sample that is  representative of the overall population .
<b>Bonus:</b> For a real-life example of two-stage cluster sampling, check out  this study  that used two-stage cluster sampling to obtain a sample to estimate mortality rates in Iraq.
<h2><span class="orange">Two-Tailed Hypothesis Tests: 3 Example Problems</span></h2>
In statistics, we use  hypothesis tests  to determine whether some claim about a  population parameter  is true or not.
Whenever we perform a hypothesis test, we always write a null hypothesis and an alternative hypothesis, which take the following forms:
<b>H<sub>0</sub></b> (Null Hypothesis): Population parameter = ≤, ≥ some value
<b>H<sub>A</sub></b> (Alternative Hypothesis): Population parameter &lt;, >, ≠ some value
There are two types of hypothesis tests:
<b>One-tailed test</b>: Alternative hypothesis contains either <b>&lt;</b> or <b>></b> sign
<b>Two-tailed test</b>: Alternative hypothesis contains the <b>≠</b> sign
In a <b>two-tailed test</b>, the alternative hypothesis always contains the not equal (<b>≠</b>) sign.
This indicates that we’re testing whether or not some effect exists, regardless of whether it’s a positive or negative effect.
Check out the following example problems to gain a better understanding of two-tailed tests.
<h2>Example 1: Factory Widgets</h2>
Suppose it’s assumed that the average weight of a certain widget produced at a factory is 20 grams. However, one engineer believes that a new method produces widgets that weigh less than 20 grams.
To test this, he can perform a one-tailed hypothesis test with the following null and alternative hypotheses:
<b>H<sub>0</sub></b> (Null Hypothesis): μ = 20 grams
<b>H<sub>A</sub></b> (Alternative Hypothesis): μ ≠ 20 grams
This is an example of a <b>two-tailed hypothesis test</b> because the alternative hypothesis contains the not equal “≠” sign. The engineer believes that the new method will influence widget weight, but doesn’t specify whether it will cause average weight to increase or decrease.
To test this, he uses the new method to produce 20 widgets and obtains the following information:
n = <b>20</b> widgets
x = <b>19.8</b> grams
s = <b>3.1</b> grams
Plugging these values into the  One Sample t-test Calculator , we obtain the following results:
t-test statistic:<b> -0.288525</b>
two-tailed p-value: <b>0.776</b>
Since the p-value is not less than .05, the engineer fails to reject the null hypothesis.
He does not have sufficient evidence to say that the true mean weight of widgets produced by the new method is different than 20 grams.
<h2>Example 2: Plant Growth</h2>
Suppose a standard fertilizer has been shown to cause a species of plants to grow by an average of 10 inches. However, one botanist believes a new fertilizer causes this species of plants to grow by an average amount different than 10 inches.
To test this, she can perform a one-tailed hypothesis test with the following null and alternative hypotheses:
<b>H<sub>0</sub></b> (Null Hypothesis): μ = 10 inches
<b>H<sub>A</sub></b> (Alternative Hypothesis): μ ≠ 10 inches
This is an example of a <b>two-tailed hypothesis test </b> because the alternative hypothesis contains the not equal “≠” sign. The botanist believes that the new fertilizer will influence plant growth, but doesn’t specify whether it will cause average growth to increase or decrease.
To test this claim, she applies the new fertilizer to a simple random sample of 15 plants and obtains the following information:
n = <b>15</b> plants
x = <b>11.4</b> inches
s = <b>2.5</b> inches
Plugging these values into the  One Sample t-test Calculator , we obtain the following results:
t-test statistic:<b> 2.1689</b>
two-tailed p-value: <b>0.0478</b>
Since the p-value is less than .05, the botanist rejects the null hypothesis.
She has sufficient evidence to conclude that the new fertilizer causes an average growth that is different than 10 inches.
<h2>Example 3: Studying Method</h2>
A professor believes that a certain studying technique will influence the mean score that her students receive on a certain exam, but she’s unsure if it will increase or decrease the mean score, which is currently 82.
To test this, she lets each student use the studying technique for one month leading up to the exam and then administers the same exam to each of the students.
She then performs a hypothesis test using the following hypotheses:
<b>H<sub>0</sub>:</b> μ = 82
<b>H<sub>A</sub>:</b> μ ≠ 82
This is an example of a <b>two-tailed hypothesis test </b> because the alternative hypothesis contains the not equal “≠” sign. The professor believes that the studying technique will influence the mean exam score, but doesn’t specify whether it will cause the mean score to increase or decrease.
To test this claim, the professor has 25 students use the new studying method and then take the exam. He collects the following data on the exam scores for this sample of students:
n = <b>25</b>
x = <b>85</b>
s = <b>4.1</b>
Plugging these values into the  One Sample t-test Calculator , we obtain the following results:
t-test statistic:<b> 3.6586</b>
two-tailed p-value: <b>0.0012</b>
Since the p-value is less than .05, the professor rejects the null hypothesis.
She has sufficient evidence to conclude that the new studying method produces exam scores with an average score that is different than 82.
<h2>Additional Resources</h2>
The following tutorials provide additional information about hypothesis testing:
 Introduction to Hypothesis Testing 
 What is a Directional Hypothesis? 
 When Do You Reject the Null Hypothesis? 
<h2><span class="orange">How to Perform a Two-Way ANOVA by Hand</span></h2>
A  two-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
This tutorial explains how to perform a two-way ANOVA by hand.
<h3>Example: Two-Way ANOVA by Hand</h3>
Suppose a botanist wants to know if plant growth is influenced by sunlight exposure and watering frequency. She plants 40 seeds and lets them grow for one month under different conditions for sunlight exposure and watering frequency.
After one month, she records the height of each plant. The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova1.png"(max-width: 392px) 100vw, 392px">
In the table above, we see that there were five plants grown under each combination of conditions.
For example, there were five plants grown with daily watering and no sunlight and their heights after two months were 4.8 inches, 4.4 inches, 3.2 inches, 3.9 inches, and 4.4 inches:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova2.png"(max-width: 392px) 100vw, 392px">
We can use the following steps to perform a two-way ANOVA:
<b>Step 1: Calculate Sum of Squares for First Factor (Watering Frequency)</b>
First, we will calculate the grand mean height of all 40 plants:
Grand mean = (4.8 + 5 + 6.4 + 6.3 + … + 3.9 + 4.8 + 5.5 + 5.5) / 40 = <b>5.1525</b>
Next, we will calculate the mean height of all plants watered daily:
Mean of Daily = (4.8 + 5 + 6.4 + 6.3 + … + 4.4 + 4.8 + 5.8 + 5.8) /20 = <b>5.155</b>
Next, we will calculate the mean height of all plants watered weekly:
Mean of Weekly = (4.4 + 4.9 + 5.8 + 6 + … + 3.9 + 4.8 + 5.5 + 5.5) /20 = <b>5.15</b>
Next, we will calculate the sum of squares for the factor “watering frequency” by using the following formula:
Σn(X<sub>j</sub> – X..)<sup>2</sup> 
where:
<b>n</b>: the sample size of group j
<b>Σ</b>: a greek symbol that means “sum”
<b>X<sub>j</sub></b>: the mean of group j
<b>X..</b>: the grand mean
In our example, we calculate the sum of squares for the factor “watering frequency” to be: 20(5.155-5.1525)<sup>2</sup> + 20(5.15-5.1525)<sup>2</sup> = <b>.00025</b>
<b>Step 2: Calculate Sum of Squares for Second Factor (Sunlight Exposure)</b>
First, we will calculate the grand mean height of all 40 plants:
Grand mean = (4.8 + 5 + 6.4 + 6.3 + … + 3.9 + 4.8 + 5.5 + 5.5) / 40 = <b>5.1525</b>
Next, we will calculate the mean height of all plants with no sunlight exposure:
Mean of No Sunlight = (4.8 + 4.4 + 3.2 + 3.9 + 4.4 + 4.4 + 4.2 + 3.8 + 3.7 + 3.9) / 10 = <b>4.07</b>
We will repeat this calculation to find the mean height of plants with various sunlight exposures:
Mean of Low Sunlight = <b>5.1</b>
Mean of Medium Sunlight = <b>5.89</b>
Mean of High Sunlight = <b>5.55</b>
Next, we will calculate the sum of squares for the factor “sunlight exposure” by using the following formula:
Σn(X<sub>j</sub> – X..)<sup>2</sup> 
where:
<b>n</b>: the sample size of group j
<b>Σ</b>: a greek symbol that means “sum”
<b>X<sub>j</sub></b>: the mean of group j
<b>X..</b>: the grand mean
In our example, we calculate the sum of squares for the factor “sunlight exposure” to be: 10(4.07-5.1525)<sup>2</sup> + 10(5.1-5.1525)<sup>2</sup> + 10(5.89-5.1525)<sup>2</sup> + 10(5.55-5.1525)<sup>2</sup>  = <b>18.76475</b>
<b>Step 3: Calculate Sum of Squares Within (Error)</b>
Next, we will calculate the sum of squares within by taking the sum of squared differences between each combination of factors and the individual plant heights.
For example, the mean height of all plants watered daily with no sunlight exposure is 4.14. We can then calculate the sum of squared differences for each of these individual plants as:
SS for daily watering and no sunlight: (4.8-4.14)<sup>2</sup> + (4.4-4.14)<sup>2</sup> + (3.2-4.14)<sup>2</sup> + (3.9-4.14)<sup>2</sup> + (4.4-4.14)<sup>2</sup> = <b>1.512</b>
We can repeat this process for each combination of factors:
SS for daily watering and low sunlight: <b>0.928</b>
SS for daily watering and medium sunlight: <b>1.788</b>
SS for daily watering and high sunlight: <b>1.648</b>
SS for weekly watering and no sunlight: <b>0.34</b>
SS for weekly watering and low sunlight: <b>0.548</b>
SS for weekly watering and medium sunlight: <b>0.652</b>
SS for weekly watering and high sunlight: <b>1.268</b>
We can then take the sum of all of these values to find the sum of squares within (error):
Sums of squares within = 1.512 + .928 + 1.788 + 1.648 + .34 + .548 + .652 + 1.268 = <b>8.684</b>
<b>Step 4: Calculate Total Sum of Squares</b>
Next, we can calculate the total sum of squares by taking the sum of the differences between each individual plant height and the grand mean:
Total Sum of Squares = (4.8 – 5.1525)<sup>2</sup> + (5 – 5.1525)<sup>2</sup> + … + (5.5 – 5.1525)<sup>2</sup> = <b>28.45975</b>
<b>Step 5: Calculate Sum of Squares Interaction</b>
Next, we will calculate the sum of squares interaction by using the following formula:
SS Interaction = SS Total – SS Factor 1 – SS Factor 2 – SS Within
SS Interaction = 28.45975 – .00025 – 18.76475 – 8.684
SS Interaction = <b>1.01075</b>
<b>Step 6: Fill in ANOVA Table</b>
Lastly, we’ll fill in the values for the two-way ANOVA table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/two_way_hand.png">
Here is how we calculated the various numbers in the table:
<b>df Watering Frequency: </b>j-1 = 2-1 = 1
<b>df Sunlight Exposure: </b>k-1 = 4-1 = 3
<b>df Interaction</b>: (j-1)*(k-1) = 1*3 = 3
<b>df Within</b>: n – (j*k) = 40 – (2*4) = 32
<b>df total: </b>n-1 = 40-1 = 39
<b>MS: </b>SS/ df
<b>F Watering Frequency</b>: MS Watering Frequency / MS Within
<b>F Sunlight Exposure</b>: MS Sunlight Exposure / MS Within
<b>F Interaction</b>: MS Interaction / MS Within
<b>p-value Watering Frequency</b>: The p-value that corresponds to F value of .000921 with df numerator = 1 and df denominator = 32
<b>p-value Sunlight Exposure</b>: The p-value that corresponds to F value of 23.04898 with df numerator = 3 and df denominator = 32
<b>p-value Interaction</b>: The p-value that corresponds to F value of 1.241517 with df numerator = 3 and df denominator = 32
<b>Note #1: </b>n = total observations, j = number of levels for watering frequency, k = number of levels for sunlight exposure.
<b>Note #2</b>: The p-values that correspond to the F-value were calculated using the  F Distribution Calculator .
<b>Step 7: Interpret the results</b>
We can observe the following from the ANOVA table:
The p-value for the interaction between watering  frequency and sunlight exposure was <b>0.311</b>. This is not statistically significant at α = 0.05.
The p-value for watering frequency was <b>0.975</b>. This is not statistically significant at α = 0.05.
The p-value for sunlight exposure was <b>&lt; 0.000</b>. This is statistically significant at α = 0.05.
These results indicate that sunlight exposure is the only factor that has a statistically significant effect on plant height.
And because there is no interaction effect, the effect of sunlight exposure is consistent across each level of watering frequency.
That is, whether a plant is watered daily or weekly has no impact on how sunlight exposure affects a plant.
<h2><span class="orange">How to Perform a Two-Way ANOVA in Excel</span></h2>
A  two-way ANOVA  (“analysis of variance”) is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
This tutorial explains how to perform a two-way ANOVA in Excel.
<h3>Example: Two Way ANOVA in Excel</h3>
A botanist wants to know whether or not plant growth is influenced by sunlight exposure and watering frequency. She plants 40 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant. The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova1.png">
In the table above, we see that there were five plants grown under each combination of conditions. For example, there were five plants grown with daily watering and no sunlight and their heights after two months were 4.8 inches, 4.4 inches, 3.2 inches, 3.9 inches, and 4.4 inches:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova2.png">
We can use the following steps to perform a two-way ANOVA on this data:
<b>Step 1: Select the Data Analysis Toolpak.</b>
On the <b>Data </b>tab, click <b>Data Analysis</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
<em>If you don’t see this as an option, you need to first  load the free Data Analysis Toolpak .</em>
<b>2. Choose Anova: Two-Factor With Replication</b>
Select the option that says <b>Anova: Two-Factor With Replication</b>, then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/twoWayExcel1.png">
In this context, “replication” refers to having multiple observations in each group. For example, there were multiple plants that were grown with no sunlight exposure and daily watering. If instead we only grew one plant under each combination of conditions, we would use “without replication”  but our sample size would be much smaller.
<b>3. Fill in the necessary values.</b>
Next, fill in the following values:
<b>Input Range: </b>Select the cell range where our data lies, including the headings.
<b>Rows per sample: </b>Type “5” because there are 5 plants in each sample.
<b>Alpha: </b>Choose a significance level to use. We will choose 0.05.
<b>Output Range: </b>Choose a cell where you would like the output of the two-way ANOVA to appear. We will choose cell $G$4.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova5.jpg">
<b>Step 4: Interpret the output.</b>
Once we click <b>OK</b>, the output of the two-way ANOVA will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova6-1.jpg"626">
The first three tables show summary statistics for each group. For example:
The average height of plants that were watered daily but given no sunlight was <b>4.14 </b>inches.
The average height of plants that were watered weekly and given low sunlight was <b>5.22 </b>inches. 
The average height of all plants that were watered daily was <b>5.115 </b>inches.
The average height of all plants that were watered weekly was <b>5.15 </b>inches.
The average height of all plants that received high sunlight was <b>5.55 </b>inches.
And so on.
The last table shows the result of the two-way ANOVA. We can observe the following:
The p-value for the interaction between watering frequency and sunlight exposure was <b>0.310898</b>. This is not statistically significant at alpha level 0.05.
The p-value for watering frequency was <b>0.975975</b>. This is not statistically significant at alpha level 0.05.
The p-value for sunlight exposure was <b>3.9E-8 (0.000000039)</b>. This is statistically significant at alpha level 0.05.
These results indicate that sunlight exposure is the only factor that has a statistically significant effect on plant height. And because there is no interaction effect, the effect of sunlight exposure is consistent across each level of watering frequency. That is, whether a plant is watered daily or weekly has no impact on how sunlight exposure affects a plant.
<h2><span class="orange">How to Perform a Two-Way ANOVA in SAS</span></h2>
A  two-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two variables (sometimes called “factors”).
This tutorial provides a step-by-step example of how to perform a two-way ANOVA in SAS.
<h3>Step 1: Create the Data</h3>
Suppose a botanist wants to know whether or not plant growth is influenced by sunlight exposure and watering frequency.
She plants 30 seeds and lets them grow for one month under different conditions for sunlight exposure and watering frequency. After one month, she records the height of each plant. The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/anovasas5.jpg"348">
We can use the following code to create this dataset in SAS:
<b>/*create dataset*/
data my_data;
    input water $ sunlight $ height;
    datalines;
daily low 6
daily low 6
daily low 6
daily low 5
daily low 6
daily med 5
daily med 5
daily med 6
daily med 4
daily med 5
daily high 6
daily high 6
daily high 7
daily high 8
daily high 7
weekly low 3
weekly low 4
weekly low 4
weekly low 4
weekly low 5
weekly med 4
weekly med 4
weekly med 4
weekly med 4
weekly med 4
weekly high 5
weekly high 6
weekly high 6
weekly high 7
weekly high 8
;
run;
</b>
<h3>Step 2: Perform the Two-Way ANOVA</h3>
Next, we’ll use <b>proc ANOVA </b>to perform the two-way ANOVA:
<b>/*perform two-way ANOVA*/
proc ANOVA data=my_data;
class water sunlight;
model height = water sunlight water*sunlight;
means water sunlight / tukey cldiff;
run;</b>
<h3>Step 3: Interpret the Results</h3>
The first table we want to analyze in the results is the ANOVA table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/anovasas6.jpg">
From this table we can see:
The p-value for water: <b>.0005</b>
The p-value for sunlight: <b>&lt;.0001</b>
The p-value for the interaction between water and sunlight: .<b>1207</b>
This tells us that both water and sunlight are statistically significant predictors of plant height and that there is no statistically significant interaction effect between water and sunlight.
Next, we can look at the results of the Tukey post-hoc tests to determine which levels of water and sunlight are statistically significantly different.
First, we’ll look at the Tukey post-hoc comparisons for water:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/anovasas7.jpg"414">
From the output we can see that the mean difference in height between plants that were watered daily vs. weekly was <b>1.0667</b> inches.
The 95% confidence interval for the difference in mean height is <b>[.5163, 1.6170]</b>. This means we’re 95% confident that the true difference in mean height between plants watered daily and plants watered weekly is between .5163 inches and 1.6170 inches.
First, we’ll look at the Tukey post-hoc comparisons for sunlight:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/anovasas8.jpg"375">
To tell which group means are different, we must look at which pairwise comparisons have stars (<b>***</b>) next to them.
From the table we can see that the following group means are statistically significantly different:
High sunlight vs. Low sunlight (95% C.I. = [.8844, 2.5156])
High sunlight vs. Medium sunlight (95% C.I. = [1.2844, 2.9156])
<h3>Step 4: Report the Results</h3>
Lastly, we can  report the results  of the two-way ANOVA:
A two-way ANOVA was performed to analyze the effect of watering frequency and sunlight exposure on plant growth.
 
A two-way ANOVA revealed that there was not a statistically significant interaction between the effects of watering frequency and sunlight exposure (p = .1207).
 
Simple main effects analysis showed that watering frequency had a statistically significant effect on plant growth (p = .0005).
 
Simple main effects analysis showed that sunlight exposure also had a statistically significant effect on plant growth (p &lt; .0001).
<h2><span class="orange">How to Perform a Two-Way ANOVA in Python</span></h2>
A  two-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
The purpose of a two-way ANOVA is to determine how two factors impact a response variable, and to determine whether or not there is an interaction between the two factors on the response variable.
This tutorial explains how to conduct a two-way ANOVA in Python.
<h2>Example: Two-Way ANOVA in Python</h2>
A botanist wants to know whether or not plant growth is influenced by sunlight exposure and watering frequency. She plants 30 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant, in inches.
Use the following steps to perform a two-way ANOVA to determine if watering frequency and sunlight exposure have a significant effect on plant growth, and to determine if there is any interaction effect between watering frequency and sunlight exposure.
<b>Step 1: Enter the data.</b>
First, we’ll create a pandas DataFrame that contains the following three variables:
<b>water: </b>how frequently each plant was watered: daily or weekly
<b>sun: </b>how much sunlight exposure each plant received: low, medium, or high
<b>height: </b>the height of each plant (in inches) after two months
<b>import numpy as np
import pandas as pd
#create data
df = pd.DataFrame({'water': np.repeat(['daily', 'weekly'], 15),   'sun': np.tile(np.repeat(['low', 'med', 'high'], 5), 2),   'height': [6, 6, 6, 5, 6, 5, 5, 6, 4, 5,              6, 6, 7, 8, 7, 3, 4, 4, 4, 5,              4, 4, 4, 4, 4, 5, 6, 6, 7, 8]})
#view first ten rows of data 
df[:10]
watersunheight
0dailylow6
1dailylow6
2dailylow6
3dailylow5
4dailylow6
5dailymed5
6dailymed5
7dailymed6
8dailymed4
9dailymed5
</b>
<b>Step 2: Perform the two-way ANOVA.</b>
Next, we’ll perform the two-way ANOVA using the  anova_lm() function  from the statsmodels library:
<b>import statsmodels.api as sm
from statsmodels.formula.api import ols
#perform two-way ANOVA
model = ols('height ~ C(water) + C(sun) + C(water):C(sun)', data=df).fit()
sm.stats.anova_lm(model, typ=2)
           sum_sq  df      F   PR(>F)
C(water) 8.533333 1.016.0000 0.000527
C(sun)        24.866667 2.023.3125 0.000002
C(water):C(sun) 2.466667 2.0 2.3125 0.120667
Residual12.80000024.0    NaN      NaN
</b>
<b>Step 3: Interpret the results.</b>
We can see the following p-values for each of the factors in the table:
<b>water: </b>p-value = .000527
<b>sun: </b>p-value = .0000002
<b>water*sun: </b>p-value = .120667
Since the p-values for water and sun are both less than .05, this means that both factors have a statistically significant effect on plant height.
And since the p-value for the interaction effect (.120667) is not less than .05, this tells us that there is no significant interaction effect between sunlight exposure and watering frequency.
<b>Note: </b>Although the ANOVA results tell us that watering frequency and sunlight exposure have a statistically significant effect on plant height, we would need to perform  post-hoc tests  to determine exactly how different levels of water and sunlight affect plant height.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Python:
 How to Perform a One-Way ANOVA in Python 
 How to Perform a Three-Way ANOVA in Python 
<h2><span class="orange">How to Conduct a Two-Way ANOVA in R</span></h2>
A  two-way ANOVA  (“analysis of variance”) is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
This tutorial explains how to perform a two-way ANOVA in R.
<h3>Example: Two-Way ANOVA in R</h3>
Suppose we want to determine if exercise intensity and gender impact weight loss. In this case, the two factors we’re studying are <em>exercise</em> and <em>gender</em> and the response variable is <em>weight loss, </em>measured in pounds.
We can conduct a two-way ANOVA to determine if exercise and gender impact weight loss and to determine if there is an interaction between exercise and gender on weight loss.
We recruit 30 men and 30 women to participate in an experiment in which we randomly assign 10 of each to follow a program of either no exercise, light exercise, or intense exercise for one month.
The following code creates the data frame we’ll be working with:
<b>#make this example reproducible
set.seed(10)
#create data frame
data &lt;- data.frame(gender = rep(c("Male", "Female"), each = 30),   exercise = rep(c("None", "Light", "Intense"), each = 10, times = 2),   weight_loss = c(runif(10, -3, 3), runif(10, 0, 5), runif(10, 5, 9),                   runif(10, -4, 2), runif(10, 0, 3), runif(10, 3, 8)))
#view first six rows of data frame
head(data)
#  gender exercise weight_loss
#1   Male     None  0.04486922
#2   Male     None -1.15938896
#3   Male     None -0.43855400
#4   Male     None  1.15861249
#5   Male     None -2.48918419
#6   Male     None -1.64738030
#see how many participants are in each group
table(data$gender, data$exercise)
#         Intense Light None
#  Female      10    10   10
#  Male        10    10   10
</b>
<h3>Exploring the Data</h3>
Before we even fit the two-way ANOVA model, we can gain a better understanding of the data by finding the mean and standard deviation of weight loss for each of the six treatment groups using the <b>dplyr </b>package:
<b>#load <em>dplyr </em>package
library(dplyr)
#find mean and standard deviation of weight loss for each treatment group
data %>%
  group_by(gender, exercise) %>%
  summarise(mean = mean(weight_loss),
            sd = sd(weight_loss))
# A tibble: 6 x 4
# Groups:   gender [2]
#  gender exercise   mean    sd
#          
#1 Female Intense   5.31  1.02 
#2 Female Light     0.920 0.835
#3 Female None     -0.501 1.77 
#4 Male   Intense   7.37  0.928
#5 Male   Light     2.13  1.22 
#6 Male   None     -0.698 1.12 
</b>
We can also create a  boxplot  for each of the six treatment groups to visualize the distribution of weight loss for each group:
<b>#set margins so that axis labels on boxplot don't get cut off
par(mar=c(8, 4.1, 4.1, 2.1))
#create boxplots
boxplot(weight_loss ~ gender:exercise,
data = data,
main = "Weight Loss Distribution by Group",
xlab = "Group",
ylab = "Weight Loss",
col = "steelblue",
border = "black", 
las = 2 #make x-axis labels perpendicular
)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/2way_anova.jpg">
Right away we can see that the two groups who participated in <em>intense </em>exercise appear to have greater weight loss values. We can also see that males tend to have higher weight loss values for the <em>intense </em>and <em>light </em>exercise groups compared to females.
Next, we’ll fit the two-way ANOVA model to our data to see if these visual differences are actually statistically significant. 
<h3>Fitting the Two-Way ANOVA Model</h3>
The general syntax to fit a two-way ANOVA model in R is as follows:
<b>aov(response variable ~ predictor_variable1 * predictor_variable2, data = dataset)</b>
Note that the <b>*</b> between the two predictor variables indicates that we also want to test for an interaction effect between the two predictor variables.
In our example, we can use the following code to fit the two-way ANOVA model, using <em>weight_loss </em>as the response variable and <em>gender </em>and <em>exercise </em>as our two predictor variables.
We can then use the <b>summary() </b>function to view the output of our model:
<b>#fit the two-way ANOVA model
model &lt;- aov(weight_loss ~ gender * exercise, data = data)
#view the model output
summary(model)
#                Df Sum Sq Mean Sq F value Pr(>F)    
#gender           1   15.8   15.80  11.197 0.0015 ** 
#exercise         2  505.6  252.78 179.087 &lt;2e-16 ***
#gender:exercise  2   13.0    6.51   4.615 0.0141 *  
#Residuals       54   76.2    1.41                   
#---
#Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</b>
From the model output we can see that <em>gender</em>, <em>exercise</em>, and the interaction between the two variables are all statistically significant at the .05 significance level.
<h3>Checking the Model Assumptions</h3>
Before we go any further, we should check to see that the assumptions of our model are met so that the our results from the model are reliable. In particular, a two-way ANOVA assumes:
<b>1. Independence</b> – the observations in each group need to be independent of each other. Since we used a randomized design, this assumption should be met so we don’t need to worry too much about this.
<b>2. Normality</b> – the dependent variable should be approximately normally distributed for each combination of the groups of the two factors. 
One way to check this assumption is to create a histogram of the model residuals. If the residuals are roughly normally distributed, this assumption should be met.
<b>#define model residuals
resid &lt;- model$residuals</b>
<b>#create histogram of residuals</b>
<b>hist(resid, main = "Histogram of Residuals", xlab = "Residuals", col = "steelblue")</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/2way_anova1.jpg">
The residuals are roughly normally distributed, so we can assume the normality assumption is met.
<b>3. Equal Variance</b> – the variances for each group are equal or approximately equal.
One way to check this assumption is to conduct a Levene’s Test for equality of variances using the <b>car </b>package:
<b>#load <em>car </em>package
library(car)
#conduct Levene's Test for equality of variances
leveneTest(weight_loss ~ gender * exercise, data = data)
#Levene's Test for Homogeneity of Variance (center = median)
#      Df F value Pr(>F)
#group  5  1.8547 0.1177
#      54  
</b>
Since the p-value of the test is greater than our significance level of 0.05, we can assume that our assumption of equality of variances among groups is met.
<h3>Analyzing Treatment Differences</h3>
Once we have verified that the model assumptions are met, we can then conduct a  post hoc test  to determine exactly which treatment groups differ from one another.
For our post hoc test, we will use the function <b>TukeyHSD()</b> to conduct Tukey’s Test for multiple comparisons:
<b>#perform Tukey's Test for multiple comparisons
TukeyHSD(model, conf.level=.95) 
#  Tukey multiple comparisons of means
#    95% family-wise confidence level
#
#Fit: aov(formula = weight_loss ~ gender * exercise, data = data)
#
#$gender
#                diff       lwr      upr     p adj
#Male-Female 1.026456 0.4114451 1.641467 0.0014967
#
#$exercise
#                   diff       lwr       upr   p adj
#Light-Intense -4.813064 -5.718493 -3.907635 0.0e+00
#None-Intense  -6.938966 -7.844395 -6.033537 0.0e+00
#None-Light    -2.125902 -3.031331 -1.220473 1.8e-06
#
#$`gender:exercise`
#                                  diff        lwr         upr     p adj
#Male:Intense-Female:Intense  2.0628297  0.4930588  3.63260067 0.0036746
#Female:Light-Female:Intense -4.3883563 -5.9581272 -2.81858535 0.0000000
#Male:Light-Female:Intense   -3.1749419 -4.7447128 -1.60517092 0.0000027
#Female:None-Female:Intense  -5.8091131 -7.3788841 -4.23934219 0.0000000
#Male:None-Female:Intense    -6.0059891 -7.5757600 -4.43621813 0.0000000
#Female:Light-Male:Intense   -6.4511860 -8.0209570 -4.88141508 0.0000000
#Male:Light-Male:Intense     -5.2377716 -6.8075425 -3.66800066 0.0000000
#Female:None-Male:Intense    -7.8719429 -9.4417138 -6.30217192 0.0000000
#Male:None-Male:Intense      -8.0688188 -9.6385897 -6.49904786 0.0000000
#Male:Light-Female:Light      1.2134144 -0.3563565  2.78318536 0.2185439
#Female:None-Female:Light    -1.4207568 -2.9905278  0.14901410 0.0974193
#Male:None-Female:Light      -1.6176328 -3.1874037 -0.04786184 0.0398106
#Female:None-Male:Light      -2.6341713 -4.2039422 -1.06440032 0.0001050
#Male:None-Male:Light        -2.8310472 -4.4008181 -1.26127627 0.0000284
#Male:None-Female:None       -0.1968759 -1.7666469  1.37289500 0.9990364</b>
The p-value indicates whether or not there is a statistically significant difference between each group. 
For example, in the last row above we see that the male group with no exercise did not experience a statistically significant difference in weight loss compared to the female group with no exercise (p-value: 0.990364).
We can also visualize the 95% confidence intervals that result from the Tukey Test by using the <b>plot()</b> function in R:
<b>#set axis margins so labels don't get cut off
par(mar=c(4.1, 13, 4.1, 2.1))
#create confidence interval for each comparison
plot(TukeyHSD(model, conf.level=.95), las = 2)
</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/2way_anova2.jpg">
<h3>Reporting the Results of the Two-Way ANOVA</h3>
Lastly, we can report the results of the two-way ANOVA in such a way that summarizes the findings:
A two-way ANOVA was conducted to examine the effects of gender (<em>male, female)</em> and exercise regimen <em>(none, light, intense) </em>on weight loss <em>(measure in lbs).</em> There was a statistically significant interaction between the effects of gender and exercise on weight loss (F(2, 54) = 4.615, p = 0.0141). Tukey’s HSD post hoc tests were carried out.
For males, an <em>intense </em>exercise regimen lead to significantly higher weight loss compared to both a <em>light </em>regimen (p &lt; .0001) and <em>no exercise </em>regimen (p &lt; .0001). In addition for males, a <em>light </em>regimen lead to significantly higher weight loss compared to <em>no exercise </em>regimen (p &lt; .0001).
For females, an <em>intense </em>exercise regimen lead to significantly higher weight loss compared to both a <em>light </em>regimen (p &lt; .0001) and <em>no exercise </em>regimen (p &lt; .0001).
Normality checks and Levene’s test were conducted to verify that the ANOVA assumptions were met.
<h2><span class="orange">How to Perform a Two-Way ANOVA in SPSS</span></h2>
A  two-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
The purpose of a two-way ANOVA is to determine how two factors impact a response variable, and to determine whether or not there is an interaction between the two factors on the response variable.
This tutorial explains how to conduct a two-way ANOVA in SPSS.
<h3>Example: Two-Way ANOVA in SPSS</h3>
A botanist wants to know whether or not plant growth is influenced by sunlight exposure and watering frequency. She plants 30 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant, in inches.
The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss1.png">
Use the following steps to perform a two-way ANOVA to determine if watering frequency and sunlight exposure have a significant effect on plant growth, and to determine if there is any interaction effect between watering frequency and sunlight exposure.
<b>Step 1: Perform the two-way ANOVA.</b>
Click the <b>Analyze </b>tab, then <b>General Linear Model</b>, then <b>Univariate</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss2.png">
Drag the response variable <b>height </b>into the box labelled Dependent variable. Drag the two factor variables <b>water </b>and <b>sun </b>into the box labelled Fixed Factor:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss3.png">
Next, click the <b>Plots </b>button. Drag <b>water </b>into the box labelled Horizontal axis and <b>sun </b>into the box labelled Separate lines. Then click <b>Add</b>. The words <b>water*sun </b>will appear in the box labelled Plots. Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss4.png">
Next, click the <b>Post Hoc </b>button. In the new window that pops up, drag the variable <b>sun </b>into the box labelled Post Hoc Tests for. Then check the box next to <b>Tukey</b>. Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss5.png">
Next, click the <b>EM Means </b>button. Drag the following variables into the box labelled Display Means for. Then click <b>Continue</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss6.png">
Lastly, click <b>OK</b>.
<b>Step 2: Interpret the results.</b>
Once you click <b>OK</b>, the results of the two-way ANOVA will appear. Here is how to interpret the results:
<b>Tests of Between-Subjects Effects</b>
The first table displays the p-values for the factors <b>water </b>and <b>sun</b>, along with the interaction effect <b>water*sun</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss7.png">
We can see the following p-values for each of the factors in the table:
<b>water: </b>p-value = .000
<b>sun: </b>p-value = .000
<b>water*sun: </b>p-value = .201
Since the p-value for water and sun are both less than .05, this tells us that both factors have a statistically significant effect on plant height.
And since the p-value for the interaction effect (.201) is not less than .05, this tells us that there is no significant interaction effect between sunlight exposure and watering frequency.
<b>Estimated Marginal Means</b>
The first table displays the means of the observations for each factor:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss8.png">
For example:
The mean height of plants that were watered daily was <b>5.893 </b>inches.
The mean height of plants that received high sunlight exposure was <b>6.62 </b>inches.
The mean height of plants that were watered daily <em>and </em>received high sunlight exposure was <b>6.32 </b>inches.
And so on.
<b>Post Hoc Tests</b>
This table displays the p-values for the Tukey post-hoc comparisons between the three different levels of sunlight exposure.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/anova2spss9.png">
From the table we can see the p-values for the following comparisons:
high vs. low: | p-value = <b>0.000</b>
high vs. medium | p-value = <b>0.000</b>
low vs. medium | p-value = <b>0.447</b>
This tells us that there is a statistically significant difference between high and low sunlight exposure, along with high and medium sunlight exposure, but there is no significant difference between low and medium sunlight exposure.
<b>Step 3: Report the results.</b>
Lastly, we can report the results of the two-way ANOVA. Here is an example of how to do so:
A two-way ANOVA was performed to determine if watering frequency (daily vs. weekly) and sunlight exposure (low, medium, high) had a significant effect on plant growth. A total of 30 plants were used in the study.
 
A two-way ANOVA revealed that watering frequency (p &lt; .000) and sunlight exposure (p &lt; .000) both a statistically significant effect on plant growth.
 
Plants that were watered daily experienced significantly higher growth than plants that were watered weekly.
 
Further, Tukey’s test for multiple comparisons found that plants that received high sunlight exposure had significantly higher growth than plants that received medium and low sunlight exposure. However, there was no significant difference between plants that received medium and low sunlight exposure.
 
There was also no statistically significant interaction effect between watering frequency and sunlight exposure.
<h2><span class="orange">How to Perform a Two-Way ANOVA in Stata</span></h2>
A  two-way ANOVA  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two factors.
The purpose of a two-way ANOVA is to determine how two factors impact a response variable, and to determine whether or not there is an interaction between the two factors on the response variable.
This tutorial explains how to conduct a two-way ANOVA in Stata.
<h2>Example: Two-Way ANOVA in Stata</h2>
In this example we will use the built-in Stata dataset called <em>systolic </em>to perform a two-way ANOVA. This dataset contains the following three variables for 58 different individuals:
Drug used
Patient’s disease
Change in systolic blood pressure
We will use the following steps to perform a two-way ANOVA to find out if the type of drug used and the patient’s disease type has a significant impact in the change in systolic blood pressure.
<b>Step 1: Load the data.</b>
First, load the data by typing <b>webuse systolic </b>in the command box and clicking Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/oneWayStata1.png">
<b>Step 2: View the raw data.</b>
Before we perform a two-way ANOVA, let’s first view the raw data. Along the top menu bar, go to <b>Data > Data Editor > Data Editor (Browse)</b>. This will show us the actual data for all 58 patients:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/oneWayStata2.png">
<b>Step 3: Perform a two-way ANOVA.</b>
Along the top menu bar, go to <b>Statistics > Linear models and related > ANOVA/MANOVA > Analysis of variance and covariance</b>.
For Dependent variable, choose <em>systolic</em>. Then, click the three dots  …  next to the dropdown arrow under <em>Model</em>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/twoWayStata1-1.png">
You will be presented with a new screen. Keep <em>Factor variable </em>selected. For Specification, choose <em>2-way full factorial</em> since we are conducting a two-way ANOVA. For variable 1, choose <em>drug </em>and use <em>Default </em>for the Base. For variable 2, choose <em>disease </em>and use <em>Default </em>for the Base. Then, click <em>Add to varlist </em>at the bottom. Then, click <em>OK</em>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/twoWayStata2.png">
The original window will appear with drug##disease now filled in under <em>Model</em>. You don’t need to do anything here again. Simply click <em>OK</em>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/twoWayStata3.png">
The results of the two-way ANOVA will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/twoWayStata4.png">
From the output we can observe the following:
There is no significant interaction between drug and disease (p-value = 0.3958)
Disease has no significant effect on systolic blood pressure (p-value = 0.1637)
Drug has a statistically significant effect on systolic blood pressure (0.0001)
<b>Step 4: Report the results.</b>
Lastly, we will report the results of our two-way ANOVA analysis. Here is an example of how to do so:
A two-way ANOVA was conducted on 58 individuals to examine the effect that drug and disease has on systolic blood pressure.
 
There was no significant interaction between the effects of drug and disease on systolic blood pressure (p = 0.3958). There was no significant effect of disease on systolic blood pressure (p = 0.1637). There was a significant effect of drug on systolic blood pressure (0.0001). 
<h2><span class="orange">Two-Way ANOVA: Definition, Formula, and Example</span></h2>
A <b>two-way ANOVA</b> (“analysis of variance”) is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups that have been split on two variables (sometimes called “factors”).
This tutorial explains the following:
When to use a two-way ANOVA.
The assumptions that should be met to perform a two-way ANOVA.
An example of how to perform a two-way ANOVA.
<h2>When to Use a Two-Way ANOVA</h2>
You should use a two-way ANOVA when you’d like to know how two factors affect a response variable and whether or not there is an interaction effect between the two factors on the response variable.
For example, suppose a botanist wants to explore how sunlight exposure and watering frequency affect plant growth. She plants 40 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant.
In this case, we have the following variables:
<b>Response variable: </b>plant growth
<b>Factors: </b>sunlight exposure, watering frequency
And we would like to answer the following questions:
Does sunlight exposure affect plant growth?
Does watering frequency affect plant growth?
Is there an interaction effect between sunlight exposure and watering frequency? (e.g. the effect that sunlight exposure has on the plants is dependent on watering frequency)
We would use a two-way ANOVA for this analysis because we have <b>two </b>factors. If instead we wanted to know how only watering frequency affected plant growth, we would use a  one-way ANOVA  since we would only be working with one factor.
<h2>Two-Way ANOVA Assumptions</h2>
For the results of a two-way ANOVA to be valid, the following assumptions should be met:
<b>1. Normality </b>– The response variable is approximately normally distributed for each group.
<b>2. Equal Variances </b>– The variances for each group should be roughly equal.
<b>3. Independence </b>– The observations in each group are independent of each other and the observations within groups were obtained by a random sample.
<h2>Two-Way ANOVA: Example</h2>
A botanist wants to know whether or not plant growth is influenced by sunlight exposure and watering frequency. She plants 40 seeds and lets them grow for two months under different conditions for sunlight exposure and watering frequency. After two months, she records the height of each plant. The results are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova1.png"(max-width: 392px) 100vw, 392px">
In the table above, we see that there were five plants grown under each combination of conditions.
For example, there were five plants grown with daily watering and no sunlight and their heights after two months were 4.8 inches, 4.4 inches, 3.2 inches, 3.9 inches, and 4.4 inches:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova2.png"(max-width: 392px) 100vw, 392px">
She performs a  two-way ANOVA in Excel  and ends up with the following output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/2wayanova6-1.jpg">
The last table shows the result of the two-way ANOVA. We can observe the following:
The p-value for the interaction between watering  frequency and sunlight exposure was <b>0.310898</b>. This is not statistically significant at alpha level 0.05.
The p-value for watering frequency was <b>0.975975</b>. This is not statistically significant at alpha level 0.05.
The p-value for sunlight exposure was <b>3.9E-8 (0.000000039)</b>. This is statistically significant at alpha level 0.05.
These results indicate that sunlight exposure is the only factor that has a statistically significant effect on plant height.
And because there is no interaction effect, the effect of sunlight exposure is consistent across each level of watering frequency.
That is, whether a plant is watered daily or weekly has no impact on how sunlight exposure affects a plant.
<h2>Additional Resources</h2>
The following articles explain how to perform a two-way ANOVA using different statistical software:
 How to Perform a Two-Way ANOVA in Excel 
 How to Perform a Two-Way ANOVA in R 
 How to Perform a Two-Way ANOVA in Python 
 How to Perform a Two-Way ANOVA in SPSS 
 How to Perform a Two-Way ANOVA in Stata 
<h2><span class="orange">How to Create a Two Way Table in R (With Examples)</span></h2>
A <b>two-way table</b> is a type of table that displays the frequencies for two categorical variables.
For example, the following two-way table shows the results of a survey that asked 100 people which sport they liked best: baseball, basketball, or football.
The rows display the gender of the respondent and the columns show which sport they chose:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/jointFreq1.png">
This tutorial provides several examples of how to create and work with two-way tables in R.
<h3>Example 1: Create a Two Way Table from Scratch</h3>
The following code shows how to create a two way table from scratch using the <b>as.table()</b> function:
<b>#create matrix
data &lt;- matrix(c(13, 23, 15, 16, 20, 13), ncol=3)
#specify row and column names of matrix
rownames(data) &lt;- c('Male', 'Female')
colnames(data) &lt;- c('Baseball', 'Basketball', 'Football')
#convert matrix to table
data &lt;- as.table(data)
#display table
data
       Baseball Basketball Football
Male         13         15       20
Female       23         16       13</b>
<h3>Example 2: Create a Two Way Table from Data</h3>
The following code shows how to create a two-way table from a data frame:
<b>#create data frame
df &lt;- data.frame(sport=c('Base', 'Base', 'Bask', 'Foot', 'Foot'), gender=c('Male', 'Female', 'Male', 'Male', 'Female'))
#view data frame 
df
#create two way table from data frame
data &lt;- table(df$gender, df$sport)
#display two way table
data 
         Base Bask Foot
  Female    1    0    1
  Male      1    1    1
</b>
<h3>Example 3: Calculate Margin Sums of a Two Way Table</h3>
The following code shows how to calculate margin sums of a two-way table using the <b>margin.table()</b> function:
<b>#create matrix of data
data &lt;- matrix(c(13, 15, 20, 23, 16, 13), ncol=3)
rownames(data) &lt;- c('Male', 'Female')
colnames(data) &lt;- c('Baseball', 'Basketball', 'Football')
#find sum of genders
margin.table(data, margin=1)
  Male Female 
    49     51
#find sum of sports
margin.table(data, margin=2)
  Baseball Basketball   Football 
        28         43         29 
</b>
<h3>Example 4: Visualize Two Way Table Frequencies</h3>
One way to visualize the frequencies in a two way table is to create a <b>barplot</b>:
<b>barplot(data, legend=True, beside=True, main='Favorite Sport by Gender')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/twoWayTable1.png">
Another way to visualize the frequencies in a two way table is to create a <b>mosaic plot</b>:
<b>mosaicplot(data, main='Sports Preferences', xlab='Gender', ylab='Favorite Sport')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/twoWayTable2.png">
You can find more R tutorials on  this page .
<h2><span class="orange">Type II Error Calculator</span></h2>
A <b>type II error</b> occurs in hypothesis tests when we fail to reject the null hypothesis when it actually is false. The probability of committing this type of error is called the  beta level  of a test, typically denoted as β.
To calculate the beta level for a given test, simply fill in the information below and then click the “Calculate” button.
<label>Mean Under the Null Hypothesis</label>
<input type="number" id="null" value="500">
<label>The True Mean</label>
<input type="number" id="true" value="490">
<label>Standard Deviation</label>
<input type="number" id="s" value="24">
<label>Sample Size</label>
<input type="number" id="n" value="40">
<label>Alpha Level (α)</label>
<input type="number" id="a" value="0.05">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
Beta Level (β): 0.16099
<script>
function calc() {
//get input values
var nullmean = +document.getElementById('null').value;
var truemean = +document.getElementById('true').value;
var s = +document.getElementById('s').value;
var n = +document.getElementById('n').value;
var a = +document.getElementById('a').value;
//calculate z critical value
var z = Math.abs(jStat.normal.inv(a, 0, 1));
//find minimum sample mean
var min_samp = nullmean - z*(s/Math.sqrt(n));
//find beta
var b_hold = (min_samp-truemean) / (s/Math.sqrt(n));
var b = jStat.normal.cdf(10000, 0, 1)-jStat.normal.cdf(b_hold, 0, 1);
//output probabilities
document.getElementById('b').innerHTML = b.toFixed(5);
}
</script>
<h2><span class="orange">How to Fix: TypeError: cannot perform reduce with flexible type</span></h2>
One error you may encounter when using Python is:
<b>ValueError: cannot perform reduce with flexible type
</b>
This error occurs when you attempt to perform some calculation on an object in Python that is not numeric.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following NumPy array:
<b>import numpy as np
#define NumPy array of values
data = np.array(['1', '2', '3', '4', '7', '9', '10', '12'])
#attempt to calculate median of values
np.median(data)
TypeError: cannot perform reduce with flexible type
</b>
We receive a <b>TypeError</b> because we attempted to calculated the median of a list of string values.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply convert the NumPy array to a float object so that we can perform mathematical operations on it.
The following code shows how to do so:
<b>#convert NumPy array of string values to float values
data_new = data.astype(float)
#view updated NumPy array
data_new
array([ 1.,  2.,  3.,  4.,  7.,  9., 10., 12.])
#check data type of array
data_new.dtype
dtype('float64')
</b>
We can now perform mathematical operations on the NumPy array:
<b>#calculate median value of array
np.median(data_new)
5.5
#calculate mean value of array
np.mean(data_new)
6.0
#calculate max value of array
np.max(data_new)
12.0</b>
Notice that we don’t receive any errors because the NumPy array is a float object, which means we can perform mathematical operations on it.
<h2><span class="orange">How to Fix: Typeerror: expected string or bytes-like object</span></h2>
One error you may encounter when using Python is:
<b>TypeError: expected string or bytes-like object
</b>
This error typically occurs when you attempt to use the <b>re.sub()</b> function to replace certain patterns in an object but the object you’re working with is not composed entirely of strings.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following list of values:
<b>#define list of values
x = [1, 'A', 2, 'B', 5, 'C', 'D', 'E']
</b>
Now suppose we attempt to replace each non-letter in the list with an empty string:
<b>import re
#attempt to replace each non-letter with empty string
x = re.sub('[^a-zA-Z]', '', x)
TypeError: expected string or bytes-like object
</b>
We receive an error because there are certain values in the list that are not strings.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to convert the list to a string object by wrapping it in the <b>str()</b> operator:
<b>import re
#replace each non-letter with empty string
x = re.sub('[^a-zA-Z]', '', str(x))
#display results
print(x)
ABCDE
</b>
Notice that we don’t receive an error because we used <b>str()</b> to first convert the list to a string object.
The result is the original list with each non-letter replaced with a blank.
<b>Note</b>: You can find the complete documentation for the <b>re.sub()</b> function  here .
<h2><span class="orange">How to Fix: first argument must be an iterable of pandas objects, you passed an object of type “DataFrame”</span></h2>
One common error you may encounter when using Python is:
<b>TypeError: first argument must be an iterable of pandas objects, you passed an object
           of type "DataFrame"
</b>
This error usually occurs when you attempt to use the <b>concat()</b> function to append two pandas DataFrames together without wrapping the DataFrame names in brackets.
The following example shows how to resolve this error in practice.
<h2>How to Reproduce the Error</h2>
Suppose we have the following two pandas DataFrames:
<b>import pandas as pd
#create first DataFrame
df1 = pd.DataFrame({'x': [25, 14, 16, 27, 20,15, 14],    'y': [5, 7, 7, 5, 7, 6, 9],    'z': [8, 8, 10, 6, 6, 9, 6]})
print(df1)
    x  y   z
0  25  5   8
1  14  7   8
2  16  7  10
3  27  5   6
4  20  7   6
5  15  6   9
6  14  9   6
#create second DataFrame 
df2 = pd.DataFrame({'x': [58, 60, 65],    'y': [14, 22, 23],    'z': [9, 12, 19]})
print(df2)
    x   y   z
0  58  14   9
1  60  22  12
2  65  23  19
</b>
Now suppose we attempt to use the <b>concat()</b> function to append the two DataFrames into one DataFrame:
<b>#attempt to append two DataFrames together
combined = pd.concat(df1, df2, ignore_index=True)
#view final DataFrame
print(combined)
TypeError: first argument must be an iterable of pandas objects, you passed an object
           of type "DataFrame"
</b>
We receive an error because we failed to wrap the DataFrame names in brackets within the <b>concat()</b> function.
<h2>How to Fix the Error</h2>
The way to resolve this error is to simply wrap the DataFrame names in a bracket within the <b>concat()</b> function as follows:
<b>#append two DataFrames together
combined = pd.concat([df1, df2], ignore_index=True)
#view final DataFrame
print(combined)
    x   y   z
0  25   5   8
1  14   7   8
2  16   7  10
3  27   5   6
4  20   7   6
5  15   6   9
6  14   9   6
7  58  14   9
8  60  22  12
9  65  23  19</b>
Notice that we’re able to successfully combine the two DataFrames without any error this time.
<h2>Additional Resources</h2>
The following tutorials explain how to fix other common errors in Python:
 How to Fix in Python: ‘numpy.ndarray’ object is not callable 
 How to Fix: TypeError: ‘numpy.float64’ object is not callable 
 How to Fix: Typeerror: expected string or bytes-like object 
<h2><span class="orange">How to Fix: TypeError: ‘numpy.float64’ object is not callable</span></h2>
One error you may encounter when using Python is:
<b>TypeError: 'numpy.float64' object is not callable
</b>
This error may occur in two different scenarios:
<b>Scenario 1: </b>Multiplication Without Using * Sign
<b>Scenario 2:</b> Failure to Use NumPy Min Function
The following examples shows how to fix this error in each scenario.
<h3>Scenario 1: Multiplication Without Using * Sign</h3>
Suppose we attempt to multiply two NumPy arrays without using a multiplication sign (*) as follows:
<b>import numpy as np
#define arrays
x = np.array([1, 2, 3, 4, 5])
y = np.array([12, 14, 14, 19, 22])
#attempt to multiply two arrays together
combo = (x)(y)
#view result
print(combo)
TypeError: 'numpy.float64' object is not callable 
</b>
We receive a <b>TypeError</b> because we didn’t use the multiplication sign (*) when attempting to multiply the two arrays.
The way to avoid this error is to make sure we used the multiplication sign:
<b>import numpy as np
#define arrays
x = np.array([1, 2, 3, 4, 5])
y = np.array([12, 14, 14, 19, 22])
#multiply two arrays together
combo = (x)*(y)
#view result
print(combo)
[ 12  28  42  76 110]
</b>
Notice that we receive no error this time.
<h3>Scenario 2: Failure to Use NumPy Min Function</h3>
Suppose we use the following code to attempt to find the minimum value of a NumPy array:
<b>import numpy as np
#define array of data
data = np.array([3.3, 4.1, 4, 5.6, 8.1, 9.9, 9.7, 10.2])
#attempt to find minimum value of array
min_val = min(data)
#view minimum value
print(min_val)
TypeError: 'numpy.float64' object is not callable </b>
We receive a <b>TypeError</b> because we used the <b>min()</b> function.
Instead, we need to use <b>np.min()</b> as follows:
<b>import numpy as np
#define array of data
data = np.array([3.3, 4.1, 4, 5.6, 8.1, 9.9, 9.7, 10.2])
#attempt to find minimum value of array
min_val = np.min(data)
#view minimum value
print(min_val)
3.3</b>
Notice that we receive no error this time.
<h2><span class="orange">How to Fix: only integer scalar arrays can be converted to a scalar index</span></h2>
One error you may encounter when using Python is:
<b>TypeError: only integer scalar arrays can be converted to a scalar index</b>
This error usually occurs for one of two reasons:
<b>1.</b> You attempted to perform array indexing on a list.
<b>2.</b> You attempted to concatenate two matrices using incorrect syntax.
The following examples shows how to avoid these errors in both scenarios.
<h3>Example 1: You attempted to perform array indexing on a list.</h3>
Suppose we attempt to use the following code to create a line chart in matplotlib with a legend and labels:
<b>import numpy as np
#create a list of values
data = [3, 5, 5, 7, 8, 10, 12, 14]
#choose 3 random values from list
random_values = np.random.choice(range(len(data)), size=2)
#attempt to use indexing to access elements in list
random_vals = data[random_values.astype(int)]
#view results
random_vals
TypeError: only integer scalar arrays can be converted to a scalar index
</b>
We receive an error because we attempted to use array indexing on a list.
To avoid this error, we must first convert the list to a NumPy array by using <b>np.array()</b> as follows:
<b>import numpy as np
#create a list of values
data = [3, 5, 5, 7, 8, 10, 12, 14]
#choose 3 random values from list
random_values = np.random.choice(range(len(data)), size=2)
#attempt to use indexing to access elements in list
random_vals = np.array(data)[random_values.astype(int)]
#view results
random_vals
array([5, 7])
</b>
This time we’re able to randomly select two values from the list without any errors since we first converted the list to a NumPy array.
<h3>Example 2: You attempted to concatenate two matrices using incorrect syntax.</h3>
Suppose we attempt to use the following code to concatenate two NumPy matrices together:
<b>import numpy as np
#create twoNumPy matrices
mat1 = np.matrix([[3, 5], [5, 7]])
mat2 = np.matrix([[2, 4], [1, 8]])
#attempt to concatenate both matrices
np.concatenate(mat1, mat2)
TypeError: only integer scalar arrays can be converted to a scalar index
</b>
We receive an error because we failed to supply the matrices in the form of a tuple to the <b>concatenate()</b> function.
To avoid this error, we must use double parenthesis to supply the matrices in the form of a tuple to the <b>concatenate()</b> function as follows:
<b>import numpy as np
#create twoNumPy matrices
mat1 = np.matrix([[3, 5], [5, 7]])
mat2 = np.matrix([[2, 4], [1, 8]])
#attempt to concatenate both matrices
np.concatenate((mat1, mat2))
matrix([[3, 5],
        [5, 7],
        [2, 4],
        [1, 8]])
</b>
This time we’re able to concatenate the two matrices without any error.
<h2><span class="orange">How to Fix: TypeError: unsupported operand type(s) for -: ‘str’ and ‘int’</span></h2>
One error you may encounter when using Python is:
<b>TypeError: unsupported operand type(s) for -: 'str' and 'int'
</b>
This error occurs when you attempt to perform subtraction with a string variable and a numeric variable.
The following example shows how to address this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],   'points_for': ['18', '22', '19', '14', '14', '11', '20', '28'],   'points_against': [5, 7, 17, 22, 12, 9, 9, 4]})
#view DataFrame
print(df)
  team points_for  points_against
0    A         18               5
1    B         22               7
2    C         19              17
3    D         14              22
4    E         14              12
5    F         11               9
6    G         20               9
7    H         28               4
#view data type of each column
print(df.dtypes)
team              object
points_for        object
points_against     int64
dtype: object
</b>
Now suppose we attempt to subtract the <b>points_against</b> column from the <b>points_for</b> column:
<b>#attempt to perform subtraction
df['diff'] = df.points_for - df.points_against
TypeError: unsupported operand type(s) for -: 'str' and 'int'
</b>
We receive a <b>TypeError</b> because the <b>points_for</b> column is a string while the <b>points_against</b> column is numeric.
In order to perform subtraction, both columns must be numeric.
<h3>How to Fix the Error</h3>
To resolve this error, we can use <b>.astype(int)</b> to convert the <b>points_for</b> column to an integer before performing the subtraction:
<b>#convert points_for column to integer
df['points_for'] = df['points_for'].astype(int)
#perform subtraction
df['diff'] = df.points_for - df.points_against
#view updated DataFrame
print(df)
  team  points_for  points_against  diff
0    A          18               5    13
1    B          22               7    15
2    C          19              17     2
3    D          14              22    -8
4    E          14              12     2
5    F          11               9     2
6    G          20               9    11
7    H          28               4    24
#view data type of each column
print(df.dtypes)
team              object
points_for         int32
points_against     int64
diff               int64
dtype: object</b>
Notice that we don’t receive an error because both columns we used for the subtraction are numeric columns.
<h2><span class="orange">The 3 Types of Logistic Regression (Including Examples)</span></h2>
<b>Logistic regression</b> refers to any regression model in which the  response variable  is categorical.
There are three types of logistic regression models:
<b>Binary logistic regression</b>: The response variable can only belong to one of two categories.
<b>Multinomial logistic regression</b>: The response variable can belong to one of three or more categories and there is no natural ordering among the categories.
<b>Ordinal logistic regression</b>: The response variable can belong to one of three or more categories and there <em>is</em> a natural ordering among the categories.
The following table summarizes these differences:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/typesLogisticRegression1.png">
This tutorial provides a brief explanation of each type of logistic regression model along with examples of each.
<h3>Type #1: Binary Logistic Regression</h3>
<b>Binary logistic regression models</b> are a type of logistic regression in which the response variable can only belong to two categories.
Here are a couple examples:
<b>Example 1: NBA Draft</b>
Suppose a sports data scientist wants to use the predictor variables (1) points, (2) rebounds, and (3) assists to predict the probability that a given college basketball player gets drafted into the NBA.
Since there are only two possible outcomes (drafted or not drafted) for the response variable, the data scientist would use a binomial logistic regression model.
<b>Example 2: Spam Detection</b>
Suppose a business wants to use the predictor variables (1) word count and (2) country of origin to predict the probability that a given email is spam.
Since there are only two possible outcomes (spam or not spam) for the response variable, the business would use a binomial logistic regression model.
<h3>Type #2: Multinomial Logistic Regression</h3>
<b>Multinomial logistic regression models</b> are a type of logistic regression in which the response variable can belong to one of three or more categories and there is no natural ordering among the categories.
Here are a couple examples:
<b>Example 1: Political Preference</b>
Suppose a political scientist wants to use the predictor variables (1) annual income and (2) years of education to predict the probability that an individual will vote for one of four different presidential candidates.
Since there are more than two possible outcomes (there are four potential candidates) for the response variable and there is no natural ordering among the outcomes, the political scientist would use a multinomial logistic regression model.
<b>Example 2: Sports Preference</b>
Suppose a sports analyst wants to use the predictor variables (1) TV hours viewed per week and (2) age to predict the probability that an individual will pick either basketball, football, or baseball as their preferred sport.
Since there are more than two possible outcomes (there are three sports) for the response variable, the sports analyst would use a multinomial logistic regression model.
<h3>Type #3: Ordinal Logistic Regression</h3>
<b>Ordinal logistic regression models</b> are a type of logistic regression in which the response variable can belong to one of three or more categories and there <em>is</em> a natural ordering among the categories.
Here are a couple examples:
<b>Example 1: School Ratings</b>
Suppose an academic advisor wants to use the predictor variables (1) GPA, (2) ACT score, and (3) SAT score to predict the probability that an individual will get into a university that can be categorized into “bad”, “mediocre”, “good”, or “great.”
Since there are more than two possible outcomes (there are four classifications of school quality) for the response variable and there <em>is</em> a natural ordering among the outcomes, the academic advisor would use an ordinal logistic regression model.
<b>Example 2: Movie Ratings</b>
Suppose a movie critic wants to use the predictor variables (1) total run time and (2) genre to predict the probability that a given movie will receiving a rating between 1 and 10.
Since there are more than two possible outcomes (there are 10 possible ratings) for the response variable and there <em>is</em> a natural ordering among the outcomes, the movie critic would use an ordinal logistic regression model.
<h2><span class="orange">7 Common Types of Regression (And When to Use Each)</span></h2>
<b>Regression analysis</b> is one of the most commonly used techniques in statistics.
The basic goal of regression analysis is to fit a model that best describes the relationship between one or more predictor variables and a  response variable .
In this article we share the 7 most commonly used regression models in real life along with when to use each type of regression.
<h3>1. Linear Regression</h3>
Linear regression is used to fit a regression model that describes the relationship between one or more predictor variables and a numeric response variable.
<b>Use when:</b>
The relationship between the predictor variable(s) and the response variable is reasonably linear.
The response variable is a continuous numeric variable.
<b>Example: </b>A retail company may fit a linear regression model using advertising spend to predict total sales.
Since the relationship between these two variables is likely linear (more money spent on advertising generally leads to an increase in sales) and the response variable (total sales) is a continuous numeric variable, it makes sense to fit a linear regression model.
<b>Resource:</b>  An Introduction to Multiple Linear Regression 
<h3>2. Logistic Regression</h3>
Logistic regression is used to fit a regression model that describes the relationship between one or more predictor variables and a binary response variable.
<b>Use when:</b>
The response variable is binary – it can only take on two values.
<b>Example: </b>Medical researchers may fit a logistic regression model using exercise and smoking habits to predict the likelihood that an individual experiences a heart attack.
Since the response variable (heart attack) is binary – an individual either does or does not have a heart attack – it’s appropriate to fit a logistic regression model.
<b>Resource:</b>  An Introduction to Logistic Regression 
<h3>3. Polynomial Regression</h3>
Polynomial regression is used to fit a regression model that describes the relationship between one or more predictor variables and a numeric response variable.
<b>Use when:</b>
The relationship between the predictor variable(s) and the response variable is non-linear.
The response variable is a continuous numeric variable.
<b>Example: </b>Psychologists may fit a polynomial regression using ‘hours worked’ to predict ‘overall happiness’ of employees in a certain industry.
The relationship between these two variables is likely to be nonlinear. That is, as hours increases an individual may report higher happiness but beyond a certain number of hours worked, overall happiness is likely to decrease. Since this relationship between the predictor variable and response variable is nonlinear, it makes sense to fit a polynomial regression model.
<b>Resource:</b>  An Introduction to Polynomial Regression 
<h3>4. Ridge Regression</h3>
Ridge regression is used to fit a regression model that describes the relationship between one or more predictor variables and a numeric response variable.
<b>Use when:</b>
The predictor variables are highly correlated and  multicollinearity  becomes a problem.
The response variable is a continuous numeric variable.
<b>Example: </b>A basketball data scientist may fit a ridge regression model using predictor variables like points, assists, and rebounds to predict player salary.
The predictor variables are likely to be highly correlated since better players tend to get more points, assists, and rebounds. Thus, multicollinearity is likely to be a problem so we can minimize this problem by using ridge regression.
<b>Resource:</b>  An Introduction to Ridge Regression 
<h3>5. Lasso Regression</h3>
Lasso regression is very similar to ridge regression and is used to fit a regression model that describes the relationship between one or more predictor variables and a numeric response variable.
<b>Use when:</b>
The predictor variables are highly correlated and  multicollinearity  becomes a problem.
The response variable is a continuous numeric variable.
<b>Example: </b>An economist may fit a lasso regression model using predictor variables like total years of schooling, hours worked, and cost of living to predict household income.
The predictor variables are likely to be highly correlated since individuals who receive more schooling also tend to live in cities with higher costs of living and work more hours. Thus, multicollinearity is likely to be a problem so we can minimize this problem by using lasso regression.
Note that Lasso regression and ridge regression are quite similar. When multicollinearity is a problem in a dataset, i’s recommended to fit both a Lasso and Ridge regression model to see which model performs best.
<b>Resource:</b>  An Introduction to Lasso Regression 
<h3>6. Poisson Regression</h3>
Poisson regression is used to fit a regression model that describes the relationship between one or more predictor variables and a response variable.
<b>Use when:</b>
The response variable consists of “count” data – e.g. number of sunny days per week, number of traffic accidents per year, number of calls made per day, etc.
<b>Example: </b>A university may use Poisson regression to examine the number of students who graduate from a specific college program based on their GPA upon entering the program and their gender.
In this case, since the response variable consists of count data (we can “count” the number of students who graduate – 200, 250, 300, 413, etc.) it’s appropriate to use Poisson regression.
<b>Resource:</b>  An Introduction to Poisson Regression 
<h3>7. Quantile Regression</h3>
Quantile regression is used to fit a regression model that describes the relationship between one or more predictor variables and a response variable.
<b>Use when:</b>
We would like to estimate a specific quantile or percentile of the response variable – e.g. the 90th percentile, 95th percentile, etc.
<b>Example: </b>A professor may use quantile regression to predict the expected 90th percentile of exam scores based on the number of hours studied:
In this case, since the professor is interested in predicting a specific percentile of the response variable (exam scores), it’s appropriate to use quantile regression.
<b>Resource:</b>  An Introduction to Quantile Regression 
<h2><span class="orange">How to Handle “undefined columns selected” in R</span></h2>
One of the most common errors that you’ll encounter in R is:
<b>undefined columns selected</b>
This error occurs when you try to select a subset of a data frame and forget to add a comma.
For example, suppose we have the following data frame in R:
<b>#create data frame with three variables
data &lt;- data.frame(var1 = c(0, 4, 2, 2, 5),   var2 = c(5, 5, 7, 8, 9),   var3 = c(2, 7, 9, 9, 7))
#view DataFrame
data
  var1 var2 var3
1    0    5    2
2    4    5    7
3    2    7    9
4    2    8    9
5    5    9    7</b>
Now suppose we attempt to select all rows where <b>var1 </b>is greater than 3:
<b>data[data$var1>3]
Error in `[.data.frame`(data, data$var1 > 3) : undefined columns selected
</b>
We receive an error because we forgot to add a comma after the 3. Once we add the comma, the error will go away:
<b>data[data$var1>3, ]
  var1 var2 var3
2    4    5    7
5    5    9    7</b>
The reason you need to add a comma is because R uses the following syntax for subsetting data frames:
<b>data[rows you want, columns you want]</b>
If you only type <b>data[data$var1>3]</b>, then you’re telling R to return the rows where <b>var1>3</b>, but you’re not telling R which columns to return.
By using <b>data[data$var1>3, ]</b>, you’re telling R to return the rows where <b>var1>3 </b>and <em>all </em>of the columns in the data frame. An equivalent command would be <b>data[data$var1>3, 1:3]</b>.
<b>data[data$var1>3, 1:3]
  var1 var2 var3
2    4    5    7
5    5    9    7</b>
Notice that this command returns the same subset of data as before.
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">Undercoverage Bias: Explanation & Examples</span></h2>
<b>Undercoverage bias </b>is the bias that occurs when some members of a population are inadequately represented in the sample.
This type of bias often occurs in  convenience sampling  and  voluntary response sampling , in which you collect a sample that is easy to obtain but is often prone to undercoverage of certain members of a population.
<h3>Why is Undercoverage Bias a Problem?</h3>
Undercoverage bias is a problem because it causes the sample to be unrepresentative of the population. The point of collecting data for a sample is to obtain data in a way that is quicker and easier than collecting data for an entire population, and to be able to extrapolate the findings from the sample to the larger population.
In order to extrapolate the findings, though, the sample needs to be  representative of our population  as a whole. Ideally we would like our sample to be a “mini” version of the population. Unfortunately, undercoverage bias can cause the people in our sample to be significantly different than the people in the larger population.
For example, suppose researchers want to know what citizens in a certain city think of a potential new law. To collect data, they go to a nearby library and ask people that walk in what they think of the potential new law. Although this is a convenient way to gather data, the researchers risk undercoverage of several types of people, including:
People who are housebound
People who simply don’t like visiting the library
People who go to a different library in a different part of the city
Because this study excludes certain types of people, the results of the study are unlikely to be representative of the population.
For example, suppose the people who go to this particular library are far more likely to be supportive of the potential new law compared to the rest of the population. This means that when the results of the survey are in, it will appear that a large percentage of citizens in this city support the potential new law, when in fact most of the citizens do not.
The visual below illustrates this problem: suppose the green circles represent people who are in favor of the new law while the red circles represent people who are opposed to the new law:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/nonResponseBias.jpg">
Notice how most of the people who are in favor of the new law are included in the sample, yet the sample is not representative of the larger population. The results of the survey would show that most people are in favor of the new law, when in fact this is not true. 
<h2>Examples of Undercoverage Bias</h2>
The following examples illustrate several cases in which undercoverage bias can occur.
<h3>Example 1</h3>
Researchers want to learn what citizens in a certain city think of having a new park built. In order to collect data, researchers attend a local town meeting and ask people there about their thoughts.  Unfortunately, this form of convenience sampling is likely to suffer from undercoverage of the following groups:
People who have no access to transportation to go to the town meetings
People who aren’t even aware of that fact that town meetings take place
People who work in the evenings and are simply unable to attend town meetings
Thus, the opinions of these people will not be included in the results of the study. Because of this undercoverage of these specific groups, the sample is unlikely to be representative of the larger population.
<h3>Example 2</h3>
Researchers want to know how many hours per day people watch TV in a particular county. To collect data for the study, they randomly pick names from a local phonebook and call people to ask them about their TV consumption. This is a form of convenience sampling and it is likely to suffer from undercoverage of the following groups:
Very wealthy people who do not list their phone numbers in local phonebooks
Young people who only use cellphones and do not have their numbers listed in local phonebooks
Thus, the amount of TV that very wealthy people and young people watch will be undercovered in this study. Because of this undercoverage of these specific groups, the sample is unlikely to be representative of the larger population.
<h3>Example 3</h3>
Researchers want to know what citizens in a particular city think of a new traffic law so they give out a questionnaire to people that walk by at a local mall. This is a form of convenience sampling and it’s likely to suffer from undercoverage of the following groups:
People who have no access to transportation to go to the mall (and thus are largely unaffected by traffic laws)
People who don’t like going to the mall (and thus may choose not to drive in busy areas)
People who go to a different mall in a different city
Thus, the opinions of these people will not be included in the results of the study. Because of this undercoverage of these specific groups, the sample is unlikely to be representative of the larger population.
<h2>How to Prevent Undercoverage Bias</h2>
Undercoverage bias often occurs as a result of convenience sampling. To eliminate (or at least minimize) the effects of undercoverage bias, a better form of sampling is using a  simple random sample . 
In this type of sample, every member of a population has an equal chance of being selected to be in the sample.
The benefit of this approach is that simple random samples are usually representative of the population we’re interested in since every member has an equal chance of being included in the sample.
When we use this approach instead of convenience sampling, we can be more confident in our ability to extrapolate the findings from the sample to the larger population since it’s likely that members from every (or nearly every) group in the population are included in the sample.
<h2><span class="orange">Ungrouped Frequency Distribution: Definition & Example</span></h2>
Suppose we conduct a survey in which we ask 15 households how many pets they have in their home. The results are as follows:
<b>1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 6, 7, 8</b>
One way to summarize these results is to create a <b>frequency distribution</b>, which tells us how frequently different values occur in a dataset.
Often we use <b>grouped frequency distributions</b>, in which we create groups of values and then summarize how many observations from a dataset fall into those groups.
Here’s an example of a grouped frequency distribution for our survey data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/ungrouped_freq1.png">
We first created groups of size 2, then we counted how many individual observations from the dataset fell in each group. For example:
7 families had either 1 or 2 pets
3 families had either 3 or 4 pets
3 families had either 5 or 6 pets
2 families had either 7 or 8 pets
Another type of frequency distribution we could create is an <b>ungrouped frequency distribution</b>, which displays the frequency of each individual data value rather groups of data values.
Here’s an example of an ungrouped frequency distribution for our survey data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/ungrouped_freq2.png">
This type of frequency distribution allows us to directly see how often different values occurred in our dataset. For example:
4 families had 1 pet
3 families had 2 pets
2 families had 3 pets
1 family had 4 pets
And so on.
<h3>When to Use Ungrouped Frequency Distributions</h3>
Ungrouped frequency distributions can be useful when you want to see how often each individual value occurs in a dataset.
<b>Note that ungrouped frequency distributions work best with small datasets in which there are only a few unique values.</b>
For example, in our survey data from earlier there were only 8 unique values so it made sense to create an ungrouped frequency distribution.
However, if we had a dataset with hundreds or thousands of unique values, an ungrouped frequency distribution would be incredibly long and difficult to gather information from.
<b>For larger datasets, it makes sense to construct grouped frequency distributions.</b>
<h3>How to Visualize Ungrouped Frequency Distributions</h3>
The easiest way to visualize the values in an ungrouped frequency distribution is to create a <b>frequency polygon</b>, which displays the frequencies of each individual value in a simple chart.
Here’s what a frequency polygon would look like for our sample data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/ungrouped_freq3.png">
This helps us quickly gain an understanding of how often each value occurs in the dataset.
Alternatively, we could create a <b>bar chart</b> to display the exact same data using bars rather than a single line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/ungrouped_freq4.png">
Both charts allow us to quickly understand the distribution of values in our dataset.
<h2><span class="orange">Uniform Distribution Calculator</span></h2>
The <b> uniform distribution </b> is a probability distribution in which every value between an interval from <i>a</i> to <i>b</i> is equally likely to occur.
This calculator finds the probability of obtaining a value between a lower value x<sub>1</sub> and an upper value x<sub>2</sub> on a uniform distribution.
Simply fill in the values below and then click the “Calculate” button.
<label for="a"><b>a (lower limit of distribution)</b></label>
<input type="number" id="a" value="1"><label for="b"><b>b (upper limit of distribution)</b></label>
<input type="number" id="b" value="20"><label for="x1"><b>x<sub>1</sub> (lower value of interest)</b></label>
<input type="number" id="x1" value="2"><label for="x1"><b>x<sub>2</sub> (upper value of interest)</b></label>
<input type="number" id="x2" value="8">
<input type="button" id="button_calc" onclick="calc()" value="Calculate">
<b>Probability: </b> 0.31579
<script>
function calc() {
//get input values
var a  = document.getElementById('a').value*1;
var b = document.getElementById('b').value*1;
var x1 = document.getElementById('x1').value*1;
var x2 = document.getElementById('x2').value*1;
//find probability
var prob = (x2-x1)/(b-a);
//output
document.getElementById('prob').innerHTML = prob.toFixed(5);
}
</script>
<h2><span class="orange">How to Use the Uniform Distribution in Excel</span></h2>
A  uniform distribution  is a probability distribution in which every value between an interval from <em>a </em>to <em>b </em>is equally likely to be chosen.
The probability that we will obtain a value between x<sub>1</sub> and x<sub>2</sub> on an interval from <em>a </em>to <em>b </em>can be found using the formula:
P(obtain value between x<sub>1</sub> and x<sub>2</sub>)  =  (x<sub>2</sub> – x<sub>1</sub>) / (b – a)
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/uniform_pic.jpg" sizes="(max-width: 336px) 100vw, 336px"> 
The uniform distribution has the following properties:
The mean of the distribution is <b>μ</b> = (a + b) / 2
The variance of the distribution is <b>σ<sup>2</sup> </b>= (b – a)<sup>2</sup> / 12
The standard deviation of the distribution is <b>σ</b> = √σ<sup>2</sup>
The following examples show how to calculate probabilities for uniform distributions in Excel.
<b>Note:</b> You can double check the solution to each example below using the  Uniform Distribution Calculator .
<h3>Examples: Uniform Distribution in Excel</h3>
<b>Example 1: </b><i>A bus shows up at a bus stop every 20 minutes. If you arrive at the bus stop, what is the probability that the bus will show up in 8 minutes or less?</i>
<b>Solution:</b>
<li data-slot-rendered-dynamic="true">a: 0 minutes
<li data-slot-rendered-dynamic="true">b: 20 minutes
<li data-slot-rendered-dynamic="true">x<sub>1</sub>: 0 minutes
<li data-slot-rendered-dynamic="true">x<sub>2</sub>: 8 minutes
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/uniformexcel1.png">
The probability that the bus shows up in 8 minutes or less is <b>0.4</b>.
<b>Example 2:</b><i>The weight of a certain species of frog is uniformly distributed between 15 and 25 grams. If you randomly select a frog, what is the probability that the frog weighs between 17 and 19 grams?</i>
<b>Solution:</b>
<li data-slot-rendered-dynamic="true">a: 15 grams
<li data-slot-rendered-dynamic="true">b: 25 grams
<li data-slot-rendered-dynamic="true">x<sub>1</sub>: 17 grams
<li data-slot-rendered-dynamic="true">x<sub>2</sub>: 19 grams
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/uniformexcel2.png">
The probability that the frog weighs between 17 and 19 grams is<b> 0.2</b>.
<b>Example 3: </b><em>The length of an NBA game is uniformly distributed between 120 and 170 minutes. What is the probability that a randomly selected NBA game lasts more than 150 minutes?</em>
<b>Solution:</b>
<li data-slot-rendered-dynamic="true">a: 120 minutes
<li data-slot-rendered-dynamic="true">b: 170 minutes
<li data-slot-rendered-dynamic="true">x<sub>1</sub>: 150 minutes
<li data-slot-rendered-dynamic="true">x<sub>2</sub>: 170 minutes
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/uniformexcel3.png">
The probability that a randomly selected NBA game lasts more than 150 minutes is <b>0.4</b>.
<em>Find more Excel tutorials on  this page .</em>
<h2><span class="orange">How to Use the Uniform Distribution in Python</span></h2>
A  uniform distribution  is a probability distribution in which every value between an interval from <em>a </em>to <em>b </em>is equally likely to be chosen.
The probability that we will obtain a value between x<sub>1</sub> and x<sub>2</sub> on an interval from <em>a </em>to <em>b </em>can be found using the formula:
P(obtain value between x<sub>1</sub> and x<sub>2</sub>)  =  (x<sub>2</sub> – x<sub>1</sub>) / (b – a)
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/uniform_pic.jpg" sizes="(max-width: 336px) 100vw, 336px"> 
To calculate probabilities related to the uniform distribution in Python we can use the  scipy.stats.uniform()  function, which uses the following basic syntax:
<b>scipy.stats.uniform(x, loc, scale)</b>
where:
<b>x</b>: The value of the uniform distribution
<b>loc</b>: The minimum possible value
<b>loc + scale</b>: The maximum possible value
The following examples show how to use this function in practice.
<h3>Example 1</h3>
Suppose a bus shows up at a bus stop every 20 minutes. If you arrive at the bus stop, what is the probability that the bus will show up in 8 minutes or less?
We can use the following code in Python to calculate this probability:
<b>from scipy.stats import uniform
#calculate uniform probability
uniform.cdf(x=8, loc=0, scale=20) - uniform.cdf(x=0, loc=0, scale=20)
0.4</b>
The probability that the bus shows up in 8 minutes or less is <b>0.4</b>.
<h3>Example 2</h3>
The weight of a certain species of frog is uniformly distributed between 15 and 25 grams. If you randomly select a frog, what is the probability that the frog weighs between 17 and 19 grams?
We can use the following code in Python to calculate this probability:
<b>from scipy.stats import uniform
#calculate uniform probability
uniform.cdf(x=19, loc=15, scale=10) - uniform.cdf(x=17, loc=15, scale=10)
0.2</b>
The probability that the frog weighs between 17 and 19 grams is<b> 0.2</b>.
<h3>Example 3</h3>
The length of an NBA game is uniformly distributed between 120 and 170 minutes. What is the probability that a randomly selected NBA game lasts more than 150 minutes?
We can use the following code in Python to calculate this probability:
<b>from scipy.stats import uniform
#calculate uniform probability 
uniform.cdf(x=170, loc=120, scale=50) - uniform.cdf(x=150, loc=120, scale=50)
0.4</b>
The probability that a randomly selected NBA game lasts more than 150 minutes is <b>0.4</b>.
<b>Bonus:</b> You can double check the solution to each example by using the  Uniform Distribution Calculator .
<h2><span class="orange">The Uniform Distribution in R</span></h2>
A  uniform distribution  is a probability distribution in which every value between an interval from <em>a </em>to <em>b </em>is equally likely to be chosen.
The probability that we will obtain a value between x<sub>1</sub> and x<sub>2</sub> on an interval from <em>a </em>to <em>b </em>can be found using the formula:
P(obtain value between x<sub>1</sub> and x<sub>2</sub>)  =  (x<sub>2</sub> – x<sub>1</sub>) / (b – a)
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/uniform_pic.jpg" sizes="(max-width: 336px) 100vw, 336px"> 
The uniform distribution has the following properties:
The mean of the distribution is <b>μ</b> = (a + b) / 2
The variance of the distribution is <b>σ<sup>2</sup> </b>= (b – a)<sup>2</sup> / 12
The standard deviation of the distribution is <b>σ</b> = √σ<sup>2</sup>
<h2>Uniform Distribution in R: Syntax</h2>
The two built-in functions in R we’ll use to answer questions using the uniform distribution are:
<b>dunif(x, min, max) </b>– calculates the probability density function (pdf) for the uniform distribution where <em>x </em>is the value of a random variable, and <em>min </em>and <em>max </em>are the minimum and maximum numbers for the distribution, respectively. 
<b>punif(x, min, max) </b>– calculates the cumulative distribution function (cdf) for the uniform distribution where <em>x </em>is the value of a random variable, and <em>min </em>and <em>max </em>are the minimum and maximum numbers for the distribution, respectively. 
<em>Find the full R documentation for the uniform distribution  here .</em>
<h2>Solving Problems Using the Uniform Distribution in R</h2>
<b>Example 1: </b><i>A bus shows up at a bus stop every 20 minutes. If you arrive at the bus stop, what is the probability that the bus will show up in 8 minutes or less?</i>
<b>Solution:</b> Since we want to know the probability that the bus will show up in 8 minutes or less, we can simply use the punif() function since we want to know the cumulative probability that the bus will show up in 8 minute or less, given the minimum time is 0 minutes and the maximum time is 20 minutes:
<b>punif(8, min=0, max=20)</b>
<b>## [1] 0.4</b>
The probability that the bus shows up in 8 minutes or less is <b>0.4</b>.
<b>Example 2:</b><i>The weight of a certain species of frog is uniformly distributed between 15 and 25 grams. If you randomly select a frog, what is the probability that the frog weighs between 17 and 19 grams?</i>
<b>Solution:</b> To find the solution, we will calculate the cumulative probability of a frog weighing less than 19 pounds, then subtract the cumulative probability of a frog weighing less than 17 pounds using the following syntax:
<b>punif(19, 15, 25) - punif(17, 15, 25)
</b>
<b>## [1] 0.2</b>
Thus, the probability that the frog weighs between 17 and 19 grams is<b> 0.2</b>.
<b>Example 3: </b><em>The length of an NBA game is uniformly distributed between 120 and 170 minutes. What is the probability that a randomly selected NBA game lasts more than 150 minutes?</em>
<b>Solution:</b>  To answer this question, we can use the formula 1 – (probability that the game lasts less than 150 minutes). This is given by:
<b>1 - punif(150, 120, 170)</b>
<b>## [1] 0.4</b>
The probability that a randomly selected NBA game lasts more than 150 minutes is <b>0.4</b>.
<h2><span class="orange">5 Real-Life Examples of the Uniform Distribution</span></h2>
The  uniform distribution  is a probability distribution in which every value between an interval from <em>a</em> to <em>b</em> is equally likely to occur.
In this article we share 5 examples of the uniform distribution in real life.
<h3>Example 1: Guessing a Birthday</h3>
If you walked up to a random person on the street, the probability that their birthday falls on a given date would follow a uniform distribution because each day of the year is equally likely to be their birthday.
For example, there are 365 days in a year so the probability that their birthday is on January 1st would be <b>1/365</b>.
Similarly, the probability that their birthday is on January 2nd is <b>1/365</b>.
Similarly, the probability that their birthday is on January 3rd is <b>1/365</b>.
And so on.
<h3>Example 2: Rolling a Die</h3>
If you roll a die one time, the probability that it falls on a number between 1 and 6 follows a uniform distribution because each number is equally likely to occur.
For example, there are 6 possible numbers the die can land on so the probability that you roll a 1 is <b>1/6</b>.
Similarly, the probability that you roll a 2 is <b>1/6</b>.
Similarly, the probability that you roll a 3 is <b>1/6</b>.
And so on.
<h3>Example 3: Raffle Tickets </h3>
Suppose a basketball stadium holds a raffle in which it will randomly select one seat number out of 10,000 possible seats in the stadium and give the patron in that seat number a prize. The probability that any individual seat is chosen follows a uniform distribution.
For example, if there are 10,000 total seats then the probability that seat “1” will be chosen is <b>1/10,000</b>.
Similarly, the probability that seat “2” is chosen is <b>1/10,000</b>.
Similarly, the probability that seat “3” is chosen is <b>1/10,000</b>.
And so on.
<h3>Example 4: Deck of Cards</h3>
Suppose you randomly select a card from a deck. The probability that the card will be either a spade, heart, club, or diamond follows a uniform distribution because each suit is equally likely to be chosen.
For example, the probability that you choose a spade is <b>1/4</b>.
Similarly, the probability that you choose a heart is <b>1/4</b>. 
Similarly, the probability that you choose a club is <b>1/4</b>. 
Similarly, the probability that you choose a diamond is <b>1/4</b>. 
<h3>Example 5: Spinning a Spinner</h3>
Suppose a spinner is split into three equal parts with the following colors painted on different parts: red, green, and blue. If you spin the spinner one time, the probability that it will land on any given color follows a uniform distribution because the spinner is equally likely to land on each color.
For example, the probability that the spinner lands on red is <b>1/3</b>.
Similarly, the probability that the spinner lands on green is <b>1/3</b>.
Similarly, the probability that the spinner lands on blue is <b>1/3</b>.
<h2><span class="orange">An Introduction to the Uniform Distribution</span></h2>
The <b>uniform distribution</b> is a probability distribution in which every value between an interval from <em>a</em> to <em>b</em> is equally likely to occur.
If a  random variable  <em>X</em> follows a uniform distribution, then the probability that <em>X</em> takes on a value between <em>x<sub>1</sub></em> and <em>x</em><sub>2</sub> can be found by the following formula:
<b>P(x<sub>1</sub> &lt; X &lt; x<sub>2</sub>) = (x<sub>2 </sub>– x<sub>1</sub>) / (b – a)</b>
where:
<b>x<sub>1</sub>:</b> the lower value of interest
<b>x<sub>2</sub>:</b> the upper value of interest
<b>a: </b>the minimum possible value
<b>b: </b>the maximum possible value
For example, suppose the weight of dolphins is uniformly distributed between 100 pounds and 150 pounds.
If we randomly select a dolphin at random, we can use the formula above to determine the probability that the chosen dolphin will weigh between 120 and 130 pounds:
P(120 &lt; X &lt; 130) = (130 – 120) / (150 – 100)
P(120 &lt; X &lt; 130) = 10 / 50
P(120 &lt; X &lt; 130) =<b> 0.2</b>
The probability that the chosen dolphin will weigh between 120 and 130 pounds is <b>0.2</b>.
<h3>Visualizing the Uniform Distribution</h3>
If we create a density plot to visualize the uniform distribution, it would look like the following plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/uniform1.png">
Every value between the lower bound <em>a</em> and upper bound <em>b</em> is equally likely to occur and any value outside of those bounds has a probability of zero.
For example, in our previous example we said the weight of dolphins is uniformly distributed between 100 pounds and 150 pounds. Here’s how to visualize that distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/uniform2.png">
And the probability that a randomly selected dolphin weighs between 120 and 130 pounds can be visualized as follows:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/uniform3.png">
<h3>Properties of the Uniform Distribution</h3>
The uniform distribution has the following properties:
Mean:<b> (a + b) / 2</b>
Median: <b>(a + b) / 2</b>
Standard Deviation: √<b>(b – a)<sup>2</sup> / 12</b>
Variance: <b>(b – a)<sup>2</sup> / 12</b>
For example, suppose the weight of dolphins is uniformly distributed between 100 pounds and 150 pounds.
We could calculate the following properties for this distribution:
Mean weight: (a + b) / 2 = (150 + 100) / 2 = <b>125</b>
Median weight: (a + b) / 2 = (150 + 100) / 2 = <b>125</b>
Standard Deviation of weight: √(150 – 100)<sup>2</sup> / 12 = <b>14.43</b>
Variance of weight: (150 – 100)<sup>2</sup> / 12 =<b> 208.33</b>
<h3>Uniform Distribution Practice Problems</h3>
Use the following practice problems to test your knowledge of the uniform distribution.
<b>Question 1:</b> A bus shows up at a bus stop every 20 minutes. If you arrive at the bus stop, what is the probability that the bus will show up in 8 minutes or less?
<b>Solution 1:</b> The minimum amount of time you’d have to wait is 0 minutes and the maximum amount is 20 minutes. The lower value of interest is 0 minutes and the upper value of interest is 8 minutes.
Thus, we’d calculate the probability as: 
P(0 &lt; X &lt; 8) = (8-0) / (20-0) = 8/20 = <b>0.4</b>.
<b>Question 2:</b> The length of an NBA game is uniformly distributed between 120 and 170 minutes. What is the probability that a randomly selected NBA game lasts more than 155 minutes?
<b>Solution 2:</b> The minimum time is 120 minutes and the maximum time is 170 minutes. The lower value of interest is 155 minutes and the upper value of interest is 170 minutes.
Thus, we’d calculate the probability as: 
P(155 &lt; X &lt; 170) = (170-155) / (170-120) = 15/50 = <b>0.3</b>.
<b>Question 3:</b> The weight of a certain species of frog is uniformly distributed between 15 and 25 grams. If you randomly select a frog, what is the probability that the frog weighs between 17 and 19 grams?
<b>Solution 3:</b> The minimum weight is 15 grams and the maximum weight is 25 grams. The lower value of interest is 17 grams and the upper value of interest is 19 grams.
Thus, we’d calculate the probability as: 
P(17 &lt; X &lt; 19) = (19-17) / (25-15) = 2/10 = <b>0.2</b>.
<b>Note:</b> We can use the  Uniform Distribution Calculator  to check our answers for each of these problems.
<h2><span class="orange">What is a Unimodal Distribution? (Definition & Example)</span></h2>
A <b>unimodal distribution</b> is a probability distribution with one clear peak.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/multimodal3.png">
This is in contrast to a  bimodal distribution , which has two clear peaks:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/multimodal2.png">
This is also in contrast to a  multimodal distribution , which has two or more peaks:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/mulitmodal1.png">
<em><b>Note:</b> A bimodal distribution is just a specific type of multimodal distribution.</em>
<h3>Examples of Unimodal Distributions</h3>
Here are a few examples of unimodal distributions in practice.
<b>Example 1: Birthweight of Babies</b>
It’s well known that the distribution of the weights of newborn babies follows a unimodal distribution with an average around 7.5 lbs. If we create a histogram of baby weights, we’ll see a “peak” at 7.5 lbs with some babies weighing more and some weighing less.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal1-2.png">
<b>Example 2: ACT Scores</b>
The average ACT score for high school students in the U.S. is about a 21 with some students scoring less and some scoring higher. If we create a histogram of ACT scores for all students in the U.S. we’ll see a single “peak” at 21 with some students scoring higher and some scoring lower.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal2.png">
<b>Example 3: Shoe Sizes</b>
The distribution of men’s shoe sizes is a unimodal distribution with a “peak” around 10. If we create a histogram of all shoe sizes for men, we’ll see a single peak at 10 with some men wearing a larger size and some wearing a smaller size.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal3.png">
<h3>Unimodal Distributions in Statistics</h3>
The following probability distributions in statistics are all unimodal distributions:
<b>The Normal Distribution</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/symmetric1.png">
<b>The t-Distribution</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/symmetric4.png">
<b>The Uniform Distribution</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/symmetric3.png">
<b>The Cauchy Distribution</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/symmetric2.png">
Notice that each of these distributions has a single distinct peak.
<h3>How to Analyze Unimodal Distributions</h3>
We often describe unimodal distributions using three different  measures of central tendency :
<b>Mean</b>: The average value
<b>Median</b>: The middle value
<b>Mode</b>: The value that occurs most often
Depending on how  skewed  the distribution is, these three metrics can be in different places.
<b>Left Skewed Distribution:</b> Mean &lt; Median &lt; Mode
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew4.png">
In a left skewed distribution, the mean is less than the median.
<b>Right Skewed Distribution:</b> Mode &lt; Median &lt; Mean
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew6.png">
In a right skewed distribution, the mean is greater than the median.
<b>No Skew:</b> Mean = Median = Mode
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/skew5.png">
In a symmetrical distribution, the mean, median, and mode are all equal.
<h2><span class="orange">Union and Intersection Probability Calculator</span></h2>
<label for="probA"><b>Probability of event A: P(A)</b></label>
<input type="number" id="probA" min="0" value="0.3">
<label for="probB"><b>Probability of event B: P(B)</b></label>
<input type="number" id="probB" min="0" value="0.5">
<input type="button" id="button" onclick="probCalc()" value="Calculate">
<div>
Probability that event A does not occur: P(A’): <b>0.7</b>
<div>
Probability that event B does not occur: P(B’): <b>0.5</b>
<div>
Probability that event A and/or event B occurs P(A∪B): <b>0.65</b>
<div>
Probability that event A and event B both occur P(A∩B): <b>0.15</b>
<div>
Probability that either event A or event B occurs, but not both: <b>0.5</b>
<script>
function probCalc() {
//get input values
var probA = document.getElementById('probA').value;
var probB = document.getElementById('probB').value;
//assign probabilities to variable names
var complementA = 1 - probA;
var complementB = 1 - probB;
var intersection = probA * probB;
var union = probA - (-1*probB) - intersection;
var singleOccur = probA - (-1*probB) - (2*intersection);
//output probabilities
document.getElementById('complementA').innerHTML = complementA.toPrecision();
document.getElementById('complementB').innerHTML = complementB.toPrecision();
document.getElementById('union').innerHTML = union.toPrecision();
document.getElementById('intersection').innerHTML = intersection.toPrecision();
document.getElementById('singleOccur').innerHTML = singleOccur.toPrecision();
}
</script>
<h2><span class="orange">Unit Vector Calculator</span></h2>
A <b>unit vector</b> is a vector that has a length of 1. For any given vector, it’s possible to find the unit vector that has the same direction as the given vector.
For example, suppose a given vector <b>a</b> = (2, 5, -9). To find the unit vector, we first find the magnitude of vector <b>a</b>, which can be found using the formula:
Magnitude of vector <b>a</b> =  √(2<sup>2</sup>+5<sup>2</sup>+ -9<sup>2</sup>) = 10.488.
Next, we divide each of the original vector’s components by the magnitude:
x = 2 / 10.488 = .191
y = 5 / 10.488 = .477
x = -9 / 10.488 = -.858
Thus, the unit vector = (.191, .477, -.858), which has a length of 1 and is along the same direction as the original vector.
To find the unit vector for a given vector, simply enter the coordinates of the original vector below and then click the “Calculate” button.
<label for="equation"><b>Original vector</b></label>
<label for="ax"><b>x</b></label>
<input type="number" id="ax" value="2"><label for="ay"><b>y</b></label>
<input type="number" id="ay" value="5"><label for="az"><b>z</b></label>
<input type="number" id="az" value="-9">
<input type="button" id="button_calc" onclick="calc()" value="Calculate Unit Vector">
<label for="equation"><b>Unit vector</b></label>
<label for="bx"><b>x</b></label>
<input type="number" id="bx" name="bx" value="0.19069252" readonly><label for="by"><b>y</b></label>
<input type="number" id="by" name="by" value="0.47673129" readonly><label for="bz"><b>z</b></label>
<input type="number" id="bz" name="bz" value="-0.85811633" readonly>
<hr id="hr_top">
<b>Explanation:</b>
Magnitude of original vector = √(2<sup>2</sup>+5<sup>2</sup>+-9<sup>2</sup>) = 10.48808848
x = 2 / 10.48808848 = 0.19069252
y = 5 / 10.48808848 = 0.47673129
z = -9 / 10.48808848 = -0.85811633
Unit vector = (0.19069252, 0.47673129, -0.85811633)
<script>
function calc() {
function add(a, b) {
    return a + b;
}
//get input values
var ax = document.getElementById('ax').value*1;
var ay = document.getElementById('ay').value*1;
var az = document.getElementById('az').value*1;
var arr = [ax, ay, az];
var arr_mag = Math.sqrt((arr.map(function(x) { return Math.pow(x, 2); })).reduce(add, 0));
var bx = ax / arr_mag;
var by = ay / arr_mag;
var bz = az / arr_mag;
//output
document.getElementsByName('bx')[0].value = bx.toFixed(8);
document.getElementsByName('by')[0].value = by.toFixed(8);
document.getElementsByName('bz')[0].value = bz.toFixed(8);
document.getElementById('ax_out').innerHTML = ax;
document.getElementById('ay_out').innerHTML = ay;
document.getElementById('az_out').innerHTML = az;
document.getElementById('mag_out').innerHTML = arr_mag.toFixed(8);
document.getElementById('ax_out2').innerHTML = ax;
document.getElementById('ay_out2').innerHTML = ay;
document.getElementById('az_out2').innerHTML = az;
document.getElementById('bx_out').innerHTML = bx.toFixed(8);
document.getElementById('by_out').innerHTML = by.toFixed(8);
document.getElementById('bz_out').innerHTML = bz.toFixed(8);
document.getElementById('mag_out2').innerHTML = arr_mag.toFixed(8);
document.getElementById('mag_out3').innerHTML = arr_mag.toFixed(8);
document.getElementById('mag_out4').innerHTML = arr_mag.toFixed(8);
document.getElementById('bx_out2').innerHTML = bx.toFixed(8);
document.getElementById('by_out2').innerHTML = by.toFixed(8);
document.getElementById('bz_out2').innerHTML = bz.toFixed(8);
}
</script>
<h2><span class="orange">How to Use the Unite Function in R (With Examples)</span></h2>
The <b>unite()</b> function from the  tidyr  package can be used to unite multiple data frame columns into a single column.
This function uses the following basic syntax:
<b>unite(data, col, into, sep)</b>
where:
<b>data</b>: Name of the data frame
<b>col</b>: Name of the new united column
<b>… </b>: Vector of names for the columns to unite
<b>sep</b>: How to join the data in the new united column
The following examples show how to use this function in practice.
<h3>Example 1: Unite Two Columns into One Column</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'A', 'B', 'B', 'C', 'C'), year=c(1, 2, 1, 2, 1, 2), points=c(22, 29, 18, 11, 12, 19), assists=c(2, 3, 6, 8, 5, 2))
#view data frame
df
  player year points assists
1      A    1     22       2
2      A    2     29       3
3      B    1     18       6
4      B    2     11       8
5      C    1     12       5
6      C    2     19       2
</b>
We can use the <b>unite()</b> function to unite the “points” and “assists” columns into a single column:
<b>library(tidyr)
#unite points and assists columns into single column
unite(df, col='points-assists', c('points', 'assists'), sep='-')
  player year points-assists
1      A    1           22-2
2      A    2           29-3
3      B    1           18-6
4      B    2           11-8
5      C    1           12-5
6      C    2           19-2</b>
<h3>Example 2: Unite More Than Two Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df2 &lt;- data.frame(player=c('A', 'A', 'B', 'B', 'C', 'C'),  year=c(1, 2, 1, 2, 1, 2),  points=c(22, 29, 18, 11, 12, 19),  assists=c(2, 3, 6, 8, 5, 2),  blocks=c(2, 3, 3, 2, 1, 0))
#view data frame
df2
  player year points assists blocks
1      A    1     22       2      2
2      A    2     29       3      3
3      B    1     18       6      3
4      B    2     11       8      2
5      C    1     12       5      1
6      C    2     19       2      0</b>
We can use the <b>unite()</b> function to unite the points, assists, and blocks column into a single column:
<b>library(tidyr)
#unite points, assists, and blocks column into single column
unite(df2, col='stats', c('points', 'assists', 'blocks'), sep='/')
  player year   stats
1      A    1  22/2/2
2      A    2  29/3/3
3      B    1  18/6/3
4      B    2  11/8/2
5      C    1  12/5/1
6      C    2  19/2/0</b>
Every column is a variable.
Every row is an observation.
Every cell is a single value.
The tidyr package uses four core functions to create tidy data:
<b>1.</b> The  <b>spread()</b>  function.
<b>2.</b> The  <b>gather()</b>  function.
<b>3.</b> The  <b>separate()</b>  function.
4. The <b>unite()</b> function.
If you can master these four functions, you will be able to create “tidy” data from any data frame.
<h2><span class="orange">How to Perform Univariate Analysis in Excel (With Examples)</span></h2>
The term <b>univariate analysis</b> refers to the analysis of one variable. You can remember this by knowing that the prefix “uni” means “one.”
The most common way to perform univariate analysis is to describe a variable using summary statistics. There are two popular types of summary statistics:
 Measures of central tendency : Numbers that describe the center of a dataset. Examples include:
Mean
Median
Mode
 Measures of dispersion : Numbers that describe the spread of values in a dataset. Examples include:
Standard Deviation
Interquartile Range
Range
The following example explains how to perform univariate analysis in Excel.
<h3>Example: Performing Univariate Analysis in Excel</h3>
Suppose we have the following dataset in Excel that shows the points, assists, and rebounds for 20 different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/univariate1.png">
Now suppose that we’d like to perform univariate analysis on the values in the “Points” column.
We can use the following formulas to calculate various summary statistics for the “Points” variable:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/univariate2.png">
Here’s how to interpret these values for the “Points” variable:
Mean = <b>18.85</b>. This represents the average value.
Median = <b>18.5</b> This represents the “middle” value.
Mode = <b>14</b>. This represents the most frequently occurring value.
Standard Deviation = <b>5.75</b>. This represents the average spread of values from the mean.
Interquartile Range = <b>9.25</b>. This represents the spread of the middle 50% of values.
Range = <b>20</b>. This represents the difference between the largest and smallest value.
By knowing just these summary statistics, we can know a great deal about the distribution of values in the dataset.
<h2><span class="orange">How to Perform Univariate Analysis in Python (With Examples)</span></h2>
The term  univariate analysis  refers to the analysis of one variable. You can remember this because the prefix “uni” means “one.”
There are three common ways to perform univariate analysis on one variable:
<b>1. Summary statistics</b> – Measures the center and spread of values.
<b>2. Frequency table</b> – Describes how often different values occur.
<b>3. Charts</b> – Used to visualize the distribution of values.
This tutorial provides an example of how to perform univariate analysis with the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'points': [1, 1, 2, 3.5, 4, 4, 4, 5, 5, 6.5, 7, 7.4, 8, 13, 14.2],   'assists': [5, 7, 7, 9, 12, 9, 9, 4, 6, 8, 8, 9, 3, 2, 6],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12, 6, 6, 7, 8, 7, 9, 15]})
#view first five rows of DataFrame
df.head()
pointsassistsrebounds
01.0511
11.078
22.0710
33.596
44.0126
</b>
<h3>1. Calculate Summary Statistics</h3>
We can use the following syntax to calculate various summary statistics for the ‘points’ variable in the DataFrame:
<b>#calculate mean of 'points'
df['points'].mean()
5.706666666666667
#calculate median of 'points' 
df['points'].median() 
5.0
#calculate standard deviation of 'points'
df['points'].std() 
3.858287308169384
</b>
<h3>2. Create Frequency Table</h3>
We can use the following syntax to create a frequency table for the ‘points’ variable:
<b>#create frequency table for 'points'
df['points'].value_counts()
4.0     3
1.0     2
5.0     2
2.0     1
3.5     1
6.5     1
7.0     1
7.4     1
8.0     1
13.0    1
14.2    1
Name: points, dtype: int64</b>
This tells us that:
The value <b>4</b> occurs 3 times
The value <b>1</b> occurs 2 times
The value <b>5</b> occurs 2 times
The value <b>2</b> occurs 1 time
And so on.
<b>Related:</b>  How to Create Frequency Tables in Python 
<h3>3. Create Charts</h3>
We can use the following syntax to create a  boxplot  for the ‘points’ variable:
<b>import matplotlib.pyplot as plt
df.boxplot(column=['points'], grid=False, color='black')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/uni11.png">
<b>Related:</b>  How to Create Boxplot from Pandas DataFrame 
We can use the following syntax to create a histogram for the ‘points’ variable:
<b>import matplotlib.pyplot as plt
df.hist(column='points', grid=False, edgecolor='black')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/uni12.png">
<b>Related:</b>  How to Create a Histogram from Pandas DataFrame 
We can use the following syntax to create a  density curve  for the ‘points’ variable:
<b>import seaborn as sns
sns.kdeplot(df['points'])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/uni13.png">
<b>Related:</b>  How to Create a Density Plot in Matplotlib 
Each of these charts give us a unique way to visualize the distribution of values for the ‘points’ variable.
<h2><span class="orange">How to Perform Univariate Analysis in R (With Examples)</span></h2>
The term  univariate analysis  refers to the analysis of one variable. You can remember this because the prefix “uni” means “one.”
There are three common ways to perform univariate analysis on one variable:
<b>1. Summary statistics</b> – Measures the center and spread of values.
<b>2. Frequency table</b> – Describes how often different values occur.
<b>3. Charts</b> – Used to visualize the distribution of values.
This tutorial provides an example of how to perform univariate analysis for the following variable:
<b>#create variable with 15 values
x &lt;- c(1, 1, 2, 3.5, 4, 4, 4, 5, 5, 6.5, 7, 7.4, 8, 13, 14.2)
</b>
<h3>Summary Statistics</h3>
We can use the following syntax to calculate various summary statistics for our variable:
<b>#find mean
mean(x)
[1] 5.706667
#find median
median(x)
[1] 5
#find range
max(x) - min(x)
[1] 13.2
#find interquartile range (spread of middle 50% of values)
IQR(x)
[1] 3.45
#find standard deviation
sd(x)
[1] 3.858287</b>
<h3>Frequency Table</h3>
We can use the following syntax to produce a frequency table for our variable:
<b>#produce frequency table
table(x)
   1    2  3.5    4    5  6.5    7  7.4    8   13  14.2 
   2    1    1    3    2    1    1    1    1    1     1 
</b>
This tells us that:
The value <b>1</b> occurs 2 times
The value <b>2</b> occurs 1 time
The value <b>3.5</b> occurs 1 time
And so on.
<h3>Charts</h3>
We can produce a  boxplot  using the following syntax: 
<b>#produce boxplot
boxplot(x)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uniR1.png">
We can produce a histogram using the following syntax: 
<b>#produce histogram
hist(x)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uniR2.png">
We can produce a  density curve  using the following syntax: 
<b>#produce density curve
plot(density(x))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uniR3.png">
Each of these charts give us a unique way to visualize the distribution of values for our variable.
You can find more R tutorials on  this page .
<h2><span class="orange">What is Univariate Analysis? (Definition & Example)</span></h2>
The term <b>univariate analysis </b>refers to the analysis of one variable. You can remember this because the prefix “uni” means “one.”
The purpose of univariate analysis is to understand the distribution of values for a single variable. You can contrast this type of analysis with the following:
<b> Bivariate Analysis : </b>The analysis of two variables.
<b>Multivariate Analysis: </b>The analysis of two or more variables.
For example, suppose we have the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni1.png">
We could choose to perform univariate analysis on any of the individual variables in the dataset to gain a better understanding of its distribution of values.
For example, we may choose to perform univariate analysis on the variable <b>Household Size</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni2.png">
There are three common ways to perform univariate analysis:
<b>1. Summary Statistics</b>
The most common way to perform univariate analysis is to describe a variable using  summary statistics .
There are two popular types of summary statistics:
<b> Measures of central tendency :</b> these numbers describe where the center of a dataset is located. Examples include the <em>mean </em>and the <em>median</em>.
<b> Measures of dispersion :</b> these numbers describe how spread out the values are in the dataset. Examples include the <em>range</em>, <em>interquartile range</em>, <em>standard deviation</em>, and <em>variance</em>.
<b>2. Frequency Distributions</b>
Another way to perform univariate analysis is to create a  frequency distribution , which describes how often different values occur in a dataset.
<b>3. Charts</b>
Yet another way to perform univariate analysis is to create charts to visualize the distribution of values for a certain variable.
Common examples include:
Boxplots
Histograms
Density Curves
Pie Charts
The following examples show how to perform each type of univariate analysis using the <b>Household Size</b> variable from our dataset mentioned earlier:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni2.png">
<h3>Summary Statistics</h3>
We can calculate the following measures of central tendency for Household Size:
<b>Mean (the average value):</b> 3.8
<b>Median (the middle value):</b> 4
These values give us an idea of where the “center” value is located.
We can also calculate the following  measures of dispersion:
<b>Range (the difference between the max and min):</b> 6
<b>Interquartile Range (the spread of the middle 50% of values):</b> 2.5
<b>Standard Deviation (an average measure of spread):</b> 1.87
These values give us an idea of how spread out the values are for this variable.
<h3>Frequency Distributions</h3>
We can also create the following frequency distribution table to summarize how often different values occur:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni3.png">
This allows us to quickly see that the most frequent household size is <b>4</b>.
<b>Resource:</b> You can use this  Frequency Calculator  to automatically produce a frequency distribution for any variable.
<h3>Charts</h3>
We can create the following charts to help us visualize the distribution of values for Household Size:
<b>1. Boxplot</b>
A  boxplot  is a plot that shows the five-number summary of a dataset.
The five-number summary includes:
The minimum value
The first quartile
The median value
The third quartile
The maximum value
Here’s what a boxplot would look like for the variable Household Size:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni4.png">
<b>Resource:</b> You can use this  Boxplot Generator  to automatically produce a boxplot for any variable.
<b>2. Histogram</b>
A histogram is a type of chart that uses vertical bars to display frequencies. This type of chart is a useful way to visualize the distribution of values in a dataset.
Here’s what a histogram would look like for the variable Household Size:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni5.png">
<b>3. Density Curve</b>
A  density curve  is a curve on a graph that represents the distribution of values in a dataset.
It’s particularly useful for visualizing  the “shape” of a distribution, including whether or not a distribution has  one or more “peaks”  of frequently occurring values and whether or not the distribution is  skewed to the left or the right .
Here’s what a density curve would look like for the variable Household Size:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni6.png">
<b>4. Pie Chart</b>
A pie chart is a type of chart that is shaped like a circle and uses slices to represent proportions of a whole.
Here’s what a pie chart would look like for the variable Household Size:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni7.png">
Depending on the type of data, one of these charts may be more useful for visualizing the distribution of values than the others.
<h2><span class="orange">Univariate vs. Multivariate Analysis: What’s the Difference?</span></h2>
The term <b>univariate analysis </b>refers to the analysis of one variable. You can remember this because the prefix “uni” means “one.”
The term <b>multivariate analysis </b>refers to the analysis of more than one variable. You can remember this because the prefix “multi” means “more than one.”
There are three common ways to perform <b>univariate analysis</b>:
<b>1. Summary Statistics</b>
We can calculate  measures of central tendency  like the mean or median for one variable.
We can also calculate  measures of dispersion  such as the standard deviation for one variable.
<b>2. Frequency Distributions</b>
We can create a  frequency distribution , which describes how often each value occurs for one variable.
<b>3. Charts</b>
We can create charts like boxplots, histograms, density curves, etc. to visualize the distribution of values for one variable.
There are two common ways to perform <b>multivariate analysis</b>:
<b>1. Scatterplot Matrix</b>
We can create a scatterplot matrix, which allows us to visualize the relationship between each pairwise combination of variables in a dataset.
<b>2. Machine Learning Algorithms</b>
We can use a supervised learning algorithm to fit a model like  multiple linear regression  that quantifies the relationship between multiple predictor variables and a response variable.
We can also use an unsupervised learning algorithm like  principal components analysis  to find structure and relationships between multiple variables in a dataset at once.
The following examples show how to perform both univariate and multivariate analysis with the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni1.png">
<b>Note</b>: When you analyze exactly two variables, this is referred to as  bivariate analysis .
<h2>Example: How to Perform Univariate Analysis</h2>
We could choose to perform univariate analysis on any of the individual variables in the dataset.
For example, we may choose to perform univariate analysis on the variable <b>Household Size</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni2.png">
We can calculate the following measures of central tendency for Household Size:
Mean (the average value): 3.8
Median (the middle value): 4
These values give us an idea of where the “center” value is located.
We can also calculate the following  measures of dispersion:
Range (the difference between the max and min): 6
Interquartile Range (the spread of the middle 50% of values): 2.5
Standard Deviation (an average measure of spread): 1.87
These values give us an idea of how spread out the values are for this variable.
We can also create the following frequency distribution table to summarize how often different values occur:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni3.png">
We can also create a boxplot to visualize the distribution of values for household size:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni4.png">
Alternatively, we could create a histogram to visualize the distribution of values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni5.png">
By calculating these metrics and creating these charts, we can gain a strong understanding of how the values are distributed for the variable Household Size.
<h2>Example: How to Perform Multivariate Analysis</h2>
Once again suppose we have the same dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/uni1.png">
One simple form of multivariate analysis we could perform on this dataset is to create a <b>scatterplot matrix</b>, which is a matrix that shows a scatterplot for each pairwise combination of numeric variables in the dataset.
We could create this type of matrix to visualize the relationship between household size, annual income, and number of pets all at once.
<b>Resource</b>: Check out  this tutorial  to see how to create a scatterplot matrix in R.
Another way to perform multivariate analysis on this dataset would be to fit a <b>multiple linear regression model</b>. For example, we could create a regression model that uses household size and number of pets to predict annual income.
<b>Resource</b>: Check out  this tutorial  to see how to perform multiple linear regression in R.
Yet another way to perform multivariate analysis on this dataset would be to perform <b>principal components analysis</b>, which allows us to find an underlying structure in the dataset.
<b>Resource</b>: Check out  this tutorial  to see how to perform principal components analysis in R.
<h2>Conclusion</h2>
Here’s a quick summary of this article:
Univariate analysis is the analysis of one variable.
Multivariate analysis is the analysis of more than one variable.
There are various ways to perform each type of analysis depending on your end goal.
In the real world, we often perform both types of analysis on a single dataset.
Univariate analysis allows us to understand the distribution of values for one variable while multivariate analysis allows us to understand the relationship between several variables.
<h2><span class="orange">Upper and Lower Fence Calculator (With Explanation)</span></h2>
In statistics, the <b>upper and lower fences</b> represent the cut-off values for upper and lower outliers in a dataset. They are calculated as:
Upper fence = Q3 + (1.5*IQR)
Lower fence = Q1 – (1.5*IQR)
where IQR stands for “interquartile range” and represents the difference between the 75th percentile and 25th percentile in a dataset.
This calculator finds the upper and lower fences for a given dataset.
Simply enter a list of comma-separated values for the dataset in the box below, then click the “Calculate” button:
<b>Values:</b>
<textarea id="x" rows="5" cols="40">11, 13, 14, 14, 15, 16, 18, 22, 24, 27, 34, 36, 38, 41, 45</textarea>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
Q1 (First Quartile) = 14.00
Q3 (Third Quartile) = 36.00
IQR (Interquartile Range) = 22.00
Lower Fence = 14.00 – (1.5*22.00) = -19.00
Lower Fence = 36.00 + (1.5*22.00) = 69.00
<script>
function calc() {
//get input data
var x= document.getElementById('x').value.split(',').map(Number);
//calculate stuff
var _median = math.median(x)
var _firstHalf = x.filter(function(f){ return f < _median })
var _secondHalf = x.filter(function(f){ return f > _median })
var Q1 = math.median(_firstHalf);
var Q3 = math.median(_secondHalf);
var IQR = Q3 - Q1;
var lower = Q1 - (1.5*IQR);
var upper = Q3 -(-1*1.5*IQR);
//output stuff
document.getElementById('Q1').innerHTML = Q1.toFixed(2);
document.getElementById('Q3').innerHTML = Q3.toFixed(2);
document.getElementById('IQR').innerHTML = IQR.toFixed(2);
document.getElementById('lower').innerHTML = lower.toFixed(2);
document.getElementById('upper').innerHTML = upper.toFixed(2);
document.getElementById('Q1_out').innerHTML = Q1.toFixed(2);
document.getElementById('IQR_out1').innerHTML = IQR.toFixed(2);
document.getElementById('Q3_out').innerHTML = Q3.toFixed(2);
document.getElementById('IQR_out2').innerHTML = IQR.toFixed(2);
  
} //end calc function
</script>
<h2><span class="orange">Upper and Lower Fences: Definition & Example</span></h2>
In statistics, the <b>upper and lower fences</b> represent the cut-off values for upper and lower outliers in a dataset. They are calculated as:
<b>Lower fence</b> = Q1 – (1.5*IQR)
<b>Upper fence</b> = Q3 + (1.5*IQR)
where IQR stands for “interquartile range” which represents the difference between the 75th percentile (Q3) and 25th percentile (Q1) in a dataset.
An  observation  that lies above the upper fence or below the lower fence is often considered to be an outlier.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/upper_lower_fence2.png">
<h3>Example: Calculating the Upper and Lower Fence</h3>
Suppose we have the following dataset:
<b>Dataset: 11, 13, 14, 14, 15, 16, 18, 22, 24, 27, 34, 36, 38, 41, 45
</b>
We can use the following steps to calculate the upper and lower fence of the dataset:
<b>Step 1: Find Q1 and Q3.</b>
Q1 represents the 25th percentile of the dataset and Q3 represents the 75th percentile. According to the Interquartile Range Calculator, Q1 and Q3 for this dataset are as follows:
<b>Q1:</b> 14
<b>Q3:</b> 36
<b>Step 2: Find the IQR (Interquartile Range).</b>
The interquartile range represents the difference between Q3 and Q1, which is calculated as:
<b>Interquartile Range:</b> Q3 – Q1 = 36 – 14 = 22
<b>Step 3: Find the Upper and Lower Fence</b>
We can use the following formulas to calculate the upper and lower fences:
<b>Lower fence:</b> Q1 – (1.5*IQR) = 14 – (1.5*22) = -19
<b>Upper fence:</b> Q3 + (1.5*IQR) = 36 + (1.5*22) = 69
Since none of the observations in our dataset lie below the lower fence or above the upper fence, none of the observations would be considered outliers.
We can also create a  boxplot  to visualize our distribution of data values along with the upper and lower fences:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/upper_lower_fence1.png">
<h3>Bonus: Upper and Lower Fence Calculator</h3>
Instead of calculating the upper and lower fence of a dataset by hand, feel free to use the  Upper and Lower Fence Calculator :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/fenceCalc1.png">
You can find more helpful statistics calculators on  this page .
<h2><span class="orange">How to Determine if a Probability Distribution is Valid</span></h2>
A <b>probability distribution</b> tells us the probability that a  random variable  takes on certain values. 
In order for a probability distribution to be valid, it must meet two requirements:
<b>1.</b> Each probability must be between 0 and 1.
<b>2.</b> The sum of the probabilities must add up to 1.
If both of these requirements are met, then the probability distribution is valid.
The following examples show how to check if different probability distributions are valid.
<h2>Example 1: Goals Scored in a Soccer Game</h2>
The following probability distribution shows the probability of a certain soccer team scoring a certain number of goals in a game:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/valid1.jpg"276">
Let’s check if this probability distribution meets the two requirements to be valid:
<b>1. Each probability must be between 0 and 1.</b>
We can see that each individual probability is between 0 and 1. 
<b>2. The sum of the probabilities must add up to 1.</b>
We can see that the sum of the probabilities adds up to 1:
Sum = .18 + .34 + .35 + .11 + .02 = 1
Both requirements are met so this probability distribution is <b>valid</b>.
<h2>Example 2: Sales Made in a Month</h2>
The following probability distribution shows the probability that a given salesman will make a certain number of sales in the upcoming month:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/valid2.jpg"279">
Let’s check if this probability distribution meets the two requirements to be valid:
<b>1. Each probability must be between 0 and 1.</b>
We can see that each individual probability is between 0 and 1. 
<b>2. The sum of the probabilities must add up to 1.</b>
We can see that the sum of the probabilities does not add up to 1:
Sum = .44 + .31 + .39 + .06 = 1.2
Both requirements are not met so this probability distribution is <b>not valid</b>.
<h2>Example 3: Number of Battery Failures</h2>
The following probability distribution tells us the probability that a given vehicle experiences a certain number of battery failures during a 10-year span:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/valid3.jpg"286">
Let’s check if this probability distribution meets the two requirements to be valid:
<b>1. Each probability must be between 0 and 1.</b>
We can see that each individual probability is not between 0 and 1.
The last probability in the table is a negative value.
<b>2. The sum of the probabilities must add up to 1.</b>
We can see that the sum of the probabilities does add up to 1:
Sum = .24 + .57 + .22 – .03 = 1
Both requirements are not met so this probability distribution is <b>not valid</b>.
<h2>Additional Resources</h2>
The following tutorials provide additional information about probability distributions:
 How to Find the Mean of a Probability Distribution 
 How to Find the Variance of a Probability Distribution 
 How to Find the Standard Deviation of a Probability Distribution 
<h2><span class="orange">Validation Set vs. Test Set: What’s the Difference?</span></h2>
Whenever we fit a  machine learning algorithm  to a dataset, we typically split the dataset into three parts:
<b>1. Training Set</b>: Used to train the model.
<b>2. Validation Set</b>: Used to optimize model parameters.
<b>3. Test Set</b>: Used to get an unbiased estimate of the final model performance.
The following diagram provides a visual explanation of these three different types of datasets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/test_val1.png">
One point of confusion for students is the difference between the validation set and the test set.
In simple terms, the <b>validation set</b> is used to optimize the model parameters while the <b>test set</b> is used to provide an unbiased estimate of the final model.
It can be shown that the error rate as measured by k-fold cross validation tends to underestimate the true error rate once the model is applied to an unseen dataset.
Thus, we fit the final model to the <b>test set</b> to get an unbiased estimate of what the true error rate will be in the real world.
The following example illustrates the difference between a validation set and a test set in practice.
<h3>Example: Understanding the Difference Between Validation Set & Test Set</h3>
Suppose a real estate investor wants to use (1) number of bedrooms, (2) total square feet, and (3) number of bathrooms to predict the selling price of a given house.
Suppose he has a dataset with this information on 10,000 houses. First, he’ll split up the dataset into a training set of 8,000 houses and a test set of 2,000 houses:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/test_val2.png">
Next, he’ll fit a multiple linear regression model to the dataset four times. Each time he’ll use 6,000 houses for the training set and 2,000 houses for the validation set.
This is known as <b>k-fold cross validation.</b>
The training set is used to train the model and the validation set is used to assess the model performance. Each time he will use a different group of 2,000 houses for the validation set.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/test_val3.png">
He may perform this k-fold cross validation on several different types of regression models to identify the model that has the lowest error (i.e. identify the model that fits the dataset best).
Only once he has identified the best model will he then use the test set of 2,000 houses that he held out at the beginning to get an unbiased estimate of the final model performance.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/test_val4.png">
For example, he might identify a specific type of regression model that has a mean absolute error of <b>8,345</b>. That is, the mean absolute difference between the predicted house price and actual house price is $8,345.
He may then fit this exact regression model to the test set of 2,000 houses that has not yet been used and find that the mean absolute error of the model is <b>8,847</b>.
Thus, the unbiased estimate of the true mean absolute error for the model is $8,847.
<h2><span class="orange">How to Fix: ValueError: All arrays must be of the same length</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: All arrays must be of the same length
</b>
This error occurs when you attempt to create a pandas DataFrame and not every column in the DataFrame has the same length.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create the following pandas DataFrame:
<b>import pandas as pd
#define arrays to use as columns in DataFrame
team = ['A', 'A', 'A', 'A', 'B', 'B', 'B']
position = ['G', 'G', 'F', 'F', 'G', 'G', 'F', 'F']
points = [5, 7, 7, 9, 12, 9, 9, 4]
#attempt to create DataFrame from arrays
df = pd.DataFrame({'team': team,   'position': position,   'points': points})
ValueError: All arrays must be of the same length
</b>
We receive an error that tells us each array does not have the same length.
We can verify this by printing the length of each array:
<b>#print length of each array
print(len(team), len(position), len(points))
7 8 8</b>
We see that the ‘team’ array only has <b>7</b> elements while the ‘position’ and ‘points’ arrays each have <b>8</b> elements.
<h3>How to Fix the Error</h3>
The easiest way to address this error is to simply make sure that each array we use has the same length:
<b>import pandas as pd
#define arrays to use as columns in DataFrame
team = ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B']
position = ['G', 'G', 'F', 'F', 'G', 'G', 'F', 'F']
points = [5, 7, 7, 9, 12, 9, 9, 4]
#create DataFrame from arrays
df = pd.DataFrame({'team': team,   'position': position,   'points': points})
#view DataFrame
df
teamposition points
0AG 5
1AG 7
2AF 7
3AF 9
4BG 12
5BG 9
6BF 9
7BF 4
</b>
Notice that each array has the same length this time.
Thus, when we use the arrays to create the pandas DataFrame we don’t receive an error because each column has the same length.
<h2><span class="orange">How to Fix: ValueError: cannot convert float NaN to integer</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: cannot convert float NaN to integer
</b>
This error occurs when you attempt to convert a column in a pandas DataFrame from a float to an integer, yet the column contains NaN values.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following pandas DataFrame:
<b>import pandas as pd
import numpy as np
#create DataFrame
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, np.nan, 10, 6, 5, np.nan, 9, 12]})
#view DataFrame
df
        pointsassists rebounds
0255 11
1127 NaN
2157 10
3149 6
41912 5
5239 NaN
6259 9
7294 12</b>
Currently the ‘rebounds’ column is of the data type ‘float.’
<b>#print data type of 'rebounds' column
df['rebounds'].dtype
dtype('float64')
</b>
Suppose we attempt to convert the ‘rebounds’ column from a float to an integer:
<b>#attempt to convert 'rebounds' column from float to integer
df['rebounds'] = df['rebounds'].astype(int)
ValueError: cannot convert float NaN to integer 
</b>
We receive a <b>ValueError</b> because the NaN values in the ‘rebounds’ column cannot be converted to integer values.
<h3>How to Fix the Error</h3>
The way to fix this error is to deal with the NaN values before attempting to convert the column from a float to an integer.
We can use the following code to first identify the rows that contain NaN values:
<b>#print rows in DataFrame that contain NaN in 'rebounds' column
print(df[df['rebounds'].isnull()])
   points  assists  rebounds
1      12        7       NaN
5      23        9       NaN
</b>
We can then either drop the rows with NaN values or replace the NaN values with some other value before converting the column from a float to an integer:
<b>Method 1: Drop Rows with NaN Values</b>
<b>#drop all rows with NaN values
df = df.dropna()
#convert 'rebounds' column from float to integer
df['rebounds'] = df['rebounds'].astype(int) 
#view updated DataFrame
df
pointsassistsrebounds
025511
215710
31496
419125
62599
729412
#view class of 'rebounds' column
df['rebounds'].dtype
dtype('int64')
</b>
<b>Method 2: Replace NaN Values</b>
<b>#replace all NaN values with zeros
df['rebounds'] = df['rebounds'].fillna(0)
#convert 'rebounds' column from float to integer
df['rebounds'] = df['rebounds'].astype(int) 
#view updated DataFrame
df
pointsassistsrebounds
025511
11270
215710
31496
419125
52390
62599
729412
#view class of 'rebounds' column
df['rebounds'].dtype
dtype('int64')</b>
Note that both methods allow us to avoid the <b>ValueError</b> and successfully convert the float column to an integer column.
<h2><span class="orange">How to Fix: ValueError: cannot set a row with mismatched columns</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: cannot set a row with mismatched columns
</b>
This error occurs when you attempt to add a new row to a pandas DataFrame but the number of values in the new row doesn’t match the number of columns in the existing DataFrame.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'],   'points': [18, 22, 19, 14, 14, 11, 20, 28, 22],   'assists': [5, 7, 7, 9, 12, 9, 9, 4, 8],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12, 9]})
#view DataFrame
df
teampointsassistsrebounds
0A18511
1B2278
2C19710
3D1496
4E14126
5F1195
6G2099
7H28412
8I2289
</b>
Now suppose we try to append a new row to the end of the DataFrame:
<b>#define new row to append
new_team = ['J', 30]
#append row to DataFrame
df.loc[len(df)] = new_team
#view updated DataFrame
df
ValueError: cannot set a row with mismatched columns
</b>
We receive a <b>ValueError</b> because the new row we’re trying to append only contains two values, but the existing DataFrame has four columns.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to use the <b>append()</b> function to add the new row to the end of the DataFrame, which will automatically fill in missing values with NaN:
The following syntax shows how to use this function in practice:
<b>#define new row to append
new = ['J', 30]
#append row to end of DataFrame
df = df.append(pd.Series(new, index=df.columns[:len(new)]), ignore_index=True)
#view updated DataFrame
df
teampointsassistsrebounds
0A185.011.0
1B227.08.0
2C197.010.0
3D149.06.0
4E1412.06.0
5F119.05.0
6G209.09.0
7H284.012.0
8I228.09.0
9J30NaNNaN
</b>
Notice that we don’t receive any <b>ValueError</b> and the new row has been appended to the end of the DataFrame.
Also notice that both of the missing values in the new row were simply filled in with NaN values.
<h2><span class="orange">How to Fix: if using all scalar values, you must pass an index</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: If using all scalar values, you must pass an index
</b>
This error occurs when you attempt to create a pandas DataFrame by passing all scalar values, yet fail to pass an index as well.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a pandas DataFrame from several scalar values:
<b>import pandas as pd
#define scalar values
a = 1
b = 2
c = 3
d = 4
#attempt to create DataFrame from scalar values
df = pd.DataFrame({'A': a, 'B': b, 'C': c, 'D': d})
ValueError: If using all scalar values, you must pass an index
</b>
We receive an error because we passed only scalar values to the DataFrame, yet failed to pass an index.
<h3>How to Fix the Error</h3>
Here are three methods you can use to fix this error:
<b>Method 1: Transform Scalar Values to List</b>
<b>import pandas as pd
#define scalar values
a = 1
b = 2
c = 3
d = 4
#create DataFrame by transforming scalar values to list
df = pd.DataFrame({'A': [a], 'B': [b], 'C': [c], 'D': [d]})
#view DataFrame
df
        ABCD
01234</b>
<b>Method 2: Pass Scalar Values and Pass Index</b>
<b>import pandas as pd
#define scalar values
a = 1
b = 2
c = 3
d = 4
#create DataFrame by passing scalar values and passing index
df = pd.DataFrame({'A': a, 'B': b, 'C': c, 'D': d}, index=[0])
#view DataFrame
df
        ABCD
01234</b>
<b>Method 3: Place Scalar Values into Dictionary </b>
<b>import pandas as pd
#define scalar values
a = 1
b = 2
c = 3
d = 4
#define dictionary of scalar values
my_dict = {'A':1, 'B':2, 'C':3, 'D':4}
#create DataFrame by passing dictionary wrapped in a list
df = pd.DataFrame([my_dict])
#view DataFrame
df
        ABCD
01234</b>
Notice that each method produces the same DataFrame.
<h2><span class="orange">How to Fix: ValueError: Index contains duplicate entries, cannot reshape</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: Index contains duplicate entries, cannot reshape
</b>
This error usually occurs when you attempt to reshape a pandas DataFrames by using the <b>pivot()</b> function, but there are multiple values in the resulting DataFrame that share the same index values.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],   'position': ['G', 'G', 'F', 'F', 'G', 'G', 'F', 'F'],   'points': [5, 7, 7, 9, 4, 9, 9, 12]})
#view DataFrame
df
        teamposition  points
0AG  5
1AG  7
2AF  7
3AF  9
4BG  4
5BG  9
6BF  9
7BF  12
</b>
Now suppose we attempt to pivot the DataFrame, using <b>team</b> as the rows and <b>position</b> as the columns:
<b>#attempt to reshape DataFrame
df.pivot(index='team', columns='position', values='points')
ValueError: Index contains duplicate entries, cannot reshape
</b>
We receive an error because there are multiple rows in the DataFrame that share the same values for <b>team</b> and <b>position</b>.
Thus, when we attempt to reshape the DataFrame, pandas doesn’t know which <b>points</b> value to display in each cell in the resulting DataFrame.
<h3>How to Fix the Error</h3>
To fix this error, we can use the <b>pivot_table()</b> function with a specific <b>aggfunc</b> argument to aggregate the data values in a certain way.
For example, we can use <b>pivot_table()</b> to create a new DataFrame that uses <b>team</b> as the rows, <b>position</b> as the columns, and the sum of the <b>points</b> values in the cells of the DataFrame:
<b>df.pivot_table(index='team', columns='position', values='points', aggfunc='sum')
position  F G
team
A 1612
B 2113
</b>
Notice that we don’t receive an error this time.
The values in the DataFrame show the sum of <b>points</b> for each combination of <b>team</b> and <b>position</b>.
Note that we could also use a different value for <b>aggfunc</b>, such as the mean:
<b>df.pivot_table(index='team', columns='position', values='points', aggfunc='mean')
position    F  G
team
A  8.06.0
B  10.56.5</b>
By using the <b>aggfunc</b> argument within the <b>pivot_table()</b> function, we’re able to avoid any errors.
<b>Note:</b> You can find the complete documentation for the <b>pivot_table()</b> function  here .
<h2><span class="orange">How to Fix: ValueError: setting an array element with a sequence</span></h2>
One error you may encounter when using Python is:
<b>ValueError: setting an array element with a sequence.
</b>
This error typically occurs when you attempt to cram several numbers into a single position in a NumPy array.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following NumPy array:
<b>import numpy as np
#create NumPy array
data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
</b>
Now suppose we attempt to cram two numbers into the first position of the array:
<b>#attempt to cram values '4' and '5' both into first position of NumPy array
data[0] = np.array([4,5])
ValueError: setting an array element with a sequence.
</b>
The error tells us exactly what we did wrong: We attempted to set one element in the NumPy array with a sequence of values.
In particular, we attempted to cram the values ‘4’ and ‘5’ both into the first position of the NumPy array.
This isn’t possible to do, so we receive an error.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply assign one value into the first position of the array:
<b>#assign the value '4' to the first position of the array
data[0] = np.array([4])
#view updated array
data
array([ 4,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</b>
Notice that we don’t receive any error.
If we actually do want to assign two new values to elements in the array, we need to use the following syntax:
<b>#assign the values '4' and '5' to the first two positions of the array
data[0:2] = np.array([4, 5])
#view updated array
data
array([ 4,  5,  3,  4,  5,  6,  7,  8,  9, 10])</b>
Notice that the first two values were changed in the array while all of the other values remained the same.
<h2><span class="orange">How to Fix in Python: ValueError: Trailing data</span></h2>
One error you may encounter when using Python is:
<b>ValueError: Trailing data
</b>
This error usually occurs when you attempt to import a JSON file into a pandas DataFrame, yet the data is written in lines separated by endlines like ‘<b>\n</b>‘.
The easiest way to fix this error is to simply specify <b>lines=True</b> when importing the data:
<b>df = pd.read_json('my_data.json', lines=True)</b>
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following JSON file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/json1.png">
Now suppose we attempt to import this JSON file into a pandas DataFrame:
<b>#attempt to import JSON file into pandas DataFrame
df = pd.read_json('Documents/DataFiles/my_data.json')
ValueError: Trailing data
</b>
We receive an error because the “Review” item in our JSON file contains <b>\n</b> to represent endlines.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply specify <b>lines=True</b> when importing the data:
<b>#import JSON file into pandas DataFrame
df = pd.read_json('Documents/DataFiles/my_data.json', lines=True)
#view DataFrame
df
IDRatingReview
0A8Great movie.\nI would recommend it.
1B5Mediocre movie.\nWould not recommend it.
2C3Bad movie.\nI would not recommend.
3D7Decent movie.\nI might recommend it.
</b>
Notice that we’re able to successfully import the JSON file into a pandas DataFrame without any errors.
If we’d like to remove the <b>\n</b> endlines from the “Review” column, we can use the following syntax:
<b>#replace \n with empty space in 'Review' column
df['Review'] = df['Review'].str.replace('\n', ' ')
#view updated DataFrame
df
IDRatingReview
0A8Great movie. I would recommend it.
1B5Mediocre movie. Would not recommend it.
2C3Bad movie. I would not recommend.
3D7Decent movie. I might recommend it.
</b>
The <b>\n</b> values are now removed from the “Review” column.
<h2><span class="orange">How to Fix: ValueError: Unknown label type: ‘continuous’</span></h2>
One common error you may encounter in Python is:
<b>ValueError: Unknown label type: 'continuous'
</b>
This error usually occurs when you attempt to use <b>sklearn</b> to fit a  classification model  like  logistic regression  and the values that you use for the response variable are continuous instead of categorical.
The following example shows how to use this syntax in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to use the following code to fit a logistic regression model:
<b>import numpy as np
from sklearn.linear_model import LogisticRegression
#define values for predictor and response variables
x = np.array([[2, 2, 3], [3, 4, 3], [5, 6, 6], [7, 5, 5]])
y = np.array([0, 1.02, 1.02, 0])
#attempt to fit logistic regression model
classifier = LogisticRegression()
classifier.fit(x, y)
ValueError: Unknown label type: 'continuous'
</b>
We receive an error because currently the values for our response variable are continuous.
Recall that a  logistic regression model  requires the values of the response variable to be  categorical  such as:
0 or 1
“Yes” or “No”
“Pass” or “Fail”
Currently our response variable contains continuous values such as <b>0</b> and <b>1.02</b>.
<h3>How to Fix the Error</h3>
The way to resolve this error is to simply convert the continuous values of the response variable to categorical values using the <b>LabelEncoder()</b> function from <b>sklearn</b>:
<b>from sklearn import preprocessing
from sklearn import utils
#convert y values to categorical values
lab = preprocessing.LabelEncoder()
y_transformed = lab.fit_transform(y)
#view transformed values
print(y_transformed)
[0 1 1 0]
</b>
Each of the original values is now encoded as a <b>0</b> or <b>1</b>.
We can now fit the logistic regression model:
<b>#fit logistic regression model
classifier = LogisticRegression()
classifier.fit(x, y_transformed)</b>
This time we don’t receive any error because the response values for the model are categorical.
<h2><span class="orange">How to Calculate Sample & Population Variance in R</span></h2>
The <b>variance </b>is a way to measure  how spread out  data values are around the mean.
The formula to find the variance of a  population  is:
<b>σ<sup>2</sup></b> = Σ (x<sub>i</sub> – μ)<sup>2</sup> / N
where μ is the population mean, x<sub>i</sub> is the i<sup>th</sup> element from the population, N is the population size, and Σ is just a fancy symbol that means “sum.”
The formula to find the variance of a  sample  is:
<b>s<sup>2</sup></b> = Σ (x<sub>i</sub> – x)<sup>2</sup> / (n-1)
where x is the sample mean, x<sub>i</sub> is the i<sup>th</sup> element in the sample, and n is the sample size.
<h3>Example: Calculate Sample & Population Variance in R</h3>
Suppose we have the following dataset in R:
<b>#define dataset
data &lt;- c(2, 4, 4, 7, 8, 12, 14, 15, 19, 22)
</b>
We can calculate the <b>sample variance</b> by using the <b>var()</b> function in R:
<b>#calculate sample variance
var(data)
[1] 46.01111
</b>
And we can calculate the <b>population variance </b>by simply multiplying the sample variance by (n-1)/n as follows:
<b>#determine length of data
n &lt;- length(data)
#calculate population variance
var(data) * (n-1)/n
[1] 41.41
</b>
Note that the population variance will always be smaller than the sample variance.
In practice, we typically calculate sample variances for datasets since it’s unusual to collect data for an entire population.
<h3>Example: Calculate Sample Variance of Multiple Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
data &lt;- data.frame(a=c(1, 3, 4, 4, 6, 7, 8, 12),   b=c(2, 4, 4, 5, 5, 6, 7, 16),   c=c(6, 6, 7, 8, 8, 9, 9, 12))
#view data frame
data
   a  b  c
1  1  2  6
2  3  4  6
3  4  4  7
4  4  5  8
5  6  5  8
6  7  6  9
7  8  7  9
8 12 16 12</b>
We can use the  sapply()  function to calculate the sample variance of each column in the data frame:
<b>#find sample variance of each column
sapply(data, var)
        a         b         c 
11.696429 18.125000  3.839286 
</b>
And we can use the following code to calculate the sample standard deviation of each column, which is simply the square root of the sample variance:
<b>#find sample standard deviation of each column
sapply(data, sd)
       a        b        c 
3.420004 4.257347 1.959410 </b>
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">How to Calculate Variance Inflation Factor (VIF) in R</span></h2>
 Multicollinearity  in regression analysis occurs when two or more predictor variables are highly correlated to each other, such that they do not provide unique or independent information in the regression model.
If the degree of correlation is high enough between variables, it can cause problems when fitting and  interpreting the regression model .
The most common way to detect multicollinearity is by using the variance inflation factor (VIF), which measures the  correlation  and strength of correlation between the predictor variables in a regression model.
The value for VIF starts at 1 and has no upper limit. A general rule of thumb for interpreting VIFs is as follows:
A value of 1 indicates there is no correlation between a given predictor variable and any other predictor variables in the model.
A value between 1 and 5 indicates moderate correlation between a given predictor variable and other predictor variables in the model, but this is often not severe enough to require attention.
A value greater than 5 indicates potentially severe correlation between a given predictor variable and other predictor variables in the model. In this case, the coefficient estimates and p-values in the regression output are likely unreliable.
Note that there are some cases in which high VIF values  can safely be ignored .
<h3>How to Calculate VIF in R</h3>
To illustrate how to calculate VIF for a regression model in R, we will use the built-in dataset <em>mtcars</em>:
<b>#view first six lines of <em>mtcars</em>
head(mtcars)
#                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
#Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
#Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
#Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
#Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
#Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
#Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</b>
First, we’ll fit a regression model using <em>mpg</em> as the response variable and <em>disp</em>, <em>hp</em>, <em>wt</em>, and <em>drat</em> as the predictor variables:
<b>#fit the regression model
model &lt;- lm(mpg ~ disp + hp + wt + drat, data = mtcars)
#view the output of the regression model
summary(model)
#Call:
#lm(formula = mpg ~ disp + hp + wt + drat, data = mtcars)
#
#Residuals:
#    Min      1Q  Median      3Q     Max 
#-3.5077 -1.9052 -0.5057  0.9821  5.6883 
#
#Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
#(Intercept) 29.148738   6.293588   4.631  8.2e-05 ***
#disp         0.003815   0.010805   0.353  0.72675    
#hp          -0.034784   0.011597  -2.999  0.00576 ** 
#wt          -3.479668   1.078371  -3.227  0.00327 ** 
#drat         1.768049   1.319779   1.340  0.19153    
#---
#Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#Residual standard error: 2.602 on 27 degrees of freedom
#Multiple R-squared:  0.8376,Adjusted R-squared:  0.8136 
#F-statistic: 34.82 on 4 and 27 DF,  p-value: 2.704e-10
</b>
We can see from the output that  the R-squared value  for the model is<b> 0.8376</b>.  We can also see that  the overall F-statistic  is <b>34.82</b> and the corresponding p-value is <b>2.704e-10</b>, which indicates that the overall regression model is significant. Also, the predictor variables <em>hp</em> and <em>wt</em> are statistically significant at the 0.05 significance level while <em>disp</em> and <em>drat</em> are not.
Next, we’ll use the <b>vif()</b> function from the <b>car</b> library to calculate the VIF for each predictor variable in the model:
<b>#load the <em>car </em>library
library(car)
#calculate the VIF for each predictor variable in the model
vif(model)
#    disp       hp       wt     drat 
#8.209402 2.894373 5.096601 2.279547 
</b>
We can see that the VIF for both <em>disp</em> and <em>wt</em> are greater than 5, which is potentially concerning.
<h3>Visualizing VIF Values</h3>
To visualize the VIF values for each predictor variable, we can create a simple horizontal bar chart and add a vertical line at 5 so we can clearly see which VIF values exceed 5:
<b>#create vector of VIF values
vif_values &lt;- vif(model)
#create horizontal bar chart to display each VIF value
barplot(vif_values, main = "VIF Values", horiz = TRUE, col = "steelblue")
#add vertical line at 5
abline(v = 5, lwd = 3, lty = 2)</b>
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/vifChart.jpg">
Note that this type of chart would be most useful for a model that has a lot of predictor variables, so we could easily visualize all of the VIF values at once. It is still a useful chart in this example, though.
Depending on what value of VIF you deem to be too high to include in the model, you may choose to remove certain predictor variables and see if the corresponding  R-squared value  or  standard error  of the model is affected.
<h3>Visualizing Correlations Between Predictor Variables</h3>
To gain a better understanding of why one predictor variable may have a high VIF value, we can create a correlation matrix to view the linear correlation coefficients between each pair of variables:
<b>#define the variables we want to include in the correlation matrix
data &lt;- mtcars[ , c("disp", "hp", "wt", "drat")]
#create correlation matrix
cor(data)
#           disp         hp         wt       drat
#disp  1.0000000  0.7909486  0.8879799 -0.7102139
#hp    0.7909486  1.0000000  0.6587479 -0.4487591
#wt    0.8879799  0.6587479  1.0000000 -0.7124406
#drat -0.7102139 -0.4487591 -0.7124406  1.0000000
</b>
Recall that the variable <em>disp </em>had a VIF value over 8, which was the largest VIF value among all of the predictor variables in the model. From the correlation matrix we can see that <em>disp </em>is strongly correlated with all three of the other predictor variables, which explains why it has such a high VIF value.
In this case, you may want to remove <em>disp </em>from the model because it has a high VIF value <em>and </em>it was not statistically significant at the 0.05 significance level.
Note that a correlation matrix and a VIF will provide you with similar information: they both tell you when one variable is highly correlated with one or more other variables in a regression model.
<b>Further Reading:</b>
<b> A Guide to Multicollinearity & VIF in Regression 
 What is a Good R-squared Value? </b>
<h2><span class="orange">How to Find the Variance of Grouped Data (With Example)</span></h2>
Often we may want to calculate the  variance  of a grouped frequency distribution.
For example, suppose we have the following grouped frequency distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/mean_sd_grouped1.png">
While it’s not possible to calculate the exact variance since we don’t know the  raw data values , it is possible to estimate the variance using the following formula:
<b>Variance:</b> Σn<sub>i</sub>(m<sub>i</sub>-μ)<sup>2</sup> / (N-1)
where:
<b>n<sub>i</sub>:</b> The frequency of the i<sup>th</sup> group
<b>m<sub>i</sub>:</b> The midpoint of the i<sup>th</sup> group
<b>μ</b>: The mean
<b>N:</b> The total sample size
<b>Note:</b> The  midpoint  for each group can be found by taking the average of the lower and upper value in the range. For example, the midpoint for the first group is calculated as: (1+10) / 2 = 5.5.
The following example shows how to use this formula in practice.
<h3>Example: Calculate the Variance of Grouped Data</h3>
Suppose we have the following grouped data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/mean_sd_grouped1.png">
Here’s how we would use the formula mentioned earlier to calculate the variance of this grouped data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/vargroup1.jpg">
We would then calculate the variance as:
<b>Variance:</b> Σn<sub>i</sub>(m<sub>i</sub>-μ)<sup>2</sup> / (N-1)
<b>Variance</b>: (604.82 + 382.28 + 68.12 + 477.04 + 511.21) / (23-1)
<b>Variance</b>: 92.885
The variance of the dataset turns out to be <b>92.885</b>.
<h2><span class="orange">How to Calculate the Variance of a Probability Distribution</span></h2>
A probability distribution tells us the probability that a  random variable  takes on certain values.
For example, the following probability distribution tells us the probability that a certain soccer team scores a certain number of goals in a given game:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist1.png">
To find the <b>variance </b>of a probability distribution, we can use the following formula:
<b>σ<sup>2</sup> = Σ(x<sub>i</sub>-μ)<sup>2</sup> * P(x<sub>i</sub>)</b>
where:
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value
<b>μ:</b> The mean of the distribution
<b>P(x<sub>i</sub>):</b> The probability of the i<sup>th</sup> value
For example, consider our probability distribution for the soccer team:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist1.png">
The mean number of goals for the soccer team would be calculated as:
μ = 0*0.18  +  1*0.34  +  2*0.35  +  3*0.11  +  4*0.02  =  <b>1.45</b> goals.
We could then calculate the variance as:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sdDist1.png">
The variance is simply the sum of the values in the third column. Thus, we would calculate it as:
σ<sup>2</sup> = .3785 + .0689 + .1059 + .2643 + .1301 = <b>0.9475</b>
The following examples show how to calculate the variance of a probability distribution in a few other scenarios.
<h3>Example 1: Variance of Vehicle Failures</h3>
The following probability distribution tells us the probability that a given vehicle experiences a certain number of battery failures during a 10-year span:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist2.png">
To find the variance of this probability distribution, we need to first calculate the mean number of expected failures:
μ = 0*0.24  +  1*0.57  +  2*0.16  +  3*0.03 =  <b>0.98 </b>failures.
We could then calculate the variance as:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sdDist2.png">
The variance is the sum of the values in the third column. Thus, we would calculate it as:
σ<sup>2</sup> = .2305 + .0002 + .1665 + .1224 = <b>0.5196</b>
<h3>Example 2: Variance of Sales</h3>
The following probability distribution tells us the probability that a given salesman will make a certain number of sales in the upcoming month:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/meanDist4.png">
To find the variance of this probability distribution, we need to first calculate the mean number of expected sales:
μ = 10*.24  +  20*.31  +  30*0.39  +  40*0.06  =  <b>22.7 </b>sales.
We could then calculate the variance as:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sdDist3.png">
The variance is the sum of the values in the third column. Thus, we would calculate it as:
σ<sup>2</sup> = 38.7096 + 2.2599 + 20.7831 + 17.9574 =<b> 79.71</b>
Note that we could also use the  Probability Distribution Calculator  to automatically calculate the variance of this distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/stdProb1.png">
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/stdProb2.png">
The variance is <b>79.71</b>. This matches the value that we calculated by hand.
<h2><span class="orange">How to Perform a Variance Ratio Test in Excel</span></h2>
A <b>variance ratio test</b> is used to test whether or not two population variances are equal.
This test uses the following null and alternative hypotheses:
<b>H<sub>0</sub></b>: The population variances are equal
<b>H<sub>A</sub></b>: The population variances are not equal
To perform this test, we calculate the following test statistic:
<b>F</b> = s<sub>1</sub><sup>2</sup> / s<sub>2</sub><sup>2</sup>
where:
<b>s<sub>1</sub><sup>2</sup></b>: The sample variance of the first group
<b>s<sub>2</sub><sup>2</sup></b>: The sample variance of the second group
If the  p-value  that corresponds to this F test-statistic is less than a certain threshold (e.g. 0.05) then we reject the null hypothesis and conclude that the population variance are not equal.
The following step-by-step example shows how to perform a variance ratio test in Excel.
<h2>Step 1: Enter the Data</h2>
Suppose we want to know if two different species of plants have the same variance in height.
To test this, we collect a  simple random sample  of 15 plants from each species.
First, we’ll enter the heights for each species:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/vartest1.jpg"426">
<h2>Step 2: Calculate the F Test Statistic</h2>
Next, we’ll type the following formula into cell <b>E1</b> to calculate the F test-statistic:
<b>=VAR.S(A2:A16)/VAR.S(B2:B16)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/vartest2.jpg"501">
The F test-statistic turns out to be <b>0.437178</b>.
<h2>Step 3: Calculate the P-Value</h2>
Next, we’ll type the following formula into cell <b>E2 </b>to calculate the p-value that corresponds to the F test-statistic:
<b>=F.DIST(E1, COUNT(A2:A16)-1, COUNT(B2:B16)-1, TRUE)*2</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/vartest3.jpg">
<b>Note</b>: In the formula, we multiplied by 2 at the end to produce a two-tailed p-value.
The p-value turns out to be <b>0.133596</b>.
Recall the null and alternative hypotheses for this test:
<b>H<sub>0</sub></b>: The population variances are equal
<b>H<sub>A</sub></b>: The population variances are not equal
Because the p-value of our test<b> (.133596) </b>is not less than 0.05, we fail to reject the null hypothesis.
This means we do not have sufficient evidence to conclude that the variance in plant height between the two species is unequal.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Perform a Correlation Test in Excel 
 How to Perform Welch’s t-test in Excel 
 How to Perform a Kolmogorov-Smirnov Test in Excel 
<h2><span class="orange">How to Perform a Variance Ratio Test in R (With Example)</span></h2>
A <b>variance ratio test</b> is used to test whether or not two population variances are equal.
This test uses the following null and alternative hypotheses:
<b>H<sub>0</sub></b>: The population variances are equal
<b>H<sub>A</sub></b>: The population variances are not equal
To perform this test, we calculate the following test statistic:
<b>F</b> = s<sub>1</sub><sup>2</sup> / s<sub>2</sub><sup>2</sup>
where:
<b>s<sub>1</sub><sup>2</sup></b>: The sample variance of the first group
<b>s<sub>2</sub><sup>2</sup></b>: The sample variance of the second group
If the  p-value  that corresponds to this F test-statistic is less than a certain threshold (e.g. 0.05) then we reject the null hypothesis and conclude that the population variance are not equal.
To perform a variance ratio test in R, we can use the built-in <b>var.test()</b> function.
The following example shows how to use this function in practice.
<h2>Example: Variance Ratio Test in R</h2>
Suppose we want to know if two different species of plants have the same variance in height.
To test this, we collect a  simple random sample  of 15 plants from each species.
The following code shows how to perform a variance ratio test in R to determine if the variance in height is equal between the two species:
<b>#create vectors to hold plant heights from each sample
group1 &lt;- c(5, 6, 6, 8, 10, 12, 12, 13, 14, 15, 15, 17, 18, 18, 19)
group2 &lt;- c(9, 9, 10, 12, 12, 13, 14, 16, 16, 19, 22, 24, 26, 29, 29)
#perform variance ratio test
var.test(group1, group2)
F test to compare two variances
data:  group1 and group2
F = 0.43718, num df = 14, denom df = 14, p-value = 0.1336
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.1467737 1.3021737
sample estimates:
ratio of variances 
         0.4371783 </b>
Here’s how to interpret the results of the test:
<b>data:</b> The names of the vectors that contain the sample data.
<b>F:</b> The F test-statistic. In this case, it is <b>0.43718</b>.
<b>num df, denom df</b>: The degrees of freedom numerator and denominator for the F test-statistic, calculated as n<sub>1</sub> – 1 and n<sub>2</sub>-1, respectively.
<b>p-value:</b> The p-value that corresponds to the F test-statistic of 0.43718 with numerator df  = 14 and denominator df = 14. The p-value turns out to be <b>.1336</b>.
<b>95 percent confidence interval:</b> The 95% confidence interval for the true ratio of variances between the two groups. It turns out to be <b>[.147, 1.302]</b>. Since 1 is contained in this interval, it’s plausible for the true ratio of variances to be 1, i.e. equal variances.
<b>sample estimates:</b> This represents the ratio of variances between each group. If we use the <b>var()</b> function, we can find that the sample variance of the first group is 21.8381 and the sample variance of the second group is 49.95238 . Thus, the ratio of variances is 21.8381 / 49.95238 = <b>0.4371783</b>.
Recall the null and alternative hypotheses for this test:
<b>H<sub>0</sub></b>: The population variances are equal
<b>H<sub>A</sub></b>: The population variances are not equal
Because the p-value of our test<b> (.1336) </b>is not less than 0.05, we fail to reject the null hypothesis.
This means we do not have sufficient evidence to conclude that the variance in plant height between the two species is unequal.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Perform a One Sample T-Test in R 
 How to Perform Welch’s T-Test in R 
 How to Perform a Paired Samples T-Test in R 
<h2><span class="orange">VAR.P vs. VAR.S in Excel: What’s the Difference?</span></h2>
There are three different functions you can use to calculate variance in Excel:
<b>1. VAR.P:</b> This function calculates the population variance. Use this function when the range of values represents the entire population.
This function uses the following formula:
Population variance = Σ(x<sub>i</sub> – μ)<sup>2</sup> / N
where:
<b>Σ:</b> A greek symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value in the dataset
<b>μ:</b> The population mean
<b>N:</b> The total number of observations
<b>2. VAR.S:</b> This function calculates the sample variance. Use this function when the range of values represents a sample of values, rather than an entire population.
This function uses the following formula:
Sample variance = Σ(x<sub>i</sub> – x)<sup>2</sup> / (n-1)
where:
<b>Σ:</b> A greek symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value in the dataset
<b> x:</b> The sample mean
<b>N:</b> The total number of observations
<b>3. VAR:</b> This function calculates the sample variance as well. It will return the exact same value as the <b>VAR.S</b> function.
<b>Technical Note:</b>
 
Since the formula for the population variance divides by <em>N</em> instead of <em>n-1</em>, the population variance will always be smaller than the sample variance.
 
The reason the population variance will be smaller is because if we know every value in the population, then we know the exact variance.
 
However, when we only have a sample of the population then we have more uncertainty around the exact variance of the overall population, so our estimate for the variance needs to be larger.
The following example shows how to use these functions in practice.
<h3>Example: VAR.P vs. VAR.S in Excel</h3>
Suppose we have the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/varp1.png">
The following screenshot shows how to calculate the variance for the dataset using the three different variance formulas:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/varp2.png">
The sample variance turns out to be <b>76.99</b> and the population variance turns out to be <b>73.14</b>.
As mentioned earlier, the population variance will always be smaller than the sample variance.
<h3>When to Use VAR.P vs. VAR.S</h3>
In most cases, we’re unable to collect data for an entire population so we instead collect data for just a  sample  of the population.
Thus, we almost always use <b>VAR.S</b> to calculate the variance of a dataset because our dataset typically represents a sample.
Note that <b>VAR</b> and <b>VAR.S</b> return the exact same values, so we can use either function to calculate the sample variance of a given dataset.
<h2><span class="orange">How to Use the View() Function in R (With Examples)</span></h2>
The <b>View()</b> function in R can be used to invoke a spreadsheet-style data viewer within RStudio.
This function uses the following syntax:
<b>View(df)
</b>
<b>Note</b>: Make sure you type a capital “V” when using this function.
The following example shows how to use this syntax in practice.
<h3>How to Use the View() Function</h3>
We can use the following code to create a data frame in R with 100 rows and 2 columns:
<b>#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(x=rnorm(100), y=rnorm(100))</b>
We can then use the <b>View()</b> function to invoke a spreadsheet-style data viewer within RStudio:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view1.png">
Notice that a new tab appears in Rstudio that provides an interactive display of the data frame we just created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view2.png">
At the bottom of the viewer, we can see the size of the data frame: <b>100</b> entries (i.e. rows) and <b>2</b> columns.
<h3>How to Sort Data Using the View() Function</h3>
We can also quickly <b>sort</b> the data frame by clicking on one of the columns.
For example, if I click on the header for column x then the rows of the data frame will automatically be sorted from smallest to largest based on the values in column x:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view3.png">
If I click on the header for column x again, the data frame will then be sorted by column x from largest to smallest:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view4.png">
<h3>How to Filter Data Using the View() Function</h3>
I can also quickly <b>filter</b> the data frame by clicking the Filter icon, then clicking one of the column names, then typing in a range of values.
For example, I may choose to filter the data frame to only show the rows where x is between 0 and 1:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view6.png">
Once I press enter, the data frame will automatically be filtered:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/view5.png">
At the bottom of the screen we can see that <b>33</b> rows have values in the x column between 0 and 1.
Note that I can also add a filter in the y column to filter by specific values in both x and y.
<h2><span class="orange">How to Compare Two Lists in Excel Using VLOOKUP</span></h2>
You can use the following basic formula to compare two lists in Excel using the <b>VLOOKUP</b> function:
<b>=ISNA(VLOOKUP(A2,$C$2:$C$9,1,False))
</b>
Using the <b>Conditional Formatting</b> tool in Excel, we can use this formula to highlight every value in column A that does not belong to a range in column C.
The following example shows how to use this formula in practice.
<h3>Example: Compare Two Lists Using VLOOKUP</h3>
Suppose we have the following two datasets in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/vlookup1.png">
Suppose we’d like to identify the teams in Dataset 1 that are not in Dataset 2.
To do so, we can highlight every value in column A and then click the <b>Conditional Formatting</b> button on the <b>Home</b> tab along the top ribbon.
We can then click <b>New Rule…</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/vlookup2.png">
In the new window that appears, select the option that says <b>Use a formula to determine which cells to format</b> then type in the following formula:
<b>=ISNA(VLOOKUP(A2,$C$2:$C$9,1,False))</b>
Then click the <b>Format</b> button and choose a color to fill in values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/vlookup3.png">
Once you click <b>OK</b>, every value in column A that does not appear in column C will be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/vlookup4.png">
We can manually verify that a few of the values are highlighted correctly:
<b>Hawks</b> appear in both Dataset 1 and Dataset 2, so it is not highlighted.
<b>Mavericks</b> appear in both Dataset 1 and Dataset 2, so it is not highlighted.
<b>Lakers</b> appear in Dataset 1 but not Dataset 2, so it <em>is</em> highlighted.
And so on.
Note that we chose to highlight values that did not belong to both datasets, but we could also apply a different styling such as bolded text, increased font size, a border around cells, etc.
<h2><span class="orange">How to Perform a VLOOKUP (Similar to Excel) in R</span></h2>
The <b>VLOOKUP </b>function in Excel allows you to look up a value in a table by matching on a column.
For example, in the following Excel worksheet we can look up a player’s team name by using the VLOOKUP to match on player name and return the player’s team:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/vlookup_r2.png">
We can replicate this function using base R or the dplyr package:
<b>Using Base R:</b>
<b>merge(df1, df2, by="merge_column")
</b>
<b>Using dplyr:</b>
<b>inner_join(df1, df2, by="merge_column")</b>
The following examples show how to use each of these functions in R to replicate the VLOOKUP function from Excel.
<h3>VLOOKUP Using Base R</h3>
The following code shows how to perform a function similar to VLOOKUP in base R by using the <b>merge()</b> function:
<b>#create first data frame
df1 &lt;- data.frame(player=LETTERS[1:15],  team=rep(c('Mavs', 'Lakers', 'Rockets'), each=5))
#create second data frame 
df2 &lt;- data.frame(player=LETTERS[1:15],  points=c(14, 15, 15, 16, 8, 9, 16, 27, 30, 24, 14, 19, 8, 6, 5))
#merge the two data frames
merge(df1, df2, by="player")
   player    team points
1       A    Mavs     14
2       B    Mavs     15
3       C    Mavs     15
4       D    Mavs     16
5       E    Mavs      8
6       F  Lakers      9
7       G  Lakers     16
8       H  Lakers     27
9       I  Lakers     30
10      J  Lakers     24
11      K Rockets     14
12      L Rockets     19
13      M Rockets      8
14      N Rockets      6
15      O Rockets      5</b>
Notice that this returns the same results as the VLOOKUP function from the introductory example. Also note that you can specify multiple columns to merge on using the <b>by</b> argument.
<h3>VLOOKUP Using dplyr</h3>
<b>library(dplyr)
#create first data frame
df1 &lt;- data.frame(player=LETTERS[1:15],  team=rep(c('Mavs', 'Lakers', 'Rockets'), each=5))
#create second data frame 
df2 &lt;- data.frame(player=LETTERS[1:15],  points=c(14, 15, 15, 16, 8, 9, 16, 27, 30, 24, 14, 19, 8, 6, 5))
#merge the two data frames using inner_join
inner_join(df1, df2, by="player")
   player    team points
1       A    Mavs     14
2       B    Mavs     15
3       C    Mavs     15
4       D    Mavs     16
5       E    Mavs      8
6       F  Lakers      9
7       G  Lakers     16
8       H  Lakers     27
9       I  Lakers     30
10      J  Lakers     24
11      K Rockets     14
12      L Rockets     19
13      M Rockets      8
14      N Rockets      6
15      O Rockets      5
</b>
Notice that this returns the same results as the VLOOKUP function in Excel. Also note that you can specify multiple columns to merge on using the <b>by</b> argument.
Also, if you’d like non-matches to be shown you can instead use the <b>left_join</b> function.
<h2><span class="orange">How to Perform a VLOOKUP with Two Lookup Values</span></h2>
You can use the following basic formula to perform a VLOOKUP with two lookup values in Excel:
<b>=VLOOKUP(F1&F2,CHOOSE({1,2},A2:A10&B2:B10,C2:C10),2,FALSE)
</b>
This particular formula looks up the values in <b>F1</b> and <b>F2</b> in the ranges <b>A2:A10</b> and <b>B2:B10</b>, respectively, and returns the corresponding value in the range <b>C2:C10</b>.
The following example shows how to use this formula in practice.
<h2>Example: Perform VLOOKUP with Two Lookup Values</h2>
Suppose we have the following dataset in Excel that shows the points scored by various basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/vlookuptwo.jpg"491">
Now suppose we would like to use a <b>VLOOKUP</b> function to find the points value that corresponds to a Team value of <b>Mavs</b> <em>and</em> a Position value of <b>Center</b>.
To do so, we can type the following formula into cell F3:
<b>=VLOOKUP(F1&F2,CHOOSE({1,2},A2:A10&B2:B10,C2:C10),2,FALSE)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/vlookuptwo1.jpg">
The formula returns a value of <b>31</b>.
This is the correct points value that corresponds to the player on the <b>Mavs</b> team who has a position of <b>Center</b>.
Note that we can change the values in column F to find the points value for a different player.
For example, if we change the Team to <b>Spurs</b> and the Position to <b>Guard</b>, the <b>VLOOKUP</b> function will automatically update to find the points value for this player:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/vlookuptwo2.jpg"527">
The formula returns the correct points value of <b>40</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate a Weighted Percentage in Excel 
 How to Multiply Column by a Percentage in Excel 
 How to Calculate Percentile Rank in Excel 
<h2><span class="orange">What is a Voluntary Response Sample? (Definition & Example)</span></h2>
A <b>voluntary response sample</b> is a  sample  made up of individuals who <em>volunteer</em> to be included in the sample.
For example, suppose a radio host asks listeners to go online and take a survey on his website about their opinion of his show. Each individual listener can voluntarily decide to take the survey or not.
The drawback of this sampling method is that the individuals who voluntarily respond will likely have stronger opinions (positive or negative) than the rest of the population, which makes them an  unrepresentative sample .
The visual below illustrates this problem: suppose the green circles represent people who think highly of the radio show while the red circles represent people who dislike the show:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/voluntary1.png">
Notice how most of the people who think highly of the show are included in the sample, yet the sample is not representative of the larger population. The results of the survey would show that most people like the show, when in fact this is not true.
Voluntary response sampling is a type of  non-probability sampling  because not every individual in the population has an equal probability of being included in the sample.
This is in contrast to probability-sampling methods, in which each individual in the population is equally likely to be included in the sample and thus the sample is likely to be representative of the overall population.
<h3>Examples of Voluntary Response Samples</h3>
The following scenarios illustrate a couple more examples of voluntary response samples.
<b>Example 1: Exam Prep</b>
Suppose a professor wants to know if a new exam prep course helps students improve test scores. She posts a sign-up sheet outside of her classroom and lets students decide if they’d like to participate in the course.
This is an example of voluntary response sampling because students can voluntarily decide to be included in the sample.
Unfortunately, students who are more studious are more likely to sign up which means the sample of students who take the course aren’t likely to match the overall population of students who could potentially take the course.
<b>Example 2: Traffic Law</b>
Suppose researchers want to know what citizens in a particular city think of a new traffic law so they mail out a questionnaire to every citizen.
This is an example of voluntary response sampling because each individual citizen can decide to be included in the sample or not.
Unfortunately, the citizens who respond are likely to have stronger opinions than ordinary citizens which means the resulting sample won’t be representative of the overall population of citizens.
<h3>Disadvantages of Voluntary Response Samples</h3>
Voluntary response sampling suffers from the following types of bias:
<b>1.  Undercoverage Bias :</b> When some members of a population are inadequately represented in the sample.
<b>2.  Self-selection Bias :</b> When individuals select themselves to be included in a survey.
<b>3.  Non-response Bias :</b> When the people who respond to a survey differ significantly from the people who do not respond to the survey.
Due to all of these types of bias, voluntary response samples end up not being representative of the overall population of interest.
Despite so many drawbacks, voluntary response sampling is often used simply because it’s an easy way to collect a sample since individuals voluntarily decide to include themselves.
<h2><span class="orange">How to Perform a Wald Test in R</span></h2>
A <b>Wald test</b> can be used to test if one or more parameters in a model are equal to certain values.
This test is often used to determine if one or more predictor variables in a  regression model  are equal to zero.
We use the following null and alternative  hypotheses  for this test:
<b>H<sub>0</sub></b>: Some set of predictor variables are all equal to zero.
<b>H<sub>A</sub></b>: Not all predictor variables in the set are equal to zero.
If we fail to reject the null hypothesis, then we can drop the specified set of predictor variables from the model because they don’t offer a statistically significant improvement in the fit of the model.
The following example shows how to perform a Wald test in R.
<h3>Example: Wald Test in R</h3>
For this example, we’ll use the built-in  mtcars  dataset in R to fit the following multiple linear regression model:
mpg  = β<sub>0</sub> + β<sub>1</sub>disp + β<sub>2</sub>carb + β<sub>3</sub>hp + β<sub>4</sub>cyl
The following code shows how to fit this regression model and view the model summary:
<b>#fit regression model
model &lt;- lm(mpg ~ disp + carb + hp + cyl, data = mtcars)
#view model summary
summary(model)
Call:
lm(formula = mpg ~ disp + carb + hp + cyl, data = mtcars)
Residuals:
    Min      1Q  Median      3Q     Max 
-5.0761 -1.5752 -0.2051  1.0745  6.3047 
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 34.021595   2.523397  13.482 1.65e-13 ***
disp        -0.026906   0.011309  -2.379   0.0247 *  
carb        -0.926863   0.578882  -1.601   0.1210    
hp           0.009349   0.020701   0.452   0.6551    
cyl         -1.048523   0.783910  -1.338   0.1922    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 2.973 on 27 degrees of freedom
Multiple R-squared:  0.788,Adjusted R-squared:  0.7566 
F-statistic: 25.09 on 4 and 27 DF,  p-value: 9.354e-09</b>
Next, we can use the <b>wald.test()</b> function from the <b>aod</b> package to test if the regression coefficients for the predictor variables “hp” and “cyl” are both equal to zero.
This function uses the following basic syntax:
<b>wald.test(Sigma, b, Terms)</b>
where:
<b>Sigma</b>: The variance-covariance matrix of the regression model
<b>b</b>: A vector of regression coefficients from the model
<b>Terms</b>: A vector that specifies which coefficients to test
The following code shows how to use this function in practice:
<b>library(aod)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(model), b = coef(model), Terms = 3:4)
Wald test:
----------
Chi-squared test:
X2 = 3.6, df = 2, P(> X2) = 0.16
</b>
From the output we can see that the  p-value  of the test is 0.16.
Since this p-value is not less than .05, we fail to reject the null hypothesis of the Wald test.
This means we can assume the regression coefficients for the predictor variables “hp” and “cyl” are both equal to zero.
We can drop these terms from the model since they don’t statistically significantly improve the overall fit of the model.
<h2><span class="orange">How to Use a Weighted Average IF Formula in Excel</span></h2>
You can use the following syntax in Excel to apply a weighted average IF formula:
<b>=SUMPRODUCT(--(A2:A7="A"), B2:B7, C2:C7)/SUMIF(A2:A7, "A", C2:C7)
</b>
This formula calculates the weighted average of the values in the range <b>B2:B7</b>, using <b>C2:C7</b> as the weights, <em>only</em> for the cells where <b>A2:A7</b> are equal to “A”.
The following example shows how to use this formula in practice.
<h3>Example: Weighted Average IF Formula in Excel</h3>
First, let’s enter the following data that shows the scores for two students (Student A and Student B) on three different exams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/weighted1.jpg"459">
Next, we’ll use the following formula to calculate the weighted average of exam scores for student A only:
<b>=SUMPRODUCT(--(A2:A7="A"), B2:B7, C2:C7)/SUMIF(A2:A7, "A", C2:C7)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/weighted2.jpg">
The weighted average of exam scores for student A is <b>78</b>.
We can verify this is correct by manually computing the weighted average exam score for student A.
Recall that we use the following formula for weighed average:
<b>Weighed Average = Σw<sub>i</sub>X<sub>i</sub> / Σw<sub>i</sub></b>
where:
<b>w<sub>i</sub></b> = the weight values
<b>X<sub>i</sub></b> = the data values
We can plug in the values from our dataset into this formula to calculate the weighted average exam score for student A:
Weighed Average for Student A = Σw<sub>i</sub>X<sub>i</sub> / Σw<sub>i</sub>
Weighed Average for Student A = (2*60 + 5*90 + 70*3) / (2+5+3)
Weighed Average for Student A = <b>78</b>
This matches the value that we calculated using the formula in Excel.
<h2><span class="orange">How to Perform Weighted Least Squares Regression in Python</span></h2>
One of the key  assumptions of linear regression  is that the  residuals  are distributed with equal variance at each level of the predictor variable. This assumption is known as <b>homoscedasticity</b>.
When this assumption is violated, we say that  heteroscedasticity  is present in the residuals. When this occurs, the results of the regression become unreliable.
One way to handle this issue is to instead use <b>weighted least squares regression</b>, which places weights on the  observations  such that those with small error variance are given more weight since they contain more information compared to observations with larger error variance.
This tutorial provides a step-by-step example of how to perform weight least squares regression in Python.
<h2>Step 1: Create the Data</h2>
First, let’s create the following pandas DataFrame that contains information about the number of hours studied and the final exam score for 16 students in some class:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'hours': [1, 1, 2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 6, 6, 7, 8],   'score': [48, 78, 72, 70, 66, 92, 93, 75, 75, 80, 95, 97,             90, 96, 99, 99]})
#view first five rows of DataFrame
print(df.head())
   hours  score
0      1     48
1      1     78
2      2     72
3      2     70
4      2     66</b>
<h2>Step 2: Fit Simple Linear Regression Model</h2>
Next, we’ll use functions from the <b>statsmodels</b> module to fit a simple linear regression model using <b>hours</b> as the predictor variable and <b>score</b> as the response variable:
<b>import statsmodels.api as sm
#define predictor and response variables
y = df['score']
X = df['hours']
#add constant to predictor variables
X = sm.add_constant(x)
#fit linear regression model
fit = sm.OLS(y, X).fit()
#view model summary
print(fit.summary())
            OLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.630
Model:                            OLS   Adj. R-squared:                  0.603
Method:                 Least Squares   F-statistic:                     23.80
Date:                Mon, 31 Oct 2022   Prob (F-statistic):           0.000244
Time:                        11:19:54   Log-Likelihood:                -57.184
No. Observations:                  16   AIC:                             118.4
Df Residuals:                      14   BIC:                             119.9
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         60.4669      5.128     11.791      0.000      49.468      71.465
hours          5.5005      1.127      4.879      0.000       3.082       7.919
==============================================================================
Omnibus:                        0.041   Durbin-Watson:                   1.910
Prob(Omnibus):                  0.980   Jarque-Bera (JB):                0.268
Skew:                          -0.010   Prob(JB):                        0.875
Kurtosis:                       2.366   Cond. No.                         10.5</b>
From the model summary we can see that the R-squared value of the model is <b>0.630</b>.
<b>Related:</b>  What is a Good R-squared Value? 
<h2>Step 3: Fit Weighted Least Squares Model</h2>
Next, we can use the <b>WLS()</b> function from <b>statsmodels</b> to perform weighted least squares by defining the weights in such a way that the observations with lower variance are given more weight:
<b>#define weights to use
wt = 1 / smf.ols('fit.resid.abs() ~ fit.fittedvalues', data=df).fit().fittedvalues**2
#fit weighted least squares regression model
fit_wls = sm.WLS(y, X, weights=wt).fit()
#view summary of weighted least squares regression model
print(fit_wls.summary())
            WLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.676
Model:                            WLS   Adj. R-squared:                  0.653
Method:                 Least Squares   F-statistic:                     29.24
Date:                Mon, 31 Oct 2022   Prob (F-statistic):           9.24e-05
Time:                        11:20:10   Log-Likelihood:                -55.074
No. Observations:                  16   AIC:                             114.1
Df Residuals:                      14   BIC:                             115.7
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
============================================================================== coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         63.9689      5.159     12.400      0.000      52.905      75.033
hours          4.7091      0.871      5.407      0.000       2.841       6.577
==============================================================================
Omnibus:                        2.482   Durbin-Watson:                   1.786
Prob(Omnibus):                  0.289   Jarque-Bera (JB):                1.058
Skew:                           0.029   Prob(JB):                        0.589
Kurtosis:                       1.742   Cond. No.                         17.6
==============================================================================</b>
From the output we can see that the R-squared value for this weighted least squares model increased to <b>0.676</b>.
This indicates that the weighted least squares model is able to explain more of the variance in exam scores compared to the simple linear regression model.
This tells us that the weighted least squares model offers a better fit to the data compared to the simple linear regression model.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Python:
 How to Create a Residual Plot in Python 
 How to Create a Q-Q Plot in Python 
 How to Test for Multicollinearity in Python 
<h2><span class="orange">How to Perform Weighted Least Squares Regression in R</span></h2>
One of the key  assumptions of linear regression  is that the  residuals  are distributed with equal variance at each level of the predictor variable. This assumption is known as <b>homoscedasticity</b>.
When this assumption is violated, we say that  heteroscedasticity  is present in the residuals. When this occurs, the results of the regression become unreliable.
One way to handle this issue is to instead use <b>weighted least squares regression</b>, which places weights on the  observations  such that those with small error variance are given more weight since they contain more information compared to observations with larger error variance.
This tutorial provides a step-by-step example of how to perform weight least squares regression in R.
<h3>Step 1: Create the Data</h3>
The following code creates a data frame that contains the number of hours studied and the corresponding exam score for 16 students:
<b>df &lt;- data.frame(hours=c(1, 1, 2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 6, 6, 7, 8), score=c(48, 78, 72, 70, 66, 92, 93, 75, 75, 80, 95, 97, 90, 96, 99, 99))
</b>
<h3>Step 2: Perform Linear Regression</h3>
Next, we’ll use the <b>lm()</b> function to fit a  simple linear regression model  that uses hours as the predictor variable and score as the  response variable :
<b>#fit simple linear regression model
model &lt;- lm(score ~ hours, data = df)
#view summary of model
summary(model)
Call:
lm(formula = score ~ hours, data = df)
Residuals:
    Min      1Q  Median      3Q     Max 
-17.967  -5.970  -0.719   7.531  15.032 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   60.467      5.128  11.791 1.17e-08 ***
hours          5.500      1.127   4.879 0.000244 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 9.224 on 14 degrees of freedom
Multiple R-squared:  0.6296,Adjusted R-squared:  0.6032 
F-statistic:  23.8 on 1 and 14 DF,  p-value: 0.0002438
</b>
<h3>Step 3: Test for Heteroscedasticity</h3>
Next, we’ll create a residual vs. fitted values plot to visually check for heteroscedasticity:
<b>#create residual vs. fitted plot
plot(fitted(model), resid(model), xlab='Fitted Values', ylab='Residuals')
#add a horizontal line at 0 
abline(0,0)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/wls1.png">
We can see from the plot that the residuals exhibit a “cone” shape – they’re not distributed with equal variance throughout the plot. 
To formally test for heteroscedasticity, we can perform a Breusch-Pagan test:
<b>#load lmtest package
library(lmtest)
#perform Breusch-Pagan test
bptest(model)
studentized Breusch-Pagan test
data:  model
BP = 3.9597, df = 1, p-value = 0.0466
</b>
The Breusch-Pagan test uses the following null and alternative  hypotheses :
<b>Null Hypothesis (H<sub>0</sub>):</b> Homoscedasticity is present (the residuals are distributed with equal variance)
<b>Alternative Hypothesis (H<sub>A</sub>):</b> Heteroscedasticity is present (the residuals are not distributed with equal variance)
Since the p-value from the test is <b>0.0466</b> we will reject the null hypothesis and conclude that heteroscedasticity is a problem in this model.
<h3>Step 4: Perform Weighted Least Squares Regression</h3>
Since heteroscedasticity is present, we will perform weighted least squares by defining the weights in such a way that the observations with lower variance are given more weight:
<b>#define weights to use
wt &lt;- 1 / lm(abs(model$residuals) ~ model$fitted.values)$fitted.values^2
#perform weighted least squares regression
wls_model &lt;- lm(score ~ hours, data = df, weights=wt)
#view summary of model
summary(wls_model)
Call:
lm(formula = score ~ hours, data = df, weights = wt)
Weighted Residuals:
    Min      1Q  Median      3Q     Max 
-2.0167 -0.9263 -0.2589  0.9873  1.6977 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  63.9689     5.1587  12.400 6.13e-09 ***
hours         4.7091     0.8709   5.407 9.24e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 1.199 on 14 degrees of freedom
Multiple R-squared:  0.6762,Adjusted R-squared:  0.6531 
F-statistic: 29.24 on 1 and 14 DF,  p-value: 9.236e-05
</b>
From the output we can see that the coefficient estimate for the predictor variable <em>hours</em> changed a bit and the overall fit of the model improved.
The weighted least squares model has a residual standard error of <b>1.199</b> compared to <b>9.224</b> in the original simple linear regression model.
This indicates that the predicted values produced by the weighted least squares model are much closer to the actual observations compared to the predicted values produced by the simple linear regression model.
The weighted least squares model also has an R-squared of <b>.6762</b> compared to <b>.6296</b> in the original simple linear regression model.
This indicates that the weighted least squares model is able to explain more of the variance in exam scores compared to the simple linear regression model.
These metrics indicate that the weighted least squares model offers a better fit to the data compared to the simple linear regression model.
<h2><span class="orange">How to Calculate Weighted MAPE in Excel</span></h2>
One of the most common metrics used to measure the forecasting accuracy of a model is <b>MAPE</b>, which stands for <b>mean absolute percentage error</b>.
The formula to calculate MAPE is as follows:
<b>MAPE</b> = (1/n) * Σ(|actual – forecast| / |actual|) * 100
where:
<b>Σ</b> – a fancy symbol that means “sum”
<b>n</b> – sample size
<b>actual</b> – the actual data value
<b>forecast</b> – the forecasted data value
MAPE is commonly used because it’s easy to interpret and easy to explain. For example, a MAPE value of 8% means that the average difference between the forecasted value and the actual value is 8%. 
However, MAPE performs poorly with low volume data. For example, if the actual demand for some item is 2 and the forecast is 1, the value for the absolute percent error will be |2-1| / |2| = 50%, which makes it seem like the forecast error is quite high, despite the forecast only being off by one unit.
Thus, an alternative to MAPE is <b>Weighted MAPE</b>, which is calculated as:
<b>Weighted MAPE</b> = Σ(|actual – forecast| / |actual|) * 100 * actual  /  Σ(actual)
By weighting the percentage errors based on volume, we can get a better idea of the true error.
This tutorial explains how to calculate Weighted MAPE in Excel.
<h2>Example: Weighted MAPE in Excel</h2>
To calculate Weighted MAPE in Excel, we can perform the following steps:
<b>Step 1: Enter the actual values and forecasted values in two separate columns.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/WMAPE1.png">
<b>Step 2: Calculate the weighted error for each row.</b>
Recall that the weighted error is calculated as: |actual-forecast| / |actual| * 100 * actual. We will use this formula to calculate the weighted error for each row.
Column D displays the weighted error and Column E shows the formula we used:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/WMAPE2.png">
We will repeat this formula for each row:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/WMAPE3.png">
<b>Step 3: Find the sum of actual values.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/WMAPE4.png">
<b>Step 4: Calculate the Weighted MAPE.</b>
Lastly, we will calculated the Weighted MAPE by dividing the total weighted errors by the sum of the actual values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/WMAPE5.png">
The Weighted MAPE turns out to be <b>5.92%</b>.
<h2><span class="orange">How to Calculate a Weighted Mean in R</span></h2>
To calculate a weighted mean in R, you can use the built-in  weighted.mean()  function, which uses the following syntax:
<b>weighted.mean(x, w)</b>
where:
<b>x:</b> A vector of raw data values
<b>w:</b> A vector of weights
This tutorial shows several examples of how to use this function in practice.
<h3>Example 1: Weighted Mean of a Vector</h3>
The following code shows how to calculated the weighted mean for a given vector of data:
<b>#define vector of data values
data &lt;- c(3, 5, 6, 7, 8)
#define vector of weights
weights &lt;- c(.1, .3, .3, .2, .1)
#calculate weighted mean
weighted.mean(x=data, w=weights)
[1] 5.8
</b>
The weighted mean turns out to be <b>5.8</b>.
<h3>Example 2: Weighted Mean of a Column in a Data Frame</h3>
The following code shows how to calculated the weighted mean for a column in a data frame, using another column as the weights:
<b>#create data frame
df &lt;- data.frame(values = c(3, 5, 6, 7, 8), weights = c(.1, .3, .3, .2, .1))
#calculate weighted mean
weighted.mean(x=df$values, w=df$weights)
[1] 5.8
</b>
The weighted mean turns out to be <b>5.8</b>.
Note that you can also calculate the weighted mean for a column in a data frame by using a separate vector as the weights:
<b>#create data frame
df &lt;- data.frame(values = c(3, 5, 6, 7, 8), other_data = c(6, 12, 14, 14, 7), more_data = c(3, 3, 4, 7, 9))
#define vector of weights
weights &lt;- c(.1, .3, .3, .2, .1)
#calculate weighted mean
weighted.mean(x=df$values, w=weights)
[1] 5.8</b>
Once again the weighted mean turns out to be <b>5.8</b>.
<h3>When to Use a Weighted Mean</h3>
In practice, a weighted mean is used when we consider some data values to be more important than others and so we want those more important values to contribute more to the final mean.
<h2><span class="orange">How to Find Weighted Moving Averages in Excel</span></h2>
A <b>weighted moving average </b>is a technique that can be used to smooth out time series data to reduce the “noise” in the data and more easily identify patterns and trends.
The whole idea behind a weighted moving average is to take the average of a certain number of previous periods to come up with an “average” value for a given period, while giving more weight to more recent time periods.
In this tutorial, we show how to find weighted moving averages for time series data in Excel.
<h2>Example: Weighted Moving Averages in Excel</h2>
Suppose we have the following dataset that shows the sales for a certain company during 10 periods:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/expSmooth1.png">
We can perform the following steps to calculated weighted moving averages for this time period:
<b>Step 1: Decide how many previous periods to include in the weighted moving average calculation.</b>
We’ll use three periods for this example.
<b>Step 2: Decide what weights to assign each period.</b>
We’ll assign the weights as follows:
0.5 for the current period
0.3 for the previous period
0.2 for two periods back
Note that the total weights must add up to 1.
<b>Step 3: Calculate the weighted moving average for each period.</b>
In the image below, column C shows the weighted moving average (WMA) for time period 3 and column D shows the formula we used to calculate it:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wma1.png">
We can use a similar formula to find the weighted moving average for every time period:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wma2.png">
If we create a line chart to visualize the actual sales vs. the weighted moving average, we’ll notice that the WMA line is more smooth with less peaks and valleys. This is the whole idea behind a weighed moving average – it allows us to see the true underlying trend of the data without the extra noise.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wma3.png">
<h2>Making Adjustments to the Weighted Moving Average</h2>
There are two numbers you can adjust that will lead to different weighted moving average calculations:
<b>The number of previous periods used</b>. In our example we used three previous periods to calculate the weighted moving averages, but we could have chosen 4, 5, 6, etc. As a rule of thumb, the more periods you use in your calculations, the smoother the weighed moving average line will be.
<b>The weights assigned to each period</b>. In our example we assigned the weights as 0.5, 0.3, and 0.2, but we could have chosen any combination of weights as long as they added up to 1. As a rule of thumb, the more weight you give to the most current period, the less smooth the weighted moving average line will be.
To illustrate this, consider if we again used three periods for our WMA calculation but instead used the following weights:
0.7 for the current period
0.2 for the previous period
0.1 for two periods back
Since we gave so much weight to the current time period, the weighted moving average line would be less smooth and more closely resemble the actual sales line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wma4.png">
<h2>Simple Moving Averages vs. Weighted Moving Averages</h2>
A <b>simple moving average </b>is a way to calculate a moving average in which all time periods used in the calculation are given the same weight.
For example, if you use three time periods to calculate the moving average then the weight given to each time period would be 0.333. Or if you use four time periods to calculate the moving average then the weight given to each period would be 0.25.
A simple moving average is more straightforward to calculate, but the benefit of using a weighted moving average is that you can assign higher weights to more recent periods. This is useful if your data is trending in a certain direction and you want to get a more accurate idea of the trend.
For example, suppose you’re calculating the weighted moving average for points scored by a basketball player who is getting better and better as the season goes on.
Using a five-game moving average, you would want to place more weight on the points scored in their most recent game so that you can get a more accurate idea of how many points they’re expected to score.
<h2><span class="orange">How to Calculate a Weighted Percentage in Excel</span></h2>
You can use the following formula to calculate a weighted percentage in Excel:
<b>=SUMPRODUCT(A:A, B:B)/SUM(B:B)
</b>
This formula assumes column <b>A</b> contains the percentage values and column <b>B</b> contains the weights.
The following example shows how to use this formula in practice.
<h2>Example: Calculate Weighted Percentage in Excel</h2>
Suppose we have the following dataset that shows the scores that some student received on various exams along with the weights for each exam:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/weightedpercentage1.jpg"468">
We can use the following formula to calculate a weighted percentage for their final grade in the class:
<b>=SUMPRODUCT(B2:B6, C2:C6)/SUM(C2:C6)
</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/weightedpercentage2.jpg"530">
The final grade turns out to be <b>85%</b>.
We can verify that this is correct by manually calculating the weighted percentage of grades:
Weighted Percentage: (90%*10%) + (91%*10%) + (81%*10%) + (78%*10%) + (85%*60%)
Weighted Percentage: 9% + 9.1% + 8.1% + 7.8% + 51%
Weighted Percentage = <b>85%</b>.
This weighted percentage matches the value that we calculated using the formula from earlier.
<b>Note</b>: You can find the complete documentation for the <b>SUMPRODUCT</b> function in Excel  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Find Weighted Moving Averages in Excel 
 How to Use a Weighted Average IF Formula in Excel 
 How to Calculate Weighted Standard Deviation in Excel 
<h2><span class="orange">How to Calculate a Weighted Percentage in Google Sheets</span></h2>
You can use the following formula to calculate a weighted percentage in Google Sheets:
<b>=SUMPRODUCT(A:A, B:B)/SUM(B:B)
</b>
This formula assumes column <b>A</b> contains the percentage values and column <b>B</b> contains the weights.
The following example shows how to use this formula in practice.
<h2>Example: Weighted Percentage in Google Sheets</h2>
Suppose we have the following dataset that shows the scores that some student received on various exams along with the weights for each exam:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/wpsheets1.jpg"604">
We can use the following formula to calculate a weighted percentage for their final grade in the class:
<b>=SUMPRODUCT(B2:B6, C2:C6)/SUM(C2:C6)
</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/wpsheets2.jpg">
Click the <b>Format as percent</b> button to convert this decimal to a percentage:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/wpsheets3.jpg"588">
The value will automatically be formatted as a percentage:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/wpsheets4.jpg"584">
The final grade turns out to be <b>85%</b>.
We can verify that this is correct by manually calculating the weighted percentage of grades:
Weighted Percentage: (90%*10%) + (91%*10%) + (81%*10%) + (78%*10%) + (85%*60%)
Weighted Percentage: 9% + 9.1% + 8.1% + 7.8% + 51%
Weighted Percentage = <b>85%</b>.
This weighted percentage matches the value that we calculated using the formula from earlier.
<b>Note</b>: You can find the complete documentation for the <b>SUMPRODUCT</b> function in Google Sheets  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Google Sheets:
 How to Calculate Frequencies in Google Sheets 
 How to Calculate Cumulative Percentage in Google Sheets 
<h2><span class="orange">How to Calculate Weighted Standard Deviation in Excel</span></h2>
The <b>weighted standard deviation</b> is a useful way to measure  the dispersion  of values in a dataset when some values in the dataset have higher weights than others.
The formula to calculate a weighted standard deviation is:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd1.png">
where:
<b>N:</b> The total number of  observations 
<b>M:</b> The number of non-zero weights
<b>w<sub>i</sub>:</b> A vector of weights
<b>x<sub>i</sub>:</b> A vector of data values
<b>x:</b> The weighted mean
The following step-by-step example shows how to calculate a weighted standard deviation in Excel.
<h3>Step 1: Create the Data</h3>
First, let’s create a column of data values along with their weights:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd_excel1.png">
<h3>Step 2: Calculate the Weighted Mean</h3>
Next, we can use the following formula to calculate the weighted mean:
<b>=SUMPRODUCT(A2:A11, B2:B11) / SUM(B2:B11)
</b>
The weighted mean turns out to be <b>31.147</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd_excel2.png">
<h3>Step 3: Calculate the Weighted Standard Deviation </h3>
Next, we can use the following formula to calculate the weighted standard deviation:
<b>=SQRT(SUMPRODUCT((A2:A11-E2)^2, B2:B11) / SUM(B2:B11, -1))</b>
The weighted standard deviation turns out to be <b>8.570</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd_excel3.png">
And if you’d like to calculate the weighted variance, it’s simply 8.570<sup>2</sup> = <b>73.44</b>.
<h2><span class="orange">How to Calculate Weighted Standard Deviation in Python</span></h2>
The <b>weighted standard deviation</b> is a useful way to measure  the dispersion  of values in a dataset when some values in the dataset have higher weights than others.
The formula to calculate a weighted standard deviation is:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd1.png">
where:
<b>N:</b> The total number of  observations 
<b>M:</b> The number of non-zero weights
<b>w<sub>i</sub>:</b> A vector of weights
<b>x<sub>i</sub>:</b> A vector of data values
<b>x:</b> The weighted mean
The easiest way to calculate a weighted standard deviation in Python is to use the  DescrStatsW()  function from the statsmodels package:
<b>DescrStatsW(values, weights=weights, ddof=1).std
</b>
The following example shows how to use this function in practice.
<h3>Example: Weighted Standard Deviation in Python</h3>
Suppose we have the following array of data values and corresponding weights:
<b>#define data values 
values = [14, 19, 22, 25, 29, 31, 31, 38, 40, 41]
#define weights
weights = [1, 1, 1.5, 2, 2, 1.5, 1, 2, 3, 2]
</b>
The following code shows how to calculate the weighted standard deviation for this array of data values:
<b>from statsmodels.stats.weightstats import DescrStatsW
#calculate weighted standard deviation
DescrStatsW(values, weights=weights, ddof=1).std
8.570050878426773
</b>
The weighted standard deviation turns out to be <b>8.57</b>.
Note that we can also use <b>var</b> to quickly calculate the weighted variance as well:
<b>from statsmodels.stats.weightstats import DescrStatsW
#calculate weighted variance
DescrStatsW(values, weights=weights, ddof=1).var
73.44577205882352</b>
The weighted variance turns out to be <b>73.446</b>.
<h2><span class="orange">How to Calculate Weighted Standard Deviation in R</span></h2>
The <b>weighted standard deviation</b> is a useful way to measure  the dispersion  of values in a dataset when some values in the dataset have higher weights than others.
The formula to calculate a weighted standard deviation is:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/weighted_sd1.png">
where:
<b>N:</b> The total number of  observations 
<b>M:</b> The number of non-zero weights
<b>w<sub>i</sub>:</b> A vector of weights
<b>x<sub>i</sub>:</b> A vector of data values
<b>x:</b> The weighted mean
The easiest way to calculate a weighted standard deviation in R is to use the <b>wt.var()</b> function from the <b>Hmisc</b> package, which uses the following syntax:
<b>#define data values
x &lt;- c(4, 7, 12, 13, ...)
#define weights
wt &lt;- c(.5, 1, 2, 2, ...)
#calculate weighted variance
weighted_var &lt;- wtd.var(x, wt)
#calculate weighted standard deviation
weighted_sd &lt;- sqrt(weighted_var)
</b>
The following examples show how to use this function in practice.
<h3>Example 1: Weighted Standard Deviation for One Vector</h3>
The following code shows how to calculate the weighted standard deviation for a single vector in R:
<b>library(Hmisc)
#define data values 
x &lt;- c(14, 19, 22, 25, 29, 31, 31, 38, 40, 41)
#define weights
wt &lt;- c(1, 1, 1.5, 2, 2, 1.5, 1, 2, 3, 2)
#calculate weighted variance 
weighted_var &lt;- wtd.var(x, wt)
#calculate weighted standard deviation
sqrt(weighted_var)
[1] 8.570051
</b>
The weighted standard deviation turns out to be <b>8.57</b>.
<h3>Example 2: Weighted Standard Deviation for One Column of Data Frame</h3>
The following code shows how to calculate the weighted standard deviation for one column of a data frame in R:
<b>library(Hmisc)
#define data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'A', 'B', 'B', 'C'), wins=c(2, 9, 11, 12, 15, 17, 18, 19), points=c(1, 2, 2, 2, 3, 3, 3, 3))
#define weights
wt &lt;- c(1, 1, 1.5, 2, 2, 1.5, 1, 2)
#calculate weighted standard deviation of points
sqrt(wtd.var(df$points, wt))
[1] 0.6727938
</b>
The weighted standard deviation for the points column turns out to be <b>0.673</b>.
<h3>Example 3: Weighted Standard Deviation for Multiple Columns of Data Frame</h3>
The following code shows how to use the  sapply()  function in R to calculate the weighted standard deviation for multiple columns of a data frame:
<b>library(Hmisc)
#define data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'A', 'B', 'B', 'C'), wins=c(2, 9, 11, 12, 15, 17, 18, 19), points=c(1, 2, 2, 2, 3, 3, 3, 3))
#define weights
wt &lt;- c(1, 1, 1.5, 2, 2, 1.5, 1, 2)
#calculate weighted standard deviation of points and wins
sapply(df[c('wins', 'points')], function(x) sqrt(wtd.var(x, wt)))
     wins    points 
4.9535723 0.6727938 
</b>
The weighted standard deviation for the wins column is <b>4.954</b> and the weighted standard deviation for the points column is <b>0.673</b>.
<h2><span class="orange">How to Perform Welch’s t-Test in R</span></h2>
 Welch’s t-test  is used to compare the means between two independent groups when it is <em>not</em> assumed that the two groups have equal variances.
To perform Welch’s t-test in R, we can use the <b>t.test()</b> function, which uses the following syntax:
<b>t.test(x, y, alternative = c(“two.sided”, “less”, “greater”))</b>
where:
<b>x: </b>A numeric vector of data values for the first group
<b>y: </b>A numeric vector of data values for the second group
<b>alternative: </b>The alternative hypothesis for the test. Default is two.sided.
The following example shows how to use this function to perform Welch’s t-test in R.
<h2>Example: Welch’s t-test in R</h2>
A teacher wants to compare the exam scores of 12 students who used an exam prep booklet to prepare for some exam vs. 12 students who did not.
The following vectors show the exam scores for the students in each group:
<b>booklet &lt;- c(90, 85, 88, 89, 94, 91, 79, 83, 87, 88, 91, 90)
no_booklet &lt;- c(67, 90, 71, 95, 88, 83, 72, 66, 75, 86, 93, 84)
</b>
Before we perform a Welch’s t-test, we can first create  boxplots  to visualize the distribution of scores for each group:
<b>boxplot(booklet, no_booklet, names=c("Booklet","No Booklet"))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/welchR1.png">
We can clearly see that the “Booklet” group has a higher mean score and lower variance in scores.
To formally test whether or not the mean scores between the groups are significantly different, we can perform Welch’s t-test:
<b>#perform Welch's t-test
t.test(booklet, no_booklet)
Welch Two Sample t-test
data:  booklet and no_booklet
t = 2.2361, df = 14.354, p-value = 0.04171
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  0.3048395 13.8618272
sample estimates:
mean of x mean of y 
 87.91667  80.83333 
</b>
From the output we can see that the <em>t</em> test-statistic is <b>2.2361</b> and the corresponding p-value is <b>0.04171</b>. 
Since this p-value is less than .05, we can reject the null hypothesis and conclude that there is a statistically significant difference in mean exam scores between the two groups.
The <b>t.test()</b> function also provides us with the following information:
The 95%  confidence interval  for the difference in mean exam scores between the two groups is <b>[0.3048, 13.8618</b>].
The mean exam score of the first group is <b>87.91667</b>.
The mean exam score of the second group is <b>80.83333</b>.
<em>You can find the complete documentation for the t.test() function  here .</em>
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Perform a One Sample t-test in R 
 How to Perform a Two Sample t-test in R 
 How to Perform a Paired Samples t-test in R 
 How to Plot Multiple Boxplots in One Chart in R 
<h2><span class="orange">How to Perform Welch’s t-test in Python</span></h2>
The most common way to compare the means between two independent groups is to use a <b>two-sample t-test</b>. However, this test assumes that the variances between the two groups is equal.
If you suspect that the variance between the two groups is <em>not </em>equal, then you can instead use <b> Welch’s t-test </b>, which is the non-parametric equivalent of the two-sample t-test.
To perform Welch’s t-test in Python, we can use the  ttest_ind() function  from the <b>SciPy</b> library, which uses the following syntax:
<b>ttest_ind(a, b, equal_var=False)</b>
where:
<b>a: </b>First array of data values
<b>b: </b>Second array of data values
<b>equal_var: </b>Specifies no assumption of equal variances between the two arrays
This tutorial explains how to use this function to perform Welch’s t-test in Python.
<h3>Example: Welch’s t-test in Python</h3>
Suppose we want to compare the exam scores of 12 students who used an exam prep booklet to prepare for some exam vs. 12 students who did not.
The following code shows how to perform Welch’s t-test in Python to determine if the mean exam scores are equal between the two groups:
<b>#import ttest_ind() function
from scipy import stats
#define two arrays of data
booklet = [90, 85, 88, 89, 94, 91, 79, 83, 87, 88, 91, 90]
no_booklet = [67, 90, 71, 95, 88, 83, 72, 66, 75, 86, 93, 84]
#perform Welch's t-test 
stats.ttest_ind(booklet, no_booklet, equal_var = False)
Ttest_indResult(statistic=2.23606797749, pvalue=0.04170979503207)
</b>
The test statistic turns out to be <b>2.2361 </b>and the corresponding p-value is <b>0.0417</b>.
Since this p-value is less than .05, we can reject the null hypothesis of the test and conclude that there is a statistically significant difference in mean exam scores between the two groups.
Note that the two sample sizes in this example were equal, but Welch’s t-test still works even if the two sample sizes are not equal.
<h2><span class="orange">Welch’s ANOVA in Python (Step-by-Step)</span></h2>
<b>Welch’s ANOVA</b> is an alternative to the typical  one-way ANOVA  when the  assumption of equal variances  is violated.
The following step-by-step example shows how to perform Welch’s ANOVA in Python.
<h3>Step 1: Create the Data</h3>
To determine if three different studying techniques lead to different exam scores, a professor randomly assigns 10 students to use each technique (Technique A, B, or C) for one week and then makes each student take an exam of equal difficulty. 
The exam scores of the 30 students are shown below:
<b>A = [64, 66, 68, 75, 78, 94, 98, 79, 71, 80]
B = [91, 92, 93, 90, 97, 94, 82, 88, 95, 96]
C = [79, 78, 88, 94, 92, 85, 83, 85, 82, 81]
</b>
<h3>Step 2: Test for Equal Variances</h3>
Next, we can perform  Bartlett’s test  to determine if the variances between each group is equal.
If the  p-value  of the test statistic is less than some significance level (like α = .05) then we can reject the null hypothesis and conclude that not all groups have the same variance.
We can use the following code to perform Bartlett’s test in Python:
<b>import scipy.stats as stats
#perform Bartlett's test 
stats.bartlett(A, B, C)
BartlettResult(statistic=9.039674395, pvalue=0.010890796567)
</b>
The p-value (<b>.01089</b>) from Bartlett’s test is less than α = .05, which means we can reject the null hypothesis that each group has the same variance.
Thus, the assumption of equal variances is violated and we can proceed to perform Welch’s ANOVA.
<h3>Step 3: Perform Welch’s ANOVA</h3>
To perform Welch’s ANOVA in Python, we can use the <b>welch_anova()</b> function from the Pingouin package.
First, we need to install Pingouin:
<b>pip install Pingouin
</b>
Next, we can use the following code to perform Welch’s ANOVA:
<b>import pingouin as pg
import pandas as pd
import numpy as np
#create DataFrame
df = pd.DataFrame({'score': [64, 66, 68, 75, 78, 94, 98, 79, 71, 80,             91, 92, 93, 90, 97, 94, 82, 88, 95, 96,             79, 78, 88, 94, 92, 85, 83, 85, 82, 81],   'group': np.repeat(['a', 'b', 'c'], repeats=10)}) 
#perform Welch's ANOVA
pg.welch_anova(dv='score', between='group', data=df)
        Sourceddof1ddof2        F        p-unc        np2
0group216.6512959.7171850.0015980.399286
</b>
The overall p-value (<b>.001598</b>) from the ANOVA table is less than α = .05, which means we can reject the null hypothesis that the exam scores are equal between the three studying techniques.
We can then perform the Games-Howell post-hoc test to determine exactly which group means are different:
<b>pg.pairwise_gameshowell(dv='score', between='group', data=df)
        ABmean(A)mean(B)diffse T   df   pval
0ab77.391.8-14.53.843754 -3.772354 11.6767 0.0072
1ac77.384.7-7.43.952777 -1.872102 12.7528 0.1864
2bc91.884.77.12.179959 3.256942  17.4419 0.0119
</b>
From the p-values we can see that the mean difference between groups <b>a</b> and <b>b</b> are significantly different and the mean difference between groups <b>b</b> and <b>c</b> are significantly different.
<h2><span class="orange">How to Perform Welch’s ANOVA in R (Step-by-Step)</span></h2>
<b>Welch’s ANOVA</b> is an alternative to the typical  one-way ANOVA  when the  assumption of equal variances  is violated.
The following step-by-step example shows how to perform Welch’s ANOVA in R.
<h3>Step 1: Create the Data</h3>
To determine if three different studying techniques lead to different exam scores, a professor randomly assigns 10 students to use each technique (Technique A, B, or C) for one week and then makes each student take an exam of equal difficulty. 
The exam scores of the 30 students are shown below:
<b>#create data frame
df &lt;-data.frame(group = rep(c('A','B', 'C'), each=10),
                score = c(64, 66, 68, 75, 78, 94, 98, 79, 71, 80,          91, 92, 93, 85, 87, 84, 82, 88, 95, 96,          79, 78, 88, 94, 92, 85, 83, 85, 82, 81))
#view first six rows of data frame
head(df)
   group score
1      A    64
2      A    66
3      A    68
4      A    75
5      A    78
6      A    94</b>
<h3>Step 2: Test for Equal Variances</h3>
Next, we can perform  Bartlett’s test  to determine if the variances between each group is equal.
If the  p-value  of the test statistic is less than some significance level (like α = .05) then we can reject the null hypothesis and conclude that not all groups have the same variance.
To perform Bartlett’s test we can use the <b>bartlett.test</b> function in base R, which uses the following syntax:
<b>bartlett.test(formula, data)</b>
Here’s how to use this function in our example:
<b>#perform Bartlett's test
bartlett.test(score ~ group, data = df)
Bartlett test of homogeneity of variances
data:  score by group
Bartlett's K-squared = 8.1066, df = 2, p-value = 0.01737
</b>
The p-value (<b>.01737</b>) from Bartlett’s test is less than α = .05, which means we can reject the null hypothesis that each group has the same variance.
Thus, the assumption of equal variances is violated and we can proceed to perform Welch’s ANOVA.
<h3>Step 3: Perform Welch’s ANOVA</h3>
To perform Welch’s ANOVA in R, we can use the <b>oneway.test()</b> function from base R as follows:
<b>#perform Welch's ANOVA
oneway.test(score ~ group, data = df, var.equal = FALSE)
One-way analysis of means (not assuming equal variances)
data:  score and group
F = 5.3492, num df = 2.00, denom df = 16.83, p-value = 0.01591
</b>
The overall p-value (<b>.01591</b>) from the ANOVA table is less than α = .05, which means we can reject the null hypothesis that the exam scores are equal between the three studying techniques.
We can then perform a post-hoc test to determine which group means are different. Refer to the following tutorials to see how to perform various post-hoc tests in R:
 How to Perform a Bonferroni Correction in R 
 How to Perform Tukey’s Test in R 
 How to Perform Scheffe’s Test in R 
Reference  this tutorial  to determine which post-hoc test is best to use depending on your situation.
<h2><span class="orange">Welch’s t-test Calculator</span></h2>
<b>Welch’s t-test</b> is used to test whether or not the means of two populations are equal.
This type of test does not assume that the two samples have equal variances. If you would like to make this assumption, you should instead use the  two sample t-test calculator .
To perform Welch’s t-test, simply fill in the information below and then click the “Calculate” button.
<label for="raw">Enter raw data</label>
<input type="radio" id="raw" name="tails" onclick="check()" checked><label for="summary">Enter summary data</label>
<input type="radio" id="summary" name="tails" onclick="check()">
<b>Sample 1</b>
<textarea id="rawData1" rows="5" cols="40">301, 298, 295, 297, 304, 305, 309, 298, 291, 299, 293, 304</textarea>
<b>Sample 2</b>
<textarea id="rawData2" rows="5" cols="40">302, 309, 324, 313, 312, 310, 305, 298, 299, 300, 289, 294</textarea>
<label><b>x<sub>1</sub></b> (sample 1 mean)</label>
<input type="number" id="x1" value="300">
<label><b>s<sub>1</sub></b> (sample 1 standard deviation)</label>
<input type="number" id="s1" value="18.5">
<label><b>n<sub>1</sub></b> (sample 1 size)</label>
<input type="number" id="n1" value="40">
<label><b>x<sub>2</sub></b> (sample 2 mean)</label>
<input type="number" id="x2" value="305">
<label><b>s<sub>2</sub></b> (sample 1 standard deviation)</label>
<input type="number" id="s2" value="16.7">
<label><b>n<sub>2</sub></b> (sample 2 size)</label>
<input type="number" id="n2" value="38">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>t = </b> -1.608761
<b>df = </b> 17
<b>p-value (one-tailed) = </b> 0.063040
<b>p-value (two-tailed) = </b> 0.126080
<script>
//set summary table to hidden to start
var summary_display = document.getElementById("summary_table");
summary_display.style.display = "none";
//find which radio button is checked
function check() {
if (document.getElementById('raw').checked) {
var table_display = document.getElementById("words_table");
        table_display.style.display = "block";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "none";
} else {
var table_display = document.getElementById("words_table");
        table_display.style.display = "none";
        var summary_display = document.getElementById("summary_table");
        summary_display.style.display = "block";
}
} //end check
//perform one-sample t-test
function calc() {
if (document.getElementById('summary').checked) {
var x1 = +document.getElementById('x1').value;
var s1 = +document.getElementById('s1').value;
var n1 = +document.getElementById('n1').value;
var x2 = +document.getElementById('x2').value;
var s2 = +document.getElementById('s2').value;
var n2 = +document.getElementById('n2').value;
var s12 = Math.pow(s1,2);
var s22 = Math.pow(s2,2);
var df1 = (Math.pow(s12/n1 - (-1*s22/n2),2)) / ((Math.pow(s12/n1,2)/(n1-1)) - (-1*Math.pow(s22/n2,2)/(n2-1)));
var df = Math.floor(df1);
var t = (x1-x2)/(Math.sqrt(Math.pow(s1,2)/n1 - (-1*Math.pow(s2,2)/n2)));
if (t<0) {
var p1 = jStat.studentt.cdf(t, df);
var p2 = p1*2;
} else {
var p1 = 1-jStat.studentt.cdf(t, df);
var p2 = p1*2;
}
document.getElementById('t').innerHTML = t.toFixed(6);
document.getElementById('df').innerHTML = df;
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
} else {
var raw1 = document.getElementById('rawData1').value.split(',').map(Number);
var raw2 = document.getElementById('rawData2').value.split(',').map(Number);
var x1 = math.mean(raw1)
var s1 = math.std(raw1)
var n1 = raw1.length;
var x2 = math.mean(raw2)
var s2 = math.std(raw2)
var n2 = raw2.length;
var s12 = Math.pow(s1,2);
var s22 = Math.pow(s2,2);
var df1 = (Math.pow(s12/n1 - (-1*s22/n2),2)) / ((Math.pow(s12/n1,2)/(n1-1)) - (-1*Math.pow(s22/n2,2)/(n2-1)));
var df = Math.floor(df1);
var t = (x1-x2)/(Math.sqrt(Math.pow(s1,2)/n1 - (-1*Math.pow(s2,2)/n2)));
if (t<0) {
var p1 = jStat.studentt.cdf(t, df);
var p2 = p1*2;
} else {
var p1 = 1-jStat.studentt.cdf(t, df);
var p2 = p1*2;
}
document.getElementById('t').innerHTML = t.toFixed(6);
document.getElementById('df').innerHTML = df;
document.getElementById('p1').innerHTML = p1.toFixed(6);
document.getElementById('p2').innerHTML = p2.toFixed(6);
}
//output results
}
</script>
<h2><span class="orange">How to Perform Welch’s t-test in Excel</span></h2>
The most common way to compare the means between two independent groups is to use a <b>two-sample t-test</b>. However, this test assumes that the variances between the two groups is equal.
If you suspect that the variance between the two groups is <em>not </em>equal, then you can instead use <b> Welch’s t-test </b>, which is the non-parametric equivalent of the two-sample t-test.
This tutorial explains how to perform Welch’s t-test in Excel.
<h2>Example: Welch’s t-test in Excel</h2>
For this example we will compare the exam scores of 12 students who used an exam prep booklet to prepare for the exam vs. 12 students who did not.
Use the following steps to perform a Welch’t t-test to determine if there is a difference in the mean exam scores between the two groups.
<b>Step 1: Enter the data.</b>
First, enter the exam scores into two columns:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchExcel1.png">
<b>Step 2: Perform Welch’s t-test.</b>
Along the top ribbon in Excel, go to the <b>Data</b> tab and click on <b>Data Analysis</b>. If you don’t see this option, then you need to first  install the free Analysis ToolPak .
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
Once you click on Data Analysis, a new window will pop up. Select <b>t-Test: Two-Sample Assuming Unequal Variances </b>and click <b>OK</b>.
In the new window, type in the range of data values for both <b>Variable 1 </b>and <b>Variable 2</b>, including their group labels. For <b>Hypothesized Mean Difference</b>, type 0. Check the box next to <b>Labels</b>. Leave <b>Alpha </b>set to 0.05. For <b>Output Range</b>, choose a cell where you’d like the results of the test to appear. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchExcel2.png">
The following output automatically appears:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchExcel3.png">
Here is how to interpret the output:
<b>Mean: </b>The mean exam score for each group.
<b>Variance: </b>The variance of exam scores for each group.
<b>Observations: </b>The sample size for each group.
<b>Hypothesized Mean Difference: </b>The mean difference to use in the null hypothesis of the test.
<b>df: </b>The degrees of freedom to be used with the test statistic, calculated as n<sub>1</sub> + n<sub>2</sub> – 2.
<b>t Stat: </b>The test statistic for the test.
<b>P(T&lt;=t) one-tail: </b>The p-value associated with the test statistic for a one-tailed test. Ignore this since we’re conducting a two-tailed test.
<b>P(T&lt;=t) two-tail: </b>The p-value associated with the test statistic for a two-tailed test. Since this is less than 0.05, we would reject the null hypothesis and conclude that the mean exam score between the two groups is statistically significantly different at the level α = 0.05.
<b>Step 3: Report the results.</b>
Lastly, we want to report the results of our Welch’s t-test. Here is an example of how to do so:
A Welch’s t-test was performed to determine if there was a statistically significant difference in exam scores between a group of students that used an exam prep booklet to prepare for the exam vs. a group that did not. The sample size for both groups was 12 students.
 
A Welch’s t-test revealed that there was a statistically significant difference in mean exam scores (t = 2.236, p = 0.0421) between the two groups.
<h2><span class="orange">How to Perform Welch’s t-Test in SAS</span></h2>
 Welch’s t-test  is used to compare the means between two independent groups when it is <em>not</em> assumed that the two groups have equal variances.
This tutorial explains how to perform a Welch’s t-test in SAS.
<h3>Example: Welch’s t-Test in SAS</h3>
Suppose a teacher wants to compare the exam scores of 12 students who used an exam prep booklet to prepare for some exam vs. 12 students who did not.
The following lists show the exam scores for the students in each group:
<b>Booklet</b>: 90, 85, 88, 89, 94, 91, 79, 83, 87, 88, 91, 90
<b>No Booklet</b>: 67, 90, 71, 95, 88, 83, 72, 66, 75, 86, 93, 84
Use the following steps to perform Welch’s t-test to determine if the mean exam score is equal between the two groups.
<b>Step 1: Create the data.</b>
First, we’ll use the following code to create the dataset in SAS:
<b>/*create dataset*/
data exam_scores;
    input group $ score;
    datalines;
booklet 90
booklet 85
booklet 88
booklet 89
booklet 94
booklet 91
booklet 79
booklet 83
booklet 87
booklet 88
booklet 91
booklet 90
no_booklet 67
no_booklet 90
no_booklet 71
no_booklet 95
no_booklet 88
no_booklet 83
no_booklet 72
no_booklet 66
no_booklet 75
no_booklet 86
no_booklet 93
no_booklet 84
;
run;</b>
<b>Step 2: Perform Welch’s t-test.</b>
Next, we’ll use <b>proc ttest</b> to perform Welch’s t-test:
<b>/*perform Welch's t-test*/
proc ttest data=exam_scores alpha=0.05;
    class group;
    var score;
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/welch1.jpg"502">
The last table titled <b>Equality of Variances</b> performs an F-test to determine if the variances are equal between the two samples.
This F-test uses the following null and alternative hypotheses:
<b>H<sub>0</sub></b>: The variances are equal.
<b>H<sub>A</sub></b>: The variances are not equal.
Since the p-value (.<b>0046</b>) of this test is less than .05, we reject the null hypothesis. This means the two sample variances are not equal.
Thus, we must refer to the row titled <b>Unequal</b> in the second to last table to determine the t value and corresponding p-value to use:
t Value: <b>2.24</b>
p-value: <b>.0417</b>
Recall that Welch’s t-test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub>
<b>H<sub>A</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub>
Since the p-value (<b>.0417</b>) is less than .05, we reject the null hypothesis.
This means we have sufficient evidence to say that the mean exam score between the two groups is not equal.
<b>Bonus</b>: Feel free to use this  Welch’s t-test Calculator  to automatically perform Welch’s t-test for any two samples.
<h2><span class="orange">How to Perform Welch’s t-test in Stata</span></h2>
The most common way to compare the means between two independent groups is to use a  two-sample t-test . However, this test assumes that the variances between the two groups is equal.
If you suspect that the variance between the two groups is <em>not </em>equal, then you can instead use  Welch’s t-test , which is the non-parametric equivalent of the two-sample t-test.
This tutorial explains how to perform Welch’s t-test in Stata.
<h2>Example: Welch’s t-test in Stata</h2>
For this example we will use the <em>fuel3 </em>dataset, which contains the mpg of 12 cars that received a certain fuel treatment and 12 cars that did not.
Use the following steps to perform a Welch’t t-test to determine if there is a difference in the mean mpg between the two groups.
<b>Step 1: Load and view the data.</b>
First, load the dataset by typing the following command into the Command box:
<b>use http://www.stata-press.com/data/r13/fuel3</b>
View the raw data by using the following command:
<b>list</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchStata1.png">
<b>Step 2: Visualize the data.</b>
Before we perform Welch’s t-test, let’s first create two  box plots  to visualize the distribution of mpg for each group:
<b>graph box mpg, over(treated)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchStata2.png">
We can see that the mpg for group 1 (the group that received the fuel treatment) tends to be higher than that of group 0. We can also see that the variance for group 1 looks quite a bit smaller than that of group 0 (the width of the box is smaller).
<b>Step 3: Perform Welch’s t-test</b>
Use the following syntax to perform Welch’s t-test:
<b>ttest variable_to_measure, by(grouping_variable) welch</b>
Here is the syntax for our particular example:
<b>ttest mpg, by(treated) welch</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/welchStata3.png">
Here is how to interpret the output:
The mean mpg for Group 0 was <b>21</b>. The 95% confidence interval for the true population mean was <b>(19.26525, 22.73745)</b>.
The mean mpg for Group 1 was <b>22.75</b>. The 95% confidence interval for the true population mean was <b>(20.68449, 24.81551)</b>.
The mean difference in mpg for Group 0 – Group 1 was <b>-1.75</b>. The 95% confidence interval for the true difference in population means was <b>(-4.28369, .7836902)</b>.
The test statistic, <em>t</em>, for Welch’s t-test was <b>-1.4280</b>. 
Because we are interested in the alternative hypothesis that the mean mpg was simply different between the two groups, we will look at the p-value associated with Ha: diff != 0, which turns out to be <b>0.1666</b>. Since this value is not less than 0.05, we do not have sufficient evidence to say that the mean mpg between the two groups is different.
<b>Step 4: Report the results.</b>
Lastly, we want to report the results of our Welch’s t-test. Here is an example of how to do so:
A Welch’s t-test was performed to determine if there was a statistically significant difference in mpg between a group  of cars that received a fuel treatment and a group that did not. The sample size for both groups was 12 cars.
 
A Welch’s t-test revealed that there was <em>not </em>a statistically significant difference in means (t = -1.4280, p = 0.1666) between the two groups.
 
The 95% confidence interval for the true mean difference in group 0 (non-treatment group) and group 1(treatment group) was found to be (-4.28369, .7836902).
<h2><span class="orange">Welch’s t-test: When to Use it + Examples</span></h2>
When we want to compare the means of two independent groups, we can choose between using two different tests:
<b>Student’s t-test: </b>this test assumes that both groups of data are sampled from populations that follow a  normal distribution  and that both populations have the same variance.
<b>Welch’s t-test: </b>this test assumes that both groups of data are sampled from populations that follow a normal distribution, <em>but it does not assume that those two populations have the same variance</em>.
<h2>The Difference Between Student’s t-test and Welch’s t-test</h2>
There are two differences in how the Student’s t-test and Welch’s t-test are carried out:
<b>The test statistic</b>
<b>The degrees of freedom</b>
<h3>Student’s t-test:</h3>
<b>Test statistic:</b> (x<sub>1</sub> – x<sub>2</sub>)  /  s<sub>p</sub>(√1/n<sub>1</sub> + 1/n<sub>2</sub>)
where x<sub>1</sub> and x<sub>2</sub> are the sample means, n<sub>1 </sub>and n<sub>2 </sub>are the sample sizes for sample 1 and sample 2, respectively, and where s<sub>p</sub> is calculated as:
s<sub>p</sub> = √ (n<sub>1</sub>-1)s<sub>1</sub><sup>2</sup> +  (n<sub>2</sub>-1)s<sub>2</sub><sup>2</sup> /  (n<sub>1</sub>+n<sub>2</sub>-2)
where s<sub>1</sub><sup>2</sup> and s<sub>2</sub><sup>2</sup> are the sample variances.
<b>Degrees of freedom:</b> n<sub>1 </sub>+ n<sub>2 </sub>– 2
<h3>Welch’s t-test</h3>
<b>Test statistic: </b>(x<sub>1</sub> – x<sub>2</sub>)  /  (√s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)
<b>Degrees of freedom:</b> (s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup> / { [ (s<sub>1</sub><sup>2</sup> / n<sub>1</sub>)<sup>2</sup> / (n<sub>1</sub> – 1) ] + [ (s<sub>2</sub><sup>2</sup> / n<sub>2</sub>)<sup>2</sup> / (n<sub>2</sub> – 1) ] }
The formula to calculate the degrees of freedom for Welch’s t-test takes into account the difference between the two standard deviations. If the two  samples  have the same standard deviations, though, then the degrees of freedom for the Welch’s t-test will be the exact same as the degrees of freedom for the Student’s t-test.
Typically, the standard deviations for the two samples are not the same and thus the degrees of freedom for Welch’s t-test tends to be smaller than the degrees of freedom for Student’s t-test.
It’s also important to note that the degrees of freedom for the Welch’s t-test typically is typically not an integer. If you are conducting the test by hand, it’s best practice to round down to the next lowest integer. If you are using a statistical software like <em>R</em>, the software will be able to hand the decimal value for the degrees of freedom.
<h2>When Should You Use Welch’s t-test?</h2>
Some people argue that  the Welch’s t-test should be the default choice  for comparing the means of two independent groups since it performs better than the Student’s t-test when sample sizes and variances are unequal between groups, and it gives identical results when sample sizes are variances are equal.
In practice, when you are comparing the means of two groups it’s unlikely that the standard deviations for each group will be identical. This makes it a good idea to just always use Welch’s t-test, so that you don’t have to make any assumptions about equal variances. 
<h2>Examples of Using Welch’s t-test</h2>
Next, we will perform Welch’s t-test on the following two samples to determine if their populations means differ significantly at a significance level of 0.05:
<b>Sample 1:</b> 14, 15, 15, 15, 16, 18, 22, 23, 24, 25, 25
<b>Sample 2:</b> 10, 12, 14, 15, 18, 22, 24, 27, 31, 33, 34, 34, 34
We’ll illustrate how to conduct the test in three different ways:
By hand
Using Microsoft Excel
Using the statistical programming language <em>R</em>
<h3>Welch’s t-test by Hand</h3>
To conduct Welch’s t-test by hand, we first need to find the sample means, sample variances, and sample sizes:
<b>x<sub>1</sub> </b>– 19.27
<b>x<sub>2</sub></b> – 23.69
<b>s<sub>1</sub><sup>2</sup></b> – 20.42
<b> s<sub>2</sub><sup>2</sup> </b>– 83.23
<b>n</b><sub><b>1 </b></sub>– 11<b>
n</b><sub><b>2</b> </sub>– 13
Next, we can plug in these numbers to find the test statistic:
<b>Test statistic: </b>(x<sub>1</sub> – x<sub>2</sub>)  /  (√s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)
Test statistic: (19.27 – 23.69) / (√20.42/11 + 83.23/13) =  -4.42 / 2.873  =  <b>-1.538</b>
<b>Degrees of freedom:</b> (s<sub>1</sub><sup>2</sup>/n<sub>1</sub> + s<sub>2</sub><sup>2</sup>/n<sub>2</sub>)<sup>2</sup> / { [ (s<sub>1</sub><sup>2</sup> / n<sub>1</sub>)<sup>2</sup> / (n<sub>1</sub> – 1) ] + [ (s<sub>2</sub><sup>2</sup> / n<sub>2</sub>)<sup>2</sup> / (n<sub>2</sub> – 1) ] }
Degrees of freedom: (20.42/11 + 83.23/13)<sup>2</sup> / { [ (20.42/11)<sup>2</sup> / (11 – 1) ] + [ (83.23/13)<sup>2</sup> / (13 – 1) ] } = 18.137. We round this down to the next nearest integer of <b>18</b>.
Lastly, we will find the <em>t </em>critical value in the t-distribution table that corresponds to a two-tailed test with alpha = .05 for 18 degrees of freedom:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/t_dist.png">
The t critical value is <b>2.101</b>. Since the absolute value of our test statistic (1.538) is not larger than the t critical value, we fail to reject the null hypothesis of the test. There is not sufficient evidence to say that the means of the two populations are significantly different.
<h3>Welch’s t-test Using Excel</h3>
To conduct Welch’s t-test in Excel, we first need to download the free Analysis ToolPak. If you don’t already have this downloaded in Excel, I wrote up  a quick tutorial on how to download it .
Once you have the Analysis ToolPak downloaded, you can follow the steps below to conduct Welch’s t-test on our two samples:
<b>1. Input the data.</b> Enter the data values for the two samples in columns A and B along with the headers <em>Sample 1 </em>and <em>Sample 2</em> in the first cell of each column.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/welch1.jpg">
<b>2. Conduct Welch’s t-test using the Analysis ToolPak. </b>Navigate to the <b>Data </b>tab along the top ribbon. Then, under the <b>Analysis</b> group, click the icon for the Analysis ToolPak.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/welch2.jpg">
In the box that pops up, click <b>t-Test: Two Sample Assuming Unequal Variances</b>, then click OK.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/welch3.jpg">
Lastly, fill in the values below and then click OK:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/welch4.jpg">
The following output should appear:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/05/welch5-1.jpg">
Notice that the results of this test match the results that we got by hand:
The test statistic is <b>-1.5379</b>.
The critical two-tail value is <b>2.1009</b>.
Since the absolute value of the test statistic is not greater than the critical two-tail value, the two populations means are not statistically different.
Also, the two-tailed p-value of the test is 0.14, which is larger than 0.05 and confirms that the two population means are not statistically different.
<h3>Welch’s t-test Using R</h3>
The following code illustrates how to perform Welch’s t-test for our two samples using the statistical programming language <em>R</em>:
<b>#create two vectors to hold sample data values
sample1 &lt;- c(14, 15, 15, 15, 16, 18, 22, 23, 24, 25, 25)
sample2 &lt;- c(10, 12, 14, 15, 18, 22, 24, 27, 31, 33, 34, 34, 34)
#conduct Welch's test
t.test(sample1, sample2)
#Welch Two Sample t-test
#
#data:  sample1 and sample2
#t = -1.5379, df = 18.137, p-value = 0.1413
#alternative hypothesis: true difference in means is not equal to 0
#95 percent confidence interval:
# -10.453875   1.614714
#sample estimates:
#mean of x mean of y 
# 19.27273  23.69231 
#              </b>
The <b>t.test() </b>function displays the following relevant output:
<b>t: </b>the test statistic =<b> -1.5379</b>
<b>df</b>: the degrees of freedom = <b>18.137</b>
<b>p-value:</b> the p-value of the two-sided test = <b>0.1413</b>
<b>95% confidence interval</b>: the 95%  confidence interval  for the true difference in population means = <b>(-10.45, 1.61)</b>
The results of this test match the results we got by hand and by using Excel: the difference in means for these two populations is not statistically significant at the level of alpha = 0.05.
<h2><span class="orange">What are Cases in Statistics? (Definition & Examples)</span></h2>
In statistics, <b>cases</b> simply refer to the individuals in a dataset.
In most datasets, we have <b>cases</b> (the individuals) and <b>variables</b> (the attributes for the individuals).
For example, the following dataset contains 10 cases and 3 variables that we measure for each case:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/case1.png">
Notice that each case has multiple variables or “attributes.”
For example, each player has a value for points, assists, and rebounds.
Note that cases are also sometimes called <b>experimental units</b>. These terms are used interchangeably.
Check out the following examples to gain an even better understanding of cases.
<h3>Example 1: Education</h3>
The following dataset contains 10 cases and 2 variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/case2.png">
The <b>cases</b> are the individual students and the <b>variables</b> are time studied and exam score.
<h3>Example 2: Business</h3>
The following dataset contains 6 cases and 3 variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/case3.png">
The <b>cases</b> are the individual stores and the <b>variables</b> are total sales, total customers, and total refunds.
<h3>Example 3: Biology</h3>
The following dataset contains 15 cases and 3 variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/case4.png">
The <b>cases</b> are the individual plants and the <b>variables</b> are height, width, and age.
<h2><span class="orange">What Does a High F Value Mean in ANOVA?</span></h2>
A  one-way ANOVA  is used to determine whether or not the means of three or more independent groups are equal.
A one-way ANOVA uses the following null and alternative hypotheses:
<b>H<sub>0</sub>:</b> All group means are equal.
<b>H<sub>A</sub>:</b> At least one group mean is different from the rest.
Whenever you perform a one-way ANOVA, you will end up with a summary table that looks like the following:
<table><tbody>
<tr>
<th style="text-align: center;"><b>Source</b></th>
<th style="text-align: center;"><b>Sum of Squares (SS)</b></th>
<th style="text-align: center;"><b>df</b></th>
<th style="text-align: center;"><b>Mean Squares (MS)</b></th>
<th style="text-align: center;"><b>F</b></th>
<th style="text-align: center;"><b>P-value</b></th>
</tr>
<tr>
<td><b>Treatment</b></td>
<td style="text-align: center;">192.2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">2.358</td>
<td style="text-align: center;">0.1138</td>
</tr>
<tr>
<td><b>Error</b></td>
<td style="text-align: center;">1100.6</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">40.8</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td><b>Total</b></td>
<td style="text-align: center;">1292.8</td>
<td style="text-align: center;">29</td>
<td> </td>
<td> </td>
<td> </td>
</tr>
</tbody></table>
The <b>F-value</b> in the table is calculated as:
F-value = Mean Squares Treatment / Mean Squares Error
Another way to write this is as follows:
F-value = variation between sample means / variation within the samples
If the variation between the sample means is high relative to the variation within each of the samples, then the F-value will be large.
For example, the F-value in the table above is calculated as:
F-value = 96.1 / 40.8 = 2.358
To find the  p-value  that corresponds to this F-value, we can use an  F Distribution Calculator  with numerator degrees of freedom = df Treatment and denominator degrees of freedom = df Error.
For example, the p-value that corresponds to an F-value of 2.358, numerator df = 2, and denominator df = 27 is <b>0.1138</b>.
Since this p-value is not less than α = .05, we fail to reject the null hypothesis. This means there is no statistically significant difference between the means of the three groups.
<h3>Visualizing the F-Value of an ANOVA</h3>
To gain an intuitive understanding of the F-value in an ANOVA table, consider the following example.
Suppose we’d like to perform a one-way ANOVA to determine if three different studying techniques produce different mean exam scores. The following table shows the exam scores of 10 students who used each technique:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/highf1.png">
We can create the following plot to visualize the exam scores by group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/highf2.png">
The variation <em>within</em> the samples is represented by the spread of the values within each individual sample:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/highf3.png">
The variation <em>between</em> the samples is represented by the differences between the sample means:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/highf4.png">
Upon performing a one-way ANOVA for this dataset, we find that the F-value is <b>2.358</b> and the corresponding p-value is <b>0.1138</b>.
Since this p-value is not less than .05, we fail to reject the null hypothesis. This means we don’t have sufficient evidence to say that the studying technique used causes statistically significant differences in mean exam scores.
In other words, this tells us that the variation between the sample means is not high enough relative to the variation within the samples to reject the null hypothesis.
<h3>Conclusion</h3>
Here’s a brief summary of the main points in this article:
The F-value in an ANOVA is calculated as: variation between sample means / variation within the samples.
The higher the F-value in an ANOVA, the higher the variation between sample means relative to the variation within the samples.
The higher the F-value, the lower the corresponding p-value.
If the p-value is below a certain threshold (e.g. α = .05), we can reject the null hypothesis of the ANOVA and conclude that there is a statistically significant difference between group means.
<h2><span class="orange">What Does It Mean If A Statistic Is Resistant?</span></h2>
A statistic is said to be <b>resistant</b> if it is not sensitive to extreme values.
Two examples of statistics that are resistant include:
The median
The interquartile range
Examples of statistics that are <em>not</em> resistant include:
The mean
The standard deviation
The range
The following example illustrates the difference between resistant and non-resistant statistics.
<h3>Example: Resistant vs. Non-Resistant Statistics</h3>
Suppose we have the following dataset:
<b>Dataset:</b> 2, 5, 6, 7, 8, 13, 15, 18, 22, 24, 29
Using a calculator or statistical software, we can compute the value of the following resistant statistics for this dataset:
Median: 13
Interquartile range: 13.5
We can also compute the value of the following non-resistant statistics for this dataset:
Mean: 13.54
Standard deviation: 8.82
Range: 27
Now consider if this dataset had one extreme outlier added to it:
<b>Dataset:</b> 2, 5, 6, 7, 8, 13, 15, 18, 22, 24, 29, <b>450</b>
We can once again compute the value of the following resistant statistics for this dataset:
Median: 14
Interquartile range: 15.75
We can also compute the value of the following non-resistant statistics for this dataset:
Mean: 49.92
Standard deviation: 126.27
Range: 448
Notice how drastically the non-resistant statistics changed by simply adding one extreme value to the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/resistant1.png">
Conversely, the resistant statistics barely changed at all. Both the median and the interquartile range only changed by a little.
<h3>When to Use Resistant Statistics</h3>
The most common statistics used to measure  the center  and  the dispersion  of values in a dataset are the mean and the standard deviation, respectively.
Unfortunately, these two statistics are sensitive to extreme values. So, if outliers are present in a dataset then the mean and standard deviation won’t accurately describe the distribution of values in a dataset.
Instead, it’s recommended to use the median and the interquartile range to measure the center and the dispersion of values in a dataset if outliers are present because these two statistics are <b>resistant</b>.
<h2><span class="orange">How to Perform What-If Analysis in Google Sheets</span></h2>
<b>What-if analysis</b> is a type of analysis that allows you to plug in different numbers into formulas to see how the results change.
For example, suppose a store sells three different products at different prices and calculates the total revenue from these products:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif1.png">
Now suppose the store manager would like to know how many more units of product A need to be sold to reach a total revenue of $2,000.
The following step-by-step example shows how to perform this exact what-if analysis in Google Sheets.
<h3>Step 1: Get the Goal Seek Add-On</h3>
Before we perform what-if analysis, we need to first get the Goal Seek add-on.
To do so, click the <b>Add-ons</b> tab and then click <b>Get add-ons</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif2.png">
Search for “Goal Seek” and then click the first result that says <b>Goal Seek for Sheets</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif3.png">
Then click <b>Install</b>. You will be asked for permission to install Goal Seek. Choose to accept.
The Goal Seek add-on will then be added to the <b>Add-ons</b> tab.
<h3>Step 2: Perform What-If Analysis</h3>
Next, click the <b>Add-ons</b> tab and then click <b>Goal Seek</b> and then click <b>Open</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif4.png">
In the Goal Seek panel that appears, input the following cell values and then click <b>Solve</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif5.png">
The Goal Seek will try various values in D2 until it’s able to achieve the value 2000 in cell D5.
Here is the result that it finds:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif6.png">
This tells us that the store must sell roughly 860 units of product A in order to increase the total revenue up to $2,000.
The Goal Seek panel also provides us with information about how long the Goal Seek took to find a solution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/whatif7.png">
It took 20.3 seconds to find a solution and Goal Seek tried 48 iterations until it found the final solution.
<b>Note</b>: Within the Goal Seek panel, there is an “Options” button where you can specify the max number of seconds or iterations to use until Goal Seek stops running. By default, the max iterations is set to 200 and the max time limit is set to 120 seconds.
<h2><span class="orange">What is Considered a Good AIC Value?</span></h2>
The Akaike information criterion (AIC) is a metric that is used to compare the fit of different regression models.
It is calculated as:
AIC = 2K – 2<em>ln</em>(L)
where:
<b>K:</b> The number of model parameters.
<b><em>ln</em>(L)</b>: The log-likelihood of the model. This tells us how likely the model is, given the data.
Once you’ve fit several regression models, you can compare the AIC value of each model. The model with the lowest AIC offers the best fit.
One question students often have about AIC is: <em><b>What is considered a good AIC value?</b></em>
The simple answer: <b>There is no value for AIC that can be considered “good” or “bad” because we simply use AIC as a way to compare regression models. The model with the lowest AIC offers the best fit. The absolute value of the AIC value is not important.</b>
For example, if Model 1 has an AIC value of 730.5 and Model 2 has an AIC value of 456.3, then Model 2 offers a better fit. The absolute values of the AIC are not important.
A useful reference on this topic comes from  <em>Serious Stats: A Guide to Advanced Statistics for the Behavioral Sciences</em>  on page 402:
As with likelihood, the absolute value of AIC is largely meaningless (being determined by the arbitrary constant). As this constant depends on the data, AIC can be used to compare models fitted on identical samples.
 
The best model from the set of plausible models being considered is therefore the one with the smallest AIC value (the least information loss relative to the true model).
As noted in the textbook, the absolute value of the AIC is not important. We simply use AIC values to compare the fit of models and the model with the lowest AIC value is best.
<h3>How to Determine if a Model Fits a Dataset Well</h3>
The AIC value is a useful way to determine which regression model fits a dataset the best among a list of potential models, but it doesn’t actually quantify <em> how well</em> the model fits the data.
For example, a particular regression model might have the lowest AIC value among a list of potential models, but it may still be a poor fitting model.
To determine if a model fits a dataset well, we can use the following two metrics:
 Mallows’ Cp : A metric that quantifies the amount of bias in regression models.
 Adjusted R-squared : The proportion of the variance in the response variable that can be explained by the predictor variables in the model, adjusted for the number of predictor variables in the model.
One potential strategy for choosing the “best” regression model among several potential models is as follows:
First, identify the model with the lowest AIC value.
Then, fit this regression model to the data and calculate the Mallows’ Cp and adjusted R-squared of the model to quantify how well it actually fits the data.
This approach allows you to identify the best fitting model <em>and</em> quantify how well the model actually fits the data.
<h2><span class="orange">What is Considered a Good AUC Score?</span></h2>
 Logistic Regression  is a method that we use to fit a regression model when the response variable is binary.
To assess how well a logistic regression model fits a dataset, we can look at the following two metrics:
<b>Sensitivity: </b>The probability that the model predicts a positive outcome for an observation when indeed the outcome is positive. This is also called the “true positive rate.”
<b>Specificity: </b>The probability that the model predicts a negative outcome for an observation when indeed the outcome is negative. This is also called the “true negative rate.”
One way to visualize these two metrics is by creating a <b>ROC curve</b>, which stands for “receiver operating characteristic” curve.
This is a plot that displays the sensitivity along the y-axis and (1 – specificity) along the x-axis.
One way to quantify how well the logistic regression model does at classifying data is to calculate <b>AUC</b>, which stands for “area under curve.”
The value for AUC ranges from 0 to 1. A model that has an AUC of 1 is able to perfectly classify observations into classes while a model that has an AUC of 0.5 does no better than a model that performs random guessing.
<h3>What is a Good AUC Score?</h3>
One question students often have about AUC is:
<em><b>What is a good AUC score?</b></em>
The answer:
<b>There is no specific threshold for what is considered a good AUC score.</b>
Obviously the higher the AUC score, the better the model is able to classify observations into classes. 
And we know that a model with an AUC score of 0.5 is no better than a model that performs random guessing.
However, there is no magic number that determines if an AUC score is good or bad.
If we<em> must</em> label certain scores as good or bad, we can reference the following rule of thumb from Hosmer and Lemeshow in  <em>Applied Logistic Regression</em>  (p. 177):
<b>0.5</b> = No discrimination
<b>0.5-0.7</b> = Poor discrimination
<b>0.7-0.8</b> = Acceptable discrimination
<b>0.8-0.9</b>= Excellent discrimination
<b>>0.9</b> = Outstanding discrimination
By these standards, a model with an AUC score below 0.7 would be considered poor and anything higher would be considered acceptable or better.
<h3>A “Good” AUC Score Varies by Industry</h3>
It’s important to keep in mind that what is considered a “good” AUC score varies by industry.
For example, in medical settings researchers often seeking AUC scores above 0.95 because the cost of being wrong is so high.
For example, if we have a logistic regression model that predicts whether or not a patient will develop cancer, the price of being wrong (incorrectly telling a patient they do not have cancer when they do) is so high that we want a model that is correctly nearly every time.
Conversely, in other industries like marketing a lower AUC score may be acceptable for a model.
For example, if we have a model that predicts whether or not a customer will be a repeat customer or not, the price of being wrong is not life-altering so a model with an AUC as low as 0.6 could still be useful.
<h3>Compare AUC Scores to the Current Model</h3>
In real-world settings, we often compare the AUC scores of new logistic regression models with the AUC score of the current model being used.
For example, suppose a business uses a logistic regression model to predict whether or not customers will be repeat customers.
If the current model has an AUC score of 0.6 and you develop a new model that has an AUC of 0.65, then the new model that you have developed will be preferable even though it only offers a slight improvement and would be considered “poor” by the standards of Hosmer and Lemeshow.
<h2><span class="orange">What is Considered a Good Coefficient of Variation?</span></h2>
A <b>coefficient of variation</b>, often abbreviated <em>CV</em>, is a way to measure how spread out values are in a dataset relative to the mean. It is calculated as:
<b>CV = σ / μ</b>
where:
<b>σ:</b> The standard deviation of dataset
<b>μ:</b> The mean of dataset
Simply put, the coefficient of variation is the ratio between the standard deviation and the mean.
For example:
A CV of 0.5 means the standard deviation is half as large as the mean.
A CV of 1 means the standard deviation is equal to the mean.
A CV of 1.5 means the standard deviation is 1.5 times larger than the mean.
The higher the coefficient of variation, the higher the standard deviation <em>relative</em> to the mean.
<h3>What is a Good Coefficient of Variation?</h3>
One questions that students often have is: <em><b>What is considered a good value for a coefficient of variation?</b></em>
The answer: <b>There is no specific value for a coefficient of variation that is considered to be a “good” value. It depends on the situation.</b>
In most cases, the lower the coefficient of variation the better because it means the spread of data values is low relative to the mean. The following examples illustrate this phenomenon in different fields.
<b>Finance:</b>
In the finance industry, the coefficient of variation is used to compare the mean expected return of an investment relative to the expected standard deviation of the investment.
For example, suppose an investor is considering investing in the following two mutual funds:
Mutual Fund A: mean = 9%, standard deviation = 12.4%
Mutual Fund B: mean = 5%, standard deviation = 8.2%
The investor can calculate the coefficient of variation for each fund:
CV for Mutual Fund A = 12.4% / 9% = 1.38
CV for Mutual Fund B = 8.2% / 5% = 1.64
Since Mutual Fund A has a lower coefficient of variation, it offers a better mean return relative to the standard deviation.
<b>Retail:</b>
In the retail industry, companies often calculate the coefficient of variation to understand the variation of their revenue from one week to the next.
For example, consider the following mean weekly sales and standard deviation of weekly sales for two different companies:
Company A: Mean Weekly Sales = $4,000, Standard Deviation = $1,500
Company B: Mean Weekly Sales = $8,000, Standard Deviation  = $2,000
We can calculate the coefficient of variation for each store:
CV for Company A: $1,500 / $4,000 = 0.375
CV for Company B: $2,000 / $8,000 = 0.25
Since Company B has a lower CV, it has lower volatility in weekly sales relative to the mean compared to company A. This means Company B can likely predict their weekly sales with more certainty than Company A.
<b>Economics:</b>
Economists often calculate the coefficient of variation for annual income in different cities to understand which cities have more inequality.
For example, consider the mean and standard deviation of annual incomes for residents in two different cities:
City A: Mean Income: $50,000, Standard Deviation = $5,000
City B: Mean Income: $77,000, Standard Deviation = $6,000
We can calculate the coefficient of variation for each city:
CV for City A: $5,000 / $50,000 = 0.1
CV for City B: $6,000 / $77,000 = 0.078
Since City B has a lower CV, it has a lower standard deviation of incomes <em>relative</em> to its mean income. This means there is less variation in incomes relative to the mean income of residents in City B compared to City A.
<h3>Conclusion</h3>
There is no specific value that is considered “low” for a coefficient of variation.
Instead, the coefficient of variation is often compared between two or more groups to understand which group has a lower standard deviation relative to its mean.
In most fields, lower values for the coefficient of variation are considered better because it means there is less variability around the mean.
<h2><span class="orange">What is Considered a Good Confidence Interval?</span></h2>
A <b>confidence interval</b> is a range of values that is likely to contain a population  parameter  with a certain level of confidence.
One question students often have is:
<b><em>What is considered a good confidence interval?</em></b>
The answer: In general, narrow confidence intervals are more desirable since this provides us with a narrow range of values that we’re confident contains some population parameter.
For example, suppose we want to estimate the mean height of a certain species of plant and we create the following 95% confidence interval:
95% Confidence Interval = [12.5 inches, 60.5 inches]
Compare this to the following 95% confidence interval:
95% Confidence Interval = [34 inches, 39 inches]
The second confidence interval is much narrower and gives us a more precise idea of what the true population mean height may be.
However, in order to obtain a narrow confidence interval we must increase our sample size which is not always practical in real-world research.
To illustrate this, consider the following example.
<h3>Example: Calculating a Confidence Interval</h3>
To calculate a confidence interval for a  population mean , we can use the following formula:
<b>Confidence Interval = x  ±  z*(s/√n)</b>
where:
<b>x: </b>sample mean
<b>z: </b>the chosen z-value
<b>s: </b>sample standard deviation
<b>n: </b>sample size
The z-value that you will use is dependent on the confidence level that you choose. The following table shows the z-value that corresponds to popular confidence level choices:
<table><tbody>
<tr>
<th style="text-align: center;"><b>Confidence Level</b></th>
<th style="text-align: center;"><b>z-value</b></th>
</tr>
<tr>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">1.645</td>
</tr>
<tr>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.96</td>
</tr>
<tr>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">2.58</td>
</tr>
</tbody></table>
For example, suppose we collect a random sample of 25 plants with the following information:
Sample size <b>n = 25</b>
Sample mean height <b>x = 36.5 inches</b>
Sample standard deviation <b>s = 18.5 inches</b>
Here is how to find calculate the 95% confidence interval for the true population mean height:
<b>95% Confidence Interval: </b>36.5 ± 1.96*(18.5/√25) = <b>[29.248, 43.752]</b>
We interpret this interval to mean that we’re 95% confident that the true population mean height for this species of plant is between 29.248 inches and 43.752 inches.
Now suppose instead we collect the following random sample of 100 plants with the following information:
Sample size <b>n = 100</b>
Sample mean height <b>x = 36.5 inches</b>
Sample standard deviation <b>s = 18.5 inches</b>
Here is how to find calculate the 95% confidence interval for the true population mean height:
<b>95% Confidence Interval: </b>36.5 ± 1.96*(18.5/√100) = <b>[32.874, 40.126]</b>
We interpret this interval to mean that we’re 95% confident that the true population mean height for this species of plant is between 32.874 inches and 40.126 inches.
Notice that by simply increasing the sample size we were able to produce a more narrow confidence interval for the population mean.
In a real-life situation, a researcher would prefer this second interval because it gives them a more precise idea of the range of values that could contain the true population mean.
However, it’s often more time-consuming and resource-intensive to gather larger sample sizes, so in reality it’s not always practical to do so.
Also keep in mind that some datasets simply have more variability in the data, which causes high values for the sample standard deviation. This naturally results in wide confidence intervals. 
Thus, in order to create a “narrow” confidence interval the only variable that researchers can actually control is the sample size.
<h3>Conclusion</h3>
Here’s a quick summary of the main points made in this article:
<b>1.</b> Researchers often consider a “good” confidence interval to be one that is narrow.
<b>2.</b> By increasing the sample size used, researchers can produce narrower confidence intervals.
<b>3.</b> What is considered a “narrow” confidence interval varies from one field to the next because some types of data naturally have higher variability than others.
<b>Related:</b>  The Relationship Between Sample Size and Margin of Error 
<h2><span class="orange">What is Considered a “Good” F1 Score?</span></h2>
When using  classification models  in machine learning, a common metric that we use to assess the quality of the model is the <b>F1 Score</b>.
This metric is calculated as:
<b>F1 Score</b> = 2 * (Precision * Recall) / (Precision + Recall)
where:
<b>Precision</b>: Correct positive predictions relative to total positive predictions
<b>Recall</b>: Correct positive predictions relative to total actual positives
For example, suppose we use a logistic regression model to predict whether or not 400 different college basketball players get drafted into the NBA.
The following confusion matrix summarizes the predictions made by the model:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/fscore1.png">
Here is how to calculate the F1 score of the model:
Precision = True Positive / (True Positive + False Positive) = 120/ (120+70) = <b>.63157</b>
Recall = True Positive / (True Positive + False Negative) = 120 / (120+40) = <b>.75</b>
F1 Score = 2 * (.63157 * .75) / (.63157 + .75) = .<b>6857</b>
<h3>What is a Good F1 Score?</h3>
One question students often have is:
<em><b>What is a good F1 score?</b></em>
In the most simple terms, higher F1 scores are generally better.
Recall that F1 scores can range from 0 to 1, with 1 representing a model that perfectly classifies each observation into the correct class and 0 representing a model that is unable to classify any observation into the correct class.
To illustrate this, suppose we have a logistic regression model that produces the following confusion matrix:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/goodf1_1.png">
Here is how to calculate the F1 score of the model:
Precision = True Positive / (True Positive + False Positive) = 240/ (240+0) = <b>1</b>
Recall = True Positive / (True Positive + False Negative) = 240 / (240+0) = <b>1</b>
F1 Score = 2 * (1 * 1) / (1 + 1) = <b>1</b>
The F1 score is equal to one because it is able to perfectly classify each of the 400 observations into a class.
Now consider another logistic regression model that simply predicts every player to get drafted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/goodf1_2.png">
Here is how to calculate the F1 score of the model:
Precision = True Positive / (True Positive + False Positive) = 160/ (160+240) = <b>0.4</b>
Recall = True Positive / (True Positive + False Negative) = 160 / (160+0) = <b>1</b>
F1 Score = 2 * (.4 * 1) / (.4 + 1) = <b>0.5714</b>
This would be considered a <b>baseline model</b> that we could compare our logistic regression model to since it represents a model that makes the same prediction for every single observation in the dataset.
The greater our F1 score is compared to a baseline model, the more useful our model.
Recall from earlier that our model had an F1 score of <b>0.6857</b>. This isn’t much greater than <b>0.5714</b>, which indicates that our model is more useful than a baseline model but not by much.
<h3>On Comparing F1 Scores</h3>
In practice, we typically use the following process to pick the “best” model for a classification problem:
<b>Step 1:</b> Fit a baseline model that makes the same prediction for every observation.
<b>Step 2:</b> Fit several different classification models and calculate the F1 score for each model.
<b>Step 3:</b> Choose the model with the highest F1 score as the “best” model, verifying that it produces a higher F1 score than the baseline model.
There is no specific value that is considered a “good” F1 score, which is why we generally pick the classification model that produces the highest F1 score.
<h2><span class="orange">What is Considered a Good Value for MAPE?</span></h2>
One of the most common metrics used to measure the forecasting accuracy of a model is <b>MAPE</b>, which stands for <b>mean absolute percentage error</b>.
The formula to calculate MAPE is as follows:
<b>MAPE</b> = (1/n) * Σ(|actual – forecast| / |actual|) * 100
where:
<b>Σ</b> – a fancy symbol that means “sum”
<b>n</b> – sample size
<b>actual</b> – the actual data value
<b>forecast</b> – the forecasted data value
MAPE is commonly used because it’s easy to interpret and explain. For example, a MAPE value of 8% means that the average difference between the forecasted value and the actual value is 8%.
One of the most common questions people have when using this metric is:
<em><b>What is a good value for MAPE?</b></em>
The unsatisfying answer: <b>It depends</b>.
Obviously the lower the value for MAPE the better, but there is no specific value that you can call “good” or “bad.” It depends on a couple factors:
The type of industry
The MAPE value compared to a simple forecasting model 
Let’s explore these two factors in depth.
<h3>MAPE Varies by Industry</h3>
Often companies create forecasts for demand of their products and then use MAPE as a way to measure the accuracy of the forecasts.
Unfortunately, there is no “standard” MAPE value because it can vary so much by the type of company. 
For example, a company that rarely changes their pricing will likely have steady and predictable demand, which means they may have a model that produces a very low MAPE, perhaps under 3%.
For other companies that constantly run promotions and specials, their demand will vary greatly over time and thus a forecasting model will likely have a harder time predicting demand as accurately which means the models may have a higher value for MAPE.
You should be highly skeptical of “industry standards” for MAPE.
<h3>Compare MAPE to a Simple Forecasting Model</h3>
Rather than trying to compare the MAPE of your model with some arbitrary “good” value, you should instead compare it to the MAPE of simple forecasting models.
There are two well-known simple forecasting models:
<b>1. The average forecasting method.</b>
This type of forecast model simply predicts the value for the next upcoming period to be the average of all prior periods. Although this method seems overly simplistic, it actually tends to perform well in practice.
<b>2. The na<U+00EF>ve forecasting method.</b>
This type of forecast model predicts the value for the next upcoming period to be equal to the prior period. Again, although this method is quite simple it tends to work surprisingly well.
When developing a new forecasting model, you should compare the MAPE of that model to the MAPE of these two simple forecasting methods.
If the MAPE of your new model is not significantly better than these two methods, then you shouldn’t consider it to be useful.
<h3>Closing Thoughts</h3>
Although MAPE is widely used and easy to interpret, there are a couple potential drawbacks to using it:
<b>1.</b> Since the formula to calculate absolute percent error is |actual-forecast| / |actual| this means that it will be undefined if any of the actual values are zero.
2. MAPE should not be used with low volume data. For example, if the actual demand for some item is 2 and the forecast is 1, the value for the absolute percent error will be |2-1| / |2| = 50%, which makes it seem like the forecast error is quite high, despite the forecast only being off by one unit. 
Potential alternatives to MAPE include mean absolute deviation and root mean squared error.
<h2><span class="orange">What is Considered a Good RMSE Value?</span></h2>
One way to assess how well a  regression model  fits a dataset is to calculate the <b>root mean square error</b>, which tells us the average distance between the predicted values from the model and the actual values in the dataset.
The formula to find the root mean square error, often abbreviated <b>RMSE</b>, is as follows:
<b>RMSE = </b>√Σ(P<sub>i</sub> – O<sub>i</sub>)<sup>2</sup> / n
where:
Σ is a fancy symbol that means “sum”
P<sub>i</sub> is the predicted value for the i<sup>th</sup> observation in the dataset
O<sub>i</sub> is the observed value for the i<sup>th</sup> observation in the dataset
n is the sample size
One question people often have is: <b>What is a good RMSE value?</b>
The short answer: <b>It depends</b>.
The lower the RMSE, the better a given model is able to “fit” a dataset. However, the range of the dataset you’re working with is important in determining whether or not a given RMSE value is “low” or not.
For example, consider the following scenarios:
<b>Scenario 1: </b>We would like to use a regression model predict the price of homes in a certain city. Suppose the model has an RMSE value of $500. Since the typical range of houses prices is between $70,000 and $300,000, this RMSE value is extremely low. This tells us that the model is able to predict house prices accurately.
<b>Scenario 2:</b> Now suppose we would like to use a regression model to predict how much someone will spend per month in a certain city. Suppose the model has an RMSE value of $500. If the typical range of monthly spending is $1,500 – $4,000, this RMSE value is quite high. This tells us that the model is not able to predict monthly spending very accurately.
These simple examples show that there is no universally “good” RMSE value. It all depends on the range of values in the dataset you’re working with.
<h3>Normalizing the RMSE Value</h3>
One way to gain a better understanding of whether a certain RMSE value is “good” is to normalize it using the following formula:
Normalized RMSE = RMSE / (max value – min value)
This produces a value between 0 and 1, where values closer to 0 represent better fitting models.
For example, suppose our RMSE value is $500 and our range of values is between $70,000 and $300,000. We would calculate the normalized RMSE value as:
Normalized RMSE = $500 / ($300,000 – $70,000) = <b>0.002</b>
Conversely, suppose our RMSE value is $500 and our range of values is between $1,500 and $4,000. We would calculate the normalized RMSE value as:
Normalized RMSE = $500 / ($4,000 – $1,500) = <b>0.2</b>.
The first normalized RMSE value is much lower, which indicates that it provides a much better fit to the data compared to the second normalized RMSE value.
<h3>Comparing RMSE Across Models</h3>
Instead of picking some arbitrary number to represent a “good” RMSE value, we can simply compare RMSE values across several models.
For example, suppose we fit three different regression models to predict house prices. Suppose the three models have the following RMSE values:
RMSE of Model 1: <b>$550</b>
RMSE of Model 2: <b>$480</b>
RMSE of Model 3: <b>$1,400</b>
Since the RMSE value of Model 2 is lowest, we would select Model 2 as the best model for predicting house prices since the average distance between the predicted prices and the actual prices is lowest for that model.
<h2><span class="orange">What is Considered a Good Standard Deviation?</span></h2>
The <b>standard deviation</b> is used to measure the spread of values in a sample.
We can use the following formula to calculate the standard deviation of a given sample:
√Σ(x<sub>i</sub> – x<sub>bar</sub>)<sup>2</sup> / (n-1)
where:
<b>Σ:</b> A symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value in the sample
<b>x<sub>bar</sub>:</b> The mean of the sample
<b>n:</b> The sample size
The higher the value for the standard deviation, the more spread out the values are in a  sample . Conversely, the lower the value for the standard deviation, the more tightly packed together the values.
One question students often have is: <b><em>What is considered a good value for the standard deviation?</em></b>
The answer: <b>A standard deviation can’t be “good” or “bad” because it simply tells us how spread out the values are in a sample.</b>
There’s also no universal number that determines whether or not a standard deviation is “high” or “low.” For example, consider the following scenarios:
<b>Scenario 1:</b> A realtor collects data on the price of 100 houses in her city and finds that the standard deviation of prices is $12,000.
<b>Scenario 2</b>: An economist measures the total income tax collected in all 50 states in the U.S. and finds that the standard deviation of total income tax collected is $480,000.
Although the standard deviation in scenario 2 is much higher than the standard deviation in scenario 1, the units being measured in scenario 2 are much higher since the total taxes collected by states are obviously much higher than house prices.
This means there’s no single number we can use to tell whether or not a standard deviation is “good” or “bad” or even “high” or “low” because it depends on the situation.
<h3>Using the Coefficient of Variation</h3>
One way to determine if a standard deviation is high is to compare it to the mean of the dataset.
A <b>coefficient of variation</b>, often abbreviated as <em>CV</em>, is a way to measure how spread out values are in a dataset relative to the mean. It is calculated as:
<b>CV = s / x</b>
where:
<b>s:</b> The standard deviation of dataset
<b>x:</b> The mean of dataset
In simple terms, the CV is the ratio between the standard deviation and the mean.
The higher the CV, the higher the standard deviation <em>relative</em> to the mean. In general, a CV value greater than 1 is often considered high.
For example, suppose a realtor collects data on the price of 100 houses in her city and finds that the mean price is $150,000 and the standard deviation of prices is $12,000. The CV would be calculated as:
CV: $12,000 / $150,000 = <b>.08</b>
Since this CV value is well below 1, this tells us that the standard deviation of the data is quite low.
Conversely, suppose an economist measures the total income tax collected in all 50 states in the U.S. and finds that the sample mean is $400,000 and the standard deviation is $480,000. The CV would be calculated as:
CV: $480,000 / $400,000 = <b>1.2</b>
Since this CV value is greater than 1, it tells us that the standard deviation of the data values are quite high.
<h3>Comparing Standard Deviations Across Datasets</h3>
Often we use the standard deviation to measure the spread of values between different datasets.
For example, suppose a professor administers three exams to his students during the course of one semester. He then calculates the sample standard deviation of scores for each exam:
Sample standard deviation of Exam 1 Scores: <b>4.6</b>
Sample standard deviation of Exam 2 Scores: <b>12.4</b>
Sample standard deviation of Exam 3 Scores: <b>2.3</b>
This tells the professor that the exam scores were most spread out for Exam 2 while the scores were most tightly packed together for Exam 3.
<h2><span class="orange">What is Considered a Good Z-Score?</span></h2>
A <b>z-score</b> tells us how many standard deviations away a value is from the mean. We use the following formula to calculate a z-score:
<b>Z-Score = (x – μ) / σ</b>
where:
<b>x:</b> A raw data value
<b>μ:</b> The mean of the dataset
<b>σ:</b> The standard deviation of the dataset
 For example:
If a value has a z-score equal to 0, then the value is equal to the mean.
If a value has a z-score equal to -1.3, then the value is 1.3 standard deviations below the mean.
If a value has a z-score equal to 2.2, then the value is 2.2 standard deviations above the mean.
One question that students often have is:<b><em> What is a good z-score?</em></b>
The answer: <b>A z-score simply tells us how many standard deviations a given value is from the mean, so it can’t be “good” or “bad.”</b>
However, we can determine what percentage of values fall below a certain z-score in a distribution by using a  z table , which gives us an idea of where a certain value lies relative to all other values in the distribution.
For example, suppose the score that Mike receives on an exam has a z-score of -1.22. We can locate the value of -1.22 in the z table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/zhand1.png">
We find that the value in the z table is <b>0.1112</b>. This means that Mike only scored higher than 11.12% of all students who took the exam.
In this scenario, a z-score of -1.22 might be considered “bad” since Mike only scored higher than a small percentage of students.
Conversely, suppose the score that Tom receives has a z-score of 1.43. We can locate this value in the z table as well:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/zhand2.png">
We find that the value in the z table is <b>0.9236</b>. This means that Mike scored higher than 92.36% of students who took the exam.
In this scenario, a z-score of 1.43 might be considered “good” since Mike scored higher than so many other students.
<h3>How to Classify “Good” Z-Scores</h3>
To determine whether or not a certain z-score is “good” depends largely on the situation.
For example, when measuring exam scores of students, one university may consider a z-score that corresponds to the 80th percentile or higher as “good.”
According to the  Percentile to Z-Score Calculator , the z-score that corresponds to the 80th percentile is <b>0.8416</b>. Thus, any student who receives a z-score greater than or equal to 0.8416 would be considered a “good” z-score.
However, suppose another university considers a z-score that corresponds to the 90th percentile or higher as “good.”
According to the  Percentile to Z-Score Calculator , the z-score that corresponds to the 90th percentile is <b>1.2816</b>. Thus, any student who receives a z-score greater than or equal to 1.2816 would be considered a “good” z-score.
The decision of what is a “good” or “bad” z-score is subjective, but we can always make the following statements:
A z-score equal to zero represents a value equal to the mean.
A z-score greater than zero represents a value greater than the mean.
A z-score less than zero represents a value less than the mean.
It’s helpful to convert a z-score to a percentile to determine what percentage of values the value is greater than in a distribution. 
It’s up to an individual company, association, school, etc. to determine whether a “good” z-score should be one that represents the 70th, 80th, 90th, 95th percentile, etc.
<h2><span class="orange">What is Considered a Low Standard Deviation?</span></h2>
The <b>standard deviation</b> is used to measure the spread of values in a sample.
We can use the following formula to calculate the standard deviation of a given sample:
√Σ(x<sub>i</sub> – x<sub>bar</sub>)<sup>2</sup> / (n-1)
where:
<b>Σ:</b> A symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value in the sample
<b>x<sub>bar</sub>:</b> The mean of the sample
<b>n:</b> The sample size
The higher the value for the standard deviation, the more spread out the values are in a  sample . Conversely, the lower the value for the standard deviation, the more closely packed together the values.
One question students often have is: <b><em>What is considered a low value for the standard deviation?</em></b>
The answer: <b>There is no cut-off value for what is considered a “low” standard deviation because it depends on the type of data you’re working with.</b>
For example, consider the following scenarios:
<b>Scenario 1:</b> A professor collects data on the exam scores of students in his class and finds that the standard deviation of exam scores is 7.8.
<b>Scenario 2</b>: An economist measures the total income tax collected by different countries around the world and finds that the standard deviation of total income tax collected is $1.2 million.
The standard deviation in scenario 2 is much higher, but that’s only because the values being measured in scenario 2 are considerably higher than those being measured in scenario 1.
This means there is no single number we can use to tell whether or not a standard deviation is “low” or not. It all depends on the situation.
<h3>Using the Coefficient of Variation</h3>
One way to determine if a standard deviation is “low” is to compare it to the mean of the dataset.
A <b>coefficient of variation</b>, often abbreviated <em>CV</em>, is a way to measure how spread out values are in a dataset relative to the mean. It is calculated as:
<b>CV = s / x</b>
where:
<b>s:</b> The standard deviation of dataset
<b>x:</b> The mean of dataset
The lower the CV, the lower the standard deviation <em>relative</em> to the mean.
For example, suppose a professor collects data on the exam scores of students and finds that the mean score is 80.3 and the standard deviation of scores is 7.8. The CV would be calculated as:
CV: 7.8 / 80.3 = <b>.097</b>
Suppose another professor at a different university collects data on the exam scores of his students and finds that the mean score is 70.3 and the standard deviation of scores is 8.5. The CV would be calculated as:
CV: 8.5 / 90.2 = <b>0.094</b>
Although the standard deviation of exam scores is lower for the first professor’s students, the coefficient of variation is actually higher than that of the exam scores for the second professor’s students.
This means the variation of exam scores <em>relative</em> to the mean score is higher for the first professor’s students.
<h3>Comparing Standard Deviations Between Samples</h3>
Rather than classifying a standard deviation as “low” or not, often we simply compare the standard deviation between several samples to determine which sample has the lowest standard deviation.
For example, suppose a professor administers three exams to his students during the course of one semester. He then calculates the sample standard deviation of scores for each exam:
Sample standard deviation of Exam 1 Scores: <b>4.9</b>
Sample standard deviation of Exam 2 Scores: <b>14.4</b>
Sample standard deviation of Exam 3 Scores: <b>2.5</b>
The professor can see that Exam 3 had the lowest standard deviation of scores among all three exams, which means the exam scores were most closely packed together for that exam.
 Conversely, he can see that Exam 2 had the highest standard deviation, which means the exam scores were most spread out for that exam.
<h2><span class="orange">What is Considered to Be a “Strong” Correlation?</span></h2>
In statistics, we’re often interested in understanding how two variables are related to each other. For example, we might want to know:
What is the relationship between the number of hours a student studies and the exam score they receive?
What is the relationship between the temperature outside and the number of ice cream cones that a food truck sells?
What is the relationship between marketing dollars spent and total income earned for a certain business?
In each of these scenarios, we’re trying to understand the relationship between two different variables.
In statistics, one of the most common ways that we quantify a relationship between two variables is by using the  Pearson correlation coefficient , which is a measure of the linear association between two variables<em>. </em>It has a value between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
Often denoted as <em>r</em>, this number helps us understand how strong a relationship is between two variables. <b>The further away <em>r </em>is from zero, the stronger the relationship between the two variables</b>.
It’s important to note that two variables could have a strong <i>positive </i>correlation or a strong <em>negative</em> correlation.
<b>Strong positive correlation: </b>When the value of one variable increases, the value of the other variable increases in a similar fashion. For example, the more hours that a student studies, the higher their exam score tends to be. Hours studied and exam scores have a strong positive correlation.
<b>Strong negative correlation: </b>When the value of one variable increases, the value of the other variable tends to decrease. For example, the older a chicken becomes, the less eggs they tend to produce. Chicken age and egg production have a strong negative correlation.
The following table shows the rule of thumb for interpreting the strength of the relationship between two variables based on the value of <em>r</em>:
<table><tbody>
<tr>
<th><b>Absolute value of <em>r</em></b></th>
<th><b>Strength of relationship</b></th>
</tr>
<tr>
<td>r &lt; 0.25</td>
<td>No relationship</td>
</tr>
<tr>
<td>0.25 &lt; r &lt; 0.5</td>
<td>Weak relationship</td>
</tr>
<tr>
<td>0.5 &lt; r &lt; 0.75</td>
<td>Moderate relationship</td>
</tr>
<tr>
<td>r > 0.75</td>
<td>Strong relationship</td>
</tr>
</tbody></table>
The correlation between two variables is considered to be strong if the absolute value of <em>r </em>is greater than <b>0.75</b>. However, the definition of a “strong” correlation can vary from one field to the next.
<h3>Medical</h3>
For example, often in medical fields the definition of a “strong” relationship is often much lower. If the relationship between taking a certain drug and the reduction in heart attacks is <em>r</em> = <b>0.3,</b> this might be considered a “weak positive” relationship in other fields, but in medicine it’s significant enough that it would be worth taking the drug to reduce the chances of having a heart attack.
<h3>Human Resources</h3>
In another field such as human resources, lower correlations might also be used more often. For example, the correlation between college grades and job performance has been shown to be about <em>r </em>= <b>0.16</b>. This is fairly low, but it’s large enough that it’s something a company would at least look at during an interview process. 
<h3>Technology</h3>
And in a field like technology, the correlation between variables might need to be much higher in some cases to be considered “strong.” For example, if a company creates a self-driving car and the correlation between the car’s turning decisions and the probability of getting in a wreck is <em>r</em> = <b>0.95</b>, this is likely too low for the car to be considered safe since the result of making the wrong decision can be fatal.
<h2>Visualizing Correlations</h2>
No matter which field you’re in, it’s useful to create a scatterplot of the two variables you’re studying so that you can at least visually examine the relationship between them.
For example, suppose we have the following dataset that shows the height an weight of 12 individuals:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/correlationExample2.jpg"193">
It’s a bit hard to understand the relationship between these two variables by just looking at the raw data. However, it’s much easier to understand the relationship if we create a  scatterplot  with height on the x-axis and weight on the y-axis:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/correl15.jpg"461">
Clearly there is a positive relationship between the two variables.
Creating a scatterplot is a good idea for two more reasons:
<b>(1) A scatterplot allows you to identify outliers that are impacting the correlation.</b>
One extreme outlier can dramatically change a Pearson correlation coefficient. Consider the example below, in which variables <em>X </em>and <em>Y </em>have a Pearson correlation coefficient of <em>r </em> = <b>0.00</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/correl9.jpg"454">
But now imagine that we have one outlier in the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/correl10.jpg"456">
This outlier causes the correlation to be <em>r </em>= <b>0.878</b>. This single data point completely changes the correlation and makes it seem as if there is a strong relationship between variables <em>X </em>and <em>Y</em>, when there really isn’t.
<b>(2) A scatterplot can help you identify nonlinear relationships between variables.</b>
A Pearson correlation coefficient merely tells us if two variables are <em>linearly</em> related. But even if a Pearson correlation coefficient tells us that two variables are uncorrelated, they could still have some type of nonlinear relationship. This is another reason that it’s helpful to create a scatterplot.
For example, consider the scatterplot below between variables <em>X </em>and <em>Y</em>, in which their correlation is <em>r </em>= <b>0.00</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/correl11.jpg"448">
The variables clearly have no linear relationship, but they <em>do</em> have a nonlinear relationship: The y values are simply the x values squared. A correlation coefficient by itself couldn’t pick up on this relationship, but a scatterplot could.
<h2>Conclusion</h2>
In summary:
As a rule of thumb, a correlation greater than 0.75 is considered to be a “strong” correlation between two variables.
However, this rule of thumb can vary from field to field. For example, a much lower correlation could be considered strong in a medical field compared to a technology field. It’s best to use domain specific expertise when deciding what is considered to be strong.
When using a correlation to describe the relationship between two variables, it’s useful to also create a scatterplot so that you can identify any outliers in the dataset along with a potential nonlinear relationship.
<h2><span class="orange">What is Considered to Be a “Weak” Correlation?</span></h2>
In statistics, we’re often interested in understanding how two variables are related to each other. For example, we might want to know:
What is the relationship between the number of hours a student studies and the exam score they receive?
What is the relationship between the temperature outside and the number of ice cream bars sold by a food truck?
What is the relationship between dollars spent on advertising and total income earned for a certain company?
In each scenario, we’re interested in understanding the relationship between two variables.
One of the most common ways to quantify a relationship between two variables is to use the  Pearson correlation coefficient , which is a measure of the linear association between two variables.
It always takes on a value between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
Often denoted as <em>r</em>, this number helps us understand the strength of the relationship between two variables. <b>The closer <em>r </em>is to zero, the weaker the relationship between the two variables</b>.
It’s important to note that two variables could have a weak <i>positive </i>correlation or a weak <em>negative</em> correlation.
<b>Weak positive correlation: </b>When one variable increases, the other variable tends to increase as well, but in a weak or unreliable manner.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/weak1.png">
<b>Weak negative correlation: </b>When one variable increases, the other variable tends to decrease, but in a weak or unreliable manner.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/weak2.png">
The following table shows the rule of thumb for interpreting the strength of the relationship between two variables based on the value of <em>r</em>:
<table><tbody>
<tr>
<th><b>Absolute value of <em>r</em></b></th>
<th><b>Strength of relationship</b></th>
</tr>
<tr>
<td>r &lt; 0.25</td>
<td>No relationship</td>
</tr>
<tr>
<td>0.25 &lt; r &lt; 0.5</td>
<td>Weak relationship</td>
</tr>
<tr>
<td>0.5 &lt; r &lt; 0.75</td>
<td>Moderate relationship</td>
</tr>
<tr>
<td>r > 0.75</td>
<td>Strong relationship</td>
</tr>
</tbody></table>
The correlation between two variables is considered to be weak if the absolute value of <em>r </em>is between 0.25 and 0.5.
However, the definition of a “weak” correlation can vary from one field to the next.
<h3>Medical</h3>
In medical fields the definition of a “weak” relationship is often much lower. If the relationship between taking a certain drug and the reduction in heart attacks is <em>r</em> = <b>0.2,</b> this might be considered “no relationship” in other fields, but in medicine it’s significant enough that it would be worth taking the drug to reduce the chances of having a heart attack.
<h3>Human Resources</h3>
In a field like human resources, lower correlations are also used more often. For example, the correlation between college GPA and job performance has been shown to be about <em>r </em>= <b>0.16</b>. This is fairly low, but it’s large enough that it’s something a company would at least look at during an interview process. 
<h3>Technology</h3>
In technology fields, the correlation between variables might need to be much higher to even be considered “weak.” For example, if a company creates a self-driving car and the correlation between the car’s turning decisions and the probability of avoiding a wreck is <em>r</em> = <b>0.95</b>, this may be considered a “weak” correlation and is likely too low for the car to be considered safe since the result of making the wrong decision can be fatal.
<h3>Using Scatterplots to Visualize Correlations</h3>
When you calculate the correlation coefficient between two variables, it’s useful to create a scatterplot to visualize the correlation as well.
In particular, scatterplots offer two benefits:
<b>1. Scatterplots can help you identify outliers that affect the correlation coefficient.</b>
One extreme outlier can have a large impact on the correlation coefficient. Consider the example below, in which variables <em>X </em>and <em>Y </em>have a Pearson correlation coefficient of <em>r </em> = <b>0.91</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/weak3.png">
Now imagine that the we modify the first data point to be much larger. The correlation coefficient suddenly becomes <em>r</em> = <b>0.29</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/weak4-1.png">
This single data point causes the correlation coefficient to change from a strong positive relationship to a weak positive relationship.
<b>(2) Scatterplots can help you identify nonlinear relationships between variables.</b>
A Pearson correlation coefficient merely tells us if two variables are <em>linearly</em> related. But even if a Pearson correlation coefficient tells us that two variables are uncorrelated, they could still have some type of nonlinear relationship.
For example, consider the scatterplot below between variables <em>X</em> and <em>Y</em>, in which their correlation is <em>r</em> = <b>0.00</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/weak5.png">
The variables clearly have no linear relationship, but they <em>do</em> have a nonlinear relationship: The y values are simply the x values squared.
A correlation coefficient by itself couldn’t pick up on this relationship, but a scatterplot could.
<h2>Conclusion</h2>
In summary:
<b>1.</b> As a rule of thumb, a correlation coefficient between 0.25 and 0.5 is considered to be a “weak” correlation between two variables.
<b>2.</b> This rule of thumb can vary from field to field. For example, a much lower correlation could be considered weak in a medical field compared to a technology field. Be sure to use subject matter expertise when deciding what is considered to be a weak correlation.
<b>3.</b>When using a correlation coefficient to describe the relationship between two variables, it’s useful to create a scatterplot as well so you can identify any outliers in the dataset along with a potential nonlinear relationship.
<h2><span class="orange">What is the Difference Between a T-test and an ANOVA?</span></h2>
This tutorial explains the difference between a <b>t-test</b> and an <b>ANOVA</b>, along with when to use each test.
<h3>T-test</h3>
A <b>t-test </b>is used to determine whether or not there is a statistically significant difference between the means of two groups. There are two types of t-tests: 
<b>1. Independent samples t-test.</b> This is used when we wish to compare the difference between the means of two groups and the groups are completely independent of each other.
For example, researchers may want to know whether diet A or diet B helps people lose more weight. 100 randomly assigned people are assigned to diet A. Another 100 randomly assigned people are assigned to diet B. After three months, researchers record the total weight loss for each person. To determine if the mean weight loss between the two groups is significantly different, researchers can conduct an independent samples t-test.
<b>2. Paired samples t-test</b>. This is used when we wish to compare the difference between the means of two groups and where each observation in one group can be paired with one observation in the other group. 
For example, suppose 20 students in a class take a test, then study a certain guide, then retake the test. To compare the difference between the scores in the first and second test, we use a paired t-test because for each student their first test score can be paired with their second test score.
For a t-test to produce valid results, the following assumptions should be met:
<b>Random:</b> A random sample or random experiment should be used to collect data for both samples.
<b>Normal:</b> The sampling distribution is normal or approximately normal.
If these assumptions are met, then it’s safe to use a t-test to test for the difference between the means of two groups.
<h2>ANOVA</h2>
An <b>ANOVA </b>(analysis of variance) is used to determine whether or not there is a statistically significant difference between the means of three or more groups. The most commonly used ANOVA tests in practice are the one-way ANOVA and the two-way ANOVA:
<b>One-way ANOVA: </b>Used to test whether or not there is a statistically significant difference between the means of three or more groups when the groups can be split on one factor.
<b>Example: </b>You randomly split up a class of 90 students into three groups of 30. Each group uses a different studying technique for one month to prepare for an exam. At the end of the month, all of the students take the same exam. You want to know whether or not the studying technique has an impact on exam scores so you conduct a one-way ANOVA to determine if there is a statistically significant difference between the mean scores of the three groups.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/NOVA1.jpg">
<b>Two-way ANOVA: </b>Used to test whether or not there is a statistically significant difference between the means of three or more groups when the groups can be split on two factors.
<b>Example:</b> You want to determine if level of exercise (no exercise, light exercise, intense exercise) and gender (male, female) impact weight loss. In this case, the two factors you’re studying are exercise and gender and your response variable is weight loss (measured in pounds). You can conduct a two-way ANOVA to determine if exercise and gender impact weight loss and to determine if there is an interaction between exercise and gender on weight loss.
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/NOVA2.jpg">
For an ANOVA to produce valid results, the following assumptions should be met:
<b>Normality</b> – all populations that we’re studying follow a normal distribution. So, for example, if we want to compare the exam scores of three different groups of students, the exam scores for the first group, second group, and third group all need to be normally distributed.
<b> Equal Variance</b> – the population variances in each group are equal or approximately equal.
<b>Independence</b> – the observations in each group need to be independent of each other. Usually a  randomized design  will take care of this.
If these assumptions are met, then it’s safe to use an ANOVA to test for the difference between the means of three or more groups.
<h2>Understanding the Differences Between Each Test</h2>
The main difference between a t-test and an ANOVA is in how the two tests calculate their test statistic to determine if there is a statistically significant difference between groups.
An <b>independent samples t-test</b> uses the following test statistic:
test statistic <em>t</em> = [ (x<sub>1</sub> – x<sub>2</sub>) – d ]  /  (√s<sup>2</sup><sub>1</sub> / n<sub>1</sub> + s<sup>2</sup><sub>2</sub> / n<sub>2</sub>)
where x<sub>1</sub> and x<sub>2 </sub>are the sample means for groups 1 and 2,<em> d</em>  is the hypothesized difference between the two means (often this is zero), s<sub>1</sub><sup>2 </sup>and s<sub>2</sub><sup>2 </sup>are the sample variances for groups 1 and 2, and n<sub>1 </sub>and n<sub>2 </sub>are the sample sizes for groups 1 and 2, respectively. 
A <b>paired samples t-test </b>uses the following test statistic:
test statistic <em>t </em>= d / (s<sub>d</sub> / √n)
where d is the mean difference between the two groups, s<sub>d</sub> is the standard deviation of the differences, and n is the sample size for each group (note that both groups will have the same sample size).
An <b>ANOVA </b>uses the following test statistic:
test statistic <em>F </em>= s<sup>2</sup><sub>b</sub> / s<sup>2</sup><sub>w</sub>
where s<sup>2</sup><sub>b</sub> is the between sample variance, and s<sup>2</sup><sub>w</sub> is the within sample variance.
A t-test measures the ratio of the mean difference between two groups relative to the overall standard deviation of the differences. If this ratio is high enough, it provides sufficient evidence that there is a significant difference between the two groups.
An ANOVA, on the other hand, measures the ratio of variance between the groups relative to the variance within the groups. Similar to the t-test, if this ratio is high enough, it provides sufficient evidence that not all three groups have the same mean.
Another key difference between a t-test and an ANOVA is that the t-test can tell us whether or not two groups have the same mean. An ANOVA, on the other hand, tells us whether or not three groups all have the same mean, but it doesn’t explicitly tell us <em>which </em>groups have means that are different from one another.
To find out which groups differ from one another, we would have to perform  post-hoc tests .
<h2>Understanding When to use Each Test</h2>
In practice, when we want to compare the means of two groups<em>,</em> we use a t-test. When we want to compare the means of three or more groups, we use an ANOVA.
The underlying reason we don’t simply use several t-tests to compare the means of three or more groups goes back to understanding the type I error rate. Suppose we have three groups we wish to compare the means between: group A, group B, and group C. You may be tempted to perform the following three t-tests:
A t-test to compare the difference in means between group A and group B
A t-test to compare the difference in means between group A and group C
A t-test to compare the difference in means between group B and group C
For each t-test there is a chance that we will commit a<b> type I error</b>, which is the probability that we reject the null hypothesis when it is actually true. This probability is typically 5%. This means that when we perform multiple t-tests, this error rate increases. For example:
The probability that we commit a type I error with one t-test is 1 – 0.95 = <b>0.05</b>.
The probability that we commit a type I error with two t-tests is 1 – (0.95<sup>2</sup>) = <b>0.0975</b>.
The probability that we commit a type I error with two t-tests is 1 – (0.95<sup>3</sup>) = <b>0.1427</b>.
This error rate is unacceptably high. Fortunately, an ANOVA controls for these errors so that the Type I error remains at just 5%. This allows us to be more confident that a statistically significant test result is actually meaningful and not just a result that we got from performing a lot of tests.
Thus, when we want to understand whether there is a difference between the means of three or more groups, we must use an ANOVA so that our results are statistically valid and reliable.
<h2><span class="orange">When Do You Reject the Null Hypothesis? (3 Examples)</span></h2>
A  hypothesis test  is a formal statistical test we use to reject or fail to reject a statistical hypothesis.
We always use the following steps to perform a hypothesis test:
<b>Step 1: State the null and alternative hypotheses.</b>
The <b>null hypothesis</b>, denoted as H<sub>0</sub>, is the hypothesis that the sample data occurs purely from chance.
The <b>alternative hypothesis</b>, denoted as H<sub>A</sub>, is the hypothesis that the sample data is influenced by some non-random cause.
<b>2. Determine a significance level to use.</b>
Decide on a significance level. Common choices are .01, .05, and .1. 
<b>3. Calculate the test statistic and p-value.</b>
Use the sample data to calculate a test statistic and a corresponding  p-value .
<b>4. Reject or fail to reject the null hypothesis.</b>
If the p-value is less than the significance level, then you reject the null hypothesis.
If the p-value is not less than the significance level, then you fail to reject the null hypothesis.
You can use the following clever line to remember this rule:
<b>“If the p is low, the null must go.”</b>
In other words, if the p-value is low enough then we must reject the null hypothesis.
The following examples show when to reject (or fail to reject) the null hypothesis for the most common types of hypothesis tests.
<h2>Example 1: One Sample t-test</h2>
A  one sample t-test  is used to test whether or not the mean of a population is equal to some value.
For example, suppose we want to know whether or not the mean weight of a certain species of turtle is equal to 310 pounds.
We go out and collect a simple random sample of 40 turtles with the following information:
Sample size n = 40
Sample mean weight x = 300
Sample standard deviation s = 18.5
We can use the following steps to perform a one sample t-test:
<b>Step 1: State the Null and Alternative Hypotheses</b>
We will perform the one sample t-test with the following hypotheses:
<b>H<sub>0</sub>: </b>μ = 310 (population mean is equal to 310 pounds)
<b>H<sub>A</sub>: </b>μ ≠ 310 (population mean is not equal to 310 pounds)
<b>2. Determine a significance level to use.</b>
We will choose to use a significance level of <b>0.05</b>.
<b>3. Calculate the test statistic and p-value.</b>
We can plug in the numbers for the sample size, sample mean, and sample standard deviation into this  One Sample t-test Calculator  to calculate the test statistic and p-value:
t test statistic: -3.4187
two-tailed p-value: 0.0015
<b>4. Reject or fail to reject the null hypothesis.</b>
Since the p-value (0.0015) is less than the significance level (0.05) we <b>reject the null hypothesis</b>.
We conclude that there is sufficient evidence to say that the mean weight of turtles in this population is not equal to 310 pounds.
<h2>Example 2: Two Sample t-test</h2>
A  two sample t-test  is used to test whether or not two population means are equal.
For example, suppose we want to know whether or not the mean weight between two different species of turtles is equal.
We go out and collect a simple random sample from each population with the following information:
<b>Sample 1:</b>
Sample size n<sub>1</sub> = 40
Sample mean weight x<sub>1</sub> = 300
Sample standard deviation s<sub>1</sub> = 18.5
<b>Sample 2:</b>
Sample size n<sub>2</sub> = 38
Sample mean weight x<sub>2</sub> = 305
Sample standard deviation s<sub>2</sub> = 16.7
We can use the following steps to perform a two sample t-test:
<b>Step 1: State the Null and Alternative Hypotheses</b>
We will perform the two sample t-test with the following hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>1</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>2. Determine a significance level to use.</b>
We will choose to use a significance level of <b>0.10</b>.
<b>3. Calculate the test statistic and p-value.</b>
We can plug in the numbers for the sample sizes, sample means, and sample standard deviations into this  Two Sample t-test Calculator  to calculate the test statistic and p-value:
t test statistic: -1.2508
two-tailed p-value: 0.2149
<b>4. Reject or fail to reject the null hypothesis.</b>
Since the p-value (0.2149) is not less than the significance level (0.10) we <b>fail to reject the null hypothesis</b>.
We do not have sufficient evidence to say that the mean weight of turtles between these two populations is different.
<h2>Example 3: Paired Samples t-test</h2>
A  paired samples t-test  is used to compare the means of two samples when each observation in one sample can be paired with an observation in the other sample.
For example, suppose we want to know whether or not a certain training program is able to increase the max vertical jump of college basketball players.
To test this, we may recruit a  simple random sample  of 20 college basketball players and measure each of their max vertical jumps. Then, we may have each player use the training program for one month and then measure their max vertical jump again at the end of the month:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/12/pairedT1.png">
We can use the following steps to perform a paired samples t-test:
<b>Step 1: State the Null and Alternative Hypotheses</b>
We will perform the paired samples t-test with the following hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>before</sub> = μ<sub>after</sub> (the two population means are equal)
<b>H<sub>1</sub>: </b>μ<sub>before</sub> ≠ μ<sub>after</sub> (the two population means are not equal)
<b>2. Determine a significance level to use.</b>
We will choose to use a significance level of <b>0.01</b>.
<b>3. Calculate the test statistic and p-value.</b>
We can plug in the raw data for each sample into this  Paired Samples t-test Calculator  to calculate the test statistic and p-value:
t test statistic: -3.226
two-tailed p-value: 0.0045
<b>4. Reject or fail to reject the null hypothesis.</b>
Since the p-value (0.0045) is less than the significance level (0.01) we <b>reject the null hypothesis</b>.
We have sufficient evidence to say that the mean vertical jump before and after participating in the training program is not equal.
<h2>Bonus: Decision Rule Calculator </h2>
You can use this  decision rule calculator  to automatically determine whether you should reject or fail to reject a null hypothesis for a hypothesis test based on the value of the test statistic.
<h2><span class="orange">When Should You Use a Box Plot? (3 Scenarios)</span></h2>
A <b>box plot</b> is a type of plot that displays the five number summary of a dataset, which includes:
The minimum value
The first quartile (the 25th percentile)
The median value
The third quartile (the 75th percentile)
The maximum value
We use three simple steps to create a box plot for any dataset:
<b>1.</b> Draw a box from the first to the third quartile
<b>2.</b> Draw a vertical line at the median
<b>3.</b> Draw “whiskers” from the quartiles to the minimum and maximum value
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/boxplot.png">
We typically create box plots in one of three scenarios:
<b>Scenario 1: To visualize the distribution of values in a dataset.</b>
A box plot allows us to quickly visualize the distribution of values in a dataset and see where the five number summary values are located.
<b>Scenario 2: To compare two or more distributions.</b>
Side-by-side box plots allow us to visualize the differences between two or more distributions and compare the median values and the spread of values between distributions.
<b>Scenario 3: To identify outliers.</b>
In box plots, outliers are typically represented by tiny circles that extend beyond either whisker. An observation is defined to be an outlier if it meets one of the following criteria:
An observation is less than Q1 – 1.5*(Interquartile range)
An observation is greater than Q3 + 1.5*(Interquartile range)
By creating a box plot, we can quickly see whether or not a distribution has any outliers.
The following examples show how we would use a box plot in each scenario.
<h3>Scenario 1: Visualize the Distribution of Values in a Dataset</h3>
Suppose a basketball coach wants to visualize the distribution of points scored by players on his team so he creates the following box plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/whenBox1.png">
Based on this box plot, he can quickly see the following values:
Minimum: 5
Q1 (First Quartile): About 8
Median: About 13
Q3 (Third Quartile): About 18
Maximum: 25
This allows the coach to quickly see that the points scored by players ranges from 5 to 25, the median points scored is about 13, and 50% of his players score between about 8 and 18 points per game.
<h3>Scenario 2: Compare Two or More Distributions</h3>
Suppose a sports analyst wants to compare the distribution of points scored by basketball players on three different teams so he creates the following box plots:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/whenBox2.png">
Using these plots, he can quickly see that Team C has the highest median points scored and Team A has the lowest median points scored.
He can also quickly see that Team B has the highest spread of points scored since the box plot for Team B has the longest box.
<h3>Scenario 3: Identify Outliers</h3>
Suppose a basketball coach wants to know if any of his players are outliers in terms of points scored. He decides to create the following box plot to visualize the distribution of points scored by his players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/whenBox3.png">
Using this plot, the coach can see that the tiny dot at the top of the plot indicates an outlier.
Specifically, one of the players scored about 50 points which is considered an outlier compared to all of the other points scored.
<h2><span class="orange">When to Use a Chi-Square Test (With Examples)</span></h2>
In statistics, there are two different types of <b>Chi-Square tests:</b>
<b>1.</b>  The Chi-Square Goodness of Fit Test  – Used to determine whether or not a categorical variable follows a hypothesized distribution.
<b>2.</b>  The Chi-Square Test of Independence  – Used to determine whether or not there is a significant association between two categorical variables.
Note that both of these tests are only appropriate to use when you’re working with <b>categorical variables</b>. These are variables that take on names or labels and can fit into categories. Examples include:
Eye color (e.g. “blue”, “green”, “brown”)
Gender (e.g. “male”, “female”)
Marital status (e.g. “married”, “single”, “divorced”)
This tutorial explains <em>when</em> to use each test along with several examples of each.
<h3>The Chi-Square Goodness of Fit Test</h3>
You should use the Chi-Square Goodness of Fit Test whenever you would like to know if some categorical variable follows some hypothesized distribution.
Here are some examples of when you might use this test:
<b>Example 1: Counting Customers</b>
A shop owner wants to know if an equal number of people come into a shop each day of the week, so he counts the number of people who come in each day during a random week.
He can use a Chi-Square Goodness of Fit Test to determine if the distribution of customers follows the theoretical distribution that an equal number of customers enters the shop each weekday.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/GOFexcel1.png">
<b>Example 2: Testing if a Die is Fair</b>
Suppose a researcher would like to know if a die is fair. She decides to roll it 50 times and record the number of times it lands on each number.
She can use a Chi-Square Goodness of Fit Test to determine if the distribution of values follows the theoretical distribution that each value occurs the same number of times.
<b>Example 3: Counting M&M’s</b>
Suppose we want to know if the percentage of M&M’s that come in a bag are as follows: 20% yellow, 30% blue, 30% red, 20% other. To test this, we open a random bag of M&M’s and count how many of each color appear.
We can use a Chi-Square Goodness of Fit Test to determine if the distribution of colors is equal to the distribution we specified.
For a step-by-step example of a Chi-Square Goodness of Fit Test, check out  this example  in Excel.
<h3>The Chi-Square Test of Independence</h3>
You should use the Chi-Square Test of Independence when you want to determine whether or not there is a significant association between two categorical variables.
Here are some examples of when you might use this test:
<b>Example 1: Voting Preference & Gender</b>
Researchers want to know if gender is associated with political party preference in a certain town so they survey 500 voters and record their gender and political party preference.
They can perform a Chi-Square Test of Independence to determine if there is a statistically significant association between voting preference and gender.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/chiIndepExcel1.png">
<b>Example 2: Favorite Color & Favorite Sport</b>
Researchers want to know if a person’s favorite color is associated with their favorite sport so they survey 100 people and ask them about their preferences for both.
They can perform a Chi-Square Test of Independence to determine if there is a statistically significant association between favorite color and favorite sport.
<b>Example 3: Education Level & Marital Status</b>
Researchers want to know if education level and marital status are associated so they collect data about these two variables on a simple random sample of 2,000 people.
They can perform a Chi-Square Test of Independence to determine if there is a statistically significant association between education level and marital status.
For a step-by-step example of a Chi-Square Test of Independence, check out  this example  in Excel.
<h2><span class="orange">When Should You Use Correlation? (Explanation & Examples)</span></h2>
Correlation is used to measure the linear association between two variables.
A correlation coefficient always takes on a value between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
One question students often have is: <b>When should I use correlation?</b>
The short answer: <b>Use correlation when you want to quantify the linear relationship between two variables and neither of the variables represents a response or “outcome” variable</b>.
The following examples illustrate when you should and should not use correlation in practice.
<h3>Example 1: When to Use Correlation</h3>
Suppose a professor wants to understand the linear relationship between math exam scores and science exam scores for students in his class.
For example, do students who score high on the math exam also score high on the science exam? Or do students who score high in math tend to score low on science?
In this scenario, he could calculate the <b>correlation</b> between the math exam scores and science exam scores because he simply wants to understand the linear relationship between the two variables and neither variable can be considered a response variable.
Suppose he does calculate the  Pearson correlation coefficient  and finds it to be r = 0.78. This is a strong positive correlation, which means that students who score high on math also tend to score high on science.
<h3>Example 2: When Not to Use Correlation</h3>
Suppose a marketing department at some company wants to quantify how advertisement spending affects total revenue.
For example, for each additional dollar spent on advertising how much additional revenue can the company expect to earn?
In this scenario, the department should use a <b>linear regression model</b> to quantify the relationship between ad spend and total revenue because the variable “revenue” is the response variable.
Suppose the department does fit a  simple linear regression model  and finds the following equation best describes the relationship between ad spend and total revenue:
Total revenue = 145.4 + .34*(ad spend)
We would interpret this to mean that each additional dollar spent on advertising results in an average increase of $0.34 in total revenue.
<h3>Cautions on Using Correlation</h3>
It’s important to note that correlation can only be used to quantify the <b>linear</b> relationship between two variables.
However, in some circumstances a correlation coefficient won’t be able to effectively capture a relationship between two variables that share a non-linear relationship.
For example, suppose we create the following scatterplot to visualize the relationship between two variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/useCor1.png">
If we calculate the correlation coefficient between these two variables, it turns out to be r = 0. This means there is no linear relationship between the two variables.
However, from the plot we can see that the two variables <em>do</em> have a relationship – it just happens to be a quadratic relationship instead of a linear one.
Thus, when you calculate the correlation between two variables keep in mind that it can be helpful to create a scatterplot to visualize the relationship between the variables as well.
Even if two variables don’t have a linear relationship, it’s possible that they could have a non-linear relationship which would be revealed in a scatterplot.
<h2><span class="orange">When Should You Use a Log Scale in Charts?</span></h2>
There are two common scenarios where it’s a good idea to use a <b>log scale</b> when creating charts:
<b>Scenario 1:</b> A few values are significantly larger than all other values.
By using a log scale, it’s easier to visualize the smaller values on the chart.
<b>Scenario 2:</b> You want to analyze percent change instead of raw change.
By using a log scale, it’s easier to visualize percentage change in values over time.
The following examples illustrate when each scenario may occur in the real world.
<h3>Scenario 1: Using a Log Scale When a Few Values Are Much Larger than All Others</h3>
Suppose we would like to visualize the annual revenue of 10 different companies in which 2 of the companies have revenues that are significantly larger than all of the other companies.
Here’s what a bar chart would look like if we visualized the revenues on a <b>linear scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenLog1.png">
Notice that it’s extremely difficult to read the smaller values on the chart and it’s tough to see the differences between the smaller values.
Here’s what the same bar chart would look like on a <b>log scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenLog2.png">
Notice how it’s much easier to differentiate the smaller values using a log scale compared to a linear scale.
<h3>Scenario 2: Using a Log Scale to Visualize Percent Change</h3>
Suppose we make a $100,000 investment in a stock that grows at 6% per year.
Here’s what a line chart of the investment would look like over a 30-year period on a <b>linear scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenLog3.png">
This chart is useful for visualizing how much the investment value changes in raw dollars each year, but suppose we’re more interested in understanding the percentage growth of the investment.
In this case, it would be useful to convert the y-axis to a <b>log scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenLog4.png">
Using this chart, we can see that the percentage change in the investment value has been constant every year during the 30-year period.
<b>Note</b>: Using a log scale can be a useful way to visualize the percentage change of any variable during a time period when the variable experiences exponential growth since the change in values near the end of the time period tend to dwarf the change in values near the beginning.
<h2><span class="orange">When to Use Mean vs. Median (With Examples)</span></h2>
The <b>mean</b> of a dataset represents the average value of the dataset. It is calculated as:
Mean = Σx<sub>i</sub> / n
where:
<b>Σ:</b> A symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> observation in a dataset
<b>n:</b> The total number of observations in the dataset
The <b>median</b> represents the middle value of a dataset. It is calculated by arranging all of the observations in a dataset from smallest to largest and then identifying the middle value. 
For example, suppose we have the following dataset with 11  observations :
<b>Dataset:</b> 3, 4, 4, 6, 7, 8, 12, 13, 15, 16, 17
The mean of the dataset is calculated as:
Mean = (3+4+4+6+7+8+12+13+15+16+17) / 11 = <b>9.54</b>
The median of the dataset is the value directly in the middle, which turns out to be <b>8:</b>
3, 4, 4, 6, 7, <b>8</b>, 12, 13, 15, 16, 17
Both the mean and the median estimate where  the center  of a dataset is located. However, depending on the nature of the data, either the mean or the median may be more useful for describing the center of the dataset.
<h3>When to Use the Mean</h3>
It’s best to use the <b>mean</b> to describe the center of a dataset when the distribution is mostly  symmetrical  and there are no outliers.
For example, suppose we have the following distribution that shows the salaries of residents in a certain city:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/mean_dist.jpg"449">
Since this distribution is fairly symmetrical (if you split it down the middle, each half would look roughly equal) and there are no outliers, we can use the mean to describe the center of this dataset.
The mean turns out to be $63,000, which is located approximately in the center of the distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/mean_dist2.jpg"476">
<h3>When to Use the Median</h3>
It is best to use the median when the distribution is either  skewed  or there are outliers present.
<b>Skewed Data:</b>
When a distribution is skewed, the median does a better job of describing the center of the distribution than the mean.
For example, consider the following distribution of salaries for residents in a certain city:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/median_dist.jpg"473">
The median does a better job of capturing the “typical” salary of a resident than the mean. This is because the large values on the tail end of the distribution tend to pull the mean away from the center and towards the long tail.
In this example, the mean tells us that the typical individual earns about $47,000 per year while the median tells us that the typical individual only earns about $32,000 per year, which is much more representative of the typical individual.
<b>Outliers:</b>
The median also does a better job of capturing the central location of a distribution when there are outliers present in the data. For example, consider the following chart that shows the square footage of houses on a certain street:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2018/09/mean_dist3.jpg">
The mean is heavily influenced by a couple extremely large houses, while the median is not. Thus, the median does a better job of capturing the “typical” square footage of a house on this street compared to the mean.
<h3>Summary</h3>
In summary:
Both the mean and the median can be used to describe where the “center” of a dataset is located.
It’s best to use the mean when the distribution of the data values is symmetrical and there are no clear outliers.
It’s best to use the median when the the distribution of data values is skewed or when there are clear outliers.
<h2><span class="orange">When Should You Use Polynomial Regression?</span></h2>
<b>Polynomial regression</b> is a technique we can use to fit a regression model when the relationship between the predictor variable(s) and the response variable is nonlinear.
A polynomial regression model takes the following form:
Y = β<sub>0</sub> + β<sub>1</sub>X + β<sub>2</sub>X<sup>2</sup> + … + β<sub>h</sub>X<sup>h</sup> + ε
In practice, there are three easy ways to determine if you should use polynomial regression compared to a simpler model like  linear regression .
<h3>1. Create a Scatterplot of the Predictor Variable and Response Variable</h3>
The easiest way to determine if you should use polynomial regression is to create a simple scatterplot of the predictor variable and the response variable.
For example, suppose we’d like to use the predictor variable “hours studied” to predict the score that a student will receive on a final exam.
Before fitting a regression model, we can first create a scatterplot of hours studied vs. exam score. Suppose our scatterplot looks like the following:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenPol1.png">
The relationship between hours studied and exam score looks <b>linear</b>, so it would make sense to fit a simple linear regression model to this dataset.
However, suppose the scatterplot actually looked like the following:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenPol2.png">
This relationship looks a bit more <b>nonlinear</b>, so this tells us that it may be a good idea to fit a polynomial regression model instead.
<h3>2. Create a Fitted Values vs. Residual Plot</h3>
Another way to determine if you should use polynomial regression is to fit a linear regression model to the dataset and then created a <b>fitted values vs. residuals plot</b> for the model.
If there is a clear nonlinear pattern in the residuals, then this is an indication that polynomial regression could offer a better fit to the data.
For example, suppose we fit a linear regression model using hours studied as a predictor variable and exam score as a response variable, then create the following fitted values vs. residuals plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenPol4.png">
The residuals are randomly scattered around zero with no clear pattern, which indicates that a linear model provides an appropriate fit to the data.
However, suppose our fitted values vs. residuals plot actually looked like the following:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/whenPol3.png">
From the plot we can see that there is a clear nonlinear pattern in the residuals – the residuals exhibit a “U” shape.
This tells us that a linear model is not appropriate for this particular data and it could be a good idea to instead fit a polynomial regression model.
<h3>3. Calculate the Adjusted R-Squared Value of the Model</h3>
Another way to determine if you should use polynomial regression is to fit both a linear regression model and a polynomial regression model and calculate the adjusted R-squared values for both models.
The adjusted R-squared represents the proportion of the variance in the response variable that can be explained by the predictor variables in the model, <em>adjusted</em> for the number of predictor variables in the model.
The model with the higher adjusted R-squared represents the model that is better able to use the predictor variable(s) to explain the variation in the response variable.
<h2><span class="orange">When to Use Ridge & Lasso Regression</span></h2>
In ordinary  multiple linear regression , we use a set of <em>p</em> predictor variables and a response variable to fit a model of the form:
<b>Y = β<sub>0</sub> + β<sub>1</sub>X<sub>1</sub> + β<sub>2</sub>X<sub>2</sub> + … + β<sub>p</sub>X<sub>p</sub> + ε</b>
The values for β<sub>0</sub>, β<sub>1</sub>, B<sub>2</sub>, … , β<sub>p</sub> are chosen using the least square method, which minimizes the sum of squared residuals (RSS):
<b>RSS = Σ(y<sub>i</sub> – <U+0177><sub>i</sub>)<sup>2</sup></b>
where:
<b>Σ</b>: A symbol that means “sum”
<b>y<sub>i</sub></b>: The actual response value for the i<sup>th</sup> observation
<b><U+0177><sub>i</sub></b>: The predicted response value for the i<sup>th</sup> observation
<h3>The Problem of Multicollinearity in Regression</h3>
One problem that often occurs in practice with multiple linear regression is  multicollinearity  – when two or more predictor variables are highly correlated to each other, such that they do not provide unique or independent information in the regression model.
This can cause the coefficient estimates of the model to be unreliable and have high variance. That is, when the model is applied to a new set of data it hasn’t seen before, it’s likely to perform poorly.
<h3>Avoiding Multicollinearity: Ridge & Lasso Regression</h3>
Two methods we can use to get around this issue of multicollinearity are <b>ridge regression</b> and <b>lasso regression</b>.
<b>Ridge regression</b> seeks to minimize the following:
<b>RSS + λΣβ<sub>j</sub><sup>2</sup></b>
<b>Lasso regression</b> seeks to minimize the following:
<b>RSS + λΣ|β<sub>j</sub>|</b>
In both equations, the second term is known as a <em>shrinkage penalty</em>.
When λ = 0, this penalty term has no effect and both ridge regression and lasso regression produce the same coefficient estimates as least squares.
However, as λ approaches infinity the shrinkage penalty becomes more influential and the predictor variables that aren’t importable in the model get shrunk towards zero.
With Lasso regression, it’s possible that some of the coefficients could go <em>completely to zero</em> when λ gets sufficiently large.
<h3>Pros & Cons of Ridge & Lasso Regression</h3>
The <b>benefit</b> of ridge and lasso regression compared to least squares regression lies in the  bias-variance tradeoff .
Recall that mean squared error (MSE) is a metric we can use to measure the accuracy of a given model and it is calculated as:
MSE = Var(<em>f<U+0302>(</em>x<sub>0</sub>)) + [Bias(<em>f<U+0302>(</em>x<sub>0</sub>))]<sup>2</sup> + Var(ε)
MSE = Variance + Bias<sup>2</sup> + Irreducible error
The basic idea of both ridge and lasso regression is to introduce a little bias so that the variance can be substantially reduced, which leads to a lower overall MSE.
To illustrate this, consider the following chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/ridge1.png">
Notice that as λ increases, variance drops substantially with very little increase in bias. Beyond a certain point, though, variance decreases less rapidly and the shrinkage in the coefficients causes them to be significantly underestimated which results in a large increase in bias.
We can see from the chart that the test MSE is lowest when we choose a value for λ that produces an optimal tradeoff between bias and variance.
When λ = 0, the penalty term in lasso regression has no effect and thus it produces the same coefficient estimates as least squares. However, by increasing λ to a certain point we can reduce the overall test MSE.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/11/lasso1.png">
This means the model fit by ridge and lasso regression can potentially produce smaller test errors than the model fit by least squares regression.
The <b>drawback</b> of ridge and lasso regression is that it becomes difficult to interpret the coefficients in the final model since they get shrunk towards zero.
Thus, ridge and lasso regression should be used when you’re interested in optimizing for predictive ability rather than inference.
<h3>Ridge vs. Lasso Regression: When to Use Each</h3>
Both lasso regression and ridge regression are known as <em>regularization methods</em> because they both attempt to minimize the sum of squared residuals (RSS) along with some penalty term.
In other words, they constrain or <em>regularize</em> the coefficient estimates of the model.
This naturally brings up the question: <b>Is ridge or lasso regression better?</b>
In cases where only a small number of predictor variables are significant, <b>lasso regression</b> tends to perform better because it’s able to shrink insignificant variables completely to zero and remove them from the model.
However, when many predictor variables are significant in the model and their coefficients are roughly equal then <b>ridge regression</b> tends to perform better because it keeps all of the predictors in the model.
To determine which model is better at making predictions, we typically perform  k-fold cross-validation  and choose whichever model produces the lowest test mean squared error.
 Introduction to Ridge Regression 
 Introduction to Lasso Regression 
The following tutorials explain how to perform both types of regression in R and Python:
 Ridge Regression in R 
 Ridge Regression in Python 
 Lasso Regression in R 
 Lasso Regression in Python 
<h2><span class="orange">When to Use Spearman’s Rank Correlation (2 Scenarios)</span></h2>
The most common way to quantify the linear association between two variables is to use the  Pearson Correlation Coefficient , which always takes on a value between -1 and 1 where:
<b>-1</b> indicates a perfectly negative linear correlation
0 indicates no linear correlation
1 indicates a perfectly positive linear correlation
However, this type of correlation coefficient works best when the true underlying relationship between the two variables is <em>linear</em>.
There is another type of correlation coefficient known as <b>Spearman’s rank correlation</b> that is better to use in two specific scenarios:
<b>Scenario 1</b>: When working with ranked data.
An example could be a dataset that contains the rank of a student’s math exam score along with the rank of their science exam score in a class.
<b>Scenario 2</b>: When one or more extreme outliers are present.
When extreme outliers are present in a dataset, Pearson’s correlation coefficient is highly affected.
The following examples show how to calculate the Spearman Rank Correlation in each of these scenarios.
<h3>Scenario 1: Spearman’s Rank Correlation with Ranked Data</h3>
Consider the following dataset (and corresponding scatter plot) that shows the relationship between two variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/spearmanuse3-1.jpg"655">
Using statistical software, we can calculate the following correlation coefficients for these two variables:
Pearson’s correlation: <b>0.79</b>
Spearman’s rank correlation: <b>1</b>
In this scenario, if we only care about the ranks of the data values (when the rank of x increases, does the rank of y also increase?) then Spearman’s rank correlation would provide us with a better idea of the correlation between the two variables.
In this particular dataset, as the rank of x increases the rank of y <em>always</em> increases.
Spearman’s rank correlation captures this behavior perfectly by telling us that there is a perfect positive relationship (<b>ρ = 1</b>) between the ranks of x and the ranks of y.
By contrast, Pearson’s correlation tells us the that there is a strong linear relationship (<b>r = 0.79</b>) between the two variables.
This is true, but it’s not useful if we only care about the relationship between the ranks of x and the ranks of y.
<h3>Scenario 2: Spearman’s Rank Correlation with Extreme Outliers</h3>
Consider the following dataset (and corresponding scatter plot) that shows the relationship between two variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/spearmanuse1.jpg"654">
Using statistical software, we can calculate the following correlation coefficients for these two variables:
Pearson’s correlation: <b>0.86</b>
Spearman’s rank correlation: <b>0.85</b>
The correlation coefficients are nearly identical because the underlying relationship between the variables is roughly linear and there are no extreme outliers.
Now suppose we change the last y value in the dataset to be an extreme outlier:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/spearmanuse2.jpg"658">
Using statistical software, we can calculate the correlation coefficients once again:
Pearson’s correlation: <b>0.69</b>
Spearman’s rank correlation: <b>0.85</b>
Pearson’s correlation coefficient changed dramatically while Spearman’s rank correlation coefficient remained the same.
Using statistical jargon, we would say that the relationship between x and y is  monotonic  (as x increases, y generally increases) but not linear since the outlier influences the data so much.
In this scenario, Spearman’s rank correlation does a good job of quantifying this monotonic relationship, while Pearson’s correlation does a poor job because it’s attempting to calculate the linear relationship between the two variables.
<b>Related:</b>  How to Report Spearman’s Rank Correlation in APA Format 
<h2><span class="orange">How to Use the Which Function in R (With Examples)</span></h2>
The <b>which()</b> function in R returns the position of elements in a logical vector that are <b>TRUE</b>.
This tutorial provides several examples of how to use this function in practice.
<h3>Example 1: Find Elements in a Vector</h3>
The following code shows how to find the position of all elements in a vector that are equal to 5:
<b>#create data
data &lt;- c(1, 2, 2, 3, 4, 4, 4, 5, 5, 12)
#find the position of all elements equal to 5
which(data == 5)
[1] 8 9</b>
We can see that the elements in positions <b>8</b> and <b>9</b> in the vector are equal to the value 5.
We can also find the position of all elements in a vector that are <em>not</em> equal to 5:
<b>#find the position of all elements <em>not</em> equal to 5
which(data != 5)
[1]  1  2  3  4  5  6  7 10
</b>
We can also find which elements are between two values or outside of two values:
<b>#find the position of all elements with values between 2 and 4
which(data >= 2 & data &lt;= 4)
[1] 2 3 4 5 6 7
#find the position of all elements with values outside of 2 and 4
which(data &lt; 2 | data > 4)
[1]  1  8  9 10</b>
<h3>Example 2: Count Occurrences in a Vector</h3>
The following code shows how to use the <b>length()</b> function to find the number of elements in a vector that are greater than some value:
<b>#create data
data &lt;- c(1, 2, 2, 3, 4, 4, 4, 5, 5, 12)
#find number of elements greater than  4
length(which(data > 4))
[1] 3
</b>
We can see that there are 3 elements in this vector with values greater than 4.
<h3>Example 3: Find Rows in a Data Frame</h3>
The following code shows how to return the row in a data frame that contains the max or min value in a certain column:
<b>#create data frame
df &lt;- data.frame(x = c(1, 2, 2, 3, 4, 5), y = c(7, 7, 8, 9, 9, 9), z = c('A', 'B', 'C', 'D', 'E', 'F'))
#view data frame
df
  x y z
1 1 7 A
2 2 7 B
3 2 8 C
4 3 9 D
5 4 9 E
6 5 9 F
#return row that contains the max value in column <em>x</em>
df[which.max(df$x), ]
  x y z
6 5 9 F
#return row that contains the min value in column <em>x</em>
df[which.min(df$x), ]
  x y z
1 1 7 A
</b>
<h3>Example 4: Subset by Rows in a Data Frame</h3>
The following code shows how to subset a data frame by rows that meet a certain criteria:
<b>#create data frame
df &lt;- data.frame(x = c(1, 2, 2, 3, 4, 5), y = c(7, 7, 8, 9, 9, 9), z = c('A', 'B', 'C', 'D', 'E', 'F'))
#view data frame
df
  x y z
1 1 7 A
2 2 7 B
3 2 8 C
4 3 9 D
5 4 9 E
6 5 9 F
#return subset of data frame where values in column y are greater than 8
df[which(df$y > 8), ]
  x y z
4 3 9 D
5 4 9 E
6 5 9 F
</b>
Find more R tutorials on  this page .
<h2><span class="orange">How to Choose Which Variable to Place on X-Axis and Y-Axis</span></h2>
When creating a line plot or a scatterplot, students often have the following question:
<em><b>Which variable should I place on the x-axis and which should I place on the y-axis?</b></em>
<b>The short answer</b>: The independent variable (or “explanatory variable”) should go on the x-axis and the dependent variable (or “response variable”) should go on the y-axis.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/which2.png">
Another way to phrase it: the variable that can be viewed as “explanatory” should go on the x-axis and the variable that is “being explained” should go on the y-axis.
The following examples show how to choose which variable to place on each axis in practice.
<h3>Example 1: Hours Studied vs. Exam Score</h3>
Suppose a professor collects data on the following variables for students in his class:
Number of hours studied
Exam score received
When creating a scatterplot to visualize these two variables, he should place the following variables on each axis:
<b>x-axis</b>: Number of hours studied
<b>y-axis</b>: Exam Score received
Since the exam score received is dependent on the number of hours studied, the number of hours studied belongs on the x-axis while the exam score belongs on the y-axis.
Here’s what the scatterplot would look like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/which1.png">
<h3>Example 2: Food Consumption vs. Weight</h3>
Suppose a biologist collects data on the following variables for mice in his lab:
Grams of food fed daily
Weight after one month
When creating a scatterplot to visualize these two variables, he should place the following variables on each axis:
<b>x-axis</b>: Grams of food fed daily
<b>y-axis</b>: Weight after one month
Since the weight of each mouse is dependent on the number of grams of food they’re fed daily, the number of grams of food belongs on the x-axis while the weight belongs on the y-axis.
Here’s what the scatterplot would look like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/which3.png">
<h3>Example 3: Age vs. Height</h3>
Suppose a botanist collects data on the following variables for a certain plant:
Height (in inches)
Age (in weeks)
When creating a line plot to visualize these two variables, she should place the following variables on each axis:
<b>x-axis</b>: Age (in weeks)
<b>y-axis</b>: Height (in inches)
Since the height of the plant is dependent on the age, the age belongs on the x-axis while the height belongs on the y-axis.
Here’s what the line plot would look like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/which4.png">
<h2><span class="orange">How to Perform White’s Test in Python (Step-by-Step)</span></h2>
<b>White’s test</b> is used to determine if  heteroscedasticity  is present in a regression model.
Heteroscedasticity refers to the unequal scatter of  residuals  at different levels of a  response variable , which violates the  assumption  that the residuals are equally scattered at each level of the response variable.
The following step-by-step example shows how to perform White’s test in Python to determine whether or not heteroscedasticity is a problem in a given regression model.
<h3>Step 1: Load Data</h3>
In this example we will fit a  multiple linear regression model  using the <b>mtcars</b> dataset.
The following code shows how to load this dataset into a pandas DataFrame:
<b>from sklearn.linear_model import LinearRegression
from statsmodels.stats.diagnostic import het_white
import statsmodels.api as sm
import pandas as pd
#define URL where dataset is located
url = "https://raw.githubusercontent.com/Statology/Python-Guides/main/mtcars.csv"
#read in data
data = pd.read_csv(url)
#view summary of data
data.info()
&lt;class 'pandas.core.frame.DataFrame'>
RangeIndex: 32 entries, 0 to 31
Data columns (total 12 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   model   32 non-null     object 
 1   mpg     32 non-null     float64
 2   cyl     32 non-null     int64  
 3   disp    32 non-null     float64
 4   hp      32 non-null     int64  
 5   drat    32 non-null     float64
 6   wt      32 non-null     float64
 7   qsec    32 non-null     float64
 8   vs      32 non-null     int64  
 9   am      32 non-null     int64  
 10  gear    32 non-null     int64  
 11  carb    32 non-null     int64  
dtypes: float64(5), int64(6), object(1)
</b>
<h3>Step 2: Fit Regression Model</h3>
Next, we will fit a regression model using <b>mpg </b>as the response variable and <b>disp </b> and <b>hp </b>as the two predictor variables:
<b>#define response variable
y = data['mpg']
#define predictor variables
x = data[['disp', 'hp']]
#add constant to predictor variables
x = sm.add_constant(x)
#fit regression model
model = sm.OLS(y, x).fit()</b>
<h3>Step 3: Perform White’s Test</h3>
Next, we will use the  het_white()  function from the statsmodels package to perform White’s test to determine if heteroscedasticity is present in the regression model:
<b>#perform White's test
white_test = het_white(model.resid,  model.model.exog)
#define labels to use for output of White's test
labels = ['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value']
#print results of White's test
print(dict(zip(labels, white_test)))
{'Test Statistic': 7.076620330416624, 'Test Statistic p-value': 0.21500404394263936,
 'F-Statistic': 1.4764621093131864, 'F-Test p-value': 0.23147065943879694}</b>
Here is how to interpret the output:
The test statistic is X<sup>2</sup> = <b>7.0766</b>.
The corresponding p-value is <b>0.215</b>.
White’s test uses the following null and alternative hypotheses:
<b>Null (H<sub>0</sub>)</b>: Homoscedasticity is present (residuals are equally scattered)
<b>Alternative (H<sub>A</sub>):</b> Heteroscedasticity is present (residuals are not equally scattered)
Since the p-value is not less than 0.05, we fail to reject the null hypothesis.
This means we do not have sufficient evidence to say that heteroscedasticity is present in the regression model.
<h3>What To Do Next</h3>
If you fail to reject the null hypothesis of White’s test then heteroscedasticity is not present and you can proceed to interpret the output of the original regression.
However, if you reject the null hypothesis, this means heteroscedasticity is present. In this case, the standard errors that are shown in the output table of the regression may be unreliable.
There are two common ways to fix this issue:
<b>1. Transform the response variable.</b>
You can try performing a transformation on the response variable, such as taking  the log, square root, or cube root  of the response variable. This often causes heteroscedasticity to go away.
<b>2. Use weighted regression.</b>
Weighted regression assigns a weight to each data point based on the variance of its fitted value. Essentially, this gives small weights to data points that have higher variances, which shrinks their squared residuals. When the proper weights are used, this can eliminate the problem of heteroscedasticity.
<h2><span class="orange">How to Perform White’s Test in R (With Examples)</span></h2>
<b>White’s test</b> is used to determine if  heteroscedasticity  is present in a regression model.
Heteroscedasticity refers to the unequal scatter of  residuals  at different levels of a  response variable  in a regression model, which violates one of the key  assumptions of linear regression  that the residuals are equally scattered at each level of the response variable.
This tutorial explains how to perform White’s test in R to determine whether or not heteroscedasticity is a problem in a given regression model.
<h3>Example: White’s Test in R</h3>
In this example we will fit a  multiple linear regression model  using the built-in R dataset mtcars.
Once we’ve fit the model, we’ll use the <b>bptest </b>function from the <b>lmtest </b>library to perform White’s test to determine if heteroscedasticity is present.
<b>Step 1: Fit a regression model.</b>
First, we will fit a regression model using <b>mpg </b>as the response variable and <b>disp </b> and <b>hp </b>as the two explanatory variables.
<b>#load the dataset
data(mtcars)
#fit a regression model
model &lt;- lm(mpg~disp+hp, data=mtcars)
#view model summary
summary(model)
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 30.735904   1.331566  23.083  &lt; 2e-16 ***
disp        -0.030346   0.007405  -4.098 0.000306 ***
hp          -0.024840   0.013385  -1.856 0.073679 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 3.127 on 29 degrees of freedom
Multiple R-squared:  0.7482,Adjusted R-squared:  0.7309 
F-statistic: 43.09 on 2 and 29 DF,  p-value: 2.062e-09
</b>
<b>Step 2: Perform White’s test.</b>
Next, we will use the following syntax to perform White’s test to determine if heteroscedasticity is present:
<b>#load lmtest library
library(lmtest)
#perform White's test
bptest(model, ~ disp*hp + I(disp^2) + I(hp^2), data = mtcars)
studentized Breusch-Pagan test
data:  model
BP = 7.0766, df = 5, p-value = 0.215
</b>
Here is how to interpret the output:
The test statistic is X<sup>2</sup> = <b>7.0766</b>.
The degrees of freedom is <b>5</b>.
The corresponding p-value is <b>0.215</b>.
White’s test uses the following null and alternative hypotheses:
<b>Null (H<sub>0</sub>)</b>: Homoscedasticity is present.
<b>Alternative (H<sub>A</sub>):</b> Heteroscedasticity is present.
Since the p-value is not less than 0.05, we fail to reject the null hypothesis. We do not have sufficient evidence to say that heteroscedasticity is present in the regression model.
<h3>What To Do Next</h3>
If you fail to reject the null hypothesis of White’s test then heteroscedasticity is not present and you can proceed to interpret the output of the original regression.
However, if you reject the null hypothesis, this means heteroscedasticity is present in the data. In this case, the standard errors that are shown in the output table of the regression may be unreliable.
There are a couple common ways that you can fix this issue, including:
<b>1. Transform the response variable.</b>
You can try performing a transformation on the response variable, such as taking  the log, square root, or cube root  of the response variable. Typically this can cause heteroscedasticity to go away.
<b>2. Use weighted regression.</b>
 Weighted regression  assigns a weight to each data point based on the variance of its fitted value. Essentially, this gives small weights to data points that have higher variances, which shrinks their squared residuals. When the proper weights are used, this can eliminate the problem of heteroscedasticity.
<h2><span class="orange">Why is Sample Size Important? (Explanation & Examples)</span></h2>
<b>Sample size</b> refers to the total number of individuals involved in an experiment or study.
Sample size is important because it directly affects how precisely we can estimate population parameters.
To understand why this is the case, it helps to have a basic understanding of confidence intervals.
<h3>A Brief Explanation of Confidence Intervals</h3>
In statistics, we’re often interested in measuring  population parameters  – numbers that describe some characteristic of an entire population.
For example, we might be interested in measuring the mean height of all individuals in a certain city.
However, it’s often too costly and time-consuming to go around and collect data on every individual in a population so we typically take a  random sample  from the population instead and use data from the sample to estimate the population parameter.
For example, we might collect data on the height of 100 random individuals in the city. We can then calculate the mean height of the individuals in the sample. However, we can’t be certain that the sample mean exactly matches the population mean.
To account for this uncertainty, we can create a  confidence interval . A confidence interval is a range of values that is likely to contain a population parameter with a certain level of confidence.
The formula to calculate a confidence interval for a population mean is:
<b>Confidence Interval = x  +/-  z*(s/√n)</b>
where:
<b>x: </b>sample mean
<b>z: </b>the chosen z-value
<b>s: </b>sample standard deviation
<b>n: </b>sample size
The z-value that you will use is dependent on the confidence level that you choose. The following table shows the z-value that corresponds to popular confidence level choices:
<table><tbody>
<tr>
<th style="text-align: center;"><b>Confidence Level</b></th>
<th style="text-align: center;"><b>z-value</b></th>
</tr>
<tr>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">1.645</td>
</tr>
<tr>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.96</td>
</tr>
<tr>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">2.58</td>
</tr>
</tbody></table>
<h3>The Relationship Between Sample Size & Confidence Intervals</h3>
Suppose we want to estimate the mean weight of a population of turtles. We collect a random sample of turtles with the following information:
Sample size <b>n = 25</b>
Sample mean weight <b>x = 300</b>
Sample standard deviation <b>s = 18.5</b>
Here is how to find calculate the 90% confidence interval for the true population mean weight:
<b>90% Confidence Interval: </b>300 +/-  1.645*(18.5/√25) = <b>[293.91, 306.09]</b>
We are 90% confident that the true mean weight of the turtles in the population is between 293.91 and 306.09 pounds.
Now suppose instead of 25 turtles, we actually collect data for 50 turtles. 
Here is how to find calculate the 90% confidence interval for the true population mean weight:
<b>90% Confidence Interval: </b>300 +/-  1.645*(18.5/√50) = <b>[295.79, 304.30]</b>
Notice that this confidence interval is narrower than the previous confidence interval. This means our estimate of the true population mean weight of turtles is more precise.
Now suppose we instead collected data for 100 turtles. 
Here is how to find calculate the 90% confidence interval for the true population mean weight:
<b>90% Confidence Interval: </b>300 +/-  1.645*(18.5/√100) = <b>[296.96, 303.04]</b>
Notice that this confidence interval is <em>even narrower</em> than the previous confidence interval. 
The following table summarizes each of the confidence interval widths:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/confWidth1.png">
Here’s the takeaway: <b>The larger the sample size, the more precisely we can estimate a population parameter</b>.
<h2><span class="orange">Why is Standard Deviation Important? (Explanation + Examples)</span></h2>
The <b>standard deviation</b> is used to measure the spread of values in a sample.
We can use the following formula to calculate the standard deviation of a given sample:
√Σ(x<sub>i</sub> – x<sub>bar</sub>)<sup>2</sup> / (n-1)
where:
<b>Σ:</b> A symbol that means “sum”
<b>x<sub>i</sub>:</b> The i<sup>th</sup> value in the sample
<b>x<sub>bar</sub>:</b> The mean of the sample
<b>n:</b> The sample size
The higher the value for the standard deviation, the more spread out the values are in a sample. Conversely, the lower the value for the standard deviation, the more tightly packed together the values.
One question students often have is: <b><em>Why is the standard deviation important?</em></b>
The answer: <b>Standard deviation is important because it tells us how spread out the values are in a given dataset.</b>
Whenever we analyze a dataset, we’re interested in finding the following metrics:
<b>The center of the dataset</b>. The most common way to measure the “center” is with the mean and the median.
<b>The spread of values in the dataset</b>. The most common way to measure spread is with the standard deviation.
By knowing where the center is located and how spread out the values are, we can gain a good understanding of the distribution of values in any dataset.
The following examples illustrate the importance of the standard deviation in practice.
<h3>Example 1: Distribution of Salaries</h3>
Suppose the mean salary at company A is $80,000 and the standard deviation is $20,000. Since the standard deviation is so large, there’s no guarantee that you will get paid close to $80,000 per year if you work at this company since there’s such a variation in salaries.
Conversely, suppose the mean salary at company B is also $80,000 but the standard deviation is only $4,000. Since this standard deviation is so small, you can be sure that you’ll get paid close to $80,000 because there’s very little variation in salaries.
If we created a boxplot to visualize the distribution of salaries at these two companies, it might look something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/sdImportance.png">
Notice that the length of the boxplot for company A is so much greater because the standard deviation of salaries is so much higher.
Both companies have the same mean salary, but the spread of salaries is much higher at company A.
<h3>Example 2: Distribution of House Prices</h3>
Suppose the mean house price in neighborhood A is $250,000 and the standard deviation is $50,000. Since the standard deviation is quite large, this means that some of the house prices will be far greater than $250,000 and some will be far less. If you look at a given house in this neighborhood, there’s no guarantee that the price will be close to the mean.
Conversely, suppose the mean house price in neighborhood B is also $250,000 but the standard deviation is only $10,000. Since this standard deviation is fairly small, you can be sure that any given house you look at in the neighborhood is likely to be close to this price.
If we created a boxplot to visualize the distribution of house prices in these two neighborhoods, it might look something like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/sdImportance2.png">
The length of the boxplot for neighborhood A is so much greater because the standard deviation of house prices is so much higher.
In fact, house prices range from lower than $150k to higher than $400k for neighborhood A, while prices only range from about $230k to $270k for neighborhood B.
By simply knowing the standard deviation of house prices in each neighborhood, we can know how much variation to expect in prices in each neighborhood.
<h2><span class="orange">Why is Statistics Important? (10 Reasons Statistics Matters!)</span></h2>
The field of <b>statistics</b> is concerned with collecting, analyzing, interpreting, and presenting data.
As technology becomes more present in our daily lives, more data is being generated and collected now than ever before in human history.
Statistics is the field that can help us understand how to use this data to do the following things:
Gain a better understanding of the world around us.
Make decisions using data.
Make predictions about the future using data.
In this article we share 10 reasons for why the field of statistics is so important in modern life.
<h3>Reason 1: To Use Descriptive Statistics to Understand the World</h3>
 Descriptive statistics  are used to describe a chunk of raw data. There are three main types of descriptive statistics:
Summary statistics
Charts
Tables
Each of these can help us gain a better understanding of existing data.
For example, suppose we have a set of raw data that shows the test scores of 10,000 students in a certain city. We can use descriptive statistics to:
Calculate the average test score and the standard deviation of test scores.
Generate a histogram or boxplot to visualize the distribution of test scores.
Create a frequency table to understand the distribution of test scores.
Using descriptive statistics, we can understand the test scores of the students much more easily compared to just staring at the raw data.
<h3>Reason 2: To Be Wary of Misleading Charts</h3>
There are more charts being generated in journals, news outlets, online articles, and magazines than ever before. Unfortunately, charts can often be misleading if you don’t understand the underlying data.
For example, suppose some journal publishes a study that finds a negative correlation between GPA and ACT scores for students at a a certain university.
However, this negative correlation only occurs because the students who have <em>both</em> a high GPA and ACT score may go to an elite university while students who have <em>both</em> a low GPA and ACT score do not get admitted at all.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/berkson6.png">
Although the correlation between ACT and GPA is positive in the population, the correlation appears to be negative in the sample.
This particular bias is known as  Berkson’s bias . By being aware of this bias, you can avoid being mislead by certain charts.
<h3>Reason 3: To Be Wary of Confounding Variables</h3>
One important concept that you’ll learn about in statistics is the concept of  confounding variables .
These are variables that are unaccounted for and can <em>confound</em> the results of an experiment and lead to unreliable findings.
For example, suppose a researcher collects data on ice cream sales and shark attacks and finds that the two variables are highly correlated. Does this mean that increased ice cream sales cause more shark attacks?
That’s unlikely. The more likely cause is the confounding variable <b>temperature</b>. When it is warmer outside, more people buy ice cream and more people go in the ocean.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/confound4.png">
<h3>Reason 4: To Make Better Decisions Using Probability</h3>
One of the most important sub-fields of statistics is <b>probability</b>. This is the field that studies how likely events are to happen.
By having a basic understanding of probability, you can make more informed decisions in the real world.
For example, suppose a high school student knows that they have a 10% chance of being accepted to a given university. Using the formula for  the probability of “at least one” success , this student can find the probability that they’ll get accepted to at least one university they apply for and can adjust the number of universities they apply for accordingly.
<h3>Reason 5: To Understand P-Values in Research</h3>
Another important concept that you’ll learn about in statistics is  p-values .
The textbook definition of a p-value is:
A <b>p-value</b> is the probability of observing a sample statistic that is at least as extreme as your sample statistic, given that the null hypothesis is true.
For example, suppose a factory claims that they produce tires that have a mean weight of 200 pounds. An auditor hypothesizes that the true mean weight of tires produced at this factory is different from 200 pounds so he runs a hypothesis test and finds that the p-value of the test is 0.04.
Here is how to interpret this p-value:
If the factory does indeed produce tires that have a mean weight of 200 pounds, then 4% of all audits will obtain the effect observed in the sample, or larger, because of random sample error. This tells us that obtaining the sample data that the auditor did would be pretty rare if indeed the factory produced tires that have a mean weight of 200 pounds. 
Thus, the auditor would likely reject the null hypothesis that the true mean weight of tires produced at this factory is indeed 200 pounds.
<h3>Reason 6: To Understand Correlation</h3>
Another important concept that you’ll learn about in statistics is  correlation , which tells us the linear association between two variables.
The value for a correlation coefficient always ranges between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
By understanding these values, you can understand the relationship between variables in the real world.
For example, if the correlation between advertisement spending and revenue is 0.87, then you can understand that there is a strong positive relationship between the two variables. As you spend more money on advertising, you can expect a predictable increase in revenue.
<h3>Reason 7: To Make Predictions About the Future</h3>
Another important reason to learn statistics is to understand basic regression models such as:
 Simple linear regression 
 Multiple linear regression 
 Logistic Regression 
Each of these models allow you to make predictions about the future value of some  response variable  based on the value of certain predictor variables in the model.
For example, multiple linear regression models are used all the time in the real world by businesses when they use predictor variables such as age, income, ethnicity, etc. to predict how much customers will spend at their stores.
Similarly, logistics companies use predictor variables like total demand, population size, etc. to forecast future sales.
No matter which field you’re employed in, the odds are good that regression models will be used to predict some future phenomenon.
<h3>Reason 8: To Understand Potential Bias in Studies</h3>
Another reason to study statistics is to be aware of all the different types of bias that can occur in real-world studies.
Some examples include:
 Observer Bias 
 Self-Selection Bias 
 Referral Bias 
 Omitted Variable Bias 
 Undercoverage Bias 
 Nonresponse Bias 
By having a basic understanding of these types of biases, you can avoid committing them when performing research or be aware of them when reading through other research papers or studies.
<h3>Reason 9: To Understand the Assumptions Made by Statistical Tests</h3>
Many statistical tests make assumptions about the underlying data under study.
When reading the results of a study or even performing your own study, it’s important to understand what assumptions need to be made in order for the results to be reliable.
The following articles share the assumptions made in many commonly used statistical tests and procedures:
 What is the Assumption of Equal Variance in Statistics? 
 What is the Assumption of Normality in Statistics? 
 What is the Assumption of Independence in Statistics? 
<h3>Reason 10: To Avoid Overgeneralization</h3>
Another reason to study statistics is to understand the concept of <b>overgeneralization</b>.
This occurs when the individuals in a study are not  representative  of the individuals in the overall population and therefore it’s inappropriate to generalize the conclusions from a study to the larger population.
For example, suppose we want to know what percentage of students at a certain school prefer “drama” as their favorite movie genre. If the total student population is a mix of 50% boys and 50% girls, then a sample with a mix of 90% boys and 10% girls might lead to biased results if far fewer boys prefer drama as their favorite genre. 
Ideally, we want our sample to be like a “mini version” of our population. So, if the overall student population is composed of 50% girls and 50% boys, our sample would not be representative if it included 90% boys and only 10% girls.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/12/rep_sample1.jpg"366">
Thus, whether you’re conducting your own survey or you’re reading about the results of a survey, it’s important to understand whether the sample data is representative of the total population and whether the findings of the survey can be generalized to the population with confidence.
<h2><span class="orange">Wilcoxon Signed-Rank Test Calculator</span></h2>
The <b> Wilcoxon Signed-Rank Test </b> is the non-parametric version of the <b> paired t-test </b>. It is used to test whether or not there is a significant difference between two population means.
To perform a Wilcoxon Signed-Rank Test, simply fill in the data values for two samples below and then click the “Calculate” button.
<b>Sample 1</b>
<textarea id="rawData1" rows="5" cols="40">14, 17, 12, 15, 15, 9, 12, 13, 13, 15, 19, 17, 14, 14, 16</textarea>
<b>Sample 2</b>
<textarea id="rawData2" rows="5" cols="40">15, 17, 15, 15, 17, 14, 9, 14, 11, 16, 18, 20, 20, 10, 17</textarea>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>W test statistic =</b> 29.5
<b>Number of non-tied pairs (n) =</b> 13
Refer to the critical values table below to decide whether or not the test result is statistically significant based on <i>n</i> and your chosen alpha level.
If the test statistic <i>W</i> is less than the value found in the critical values table below, then the test result is statistically significant.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox5.png">
<script>
function calc() {
//get raw data
var raw1 = document.getElementById('rawData1').value.split(',').map(Number);
var raw2 = document.getElementById('rawData2').value.split(',').map(Number);
//calculate raw paired differences
var diff = [];
for (var i = 0; i < raw1.length; i++) {
            if (raw1[i]-raw2[i] != 0) {
            diff.push(raw1[i]-raw2[i]);
            }
        } 
//calculate absolute paired differences
var diff_abs = [];
for (var i = 0; i < raw1.length; i++) {
            if (raw1[i]-raw2[i] != 0) {
            diff_abs.push(Math.abs(raw1[i]-raw2[i]));
            }
        } 
//rank absolute paired differences
var sorted = diff_abs.slice().sort(function(a,b){return a-b})
    var reversed = sorted.slice(0).reverse();
    var frac_rank = diff_abs.slice().map(function(n) { return ( (sorted.indexOf(n) + 1) + (reversed.length - reversed.indexOf(n)) ) / 2 });
//create array of positive ranks
var positive_ranks = [];
for (var i = 0; i < diff.length; i++) {
            if (diff[i] > 0) {
            positive_ranks.push(frac_rank[i]);
            }
} 
//create array of negative ranks
var negative_ranks = [];
for (var i = 0; i < diff.length; i++) {
            if (diff[i] < 0) {
            negative_ranks.push(frac_rank[i]);
            }
} 
//find sum of positive and negative ranks
var positive_sum = Math.abs(math.sum(positive_ranks));
var negative_sum = Math.abs(math.sum(negative_ranks));
var w = Math.min(positive_sum, negative_sum);
var n = diff.length;
//output results
document.getElementById('w').innerHTML = w;
document.getElementById('n').innerHTML = n;
}
</script>
<h2><span class="orange">How to Perform a Wilcoxon Signed Rank Test in Excel (Step-by-Step)</span></h2>
The  Wilcoxon Signed-Rank Test  is the non-parametric version of the  paired samples t-test . 
It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be  normal .
This tutorial provides a step-by-step example of how to conduct a Wilcoxon Signed-Rank Test in Excel.
<h3>Step 1: Create the Data</h3>
Suppose an engineer want to know if a new fuel treatment leads to a change in the average miles per gallon of a certain car. To test this, he measures the mpg of 12 cars with and without the fuel treatment.
We’ll create the following data in Excel to hold the mpg values for each car with the fuel treatment (group1) and without the fuel treatment (group 2):
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel1.png">
<h3>Step 2: Calculate the Difference Between the Groups</h3>
Next, we’ll calculate the difference between the groups:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel2.png">
<h3>Step 3: Calculate the Absolute Differences</h3>
Next, we’ll calculate the absolute difference between the groups, returning a blank if the absolute difference is zero:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel3-2.png">
<h3>Step 4: Calculate the Rank of the Absolute Differences</h3>
Next, we’ll use the <b>RANK.AVG()</b> function to calculate the rank of the absolute differences between the groups, returning a blank if the absolute difference is zero:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel4.png">
<h3>Step 5: Calculate the Positive & Negative Ranks</h3>
Next, we’ll calculate the positive ranks:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel5.png">
And we’ll calculate the negative ranks:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel6.png">
<h3>Step 6: Calculate the Test Statistic & Sample Size</h3>
Lastly, we’ll calculate the test statistic which is simply the smaller of the sum of the positive ranks or the sum of the negative ranks:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel7.png">
And we’ll calculate the sample size, which is the total number of ranks that aren’t equal to zero:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/wilcoxExcel8.png">
The test statistic turns out to be <b>10.5</b> and the sample size is <b>11</b>.
In this example, the Wilcoxon Signed-Rank Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>The mpg is equal between the two groups
<b>H<sub>A</sub>: </b>The mpg is <em>not </em>equal between the two groups
To determine if we should reject or fail to reject the null hypothesis, we can find the critical value that corresponds to α = .05 and a sample size of 11 in the following Wilcoxon Signed Rank Test Critical Values Table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox5.png">
The critical value that corresponds to α = .05 and a sample size of 11 is <b>10</b>.
Since the test statistic (10.5) is not less than the critical value of 10,  we fail to reject the null hypothesis. 
We do not have sufficient evidence to say that the mean mpg is not equal between the two groups.
<b>Bonus:</b> Feel free to use this  Wilcoxon Signed-Rank Test Calculator  to automatically calculate the test statistic for a Wilcoxon Signed-Rank Test.
<h2><span class="orange">How to Perform a Wilcoxon Signed Rank Test in SAS</span></h2>
The  Wilcoxon Signed-Rank Test  is the non-parametric version of the  paired samples t-test . 
It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be normal.
The following example shows how to perform a Wilcoxon Signed-Rank Test in SAS.
<h3>Example: Wilcoxon Signed-Rank Test in SAS</h3>
Suppose an engineer want to know if a new fuel treatment leads to a change in the average miles per gallon of a certain car. To test this, he measures the mpg of 12 cars with and without the fuel treatment.
The results are shown in the table below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/wilcox11.jpg"280">
We can use the following code to perform a Wilcoxon Signed-Rank test in SAS to determine if there is a significant difference in the mean mpg between the two groups:
<b>/*create dataset*/
data my_data;
    input car with_fuel without_fuel;
    datalines;
1 20 24
2 23 25
3 21 21
4 25 22
5 18 23
6 17 18
7 18 17
8 24 28
9 20 24
10 24 27
11 23 21
12 19 23
;
run;
/*create new dataset with difference between two fuel treatments*/
data my_data2;
    set my_data;
    diff=with_fuel-without_fuel;
run;
/*perform Wilcoxon Signed Rank Test*/
proc univariate data=my_data2;
    var diff;
run;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/wilcoxSAS1.jpg"368">
From the output we can see that the mean difference in mpg between the cars that received the treatment and those that didn’t is <b>-1.75</b>.
In the table titled <b>Tests for Location</b> we can observe the following:
The Wilcoxon Signed-Rank Test statistic: <b>-22.5</b>
The corresponding p-value:<b> 0.0469</b>
Recall that the Wilcoxon Signed-Rank Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>The mpg is equal between the two groups
<b>H<sub>A</sub>: </b>The mpg is <em>not </em>equal between the two groups
Since the  p-value  of the test (.0469) is less than .05, we reject the null hypothesis.
This means we have sufficient evidence to say that the mean mpg is not equal between the two groups.
<h2><span class="orange">How to Conduct a Wilcoxon Signed-Rank Test in Python</span></h2>
The  Wilcoxon Signed-Rank Test  is the non-parametric version of the  paired samples t-test .
It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be normal.
This tutorial explains how to conduct a Wilcoxon Signed-Rank Test in Python.
<h3>Example: Wilcoxon Signed-Rank Test in Python</h3>
Researchers want to know if a new fuel treatment leads to a change in the average mpg of a certain car. To test this, they measure the mpg of 12 cars with and without the fuel treatment.
Use the following steps to perform a Wilcoxon Signed-Rank Test in Python to determine if there is a difference in the mean mpg between the two groups.
<b>Step 1: Create the data.</b>
First, we’ll create two arrays to hold the mpg values for each group of cars:
<b>group1 = [20, 23, 21, 25, 18, 17, 18, 24, 20, 24, 23, 19]
group2 = [24, 25, 21, 22, 23, 18, 17, 28, 24, 27, 21, 23]</b>
<b>Step 2: Conduct a Wilcoxon Signed-Rank Test.</b>
Next, we’ll use the  wilcoxon() function  from the scipy.stats library to conduct a Wilcoxon Signed-Rank Test, which uses the following syntax:
<b>wilcoxon(x, y, alternative=’two-sided’)</b>
where:
<b>x: </b>an array of sample observations from group 1
<b>y: </b>an array of sample observations from group 2
<b>alternative: </b>defines the alternative hypothesis. Default is ‘two-sided’ but other options include ‘less’ and ‘greater.’
Here’s how to use this function in our specific example:
<b>import scipy.stats as stats
#perform the Wilcoxon-Signed Rank Test
stats.wilcoxon(group1, group2)
(statistic=10.5, pvalue=0.044)
</b>
The test statistic is <b>10.5 </b>and the corresponding two-sided p-value is <b>0.044</b>.
<b>Step 3: Interpret the results.</b>
In this example, the Wilcoxon Signed-Rank Test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: </b>The mpg is equal between the two groups
<b>H<sub>A</sub>: </b>The mpg is <em>not </em>equal between the two groups
Since the p-value (<b>0.044</b>) is less than 0.05, we reject the null hypothesis. We have sufficient evidence to say that the true mean mpg is not equal between the two groups.
<h2><span class="orange">How to Perform the Wilcoxon Signed-Rank Test in R</span></h2>
The  Wilcoxon Signed-Rank Test  is the non-parametric version of  the paired t-test . It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be normal.
This tutorial explains how to conduct a Wilcoxon Signed-Rank Test in R.
<h3>Example: Wilcoxon Signed-Rank Test in R</h3>
Suppose a basketball coach want to know if a certain training program increases the number of free throws made by his players. To test this, he has 15 players shoot 20 free throws each before and after the training program.
Since each player can be “paired” with themselves, the coach had planned on using a paired t-test to determine if there was a significant difference between the mean number of free throws made before and after the training program. However, the distribution of the differences turns out to be non-normal, so the coach instead uses a Wilcoxon Signed-Rank Test.
The following table shows the number of free throws made (out of 20 attempts) by each of the 15 players, both before and after the training program:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox1-1.png"(max-width: 243px) 100vw, 243px">
To perform the Wilcoxon Signed-Rank Test on this data in R, we can use the <b>wilcox.test() </b>function, which uses the following syntax:
<b>wilcox.test(x, y, paired=TRUE)</b>
where:
<li data-slot-rendered-dynamic="true"><b>x, y: </b>two vectors of data values
<li data-slot-rendered-dynamic="true"><b>paired: </b>setting this to <b>TRUE </b>tells R that our two vectors contained paired data
The following code illustrates how to use this function to perform the Wilcoxon Signed-Rank Test on this data:
<b>#create the two vectors of data
before &lt;- c(14, 17, 12, 15, 15, 9, 12, 13, 13, 15, 19, 17, 14, 14, 16)
after &lt;- c(15, 17, 15, 15, 17, 14, 9, 14, 11, 16, 18, 20, 20, 10, 17)
#perform Wilcoxon Signed-Rank Test
wilcox.test(before, after, paired=TRUE)
Wilcoxon signed rank test with continuity correction
data:  before and after
V = 29.5, p-value = 0.275
alternative hypothesis: true location shift is not equal to 0</b>
The test statistic is <b>29.5 </b>and the corresponding p-value is <b>0.275</b>. Since this p-value is not less than 0.05, we fail to reject the null hypothesis. There is not a statistically significant difference in the number of free throws before and after players participate in the training program.
By default, this function performs a two-sided Wilcoxon Signed-Rank Test but you can specify a left-tailed test or right-tailed test by using the <b>alternative </b>argument:
<b>#perform left-tailed Wilcoxon Signed-Rank Test
wilcox.test(before, after, paired=TRUE, alternative="less")
Wilcoxon signed rank test with continuity correction
data:  before and after
V = 29.5, p-value = 0.1375
alternative hypothesis: true location shift is less than 0
#perform right-tailed Wilcoxon Signed-Rank Test
wilcox.test(before, after, paired=TRUE, alternative="greater")
Wilcoxon signed rank test with continuity correction
data:  before and after
V = 29.5, p-value = 0.8774
alternative hypothesis: true location shift is greater than 0
</b>
<h2><span class="orange">How to Perform a Wilcoxon Signed Rank Test in SPSS</span></h2>
The  Wilcoxon Signed Rank Test  is the non-parametric version of the  paired samples t-test . It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be normal.
This tutorial explains how to conduct a Wilcoxon Signed Rank Test in SPSS.
<h3>How to Perform a Wilcoxon Signed Rank Test in SPSS</h3>
Researchers want to know if a new fuel treatment leads to a change in the average mpg of a certain car. To test this, they conduct an experiment in which they measure the mpg of 12 cars with and without the fuel treatment.
The following screenshot shows the mpg for each car with (mpg1) and without (mpg2) fuel treatment:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/pairedSPSS1.png">
Use the following steps to perform a Wilcoxon Signed Rank Test to determine if there is a difference in the mean mpg between the two groups.
<b>Step 1: Choose the 2 Related Samples option.</b>
Click the <b>Analyze </b>tab, then <b>Nonparametric Tests</b>, then <b>Legacy Dialogs</b>, then <b>2 Related Samples</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/wilcoxSPSS1-1.png">
 
<b>Step 2: Fill in the necessary values to perform the test.</b>
Drag <b>mpg1 </b>into the box under Variable1 and drag <b>mpg2 </b>into the box under Variable2. Make sure the box next to <b>Wilcoxon </b>is checked. Then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/wilcoxSPSS2.png">
<b>Step 3: Interpret the results.</b>
Once you click <b>OK</b>, the results of the Wilcoxon Signed Rank Test will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/05/wilcoxSPSS3.png">
The first table displays the sum of the positive and negative ranks for the test. Check out  this tutorial  if you want to know how these ranks are calculated.
The second table displays the test statistic and the corresponding two-tailed p-value, which we can see are:
<li data-slot-rendered-dynamic="true"><b>Z test statistic: </b>-2.013
<li data-slot-rendered-dynamic="true"><b>Two-tailed p-value:</b> .044
Since the p-value is less than .05, we can reject the null hypothesis. We have sufficient evidence to conclude that the fuel treatment had a statistically significant effect on the mpg of cars.
<b>Step 4: Report the results.</b>
Lastly, we want to report the results of the Wilcoxon Signed Rank Test. Here is an example of how to do so:
A Wilcoxon Signed Rank Test was performed to determine if there was a statistically significant difference in the mean mpg before and after a car received fuel treatment. A total of 12 cars were used in the analysis.
 
The test revealed that there was a statistically significant difference in mean mpg between the two groups (z = -2.013, p = 0.044).
 
These results indicate that the fuel treatment had a significant effect on the mpg of a car.
<h2><span class="orange">How to Perform a Wilcoxon Signed Rank Test in Stata</span></h2>
The  Wilcoxon Signed Rank Test  is the non-parametric version of  the paired t-test . It is used to test whether or not there is a significant difference between two population means when the distribution of the differences between the two samples cannot be assumed to be normal.
This tutorial explains how to conduct a Wilcoxon Signed Rank Test in Stata.
<h3>How to Perform a Wilcoxon Signed Rank Test in Stata</h3>
For this example we will use the <em>fuel </em>dataset, which contains the mpg of 12 cars both before and after they received a certain fuel treatment.
Use the following steps to perform a Wilcoxon Signed Rank Test to determine if there is a difference in the mean mpg between the two groups.
<b>Step 1: Load and view the data.</b>
First, load the dataset by typing the following command into the Command box:
<b>use http://www.stata-press.com/data/r13/fuel</b>
View the raw data by using the following command:
<b>list</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wilcoxStata1.png">
The first column, <em>mpg1</em>, shows the mpg of each car before the fuel treatment while the second column, <em>mpg2</em>, shows the mpg of each car after the fuel treatment.
<b>Step 2: Perform the Wilcoxon Signed Rank Test.</b>
We can use the <b>signrank </b>command to perform a Wilcoxon Signed Rank Test in Stata:
<b>signrank mpg1 = mpg2</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/03/wilcoxStata2.png">
Here is how to interpret the output:
<b>Summary table: </b>The summary table tells us that there were three comparisons for which mpg1 was greater than mpg2, eight comparisons where mpg1 was less than mpg2, and one comparison where the two were equal.
<b>Hypothesis test: </b>Near the bottom of the output we can see that the null hypothesis we tested was Ho: mpg1 = mpg2. The z test statistic turned out to be -1.973 and the corresponding p-value was 0.0485. Since this value is less than 0.05, we reject the null hypothesis and conclude that there is a statistically significant difference between the mean mpg of the two groups.
<b>Step 3: Report the results.</b>
Lastly, we want to report the results of the Wilcoxon Signed Rank Test. Here is an example of how to do so:
A Wilcoxon Signed Rank Test was performed to determine if there was a statistically significant difference in the mean mpg before and after a car received fuel treatment. A total of 12 cars were used in the analysis.
 
The test revealed that there was a statistically significant difference in mean mpg between the two groups (z = -1.973, p = 0.0485).
 
These results indicate that the fuel treatment had a significant effect on the mpg of a car.
<h2><span class="orange">How to Perform the Wilcoxon Signed Rank Test</span></h2>
The <b>Wilcoxon Signed Rank Test </b>is the non-parametric version of  the paired t-test . It is used to test whether or not there is a significant difference between two population means.
<h2>When to Use the Wilcoxon Signed Rank Test</h2>
Use the Wilcoxon Signed Rank test when you would like to use the paired t-test but the distribution of the differences between the pairs is severely  non-normally distributed .
The easiest way to determine if the differences are non-normally distributed is to create a histogram of the differences and see if they follow a somewhat normal, “bell-shaped” distribution.
Keep in mind that the paired t-test is fairly robust to departures from normality, so the deviation from a normal distribution needs to be pretty severe to justify the use of the Wilcoxon Signed Rank test.
<h2>How to Perform the Wilcoxon Signed Rank Test</h2>
The following example illustrates how to perform the Wilcoxon Signed Rank test.
A basketball coach want to know if a certain training program increases the number of free throws made by his players. To test this, he has 15 players shoot 20 free throws each before and after the training program.
 
Since each player can be “paired” with themselves, the coach had planned on using a paired t-test to determine if there was a significant difference between the mean number of free throws made before and after the training program.
 
However, the distribution of the differences turns out to be non-normal, so the coach instead uses a Wilcoxon Signed Rank Test.
The following table shows the number of free throws made (out of 20 attempts) by each of the 15 players, both before and after the training program:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox1-1.png">
<b>Step 1: State the null and alternative hypotheses.</b>
H<sub>0</sub>: The median difference between the two groups is zero.
H<sub>A</sub>: The median difference is negative. (e.g. the players make less free throws before participating in the training program)
<b>Step 2: Find the difference and absolute difference for each pair.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox2.png">
<b>Step 3: Order the pairs by the absolute differences and assign a rank from the smallest to largest absolute differences. <em>Ignore pairs that have an absolute difference of “0” and assign mean ranks when there are ties.</em></b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox3.png">
<b>Step 4: Find the sum of the positive ranks and the negative ranks.</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox7-1.png">
<b>Step 5: Reject or fail to reject the null hypothesis.</b>
The test statistic, W, is the smaller of the absolute values of the positive ranks and negative ranks. In this case, the smaller value is 29.5. Thus, our test statistic is W = <b>29.5</b>.
To determine if we should reject or fail to reject the null hypothesis, we can reference the critical value found in the  Wilcoxon Signed Rank Test Critical Values Table  that corresponds with <em>n</em> and our chosen alpha level.
If our test statistic, W, is <em>less than or equal </em>to the critical value in the table, we can reject the null hypothesis. Otherwise, we fail to reject the null hypothesis.
The critical value that corresponds to an alpha level of 0.05 and n = 13 (the total number of pairs minus the two we didn’t calculate ranks for since they had an observed difference of 0) is <b>17</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/wilcox6.png">
Since our test statistic (W = 29.5) is not less than or equal to 17, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the training program leads to a significant increase in the number of free throws made by the players.
<em><b>Note: </b>Use the  Wilcoxon Signed-Rank Test Calculator  if you wish to perform the test using a calculator instead of by hand.</em>
<h2><span class="orange">How to Winsorize Data in Excel</span></h2>
To <b>winsorize</b> data means to set extreme outliers equal to a specified percentile of the data.
For example, a 90% winsorization sets all  observations  greater than the 95th percentile equal to the value at the 95th percentile and all observations less than the 5th percentile equal to the value at the 5th percentile.
This tutorial provides a step-by-step example of how to winsorize a dataset in Excel.
<h3>Step 1: Create the Data</h3>
First, we’ll create the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/winsorize1.png">
<h3>Step 2: Calculate the Upper and Lower Percentiles</h3>
For this example, we’ll perform a 90% winsorization. This means we’ll set all values greater than the 95th percentile equal to the 95th percentile and all values less than the 5th percentile equal to the 5th percentile.
The following formulas show how to find the 5th and 95th percentiles:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/winsorize2.png">
The 5th percentile turns out to be <b>12.35</b> and the 95th percentile turns out to be <b>92.05</b>.
<h3>Step 3: Winsorize the Data</h3>
Lastly, we’ll use the following formula to winsorize the data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/winsorize3.png">
Note that we just copy and pasted the formula in cell F2 down to the remaining cells in column F.
In this case, the value <b>3</b> became changed to <b>12.35</b> and the value <b>98</b> became changed to <b>92.05</b>.
Note that in this example we performed a 90% winsorization, but it’s possible to also perform an 80% winsorization, 95% winsorization, 99% winsorization, etc. by simply calculating different upper and lower percentiles.
<h2><span class="orange">How to Winsorize Data: Definition & Examples</span></h2>
To <b>winsorize</b> data means to set extreme outliers equal to a specified percentile of the data.
For example, a 90% winsorization sets all  observations  greater than the 95th percentile equal to the value at the 95th percentile and all observations less than the 5th percentile equal to the value at the 5th percentile.
In effect, to winsorize data means to change extreme values in a dataset to less extreme values.
<h3>Example: How to Winsorize Data</h3>
Suppose we have the following dataset:
<b>3, 14, 16, 16, 17, 29, 34, 36, 39, 47, 59, 64, 65, 66, 68, 79, 91, 98
</b>
To perform a 90% winsorization on this dataset, we would first find the 5th percentile and the 95th percentile, which turn out to be:
<b>5th percentile:</b> 12.35
<b>95th percentile:</b> 92.05
We would then set any values below 12.35 equal to 12.35 and any values above 92.05 equal to 92.05:
<b>12.35, 14, 16, 16, 17, 29, 34, 36, 39, 47, 59, 64, 65, 66, 68, 79, 91, 92.05</b>
In this case, the value <b>3</b> became changed to <b>12.35</b> and the value <b>98</b> became changed to <b>92.05</b>.
<h3>Why Winsorize Data?</h3>
The mean and the standard deviation are two common ways to measure the  location of the center  of a dataset and  the spread of observations  in a dataset, respectively.
However, these two metrics can both be influenced by extreme outliers. Thus, winsorizing data allows us to set extreme outliers equal to less extreme values.
This often allows us to get a more accurate view of the mean and the standard deviation of the dataset.
<h3>Trimming vs. Winsorizing</h3>
Another common way to deal with outliers is to <b>trim</b> them from the dataset, which means to remove them entirely.
For example, consider the dataset from earlier:
<b>3, 14, 16, 16, 17, 29, 34, 36, 39, 47, 59, 64, 65, 66, 68, 79, 91, 98</b>
If we wanted to trim the values that fall below the 5th percentile or above the 95th percentile, we would simple remove the values <b>3</b> and <b>98</b>.
Here are a couple rules of thumb for when to use trimming vs winsorizing:
<b>Trimming:</b> It makes sense to trim data values when some values seem completely unreasonable, i.e. they’re a result of a data entry error.
<b>Winsorizing:</b> It makes sense to winsorize data when we want to retain the observations that are at the extremes but we don’t want to take them too literally.
<h3>Cautions on Winsorizing Data</h3>
Here are a few things to keep in mind when deciding to winsorize data:
<b>1. </b>If there aren’t extreme outliers, then winsorizing the data will only modify the smallest and largest values slightly. This is generally not a good idea since it means we’re just modifying data values for the sake of modifications.
<b>2. </b>Outliers can represent interesting edge cases in the data. Thus, before modifying outliers it’s a good idea to take a closer look at them to see what could have caused them.
<b>3.</b> You should decide whether or not to winsorize data <em>after</em> collecting the data, not before. You should see if there actually are extreme outliers before you decide to perform winsorization. If no extreme outliers are present, winsorization may be unnecessary.
<h3>Tutorial: Winsorize Data in Excel</h3>
Refer to  this tutorial  for a step-by-step example of how to winsorize a dataset in Excel.
<h2><span class="orange">How to Use “with” in Python to Open Files (Including Examples)</span></h2>
You can use the following syntax to open a file in Python, do something with it, and then close the file:
<b>file = open('my_data.csv')
df = file.read()
print(df)
file.close()</b>
The problem with this approach is that it’s very easy to forget to close the file.
A better approach is to use <b>with open</b>, which uses the following basic syntax:
<b>with open('my_data.csv') as file:
   df = file.read()
   print(df)
</b>
Using this approach, the file that you’re working with is automatically closed so that you don’t have to remember to use <b>file.close()</b>.
The following examples show how to use <b>with open</b> in different scenarios.
<h3>Example 1: Use With Statement to Read File</h3>
The following code shows how to use the “with” statement to read a file into Python and print the contents of the file:
<b>with open('my_data.csv') as file:
   df = file.read()
   print(df)
,points,assists,rebounds
0,11,5,6
1,17,7,8
2,16,7,8
3,18,9,10
4,22,12,14
5,25,9,12
6,26,9,12
7,24,4,10
8,29,8,11
</b>
The contents of the file are printed and the file is automatically closed without us typing <b>file.close()</b>.
<h3>Example 2: Use With Statement to Write File</h3>
The following code shows how to use the “with” statement to write some text out to a file:
<b>with open('data_out.csv', 'w') as file:
    file.write('Some text to write to CSV file')
</b>
Note that the ‘<b>w</b>‘ within the <b>open()</b> statement tells Python to use ‘write’ mode with the file as opposed to read mode.
<h3>Example 3: Use With Statement to Read & Write Files</h3>
We can also open several files at once within a single “with” statement.
The following code shows how to use the “with” statement to open two files, read the contents of one file, and then write the contents of the first file out to the second file:
<b>with open('my_data.csv', 'r') as infile, open('data_out.csv', 'w') as outfile:
    for line in infile:
        outfile.write(line)</b>
If we navigate to the location where we wrote ‘data_out.csv’ then we can view the contents of the file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/with1.png">
Note that we can use the<b> open()</b> function to open as many files as we’d like within a single “with” statement.
<h2><span class="orange">Within-Group vs. Between Group Variation in ANOVA</span></h2>
A  one-way ANOVA  is used to determine whether or not the means of three or more independent groups are equal.
A one-way ANOVA uses the following null and alternative  hypotheses :
<b>H<sub>0</sub>:</b> All group means are equal.
<b>H<sub>A</sub>:</b> At least one group mean is different from the rest.
Whenever you perform a one-way ANOVA, you will end up with a summary table that looks like the following:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/variation1.png">
We can see that there are two different sources of variation that an ANOVA measures:
<b>Between Group Variation</b>: The total variation between each group mean and the overall mean.
<b>Within-Group Variation</b>: The total variation in the individual values in each group and their group mean.
If the Between group variation is high relative to the Within-group variation, then the F-statistic of the ANOVA will be higher and the corresponding p-value will be lower, which makes it more likely that we’ll reject the null hypothesis that the group means are equal.
The following example shows how to calculate the Between group variation and Within-group variation for a one-way ANOVA in practice.
<h3>Example: Calculating Within-Group and Between Group Variation in ANOVA</h3>
Suppose we want to determine if three different studying methods lead to different mean exam scores. To test this, we recruit 30 students and  randomly assign  10 each to use a different studying method.
The exam scores for the students in each group are shown below:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/variation2.png">
We can use the following formula to calculate the <b>between group variation</b>:
<b>Between Group Variation</b> = Σn<sub>j</sub>(X<sub>j</sub> – X..)<sup>2</sup> 
where:
<b>n<sub>j</sub></b>: the sample size of group j
<b>Σ</b>: a symbol that means “sum”
<b>X<sub>j</sub></b>: the mean of group j
<b>X..</b>: the overall mean
To calculate this value, we’ll first calculate each group mean and the overall mean:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/variation3.png">
Then we calculate the between group variation to be: 10(80.5-83.1)<sup>2</sup> + 10(82.1-83.1)<sup>2</sup> + 10(86.7-83.1)<sup>2</sup> = <b>207.2</b>.
Next, we can use the following formula to calculate the <b>within group variation</b>:
<b>Within Group Variation</b>: Σ(X<sub>ij</sub> – X<sub>j</sub>)<sup>2</sup> 
where:
<b>Σ</b>: a symbol that means “sum”
<b>X<sub>ij</sub></b>: the i<sup>th</sup> observation in group j
<b>X<sub>j</sub></b>: the mean of group j
In our example, we calculate within group variation to be:
<b>Group 1: </b>(75-80.5)<sup>2</sup> + (77-80.5)<sup>2 </sup>+<b> </b>(78-80.5)<sup>2 </sup>+<b> </b>(78-80.5)<sup>2 </sup>+<b> </b>(79-80.5)<sup>2 </sup>+<b> </b>(81-80.5)<sup>2 </sup>+<b> </b>(81-80.5)<sup>2 </sup>+ <b> </b>(83-80.5)<sup>2 </sup>+<b> </b>(86-80.5)<sup>2 </sup>+<b> </b>(87-80.5)<sup>2 </sup>= <b>136.5</b>
<b>Group 2: </b>(78-82.1)<sup>2</sup> + (78-82.1)<sup>2 </sup>+<b> </b>(79-82.1)<sup>2 </sup>+<b> </b>(81-82.1)<sup>2 </sup>+<b> </b>(81-82.1)<sup>2 </sup>+<b> </b>(82-82.1)<sup>2 </sup>+<b> </b>(83-82.1)<sup>2 </sup>+ <b> </b>(85-82.1)<sup>2 </sup>+<b> </b>(86-82.1)<sup>2 </sup>+<b> </b>(88-82.1)<sup>2 </sup>= <b>104.9</b>
<b>Group 3: </b>(82-86.7)<sup>2</sup> + (82-86.7)<sup>2 </sup>+<b> </b>(84-86.7)<sup>2 </sup>+<b> </b>(86-86.7)<sup>2 </sup>+<b> </b>(86-86.7)<sup>2 </sup>+<b> </b>(87-86.7)<sup>2 </sup>+<b> </b>(87-86.7)<sup>2 </sup>+ <b> </b>(89-86.7)<sup>2 </sup>+<b> </b>(90-86.7)<sup>2 </sup>+<b> </b>(94-86.7)<sup>2 </sup>= <b>122.1</b>
<b>Within Group Variation: </b>136.5 + 104.9 + 122.1 = <b>363.5</b>
If we use statistical software to perform a one-way ANOVA using this dataset, we’ll end up with the following ANOVA table:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/12/variation4.png">
Notice that the between group and within-group variation values match the ones we calculated by hand.
The overall F-statistic in the table is a way to quantify the ratio of the between group variation compared to the within group variation.
The larger the F-statistic, the greater the variation between group means relative to the variation within the groups.
Thus, the larger the F-statistic, the greater the evidence that there is a difference between the group means.
We can see in this example that the p-value that corresponds to an F-statistic of 7.6952 is <b>.0023</b>.
Since this value is less than α = .05, we reject the null hypothesis of the ANOVA and conclude that the three studying techniques do not lead to the same exam score.
<h2><span class="orange">How to Calculate WMAPE in R (With Example)</span></h2>
One of the most common metrics used to measure the forecasting accuracy of a model is <b>WMAPE</b>, which stands for <b>weighted mean absolute percentage error</b>.
The formula to calculate WMAPE is as follows:
<b>WMAPE</b> = ( Σ|y<sub>i</sub>– <U+0177><sub>i</sub>|*w<sub>i</sub> ) / ( Σy<sub>i</sub>*w<sub>i</sub> ) * 100
where:
<b>Σ</b> – a symbol that means “sum”
<b>y<sub>i</sub></b> – The actual value of the i<sup>th</sup> observation
<b><U+0177><sub>i</sub></b> – The predicted value of the i<sup>th</sup> observation 
<b>w<sub>i</sub></b> – The weight for the i<sup>th</sup> observation
We can define the following function to calculate WMAPE in R:
<b>find_WMAPE &lt;- function(y, yhat, w){
  return(sum(abs(y-yhat)*w)/sum(y*w)*100)
}
</b>
The following example shows how to use this function in practice.
<h2>Example: Calculating WMAPE in R</h2>
Suppose we have the following data frame in R that contains information about the actual sales and predicted sales for some retail store:
<b>#create dataset
data &lt;- data.frame(actual=c(23, 37, 44, 47, 48, 48, 46, 43, 32, 27, 26, 24),   forecast=c(37, 40, 46, 44, 46, 50, 45, 44, 34, 30, 22, 23))
#view dataset
data
   actual forecast
1      23       37
2      37       40
3      44       46
4      47       44
5      48       46
6      48       50
7      46       45
8      43       44
9      32       34
10     27       30
11     26       22
12     24       23
</b>
To compute the WMAPE for the difference in actual vs. forecasted sales, we can define a vector of weights to be used and then use the WMAPE function we defined earlier:
<b>#define function to calculate WMAPE
find_WMAPE &lt;- function(y, yhat, w){
  return(sum(abs(y-yhat)*w)/sum(y*w)*100)
}
#define weights for each month
weights &lt;- c(20, 20, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)
#calculate WMAPE
find_WMAPE(df$actual, df$predicted, weights)
[1] 13.27635
</b>
The WMAPE for this model turns out to be <b>13.27635%</b>.
That is, the weighted mean absolute percentage error between the forecasted sales values and actual sales values is 13.27635%.
Note that we gave significantly larger weights to the values for January and February in this example.
Depending on your particular problem, you may give larger or smaller weights to different observations depending on the importance of each error in your model.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Calculate MAPE in R 
 How to Calculate SMAPE in R 
 How to Calculate RMSE in R 
<h2><span class="orange">A Guide to dt, qt, pt, & rt in R</span></h2>
The <b>Student t distribution</b> is one of the most commonly used distribution in statistics. This tutorial explains how to work with the Student t distribution in R using the functions <b>dt()</b>, <b>qt()</b>, <b>pt()</b>, and <b>rt()</b>.
<h2>dt</h2>
The function <b>dt </b>returns the value of the probability density function (pdf) of the Student t distribution given a certain random variable <em>x </em>and degrees of freedom <em>df</em>. The syntax for using dt is as follows:
<b>dt(x, df) </b>
The following code illustrates a few examples of <b>dt </b>in action:
<b>#find the value of the Student t distribution pdf at x = 0 with 20 degrees of freedom
dt(x = 0, df = 20)
#[1] 0.3939886
#by default, R assumes the first argument is <em>x </em>and the second argument is <em>df</em>
dt(0, 20)
#[1] 0.3939886
#find the value of the Student t distribution pdf at x = 1 with 30 degrees of freedom
dt(1, 30)
#[1] 0.2379933
</b>
Typically when you’re trying to solve questions about probability using the Student t distribution, you’ll often use <b>pt </b>instead of <b>dt</b>. One useful application of <b>dt</b>, however, is in creating a Student t distribution plot in R. The following code illustrates how to do so:
<b>#Create a sequence of 100 equally spaced numbers between -4 and 4
x &lt;- seq(-4, 4, length=100)
#create a vector of values that shows the height of the probability distribution
#for each value in x, using 20 degrees of freedom
y &lt;- dt(x = x, df = 20)
#plot x and y as a scatterplot with connected lines (type = "l") and add
#an x-axis with custom labels
plot(x,y, type = "l", lwd = 2, axes = FALSE, xlab = "", ylab = "")
axis(1, at = -3:3, labels = c("-3s", "-2s", "-1s", "mean", "1s", "2s", "3s"))</b>
This generates the following plot:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/tDist1.jpg">
<h2>pt</h2>
The function <b>pt </b>returns the value of the cumulative density function (cdf) of the Student t distribution given a certain random variable <em>x </em>and degrees of freedom <em>df</em>. The syntax for using pnorm is as follows:
<b>pt(x, df) </b>
Put simply, <b>pt </b>returns the area to the left of a given value <em>x </em>in the Student t distribution. If you’re interested in the area to the right of a given value <em>x</em>, you can simply add the argument <b>lower.tail = FALSE</b>
<b>pt(x, df, lower.tail = FALSE) </b>
The following examples illustrates how to solve some probability questions using pt.
<b>Example 1:</b><em> Find the area to the <b>left</b> of a t-statistic with value of -0.785 and 14 degrees of freedom.</em>
<b>pt(-0.785, 14)
#[1] 0.2227675
</b>
<b>Example 2:</b><em>  Find the area to the <b>right</b> of a t-statistic with value of -0.785 and 14 degrees of freedom.</em>
<b>#the following approaches produce equivalent results
#1 - area to the left
1 - pt(-0.785, 14)
#[1] 0.7772325
#area to the right
pt(-0.785, 14, lower.tail = FALSE)
#[1] 0.7772325 
</b>
<b>Example 3:</b><em>  Find the total area in a Student t distribution with 14 degrees of freedom that lies to the left of -0.785 or to the right of 0.785.</em>
<b>pt(-0.785, 14) + pt(0.785, 14, lower.tail = FALSE)
#[1] 0.4455351</b>
<h2>qt</h2>
The function <b>qt </b>returns the value of the inverse cumulative density function (cdf) of the Student t distribution given a certain random variable <em>x </em>and degrees of freedom <em>df. </em>The syntax for using qt is as follows:
<b>qt(x, df) </b>
Put simply, you can use <b>qt </b>to find out what the t-score is of the p<sup>th</sup> quantile of the Student t distribution.
The following code illustrates a few examples of <b>qt </b>in action:
<b>#find the t-score of the 99th quantile of the Student t distribution with df = 20
qt(.99, df = 20)
# [1] [1] 2.527977
#find the t-score of the 95th quantile of the Student t distribution with df = 20
qt(.95, df = 20)
# [1] 1.724718
#find the t-score of the 90th quantile of the Student t distribution with df = 20
qt(.9, df = 20)
# [1] 1.325341
</b>
Note that the critical values found by <b>qt </b>will match the critical values found in the  t-Distribution table  as well as the critical values that can be found by the  Inverse t-Distribution Calculator .
<h2>rt</h2>
The function <b>rt </b>generates a vector of random variables that follow a Student t distribution given a vector length <em>n </em>and degrees of freedom <em>df</em>. The syntax for using rt is as follows:
<b>rt(n, df) </b>
The following code illustrates a few examples of <b>rt </b>in action:
<b>#generate a vector of 5 random variables that follow a Student t distribution
#with df = 20
rt(n = 5, df = 20)
#[1] -1.7422445  0.9560782  0.6635823  1.2122289 -0.7052825
#generate a vector of 1000 random variables that follow a Student t distribution
#with df = 40
narrowDistribution &lt;- rt(1000, 40)
#generate a vector of 1000 random variables that follow a Student t distribution
#with df = 5
wideDistribution &lt;- rt(1000, 5)
#generate two histograms to view these two distributions side by side, and specify
#50 bars in histogram,
par(mfrow=c(1, 2)) #one row, two columns
hist(narrowDistribution, breaks=50, xlim = c(-6, 4)) 
hist(wideDistribution, breaks=50, xlim = c(-6, 4))
</b>
This generates the following histograms:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/04/tDist2.jpg">
Notice how the wide distribution is more spread out compared to the narrow distribution. This is because we specified the degrees of freedom in the wide distribution to be 5 compared to 40  in the narrow distribution. The fewer degrees of freedom, the wider the Student t distribution will be.
<b>Further Reading:
 A Guide to dnorm, pnorm, qnorm, and rnorm in R 
 A Guide to dbinom, pbinom, qbinom, and rbinom in R 
</b>
<h2><span class="orange">How to Write Pandas DataFrames to Multiple Excel Sheets</span></h2>
Often you may have multiple pandas DataFrames that you’d like to write to multiple Excel sheets within the same workbook. 
Fortunately this is fairly to do using the pandas  ExcelWriter()  function. In order to use this function, you first need to make sure you have <b>xlsxwriter </b>installed:
<b>pip install xlsxwriter</b>
You also need to make sure you have <b>xlwt </b>installed:
<b>pip install xlwt</b>
Once those are installed, you can easily write several pandas DataFrames to multiple Excel sheets:
<b>import pandas as pd
#create three DataFrames
df1 = pd.DataFrame({'dataset': ['A', 'B', 'C', 'D', 'E']})
df2 = pd.DataFrame({'dataset': [13, 15, 15, 17, 22, 24, 29, 30]})
df3 = pd.DataFrame({'dataset': [3, 6, 6]})
#create a Pandas Excel writer using XlsxWriter as the engine
writer = pd.ExcelWriter('dataframes.xlsx', engine='xlsxwriter')
#write each DataFrame to a specific sheet
df1.to_excel(writer, sheet_name='first dataset')
df2.to_excel(writer, sheet_name='second dataset')
df3.to_excel(writer, sheet_name='third dataset')
#close the Pandas Excel writer and output the Excel file
writer.save()</b>
The resulting Excel workbook will have each of the pandas DataFrames stored in a separate sheet:
<b>The first DataFrame:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/pdMultipleExcel1.png">
<b>The second DataFrame:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/pdMultipleExcel2.png">
<b>The third DataFrame:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/pdMultipleExcel3.png">
<h2><span class="orange">How to Use write.table in R (With Examples)</span></h2>
You can use the <b>write.table</b> function in R to export a data frame or matrix to a file.
This function uses the following basic syntax:
<b>write.table(df, file='C:\\Users\\bob\\Desktop\\data.txt')
</b>
By default, the values in the exported file are separated by a single space but you can use the <b>sep</b> argument to specify a different delimiter.
For example, you could choose to use a comma as a delimiter:
<b>write.table(df, file='C:\\Users\\bob\\Desktop\\data.txt', sep=',')</b>
The following step-by-step example shows how to use this function in practice.
<b>Related: </b> How to Use read.table in R 
<h3>Step 1: Create a Data Frame</h3>
First, let’s create a data frame in R:
<b>#create data frame
df &lt;- data.frame(var1=c(1, 3, 3, 4, 5), var2=c(7, 7, 8, 3, 2), var3=c(3, 3, 6, 6, 8), var4=c(1, 1, 2, 8, 9))
#view data frame
df
  var1 var2 var3 var4
1    1    7    3    1
2    3    7    3    1
3    3    8    6    2
4    4    3    6    8
5    5    2    8    9
</b>
<h3>Step 2: Use write.table() to Export the Data Frame</h3>
Next, let’s use <b>write.table()</b> to export the data frame to a file called <b>data.txt</b> located on my Desktop:
<b>#export data frame to Desktop
write.table(df, file='C:\\Users\\bob\\Desktop\\data.txt')</b>
<h3>Step 3: View the Exported File</h3>
Next, I can navigate to my Desktop and open the file called <b>data.txt</b> to view the data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/write1-1.png">
Notice that the values in the file are separated by single spaces since we didn’t specify a different delimiter when we exported the data frame.
<h2><span class="orange">X-Bar (Sample Mean) Calculator</span></h2>
In statistics, <b>x-bar</b> (x) is a symbol used to represent the sample mean of a dataset.
To calculate x-bar for a given dataset, simply enter the list of the comma-separated values for the dataset in the box below, then click the “Calculate” button:
<b>Dataset values:</b>
<textarea id="x" rows="5" cols="40">1, 3, 3, 4, 8, 11, 13, 14, 15, 17, 22, 24, 26, 46</textarea>
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<b>X-Bar (Sample Mean): 14.78571</b>
<script>
function calc() {
//calculate sample mean
var x = document.getElementById('x').value.split(',').map(Number);
var mean = jStat.mean(x);
//output mean
document.getElementById('mean').innerHTML = mean.toFixed(5);
  
} //end calc function
</script>
<h2><span class="orange">How to Fix in R: ‘x’ must be numeric</span></h2>
One error you may encounter in R is:
<b>Error in hist.default(data) : 'x' must be numeric
</b>
This error occurs when you attempt to create a histogram for a variable that is not numeric.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a histogram for the following vector of data:
<b>#define vector
data &lt;- c('1.2', '1.4', '1.7', '1.9', '2.2', '2.5', '3', '3.4', '3.7', '4.1')
#attempt to create histogram to visualize distribution of values in vector
hist(data)
Error in hist.default(data) : 'x' must be numeric
</b>
We receive an error because <b>data</b> is currently not a numeric vector. We can confirm this by checking the class:
<b>#check class
class(data)
[1] "character"
</b>
Currently <b>data</b> is a character vector.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply use <b>as.numeric()</b> to convert our vector to numeric:
<b>#convert vector from character to numeric
data_numeric &lt;- as.numeric(data)
#create histogram
hist(data_numeric)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/histR1.png">
Notice that we don’t receive an error and we’re able to successfully create the histogram because our vector is now numeric.
We can verify this by checking the class:
<b>#check class
class(data_numeric)
[1] "numeric"
</b>
<h2><span class="orange">XGBoost in R: A Step-by-Step Example</span></h2>
 Boosting  is a technique in machine learning that has been shown to produce models with high predictive accuracy. 
One of the most common ways to implement boosting in practice is to use <b>XGBoost</b>, short for “extreme gradient boosting.”
This tutorial provides a step-by-step example of how to use XGBoost to fit a boosted model in R.
<h3>Step 1: Load the Necessary Packages</h3>
First, we’ll load the necessary libraries. 
<b>library(xgboost) #for fitting the xgboost model
library(caret)   #for general data preparation and model fitting
</b>
<h3>Step 2: Load the Data</h3>
For this example we’ll fit a boosted regression model to the <b>Boston</b> dataset from the <b>MASS</b> package.
This dataset contains 13 predictor variables that we’ll use to predict one  response variable  called <b>mdev</b>, which represents the median value of homes in different census tracts around Boston.
<b>#load the data
data = MASS::Boston
#view the structure of the data
str(data) 
'data.frame':506 obs. of  14 variables:
 $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
 $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
 $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
 $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
 $ rm     : num  6.58 6.42 7.18 7 7.15 ...
 $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
 $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
 $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
 $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
 $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
 $ black  : num  397 397 393 395 397 ...
 $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
 $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...
</b>
We can see that the dataset contains 506  observations  and 14 total variables.
<h3>Step 3: Prep the Data</h3>
Next, we’ll use the <b>createDataPartition()</b> function from the caret package to split the original dataset into a training and testing set.
For this example, we’ll choose to use 80% of the original dataset as part of the training set.
Note that the xgboost package also uses matrix data, so we’ll use the <b>data.matrix()</b> function to hold our predictor variables.
<b>#make this example reproducible
set.seed(0)
#split into training (80%) and testing set (20%)
parts = createDataPartition(data$medv, p = .8, list = F)
train = data[parts, ]
test = data[-parts, ]
#define predictor and response variables in training set
train_x = data.matrix(train[, -13])
train_y = train[,13]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -13])
test_y = test[, 13]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
</b>
<h3>Step 4: Fit the Model</h3>
Next, we’ll fit the XGBoost model by using the <b>xgb.train()</b> function, which displays the training and testing RMSE (root mean squared error) for each round of boosting. 
Note that we chose to use 70 rounds for this example, but for much larger datasets it’s not uncommon to use hundreds or even thousands of rounds. Just keep in mind that the more rounds, the longer the run time.
Also note that the <b>max.depth</b> argument specifies how deep to grow the individual decision trees. We typically choose this number to be quite low like 2 or 3 so that smaller trees are grown. It has been shown that this approach tends to produce more accurate models.
<b>#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#fit XGBoost model and display training and testing data at each round
model = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 70)
[1]train-rmse:10.167523test-rmse:10.839775 
[2]train-rmse:7.521903test-rmse:8.329679 
[3]train-rmse:5.702393test-rmse:6.691415 
[4]train-rmse:4.463687test-rmse:5.631310 
[5]train-rmse:3.666278test-rmse:4.878750 
[6]train-rmse:3.159799test-rmse:4.485698 
[7]train-rmse:2.855133test-rmse:4.230533 
[8]train-rmse:2.603367test-rmse:4.099881 
[9]train-rmse:2.445718test-rmse:4.084360 
[10]train-rmse:2.327318test-rmse:3.993562 
[11]train-rmse:2.267629test-rmse:3.944454 
[12]train-rmse:2.189527test-rmse:3.930808 
[13]train-rmse:2.119130test-rmse:3.865036 
[14]train-rmse:2.086450test-rmse:3.875088 
[15]train-rmse:2.038356test-rmse:3.881442 
[16]train-rmse:2.010995test-rmse:3.883322 
[17]train-rmse:1.949505test-rmse:3.844382 
[18]train-rmse:1.911711test-rmse:3.809830 
[19]train-rmse:1.888488test-rmse:3.809830 
[20]train-rmse:1.832443test-rmse:3.758502 
[21]train-rmse:1.816150test-rmse:3.770216 
[22]train-rmse:1.801369test-rmse:3.770474 
[23]train-rmse:1.788891test-rmse:3.766608 
[24]train-rmse:1.751795test-rmse:3.749583 
[25]train-rmse:1.713306test-rmse:3.720173 
[26]train-rmse:1.672227test-rmse:3.675086 
[27]train-rmse:1.648323test-rmse:3.675977 
[28]train-rmse:1.609927test-rmse:3.745338 
[29]train-rmse:1.594891test-rmse:3.756049 
[30]train-rmse:1.578573test-rmse:3.760104 
[31]train-rmse:1.559810test-rmse:3.727940 
[32]train-rmse:1.547852test-rmse:3.731702 
[33]train-rmse:1.534589test-rmse:3.729761 
[34]train-rmse:1.520566test-rmse:3.742681 
[35]train-rmse:1.495155test-rmse:3.732993 
[36]train-rmse:1.467939test-rmse:3.738329 
[37]train-rmse:1.446343test-rmse:3.713748 
[38]train-rmse:1.435368test-rmse:3.709469 
[39]train-rmse:1.401356test-rmse:3.710637 
[40]train-rmse:1.390318test-rmse:3.709461 
[41]train-rmse:1.372635test-rmse:3.708049 
[42]train-rmse:1.367977test-rmse:3.707429 
[43]train-rmse:1.359531test-rmse:3.711663 
[44]train-rmse:1.335347test-rmse:3.709101 
[45]train-rmse:1.331750test-rmse:3.712490 
[46]train-rmse:1.313087test-rmse:3.722981 
[47]train-rmse:1.284392test-rmse:3.712840 
[48]train-rmse:1.257714test-rmse:3.697482 
[49]train-rmse:1.248218test-rmse:3.700167 
[50]train-rmse:1.243377test-rmse:3.697914 
[51]train-rmse:1.231956test-rmse:3.695797 
[52]train-rmse:1.219341test-rmse:3.696277 
[53]train-rmse:1.207413test-rmse:3.691465 
[54]train-rmse:1.197197test-rmse:3.692108 
[55]train-rmse:1.171748test-rmse:3.683577 
[56]train-rmse:1.156332test-rmse:3.674458 
[57]train-rmse:1.147686test-rmse:3.686367 
[58]train-rmse:1.143572test-rmse:3.686375 
[59]train-rmse:1.129780test-rmse:3.679791 
[60]train-rmse:1.111257test-rmse:3.679022 
[61]train-rmse:1.093541test-rmse:3.699670 
[62]train-rmse:1.083934test-rmse:3.708187 
[63]train-rmse:1.067109test-rmse:3.712538 
[64]train-rmse:1.053887test-rmse:3.722480 
[65]train-rmse:1.042127test-rmse:3.720720 
[66]train-rmse:1.031617test-rmse:3.721224 
[67]train-rmse:1.016274test-rmse:3.699549 
[68]train-rmse:1.008184test-rmse:3.709522 
[69]train-rmse:0.999220test-rmse:3.708000 
[70]train-rmse:0.985907test-rmse:3.705192 
</b>
From the output we can see that the minimum testing RMSE is achieved at <b>56</b> rounds. Beyond this point, the test RMSE actually begins to increase, which is a sign that we’re  overfitting the training data .
Thus, we’ll define our final XGBoost model to use 56 rounds:
<b>#define final model
final = xgboost(data = xgb_train, max.depth = 3, nrounds = 56, verbose = 0)</b>
Note: The argument <b>verbose = 0</b> tells R not to display the training and testing error for each round.
<h3>Step 5: Use the Model to Make Predictions</h3>
Lastly, we can use the final boosted model to make predictions about the median house value of Boston homes in the testing set. 
We will then calculate the following accuracy measures for the model:
<b>MSE:</b> Mean Squared Error
<b>MAE:</b> Mean Absolute Error
<b>RMSE:</b> Root Mean Squared Error
<b>mean((test_y - pred_y)^2) #mse
caret::MAE(test_y, pred_y) #mae
caret::RMSE(test_y, pred_y) #rmse
[1] 13.50164
[1] 2.409426
[1] 3.674457 </b>
The root mean squared error turns out to be <b>3.674457</b>. This represents the average difference between the prediction made for the median house values and the actual observed house values in the test set.
If we want, we could compare this RMSE to other models like  multiple linear regression ,  ridge regression ,  principal components regression , etc. to see which model produces the most accurate predictions.
You can find the complete R code used in this example  here .
<h2><span class="orange">How to Use xlim() and ylim() in R</span></h2>
You can use the <b>xlim()</b> and <b>ylim()</b> functions to set the x-axis limits and y-axis limits of plots in R.
The following examples show how to use these functions in practice.
<h3>Example 1: Use xlim() to Set X-Axis Limits</h3>
The following code shows how to create a scatterplot in R and specify the x-axis limits using the <b>xlim()</b> function:
<b>#define data frame
df &lt;- data.frame(x=c(1, 3, 4, 5, 7, 9), y=c(7, 7, 8, 12, 15, 19))
#create scatterplot with x-axis limits ranging from 0 to 20
plot(df$x, df$y, pch=19, xlim=c(0, 20))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/xlim1.png">
<h3>Example 2: Use ylim() to Set Y-Axis Limits</h3>
The following code shows how to create a scatterplot in R and specify the y-axis limits using the <b>ylim()</b> function:
<b>#define data frame
df &lt;- data.frame(x=c(1, 3, 4, 5, 7, 9), y=c(7, 7, 8, 12, 15, 19))
#create scatterplot with y-axis limits ranging from 0 to 30
plot(df$x, df$y, pch=19, ylim=c(0, 30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/xlim2.png">
<h3>Example 3: Use xlim() & ylim() to Set Axis Limits</h3>
The following code shows how to create a scatterplot in R and specify both the x-axis limits and the y-axis limits:
<b>#define data frame
df &lt;- data.frame(x=c(1, 3, 4, 5, 7, 9), y=c(7, 7, 8, 12, 15, 19))
#create scatterplot and specify both x-axis limits and y-axis limits
plot(df$x, df$y, pch=19, xlim=c(0, 20), ylim=c(0, 30))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/07/xlim3.png">
<h2><span class="orange">How to Use XLOOKUP in Google Sheets (With Example)</span></h2>
The <b>XLOOKUP</b> function in Excel can be used to look up a value in a range and return some corresponding value.
For example, we can use the following <b>XLOOKUP</b> function in Excel to look up the value in <b>E2</b> in the range <b>A2:A11</b> and return the corresponding value in the range <b>C2:C11</b>:
<b>=XLOOKUP(E2, A2:A11, C2:C11)</b>
Here’s how to use this function in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/xlookup1.jpg"555">
The <b>XLOOKUP</b> function looks up the value “Rockets” in column A and returns the corresponding value in the “Points” column.
Unfortunately, Google Sheets doesn’t have an <b>XLOOKUP</b> function but you can easily replicate it by using the <b>FILTER</b> function instead.
You can use the following basic syntax to do so:
<b>=FILTER(C2:C11, A2:A11=E2)
</b>
The following screenshot shows how to use this function in practice with the same dataset in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/xlookup2.jpg">
Here’s how the <b>FILTER</b> function works:
The function looks at the range <b>C2:C11</b>.
The function then returns the value in the range <b>A2:A11</b> that is equal to the value in <b>E2</b>.
Notice that this function returns the exact same value as the <b>XLOOKUP</b> function in the previous example in Excel.
<h2><span class="orange">How to Use xtabs() in R to Calculate Frequencies</span></h2>
The <b>xtabs()</b> function in R allows you to quickly calculate frequencies for one or more variables.
It uses the following basic syntax:
<b>xtabs(~variable_name, data=data)</b>
where:
<b>variable_name: </b>The variable that you’d like to calculate the frequencies for.
<b>data: </b>The name of the data frame that the variable comes from.
This tutorial shows several examples of how to use this function in practice.
<h3>Example 1: Use xtabs() for One-Way Frequencies</h3>
The following code shows how to use <b>xtabs()</b> to calculate the frequencies for the variable <em>team</em>:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), times=c(27, 33, 40)), position=rep(c('Guard', 'Forward', 'Center'), times=c(20, 50, 30)), points=runif(100, 1, 50))
#view first six rows of data frame
head(df)
  team position   points
1    A    Guard 14.00992
2    A    Guard 19.23407
3    A    Guard 29.06981
4    A    Guard 45.50218
5    A    Guard 10.88241
6    A    Guard 45.02109
#calculate frequencies of <em>team </em>variable
xtabs(~team, data=df)
team
 A  B  C 
27 33 40 </b>
From the output we can see that:
Team A occurs <b>27 </b>times in the data frame.
Team A occurs <b>33  </b>times in the data frame.
Team A occurs <b>40 </b>times in the data frame.
<h3>Example 2: Use xtabs() for Two-Way Frequencies</h3>
The following code shows how to use <b>xtabs()</b> to calculate the two-way frequencies for the variables <em>team</em> and <em>position</em>:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), times=c(27, 33, 40)), position=rep(c('Guard', 'Forward', 'Center'), times=c(20, 50, 30)), points=runif(100, 1, 50))
#calculate frequencies of <em>team</em> and <em>position </em>variables
xtabs(~team+position, data=df)
    position
team Center Forward Guard
   A      0       7    20
   B      0      33     0
   C     30      10     0 </b>
From the output we can see that:
There are <b>0</b> Centers on team A.
There are <b>7 </b>Forwards on team A.
There are <b>20 </b>Guards on team A.
And so on.
<h3>Using xtabs() for n-Way Frequencies</h3>
The <b>xtabs() </b>function can actually be used to calculate frequencies for any number of variables by simply using the following syntax:
<b>xtabs(~variable1+variable2+variable3+...+variable<em>n</em>, data=df)</b>
In practice, this function is used most often to calculate one-way and two-way frequencies.
<h2><span class="orange">What is Y Hat in Statistics?</span></h2>
In statistics, the term <b>y hat</b> (written as <b>y<U+0302></b>) refers to the estimated value of a response variable in a  linear regression model .
We typically write an estimated regression equation as follows:
<U+0177> = β<sub>0</sub> + β<sub>1</sub>x
where:
<b><U+0177></b>: The estimated value of the response variable
<b>β<sub>0</sub></b>: The average value of the response variable when the predictor variable is zero
<b>β<sub>1</sub></b>: The average change in the response variable associated with a one unit increase in the predictor variable
For example, suppose we have the following dataset that shows the number of hours studied by six different students along with their final exam scores:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/sumSquare1.png">
Suppose we use some statistical software (like  R ,  Excel ,  Python , or even  by hand ) to fit the following regression model using <em>hours studied</em> as the predictor variable and <em>exam score</em> as the response variable:
<b>Score = 66.615 + 5.0769*(Hours)</b>
The way to interpret the regression coefficients in this model is as follows:
The average exam score for a student who studies zero hours is <b>66.615</b>.
Exam score increases by an average of <b>5.0769</b> points for each additional hour studied.
We can use this regression equation to <em>estimate</em> the score of a given student based on the number of hours they studied.
For example, a student who studies for 3 hours is predicted to get a score of:
Score = 66.615 + 5.0769*(3) = <b>81.85</b>
<h3>Why is Y Hat Used?</h3>
The “hat” symbol in statistics is used to denote any term that is “estimated.” For example, <b><U+0177></b> is used to denote an estimated response variable.
Typically when we fit linear regression models, we use a  sample  of data from a population since it’s more convenient and less time-consuming than collecting data for every possible observation in a population.
So, when we find a regression equation we’re only <em>estimating</em> the true relationship between a predictor variable and a response variable.
This is why we use the term <U+0177> in the regression equation instead of y.
<h2><span class="orange">Yate’s Continuity Correction: Definition & Example</span></h2>
A  Chi-Square Test of Independence  is used to determine whether or not there is a significant association between two categorical variables.
This test uses the following null and alternative hypotheses:
<b>H<sub>0</sub>: (null hypothesis) </b>The two variables are independent.
<b>H<sub>1</sub>: (alternative hypothesis) </b>The two variables are <em>not</em> independent. (i.e. they are associated)
We use the following formula to calculate the Chi-Square test statistic X<sup>2</sup> for this test:
<b>X<sup>2</sup> = Σ(O<sub>i</sub>-E<sub>i</sub>)<sup>2</sup> / E<sub>i</sub></b>
where:
<b>Σ:</b> is a fancy symbol that means “sum”
<b>O: </b>observed value
<b>E: </b>expected value
This test assumes that the discrete probabilities of the frequencies in a contingency table can be approximated by the Chi-Square distribution, which is a continuous distribution.
However, this assumption tends to be slightly incorrect and the resulting test statistic tends to be biased upwards.
To correct for this bias we can apply <b>Yate’s continuity correction</b>, which applies the following correction to the X<sup>2</sup>  formula:
<b>X<sup>2</sup> = Σ(|O<sub>i</sub>-E<sub>i</sub>| – 0.5)<sup>2</sup> / E<sub>i</sub></b>
We typically only use this correction when at least one cell in the contingency table has an expected frequency less than 5.
<h3>Example: Applying Yate’s Continuity Correction</h3>
Suppose we want to know whether or not gender is associated with political party preference. We take a simple random sample of 40 voters and survey them on their political party preference. The following table shows the results of the survey:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/yates2.png">
Here is how to perform a Chi-Square Test of Independence with Yate’s continuity correction:
<b>Observed Values:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/yates2.png">
<b>Expected Values:</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/yates3.png">
<em><b>Note: </b>We calculate the expected value in each cell by multipling the row total by the column total, then dividing by the grand total. For example, the expected number of male republicans is (21*19)/40 = 9.975.</em>
<b>Chi-Square Test Statistic: X<sup>2</sup> = Σ(|O<sub>i</sub>-E<sub>i</sub>| – 0.5)<sup>2</sup> / E<sub>i</sub></b>
(|8-9.975| – 0.5)<sup>2</sup> / 9.975 = .218
(|9-6.3| – 0.5)<sup>2</sup> / 6.3 = .768
(|4-4.725| – 0.5)<sup>2</sup> / 4.725 = .011
(|11-9.025| – 0.5)<sup>2</sup> / 9.025 = .241
(|3-5.7| – 0.5)<sup>2</sup> / 5.7 = .849
(|5-4.275| – 0.5)<sup>2</sup> / 4.275 = .012
Thus, X<sup>2</sup> = .218 + .768 + .011 + .241 + .849 + .012 = 2.099
P-Value: According to the  Chi-Square to P-Value Calculator , the p-value that corresponds to a Chi-Square test statistic with 2 degrees of freedom is <b>0.3501</b>.
Since this p-value is not less than .05, we would fail to reject the null hypothesis.  This means we do not have sufficient evidence to say that there is an association between gender and political party preference.
<h2><span class="orange">How to Fix: You are trying to merge on object and int64 columns</span></h2>
One error you may encounter when using pandas is:
<b>ValueError: You are trying to merge on int64 and object columns.
            If you wish to proceed you should use pd.concat
</b>
This error occurs when you attempt to merge two pandas DataFrames but the column you’re merging on is an object in one DataFrame and an integer in the other DataFrame.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we create the following two pandas DataFrames:
<b>import pandas as pd
#create DataFrame
df1 = pd.DataFrame({'year': [2015, 2016, 2017, 2018, 2019, 2020, 2021],    'sales': [500, 534, 564, 671, 700, 840, 810]})
df2 = pd.DataFrame({'year': ['2015', '2016', '2017', '2018', '2019', '2020', '2021'],    'refunds': [31, 36, 40, 40, 43, 70, 62]})
#view DataFrames
print(df1)
   year  sales
0  2015    500
1  2016    534
2  2017    564
3  2018    671
4  2019    700
5  2020    840
6  2021    810
print(df2)
   year  refunds
0  2015       31
1  2016       36
2  2017       40
3  2018       40
4  2019       43
5  2020       70
6  2021       62</b>
Now suppose we attempt to merge the two DataFrames:
<b>#attempt to merge two DataFrames
big_df = df1.merge(df2, on='year', how='left')
ValueError: You are trying to merge on int64 and object columns.
            If you wish to proceed you should use pd.concat
</b>
We receive a <b>ValueError</b> because the <b>year</b> variable in the first DataFrame is an integer but the <b>year</b> variable in the second DataFrame is an object.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply convert the <b>year</b> variable in the second DataFrame to an integer and then perform the merge.
The following syntax shows how to do so:
<b>#convert year variable in df2 to integer
df2['year']=df2['year'].astype(int)
#merge two DataFrames
big_df = df1.merge(df2, on='year', how='left')
#view merged DataFrame
big_df
yearsalesrefunds
0201550031
1201653436
2201756440
3201867140
4201970043
5202084070
6202181062</b>
Notice that we don’t receive any <b>ValueError</b> and we are able to successfully merge the two DataFrames into one.
<h2><span class="orange">How to Find the Z Critical Value in Excel</span></h2>
Whenever you conduct a hypothesis test, you will get a test statistic as a result. To determine if the results of the hypothesis test are statistically significant, you can compare the test statistic to a<b> Z critical value</b>.
If the absolute value of the test statistic is greater than the Z critical value, then the results of the test are statistically significant.
Fortunately, Excel makes it easy to find Z critical values using the following function:
<b>NORM.S.INV(probability)</b>
where:
<b>probability: </b>The significance level to use.
This function returns a Z critical value, based on the significance level you chose.
This tutorial provides three examples of how to use this function to find Z critical values.
<h3>Example 1: Two-Tailed Test</h3>
<b>Find the Z critical value for a two-tailed test, using α = 0.10.</b>
For a two-tailed test, there will be two critical values:
<b>NORM.S.INV(α/2)</b>
<b>NORM.S.INV(1-α/2)</b>
We can use the following functions in Excel to calculate these critical values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/z_crit1-1.png">
Thus, the two critical values for this test are <b>-1.645</b> and <b>1.645</b>. This means if the test statistic is less than -1.645 or greater than 1.645, then the results of the hypothesis test are statistically significant.
<h3>Example 2: Right-Tailed Test</h3>
<b>Find the Z critical value for a right-tailed test, using α = 0.05.</b>
For a right-tailed test, there will be one critical value: <b>NORM.S.INV(1-α)</b>
We can use the following function in Excel to calculate this critical value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/z_crit2.png">
Thus, the critical value for this test is <b>1.645</b>. This means if the test statistic is greater than 1.645, then the results of the hypothesis test are statistically significant.
<h3>Example 3: Left-Tailed Test</h3>
<b>Find the Z critical value for a left-tailed test, using α = 0.01.</b>
For a left-tailed test, there will be one critical value: <b>NORM.S.INV(α)</b>
We can use the following function in Excel to calculate this critical value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/z_crit3.png">
Thus, the critical value for this test is <b>-2.326</b>. This means if the test statistic is less than -2.326, then the results of the hypothesis test are statistically significant.
<h2><span class="orange">How to Find the Z Critical Value in Python</span></h2>
Whenever you conduct a hypothesis test, you will get a test statistic as a result. To determine if the results of the hypothesis test are statistically significant, you can compare the test statistic to a<b> Z critical value</b>. If the absolute value of the test statistic is greater than the Z critical value, then the results of the test are statistically significant.
To find the Z critical value in Python, you can use the  scipy.stats.norm.ppf() function , which uses the following syntax:
<b>scipy.stats.norm.ppf(q)</b>
where:
<b>q: </b>The significance level to use
The following examples illustrate how to find the Z critical value for a left-tailed test, right-tailed test, and a two-tailed test.
<h3>Left-tailed test</h3>
Suppose we want to find the Z critical value for a left-tailed test with a significance level of .05: 
<b>import scipy.stats
#find Z critical value
scipy.stats.norm.ppf(.05)
-1.64485
</b>
The Z critical value is <b>-1.64485</b>. Thus, if the test statistic is less than this value, the results of the test are statistically significant.
<h3>Right-tailed test</h3>
Suppose we want to find the Z critical value for a right-tailed test with a significance level of .05: 
<b>import scipy.stats
#find Z critical value
scipy.stats.norm.ppf(1-.05)
1.64485
</b>
The Z critical value is <b>1.64485</b>. Thus, if the test statistic is greater than this value, the results of the test are statistically significant.
<h3>Two-tailed test</h3>
Suppose we want to find the Z critical value for a two-tailed test with a significance level of .05: 
<b>import scipy.stats
#find Z critical value
scipy.stats.norm.ppf(1-.05/2)
1.95996
</b>
Whenever you perform a two-tailed test, there will be two critical values. In this case, the Z critical values are <b>1.95996 </b>and <b>-1.95996</b>. Thus, if the test statistic is less than -1.95996 or greater than 1.95996, the results of the test are statistically significant.
<em>Refer to the  SciPy documentation  for the exact details of the norm.ppf() function.</em>
<h2><span class="orange">How to Find Z Critical Values in R</span></h2>
Whenever you conduct a hypothesis test, you will get a test statistic as a result. To determine if the results of the hypothesis test are statistically significant, you can compare the test statistic to a<b> Z critical value</b>. If the absolute value of the test statistic is greater than the Z critical value, then the results of the test are statistically significant.
To find the Z critical value in R, you can use the qnorm() function, which uses the following syntax:
<b>qnorm(p, mean = 0, sd = 1, lower.tail = TRUE)</b>
where:
<b>p: </b>The significance level to use
<b>mean: </b>The mean of the normal distribution
<b>sd: </b>The standard deviation of the normal distribution
<b>lower.tail: </b>If TRUE, the probability to the left of <b>p </b>in the normal distribution is returned. If FALSE, the probability to the right is returned. Default is TRUE.
The following examples illustrate how to find the Z critical value for a left-tailed test, right-tailed test, and a two-tailed test.
<h3>Left-tailed test</h3>
Suppose we want to find the Z critical value for a left-tailed test with a significance level of .05: 
<b>#find Z critical value
qnorm(p=.05, lower.tail=TRUE)
[1] -1.644854
</b>
The Z critical value is <b>-1.644854</b>. Thus, if the test statistic is less than this value, the results of the test are statistically significant.
<h3>Right-tailed test</h3>
Suppose we want to find the Z critical value for a right-tailed test with a significance level of .05: 
<b>#find Z critical value
qnorm(p=.05, lower.tail=FALSE)
[1] 1.644854
</b>
The Z critical value is <b>1.644854</b>. Thus, if the test statistic is greater than this value, the results of the test are statistically significant.
<h3>Two-tailed test</h3>
Suppose we want to find the Z critical value for a two-tailed test with a significance level of .05: 
<b>#find Z critical value
qnorm(p=.05/2, lower.tail=FALSE)
[1] 1.959964
</b>
Whenever you perform a two-tailed test, there will be two critical values. In this case, the Z critical values are <b>1.959964 </b>and <b>-1.959964</b>. Thus, if the test statistic is less than -1.959964 or greater than 1.959964, the results of the test are statistically significant.
<i>You can find more R tutorials  here .</i>
<h2><span class="orange">How to Find the Z Critical Value on a TI-84 Calculator</span></h2>
Whenever you conduct a hypothesis test, you will get a test statistic as a result. To determine if the results of the hypothesis test are statistically significant, you can compare the test statistic to a<b> Z critical value</b>. If the absolute value of the test statistic is greater than the Z critical value, then the results of the test are statistically significant.
To find the Z critical value on a TI-84 calculator, we can use the following function:
<b>invNorm(probability, μ, σ)</b>
where:
<b>probability:</b> the significance level
<b>μ:</b> population mean
<b>σ:</b> population standard deviation
You can access this function on a TI-84 calculator by pressing 2nd and then pressing vars. This will take you to a <b>DISTR </b>screen where you can then use <b>invNorm()</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zcritTI1.png">
This tutorial shares several examples of how to use the invNorm() function to find Z critical values on a TI-84 calculator.
<h3>Example 1: Z Critical Value for a Left-Tailed Test</h3>
<b>Question: </b>Find the Z critical value for a left-tailed test with a significance level of 0.05.
<b>Answer: </b>invNorm(.05, 0, 1) = <b>-1.6449</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zcritTI3.png">
<b>Interpretation: </b>If the test statistic of the test is less than <b>-1.6449</b>, then the results of the test are statistically significant at α = 0.05.
<h3>Example 2: Z Critical Value for a Right-Tailed Test</h3>
<b>Question: </b>Find the Z critical value for a right-tailed test with a significance level of 0.10.
<b>Answer: </b>invT(1-.10, 0, 1) = <b>1.2816</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zcritTI2.png">
<b>Interpretation: </b>If the test statistic of the test is greater than <b>1.2816</b>, then the results of the test are statistically significant at α = 0.10.
<h3>Example 3: Z Critical Value for a Two-Tailed Test</h3>
<b>Question: </b>Find the Z critical value for a two-tailed test with a significance level of 0.05.
<b>Answer: </b>invNorm(.05/2, 0, 1) = <b>-1.96, 1.96</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zcritTI4.png">
<b>Interpretation: </b>Since this is a two-tailed test, we actually have two critical values: <b>-1.96</b> and <b>1.96</b>. If the test statistic of the test is less than <b>-1.96 </b>or greater than <b>1.96</b>, then the results of the test are statistically significant at α = 0.05.
<h2><span class="orange">Z Score Calculator</span></h2>
This calculator finds the <b>standardized z-score</b> for any raw value of X, a population mean, and a population standard deviation.
A z-score simply tells us how many standard deviations away from the mean a value X lies.
To find the z-score for any value of X, simply fill in the boxes below and then click the “Calculate” button.
<label for="X"><b>Raw score (X)</b></label>
<input type="number" id="X" min="0" value="17">
<label for="pop_mean"><b>Population mean (μ)</b></label>
<input type="number" id="pop_mean" min="0" value="13.5">
<label for="pop_sd"><b>Population standard deviation (σ)</b></label>
<input type="number" id="pop_sd" min="0" value="4">
<input type="button" id="buttonCalc" onclick="calc()" value="Calculate">
<div>
Z score: (X – μ) / σ
<div>
Z score: (17 – 13.5) / 4 = <b>0.875</b>
<script>
var X = document.getElementById('X').value*1;
var pop_mean = document.getElementById('pop_mean').value*1;
var pop_sd = document.getElementById('pop_sd').value*1;
function calc() {
//get input degrees of freedom, t-value
var X = document.getElementById('X').value*1;
var pop_mean = document.getElementById('pop_mean').value*1;
var pop_sd = document.getElementById('pop_sd').value*1;
//calculate z-score
var z = (X - pop_mean) / pop_sd;
var sign = "below"
if (Math.sign(z) >=0 ) {
        sign = "above"
}
//output values
document.getElementById('X2').innerHTML = X;
document.getElementById('pop_mean2').innerHTML = pop_mean;
document.getElementById('pop_sd2').innerHTML = pop_sd;
document.getElementById('z2').innerHTML = z.toPrecision();
} //end massive calc() function
</script>
<h2><span class="orange">Z Score Cut Off Calculator</span></h2>
For a normally distributed population with a given mean (<b>μ</b>) and standard deviation (<b>σ</b>), this calculator finds the value that is needed to be at the x<sup>th</sup> percentile or higher.
For example, suppose the scores on a certain test are normally distributed with a mean of 85 and a standard deviation of 4. We want to know what score a student needs to receive in order to have a higher score than 95% of all other students. This calculator will allow us to find that score.
To find the cut off value for a given population mean, population standard deviation, and percentile, simply fill in the necessary values below and then click the “Calculate” button.
<label for="pop_mean"><b>Population mean (μ)</b></label>
<input type="number" id="pop_mean" min="0" value="85">
<label for="pop_sd"><b>Population standard deviation (σ)</b></label>
<input type="number" id="pop_sd" min="0" value="4">
<label for="x"><b>x<sup>th</sup> percentile</b></label>
<input type="number" id="x" min="0" value="95">
<input type="button" id="button" onclick="calc()" value="Calculate">
<div>
A value of <b>91.57941</b> is needed to be above 95% of all other values.
<hr id="hr_top">
<div>
<h2>Explanation:</h2>
<div>
z = (X – μ) / σ
<div>
1.64485 = (X – 85) / 4
<div>
1.64485 * 4 = X – 85
<div>
(1.64485 * 4) + 85 = X
<div>
<b>91.57941</b> = X
<script>
function calc() {
    
//get input degrees of freedom, t-value
var x = document.getElementById('x').value*1;
var pop_mean = document.getElementById('pop_mean').value*1;
var pop_sd = document.getElementById('pop_sd').value*1;
//calculate z-score
var z = jStat.normal.inv((x/100), 0, 1);
var value = (z*pop_sd) - (-pop_mean);
//output values
    document.getElementById('value').innerHTML = "<b>" + value.toFixed(5) + "</b>";
    document.getElementById('value2').innerHTML = "<b>" + value.toFixed(5) + "</b>";
document.getElementById('x_out').innerHTML = x;
document.getElementById('z_out1').innerHTML = z.toFixed(5);
    document.getElementById('z_out2').innerHTML = z.toFixed(5);
    document.getElementById('z_out3').innerHTML = z.toFixed(5);
    document.getElementById('sd_out1').innerHTML = pop_sd.toFixed(5);
    document.getElementById('sd_out2').innerHTML = pop_sd.toFixed(5);
    document.getElementById('sd_out3').innerHTML = pop_sd.toFixed(5);
    document.getElementById('mean_out1').innerHTML = pop_mean.toFixed(5);
    document.getElementById('mean_out2').innerHTML = pop_mean.toFixed(5);
    document.getElementById('mean_out3').innerHTML = pop_mean.toFixed(5);
  }
</script>
<h2><span class="orange">How to Calculate Z-Scores in Excel</span></h2>
In statistics, a <b>z-score</b> tells us how many standard deviations away a value is from  the mean . We use the following formula to calculate a z-score:
<b>z</b> = (X – μ) / σ
where:
X is a single raw data value
μ is the mean of the dataset
σ is the standard deviation of the dataset
This tutorial explains how you can calculate z-scores for raw data values in Excel.
<h2>How to Calculate Z-Scores in Excel</h2>
Suppose we have the following dataset and we would like to find the z-score for every raw data value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel1.jpg">
We can perform the following steps to do so.
<b>Step 1: Find the mean and standard deviation of the dataset.</b>
First, we need to find the mean and the standard deviation of the dataset. The following formulas show how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel2-1.jpg">
The mean turns out to be <b>14.375 </b>and the standard deviation turns out to be <b>4.998</b>.
<b>Step 2: Find the z-score for the first raw data value.</b>
Next, we’ll find the z-score for the first raw data value using the formula <b>z</b> = (X – μ) / σ.
<em>Cell C2 shows the formula we used to calculate the z-value in cell B2.</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel3.jpg">
<b>Step 3: Find the z-scores for all remaining values.</b>
Now that we found the z-score for the first value in the dataset, we can simply copy the formula we used in cell B2 to the rest of the data values. We can do this by highlighting the entire z-score column, starting with the first z-score we already calculated:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel4.jpg">
Next, press <b>Ctrl+D</b>. This copies the formula in the first cell to all of the cells below it.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel5.jpg">
Now, we have found the z-score for every raw data value.
<h2>How to Interpret Z-Scores in Excel</h2>
Recall that a <b>z-score </b>simply tells us how many standard deviations away a value is from the mean.
A z-score can be positive, negative, or equal to zero.
A positive z-score indicates that a particular value is greater than the mean, a negative z-score indicates that a particular value is less than the mean, and a z-score of zero indicates that a particular value is equal to the mean.
In our example, we found that the mean was <b>14.375 </b>and the standard deviation was <b>4.998</b>.
So, the first value in our dataset was 7, which had a z-score of (7-14.375) / 4.998 = <b>-1.47546</b>. This means that the value “7” is -1.47545 standard deviations <em>below </em>the mean. 
The next value in our data, 12, had a z-score of (12-14.375) / 4.998 = <b>-0.47515</b>.  This means that the value “12” is -0.47515 standard deviations <em>below </em>the mean. 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/z_score_excel5.jpg">
The further away a value is from the mean, the higher the absolute value of the z-score will be for that value.
For example, the value 7 is further away from the mean (14.375) compared to 12, which explains why 7 had a z-score with a larger absolute value.
<h2><span class="orange">Z-Score Normalization: Definition & Examples</span></h2>
<b>Z-score normalization</b> refers to the process of normalizing every value in a dataset such that the mean of all of the values is 0 and the standard deviation is 1.
We use the following formula to perform a z-score normalization on every value in a dataset:
<b>New value = (x – μ) / σ</b>
where:
<b>x</b>: Original value
<b>μ</b>: Mean of data
<b>σ</b>: Standard deviation of data
The following example shows how to perform z-score normalization on a dataset in practice.
<h3>Example: Performing Z-Score Normalization</h3>
Suppose we have the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/zscorenorm1.png">
Using a calculator, we can find that the mean of the dataset is <b>21.2</b> and the standard deviation is <b>29.8</b>.
To perform a z-score normalization on the first value in the dataset, we can use the following formula:
New value = (x – μ) / σ
New value = (3 – 21.2) / 29.8
New value = -0.61
We can use this formula to perform a z-score normalization on every value in the dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/zscorenorm2.png">
The mean of the normalized values is <b>0</b> and the standard deviation of the normalized values is <b>1</b>.
The normalized values represent the number of standard deviations that the original value is from the mean.
For example:
The first value in the dataset is <b>0.61</b> standard deviations below the mean.
The second value in the dataset is <b>0.54</b> standard deviations below the mean.
…
The last value in the dataset is <b>3.79</b> standard deviations above the mean.
The benefit of performing this type of normalization is that the clear outlier in the dataset (134) has been transformed in such a way that it’s no longer a massive outlier.
If we then use this dataset to fit some type of  machine learning model , the outlier will no longer have as big of an influence that it might have on the model fit.
<h2><span class="orange">How to Calculate Z-Scores in Python</span></h2>
In statistics, a <b>z-score </b>tells us how many standard deviations away a value is from  the mean . We use the following formula to calculate a z-score:
<b>z</b> = (X – μ) / σ
where:
X is a single raw data value
μ is the population mean
σ is the population standard deviation
This tutorial explains how to calculate z-scores for raw data values in Python.
<h3>How to Calculate Z-Scores in Python</h3>
We can calculate z-scores in Python using <b>scipy.stats.zscore</b>, which uses the following syntax:
<b>scipy.stats.zscore(a, axis=0, ddof=0, nan_policy=’propagate’)</b>
where:
<b>a</b>: an array like object containing data
<b>axis</b>: the axis along which to calculate the z-scores. Default is 0.
<b>ddof</b>: degrees of freedom correction in the calculation of the standard deviation. Default is 0.
<b>nan_policy</b>: how to handle when input contains nan. Default is propagate, which returns nan. ‘raise’ throws an error and ‘omit’ performs calculations ignoring nan values.
The following examples illustrate how to use this function to calculate z-scores for one-dimensional numpy arrays, multi-dimensional numpy arrays, and Pandas DataFrames.
<h3>Numpy One-Dimensional Arrays</h3>
<b>Step 1: Import modules.</b>
<b>import pandas as pd
import numpy as np
import scipy.stats as stats
</b>
<b>Step 2: Create an array of values.</b>
<b>data = np.array([6, 7, 7, 12, 13, 13, 15, 16, 19, 22])
</b>
<b>Step 3: Calculate the z-scores for each value in the array.</b>
<b>stats.zscore(data)
[-1.394, -1.195, -1.195, -0.199, 0, 0, 0.398, 0.598, 1.195, 1.793]
</b>
Each z-score tells us how many standard deviations away an individual value is from the mean. For example:
The first value of “6” in the array is <b>1.394 </b>standard deviations <em>below </em>the mean.
The fifth value of “13” in the array is <b>0 </b>standard deviations away from the mean, i.e. it is equal to the mean.
The last value of “22” in the array is <b>1.793 </b>standard deviations <em>above </em>the mean.
<h3>Numpy Multi-Dimensional Arrays</h3>
If we have a multi-dimensional array, we can use the <b>axis </b>parameter to specify that we want to calculate each z-score relative to its own array. For example, suppose we have the following multi-dimensional array:
<b>data = np.array([[5, 6, 7, 7, 8], [8, 8, 8, 9, 9], [2, 2, 4, 4, 5]])
</b>
We can use the following syntax to calculate the z-scores for each array:
<b>stats.zscore(data, axis=1)
[[-1.569 -0.588 0.392 0.392 1.373]
[-0.816 -0.816 -0.816 1.225 1.225]
[-1.167 -1.167 0.5 0.5 1.333]]
</b>
The z-scores for each individual value are shown relative to the array they’re in. For example:
The first value of “5” in the first array is <b>1.159 </b>standard deviations <em>below </em>the mean of its array.
The first value of “8” in the second array is <b>.816 </b>standard deviations <em>below </em>the mean of its array.
The first value of “2” in the third array is <b>1.167 </b>standard deviations <em>below </em>the mean of its array.
<h3>Pandas DataFrames</h3>
Suppose we instead have a Pandas DataFrame:
<b>data = pd.DataFrame(np.random.randint(0, 10, size=(5, 3)), columns=['A', 'B', 'C'])
data
  A B C
0 8 0 9
1 4 0 7
2 9 6 8
3 1 8 1
4 8 0 8
</b>
We can use the <b>apply </b>function to calculate the z-score of individual values by column:
<b>data.apply(stats.zscore)
          A         B         C
0  0.659380 -0.802955  0.836080
1 -0.659380 -0.802955  0.139347
2  0.989071  0.917663  0.487713
3 -1.648451  1.491202 -1.950852
4  0.659380 -0.802955  0.487713
</b>
The z-scores for each individual value are shown relative to the column they’re in. For example:
The first value of “8” in the first column is <b>0.659</b> standard deviations <em>above</em> the mean value of its column.
The first value of “0” in the second column is <b>.803</b> standard deviations <em>below</em> the mean value of its column.
The first value of “9” in the third column is <b>.836</b> standard deviations <em>above</em> the mean value of its column.
<b>Additional Resources:</b>
 How to Calculate Z-Scores in Excel 
 How to Calculate Z-Scores in SPSS 
 How to Calculate Z-Scores on a TI-84 Calculator 
<dl>
<dd></dd>
</dl>
<h2><span class="orange">How to Calculate Z-Scores in R</span></h2>
In statistics, a <b>z-score </b>tells us how many standard deviations away a value is from the mean. We use the following formula to calculate a z-score:
<b>z</b> = (X – μ) / σ
where:
X is a single raw data value
μ is the population mean
σ is the population standard deviation
This tutorial explains how to calculate z-scores for raw data values in R.
<h3>Example 1: Find Z-Scores for a Single Vector</h3>
The following code shows how to find the z-score for every raw data value in a vector:
<b>#create vector of data
data &lt;- c(6, 7, 7, 12, 13, 13, 15, 16, 19, 22)
#find z-score for each data value 
z_scores &lt;- (data-mean(data))/sd(data)
#display z-scores 
z_scores
[1] -1.3228757 -1.1338934 -1.1338934 -0.1889822  0.0000000  0.0000000
[7]  0.3779645  0.5669467  1.1338934  1.7008401
</b>
Each z-score tells us how many standard deviations away an individual value is from the mean. For example:
The first raw data value of “6” is <b>1.323 </b>standard deviations <em>below </em>the mean.
The fifth raw data value of “13” is <b>0 </b>standard deviations away from the mean, i.e. it is equal to the mean.
The last raw data value of “22” is <b>1.701 </b>standard deviations <em>above </em>the mean.
<h3>Example 2: Find Z-Scores for a Single Column in a DataFrame</h3>
The following code shows how to find the z-score for every raw data value in a single column of a dataframe:
<b>#create dataframe
df &lt;- data.frame(assists = c(4, 4, 6, 7, 9, 13), points = c(24, 29, 13, 15, 19, 22), rebounds = c(5, 5, 7, 8, 14, 15))
#find z-score for each data value in the 'points' column
z_scores &lt;- (df$points-mean(df$points))/sd(df$points)
#display z-scores 
z_scores
[1]  0.6191904  1.4635409 -1.2383807 -0.9006405 -0.2251601  0.2814502
</b>
Each z-score tells us how many standard deviations away an individual value is from the mean. For example:
The first raw data value of “24” is <b>0.619 </b>standard deviations <em>above </em>the mean.
The second raw data value of “29” is <b>1.464 </b>standard deviations <em>above </em>the mean.
The third raw data value of “13” is <b>1.238 </b>standard deviations <em>below </em>the mean.
And so on.
<h3>Example 3: Find Z-Scores for Every Column in a DataFrame</h3>
The following code shows how to find the z-score for every raw data value in every column of a dataframe using the  sapply() function .
<b>#create dataframe
df &lt;- data.frame(assists = c(4, 4, 6, 7, 9, 13), points = c(24, 29, 13, 15, 19, 22), rebounds = c(5, 5, 7, 8, 14, 15))
#find z-scores of each column
sapply(df, function(df) (df-mean(df))/sd(df))
         assists     points   rebounds
[1,] -0.92315712  0.6191904 -0.9035079
[2,] -0.92315712  1.4635409 -0.9035079
[3,] -0.34011052 -1.2383807 -0.4517540
[4,] -0.04858722 -0.9006405 -0.2258770
[5,]  0.53445939 -0.2251601  1.1293849
[6,]  1.70055260  0.2814502  1.3552619</b>
The z-scores for each individual value are shown relative to the column they’re in. For example:
The first value of “4” in the first column is <b>0.923</b> standard deviations <i>below </i>the mean value of its column.
The first value of “24” in the second column is <b>.619</b> standard deviations <i>above </i>the mean value of its column.
The first value of “9” in the third column is <b>.904</b> standard deviations <em>below</em> the mean value of its column.
And so on.
<em>You can find more R tutorials  here .</em>
<h2><span class="orange">5 Examples of Using Z-Scores in Real Life</span></h2>
In statistics, a  z-score  tells us how many standard deviations away a given value lies from a population mean.
We use the following formula to calculate a z-score for a given value:
<b>z = (x – μ) / σ</b>
where:
<b>x</b>: Individual data value
<b>μ</b>: Mean of population
<b>σ</b>: Standard deviation of population
The following examples show how z-scores are used in real life in different scenarios.
<h3>Example 1: Exam Scores</h3>
Z-scores are often used in academic settings to analyze how well a student’s score compares to the mean score on a given exam.
For example, suppose the scores on a certain college entrance exam are roughly normally distributed with a mean of 82 and a standard deviation of 5.
If a certain student received a 90 on the exam, we would calculate their z-score to be:
z = (x – μ) / σ
z = (90 – 82) / 5
z = 1.6
This means that this student received a score that was 1.6 standard deviations above the mean.
We could use the  Area To The Left of Z-Score Calculator  to find that a z-score of 1.6 represents a value that is greater than <b>94.52%</b> of all exam scores.
<h3>Example 2: Newborn Weights</h3>
Z-scores are often used in a medical setting to analyze how a certain newborn’s weight compares to the mean weight of all babies.
For example, it’s well-documented that the weights of newborns are normally distributed with a mean of about 7.5 pounds and a standard deviation of 0.5 pounds.
If a certain newborn weights 7.7 pounds, we would calculate their z-score to be:
z = (x – μ) / σ
z = (7.7 – 7.5) / 0.5
z = 0.4
This means that this baby weighs 0.4 standard deviations above the mean.
We could use the  Area To The Left of Z-Score Calculator  to find that a z-score of 0.4 represents a weight that is greater than <b>65.54%</b> of all baby weights.
<h3>Example 3: Giraffe Heights</h3>
Z-scores are often used in a biology to assess how the height of a certain animal compares to the mean population height of that particular animal.
For example, suppose the heights of a certain species of giraffe is normally distributed with a mean of 16 feet and a standard deviation of 2 feet.
If a certain giraffe from this species is 15 feet tall, we would calculate their z-score to be:
z = (x – μ) / σ
z = (15 – 16) / 2
z = -0.5
This means that this giraffe has a height that is 0.5 standard deviations below the mean.
We could use the  Area To The Left of Z-Score Calculator  to find that a z-score of -0.5 represents a height that is greater than just <b>30.85%</b> of all giraffes.
<h3>Example 4: Shoe Size</h3>
Z-scores can be used to determine how a certain shoe size compares to the mean population size.
For example, it’s known that shoe sizes for males in the U.S. is roughly normally distributed with a mean of size 10 and a standard deviation of 1.
If a certain man has a shoe size of 10, we would calculate their z-score to be:
z = (x – μ) / σ
z = (10 – 10) / 1
z =0
This means that this man has a shoe size that is 0 standard deviations away from the mean.
We could use the  Area To The Left of Z-Score Calculator  to find that a z-score of 0 represents a shoe size that is greater than exactly <b>50%</b> of all males.
<h3>Example 5: Blood Pressure</h3>
Z-scores are often used in medical settings to assess how an individual’s blood pressure compares to the mean population blood pressure.
For example, the distribution of diastolic blood pressure for men is normally distributed with a mean of about 80 and a standard deviation of 20.
If a certain man has a diastolic blood pressure of 100, we would calculate their z-score to be:
z = (x – μ) / σ
z = (100 – 80) / 20
z = 1
This means that this man has a diastolic blood pressure that is 1 standard deviation above the mean.
We could use the  Area To The Left of Z-Score Calculator  to find that a z-score of 1 represents a blood pressure size that is greater than <b>84.13%</b> of all males.
<h2><span class="orange">How to Calculate Z-Scores in SAS</span></h2>
In statistics, a <b>z-score</b> tells us how many standard deviations away a value is from  the mean .
We use the following formula to calculate a z-score:
<b>z</b> = (X – μ) / σ
where:
X is a single raw data value
μ is the mean of the dataset
σ is the standard deviation of the dataset
The following example shows how to calculate z-scores for raw data values in SAS.
<h2>Example: Calculate Z-Scores in SAS</h2>
Suppose we create the following dataset in SAS:
<b>/*create dataset*/
data original_data;
    input values;
    datalines;
7
12
14
12
16
18
6
7
14
17
19
22
24
13
17
12
;
run;
/*view dataset*/
proc print data=original_data;
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/zsas1.jpg"107">
Now suppose we would like to calculate the z-score for each value in the dataset.
We can use <b>proc sql</b> to do so:
<b>/*create new variable that shows z-scores for each raw data value*/
proc sql;
    select values, (values - mean(values)) / std(values) as z_scores
    from original_data;
quit;</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/09/zsas2.jpg">
The <b>values</b> column shows the original data values and the <b>z_scores</b> column shows the z-score for each value.
<h2>How to Interpret Z-Scores in SAS</h2>
A <b>z-score </b>tells us how many standard deviations away a value is from the mean.
A z-score can be positive, negative, or equal to zero.
A positive z-score indicates that a particular value is greater than the mean, a negative z-score indicates that a particular value is less than the mean, and a z-score of zero indicates that a particular value is equal to the mean.
If we calculated the mean and standard deviation of our dataset, we would find that the mean is <b>14.375</b> and the standard deviation is <b>5.162</b>.
So, the first value in our dataset was 7, which had a z-score of (7-14.375) / 5.162 = <b>-1.428</b>. This means that the value “7” is 1.428 standard deviations <em>below </em>the mean. 
The next value in our data, 12, had a z-score of (12-14.375) / 5.162 = <b>-0.46</b>.  This means that the value “12” is 0.46 standard deviations <em>below </em>the mean. 
The further away a value is from the mean, the higher the absolute value of the z-score will be for that value.
For example, the value 7 is further away from the mean (14.375) compared to 12, which explains why 7 had a z-score with a larger absolute value.
<h2>Additional Resources</h2>
The following articles explain how to perform other common tasks in SAS:
 How to Identify Outliers in SAS 
 How to Calculate Percentiles in SAS 
 How to Calculate Mean, Median, & Mode in SAS 
<h2><span class="orange">How to Calculate Z-Scores on a TI-84 Calculator</span></h2>
A<b> z-score</b> tells us how many standard deviations away a given value is from the mean. The z-score of a given value is calculated as:
<b>z-score</b> = (x – μ) / σ
where:
<b>x:</b> individual value
<b>μ:</b> population mean
<b>σ:</b> population standard deviation
This tutorial explains how to calculate z-scores on a TI-84 calculator.
<h3>How to Calculate the Z-Score of a Single Value</h3>
Suppose a distribution is normally distributed with a mean of 12 and a standard deviation of 1.4 and we wish to calculate the z-score of an individual value x = 14. To calculate the z-score in a TI-84 calculator, we would simply type in the following formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI1.png">
This tells us that an individual value of 14 has a z-score of <b>1.4286</b>. In other words, the value 14 lies 1.4286 standard deviations above the mean.
<h3>How to Calculate the Z-Score of Several Values</h3>
Suppose instead that we have a list of data values and that we would like to calculate the z-score for every value in the list. In this case, we can perform the following steps:
<b>Step 1: Input the data.</b>
First, we will input the data values. Press Stat  and then press EDIT. Enter the following values in column L1:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI2.png">
<b>Step 2: Find the mean and standard deviation of the data values.</b>
Next, we will find the mean and the standard deviation of the dataset. Press Stat and then scroll over to <b>CALC</b>. Highlight <b>1-Var Stats</b> and press Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI3.png">
For <b>List</b>, make sure L1 is chosen since this is the column we entered our data in. Leave <b>FreqList </b>blank. Highlight <b>Calculate </b>and press Enter.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI4.png">
The following output will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI5.png">
We can see that the mean of the dataset is x = <b>10</b> and the standard deviation is s<sub>x</sub> = <b>5.558</b>. We will use these two values in the next step to calculate z-scores.
<b>Step 3: Use a formula to calculate every z-score.</b>
Next, we will calculate the z-score for every individual value in the dataset. Press Stat and then press EDIT. Highlight L2 and type in the formula (<b>L1-10) / 5.558</b> and then press Enter. The z-score of every individual value will automatically appear in column L2:
<em><b>Note: </b>To enter “L1” in the formula, press 2nd and then press 1.</em>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI6.png">
<h2>How to Interpret Z-Scores</h2>
Recall that a z-score simply tells us how many standard deviations away a value is from the mean. A z-score can be positive, negative, or equal to zero:
A <b>positive z-score</b> indicates that a particular value is greater than the mean.
A <b>negative z-score</b> indicates that a particular value is less than the mean.
A <b>z-score of zero</b> indicates that a particular value is equal to the mean.
In our example, we found that the mean was <b>10 </b>and the standard deviation was <b>5.558</b>.
So, the first value in our dataset was 3, which had a z-score of (3-10) / 5.558 = <b>-1.259</b>. This means that the value “3” is 1.259 standard deviations <em>below </em>the mean.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/zscoreTI6.png">
The next value in our dataset, 4, had a z-score of (4-10) / 5.558 = <b>-1.08</b>.  This means that the value “4” is 1.08 standard deviations <em>below </em>the mean.
The further away a value is from the mean, the higher the absolute value of the z-score will be for that value.
For example, the value 3 is further away from the mean compared to 4, which explains why 3 had a z-score with a larger absolute value.
<h2><span class="orange">Z Score to P Value Calculator</span></h2>
<label for="z"><b>Z score</b></label>
<input type="number" id="z" min="0" value="0.3" step="0.01">
<b>One-tailed or two-tailed hypothesis?</b>
<label for="one_tailed">One-tailed</label>
<input type="radio" id="one_tailed" name="tails" checked><label for="two_tailed">Two-tailed</label>
<input type="radio" id="two_tailed" name="tails">
<b>Significance level</b>
<label for="one">0.01</label>
<input type="radio" id="one" name="sig" value="0.01"><label for="five">0.05</label>
<input type="radio" id="five" name="sig" value="0.05" checked><label for="ten">0.10</label>
<input type="radio" id="ten" name="sig" value="0.10">
<input type="button" id="button" onclick="GetZPercent()" value="Calculate">
<div>
P-value: 0.38209
<div>
The result is NOT SIGNIFICANT at p &lt; 0.05
<script>
//the following function originated from https://stackoverflow.com/questions/16194730/seeking-a-statistical-javascript-function-to-return-p-value-from-a-z-score/30435852
function GetZPercent() 
  {
    var z_input = document.getElementById('z').value*1;
    var z = Math.abs(z_input);
    //if z is greater than 6.5 standard deviations from the mean
    //the number of significant digits will be outside of a reasonable 
    //range
    if ( z < -6.5)
      return 0.0;
    if( z > 6.5) 
      return 1.0;
    var factK = 1;
    var sum = 0;
    var term = 1;
    var k = 0;
    var loopStop = Math.exp(-23);
    while(Math.abs(term) > loopStop) 
    {
      term = .3989422804 * Math.pow(-1,k) * Math.pow(z,k) / (2 * k + 1) / Math.pow(2,k) * Math.pow(z,k+1) / factK;
      sum += term;
      k++;
      factK *= k;
    }
    sum += 0.5;
    var p_value = 1 - sum;
//get tails input
if (document.getElementById('two_tailed').checked) {
p_value = p_value * 2;
}
//get significance level input
var sig_level = '';
if (document.getElementById('one').checked) {
sig_level = 0.01;
} else if (document.getElementById('five').checked) {
sig_level = 0.05;
} else {
    sig_level = 0.10;
}
//get significance verdict
var sig_verdict = '';
if (p_value < sig_level) {
sig_verdict = 'SIGNIFICANT';
} else {
sig_verdict = 'NOT SIGNIFICANT';
}
//output values
    document.getElementById('exactProb').innerHTML = p_value.toFixed(5);
document.getElementById('sig_level').innerHTML = sig_level.toFixed(2);
document.getElementById('sig_verdict').innerHTML = sig_verdict;
  }
</script>
<h2><span class="orange">How to Calculate Z-Scores in Google Sheets</span></h2>
In statistics, a <b>z-score </b>tells us how many standard deviations away a value is from  the mean . We use the following formula to calculate a z-score:
<b>z</b> = (X – μ) / σ
where:
X is a single raw data value
μ is the mean of the dataset
σ is the standard deviation of the dataset
This tutorial explains how to calculate z-scores for raw data values in Google Sheets.
<h2>Example: Z-Scores in Google Sheets</h2>
Suppose we have the following dataset and we would like to find the z-score for every raw data value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/zScoreSheets1.png">
We can perform the following steps to do so.
<b>Step 1: Find the mean and standard deviation of the dataset.</b>
First, we need to find the mean and the standard deviation of the dataset. The following formulas show how to do so:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/zScoreSheets2.png">
The mean turns out to be <b>14.375 </b>and the standard deviation turns out to be <b>4.998</b>.
<b>Step 2: Find the z-score for the first raw data value.</b>
Next, we’ll find the z-score for the first raw data value by typing the following formula in cell B2:
<b>=(A2–$E$2)/$E$3</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/zScoreSheets3.png">
<b>Step 3: Find the z-scores for all remaining values.</b>
Once we’ve calculated the first z-score, we can highlight the rest of column B starting with cell B2 and press <b>Ctrl+D </b>to copy the formula in cell B2 to each of the cells below it:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/zScoreSheets4.png">
Now we have found the z-score for every raw data value.
<h2>How to Interpret Z-Scores</h2>
A <b>z-score </b>simply tells us how many standard deviations away a value is from the mean.
In our example, we found that the mean was <b>14.375 </b>and the standard deviation was <b>4.998</b>.
So, the first value in our dataset was 7, which had a z-score of (7-14.375) / 4.998 = <b>-1.47546</b>. This means that the value “7” is -1.47545 standard deviations <em>below </em>the mean. 
The next value in our data, 12, had a z-score of (12-14.375) / 4.998 = <b>-0.47515</b>.  This means that the value “12” is -0.47515 standard deviations <em>below </em>the mean. 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/zScoreSheets4.png">
The further away a value is from the mean, the higher the absolute value of the z-score will be for that value. For example, the value 7 is further away from the mean (14.375) compared to 12, which explains why 7 had a z-score with a larger absolute value.
<h2><span class="orange">How to Calculate Z-Scores in SPSS</span></h2>
A<b> z-score</b> tells us how many standard deviations away a given value is from the mean. The z-score of a given value is calculated as:
<b>z-score</b> = (x – μ) / σ
where:
<b>x:</b> individual value
<b>μ:</b> population mean
<b>σ:</b> population standard deviation
This tutorial explains how to calculate z-scores in SPSS.
<h3>How to Calculate Z-Scores in SPSS</h3>
Suppose we have the following dataset that shows the annual income (in thousands) for 15 individuals:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/outliersSPSS1.png">
To calculate the z-scores for each value in the dataset, click the <b>Analyze </b>tab, then <b>Descriptive Statistics</b>, then <b>Descriptives</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/zscoreSPSS1.png">
In the new window that pops up, drag the variable <b>income </b>into the box labelled Variable(s). Make sure the box is checked next to <b>Save standardized values as variables</b>, then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/zscoreSPSS2.png">
Once you click <b>OK</b>, SPSS will produce a table of descriptive statistics for your dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/zscoreSPSS4.png">
SPSS will also produce a new column of values that shows the z-score for each of the original values in your dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/06/zscoreSPSS3.png">
Each of the z-scores is calculated using the formula z = (x – μ) / σ
For example, the z-score for the income value of 18 is found to be:
z = (18 – 58.93) / 29.060 = <b>-1.40857</b>.
The z-scores for all other data values are calculated in the same manner.
<h3>How to Interpret Z-Scores</h3>
Recall that a z-score simply tells us how many standard deviations away a value is from the mean. A z-score can be positive, negative, or equal to zero:
A <b>positive z-score</b> indicates that a particular value is greater than the mean.
A <b>negative z-score</b> indicates that a particular value is less than the mean.
A <b>z-score of zero</b> indicates that a particular value is equal to the mean.
In our example, we found that the mean was 58.93and the standard deviation was 29.060.
So, the first value in our dataset was 18, which had a z-score of (18 – 58.93) / 29.060 = <b>-1.40857</b>. This means that the value “18” is 1.40857 standard deviations <b>below </b>the mean.
Conversely, the last value in our data was 108, which had a z-score of (108 – 58.93) / 29.060 = <b>1.68845</b>. This means that the value “108” is 1.68845 standard deviations <b>above </b>the mean.
<h2><span class="orange">Z Table</span></h2>
The table below shows the area under the standard normal curve to the left of z.
  
  
<h2><span class="orange">How to Perform One Sample & Two Sample Z-Tests in Excel</span></h2>
A <b>one sample z-test</b> is used to test whether a population mean is significantly different than some hypothesized value.
A <b>two sample z-test</b> is used to test whether two population means are significantly different from each other.
The following examples show how to perform each type of test in Excel.
<h2>Example 1: One Sample Z-Test in Excel</h2>
Suppose the IQ in a population is normally distributed with a mean of μ = 100 and standard deviation of σ = 15.
A scientist wants to know if a new medication affects IQ levels, so she recruits 20 patients to use it for one month and records their IQ levels at the end of the month.
We can use the following formula in Excel to perform a one sample z-test to determine if the new medication causes a significant difference in IQ levels:
<b>=Z.TEST(A2:A21, 100, 15)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/zExcel1.png">
The one-tailed p-value is <b>0.181587</b>. Since we’re performing a two-tailed test, we can multiply this value by 2 to get p = <b>0.363174</b>.
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis.
Thus, we conclude that the new medication does not significantly affect IQ level.
<h2>Example 2: Two Sample Z-Test in Excel</h2>
Suppose the IQ levels among individuals in two different cities are known to be normally distributed each with population standard deviations of 15.
A scientist wants to know if the mean IQ level between individuals in city A and city B are different, so she selects a  simple random sample  of  20 individuals from each city and records their IQ levels.
The following screenshot shows the IQ levels for the individuals in each sample:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/zExcel2.png">
To perform a two sample z-test to determine if the mean IQ level is different between the two cities, click the <b>Data</b> tab along the top ribbon, then click the <b>Data Analysis</b> button within the <b>Analysis</b> group.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see <b>Data Analysis</b> as an option, you need to first  load the Analysis ToolPak  in Excel.
Once you click this button, select <b>z-Test: Two Sample for Means</b> in the new window that appears:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/zExcel3.png">
Once you click <b>OK</b>, you can fill in the following information:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/zExcel6.png">
Once you click <b>OK</b>, the results will appear in cell E1:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/09/zExcel7.png">
The test statistic for the two sample z-test is <b>-1.71817</b>and the corresponding p-value is <b>.085765.</b>
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis.
Thus, we conclude that the mean IQ level is not significantly different between the two cities.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common statistical tests in Excel:
 How to Conduct a One Sample t-Test in Excel 
 How to Conduct a Two Sample t-Test in Excel 
 How to Conduct a Paired Samples t-Test in Excel 
 How to Perform Welch’s t-Test in Excel 
<h2><span class="orange">How to Perform One Sample & Two Sample Z-Tests in R</span></h2>
You can use the <b>z.test()</b> function from the <b>BSDA</b> package to perform one sample and two sample z-tests in R.
This function uses the following basic syntax:
<b><span>z.test(x, y, alternative='two.sided', mu=0, sigma.x=NULL, sigma.y=NULL,conf.level=.95)
</b>
where:
<b>x</b>: values for the first sample
<b>y</b>: values for the second sample (if performing a two sample z-test)
<b>alternative</b>: the alternative hypothesis (‘greater’, ‘less’, ‘two.sided’)
<b>mu</b>: mean under the null or mean difference (in two sample case)
<b>sigma.x</b>: population standard deviation of first sample
<b>sigma.y</b>: population standard deviation of second sample
<b>conf.level</b>: confidence level to use
The following examples shows how to use this function in practice.
<h2>Example 1: One Sample Z-Test in R</h2>
Suppose the IQ in a certain population is normally distributed with a mean of μ = 100 and standard deviation of σ = 15.
A scientist wants to know if a new medication affects IQ levels, so she recruits 20 patients to use it for one month and records their IQ levels at the end of the month.
The following code shows how to perform a one sample z-test in R to determine if the new medication causes a significant difference in IQ levels:
<b>library(BSDA)
#enter IQ levels for 20 patients
data = c(88, 92, 94, 94, 96, 97, 97, 97, 99, 99,
         105, 109, 109, 109, 110, 112, 112, 113, 114, 115)
#perform one sample z-test
z.test(data, mu=100, sigma.x=15)
One-sample z-Test
data:  data
z = 0.90933, p-value = 0.3632
alternative hypothesis: true mean is not equal to 100
95 percent confidence interval:
  96.47608 109.62392
sample estimates:
mean of x 
   103.05 
</b>
The test statistic for the one sample z-test is <b>0.90933</b> and the corresponding p-value is <b>0.3632</b>.
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis.
Thus, we conclude that the new medication does not significantly affect IQ level.
<h2>Example 2: Two Sample Z-Test in R</h2>
Suppose the IQ levels among individuals in two different cities are known to be normally distributed each with population standard deviations of 15.
A scientist wants to know if the mean IQ level between individuals in city A and city B are different, so she selects a  simple random sample  of  20 individuals from each city and records their IQ levels.
The following code shows how to perform a two sample z-test in R to determine if the mean IQ level is different between the two cities:
<b>library(BSDA)
#enter IQ levels for 20 individuals from each city
cityA = c(82, 84, 85, 89, 91, 91, 92, 94, 99, 99,
         105, 109, 109, 109, 110, 112, 112, 113, 114, 114)
cityB = c(90, 91, 91, 91, 95, 95, 99, 99, 108, 109,
         109, 114, 115, 116, 117, 117, 128, 129, 130, 133)
#perform two sample z-test
z.test(x=cityA, y=cityB, mu=0, sigma.x=15, sigma.y=15)
Two-sample z-Test
data:  cityA and cityB
z = -1.7182, p-value = 0.08577
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -17.446925   1.146925
sample estimates:
mean of x mean of y 
   100.65    108.80
</b>
The test statistic for the two sample z-test is <b>-1.7182</b> and the corresponding p-value is <b>0.08577</b>
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis.
Thus, we conclude that the mean IQ level is not significantly different between the two cities.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common statistical tests in R:
 How to Perform a One Proportion Z-Test 
 How to Perform a Paired Samples t-test in R 
 How to Perform Welch’s t-test in R 
<h2><span class="orange">How to Perform One Sample & Two Sample Z-Tests in Python</span></h2>
You can use the <b>ztest()</b> function from the  statsmodels  package to perform one sample and two sample z-tests in Python.
This function uses the following basic syntax:
<b><span><span>statsmodels.stats.weightstats.<span>ztest<span>(<em><span><span>x1</em>, <em><span><span>x2<span><span>=<span><span>None</em>, <em><span><span>value<span><span>=<span><span>0)</em>
</b>
where:
<b>x1</b>: values for the first sample
<b>x2</b>: values for the second sample (if performing a two sample z-test)
<b>value</b>: mean under the null (in one sample case) or mean difference (in two sample case)
The following examples shows how to use this function in practice.
<h3>Example 1: One Sample Z-Test in Python</h3>
Suppose the IQ in a certain population is normally distributed with a mean of μ = 100 and standard deviation of σ = 15.
A researcher wants to know if a new drug affects IQ levels, so he recruits 20 patients to try it and records their IQ levels.
The following code shows how to perform a one sample z-test in Python to determine if the new drug causes a significant difference in IQ levels:
<b>from statsmodels.stats.weightstats import ztest as ztest
#enter IQ levels for 20 patients
data = [88, 92, 94, 94, 96, 97, 97, 97, 99, 99,
        105, 109, 109, 109, 110, 112, 112, 113, 114, 115]
#perform one sample z-test
ztest(data, value=100)
(1.5976240527147705, 0.1101266701438426)
</b>
The test statistic for the one sample z-test is <b>1.5976</b> and the corresponding p-value is <b>0.1101</b>.
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis. In other words, the new drug does not significantly affect IQ level.
<h3>Example 2: Two Sample Z-Test in Python</h3>
Suppose the IQ levels among individuals in two different cities are known to be normally distributed with known standard deviations.
A researcher wants to know if the mean IQ level between individuals in city A and city B are different, so she selects a  simple random sample  of  20 individuals from each city and records their IQ levels.
The following code shows how to perform a two sample z-test in Python to determine if the mean IQ level is different between the two cities:
<b>from statsmodels.stats.weightstats import ztest as ztest
#enter IQ levels for 20 individuals from each city
cityA = [82, 84, 85, 89, 91, 91, 92, 94, 99, 99,
         105, 109, 109, 109, 110, 112, 112, 113, 114, 114]
cityB = [90, 91, 91, 91, 95, 95, 99, 99, 108, 109,
         109, 114, 115, 116, 117, 117, 128, 129, 130, 133]
#perform two sample z-test
ztest(cityA, cityB, value=0) 
(-1.9953236073282115, 0.046007596761332065)
</b>
The test statistic for the two sample z-test is <b>-1.9953</b> and the corresponding p-value is <b>0.0460</b>.
Since this p-value is less than .05, we have sufficient evidence to reject the null hypothesis. In other words, the mean IQ level is significantly different between the two cities.
<h2><span class="orange">The Difference Between Z-Values and P-Values in Statistics</span></h2>
Two terms that students often get confused in statistics are <b>z-values</b> and <b>p-values</b>.
To understand the difference between these terms, it helps to understand <b>z-tests</b>.
There are two common types of z-tests:
<b>One-sample z-test</b>: Used to test whether a population mean is equal to some value.
<b>Two-sample z-test</b>: Used to test whether two population means are equal.
We use the following steps to perform each test:
<b>Step 1:</b> State the null and alternative hypothesis.
<b>Step 2:</b> Calculate the z-value.
<b>Step 3:</b> Calculate the p-value that corresponds to the z-value.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/zp1.jpg">
For each test, the <b>z-value</b> is a way to quantify the difference between the population means and the <b>p-value</b> is the probability of obtaining a z-value with an absolute value at least as large as the one we actually observed in the sample data if the null hypothesis is actually true.
If the p-value is less than a certain value (e.g. 0.05) then we  reject the null hypothesis  of the test.
For each type of z-test, we’re interested in the <b>p-value</b> and we simply use the <b>z-value</b> as an intermediate step to calculating the p-value.
The following example shows how to calculate and interpret a z-value and corresponding p-value for a two-sample z-test.
<h2>Example: Calculate & Interpret Z-Values and P-Values</h2>
Suppose the IQ levels among individuals in two different cities are known to be normally distributed each with population standard deviations of 15.
A scientist wants to know if the mean IQ level between individuals in city A and city B are different, so she selects a  simple random sample  of  20 individuals from each city and records their IQ levels:
<b>City A</b>: 82, 84, 85, 89, 91, 91, 92, 94, 99, 99, 105, 109, 109, 109, 110, 112, 112, 113, 114, 114
<b>City B</b>: 90, 91, 91, 91, 95, 95, 99, 99, 108, 109, 109, 114, 115, 116, 117, 117, 128, 129, 130, 133
Here’s how to perform a two-sample z-test using this data:
<b>Step 1: State the null and alternative hypothesis.</b>
First, we’ll state the null and alternative hypotheses:
<b>H<sub>0</sub>: </b>μ<sub>1</sub> = μ<sub>2</sub> (the two population means are equal)
<b>H<sub>1</sub>: </b>μ<sub>1</sub> ≠ μ<sub>2</sub> (the two population means are not equal)
<b>Step 2: Calculate the z-value.</b>
Next, we’ll perform a  two-sample z-test in Excel  using this data and find that the z-value is <b>-1.71817</b>.
<b>Step 3: Calculate the p-value.</b>
We can use the  Z Score to P Value Calculator  to find that the p-value that corresponds to a z-value of -1.71817 is <b>.08577.</b>
Since this p-value is not less than .05, we do not have sufficient evidence to reject the null hypothesis.
Thus, we conclude that the mean IQ level is not significantly different between the two cities.
Notice that we simply used the z-value as an intermediate step to calculating the p-value.
The p-value is the true value that we were interested in, but we had to first calculate the z-value.
<h2>Additional Resources</h2>
The following tutorials explain how to perform z-tests using various statistical software:
 How to Perform Z-Tests in Excel 
 How to Perform Z-Tests in R 
 How to Perform Z-Tests in Python 
<h2><span class="orange">What is Zero-Order Correlation?</span></h2>
In statistics, the <b>correlation </b>between two variables tells us about the relationship between those two variables.
One of the most basic types of correlation is known as <b>zero-order correlation</b>, which refers to the correlation between two variables without controlling for the possible influence of other variables.
One example of this type of correlation is the  Pearson Correlation Coefficient , which measures the linear association between two variables and can take on values between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
The further away the correlation is from zero, the stronger the association between the two variables.
<h3>First-Order and Second-Order Correlations</h3>
If we calculate the correlation between two variables A and B while controlling for the influence of a third variable C, we would refer to the correlation between A and B as a <b>first-order correlation</b>.
Similarly, if we calculate the correlation between two variables A and B while controlling for the influence of variables C and D, we would refer to the correlation between A and B as a <b>second-order correlation</b>.
<h3>Example of Zero-Order Correlation</h3>
Suppose we have the following dataset that shows the number of hours spent studying and the exam score received by 10 different students:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/zeroOrderCorrel1.png">
It turns out that the correlation between these two variables is <b>0.762</b>. This would be considered the <b>zero-order correlation </b>between the two variables because we aren’t controlling for the potential influence of a third variable.
However, in reality it’s possible that other factors could affect the relationship between these two variables.
For example, perhaps the student’s current grade in the class has an effect on their exam score. Suppose we had access to this data as well:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/zeroOrderCorrel2.png">
If we then calculated the correlation between hours and exam <em>while controlling for the effect of current grade</em>, we’d find that the <b>first-order correlation</b> between hours and exam is <b>0.578</b>.
This means there is still a fairly strong positive correlation between hours studied and exam score received even after controlling for the effect of the student’s current grade in the class.
<b>Note: </b>First-order correlation is sometimes referred to as partial correlation.  This tutorial  explains how to calculate partial correlations in Excel.
<h3>Zero-Order Correlations in a Correlation Matrix</h3>
Whenever we create a  correlation matrix  for a set of variables, the correlation coefficients shown within the matrix are always zero-order correlations because they’re simply the correlations between each pairwise combination of variables without considering the influence of any other variables.
For example, consider our dataset from the previous example:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/zeroOrderCorrel2.png">
If we created a correlation matrix for this dataset, it would look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/zeroOrderCorrel3.png">
The way to interpret this is as follows:
The correlation between current grade and hours studied is <b>0.689</b>.
The correlation between current grade and exam score received is <b>0.637</b>.
The correlation between hours studied and exam score received is <b>0.762</b>.
Each of these correlations is a <b>zero-order correlation</b>.
<h2><span class="orange">How to Zip Two Lists in Python</span></h2>
Often you might be interested in zipping (or “merging”) together two lists in Python. Fortunately this is easy to do using the zip() function.
This tutorial shows several examples of how to use this function in practice.
<h3>Example 1: Zip Two Lists of Equal Length into One List</h3>
The following syntax shows how to zip together two lists of equal length into one list:
<b>#define list a and list b
a = ['a', 'b', 'c']</b>
<b>b = [1, 2, 3]
#zip the two lists together into one list</b>
<b>list(zip(a, b))
[('a', 1), ('b', 2), ('c', 3)]
</b>
<h3>Example 2: Zip Two Lists of Equal Length into a Dictionary</h3>
The following syntax shows how to zip together two lists of equal length into a dictionary:
<b>#define list of keys and list of values 
keys = ['a', 'b', 'c']
values = [1, 2, 3]
#zip the two lists together into one dictionary</b>
<b>dict(zip(keys, values)) 
{'a': 1, 'b': 2, 'c': 3}
</b>
<h3>Example 3: Zip Two Lists of Unequal Length</h3>
If your two lists have unequal length, zip() will truncate to the length of the shortest list:
<b>#define list a and list b
a = ['a', 'b', 'c', 'd']</b>
<b>b = [1, 2, 3]
#zip the two lists together into one list</b>
<b>list(zip(a, b))
[('a', 1), ('b', 2), ('c', 3)]</b>
If you’d like to prevent zip() from truncating to the length of the shortest list, you can instead use the  zip_longest()  function from the <b>itertools</b> library.
By default, this function fills in a value of “None” for missing values:
<b>from itertools import zip_longest
#define list a and list b
a = ['a', 'b', 'c', 'd']</b>
<b>b = [1, 2, 3]
#zip the two lists together without truncating to length of shortest list</b>
<b>list(zip_longest(a, b))
[('a', 1), ('b', 2), ('c', 3), ('d', None)]
</b>
However, you can use the <b>fillvalue </b>argument to specify a different fill value to use:
<b>#define list a and list b
a = ['a', 'b', 'c', 'd']</b>
<b>b = [1, 2, 3]
#zip the two lists together, using fill value of '0'</b>
<b>list(zip_longest(a, b, fillvalue=0))
[('a', 1), ('b', 2), ('c', 3), ('d', 0)]
</b>
<em>You can find the complete documentation for the zip_longest() function  here .</em>

<script src='https://williamkpchan.github.io/LibDocs/readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>
