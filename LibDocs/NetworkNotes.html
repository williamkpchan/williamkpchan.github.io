<base target="_blank"><html><head><title>Network Notes</title>
<meta http-equiv="Content-Type" content="tex沐舒坦mustt/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@13.0.1/dist/lazyload.min.js"></script>
<script type='text/javascript' src='../mainscript.js'></script>
<script>
  var showTopicNumber = true;
  var bookid = "Network Notes" 
</script>
<style>
body{width:80%;margin-left: 10%; font-size:22px;}
h1, h2 {color: gold;}
strong {color: orange;}
img {max-width:90%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>Network Notes</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a>
<br><br>
<div id="toc"></div></center>
<br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br>
<a href="https://stevessmarthomeguide.com/" class="whitebut ">Smart Home Networking Guide</a>
<a href="https://www.youtube.com/watch?v=1nRyrDGyAbI" class="whitebut ">更快的網路速度技巧</a>

<a href="https://www.youtube.com/watch?v=5a5tdJh8mKY" class="whitebut ">Oracle Cloud—for free tutorial</a>

<a href="https://www.oracle.com/hk/cloud/free/" class="whitebut ">Oracle Cloud—for free.</a>

<a href="https://www.youtube.com/watch?v=X9sexl1wXyE" class="whitebut ">永久免费的甲骨文云服务器该</a>
K..Oracle!

<a href="http://www.5gaia.org.cn/BloomingCup/Home" class="whitebut ">绽放杯 5G应用</a>

<a href="https://www.youtube.com/watch?v=ZPi56hSm__E" class="whitebut ">全局上网 Proxifier+Trojan</a>
<a href="https://wp.for-get.com/564.html" class="whitebut ">全局上网</a>

<a href="https://mp.weixin.qq.com/s/X-xF2JR3g7x33pW_7EiBkg" class="whitebut ">Nginx 可视化配置工具</a>

<a href="https://www.guru99.com/best-free-proxy.html" class="whitebut ">Proxy Server Service</a>

<a href="https://www.youtube.com/watch?v=-cRMD40Se80" class="whitebut ">Xender 無線傳輸APP</a>
<a href="https://www.youtube.com/watch?v=156s1hphwHg" class="whitebut ">免費創建自己的私人云盤</a>
<a href="https://www.youtube.com/watch?v=O4Y6UXjVlFQ" class="whitebut ">隱藏自己真實的IP地址5種方法</a>
<pre>

/F现代化智慧渔港，赋能海上执法管控
700M 零信任架构的关键信息基础设施安全管控系统
700M+900M的专网助力乌兰集团煤矿安全高效生产
700MHz与2.6GHz 融合组网的石化工业互联网应用
700M专网的海上智慧风电
AI智慧养殖平台
AR/VR红旗渠精神研学营地
AR实景导航在医疗行业的应用
AR眼镜，开拓行业新世代
C-V2X车联网，让人民生活更幸福
CBA体育赛事VR直播和体验
CIM的住建领域应用创新
eVPN技术实现固定IP通信的边缘计算网关
HIFIVE音乐开放平台
L2层实现全国跨域快速接入的-商企专网
LAN设备点控大大降低远程手术机器人时延
MEC+元宇宙释放消费新活力，加快建设全国统一大市场
MEC+区块链构建的广州市第一人民医院高水平智慧医院体系
MEC+数字孪生的广东智慧河长
MEC助力三峡集团打造国内首个大型绿色零碳数据中心
MEC打造金融行业智慧金库
MEC的双园区离散制造企业应用实践
MEC的规模应用引领家电产业链协同转型
MEC行业专网赋能新疆“丝路智港”全面升级
MEC赋能智慧校园
MEC赋能武汉市桥梁智慧管理
MEC边缘计算在唐山河钢乐钢的应用
NanoAR© ： 透明高清和AR显示的革命技术
OneBox 工业网关
OneLink 连接管理通用平台
OneMO工业互联网行业模组
OneNET城市物联网平台
OPPO柔性全连接智慧工厂
PCB智能工厂场景化解决方案
PLC边缘控制网关
R16的 LAN网关
Rokid 版AR眼镜
SUL和 NTN在海空通航运营的应用
TICloud全新技术，打造山东样板智慧化工园区
UIS不间断网关 助力人人享有连接
UPF+ 赋能新时代煤矿安全高效
V2X车规级模组
WEB3.0纺织产业互联网新模态
XR赋能南航智慧维修创新实践工程
X赋能三代核电规范建设与安全运营
ZTE XRExplore
“下井”，智慧煤矿“升级”
“功夫+智慧”开启少林
“北斗”智慧农业示范应用
“无人机”云网边端解决方案
“智能建造”虚拟仿真实训场景应用
“绿色智造，洁净生产”智慧钢铁创新港
“老师傅”重焕新活力-郑州瑞泰智慧工厂
“花园模式”创先锋 助推实施数字乡村战略
“虚拟与现实的融合”——在线教育元宇宙创新实践
“行业虚拟专网”实现宜宾三江新区车路协同智慧接驳、智慧物流示范应用
“让梦走得更远”—携手广汽本田共赴匠心智造新征程
ⁿ智慧塔吊引领山西建投绿色发展之路
《谍影成双》互动影游项目 序号 项目编号 项目名称
一体化移动智慧口腔医疗服务助力健康新农村
一体构架的专网创新实践
一汽-大众汽车生产能源与节能 左志军
一种基于的CPE+调度控制器产品在专线抢修及开通中的应用
一部手机趣旅行，信息助推全域旅游示范县乡村振兴(青川县4A级青溪古城提升项目)
一隅千象：元宇宙裸眼混合现实交互
万兆光网双核驱动煤矿安全生产
万华禾香板业智慧工厂
万物互联 智管全城—助力城市“一网统管”
三山岛金矿智慧矿山
专科联盟建设
东平县盛鑫铁矿智慧矿山
东源县 OnePARK   智慧园区
东莞市公安局“辅警通”智慧执法
东莞新沙港智慧港口
东风日产数字智能化设备生产系统
中交四航局首个全球智慧工地指挥调度平台
中原内配工厂数字化生产新基石
中原智行智行网联云控平台
中国电信固移融合网关
中国石油锦州石化公司智慧石化
中国移动专网运营平台
中国移动全国产化通用模组
中国移动医疗行业模组应用与解决方案
中国移动煤矿行业通信模组
中国移动物联卡风险防控平台
中国联通物联网智连连接管理平台
中国联通物联网格物设备管理平台
中国联通自主品牌终端 CPE VN007+
中国联通雁飞 CPE
中国联通雁飞工业CPE
中国联通雁飞智能网关助力油田数智化转型
中国银行股份有限公司消息
中天科技工业互联网能源管控示范基地
中广核大亚湾核电智慧核电创新应用
中广核智慧核电应用
中石化胜利油田智能油田联合创新应用
中药产业数字化转型升级
中骏世界城室分地下北斗定位
丰县师寨镇东渡希望初级中学桌面云
为乡村插上共富翅膀，促进产业振兴
乐活岛打造新型社交生态圈
乡镇“赤脚医生”的云巡诊包创新应用
云边协同下全生命周期的数智医疗应用
云边协同的多院区智慧PICU 一体化平台
云边协同的新一代智慧医院基础设施云平台
云边端的智慧娱乐
京东智慧物流园
人工智能在智慧物业服务运营场景的创新应用
仁和化工园“双碳”智慧园区，搭建“化学家创新创业平台”
以MEC+校园专网多云能力，打造山东“三个课堂”信息化改革创新示范
企业外网基础服务平台
伺服电机智能生产线
低空智联网及飞控平台
余东镇数字化智慧农场
佛山市乡村振兴示范
供水-助力百年水司出新出彩
便携式随行热点&MiFi终端
保险系统
信发集团构建产业融合创新实践
停车赋能上蔡县停车管理转型升级
健力宝“现场、现物、现实“管理和人工智能视觉质检建设
元宇宙才艺社交
元宇宙掌上一体机
元宇宙社交沉浸娱乐平台
光伏村
光威渔具工业互联网平台
克拉玛依百口泉智慧油田
兖州区社会治理大数据平台
党建引领基层治理网格化信息系统
全国蔬菜质量标准中心AI智慧农业示范
全流程数据采集的船舶工业智能平台
全面赋能智慧工地,为安全保驾护航
公交三维动态巡视系统
公共卫生防控
公共文化云,赋能乡村文化振兴
公证链执法仪
兰州石化榆林化工智慧化工
养殖助力阳澄湖大闸蟹标准化生产
农业产业园番茄种植
农业硅谷—浦口国家农创中心
农业种植助力乡村振兴
农产品全程可信溯源
凉山州青花椒现代农业园区
凉山精准养殖科研基地建设
出行新开始，MEC助力车路协同建设
分布式光伏大规模推进的应用实践
分布式光伏数字化升级
切片+TETRA融合实现关键通信高质量应用
切片技术的未来电力变革
切片的远程医疗技术
创新产品实践
利用技术打造国星光电新一代智能制造工厂
加油机税控 助力智慧税务建设
加速新郑煤电智慧化矿山发展
助力废钢智能判级技术演进
化工行业智慧化转型
化工行业生产更绿色、更安全、更高效
化零碎为统一 ——以物联优化能源管理
北京市属公园智慧游园新态势
北斗的“空天地”三位一体智慧林业管理示范应用
北斗的电力作业现场智能管控系统
北斗融合数字孪生赋能山东水利安澜
北斗高精度定位的农发集团无人农场
区块链一体机：让上链更简单，让信息更安全
区域“海陆空”一体化急诊急救平台
区域工业云推动区域经济结构调整
医学影像互认云服务平台
医护场景的实践
医疗急救新模式
医院应用
医院运营管理系统（HOMS）平台
千兆赋能大运河数字航道
千岛湖月光群岛“月光之恋”沉浸式农旅融合促共富
华侨城集团AI技术的多业态数据管理平台
华勤云化智慧能耗管理云平台
华北电力大学零碳校园智慧能源
华欣环保钢渣处理天车智能化
华能山东石岛湾核电“智慧电厂”
华腾未来数字牧场
华茂陶瓷智慧工厂
南方海洋科学与工程广东省实验室（珠海）移动网络建设
南方电网（汕头）配网自动化
南通海安凤山村新通扬河滨河风光带打造
博物馆，BIM加持启新篇
博鳌东屿岛车联网
卫棉集团智慧纺织工厂
印染行业智脑平台建设
县域自然资源防护平台
双千兆助力永联村“种好”乡村振兴“示范田”
双域专网的油气开采智慧测井
双碳形势下智慧能源助力盐化工产业园节能发展
双碳智慧公共建筑监管平台
台州市未来乡村建设
叶集智慧党校专网
合肥滨湖国际会展中心智慧工地
同一条河
唐山首钢京唐智慧钢铁
唐闸古镇乡村智慧文旅
嘉陵江亭子口水利枢纽智慧电站
四信F-SC241和F-NVR1105的视频监控系统
固移融合医疗专网
国内首个多式联运智慧港口
国家高原云果产业园智慧农业
国电联合动力双碳平台
国网新源控股集团山东沂蒙抽水蓄能发电站专网
国网电力 虚拟专网
国网电力分布式光伏云网新飞跃
国网电力鞍山公司菱镁工业互联网示范性
国网辽宁阜新“能源互联网小镇”示范
国能黄金埠智慧火力电厂
城建中的创新应用
培育AI互动空间
基因测序助力乡村健康
塔里木河河湖长制的探索与实践
多DNN技术的多通道接入 CPE产品
多功能智能杆构建深圳智慧城市“神经元大脑”
多氟多傲立氟化工国际舞台
多类型机器人联合巡检助力能源行业转型升级
大数据养虾管理平台
大数据分析赋能分布式光伏电站“智能云运维”
大数据打造更加精细智能化农业
大数据的智慧渔业水产种业研究
大时代来临，乡村焕然N新
大湾区智慧虚拟法庭和区块链物证系统建设
大禹“智”水-水务集团云网协同智慧“jie”水
大象智慧文旅，让文旅走进每一家
大足区国家数字乡村试点项目 15（并列）
天中高标准农田，农民挑上“金扁担”
奇瑞一路捷途
妇幼手拉手工作平台
媒制播
宁德时代灯塔工厂
宁津县天空地一体化乡村振兴建设
宁阳化工产业园有毒气体智能监控云平台
宇通智慧环卫 助力智慧城市建设
守护长三角“白菜心”智慧
安全专网的AI智能信息播报系统
安全生产，领航矿业新征程
安全认证的电力虚拟专网与智能电网全业务深度融合
完善农业物联网管理体系，提升农业专家服务
定制专网的河南中烟智能检测创新实践
实景化房屋质量风险评估
富士康——核心网下沉的“芯”工厂
富士康柔性“智”造释放生产力
屋顶智慧光伏
山东东营联通智慧城市建设
山东大学教育新基建助力构智慧教育新生态
山东工商学院绿色能源校园
山东正凯新材料园区 工业场景应用
山东港口集团日照港智慧港口园区
山东港口集团青岛港 LAN在多AGV调度等场景的应用
山东省临沂大学智慧校园
山东省京博控股集团定制网
山东胜利职业学院虚拟实训
山东西曼克技术有限公司智慧园区
山东首家 VR线上智慧法院
山东鲁西化工集团智慧炼化专网应用
山东龙口裕龙石化工业园智慧园区
山窝里下金蛋—基于的蛋鸭智慧养殖
山钢莱芜分公司智慧冶金
山钢集团板带厂1500mm宽带生产线智能无人库区
岸电清洁能源
峄城峨山智慧化工园区
工业智能终端MX880
工业机器控制
工业级室外CPE 赋能垂直行业
工业网关
工业自然导航AGV，赋能行业、协同高效
工业行业的通用DTU
工业路由器
工业路由器F-NR100
工地筑造新未来
常州市长江流域禁捕退捕信息化防控
平高电气依托网络打造虚拟电厂
广东海上风电创新
广东电网有限责任公司广州供电局基建工程通信技术研究及应用
广东省中建三局华南公司保利广钢新城智慧工地
广东省佛山市智能家居产业集群工业互联网示范
广东省西可通信工业互联网智能制造应用
广东移动海上宽带赋能智慧海洋
广东韶关钢铁电信定制网产品
广和通模组FM160的四信F-NR130全面赋能工业物联
广州市黄埔区基于的城市公共交通智慧云脑应用示范
广州方舱医院智慧防疫一体化
广汽丰田铸就全价值链数字化工厂
库卡机器人智能生产
应急互助信息服务
应急总医院基于专网的应急救治体系应用实例
应急通信指挥平台，应急救援新力量
应用的工业互联网标识解析二级节点
建筑质量安全管理系统
建设演示机智慧运营平台推进管理创新提质增效
徐州市农业农村局物联网智能化调度系统服务
德州大运河德城段文旅融合全域旅游
德州小森精工智能制造运营管理服务车间建设
德州市北斗+AICDE的国省道公路信息数字化孪生
德州移动远程医疗应用平台
心连心园区管理“智慧化”
思克奇食品科技（山东）有限公司智慧工厂
成就哈尔滨工程大学跨校区一体化智慧校园
成武县人民医院专网+医共体+医疗应用
扬帆“十大数智应用”，启航羊城智慧安全城市
扬帆十大数智应用，启航羊城智慧城市服务
技术实现预警防灾场景必达消息
技术的数字孪生交通仿真系统
拓普泰尔RG2000
改性塑料智能生产车间示范
政务随行专网的数字政府智慧应用
教培实验室赋能人才培养
数字一汽管理、生产全流程创新探索与实践
数字乡村，共展乡村美丽画卷
数字化连接工厂，助力企业数字化腾飞
数字孪生智慧矿山
数字孪生的盾构智慧园区
数字孪生的综合掘进机器人应用 -三等奖名单- （30个，排名不分先后） 项目编码 项目名称
数字律证保险箱
数字赋能 开启化工智慧巡检新时代
数字驾驶舱载着一方百姓驶向富裕
数字高速与济青中线高速全场景融合实践
数智双柏生态振兴
数智混动，筑造城管壁垒
数智赋能一池春水—泗阳县国家数字水产试点基地
数智转型新引擎
数智鸬鸟:创乡村振兴标杆示范
文旅开放平台，助力河南文旅高质量发展
文旅行业的三维数字展览应用实践
新乡移动鼎力智能管控升级改造
新农村综合服务平台
新型政务外网助力山东数字政府智能化发展
新型高标准农田助力农户“旱涝保收”
新旧动能转换
新材料产业园区发展
新能源新工厂，新新未来
新金融发展
施工远程协作监管助力建筑业复工复产
施耐德多园区协同专网应用
无人养殖场试点基地建设
无人农机在乡村振兴项目中的应用
无人机的输电线路点云数据实时处理
无人电机车把握山东能源临沂会宝岭铁矿智慧矿山新机缘
无人驾驶农机作业平台
无介质全息 虚拟与现实的交互
无锡市滨湖区农业大数据平台
日照汇丰电子有限公司机器视觉
日照港建设国际一流港口
时代 ，Rokid让美好生活更具“智”感
时尚女装“1天下货”生产模式
明珞数字制造与工业互联网全球总部项目-以工业互联网赋能汽车制造产业集群
智作系统开创融媒新未来
智影-云端智能视频创作平台
智慧医院，提升患者就诊体验
智慧生态环境监测应用
智慧高速建设管理平台应用
智绘乡村新画卷-实践“乡村振兴”新方案
智联高标准农田，“建管营一体化”打造数智化新粮仓
智能农业园区应用
智能化房屋安全综合管理平台
智能化，打造智慧教学新模式
智能客服
智能巡检机器人
智能巡检车赋能智慧工程巡检
智能智联  助力中国汽车零部件行业数字化转型
智能模组SRM815
智能矿山
智能计量仪表工业互联网平台赋能新天科技智能制造与服务新模式
智能车联网技术研究及科技冬奥创新应用示范
智能边缘计算产品
智造“伯乐慧眼”，助力消除城市“顽疾”
服务乡村振兴的现代农业虚拟仿真职业教育共享示范基地
服务机器人
未来创新实验室，科技为教育赋能
机器人楼宇服务专家
机器视觉产品外观缺陷检测应用
机器视觉技术在玉米油产业的应用
机场应用示范
机械加工转型升级
极氪汽车迈入未来工厂
构建“平台”乡村产品体系，打造乡村治理新模式
构建多维度疫情防控体系，筑牢公共卫生“力量大厦”基石
构建数智化建筑工地
构建的智慧供水运营管理系统
构筑食品安全防火墙 撑起健康生活保护伞
果园，助推乡村振兴高质量发展
枣庄市市中区水处理剂产业园有毒有害气体环境风险预警
枣庄市立医院专网+智慧云医院
枣庄科技职业学院基于双域专网的校园数据大脑融合创新应用
柑橘农业
校园安防
校园电视台打造智慧家校应用 三等奖获奖名单 （排名不分先后，以项目编号为序） 项目编号 项目名称
校园虚拟专网助力高校智慧教育新突破
校园虚拟专网的示范应用实践
格创智慧能源管理
森林河南生态文明建设
民航领域车路协同及自动驾驶试点示范
水利全感知赋能千秋古堰焕新机，助力都江堰灌区“四预”智慧管理新突破
水务低碳转型，实现成都天府新区下沉式水厂数智化、精细化管理升级
水泥
水质在线监测保护乡村绿水长流
汇丰石化智慧炼厂
汇川技术专网及工业互联网创新应用
汇川技术虚拟专网赋能智能智造
江苏三仓农业现代产业园智慧农业
江苏南沈灶智慧农业
江苏智慧高标准农田建设
江苏省溧水农白马镇农高区数字乡村区块链
江阴乡村教育全场景互动教学
汽车制造供应链创新融合应用
河南利源智慧工厂，树立焦化行业标杆
河南省域电力虚拟专网，构建“源网荷储”友好互动的新型电力系统
河南省生态环境无人机执法
河南航天室内外安全可信无人运输
河南警察学院VR省域互联训练系统
河钢唐钢专网应用建设
河长制平台打造秀美河湖，助力乡村振兴
油气装备行业新生
泛在物联的精细化医院管理
泛在高可靠 UIS CPE  倾“芯”赋能数智化
泛智能园区标准产品
泰兴市黄桥镇智慧农业产业园区建设
泰安中联水泥智慧矿山
泰安市中心医院专网智慧医院
泰安市智慧城市应急指挥平台
泰豪VR社交游戏平台 《34空间站》
洛宁县马店镇关庙村 “智慧果园”建设
洛阳智慧河湖
济南新航实验外国语学校智慧校园
济宁市新材料产业园区智慧园区
济宁市金桥煤矿智慧矿山
济宁能源发展集团专网赋能高质量能源集团
济宁能源发展集团智慧能源
济宁艾坦姆合金有限公司智慧工厂
浙里人家，诗画乡村，匠心塑造“诗画浙江大花园最美核心区
海上智慧数字油田建设
海上智慧油田升级
海上风电创新性应用
海上风电北斗一体化立体空间资源应用
海关监控指挥
海南昌江核电厂生产无线网络
海天产品全链条质量智控
海尔日日顺中德智慧园区
海岛双域乡村旅游
海洋渔业空天地海一体化网络信息服务
海虞优质稻米高质量发展示范区 二等奖获奖名单 名次 项目编号 项目名称
海陆油田全业务联合创新应用
消息在电力服务中的应用
消防应急智会系统云平台
润扬大桥智慧管理应用
淄博齐鲁石化智慧化工园区
深圳地铁数字化转型基于技术的探索与实践
深圳大学算力网络构建的国家级半导体材料虚拟仿真实验互动教学示范
深圳招商智慧园区建设与实践
深圳智慧城市新示范
深圳蓝谷“行业虚拟专网”在智慧海洋牧场领域的应用
混合专网及自组网基站的重特大及城市消防应急救援通信系统
渔政核查核录系统
渤海科技大学智慧校园
港口
湛江化工厂专网建设
源网荷储互动的虚拟电厂助力数据中心零碳经济运行
潍坊联通智慧农业产业园
激发数智转型新动能
炼钢系统
焦作市解放区智慧社区
燃气，数字赋能城市安全保障
燃气，数字赋能城市安全保障 注：入围项目将在决赛中角逐一二等奖 三等奖获奖名单 （30个，排名不分先后） 序号 项目编号 项目名称
燃电-赋能乌沙山电厂大型斗轮机双碳技改
物业技术赋能，推动社区治理数字化
物品标识、定位芯片、运营商大数据等能力的一体化助农综合解决方案
物联时代的大国重器
物联网数字底座
物联网的无人售卖现磨咖啡机器人
玉田海泰智慧工厂应用
珠海商业园区综合体智慧系统
珠海大型桥隧交通工程建设大数据保障指挥系统
琼中黎族苗族自治县“数字乡村”建设
生态环境溯源云平台
用算力换能力分身舱带你畅游朋友圈
电力供电应用解决方案
电力系统的省域专网及示范应用
电力能源应用解决方案
电力虚拟专网安全防护体系
电力行业的通用授时终端产品应用方案
电网差动保护应用
益海嘉里智慧工厂及数字化车间
直流微电网赋能打造杭州亚运全绿电零碳示范园区
省林业局广东省林业综合服务能力建设工程——林业物联网监测管理平台
睢宁县技防村(社区)提档升级二期
石化行业的OneCyber专网平台应用
石油大学智慧校园
矿山助力中原能矿迈入4.0时代
矿山变“金山”，巩固水泥现代化生产
硬切片助力大陈岛“零碳岛”建设
硬切片赋能双碳高弹性电网
碳路先锋，智云光伏赋能广西千亿钢铁行业可持续性发展
祁连山水泥数字化矿山智能管控
种植辅助+产销一体化管理打造春秋智慧葡萄园
科大讯飞新零售智能办公终端
科技动力火力全开秦皇岛京能热电智慧发电
科技抗疫智慧防线
移动机器人Oasis 600C-
空天地一体化指挥调度系统
端网协同认证与安全通道系统  护航车联网证书下载安全
管控煤炭安全生产
红旗渠智慧旅游
纺丝全流程柔性升级
经区智慧企业用电
维尚数字化工厂
绿色移动空间
绿色高效加持智慧神华，助力“能源老大”高质量发展
网易瑶台元宇宙会议系统
网络信号质量测试及上网应用方案
美丽乡村VR名片
美育协同创新基地建设
肇庆小鹏汽车智慧工厂
胜利油田智慧油井
能力魔方，规模化发展的新路径
能源云应用助力密云区打造绿色双碳城市
能源行业大数据集控管理
能源行业的工业CPE
能源边缘计算多站合一
腾讯云创
腾讯先锋云互动数字场景创新应用
自主创新的“边缘云网一体化”智慧化工园区
自动行驶及配矿行车应用推动有色金属冶炼行业转型升级
自动驾驶的智能出行系统
自动驾驶，智能配矿行车 ——直击行业痛点，引领转型升级
自动驾驶，让生活驶上“快车道”
航油加注作业智能化创新示范
艺术文化数字化升级
苏州农业职业技术学院远程教育助力乡村振兴
茶溪川插上乡村振兴的科技翅膀
菏泽市东明县智慧城市
菏泽市定陶区医药港管理服务中心智慧园区
虚拟专网+智慧城市
虚拟专网助力高校教育发展
融合通信在应急消防领域的应用
融媒体社交融合 赋能传统媒体行业数字化升级
行业专网的“智慧金农”乡村振兴金融科技赋能
行业专网赋能齐鲁化工园区实现数字化转型
行业虚拟专网的全连接工厂示范
行李智能输送系统，助力航港再升级
装配式建筑智能制造新基建研发创新产业园
西南民族大学校园能耗智慧治理
西门子赋能智慧能源
让煤黑子焕新颜
让电厂更“聪明”更“灵动”
课堂助力教育公平，促进乡村振兴
负压救护车更安全，移动核酸车更智能-
贵州省教育资源公共服务平台
赋予园区生命 创造尼龙城无限可能
赋能LNG“工业互联网+安全生产”
赋能“利通”智造，打造螺湾“流体之都”
赋能“地下蛟龙”，大国重器再遨游
赋能“阳光政府”，打造智慧政务新标杆
赋能三代核电的安全建设
赋能乡村智慧出行
赋能交通实现无人驾驶
赋能信钢 探索钢铁行业高能效新路径
赋能农业，构建现代农业产业园
赋能助力濮阳同力升级转型
赋能区域医疗远程诊疗体系
赋能博山“一区四园”绽放新活力
赋能城市水务高品质运营应用示范
赋能山东重工高端装备制造产业链数字化升级
赋能引领中国梦，乡村振兴呼唤燕归巢
赋能政务治理，渗透抗疫最后一公里
赋能数字延伸，助力临颍乡村振兴
赋能智慧园区“新生态”
赋能智慧工厂，助推“智改数转”
赋能智慧钢铁，带动广西千亿级钢铁产业腾飞
赋能江南农村商业银行多元化融合创新应用
赋能电力智能升级，助力构建新型电力系统
赋能矿企智慧化矿山建设
赋能美丽南屯，数字引领乡村振兴
赋能耐火砖，中国耐材绿色新名片
赋能自动驾驶商用化运营实践
赋能航油安全数字化应用
赋能英皇新娱乐，绽放粤港澳大湾区新魅力
赋能郑煤机，开创“智能超级装备”的新时代
赋能钢丝绳探伤，保驾护航“生命线”
赛事风向标
赛轮集团基于的智能制造智慧生产
超便携直播盒子
超便携高性能游牧专网产品
超小尺寸可编程可快速部署行业５G数据传输终端
超级QQ秀
超级SIM和国产密码技术构建安全可控政务外网
超级物联卡
超融合专网的教管评教育生态体系
超视界云化赋能工厂
超高层建筑智慧工地多场景应用
跨境报关货物智能查验系统
跨时空视频直播
践行双碳战略，专网结合智慧应用赋能园区节能降耗
车联网的 RSU路侧单元终端产品
轻量化移动热点&dongle终端
轻量级UPF助力行业数字化转型创新探索与规模实践
辰欣药业智慧工厂
边缘AI智能终端产品
边缘智脑终端
边缘计算的工业设备故障诊断与健康管理方案
边缘计算，智慧出行管控综合解决方案
边远山区全域专递课堂-古蔺共享课堂
达能开启智慧工厂新时代
运维的轨道交通关键技术创新研究
远程病理诊断与新冠筛查服务应用及赋能
连云港东旺奶牛养殖有限公司第三养殖场牧业养殖物联网
连云港市双碳绿色农业
连接“人机料法环”生产要素，全连接平台助力数字制造
连海平 应用共潮生
连海平 应用共潮生 二等奖获奖名单 序号 项目编号 项目名称
通信资源深度共享，推动智能电网建设 项目编号 项目名称
通则康威 工业路由器ZLT IR101
通用型 CPE产品应用方案
邳州市乡村振兴村级电商综合运营平台服务
郑州大学“新生态智慧校园”的探索与实践
郑州轨道交通高位智能视频监控系统服务
郑煤机智慧工厂-撑起智能制造的“钢铁脊梁”
配电站房智能辅助与人工智能可视化网关
重点人员管控
重症监护区域协同示范平台
重装生产解法，离散制造创新模式
量子通信视频会议在政务服务领域的应用
金华供销社智慧菜篮子项目 优秀奖获奖名单 （排名不分先后，以项目编号为序）
金石集团绿色矿业
金马智慧工厂打造数智化煤化工企业
钢厂智慧升级开启超低排放绿色时代
钢构行业“智造”引擎
钢研纳克（苏州）全连接工厂
钢铁应用
钢铁行业的应用
银行网点转型升级
锡山区数字化综合运营服务平台
镇江市丹徒区宝偃村智慧乡村
长城汽车日照魏牌打造智能工厂
防爆AR全景智能摄像机
防爆虚拟专网 提升化工运维质效
雄安新区天地一体化生态环境智慧监测体系
雄安新区生态环境多维监测
集成信息平台的全病程管理创新示范
集群化智能管理 烟草生产线跨越式升级
青岛中加特全流程数字化创新智能制造之路
青岛亚洲杯智慧场馆建设
青岛地铁全面自主革新的新一代调度及列控应用示范
青岛大学附属医院远程手术+智慧后勤
青岛胶州市农村污水管理平台
青海省“青智119”智慧消防平台建设
青海省数字乡村试点支撑
首个火电风筝专网：潮涌东海两岸阔、能源航母焕新生
首创上船——开创邮轮旅游
高可靠高安全专网下铁路行业新应用
高算力智能模组-SRM900
高速公路气象监测预警系统
高速荣乌新线示范应用建设
高铁核心区新型电力系统示范区全域感知互动数字配电网示范工程
魅力乡村—特色田园乡村解决方案
鹤壁汽车电子产业转型升级
黄山市徽州区西溪南镇坑上智慧茶园
黄河流域生态保护智慧生态
黑龙江哈电集团MPM焊缝纠偏
黑龙江哈电集团实训基地
鼎桥 CPE Max
鼎桥模组 MH5000-82
齐鲁生态茶园

</pre>
</div>
<pre>
<br>
<br>
<h2>5 Tools to Manage Multiple Network Connection Profiles</h2>
Every home or work network you connect to can conceivably have different settings for the connection. 
At home you might <a href="https://www.raymond.cc/blog/how-do-i-know-if-someone-is-using-my-wireless-network-wifi/">use a WiFi connection</a> with default or automatic settings, for work you might have a manually set IP address and gateway or <a href="https://www.raymond.cc/blog/test-change-dns-servers-quickly-dns-jumper/">custom DNS servers</a>. 
Each different network configuration you come across requires the settings in Windows to be adjusted to match. 
While this isn&#8217;t a major problem because Windows allows you to change these types of settings, it isn&#8217;t the quickest thing to get at and change regularly.
Manual reconfiguration each time through <a href="https://www.raymond.cc/blog/repair-xp-and-vista-internet-connection-problems-with-icr/">Windows Network Connections</a> is both time consuming and inefficient. 
It requires you to remember each individual setting or the network might not connect properly. 
An easy solution is being able to create different network profiles for different scenarios, so you can save <a href="https://www.raymond.cc/blog/6-free-websites-to-map-ip-addresses-to-geographical-locations/">IP address</a>, DNS, default gateway and other settings for each network connection you encounter. 
When you need to change to a different network, a different profile can easily be applied which changes all the required settings automatically.
Here are 5 free tools for you to create and apply network profiles.

<h3>1. TCP/IP Manager</h3>
TCP/IP Manager has a good mix of the ability to easily save network settings into a series of profiles and enough features and functions to cater for most users. 
The program is open source and available in both setup installer and portable versions. 
Make sure to get the correct 32-bit or 64-bit version for your system.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/tcpip_manager.png">

After launching the program click Create a new profile and give it a name. 
Choose a network adapter from the drop down and configure the IP address, subnet, gateway and DNS servers. 
Automatic options are also available like in Windows. 
Optionally go to the Profile settings tab and choose to show the profile in the tray menu and give it a keyboard shortcut so you can launch the profile by a key combination. 
Finally click Save current profile. 
When you want to launch a profile click Apply in the window, press the hotkey combination or select from the tray icon context menu.
Proxy servers can be configured from the corresponding tab, advanced settings include changing the computer name, changing the workgroup name and possibly a unique feature of allowing MAC spoofing on the network adapter. 
TCP/IP Manager was quite reasonable on memory usage consuming around 4MB while sitting in the tray.
<a href="https://www.raymond.cc/blog/download/did/2089/" rel="nofollow">Download TCP/IP Manager</a>

<h3>2. IP Shifter</h3>
If you just want a nice and simple network connection changer, IP Shifter is relatively easy to use and doesn&#8217;t require tons of knowledge to configure. 
It also has a portable version so installation isn&#8217;t necessary either.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/ip_shifter.png">

Start the program, click the button to create a new profile and give it a name. 
The standard options allow you to select the network adapter from the drop down and then obtain an automatic or manual IP address and DNS server. 
This window is similar to the Windows Internet Protocol 4 Properties dialog and has boxes for IP address, subnet mask, gateway and DNS servers. 
Proxies for Internet Explorer and Firefox can be setup by clicking on Settings and the check box near the bottom.
Once all the profiles are setup you can switch between them by selecting and clicking Apply in the main window or minimize the program to the tray and right click on the tray icon. 
IP Shifter used around 3MB of memory while in the tray. 
A couple of useful extras are in the Tools menu to Ping an address, scan the LAN for computers and obtain your public IP address.
<a href="https://www.raymond.cc/blog/download/did/3631/" rel="nofollow">Download IP Shifter</a>

<h3>3. NetSetMan</h3>
In contrast to IP Shifter, NetSetMan is loaded with tons of options and may be a bit too much for the average user. 
For geeks and advanced users though, it&#8217;s one of the most feature rich network profiling tools around. 
Only a setup installer is available but it can create a portable version because the program can be extracted to the folder of your choice.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/netsetman.png">

Most of the settings can be left alone if you only want a simple IP and DNS changer. 
Choose a renamable SET tab to edit the profile and enter enter the IP, gateway and DNS information or leave what you don&#8217;t need on automatic. 
Use the Activate button or the tray context menu to choose between them. 
The IP+ button takes you to an advanced settings window where extra functions such as routing tables, DNS suffixes and expert settings like running Windows ipconfig commands are available.
Other more advanced networking options like a built in WiFi connection manager, computer name and workgroup changer, create network drives, append to the HOSTS file and a dedicated IPv6 settings window could all prove useful. 
Other options like changing the default printer, changing dozens of system settings or running a script/program are nice additions but not strictly necessary. 
NetSetMan uses around 8MB of memory in the background. 
The free personal use only version cannot change proxies, browser home pages and network domains.
<a href="https://www.raymond.cc/blog/download/did/3632/" rel="nofollow">Download NetSetMan</a>

<h3>4. Net Profiles Mod</h3>
This is a modified and forked version of the discontinued Net Profiles tool which has not been updated since 2011. 
Luckily this open source modded version is still in active development so there&#8217;s a fair chance bugs and issues will be fixed in future.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/net_profiles_mod.png">

Setting up a new profile is easy and for basic usage you only have to give it a name, select a network (if there are multiple) and enter the IP and DNS details manually if required. 
Use the Get Current Settings button to create a profile of your current network configuration. 
Additional options include proxies, default browser homepage, mapped drives, default printer, running an application, desktop resolution/wallpaper and connection to a specific SSID. 
File &gt; Create Desktop Shortcut allows launching a profile via shortcut without having the program running in the background.
There are a couple of issues we had with Net Profiles Mod. 
Firstly, our WiFi adapter was not recognized unless it was connected to a wireless network. 
Secondly, you cannot obtain an IP address automatically through DHCP and set the DNS servers manually, or vice versa. 
This is easily possible through Windows and a drawback if you want to change the DNS but leave the IP alone.
<a href="https://www.raymond.cc/blog/download/did/3633/" rel="nofollow">Download Net Profiles Mod</a>

<h3>5. Argon Network Switcher</h3>
Argon Network Switcher is a middle of the road type of tool in terms of features. 
It has enough to satisfy all but the most advanced users but not too many to confuse people.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/argon_network_switcher.png">

Usage is similar to the other tools here. 
Click New to create a new profile, enter a name, select the network adapter and then enter the IP, subnet, gateway and DNS addresses. 
Click Save to add the profile. 
Additional options include assigning a specific WiFi SSID, proxy settings, map a drive, set the default printer, start and stop system services, run scripts and applications and also disabling a specific network adapter on running the profile. 
An interesting feature is Autorun which leaves it up to the program to determine the best profile to launch.
We did notice a couple of bugs during usage. 
One was the WiFi SSID profiles are not displayed for everyone so you can&#8217;t associate a wireless SSID with the network profile. 
Another was using the Test button in the Drive Map tab freezes the program. 
However, mounting and unmounting networked drives does work fine. 
Network Switcher consumes about 10-15MB of RAM when minimized to the tray.
<a href="https://www.raymond.cc/blog/download/did/3634/" rel="nofollow">Download Argon Network Switcher</a>
<em>Final Note: </em>We did also look at a few other network connection profiling tools, one we almost included was <a href="https://www.raymond.cc/blog/download/did/3635/" rel="nofollow">Eusing Free IP Switcher</a>. 
This tool is like an easier to use version of NetSetMan but a major issue is a donate popup nag every time the program launches. 
This is a shame as it has a good blend of ease of use and features to make it useful.

<h2>开源的社区网盘</h2>
在gitee上发现了开源的 KodExplorer 可道云（https://gitee.com/kalcaddle/KODExplorer），发现非常适合作为小型文件共享，也很适合作为社区网盘。

它不需要安装任何程序或者插件，也不需要特殊的软件或者权限，只要有一个浏览器（主流的网络浏览器都可以，推荐chrome或firefox），就可以在线查看pdf、图片，编辑文件，共享文件等，使用方式和windows的文件管理器类似，无需学习就可以掌握。

https://www.micropython.org.cn/pan


<h2>Find the IP address</h2>
Windows
Type in “ipconfig” and hit Enter.
Look for the line that reads “IPv4 Address.”

192.168.0.100

Find the IP address of an iPad or Android Tablet

Go to setting on your iPad
Select ” WiFi ” from the sidebar.
Tap on the arrow next to the network name.
Your IP address will be displayed to the right of "IP address"

<h2>Accessing WAMP From Computers on Your LAN</h2>
<a href="https://john-dugan.com/access-wamp-from-lan-computers/" class="whitebut ">Accessing WAMP From Computers on Your LAN</a>

<a href="https://stackoverflow.com/questions/24005828/how-to-enable-local-network-users-to-access-my-wamp-sites" class="whitebut ">enable local network users to access my WAMP sites</a>

<a href="https://stackoverflow.com/questions/36810669/why-wamp-server-put-online-offline-option-is-missing/36825283" class="whitebut ">wamp server put online/ offline</a>

Right click Wampmanager -> WAMPSetting -> Menu Item: Online/Offline

If you click it so there is a Tick beside it, you will see the Online/Offline menu on the left click menu.

However it was made optional as its use is defunct.

You should create Virtual Hosts for each of your projects, then you can amend each of those individually to control the Apache access rules.

In fact in WAMPServer 3 or greater, there is a Virtual Host defined for localhost so this old Online/Offline process wont actually do what you want.

You now have to go to the wamp\bin\apache\apache{version}\conf\extra\httpd-vhosts.conf file and manually amend that entry

&lt;VirtualHost *:80>
    ServerName localhost
    DocumentRoot D:/wamp/www
    &lt;Directory  "D:/wamp/www/">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require all granted                  #&lt;-- changed line
    &lt;/Directory>
&lt;/VirtualHost>

This file can be edited using the wampmanager menus like this
wampmanager -> Apache -> httpd-vhosts.conf

However it is not recommended to allow this sort of access to localhost. It is better to create a Virtual Hosts for each of your projects eg

&lt;VirtualHost *:80>
    ServerName localhost
    DocumentRoot D:/wamp/www
    &lt;Directory  "D:/wamp/www/">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require local
    &lt;/Directory>
&lt;/VirtualHost>

&lt;VirtualHost *:80>
    ServerName project1.dev
    DocumentRoot D:/wamp/www/project1
    &lt;Directory  "D:/wamp/www/project1">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require all granted
    &lt;/Directory>
&lt;/VirtualHost>

<h2>Setup a Virtual Host</h2>
<a href="https://john-dugan.com/wamp-vhost-setup/" class="whitebut ">Setup a Virtual Host on WAMP in 3 Steps</a>
<a href="https://www.techrepublic.com/blog/smb-technologist/create-virtual-hosts-in-a-wamp-server/" class="whitebut ">Create virtual hosts in a WAMP server</a>

<a href="http://forum.wampserver.com/read.php?2,146746" class="whitebut ">WAMPServer 3 Create a Virtual Host, the easy way</a>

<h2>Sci-Hub 用上了分布式网络</h2>
在网站域名屡次被撤销之后， Sci-Hub 创始人 Alexandra Elbakyan 在分布式域名网络 Handshake 上注册了新的网站。

现在，每个用户都可以直接通过服务门户和 NextDNS 直接访问 Sci-Hub。

<img class="lazy" data-src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9mkBqdBCp94269UtFWSXwVKf5bzAj8gh8YzGa7V5KvCricAp7ViaI0O9qrEv3Q8s5YrVOHiafdAdHKQ/640">

NextDNS：https://learn.namebase.io/starting-from-zero/how-to-access-handshake-sites#level-3-dns
HNS 网关 http://sci-hub.hns.hns.to/
这些年来，一直是 Alexandra Elbakyan 在维护 Sci-Hub，目前所有用户只能通过俄罗斯的 Yandex 和比特币赞助网站的运营。

此前，Sci-Hub 被多次撤销域名，推特账户又被封禁且无法申诉，传统域名系统显然不那么满足这个「盗版学术论文数据库」的需求，能够对抗审查的 DNS 成为 Sci-Hub 保持可访问状态的方法之一。
Handshake 工作原理Tieshun Roquerre 介绍说，Handshake 实际上是一个分布式的域名服务器。
它不使用 web 标准证书颁发机构来验证用户与服务器的连接，而是存储对在其系统中注册的网站的 IP 地址的引用。
这样一来，如果证书颁发机构公司试图通过旧版系统审查 Sci-Hub 的域名，那么想要访问网站的人仍然可以通过 Handshake 的记录访问。
Namebase 则是为用户提供访问 Handshake 网络的平台，这个名字对于国内开发者来说不算陌生。

去年，关于「Namebase 羊毛现金福利」的消息一度引起热议，「满足条件的 GitHub 开发者可以获得大约 4200 个 HNS 代币的奖励」，折合人民币 5000 元左右，还有成功领取者写出了「从天上接馅饼」的教程。
Namebase CEO Tieshun Roquerre 介绍说：「DNS 就像互联网的电话簿，电话簿中的地址是服务器 IP 地址。
DNS 的创建是为了给 IP 地址提供人类可读的名称，因此在这一平台上，用户可以通过 Handshake 找到 IP 地址，而不是通过证书颁发机构。
」Roquerre 提到：「如果你的服务器级别受到限制，则可以切换服务器。
但如果你的域名被删除，就没人能访问你的网站了。

只要名称完好无损，就可以将其指向任何服务器。
」即使 band 网站找到了一个新域名，但用户也不确定其真实性（例如 Sci-Hub 也经常被冒名顶替）。
要注册一个 Handshake 域名，任何人都可以提出一个网站名称，并在 Handshake 的市场上用其同名 HNS token 对该网站进行竞标。
据外媒 CoinDesk 统计，目前共有 6818 个 Handshake 域名处于活跃使用状态，已注册的域名达到了 375000 个。
数据显示，其市场交易量每月平均增长 60%，近期将突破 14 万美元。
像 Handshake 这样的分布式（decentralized）域名系统，可能会成为分布式网络的标志性胜利。
该项目是众多所谓「Web 3.0」应用程序的一部分，当然，「Web 3.0」这个概念还存在很多争议，比如创建某些未经审查的互联网搜索，是否会带来更多的隐患？正如 Sci-Hub 的经历所证明的问题一样，分布式的网络是出于去平台化的担忧而构建的。
随着互联网访问接入点越来越集中在「少数玩家」的手上，最近也有一些应用受到了 Web 服务器提供、应用商店和 DNS 证书颁发机构的审查。
参考链接：https://www.nasdaq.com/articles/pirated-academic-database-sci-hub-is-now-on-the-uncensorable-web-2021-01-11https://www.coindesk.com/pirated-academic-sci-hub-handshake

<h2>create simple file server</h2>
C:\Windows\System32
run ipconfig to find ip address

<a href="https://stackoverflow.com/questions/15328623/simple-file-server-to-serve-current-directory" class="whitebut ">Simple file server to serve current directory</a>

python -m SimpleHTTPServer 8000
will serve the contents of the current working directory over HTTP on port 8000.

If you use Python 3, you should instead write
python -m http.server 8000

acer:
http://192.168.128.93:8000/

For Node, there's http-server:
$ npm install -g http-server
$ http-server Downloads -a localhost -p 8080
Starting up http-server, serving Downloads on port: 8080
Hit CTRL-C to stop the server

<h2>enable FTP through Chrome on all Windows devices</h2>

In Chrome 81, FTP support is disabled by default, but you can enable it using the # enable-ftp flag.

Open Chrome and type “chrome://flags” in the address bar.
Once in the flags area, type “enable-ftp” in the search bar stating “search flags”.
When you see the “Enable support for FTP URLs” option tap where it says “Default”.
Tap “Enable” option.
Hit “Relaunch Now” option at the bottom of the page.


<b>To transfer files via FTP using your web browser:</b>

From the File menu, choose Open Location....
In the "Location" field, type a URL like the following:
  ftp://username@name-of-server
For example, if your username is dvader, and you want to reach your account on deathstar.empire.gov, enter:

  ftp://dvader@deathstar.empire.gov
Note: Do not close the URL with a /, or you will connect to the root directory rather than your home directory.

You will be prompted for your password.
After you supply the password, you will see the contents of your home directory on the remote machine.
To change directories, click the appropriate yellow folder icon.
To download a file, drag the file from the browser window to the desktop.
You can also double-click the filename, and you will be prompted to either save or open the file.
To upload a file, drag the file from your hard drive to the browser window.


<h2>Net Command Syntax</h2>
The command takes the following general form:
net [accounts | computer | config | continue | file | group | help | helpmsg | localgroup | name | pause | print | send | session | share | start | statistics | stop | time | use | user | view]
Net Command Options
<table>
<tr><td><b>Option</b></td><td><b>Explanation</b></td></tr>
<tr><td><b>net</b></td><td>Execute the net command alone to show information about how to use the command which, in this case, is simply a list of the net subset commands.</td></tr>
<tr><td><b>accounts</b></td><td>The net accounts command is used to set password and logon requirements for users. For example, the net accounts command can be used to set the minimum number of characters that users can set their password to. Also supported is password expiration, minimum number of days before a user can change their password again, and the unique password count before the user can use the same old password.</td></tr>
<tr><td><b>computer</b></td><td>The net computer command is used to add or remove a computer from a domain.</td></tr>
<tr><td><b>config</b></td><td>Use the net config command to show information about the configuration of the<em>Server</em> or<em>Workstation</em> service.</td></tr>
<tr><td><b>continue</b></td><td>The net continue command is used to restart a service that was put on hold by the net pause command.</td></tr>
<tr><td><b>file</b></td><td>Net file is used to show a list of open files on a server. The command can also be used to close a shared file and remove a file lock.</td></tr>
<tr><td><b>group</b></td><td>The net group command is used to add, delete, and manage global groups on servers.</td></tr>
<tr><td><b>localgroup</b></td><td>The net localgroup command is used to add, delete, and manage local groups on computers.</td></tr>
<tr><td><b>name</b></td><td>Net name is used to add or delete a messaging alias at a computer. The net name command was removed in conjunction with the removal of net send beginning in Windows Vista. See the net send command for more information.</td></tr>
<tr><td><b>pause</b></td><td>The net pause command puts on hold a Windows resource or service.</td></tr>
<tr><td><b>print</b></td><td>Net print is used to display and manage network print jobs. The net print command was removed beginning in Windows 7. According to Microsoft, the tasks performed with net print can be performed in Windows 10, Windows 8, and Windows 7 using the<em>prnjobs.vbs</em> and other cscript commands, Windows PowerShell cmdlets, or Windows Management Instrumentation (WMI).</td></tr>
<tr><td><b>send</b></td><td>
<a href="https://www.lifewire.com/net-send-2618095" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">Net send</a> is used to send messages to other users, computers, or net name created messaging aliases. The net send command is not available in Windows 10, Windows 8, Windows 7, or Windows Vista but the
<a href="https://www.lifewire.com/msg-command-2618093" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="2">msg command</a> accomplishes the same thing.</td></tr>
<tr><td><b>session</b></td><td>The net session command is used to list or disconnect sessions between the computer and others on the network.</td></tr>
<tr><td><b>share</b></td><td>The net share command is used to create, remove, and otherwise manage shared resources on the computer.</td></tr>
<tr><td><b>start</b></td><td>The net start command is used to start a network service or list running network services.</td></tr>
<tr><td><b>statistics</b></td><td>Use the net statistics command to show the network statistics log for the<em>Server</em> or<em>Workstation</em> service.</td></tr>
<tr><td><b>stop</b></td><td>The net stop command is used to stop a network service.</td></tr>
<tr><td><b>time</b></td><td>Net time can be used to display the current time and date of another computer on the network.</td></tr>
<tr><td><b>use</b></td><td>The<a href="https://www.lifewire.com/net-use-command-2618096" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">net use command</a> is used to display information about shared resources on the network that you're currently connected to, as well as connect to new resources and disconnect from connected ones.
In other words, the net use command can be used to show the shared drives you've mapped to as well as allow you to manage those mapped drives.</td></tr>
<tr><td><b>user</b></td><td>The<a href="https://www.lifewire.com/net-user-command-2618097" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">net user command</a> is used to add, delete, and otherwise manage the users on a computer.</td></tr>
<tr><td><b>view</b></td><td>Net view is used to show a list of computers and network devices on the network.</td></tr>
<tr><td><b>helpmsg</b></td><td>The net helpmsg is used to display more information about the numerical network messages you might receive when using net commands. For example, when executing
<b>net group</b> on a standard Windows workstation, you'll receive a
<em>3515</em> help message. To decode this message, type
<b>net helpmsg 3515</b> which displays
<em>"This command can be used only on a Windows Domain Controller."</em> on screen.</td></tr>
<tr><td><b>/?</b></td><td>Use the
<a href="https://www.lifewire.com/help-switch-2625896" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">help switch</a> with the net command to show detailed help about the command's several options.</td></tr>
</tbody>
</table>
Save to a file whatever a <strong>net </strong>command shows on screen using a <a href="https://www.lifewire.com/redirection-operator-2625979" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">redirection operator</a> with the command. Learn&nbsp;<a href="https://www.lifewire.com/how-to-redirect-command-output-to-a-file-2618084" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="2">how to redirect command output to a file</a> or see&nbsp;our list of&nbsp;<a href="https://www.lifewire.com/command-prompt-tricks-and-hacks-2618104" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="3">command prompt tricks</a>&nbsp;for more tips.
Only in Windows NT and Windows 2000 was there a difference in the <strong>net </strong>command and the <strong>net1</strong> command. The net1 command was made available in these two operating systems as a temporary fix for a Y2K problem that affected the <strong>net </strong>command.
<h2>  Net Command Examples  </h2>
net view
This is one of the simplest net commands that lists all the networked devices.
net share Downloads=Z:\Downloads&nbsp;/GRANT:everyone,FULL
In the above example, I'm sharing the&nbsp;<em>Z:\Downloads</em>&nbsp;folder with&nbsp;everyone&nbsp;on the network and giving all of them&nbsp;full&nbsp;read/write access. You could modify this one by replacing&nbsp;<em>FULL</em>&nbsp;with&nbsp;<em>READ</em>&nbsp;or&nbsp;<em>CHANGE</em>&nbsp;for those rights only, as well as replace&nbsp;<em>everyone</em>&nbsp;with a specific username to give share access to just that one user account.
net accounts /MAXPWAGE:180
This example of the net accounts command forces a user's password to expire after 180 days. This number can be anywhere from&nbsp;<em>1</em>&nbsp;to&nbsp;<em>49,710</em>, or <em>UNLIMITED</em>&nbsp;can be used so that the password never expires. Default is 90 days.
net stop&nbsp;"print spooler"
The above net command example is how you'd stop the Print Spooler service from the command line.&nbsp;Services can also be started, stopped, and restarted via the Services graphical tool in Windows (services.msc), but using the net stop command lets you control them from places like Command Prompt and <a href="https://www.lifewire.com/bat-file-2619796" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">BAT&nbsp;files</a>.

net start
Executing the net start command without any options following it (e.g. net start "print spooler")&nbsp;is useful if you want to see a list of currently running services. This list can be helpful when managing services because you don't have to leave the command line to see which services are running.

<h2>send a pop up message to another computer</h2>
<h3>Send a Message to Another PC on a Local Network</h3>
run cmd
type <b>Net send</b> followed by the name of the computer to which you wish to send the message. Next, enter the message.

msg /SERVER:DestinationPC * /TIME:60 “This is the message to be sent to a PC named DestinationPC and closes in 60 seconds."

You will need to replace DestinationPC with the name of the desired PC (you can find this in the list of computers that are currently sharing your network, if you don't already know the PC name).
Now, replace the value for TIME with how long you want the message to appear on the other screen for. For example TIME:30 for 30seconds
Then replace the text between the quotation marks with the message that you want to send.
Finally, you can hit enter, and the message will be sent.

<h3>to list all computers in a windows wi-fi network</h3>
run cmd
<b>net view</b> will probably show most of them.

Ping the server if you know or your gateway.
Type the command <b>arp -a</b>
It will usually list down all the IP's and Computers with their Mac Addresses.

If you want to use a GUI tool. I recommend <b>IPScan</b>.
Although it is a light application (433KB), it is freeware that's always worked for me.
You can also use another GUI Tool, Advance IP Scanner.

<h3>how do I send a pop up message</h3>
To send a popup message:
Select one or more users from the user list.
Issue the Send popup message command by right-clicking on any selected user and selecting the 'Popup Message' menu item.

The 'Send popup message' window will appear.
Enter message text and click on the 'Send' button.

<h3>can I send a message to an IP address? </h3>
The IP Message no longer works.
The idea behind it is that you type a message and sort of password protect using some IP address.
Only the person with that IP address will be able to see the message.

Likewise, people ask, how can I see messages from another computer using CMD?
Start command prompt
Type the command as follows:
Hit enter and voila, the message is sent.
How can I communicate with another computer on the same network?

Method 1 Sharing Internet from Windows

Connect the two computers with an Ethernet cable.
Open Start.
Open Control Panel.
Click Network and Internet.
Click Network and Sharing Center.
Click Change adapter settings.
Select both the Wi-Fi connection and the Ethernet connection.
Right-click the Wi-Fi connection.

Alternatives for Older Versions of Windows
Alternative 1
Here is the first alternative way of sending messages that may work if you have an older version of Windows. Here's how:

Click Start > Run.
Type cmd, and press Enter.
In the window that opens, type Net send followed by the name of the computer to which you wish to send the message.
Next, enter the message. For example, the format should resemble "Net send PC01 can you read this message?"
Alternative 2
It is easy to send messages through cmd prompt to other systems here is the answer first we have to set our systems messenger ACTIVE. For it, follow these steps:

1. Go to RUN
2. Type services.msc
3. Scroll down and right click on MESSENGER
4. Select PROPERTIES
5. Then for enabling it go to STARTUP TYPE and select AUTOMATIC
6. Then OK
And this should be performed on both sides (SENDER & RECEIVER). After that if you want to send message then do the following steps:

1. Go to cmd prompt
2. Type syntax as follows: net send <ipaddress of reciever> <message to be send>
Ex:

net send 172.16.6.99 "hello"

<h2>FileZilla</h2>
<a href="https://filezilla-project.org/download.php?show_all=1" class="whitebut ">downoad filezilla client</a>

<a href="https://filezilla-project.org/download.php?type=server" class="whitebut ">Download FileZilla Server for Windows</a>
<a href="https://dl4.cdn.filezilla-project.org/server/FileZilla_Server-0_9_60_2.exe?h=Q49drOcs8bOUZF_nd8ry1A&x=1626777411" class="whitebut ">FileZilla Server file</a>

<h2>Turn Wi-Fi Router USB Port into a NAS Server</h2>
<div id="routertoc">0 <a href="#routertopic-0" target="_self">Turn Wi-Fi Router USB Port into a NAS Server</a><br>1 <a href="#routertopic-1" target="_self">What's the use of a Wi-Fi router USB port?</a><br>2 <a href="#routertopic-2" target="_self">Host that (old) printer</a><br>3 <a href="#routertopic-3" target="_self">Cellular connection</a><br>4 <a href="#routertopic-4" target="_self">Network-attached storage (NAS) server</a><br>5 <a href="#routertopic-5" target="_self">How to best turn a Wi-Fi router USB port into a NAS server</a><br>6 <a href="#routertopic-6" target="_self">Get expectations straight</a><br>7 <a href="#routertopic-7" target="_self">Get a good external drive</a><br>8 <a href="#routertopic-8" target="_self">Get the right router</a><br>9 <a href="#routertopic-9" target="_self">Use the correct settings</a><br>10 <a href="#routertopic-10" target="_self">How to access your router-based NAS server</a><br>11 <a href="#routertopic-11" target="_self">Accessing your NAS server on a Windows computer</a><br>12 <a href="#routertopic-12" target="_self">Accessing your NAS server on a Mac</a><br>13 <a href="#routertopic-13" target="_self">Best USB-enabled routers that can work as a NAS server</a><br></div></center>

When it comes to network storage, I'd recommend a <a href="https://dongknows.com/dong-ngos-most-important-gadget-is-a-synology-nas-server/#Whats_a_NAS_server" target="_blank">NAS server</a>. 
But a good server can be expensive; plus, not everyone wants or has time to configure all the features. 
So the second-best option is to make use of what you likely already have: the Wi-Fi router USB port.

Indeed, there are many routers on the market that can simultaneously deliver both Wi-Fi <em>and</em> storage space for your entire home. 
Specifically, they allow you to share files stored on an external drive with the rest of the network.
This post, among other things, talks about the storage-related use of a USB-ready Wi-Fi router. 
You'll also find the link to my list of recommended routers and tips on how to best set up one as a NAS server.

<img class="lazy loaded" data-src="https://dongknows.com/wp-content/uploads/2020/12/Asus-RT-AX89X-USB-768x1024.jpg" src="https://dongknows.com/wp-content/uploads/2020/12/Asus-RT-AX89X-USB-768x1024.jpg" data-was-processed="true">
Router USB port: These little ports can bring about extra values.

<h3>What's the use of a Wi-Fi router USB port?</h3>
Not every Wi-Fi router has a USB port, but if yours happens to have one, chances are you can use it for (at least one of) the followings:
<h3>Host that (old) printer</h3>

Print serving is the original function of a router USB port. 
Connect a USB printer to this port, and it's now available to the entire network. 
There's no need to buy a printer for each person anymore.
Five or six years ago, this feature was a big deal since printers at the time were mostly USB-only. 

Nowadays, those with a built-in network port or Wi-Fi are commonplace. 
With that, some new Wi-Fi routers don't offer the print serving feature anymore, though many still do.
<h3>Cellular connection</h3>
This feature allows the router to host a cellular USB modem and share the mobile Internet to the entire network. 

A cellular connection is a great way to have a backup Internet when your broadband service, like DSL or cable, is down.
Note that a router with this feature only supports specific cellular modems. 
Make sure you check the manual to know which one to get.
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/08/Wi-Fi-Router-USB-NAS.jpg">

Picking the right external storage device is the first step to turn a Wi-Fi router USB port into a mini NAS server.
<h3>Network-attached storage (NAS) server</h3>
This feature is, by far, the most common and useful. 
Similar to the case of printing, plugging an external hard drive into the router USB port can also make its storage available to the entire network.

On top of that, you can use that public storage space for other applications, such as a backup destination (including Time Machine backup, in some cases,) PC-less downloading, or even a personal cloud.<a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/">See also How to Turn your USB-enabled Wi-Fi Router into a Time Capsule</a>
<h3>How to best turn a Wi-Fi router USB port into a NAS server</h3>
There are a couple of things to keep in mind about using a router as a NAS server.
<h3>Get expectations straight</h3>

The first and most important thing to remember is a router's primary function is to host your network. 
For this reason, even a high-end router tends to have limited processing power for non-networking tasks. 
<h4>It's a router you're using!</h4>
Naturally, a router is not as capable as a dedicated NAS server when hosting storage space. 

Also, just because the router USB port or ports support a few functions -- like NAS, printing, or cellular modem, and so on -- doesn't mean you should expect to use <em>all of them at the same time</em>, nor should you expect the top performance of each when you use them all together. 
(For the same reason, you can't, either, expect to have the same storage performance via Wi-Fi as via a wired connection. 
In the former, the router has to use its power to broadcast the Wi-Fi signals at the same time.)
By the way, if a router has multiple USB ports, chances are they all share a single USB hub. 

So, you can't use more than one bus-powered devices with it, and each port only has its share of the hub's total bandwidth.
Again, it's a router you're looking at. 
Just because there are ports doesn't mean you can use them all at your expected performance.
<h4>Security</h4>

Security can also be a concern. 
For example, some routers still use <a rel="noopener noreferrer nofollow" href="https://en.wikipedia.org/wiki/Server_Message_Block#SMB_/_CIFS_/_SMB1" target="_blank">SMBv1</a>, which is the original and ancient version of the popular Server Message Block protocol used in the Windows environment for network file and printer sharing. 
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/09/SMBv1-required.png">
Router USB port: Some routers still require the old and vulnerable SMBv1 protocol for the USB-based file sharing.

Due to security holes, for about a decade now, SMBv1 has been replaced by SMBv2 and newer versions and recently even disabled by default in most modern operating systems. 
That doesn't mean using SMBv1 will get you in trouble immediately, but it sure is not ideal. 
(Note, though, that many Asus routers might have the warning about enabling SMBv1, but they don't require it to work. 
In my experience, all Asus Wi-Fi 6 routers can work with newer SMB versions.)

Another security concern is when you use the NAS feature via the Internet. 
In this case, make sure you create an account for each user access. 
But if you're not sure, just don't turn on any “cloud” feature or FTP access. 
Use those only when you know what you're doing.

The bottom line is, if you want to do a lot of things with your network storage, it's a good idea to get a real dedicated <a href="https://dongknows.com/dong-ngos-most-important-gadget-is-a-synology-nas-server/" target="_blank">NAS server</a>. 
But if you only wish to use some casual network storage, it's quite fun and sensible to get even more use out of our router.
<h3>Get a good external drive</h3>
Any good external storage device, namely desktop or laptop (portable) USB drives, will work. 

You don't need to get a NAS-specific drive. 
So, if you want the fastest possible speed, get a fast SSD-based portable drive, such as one of those on this list. 
However, keep in mind that the performance depends on the network connection or the router's processing power.
That said, a fast external storage device doesn't always translate into better performance. 

In most cases, an affordable hard-drive-based portable drive, like the <a href="https://dongknows.com/wd-my-passport-2019-portable-drive-review/" class="rank-math-link">WD My Passport</a> or the <a href="https://dongknows.com/g-tech-g-drive-mobile-usb-c-review/" class="rank-math-link">G-Tech Mobile</a>, will do. 
Generally, a router USB port has enough juice to power one bus-powered drive. 
But you can also use desktop external drives that have a power adapter of their own. 
In this case, you can use one with each of a router's USB ports.

<a href="https://dongknows.com/best-portable-drives/">See also Best Portable Drives of 2021: The Ultra-secure, Extra-rugged, and Super-fast</a>
When it comes to storage space, the more, the better, so get the drive with the most capacity you can afford. 
If you're serious about your data, you can also choose an external drive with <a href="https://dongknows.com/why-you-would-want-a-synology-nas-server/#Redundancy_via_the_use_of_RAID_explained" target="_blank">redundancy</a>, such as a dual-drive RAID 1 external storage device, like the <a rel="noopener noreferrer nofollow" href="https://amzn.to/2lpFRrN" target="_blank">WD My Book Duo</a>.
<strong>Note: </strong>You will need to configure the hardware RAID setup <em>before</em> plugging it into the router. 

So do that on a computer first. 
<h3>Get the right router</h3>
Not all routers are equal, especially when it comes to raw power. 
That said, get a router that has a lot of processing power. 

Generally, the higher the specs, the better.<a href="https://dongknows.com/usb-c-vs-thunderbolt-3-explained/">See also Device Connections Explained: Thunderbolt or Not, It's All about USB-C</a>
Also, make sure you get a router that supports <a href="https://dongknows.com/peripheral-connection-explained-usb-c-vs-thunderbolt-3/" target="_blank">USB 3.2 Gen 1</a>, a.k.a USB 3.0, or faster. 
Some router also has an eSATA or USB-C port. 
So, find one that suits your needs. 

And finally, get the router that includes the storage features you want, such as the <a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/" target="_blank">support for Time Machine backup</a>.
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/01/Asus-RT-AX88U-USB-mode-1024x858.png">
Router USB port: Steps to make an Asus Wi-Fi router USB port work in USB 3.0 (a.k.a USB 3.2 Gen 1) mode.
<h3>Use the correct settings</h3>

By default, many routers -- especially those from Asus and Synology -- automatically set the connected drive to work in USB 2.0 mode. 
This mode won't affect the router's NAS functionality but has a theoretical cap speed of just 480 Mbps (60 MB/s) -- the real-world rate will be just about half of that. 
The USB 3.2 Gen 1 (formerly USB 3.0) mode, which the cap of 5 Gbps (625 MB/s), unfortunately, can adversely affect the router's 2.4GHz Wi-Fi band. 
That said, if you want to get the most out of the router's storage feature, you'll need to enable the faster USB mode manually -- we use mostly the 5GHz band these days anyway.

Also, make sure you use the external drive with the right setting. 
For one, use it in the <a href="https://dongknows.com/file-system-explained-and-how-to-format-your-drive/" target="_blank">correct file system</a> that the router supports. 
Most, if not all routers, support NTFS. 
<a href="https://dongknows.com/disk-partition-and-file-system-explained/">See also File System and Partition Explained: Take Control of Your Storage</a>

By the way, it's worth noting that you only need to use the file system that the router supports, and not the one your computer supports. 
That's because the file system used by the server has nothing to do with the client. 
So, for example, if you use an NTFS (Windows) external drive with your router and share its storage, over the network, your Mac will be able to read, write to the shared folder, and use the space for Time Machine backup (if supported) just fine. 
Finally, don't turn on the external storage device's security feature if it has one. 

A router has no mechanism to unlock it.
<h3>How to access your router-based NAS server</h3>
Once you've connected a storage device to a router and turned on the data sharing feature -- often referred to as Windows-based, or SAMBA (SMB), file sharing -- it's easy to access that share space from any computer within the network. 
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2021/01/Asus-RT-AX92U-USB-Features-836x1024.jpg">

The USB-related features of an Asus router. 
For NAS, the Samba option is in the second (Servers Center) from top.
A couple of things to note here:
<ul><li>Depending on the router, there might be more features than just data sharing. 

Another popular option is the media server -- where the router shares video and audio files stored on the connected drive via media streaming protocol. 
In this case, just follow the instruction to turn the desired feature on.</li><li>Here I assume you know how to set up a router, access its web interface, etc -- enabling the NAS feature is part of working with the router's interface. 
If not, this <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener" href="https://dongknows.com/home-wi-fi-router-setup/" target="_blank">post on how to build a network from scratch</a> will help you with that.</li></ul>
But data sharing is the most useful and popular, and I'll cover it here. 

It's fairly easy. 
To make it work, the only next thing you need is the router's IP address, which is the same one you've used to access its interface. 
Alternatively, you can also use the router's network name. 
But the IP is always the <em>sure</em> way. 

For this post, let's say the IP address in question is <em>192.168.1.1</em>. 
(Chances are yours is a different one. 
If you don't know what it is, this post on IP addresses includes detailed steps to figure that out.)
Once you've got the IP address, the steps below are the standard ways to access your newly-minted NAS server from a Windows or Mac computer within your local network hosted by the router.

<h3>Accessing your NAS server on a Windows computer</h3>
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2020/07/Access-Server-Windows.png">
You can access the shared folder via the router's IP address.
1. 

Open Explorer.
2. 
On the address bar type in this command then press Enter:
<strong><em>\\192.168.1.1</em></strong>

(Alternatively, you can also use <strong>\\RouterName</strong> and the Windows search field under the Start Menu instead of Explorer. 
Don't forget the \\ (<strong>not</strong> //) and remember there's no space in the command.)
3. 
Enter the username and password if prompted. 

If you haven't set up an account for the data sharing, or if the router doesn't support that, you can just use the<em> admin username and password of the router</em>‘s web interface.
<h3>Accessing your NAS server on a Mac</h3>
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2020/07/Access-Server-Mac-1024x768.jpg">
1. 

Click on an empty spot on the desktop then press&nbsp;<em>Command + K</em>, and the “Connect to Server” window will appear.
2. 
Under <em>Server address</em>&nbsp;type in
<strong><em> smb://192.168.1.1&nbsp;</em></strong>

(Again, you can also substitute the IP address with the router's network name.)
3. 
Click on <em>Connect</em> and enter username and password (of the account you've created or the router's admin account) if prompted.
And that's it. 

Happy data sharing!
<h3>Best USB-enabled routers that can work as a NAS server</h3>
Now that you know how to turn a USB-enabled router into a NAS server, you probably wonder which router or routers you should get for the job. 
I addressed that big question in this separate, frequently updated post on <a href="https://dongknows.com/best-wi-fi-routers-for-nas/">the best Wi-Fi routers for NAS features</a>. 

Check it out!
<a href="https://dongknows.com/best-wi-fi-router-nas-solutions/">
See also Best 13 Router NAS Options: Add Some Cool Storage to Your Wi-Fi Today!</a>
By the way, again, many routers can also work as a <a href="https://dongknows.com/all-you-need-to-know-about-macs-time-machine-backup/" target="_blank" rel="noreferrer noopener">Time Machine backup</a> destination. 
For more, check out this post on how to <a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/">turn a router into a Time Capsule.</a>

'<h2>Wi-Fi Direct</h2><br>Windows 10 boasts another feature that most people don\'t know about, called <strong>Wi-Fi Direct</strong>, a wireless connectivity system that helps you effortlessly hook devices up and transfer huge amounts of data.<br><br><h3>How Does Wi-Fi Direct Work?</h3><br>For Wi-Fi Direct technology to work, you\'ll need at least a single device that\'s compatible with its protocols.3<br><br>Wi-Fi Direct is built on top of Wi-Fi. <br>The only thing that separates it from regular Wi-Fi is that while you need a router to connect your devices to the internet, Wi-Fi Direct doesn\'t have any limitations.<br><br><h3>Check If Your Windows 10 PC Is Wi-Fi Direct Compatible</h3><br>You can do this by pressing<strong> Windows Key +R</strong>, entering <strong>CMD</strong> to <a href="https://www.makeuseof.com/tag/a-beginners-guide-to-the-windows-command-line/">open the Command Prompt</a> then entering <strong>ipconfig /all</strong>.<br><img src="https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2021/06/windows-command-prompt.png"><br>If Wi-Fi Direct is available, you should see an entry labeled <strong>Microsoft Wi-Fi Direct Virtual Adapter.</strong><br><br>Next, you\'ll need to start transferring data over Wi-Fi Direct. <br><br><h3>How to Transfer Files From Android to Windows With Wi-Fi Direct</h3><br><br>As you\'ll need a third-party app to use Wi-Fi Direct, choosing the right option is important.<br><a href="https://feem.io/">Feem</a> is a software that has provided Wi-Fi Direct support to Windows PC and laptop users since the days of Windows 7 and Windows 8.<br>Feem is free to use, although it has various premium options. <br><br>Wi-Fi Direct in Feem is free, as is live chat. <br><br>Set your Android device as a mobile hotspot via <strong>Settings &gt; Network &amp; Internet &gt; Hotspot &amp; tethering</strong>. <br>Connect your Windows computer to this network.<br>Launch Feem on Android and Windows. <br><br>You\'ll notice that both devices are given unusual names by the app (e.g., Junior Raccoon) and a password. <br>Keep a note of the password, as you\'ll need it to establish the initial connection.<br>Send a file from Android to Windows using Wi-Fi Direct, choose the destination device, and tap <strong>Send File</strong>. <br><br>Browse for the file or files, then tap <strong>Send</strong>.<br>Moments later, the data will be sent to your PC. <br>It\'s as simple as that—and it works backwards, too.<br><br><strong>Download:</strong> <a href="https://feem.io/#download">Feem</a> (for Windows, macOS, Linux, Android, iOS, Windows Phone)<br><h3>Don\'t Have Wi-Fi Direct? Transfer Files With Bluetooth!</h3><br>If your devices don\'t support Wi-Fi Direct, a smart solution (in the absence of a USB cable) is Bluetooth. <br><br>This is particularly useful if you\'re trying to use Wi-Fi Direct on Windows 7 or 8 and find that the feature isn\'t there or it doesn\'t work.<br><br>First, ensure your computer is paired to a suitable Bluetooth device (phone, tablet, computer, etc.) before sending a file to it. <br>The methodology for this is largely the same across devices and requires that both are set to "discoverable."<br><br>Both devices will then search for one another and, if successful, connect following input of a confirmation code.<br>For more information, here\'s a list of how you can <a href="https://www.makeuseof.com/tag/transfer-files-android-pc/">transfer data between a PC and Android</a>.<br>If you\'re not sure where the controls for Bluetooth can be found on your Windows 10 computer, open <strong>Settings &gt; Devices. <br><br></strong>After you\'re in the <strong>Bluetooth &amp; other devices</strong> section, turn on the Bluetooth, and pair your device with the computer. <br>For that, click on <strong>Add Bluetooth or other device </strong>and go ahead with the pairing up.<br><br>Then click on <strong>Send or receive files via Bluetooth &gt; Send Files. <br><br>Next, select</strong> a device that you want to share files with, choose the file to be sent, and click on <strong>Next </strong>to go ahead with the transmission.<br><img src="https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2021/06/send-a-file-by-bluetooth.png"><br>On sending the file, the device receiving your data file will ask you to confirm that you wish to save the data. <br><br>Agree to this, and wait for the transfer to complete.<br>Note that due to the shorter range of Bluetooth, the best results will be enjoyed by keeping both devices close together.<br><h3>No Wi-Fi Direct? Transfer Files From Android to Windows PC With FTP</h3><br><br>FTP is another handy file transfer option for Android users attempting to transfer files to their Windows 10 PC (or other operating systems, for that matter).<br><a href="http://www.estrongs.com/#/">ES File Explorer</a> is a popular third-party <a href="https://www.makeuseof.com/tag/es-file-explorer-the-best-file-manager-for-android-android/">file manager for Android</a>. <br>This comes with several file management features for local and network use. <br><br>Among these is FTP, which provides a direct network connection between two devices.<br>Use ES File Explorer\'s <strong>Network &gt; FTP</strong> feature to display your Android device\'s IP address.<br>Paste this into a file transfer program such as <strong>FileZilla</strong> to browse the contents. <br><br>You can then effortlessly transfer files between the two devices.<br>So, try ES File Explorer if you want to transfer data from a mobile device to your laptop through Wi-Fi and don\'t have Wi-Fi Direct.<br><h3>Data Transfer Speeds: Which Is Best?</h3><br><br>You will probably notice while trying these two methods that Wi-Fi Direct is considerably quicker than Bluetooth. <br>Indeed, recent tests have demonstrated that Bluetooth speed is like a tortoise in comparison.<br>While Wi-Fi Direct isn\'t quicker than any cable data transfer (such as USB 2.0 or USB 3.0), it is certainly capable of transferring a 1.5 GB file within 10 minutes; in contrast, Bluetooth takes almost 125 minutes to shift the same data.<br>',

<h2>The share option is greyed out</h2>
From the Properties window, set the Advanced Shared Permissions
a. 
From the Properties window, Click the Advanced Sharing button.
b. 
The Advanced Sharing window appears. 
First, select the check box beside the Share this folder option. 
Next, you need to type in a share name. 
By default, Windows 7 uses the name of the folder as the share name, but you can change the name by typing a new name in the Share name field.
c. 
Now you’re ready to set the permissions. 
Click the Permissions button from the Advanced Sharing window
d. 
Select the Everyone group in the Group or user names list, and then click Remove. 
Click Add to display the Select users or groups window. 
Within the Enter the object names to select text box, type the name of the user or users you want to give permission to access the shared folder (separate multiple usernames with semicolons). 
Click OK when you’re done to return to the Permissions window.
e. 
Next select the appropriate user in the Group or user names list. 
You can now use the permissions list to allow or deny one of the following permissions: Read, Change, or Full Control. 
Click OK if you’re done. 
If you want to assign permissions to additional users or group, repeat these steps to assign them the appropriate permissions.
f. 
Click OK to return to the Advanced Sharing window and click OK again to return to the Sharing tab. 
Finally, when you click Close, the folder or file is accessible to others on the network.
g. 
Click OK to return to the Sharing tab, and then click Close to share the resource with the network.


<h2>Find all Wi-Fi passwords with only 1 command</h2>
netsh wlan show profile
netsh wlan export profile folder=C:\ key=clear


<h2>Github Actions</h2>
<div id="GitActionstoc"><a href="#GitActionstopic-0" target="_self" >Terminology</a><br><a href="#GitActionstopic-1" target="_self" >Documentation</a><br><a href="#GitActionstopic-2" target="_self" >Experimenting</a><br><a href="#GitActionstopic-3" target="_self" >Workflows</a><br><a href="#GitActionstopic-4" target="_self" >Events</a><br><a href="#GitActionstopic-5" target="_self" >Environment</a><br><a href="#GitActionstopic-6" target="_self" >Example Job</a><br><a href="#GitActionstopic-7" target="_self" >Environment Variables</a><br><a href="#GitActionstopic-8" target="_self" >Secrets</a><br><a href="#GitActionstopic-9" target="_self" >Third Party Actions</a><br><a href="#GitActionstopic-10" target="_self" >Conditions</a><br><a href="#GitActionstopic-11" target="_self" >Persisting Data</a><br><a href="#GitActionstopic-12" target="_self" > Using shared job data to determine if subsequent job should run</a><br><a href="#GitActionstopic-13" target="_self" > Persist data using <code>strategy.matrix</code></a><br><a href="#GitActionstopic-14" target="_self" > Clarify the cache action</a><br><a href="#GitActionstopic-15" target="_self" >Reusable Workflows</a><br><a href="#GitActionstopic-16" target="_self" >Conclusion</a><br></div>

<a href="https://github.com/features/actions">GitHub Actions</a> makes it easy to automate all your software workflows, now with world-class CI/CD. 
Build, test, and deploy your code right from GitHub.
I've been using GitHub Actions a lot recently and I've found it to be immensely flexible and feature rich. 
I think it's well worth your time learning how to run your CI/CD pipelines via GitHub Actions, and in this post that's exactly what we're going to dig into.
<h3 id="GitActionstopic-0">Terminology</h3>
It all starts with a 'workflow'.
A workflow is a yaml configuration file that defines:
<strong>Jobs</strong>: a job represents a collection of 'steps'.
<strong>Steps</strong>: each 'step' does something useful (e.g. executes a piece of code).
<strong>Events</strong>: an event determines when your 'jobs' should run.
GitHub has a nice visualisation of this..
<img src="https://www.integralist.co.uk/images/overview-actions-simple.png">
<strong>NOTE</strong>: Each job you define will run in parallel. 
If you need jobs to run sequentially, then you'll need to configure a job to depend on another job using the <code>needs</code> property (we'll see an example of this later).
<h3 id="GitActionstopic-1">Documentation</h3>
I would strongly suggest bookmarking the <a href="https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions">official documentation</a> because it's very thorough. 
Unfortunately it's so thorough that it can be a bit overwhelming, but don't worry, once you've gotten familiar with the various concepts you'll start to remember where the important information is located.
The pages I use the most are:
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/expressions">Expressions</a></strong>: explains how to use GitHub's builtin functions, like <code>contains()</code>, <code>fromJSON()</code>, and functions like <code>success()</code> and <code>failure()</code> that tell you the state of previous steps that have run.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/contexts">Contexts</a></strong>: there are lots of contextual objects your jobs can use, such as objects for getting information about git (what branch we're dealing with, the commit SHA etc), environment variables, secrets, data exposed by other jobs and lots more.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions">Syntax</a></strong>: this is the most important page as it details all the yaml configuration syntax (so I come here often).
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/workflow-commands-for-github-actions">Commands</a></strong>: when executing a shell command (or script) you can use <code>echo</code> with a specific format and, depending on the format used, it'll take on special meaning to the workflow runner and can be used (among other things) for displaying rich messaging in the GitHub UI.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/environment-variables">Environment variables</a></strong>: most of the 'context' properties are also exposed as environment variables to make it easier for your shell commands/scripts to utilise.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/reusing-workflows">Reusing workflows</a></strong>: If you have a bunch of jobs all doing a similar thing (e.g. you've three jobs and each of them setup a specific set of environment variables before installing the rust programming language), then you can move that duplication into a separate workflow file that your main workflow can call out to.
<h3 id="GitActionstopic-2">Experimenting</h3>
The best thing to do when it comes to learning GitHub Actions is to create a test repo as a playground, like I did here: <a href="https://github.com/Integralist/actions-testing">https://github.com/Integralist/actions-testing</a>.
You can of course use an existing repo if you want, but I prefer to use something completely decoupled when I'm testing a new tool.
<h3 id="GitActionstopic-3">Workflows</h3>
As I mentioned earlier: everything starts with a workflow.
To create a workflow you must save a yaml file into the <code>.github/workflows</code> directory of your project's git repo.
In the following example you'll see I have created three separate workflows:
<code>├── .github
│   └── workflows
│       ├── my-first-workflow.yaml
│       ├── my-second-workflow.yaml
│       └── my-third-workflow.yaml
</code>
You can create as many workflows as you need to, and you can name a workflow file anything you like.
<h3 id="GitActionstopic-4">Events</h3>
Once we create a workflow file, let's see how we can trigger any jobs that are defined within the workflow. 
Be aware that in the following example workflow I have not defined any jobs, I'm focusing on the events configuration only:
<code>name: My Workflow
on:
  push:
  schedule:
    - cron: "0 0 1 * *"   # https://crontab.guru/every-month
    - cron: "*/5 * * * *" # https://crontab.guru/every-5-minutes
</code>
So we can see I've given my workflow a name using the <code>name</code> key, and I've defined some events using the <code>on</code> key:
<code>push</code>: any push to your repo, whether it be to your <code>main</code> branch or a pull-request branch, will trigger your job(s) to run.
<code>schedule</code>: run your job(s) on a schedule using cron syntax, which in this example triggers job(s) every five minutes and monthly.
<strong>NOTE</strong>: <a href="https://crontab.guru/">https://crontab.guru/</a> makes dealing with cron syntax easy.
Refer to GitHub's <a href="https://docs.github.com/en/actions/learn-github-actions/events-that-trigger-workflows">events documentation</a> to learn more about the various events you can configure. 
For example, you can restrict a workflow to only execute against a specific branch.
<h3 id="GitActionstopic-5">Environment</h3>
Each job runs inside its own virtual machine 'runner', which means (just as an example) files you create, or data you produce, will not persist across jobs. 
This includes things like environment variables.
<h3 id="GitActionstopic-6">Example Job</h3>
Let's take a look at a very simple job:
<code>name: Test Workflow
on: push
jobs:
  simple-job:
    runs-on: ubuntu-latest
    steps:
      - name: Say Hello
        run: echo 'hello'
</code>
Let's now break apart this workflow to understand what it's doing..
<code>name</code>: the name for the workflow.
<code>on</code>: the event(s) we want to have trigger our job(s).
<code>jobs</code>: a list of jobs we want to be executed under this workflow.
<code>simple-job</code>: a job that consists of nested configuration.
<code>runs-on</code>: the environment I want the job to run in.
<code>steps</code>: a list of steps to run under the job.
<code>name</code>: the name of the step, which can be omitted but it makes the output in the GitHub UI nicer.
<code>run</code>: the shell command/script I want to run (in this example, my command prints the string <code>hello</code>).
<strong>NOTE</strong>: Refer to the GitHub <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#github-hosted-runners">runner documentation</a> to see what other environments are available. 
Also refer to the <a href="https://github.com/actions/virtual-environments">virtual-environments</a> repo to see what is installed on each runner's operating system.
As you can see, defining a workflow and its jobs/steps is actually very simple and intuitive. 
Now we can start looking at using more features and how to take advantage of the platform.
<h3 id="GitActionstopic-7">Environment Variables</h3>
GitHub Actions let you configure environment variables in multiple places depending on the scope they should have.
You can define environment variables globally, so they're available to all jobs (and all steps within those jobs), or at a job level (so they can be accessed by all steps within the specific job) or at a step level, meaning only a specific step will have access to them.
I'll demonstrate environment variable configuration in the following example:
<code>name: Testing Environment Variables
on: push
env:
  FOO: bar
jobs:
  validate-env-vars:
    runs-on: ubuntu-latest
    env:
      LITERAL: whatever
      INTERPOLATION: ${{ github.ref_name }}
      EXPRESSION: $(echo ${{ github.ref_name }} | perl -pe 's/[^a-zA-Z0-9]+/-/g' | perl -pe 's/(\A-|-\Z)//g' | awk '{print tolower($0)}')
    steps:
      - name: Print Global Environment Variables
        run: echo $FOO
      - name: Print Job Environment Variables
        run: |
          echo ${{ env.LITERAL }}
          echo ${{ env.INTERPOLATION }}
          echo ${{ env.EXPRESSION }}
          echo $LITERAL
          echo $INTERPOLATION
          echo $EXPRESSION          
      - name: Print Step Environment Variables:
        env:
          STEPVAR: my step
        run: |
          echo ${{ env.STEPVAR }}
          echo $STEPVAR          
</code>
OK, so there's a few things to unpack from the above example workflow.
The first thing I want to clarify is that when running shell commands/scripts using <code>steps.run</code> you can either define multiple steps like so:
<code>- run: echo hello
- run: echo world
</code>
Or alternatively you can use the pipe <code>|</code> character to indicate the value spans multiple lines, like so:
<code>- run: |
  echo hello
  echo world  
</code>
I would tend towards using separate <code>run</code> steps rather than one long multi-line <code>run</code> because it's harder to handle errors (or know where an error occurred) in the latter approach.
The next thing to clarify is that there are two ways to access an environment variable:
<ol>
<strong>Interpolation</strong>: <code>${{ ... 
}}</code> (e.g. <code>echo ${{ env.LITERAL }}</code>).
<strong>Variable reference</strong>: <code>$VARNAME</code> (e.g. <code>echo $LITERAL</code>).
</ol>
It's important to understand that although the output between the two approaches is the same, there is still a distinction worth being aware of.
With interpolation the value is acquired by looking up the relevant key within the <a href="https://docs.github.com/en/actions/learn-github-actions/contexts#env-context"><code>env</code> context object</a>, and then the value is injected into the shell command to be executed, while the more traditional variable reference approach works by the shell instance looking up the environment variable to access the value.
So when you look at the GitHub Actions GUI (e.g. <code>https://github.com/&lt;USER&gt;/&lt;REPO&gt;/actions/runs/&lt;ID&gt;</code>) and you look through the job output for the <code>LITERAL</code> example, then you'll see something like:
<code data-lang="bash">echo whatever
echo $LITERAL
</code>
This is because the first line used interpolation, so really the shell command was just echo'ing the literal value, where as the second line was echo'ing the <em>result</em> of looking up the environment variable.
In our example workflow you can see we defined a global environment variable called <code>FOO</code>, we also defined a job level set of environment variables (<code>LITERAL</code>, <code>INTERPOLATED</code> and <code>EXPRESSION</code>), and finally we defined a step level environment variable called <code>STEPVAR</code>.
Let's take a moment to clarify the job level environment variables as these demonstrate something important, which is although the <code>EXPRESSION</code> variable was assigned a shell command, that command isn't <em>evaluated</em> and so the literal characters are assigned as the value.
If you thought the <em>result</em> of the shell command (e.g. acquire the branch name from the <code>github</code> context object, and then do some normalisation of the name using a combination of <code>perl</code> and <code>awk</code>) would be assigned to the environment variable, then you would have been wrong.
Only the <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idstepsrun"><code>steps.run</code></a> key will actually evaluate a given shell command/script.
Now if the only way to evaluate a shell command is via <code>steps.run</code>, then how can we dynamically assign a value to an environment variable?
Consider this example, you're a <a href="https://nodejs.org/en/">Node.js</a> developer and you're using the Node version manager <code>nvm</code> along with a <a href="https://github.com/nvm-sh/nvm#nvmrc"><code>.nvmrc</code> file</a> to control which version of Node your project uses.
You're also using GitHub actions and you want to use a pre-existing action to manage installing Node on your job runner (we'll dig into third-party actions later, but for now just know that they are a thing).
This is where things get a little funky, because third-party actions can't evaluate shell commands given as inputs. 
So the most popular third-party action for installing Node is <a href="https://github.com/actions/setup-node"><code>actions/setup-node</code></a> and it allows you to specify the version of Node to install but it has to be a literal value.
The following example demonstrates how to side-step this restriction by using a <code>steps.run</code> to dynamically access the value inside the <code>.nvmrc</code> file and to then update the local environment with a new variable holding that value. 
This means you can then use interpolation to access that value and pass it into the <code>actions/setup-node</code> action:
<code>name: Testing Dynamic Environment Variable Value
on: push
jobs:
  validate-env-vars:
    runs-on: ubuntu-latest
    steps:
      - name: Generate Dynamic Environment Variable
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - name: Print NODE_VERSION
        run: |
          echo ${{ env.NODE_VERSION }}
          echo $NODE_VERSION          
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
</code>
The trick is to update a GitHub Actions provided environment variable called <code>$GITHUB_ENV</code>. 
All the following steps will then have an environment that includes whatever is in <code>$GITHUB_ENV</code>.
<strong>NOTE</strong>: You could also use the output of a step as the input to the <code>actions/setup-node</code> action, but we'll look at that feature later.
<h3 id="GitActionstopic-8">Secrets</h3>
The previous Node.js example workflow actually leads us quite nicely into this section about <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets#using-encrypted-secrets-in-a-workflow">secrets</a>.
Let's see a common solution to accessing a private NPM repository..
<code>name: Testing GITHUB_TOKEN access restrictions
on: push
jobs:
  testing:
    runs-on: ubuntu-latest
    steps:
      - name: Acquire Node Version
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
      - name: Authorize access to private packages
        run: echo "//npm.pkg.github.com/:_authToken=${{ secrets.GITHUB_TOKEN }}" &gt; ~/.npmrc
</code>
What we're doing here is installing Node.js and then modifying a <code>.npmrc</code> file so that it knows, when we do an <code>npm install</code>, to use an authentication token because the repository we want to use to get at our dependencies is otherwise private.
You'll see we're using a <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets"><code>secrets</code> context object</a> to access a <code>GITHUB_TOKEN</code> value to use as our authentication token. 
This should be fine, but it doesn't work and our authentication with the private NPM repository fails.
Let's take a moment to learn a bit about GitHub 'secrets'..
In the GitHub UI for a repo/project you can add secrets that are encrypted and made accessible to your workflow via the <code>secrets</code> context object. 
But additionally GitHub Actions provides access to a secret called <a href="https://docs.github.com/en/actions/security-guides/automatic-token-authentication#about-the-github_token-secret"><code>GITHUB_TOKEN</code></a>.
I'll just refer you to the GitHub documentation, as it explains it best:
At the start of each workflow run, GitHub automatically creates a unique GITHUB_TOKEN secret to use in your workflow. 
When you enable GitHub Actions, GitHub installs a GitHub App on your repository. 
The GITHUB_TOKEN secret is a GitHub App installation access token. 
You can use the installation access token to authenticate on behalf of the GitHub App installed on your repository. 
The token's permissions are limited to the repository that contains your workflow.
That last sentence is the important bit! What essentially it means is that you can't use <code>secrets.GITHUB_TOKEN</code> to access things outside of the project repo.
So to solve our problem we still need to use the <code>secrets</code> context object, but instead of using the default <code>GITHUB_TOKEN</code> we're going to need to create a new <a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token">Personal Access Token</a> (PAT).
Once you create a PAT, as long as the user account that creates the PAT has access to the private repository, we can paste the PAT into the GitHub secrets UI.
For the sake of an example let's say you create a new secret called <code>NPM_AUTH_TOKEN</code> and paste the PAT value into it. 
We can now reference the secret token value via the <code>secrets</code> context object in our workflow file:
<code>name: Testing with Personal Access Token
on: push
jobs:
  testing:
    runs-on: ubuntu-latest
    steps:
      - name: Acquire Node Version
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
      - name: Authorize access to private packages
        run: echo "//npm.pkg.github.com/:_authToken=${{ secrets.NPM_AUTH_TOKEN }}" &gt; ~/.npmrc
</code>
Notice that the workflow file basically hasn't changed, except we swapped <code>secrets.GITHUB_TOKEN</code> for <code>secrets.NPM_AUTH_TOKEN</code>.
<h3 id="GitActionstopic-9">Third Party Actions</h3>
An action is just code that interacts with your repository. 
It's possible to write your own custom actions and to share them with the community.
If you want to learn more about creating your own actions, then refer to GitHub's “<a href="https://docs.github.com/en/actions/creating-actions/about-custom-actions">About custom actions</a>”.
There are a bunch of third-party actions that you'll see used a lot..
<a href="https://github.com/actions/checkout"><code>actions/checkout</code></a>
<a href="https://github.com/actions/cache"><code>actions/cache</code></a>
<a href="https://github.com/actions/setup-go"><code>actions/setup-go</code></a>
<a href="https://github.com/actions/setup-node"><code>actions/setup-node</code></a>
<a href="https://github.com/actions-rs/toolchain"><code>actions-rs/toolchain</code></a>
All of the above actions, with the exception of the last, are official GitHub maintained actions. 
This means they are considered safe to use in your workflows (remember that an action runner will be able to use your <code>secrets.GITHUB_TOKEN</code>). 
See also <a href="https://github.com/actions">https://github.com/actions</a> for more official/verified actions you can use.
<strong>NOTE</strong>: I've no idea why they don't provide a Rust action.
<h3 id="GitActionstopic-10">Conditions</h3>
You can use an <code>if</code> conditional statement to control whether a job or step is run. 
It's best to use this feature if you need to <em>skip</em> a job/step apposed to using an exit code from within a <code>run</code> shell command/script to stop a job/step that has already started to run.
One important caveat to using <code>if</code> in a workflow is that you <em>must</em> use single quotes and not double quotes. 
Consider the following example, which you might expect to only run the job if the GitHub branch affected is <code>main</code>..
<code>name: Testing with Double Quotes
on: push
jobs:
  run-if-main:
    if: ${{ github.ref_name == "main" }}
    runs-on: ubuntu-latest
    steps:
      - run: echo hello
</code>
<strong>NOTE</strong>: Expressions can omit the surrounding <code>${{ ... 
}}</code> but I tend to include it.
The above example won't work simply because the string <code>"main"</code> is using double quotes. 
You'll find the requirement for using single quotes is mentioned in the GitHub documentation for “<a href="https://docs.github.com/en/actions/learn-github-actions/expressions#literals">Literals</a>”.
If you want to learn more about the available operators, like <code>==</code>, <code>!=</code> and <code>&amp;&amp;</code> etc, then refer to the <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#operators">operators documentation</a>.
<h3 id="GitActionstopic-11">Persisting Data</h3>
A GitHub Action job does not persist data by default, as each job runs within its own 'runner'. 
To persist data we can use either a:
<ol>
Cache (<a href="https://github.com/actions/cache"><code>actions/cache</code></a>)
Artifact (<a href="https://github.com/actions/upload-artifact"><code>actions/upload-artifact</code></a>, <a href="https://github.com/actions/download-artifact"><code>actions/download-artifact</code></a>)
Job Output (<a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idoutputs"><code>outputs</code> documenation</a>)
</ol>
Caching is quick but isn't always ideal as it requires the use of I/O to create files to be cached, and then also we have to coordinate reading values back from disk and parsing the data contained within those files etc. 
Caching is best used for simple situations such as caching installed programming language dependencies.
Artifacts are slow as they need to upload and download files from GitHub's servers and also this requires two separate external actions to configure, making them not ideal for quick data persistence (and also makes 'simple' data persistence scenarios tedious).
To persist data using a job's output requires a job to produce some data and to expose that data via the job's <code>outputs</code> field. 
A consumer can then use and parse that data however they see fit. 
This approach can also be useful for dynamically generating job matrix variants using a job's <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idstrategy"><code>strategy.matrix</code></a> field.
<strong>NOTE</strong>: A job has an <code>outputs</code> field, but also individual steps can access the output from a previous step by way of the same mechanism, which is a step needs to set an <code>id</code> field which either another step or the job itself can reference.
The way your <code>run</code> code (or an external shell script) can produce data that the GitHub job can reference is to <code>echo</code> a specially formatted string:
<code data-lang="bash">echo "::set-output name=&lt;name&gt;::&lt;data&gt;"
</code>
So in the following example we produce the data <code>bar</code> and we make it accessible via the name <code>foo</code>:
<code data-lang="bash">echo "::set-output name=foo::bar"
</code>
Now in the following example our GitHub job has two steps, and the latter step is accessing data produced by the first step:
<code>name: Produce Data
on: push
jobs:
  example:
    runs-on: ubuntu-latest
    steps:
      - id: produce-data
        run: echo "::set-output name=foo::bar"
      - run: echo ${{ steps.produce-data.outputs.foo }}
</code>
<strong>NOTE</strong>: Be sure to use the <code>id</code> field so the second step can use it to reference the first step's output!
<h3 id="GitActionstopic-12"> Using shared job data to determine if subsequent job should run</h3>
In the following example the <code>bar</code> job will not run if the required fields <code>foo</code> and <code>baz</code> aren't set to <code>true</code>.
Notice the data I produce within job <code>foo</code> is a simple array/list whose elements are strings who have a format of <code>key=value</code>:
<code>name: Produce Data To Control Job Run
on: push
jobs:
  foo:
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.footest.outputs.data }}
    steps:
      - run: |
          echo "FOO=true" &gt;&gt; $GITHUB_ENV
          echo "BAR=false" &gt;&gt; $GITHUB_ENV
          echo "BAZ=true" &gt;&gt; $GITHUB_ENV          
      - id: footest
        run: echo ::set-output name=data::[\"foo=$FOO\", \"bar=$BAR\", \"baz=$BAZ\"]
  bar:
    needs: foo
    if: ${{ contains(needs.foo.outputs.data, 'foo=true') &amp;&amp; contains(needs.foo.outputs.data, 'baz=true') }}
    runs-on: ubuntu-latest
    steps:
      - run: echo 'yay! we ran because the fields were set to true'
  build:
    needs: bar
    runs-on: ubuntu-latest
    steps:
      - run: echo 'yay! this job ran as the bar job was successful'
</code>
The key part to getting job <code>bar</code> to determine if it should run is to use an <code>if</code> along with one of GitHub's native functions called <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#contains"><code>contains()</code></a>. 
You can see I use it twice to check if the persisted data contains the values I'm looking for.
<strong>NOTE</strong>: You'll likely want to use the <code>needs</code> property to help make the jobs run sequentially. 
Otherwise without it the jobs will run in parallel and this means there would be a data race in <code>bar</code> trying to access the <code>foo</code> job's output which might not yet be available and this would cause both the <code>bar</code> job and its dependant <code>build</code> job to not be run.
<h3 id="GitActionstopic-13"> Persist data using <code>strategy.matrix</code></h3>
Below is an example of using JSON data from <code>job1</code> and exposing it to <code>job2</code>. 
This approach of using <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#fromjson"><code>fromJSON</code></a> with data from another job to create a matrix is really cool, but otherwise this approach (as far as data persistence is concerned) isn't ideal because it requires the JSON data produced by the first job to have a very specific structure that the <code>strategy.matrix</code> expects. 
So to reiterate I'm not using <code>strategy.matrix</code> in this example because I want a matrix but just to demonstrate a clever way to persist data without having to resort to using either caching or artifacts.
With this in mind I needed to ensure I set the value of each matrix field to be a <em>list</em> type that contains a <em>single</em> entry.
If I didn't use a list type then the <code>strategy.matrix</code> would fail to parse my JSON data. 
I purposely ensure there is only a single value within the list because I don't actually need my data to cause the job to be run multiple times. 
This is because a <code>strategy.matrix</code> is typically used to generate multiple 'variants' of a job. 
By setting a single value inside a list, we ensure there is only ever one job variant generated (i.e. only one job is created), and that single job can simply reference the fields within the matrix as data points of interest.
<code>name: example
on: push
jobs:
  job1:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - id: set-matrix
        run: echo "::set-output name=matrix::{\"FOO\":["abc"],\"BAR\":["xyz"]}"
  job2:
    needs: job1
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{fromJSON(needs.job1.outputs.matrix)}}
    env:
      FOO: ${{ matrix.FOO }}
      BAR: ${{ matrix.BAR }}
    steps:
      - run: echo ${{ matrix.FOO }} # abc
      - run: echo ${{ matrix.BAR }} # xyz
</code>
<h3 id="GitActionstopic-14"> Clarify the cache action</h3>
OK, so as far as data persistence is concerned, we have the <code>actions/cache</code> action we can use as an option. 
It's actually not very obvious how this action works and so I thought I'd take a brief moment to clarify my understanding, which then helped me to better understand how I could use it for data persistence outside of just caching language dependencies (which is what most examples are based on).
The <code>actions/cache@v2</code> works like so, you have to define a new step like so:
<code>- uses: actions/cache@v2
  with:
    path: path/to/be/cached
    key: ${{ runner.os }}-my-cache-key
</code>
When the step that implements the action is executed (see above snippet), the cache action simply looks up the cache key (e.g. <code>Linux-my-cache-key</code>) and if it finds something in the cache, then it restores the cache to the path you specified (e.g. <code>path/to/be/cached</code>).
If the cache action doesn't find anything in the cache, then nothing happens.
Now the important bit: the cache action has a 'post run' event that executes once your job has finished successfully. 
The cache action will be run again and this time it stores whatever was in your given path into the cache using the key you said it should be stored under.
This means, when it comes to running another job, you need to ensure you define the cache action <em>again</em> (the same as you defined it in your first job). 
This is so all of what I've just explained will happen again in your second job (i.e. it'll lookup the key but this time it'll find something in the cache thanks to the 'post run' step from the first job). 
The only difference now in the second job is that in the 'post run' event, when the action gets run again, you'll now see something like..
Cache hit occurred on the primary key <code>Linux-my-cache-key</code>, not saving cache.
Meaning there was nothing else to do. 
I imagine if there were changes to the files in the given path then it would indicate the cache was updated with the latest files.
<h3 id="GitActionstopic-15">Reusable Workflows</h3>
If you have a bunch of setup configuration that is the same between jobs, then you can move that configuration into a separate workflow file that can then be imported and used by each job in your main workflow file.
The following example, demonstrates how to <em>call</em> (i.e. import) a reusable workflow:
<code>jobs:
  build:
    ...
  deploy:
    ...
  validate-foo:
    uses: integralist/actions-testing/.github/workflows/resuable-setup@main # install node, rust, setup env vars etc
    steps: 
      - ...
  validate-bar:
    uses: integralist/actions-testing/.github/workflows/resuable-setup@main # install node, rust, setup env vars etc
    steps: 
      - ...
</code>
An example implementation of a reusable workflow would be:
<code>name: Reusable workflow for validation scripts
on:
  workflow_call:
    inputs:
      install_node:
        type: bool
      name:
        required: true
        type: string
      description:
        required: true
        type: string
      script:
        required: true
        type: string
jobs:
  validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - if: ${{ github.event_name != 'schedule' }}
        run: exit 1
      - if: ${{ inputs.install_node }}
        name: Environment
        run: |
                    echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - if: ${{ inputs.install_node }}
        uses: actions/setup-node@v2
        id: node-yarn
        with:
          node-version: "${{ env.NODE_VERSION }}"
          cache: yarn
      - name: status update
        uses: ouzi-dev/commit-status-updater@v1.1.2
        with:
          name: ${{ inputs.name }}
          description: ${{ inputs.description }}
          status: pending
      - id: validator
        run: ${{ inputs.script }}
      - if: ${{ success() }}
        name: status update
        uses: ouzi-dev/commit-status-updater@v1.1.2
        with:
          name: ${{ inputs.name }}
          description: ${{ steps.validator.outputs.description }}
          status: ${{ steps.validator.outputs.status }}
</code>
Notice that in the reusable workflow we have a new event <code>workflow_call</code> that helps us to define <em>inputs</em> for the job being called.
In this reusable job we define a bunch of inputs which helps us to control whether the steps in the job are run (making the reusable job even more flexible) by utilising a step's <code>if</code> condition and interpolating the input value.
For example, we don't always install the Node.js programming language, only if the caller requests it:
<code>- if: ${{ inputs.install_node }}
  uses: actions/setup-node@v2
  id: node-yarn
  with:
    node-version: "${{ env.NODE_VERSION }}"
    cache: yarn
</code>
Now one important consideration is that the reusable workflow will not inherit the parent workflow's environment. 
This means secrets and environment variables need to be passed in via either <code>workflow_call.inputs</code> or <code>workflow_call.secrets</code>.
Annoyingly you can't just set an input with <code>${{ env.FOO }}</code> because the <code>env</code> context object can't be referenced. 
So if your reusable job is used a lot then you either have to hardcode the value as an <code>input</code> to the reusable workflow or you store the environment variable as a secret in the GitHub UI so that you can reference it from the <code>workflow_call.secrets</code> property.
<h3 id="GitActionstopic-16">Conclusion</h3>
There is so much more to explore with GitHub Actions. 
The bits I've mentioned here are just the tip of the iceberg. 
I strongly recommend you read the documentation and have a play around with these, and other features. 
Let me know on twitter what you think of GitHub Actions and whether you're using it in your projects.


<h2>Using branches in Git</h2>
<div id="Usingbranchestoc"><a href="#Usingbranchestopic-0" target="_self">Using branches in Git</a><br><a href="#Usingbranchestopic-1" target="_self">Why and how branches are used in Git</a><br><a href="#Usingbranchestopic-3" target="_self">Pre-requisites:</a><br><a href="#Usingbranchestopic-4" target="_self">What are Git branches</a><br><a href="#Usingbranchestopic-5" target="_self">Commands used with branches</a><br><a href="#Usingbranchestopic-6" target="_self">Using branches for pull requests</a><br><a href="#Usingbranchestopic-7" target="_self">Resources:</a><br><a href="#Usingbranchestopic-8" target="_self">Glossary:</a><br><a href="#Usingbranchestopic-9" target="_self">Links:</a><br></div>
<h3 id="Usingbranchestopic-1">Why and how branches are used in Git</h3>
Version control systems like Git help manage changes to files. 
Sometimes, you’ll want (or need) to make some ‘feature’ or ‘patches’ to a collaborative research project. 
Or maybe you want to make some experimental changes to your code, but don’t want to touch your main code. 

This, and more, is where branches come into play.
In this code-along we’ll go over what branches are, and how and why you would use them.
<h3 id="Usingbranchestopic-3">Pre-requisites:</h3>
Obviously, have <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">Git installed</a>
Make sure to <a href="http://codeasmanuscript.org/lessons/git/cheatsheet/">configure your git</a>
<h3 id="Usingbranchestopic-4">What are Git branches</h3>
In very simple terms, git branches are individual projects within a git repository. 
Different branches within a repository can have completely different files and folders, or it could have everything the same except for some lines of code in a file.

Let’s use a few real world examples (at least that I’ve used before, others may have used them differently):
Pretend you submitted a research article to a journal and they want you to revise it based on some reviewers comments. 
There are several ways to deal with the comments, so instead of changing your main manuscript, you create a
<code>revision</code> branch in your manuscript git repository. 
In that branch you make the changes to your manuscript in response to the reviewers. 
Once you are satisfied,
you merge the branch into the <code>master</code> branch and resubmit the article.
Imagine you have a dataset that multiple people work off of but that is also often updated with more data. 

You think you found a problem with the dataset, but aren’t sure. 
So you create a new branch <code>fixing</code> to fix the problems without messing with the master dataset. 
After you confirm the problem is real and that you have the solution, you submit a pull request of the <code>fixing</code> branch to be merged with the <code>master</code> branch.
What is often the case in software development, a bug or missing feature in the software gets identified. 
Because the software is already in production use (fairly stable, other people rely on it, etc), you can’t just make changes to the main software code. 

So a <code>hotfix</code> or <code>feature</code> branch is created to address these problems, which will eventually get merged in with the <code>master</code> branch for the next version of the software. 
This ensures that other people’s code isn’t broken everytime a bug gets fixed.
There are many uses of branches in Git. 
The nice (and very powerful) thing about Git is the fact that branches are very cheap compared to other version control systems. 

By cheap, I mean they don’t take up much disk space, it’s computationally easy to move between branches, and it’s (relatively) easy to merge branches together. 
This is because of how Git represents branches, since they are simply <em>pointers</em> or an individual commit. 
<em>That’s it.</em> Just a pointer… Git commit history is a 
<a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graph</a>, 
which means that every single commit always has a ‘parent’ commit (the previous commit in the history, or multiple parents when a merge happens), and any individual commit can have multiple ‘children’. 
This history can be traced back through the ‘lineage’ or ‘ancestry’. 
The branch just gives a name to each ‘lineage’ when a commit has multiple children.

When you merge two branches together, the commit histories get merged together as well. 
Which means that all the changes you made in each branch gets combined back into a single lineage, rather than two. 
This makes it easier to work collaboratively on a project, since each individual could work on their own branches, without dealing with the messiness that could come from working all on one branch.
<h3 id="Usingbranchestopic-5">Commands used with branches</h3>
Branches are best understood visually. 
So let’s first start with using 
<a href="https://onlywei.github.io/explain-git-with-d3/">this website</a> to see what the 
<code>branch</code>, <code>checkout</code>, and <code>merge</code> commands are doing.
After we’ve tried that, let’s do it locally (on your own computer). 
Here is a sequence of commands to try out:
<div><div><code>cd ~/Desktop mkdir 
git-branches
cd git-branches 
git init # start a repo 
git add .
git commit -m "First commit" # make the first commit 
git branch testBranch # create branch 
git checkout testBranch # move to branch
## can also do git checkout -b testBranch
echo "Some text" > file.txt 
git add file.txt
git commit -m "Added a file with text"
git checkout master
echo "Text in another file" > new-file.txt 
git add new-file.txt 
git commit -m "Added another file"
git log --graph --oneline --decorate --all
# This command is long, so shorten it using aliases 
git config --global alias.lg 'log --graph --oneline --decorate --all'
git merge testBranch 
git lg 
git branch -d testBranch # delete the branch</code>

<h3 id="Usingbranchestopic-6">Using branches for pull requests</h3>
I mentioned this already, but branches are best used when doing a 
<a href="https://help.github.com/articles/using-pull-requests/">pull request</a> (unless the pull request is very small or few people work on the repository).
The steps to take would be:
Fork a repository on GitHub Clone it onto your computer Make a branch and move to it: <code>git checkout -b fixingBranch</code>
Make changes to the files Commit the changes to the history Push the branch up to your forked version: <code>git push origin fixingBranch</code>
On GitHub, submit a Pull Request of your <code>fixingBranch</code>
Once the pull request is merged, 
<a href="https://github.com/blog/1377-create-and-delete-branches">delete</a> 
the <code>fixingBranch</code> on your forked repo on GitHub and on your computer 
(<code>git checkout master &amp;&amp; 
git pull upstream master &amp;&amp; 
git branch -d fixingBranch</code>)

<h3 id="Usingbranchestopic-7">Resources:</h3>
If you have any questions, often one of the best places to start is either<br>
<a href="https://stackoverflow.com/questions/tagged/git">StackOverflow</a> or Google (which more likely links to StackOverflow).
<h3 id="Usingbranchestopic-8">Glossary:</h3>
<code>cd</code> - change directory directory - the same thing as a folder
<code>mkdir</code> - make a directory
<code>echo</code> - print a message to the screen or to a file if <code>></code> (redirect) is present.
<code>git init</code> - start or initialize a git repository
<code>git add</code> - put a file into the staging area, so that git starts tracking it
<code>git commit</code> - send files in the staging/index area into the history (the git repository)
<code>git log --graph --oneline --decorate --all</code> - view the commit history in the git repository and the branches, with each commit as one line.
<code>git branch</code> - An individual line of commit history that contains files that may differ from other branches.
<code>git checkout</code> - A way to move across the git commits and branches.
<code>git merge</code> - Combine a branch into the current checked out branch (i.e. the branch you are on).
<h3 id="Usingbranchestopic-9">Links:</h3>
<a href="https://pcottle.github.io/learnGitBranching/">Interactive, visual tutorial on branching</a>
<a href="https://www.atlassian.com/git/tutorials/using-branches/git-branch">Brief explanation of branching</a>


<h2>create an orphan branch</h2>
git checkout --orphan <branchname>
This will create a new branch with no parents.
Then, clear everything in the orphan branch

git rm --cached -r
or
git rm -rf

and add the documentation files, commit them and push them up to github.

to check log
git log

A pull or fetch will always update the local information about all the remote branches.
If you only want to pull/fetch the information for a single remote branch, you need to specify it.

To switch back to your master branch
git checkout master

return to the orphan branch
git checkout mybranch

added first file in the new branch
git commit -m

git push origin new_branch_name






<h2>What are SSH Keys?</h2>
<div id="SSHKeystoc"><a href="#SSHKeystopic-1" target="_self">The History of The SSH Protocol</a> <a href="#SSHKeystopic-2" target="_self">What are SSH keys?</a> <a href="#SSHKeystopic-3" target="_self">How User Keys Work</a> <a href="#SSHKeystopic-4" target="_self">First Steps – SSH Key Generation</a> <a href="#SSHKeystopic-5" target="_self">Linux/Mac Instructions:</a> <a href="#SSHKeystopic-6" target="_self">Windows Instructions:</a> <a href="#SSHKeystopic-7" target="_self">How SSH Key Authentication Works</a> <a href="#SSHKeystopic-8" target="_self">Managing SSH Keys</a> <a href="#SSHKeystopic-9" target="_self">Cloud IAM offers SSH Key Management</a> </div>
If you spend enough time in an IT environment and with the rise of cloud infrastructure such as AWS, you will likely come across the term SSH keys. 
If you’ve already come across this IT term, then you might find yourself wondering, what are SSH keys?

SSH (Secure Shell) keys are an access credential that is used in the SSH protocol and they are foundational to modern Infrastructure-as-a-Service platforms such as AWS, Google Cloud, and Azure.
Before this post delves into an explanation on what are SSH keys, let’s take a quick look at the SSH protocol.

<h3 id="SSHKeystopic-1">The History of The SSH Protocol</h3>
The first version of the SSH protocol was developed in the summer of 1995 by Tatu Ylonen. 
Tatu was a researcher at the University of Helsinki when a sniffing attack was discovered on the university network. 

A sniffing attack intercepts and logs the traffic that takes place on a network and can provide attackers with usernames and passwords which can then be used to gain access to critical IT assets.
Thousands of credentials were impacted, including those belonging to community partnerships. 
This sniffing attack motivated Tatu to figure out how to make networks more secure, and this ultimately led to the creation of the SSH protocol (<a href="https://youtu.be/OHBdKM7s5V4">SSH.com</a>).

Today, the SSH protocol is widely used to login remotely from one system into another, and its strong encryption makes it ideal to carry out tasks such as issuing remote commands and remotely managing network infrastructure and other vital system components. 
This is especially important in the era of cloud infrastructure and remote work.
To use the SSH protocol, a couple pieces of software need to be installed. 

The remote systems need to have a piece of software called an SSH daemon, and the system used to issue commands and manage the remote servers needs to have a piece of software called the SSH client. 
These pieces of software are necessary to create a proper communication channel using the SSH protocol (<a href="https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#ssh-overview">DigitalOcean</a>).
Essentially, SSH keys are an authentication method used to gain access to an encrypted connection between systems and then ultimately use that connection to manage the remote system.

<h3 id="SSHKeystopic-2">What are SSH keys?</h3>
SSH keys come in many sizes, but a popular choice is an<a href="https://www.linkedin.com/pulse/2048-bit-encryption-what-why-does-matter-srini-vasan"> RSA 2048-bit encryption</a>, which is comparable to a 617 digit long password. 
On Windows systems, it is possible to<a href="http://statistics.berkeley.edu/computing/ssh-keys"> generate your own SSH key pair</a> by downloading and using an SSH client like PuTTY. 

On Mac and Linux systems, it is possible to generate an SSH key pair using a terminal window. 
Watch the video below to find out how to generate your own RSA key pair on Mac and Linux.
<iframe src="https://www.youtube.com/embed/FocgH8gTFVw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

SSH keys always come in pairs, and every pair is made up of a private key and a public key. 
Who or what possesses these keys determines the type of SSH key pair. 
If the private key and the public key remain with the user, this set of SSH keys is referred to as user keys.

If the private and public keys are on a remote system, then this key pair is referred to as<a href="https://www.ssh.com/ssh/host-key"> host keys</a>. 
Another type of SSH key is<a href="https://www.ssh.com/ssh/session-key"> a session key</a>. 
When a large amount of data is being transmitted, session keys are used to encrypt this information.

Now let’s take a closer look at how a private key and public key work. 
To keep things simple, we will focus on how user keys work.

<h3 id="SSHKeystopic-3">How User Keys Work</h3>
In a user key set, the private key remains on the system being used to access the remote system (i.e. the user’s desktop or laptop) and is used to decrypt information that is exchanged in the SSH protocol.
Private keys should never be shared with anyone and should be secured on a system – i.e. the system is secured (full disk encryption,<a href="https://jumpcloud.com/platform/multi-factor-authentication-mfa"> MFA</a>), in the user’s possession, and the private key is secured via passphrase.
A public key is used to encrypt information, can be shared, and is used by the user and the remote server. 
On the server end, the public key is saved in a file that contains a list of authorized public keys. 

<h3 id="SSHKeystopic-4">First Steps – SSH Key Generation</h3>
Before you can start using SSH keys, first you need to generate your own SSH key pair on the system you would like to use to access a remote system. 
Please see the instructions below.

<h3 id="SSHKeystopic-5">Linux/Mac Instructions:</h3>
<strong>Recommended</strong>: Install or Update OpenSSH
<code>sudo apt-get update
sudo apt-get install openssh-server</code>

First, load a command line terminal and type the following command:
<img src="https://lh4.googleusercontent.com/j4-CVJ1I-xRjdZOaZ8cXqN2hSUpCCYWDFe2oQK9i4XFt84BhrimIatRnpfRcKwMgVsJwCoMReFzODKRTPt5sHAy0oHyWN3Vgt7NrqBpDJ-CgBmYfTYdO2kj8gdGJtPw0juumpuQt">
Your two key files will be created in the /HOME/.ssh/ directory by default, including your private key, but you may specify a direct location. 

<strong>Never share your private key.</strong>
<strong>$HOME/.ssh/id_rsa.pub (public key</strong>
<strong>$HOME/.ssh/id_rsa (private net)</strong>

<img src="https://lh3.googleusercontent.com/8ve6RT8yo_KzV422Ute-qa_mZoI6eJVAZQXqu0SSKnbCZGDLVSKyAPcyipPYWSE-m0nRbemjldlHlASXaMhmq9ShIEJWydAfgvw8EgZmNTqhUrcY4S1MfXVW48c-H_j_lFvKVE98">

Per above, you’ll be given the option to set a passphrase to make it more difficult for unauthorized users to log into your accounts by protecting the confidentiality of your keypairs.
Your public key is uploaded to your server to use SSH key authentication for access control. 

The <a href="https://linuxhint.com/use-ssh-copy-id-command/">ssh-copy-id command</a>, which is part of the OpenSSH package, can be used to automate the transfer process in the syntax of:
<code>ssh-copy-id username@host</code>
You may also add the key to your account using<a href="https://support.jumpcloud.com/support/s/article/how-do-i-add-an-ssh-key-to-my-jumpcloud-account"> JumpCloud</a>, or by manually placing the public SSH key on the remote server (<a href="https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#basic-connection-instructions">DigitalOcean</a>).
<a href="https://jumpcloud-1.wistia.com/medias/5usy6ga9lo?wvideo=5usy6ga9lo"><img src="https://embedwistia-a.akamaihd.net/deliveries/c8719e08ca0f214b1cab32d7d9f7cf71.jpg?image_play_button_size=2x&amp;image_crop_resized=960x540&amp;image_play_button=1&amp;image_play_button_color=41c8c6e0"></a>

<a href="https://jumpcloud-1.wistia.com/medias/5usy6ga9lo?wvideo=5usy6ga9lo">Mac and Linux with CLI – jumpcloud-1</a>
<h3 id="SSHKeystopic-6">Windows Instructions:</h3>
<img src="https://lh4.googleusercontent.com/Xxs3ElpyXtbw_A92tJBEaHIr0rfnQ0klXz5DV5HRYCPQpDgYQYY-ulqCj7kfNek5m5B2fVBv3jNsUahOQhWZoIV3nS1YFYvVuzlHqnrWvMwb_eBa_PsV3XDweV1BPE3TBYSXyR4z">

Download and install the PuTTY SSH keygen program.

Load the PuTTYgen program
Click the <strong>Generate</strong> button and select RSA (SSH-2)
You may opt for a 4096 bit key, but some applications may not accept it and it may result in increased CPU usage during the ‘handshake’ process.
Key in a passphrase for additional security
You must select <strong>Save private key</strong> and specify a location
<strong>Do not share this file with unauthorized individuals</strong>
You can copy and paste your public key from the field above with <strong>Select All </strong>or hit the <strong>Save public key</strong> button.
You may add the key to your account using<a href="https://support.jumpcloud.com/support/s/article/how-do-i-add-an-ssh-key-to-my-jumpcloud-account"> JumpCloud</a>
<a href="https://jumpcloud-1.wistia.com/medias/gi8wc7hlbe?wvideo=gi8wc7hlbe"><img src="https://embed-fastly.wistia.com/deliveries/af124ab6985c9e4c76abe3183720f6cb.jpg?image_play_button_size=2x&amp;image_crop_resized=960x540&amp;image_play_button=1&amp;image_play_button_color=41c8c6e0"></a>
<a href="https://jumpcloud-1.wistia.com/medias/gi8wc7hlbe?wvideo=gi8wc7hlbe">Windows SSH Pair Keygen using PuTTY – jumpcloud-1</a>

<h3 id="SSHKeystopic-7">How SSH Key Authentication Works</h3>
After completing the steps mentioned above, use your terminal to enter in your ssh username and the IP address of the remote system in this format: <code>ssh username@my_ip_address</code>. 
This will initiate a connection to the remote system using the SSH protocol. 
The protocol and specified username will then tell the remote server which public key to use to authenticate you. 
Then the remote server will use that public key to encrypt a random challenge message that is sent back to the client. 

This challenge message is decrypted using the private key on your system.
Once the message is decrypted, it is combined with a previously arranged session ID and then sent back to the server. 
If the message matches with what the server sent out, the client is authenticated, and you will gain access to the remote server. 

This process proves to the server that you have the corresponding private key to the public key it has on file.
However, the security that this authentication process provides can be undermined when SSH keys are not properly managed. 

<h3 id="SSHKeystopic-8">Managing SSH Keys</h3>
It is imperative that proper SSH key management is in place because they often grant access to mission-critical digital assets. 
Also, companies tend to have a lot of SSH keys. 
In fact, Fortune 500 companies will often have <em>several millions</em> of these.

Despite the difficulty in trying to manually manage millions of SSH keys, having an SSH key management system in place is continuously overlooked. 
SSH.com did some digging and discovered a company that had 3 million SSH keys “that granted access to live production servers.
Of those, 90% were no longer used. 

Root access was granted by 10% of the keys ”. 
An effective SSH key management system in place would have gone a long way in reducing this concerning security risk.
IT has a couple options to<a href="https://jumpcloud.com/blog/identity-service-function-ssh-key-management/"> gain control over SSH keys</a> in their environment. 

One of these includes using an SSH key management tool. 
However this means having to manage one more platforms in addition to managing an SSO provider, a directory service, and maybe a system management solution. 
A new solution has emerged that is providing IT with a second option:<a href="https://jumpcloud.com/platform"> JumpCloud Directory Platform</a>.

<h3 id="SSHKeystopic-9">Cloud IAM offers SSH Key Management</h3>
This <a href="https://jumpcloud.com/blog/cloud-identity-and-access-management/">cloud-based identity and access management solution</a> provides IT with one central place to manage SSH keys. 
Furthermore, IT can also centralize user authentication to Mac, Linux, and Windows <a href="https://jumpcloud.com/blog/centralized-system-and-user-management/">devices</a>, cloud <a href="https://jumpcloud.com/blog/idaas-and-aws-cloud-servers/">servers</a>, wired and WiFi <a href="https://jumpcloud.com/blog/secure-wifi-networks-cloud-radius/">networks</a>, web-based and on-prem <a href="https://jumpcloud.com/blog/true-single-sign-on-systems-apps-network/">applications</a>, and virtual and on-prem storage. 
With one central place to manage a user’s authentication to all of their resources, it becomes a si
mple matter of a few clicks to deprovision users from all of their resources, including SSH key access to remote systems.


<h2>ModemPOOL</h2>
猫池
就是将相当数量的Modem使用特殊的拨号请求接入设备连接在一起，可以同时接受多个用户拨号连接的设备。

<a href="https://www.aliexpress.com/w/wholesale-16-port-gsm-modem-pool.html" class="whitebut ">16-port-gsm-modem-pool</a>
<a href="https://ozeki.hu/p_7672-how-to-send-sms-with-a-gsm-modem-pool.html" class="whitebut ">send-sms-with-a-gsm-modem-pool</a>

<h2>network address translation or port forwarding</h2>
Enabling outside access to an internal computer

Please note: this tutorial is for advanced users. 
Your router's firewall is there to protect you from evildoers who try to control your computer over the Internet. 
Make sure that any service you expose to the Internet is secured with a strong password.

Enabling outside access to an internal computer on a home network requires that you set up NAT - "network address translation," or port forwarding. 

Forwarding sends requests for ports on the outside of your firewall to the right computer on the inside.

For instance, someone on the outside requests a page from a web server at your router's IP address. 
With port forwarding set up, your router knows to forward requests for port 80 (a web server's default port) to the computer with the web server running only - and none of the others on your network.

Port forwarding is only necessary when you want to expose a service to computers on the Internet outside your firewall. 

set up port forwarding:

Step 1. 
Determine your server's internal IP address.

All the computers on your internal network have an IP address which looks something like 192.168.0.XXX. 
Get on the computer with the server running and open a command window. 

Then type ipconfig to determine the machine's internal address, like so:


C:\\Gina&gt;ipconfig

Windows IP Configuration

Ethernet adapter Local Area Connection:

        Connection-specific DNS Suffix  . 
:
        IP Address. 
. 

. 
. 
. 

. 
. 
. 

. 
. 
. 

. 
: 192.168.0.11
        Subnet Mask . 
. 

. 
. 
. 

. 
. 
. 

. 
. 
. 

: 255.255.255.0
        Default Gateway . 
. 
. 

. 
. 
. 

. 
. 
. 

: 192.168.0.1


In this case, as you can see, the server's internal IP address is 192.168.0.11.

Step 2. 
Configure your router.

Most routers have an web-based administrative interface that's located at http://192.168.0.1. 
(This address does depend on your model. 

Consult your router user guide for more info.)

Once you've gone to the router administration, entered the password (if one is set up), there should be an area called "Port forwarding." There, you'll set the port number that requests from the Internet will come in, and the internal computer that should fulfill those requests. 
Here's a screenshot of my Netgear router set up to port forward 5900 to my VNC server, which is at 192.168.0.11 (see above). 
Click on the image to see a larger version.

Here's a table of common services and their default port numbers.

Any other services you port forward for that I missed? Add it in the comments to this article or drop me a note at tips at lifehacker.com.

<h2>How exactly do TCP connections work?</h2>
https://www.ionos.com/digitalguide/server/know-how/introduction-to-tcp/
Transmission Control Protocol
TCP allows for transmission of information in both directions. 
This means that computer systems that communicate over TCP can send and receive data at the same time, similar to a telephone conversation. 

The protocol uses segments (packets) as the basic units of data transmission. 
In addition to the payload, segments can also contain control information and are limited to 1,500 bytes. 
The TCP software in the network protocol stack of the operating system is responsible for establishing and terminating the end-to-end connections as well as transferring data.

The TCP software is controlled by the various network applications, such as web browsers or servers, via specific interfaces. 
Each connection must always be identified by two clearly defined endpoints (client and server). 
It doesn’t matter which side assumes the client role and which assumes the server role. 

All that matters is that the TCP software is provided with a unique, ordered pair consisting of IP address and port (also referred to as "2-tuple" or "socket") for each endpoint.

<h3>The three-way handshake: How a TCP connection is established in detail</h3>
Prerequisites for establishing a valid TCP connection: Both endpoints must already have a unique IP address (IPv4 or IPv6) and have assigned and enabled the desired port for data transfer. 

The IP address serves as an identifier, whereas the port allows the operating system to assign connections to the specific client and server applications.
The actual process for establishing a connection with the TCP protocol is as follows:
First, the requesting client sends the server a SYN packet or segment (SYN stands for synchronize) with a unique, random number. 

This number ensures full transmission in the correct order (without duplicates).
If the server has received the segment, it agrees to the connection by returning a SYN-ACK packet (ACK stands for acknowledgment) including the client's sequence number plus 1. 
It also transmits its own sequence number to the client.

Finally, the client acknowledges the receipt of the SYN-ACK segment by sending its own ACK packet, which in this case contains the server's sequence number plus 1. 
At the same time, the client can already begin transferring data to the server.

<img class="lazy" data-src="https://www.ionos.com/digitalguide/fileadmin/_processed_/d/e/csm_EN-tcp_1f6b3edf44.png">
Process of establishing a TCP connection (three-way handshake)

Since the TCP connection is established in three steps, the connection process is called a three-way handshake.

Note
If the server port is closed or access is blocked, the client receives a TCP RST packet (reset) instead of an acknowledgment packet.

<h2>netstat</h2>
<a href="https://v.douyin.com/hrbyK4e/" class="whitebut ">自查电脑被监控</a>

https://www.linuxprobe.com/netstat-common-method.html

netstat is a command-line network utility that displays network connections for Transmission Control Protocol (TCP), routing tables, and a number of network interface and network protocol statistics.
The following cheatsheet goes over a few common netstat commands. For more advanced commands you need to consult the official man pages. 

https://man.cx/netstat(1)
https://linux.die.net/man/8/netstat

# To view which users/processes are listening to which ports:
sudo netstat -lnptu

# To view routing table (use -n flag to disable DNS lookups):
netstat -r

# Which process is listening to port <port>
netstat -pln | grep <port> | awk '{print $NF}'

# Example output: 1507/python

# Fast display of ipv4 tcp listening programs
sudo netstat -vtlnp --listening -4

# Displays network-related information such as open connections, open socket ports, etc.

# List all ports:
netstat -a

# List all listening ports:
netstat -l

# List listening TCP ports:
netstat -t

# Display PID and program names:
netstat -p

# List information continuously:
netstat -c

# List routes and do not resolve IP to hostname:
netstat -rn

# List listening TCP and UDP ports (+ user and process if you're root):
netstat -lepunt

# Print the routing table:
netstat -nr

<h2>Netstat Command for DOS and Windows</h2>
<table>
<tr><th>Displays protocol statistics and current TCP/IP network connections. </th></tr>
<tr><th>NETSTAT [-a] [-e] [-n] [-s] [-p proto] [-r] [interval] </th></tr>
<tr><th>-a  </th><td>Displays all connections and listening ports. (Server-side connections are normally not shown). </td></tr>
<tr><th>-e  </th><td>Displays Ethernet statistics. This may be combined with the -s option. </td></tr>
<tr><th>-n </th><td>Displays addresses and port numbers in numerical form.  </td></tr>
<tr><th>-p proto </th><td>Shows connections for the protocol specified by proto; proto may be tcp or udp. If used with the -s option to display per-protocol statistics, proto may be tcp, udp, or ip. </td></tr>
<tr><th>-r </th><td>Displays the contents of the routing table. </td></tr>
<tr><th>-s </th><td>Displays per-protocol statistics. By default, statistics are shown for TCP, UDP and IP; the -p option may be used to specify a subset of the default. </td></tr>
<tr><th>interval </th><td>Redisplays selected statistics, pausing interval seconds between each display. Press CTRL+C to stop redisplaying statistics. If omitted, netstat will print the current configuration information once</td></tr>
</table>

<h2>Using A Laptop as a Wireless Router in Windows 10</h2>
https://www.alphr.com/laptop-pc-wireless-router/
Open the “Settings” menu in Windows 10 or 11.
Select “Network & Internet”,
then click on “Mobile hotspot” from the left menu.
Toggle “Share my Internet connection with other devices” to on.

Turn on the Wi-Fi on the other device (if not already active) and search for network.
<img class="lazy" data-src="https://youwuqiong.top/wp-admin/img.php?imgUrl=https://i0.wp.com/www.alphr.com/wp-content/uploads/2020/05/2-1.png">

Using A Laptop as a Wireless Router in Windows 8
Navigate to “Control Panel > Network Connections.”
<img class="lazy" data-src="https://youwuqiong.top/wp-admin/img.php?imgUrl=https://i0.wp.com/www.alphr.com/wp-content/uploads/2020/05/4.png">

Right-click your Wi-Fi adapter and select “Properties.”
<img class="lazy" data-src="https://youwuqiong.top/wp-admin/img.php?imgUrl=https://i0.wp.com/www.alphr.com/wp-content/uploads/2020/05/5.png">

Select the “Sharing” tab, check the box next to “Allow other network users to connect through this computer’s Internet connection,” then click on “OK.”

<img class="lazy" data-src="https://youwuqiong.top/wp-admin/img.php?imgUrl=https://i0.wp.com/www.alphr.com/wp-content/uploads/2020/05/6.png">

Open the Command Prompt as administrator.
Type the following:
netsh wlan set hostednetwork mode=allow ssid=”<YOURSSID>” key=”<PASSWORD>” and press “Enter.”
<YOURSSID> is the network name and <PASSWORD> is the network password.

Now, type: netsh wlan start hostednetwork and press “Enter.”

Then, type: netsh wlan show hostednetwork to check that everything is functioning correctly.

<h2>DHCP on Home Networks</h2>
<div id="DHCPtoc" class="toc"><a href="#DHCPtopic-0" target="_self">DHCP Client</a><br><a href="#DHCPtopic-1" target="_self"> Client Configuration</a><br><a href="#DHCPtopic-2" target="_self"> DHCP Server</a><br><a href="#DHCPtopic-3" target="_self">DHCP Server Location</a><br><a href="#DHCPtopic-4" target="_self"> DHCP Server  Settings and Configuration</a><br><a href="#DHCPtopic-5" target="_self"> Enabled</a><br><a href="#DHCPtopic-6" target="_self">Assigning Static Addresses Using DHCP</a><br><a href="#DHCPtopic-7" target="_self">Troubleshooting DHCP</a><br><a href="#DHCPtopic-8" target="_self">Common Questions and Answers</a><br><a href="#DHCPtopic-9" target="_self"> <b>Q-</b> Can I assign static IP addresses on the client  and still use DHCP?</a><br><a href="#DHCPtopic-10" target="_self"> <b>Q-</b> Can I assign DNS servers manually even though I'm using DHCP?</a><br><a href="#DHCPtopic-11" target="_self"> Q<b>-</b> My IP address doesn't appear to change does this mean that I have a static IP address?</a><br><a href="#DHCPtopic-12" target="_self"> <b>Q-</b> Can I have more than one DHCP server on a network?</a><br><a href="#DHCPtopic-13" target="_self"> <b>Q-</b> Does a DHCP server provide IPv6 addresses?</a><br><a href="#DHCPtopic-14" target="_self"> Q- Do Wi-Fi Clients use DHCP</a><br><a href="#DHCPtopic-15" target="_self"> Q- How does a DHCP client locate a DHCP server?</a><br><a href="#DHCPtopic-16" target="_self"> Q-What is the IP address of the DHCP server?</a><br><a href="#DHCPtopic-17" target="_self"> Q- How do you find the address of a DHCP Server?</a><br><a href="#DHCPtopic-18" target="_self"> Q- Does DHCP provide the address of the default gateway?</a><br><a href="#DHCPtopic-19" target="_self"> Q- Should I assign static IP addresses to all network devices?</a><br><a href="#DHCPtopic-20" target="_self"> Q- Why should I assign a static IP address to network printers?</a><br><a href="#DHCPtopic-21" target="_self"> Q- Should DHCP be on or OFF?</a><br><a href="#DHCPtopic-22" target="_self">Video -Static vs Dynamic IP Addresses</a><br><a href="#DHCPtopic-23" target="_self">Terms and Acronyms</a><br><a href="#DHCPtopic-24" target="_self">Quick Quiz</a><br></div></center><br><br>

<b>What is DHCP?
DHCP</b> stands for <b>Dynamic Host configuration protocol</b>  and provides a mechanism for automatically allocating IP (IPv4) addresses to network devices e.g. computers.
DHCP allows devices to join a home network without the need for any device setup.
The DHCP protocol consists of two components.

A DHCP client
A DHCP server
<h3 id="DHCPtopic-0">DHCP Client</h3>
All modern operating systems come equipped with a <b>DHCP client,</b> and by default, they are all configured to use DHCP.
A <b>DHCP client</b> is responsible for requesting an IP address and assigning it to the computer etc.
<h4 id="DHCPtopic-1"> Client Configuration</h4>
If you go to you adaptor settings page (see<a href="/setting-up-static-ip-address-windows-10/" target="_blank"> this tutorial</a> for windows 10) or Wi-Fi settings page you will see a page similar to the one below:
<img class="lazy loaded" data-src="https://stevessmarthomeguide.com/wp-content/uploads/standard-ip-address-settings.jpg" src="https://stevessmarthomeguide.com/wp-content/uploads/standard-ip-address-settings.jpg" data-was-processed="true">
When you enable the setting to <b>obtain IP address automatically</b> you are enabling  the <b>DHCP client.</b>
The client can obtain an IP address from the DHCP server and also the DNS server addresses.
However they are both configurable as seen in the screen shot above.
<h4 id="DHCPtopic-2"> DHCP Server</h4>
A <b>DHCP server</b> is responsible for allocating IP address and other information to requesting clients.
The <b>DHCP server</b> is configured with a <b>range of IP addresses</b> that it can assign, and also with other settings like DNS servers, default gateway addresses etc.
IP addresses from a<b> DHCP server</b> are normally <b>leased</b>, and must be<b> renewed</b> periodically.
This renewal process happens in the background, and doesn’t require any user intervention.
A DHCP client will request to keep it's IP address when it renews which is why device IP addresses don't normally change on home networks.
<h3 id="DHCPtopic-3">DHCP Server Location</h3>
On home networks the DHCP server is on  the<b> home router</b> or<b> home hub</b>.
Most home routers will have the DHCP server <b>enabled by default</b> (turned on).
However you can use another computer e.g raspberry pi  as a DHCP server, but it is generally not done.
<div class="lazy">data-If you are thinking of using another device to be a DHCP server it is important to understand that you can only have one DHCP server on a network.</div>.
<h3 id="DHCPtopic-4"> DHCP Server  Settings and Configuration</h3>
On home networks there is generally nothing to be configured.
If you go the admin page on your <b>home router</b> you will see DHCP configuration options similar to the screen shot below.
<img class="lazy" data-src="https://stevessmarthomeguide.com/wp-content/uploads/dhcp-server-settings.jpg">
The common settings are:

Enabled
Authoritative DHCP
Server Address Range
Lease Time

<h4 id="DHCPtopic-5"> Enabled</h4>
This is normally selected to make the DHCP server active (on).
<b>Authoritative DHCP</b>
This is normally selected to make the DHCP server authoritative for this address pool as it is usually the only server on the network.
<b>DHCP Address Range</b>
You usually leave these as the default settings are usually adequate.
You should note that the <b>allocation range</b> on my home router is 192.168.1.64-192.168.1.253.
The home router itself uses address 192.168.1.254 and so it leaves me 192.168.1.1-.192.168.1.63 for allocating to <b>static clients</b> if needed.
Only assigning <b>static addresses</b> in this range will help avoid <b>IP address conflicts</b>.
You should also start at address 192..168.1.1 or 192..168.1.2 and work up in case you need to increase the address range at a later date.
<b>Note:</b> Some networks use <b>192..168.1.1</b> for the default gateway address.
<b>Subnet Mask</b> - Normally 255.255.255.0 on home networks see <a title="Home Network Subnet Mask Explained" href="https://stevessmarthomeguide.com/home-network-subnet-mask-explained/" target="_blank" rel="noopener">subnet masks explained.</a>
<b>Default Gateway</b> - The IP address of your home router
<b>Lease Time</b>
IP addresses are leased to the client a must be renewed before the lease expires. You can see from my settings that the lease period is 1 day.
The default setting is generally used.
<h3 id="DHCPtopic-6">Assigning Static Addresses Using DHCP</h3>
Most devices on a network will be automatic IP addresses assigned using a DHCP server.
However devices like:

Network printers
Smart Hubs
Network Printers

Although you can manually assign a static address to a client it is not really the best way as it is very inflexible.
A better way is to use the DHCP server to assign the address on a <b>permanent basis</b> and almost all home routers have this ability.
This is usually known as <b>address reservation</b> and the screen shot below shows my Tplink router settings.
<img class="lazy" data-src="https://stevessmarthomeguide.com/wp-content/uploads/tp-link-address-reservation.jpg">
It works by using the <b>MAC address</b> of the client(which is fixed), to fix the IP address to that client.
Using DHCP to assign <b>static IP addresses</b> greatly reduces the possibility of duplicate IP addresses.
<h3 id="DHCPtopic-7">Troubleshooting DHCP</h3>
You will need to look at the clients and the home router.
The main client trouble shooting tool is the command line tool  <b>ipconfig</b> (windows) and<b> ifconfig</b> (Linux).
This tool will show you the<b> IP addresses</b> assigned to your device.
What you are looking for when using this tool is that your computer has a valid IP address,Gateway address, and DNS server address.
<img class="lazy" data-src="https://stevessmarthomeguide.com/wp-content/uploads/ipconfig-dhcp.jpg">
If your client has an IP address beginning with <b>169</b> or an address of <b>0.0.0.0</b> then something is wrong, and it can't locate a DHCP server.
In the screen shot above you can see that the client is configured for DHCP and that the IP address has been leased.
<b>Router Checks - </b>You will also need to logon to your home router and check that<b> DHCP has been enabled.</b>
If you have many clients on the network then you may also need to <b>adjust the address range.</b>
If you do adjust the address range then make sure that you haven't already assigned static addresses in this range.
<h3 id="DHCPtopic-8">Common Questions and Answers</h3>
<h4 id="DHCPtopic-9"> <b>Q-</b> Can I assign static IP addresses on the client  and still use DHCP?</h4>
<b>A-</b> Yes most DHCP servers (even on home networks) allow you to <b>exclude IP addresses</b> and address ranges.
<h4 id="DHCPtopic-10"> <b>Q-</b> Can I assign DNS servers manually even though I'm using DHCP?</h4>
<b>A-</b> Yes there is a separate setting for that on the client configuration.
<h4 id="DHCPtopic-11"> Q<b>-</b> My IP address doesn't appear to change does this mean that I have a static IP address?</h4>
<b>A-</b> No not necessarily as when a DHCP client renews its IP address it asks for the same address and will normally be allowed to keep it.
<h4 id="DHCPtopic-12"> <b>Q-</b> Can I have more than one DHCP server on a network?</h4>
<b>A-</b> Yes and No.  You might find multiple DHCP servers on large corporate networks. However the set up is tricky and they must be configured so as not to assign the same IP addresses from the same address range. <b>On Home networks you should only have one.</b>
<h4 id="DHCPtopic-13"> <b>Q-</b> Does a DHCP server provide IPv6 addresses?</h4>
<b>A-</b> Currently No as IPv6 addresses on home networks are auto assigned by the client and don't need DHCP.
<h4 id="DHCPtopic-14"> Q- Do Wi-Fi Clients use DHCP</h4>
A- Yes-This is usually the default setting.
<h4 id="DHCPtopic-15"> Q- How does a DHCP client locate a DHCP server?</h4>
A- It uses broadcasts.
<h4 id="DHCPtopic-16"> Q-What is the IP address of the DHCP server?</h4>
A- This isn't really relevant as the client will locate it using <b>broadcasts</b>.
<h4 id="DHCPtopic-17"> Q- How do you find the address of a DHCP Server?</h4>
A- On windows the ipconfig /all command will show you the DHCP IP address of the DHCP server if the client is configured to use it.
<img class="lazy" data-src="https://stevessmarthomeguide.com/wp-content/uploads/dhcp-server-address.jpg">
<h4 id="DHCPtopic-18"> Q- Does DHCP provide the address of the default gateway?</h4>
A- Yes
<h4 id="DHCPtopic-19"> Q- Should I assign static IP addresses to all network devices?</h4>
A- No only to devices you need to manage
<h4 id="DHCPtopic-20"> Q- Why should I assign a static IP address to network printers?</h4>
A- Because you will need to know the IP address in order to manage it.
<h4 id="DHCPtopic-21"> Q- Should DHCP be on or OFF?</h4>
A- On almost all home networks it should be on I can't think of a reason to turn it off.
<h3 id="DHCPtopic-22">Video -Static vs Dynamic IP Addresses</h3>
<iframe src="https://www.youtube.com/embed/2yOMNugsdE0?feature=oembed" frameborder="0" allow="accelerometer;" allowfullscreen=""></iframe>
<h3 id="DHCPtopic-23">Terms and Acronyms</h3>
<b>MAC address</b>- Also known as the Ethernet or physical address is fixed and part of the hardware.
<b>Static Address</b> - An IP address that is assigned manually.
<b>Dynamic Address</b> - An IP address assigned automatically and can change from time to time.
<b>IP Address Conflict</b> - When Two computers(devices) are configured to use the same IP address.
<b>Default Gateway</b> — The IP address of the device that provides access to the Internet i.e. your home router.
<b>Broadcast</b> -A message that is sent to all clients on a network.
<b>Resources and Related tutorials</b>
<b>Useful Ipconfig commands</b>
<b>ipconfig /all </b>  -This command will show IP and DNS settings
<b>ipconfig /release</b>  -This command will release the IP address from DHCP
<b>ipconfig /renew</b> -This command will renew the IP address using DHCP
<b>Useful Rapberry Pi /Linux commands</b>
<b>ifconfig</b> - Shows basic address details for all Interfaces.
<b>dhclient</b> lets you renew and release IP addresses:
to release use:
<b>dhclient -r</b>
to renew use:
<b>dhclient</b>
to target a particular interface (e.g eth0) use
<b>dhclient -r eth0</b>
to enable more details use the -v (verbose) switch
<b>dhclient -r -v eth0</b>

<h3 id="DHCPtopic-24">Quick Quiz</h3>
<b>Q-1</b> Which devices do you think would require a static IP address?
A- Your mobile Phone
B -Your Tablet
C -Your network router
D- Smart switches on the network
<b>Q 2</b>-You Haven't documented your network and need to manage a smart switch on the network how do you find it's IP address?
A -Use the Ping command
B -Look at address reservations on the DHCP server
C- Look for address assignments on the DHCP server.
<b>Q 3</b>- Using DHCP to assign <b>static IP addresses</b> greatly reduces the possibility of duplicate IP addresses?True or False?
Q 4 Yo need to tell all clients the IP address of the DHCO server? True or False?
Q5- On Which device do you normally find the DHCP server?

<h2>Port forwarding</h2>
how to set up virtual server on TP-Link wireless router?
What is Port Forwarding?

Port forwarding is a way of making your router use a specific port to communicate with certain devices. 

By setting a specific port for your devices, you are telling your router to always accept requests for those ports and forward data to a device’s private IP address.

In order to understand port forwarding, it helps to understand a little about how routers work first. 

Your router’s job is to transmit an internet signal to all your devices over a local area network (LAN). 

To do this, your router assigns each device in your LAN its own local IP address. 

For example, your computer will have a private IP address like 192.168.0.2 or 10.0.0.2

Then, on top of that, the applications and services on each device are also assigned a port number. 

For example, an application on your computer will have an IP address with a port number attached like 192.168.0.2:80 or 10.0.0.2:80.

With this unique IP address and port number, your router knows which program or service to send information to. 

This lets you and others access devices and programs on your LAN over a wide area network (WAN).

Example
Share my personal website I’ve built in a local network with my friends through the internet.
<b>For example</b>, the personal website has been built on my home PC (192.168.0.106). 

I hope that my friends on the internet can visit my website in some way and the port number is 90. 
The PC is connected to the router with the WAN IP address 218.18.232.154.
<img src="https://static.tp-link.com/image001_1490601216454f.jpg">

<strong>Step 1</strong> Log into the router’s web management page:
<a href="https://www.tp-link.com/support/faq/87/">How do I log into the web-based Utility (Management Page) of TP-Link wireless router?</a>

<strong>Step 2</strong> 
Click on <b>Advanced-&gt;NAT Forwarding<strong>-&gt;Virtual Server</strong></b>, then click <strong>Add </strong>button.
<img src="https://static.tp-link.com/upload/faq/image-20211025190704-8_20211025111129c.png">

<strong>Step 3</strong> In the Service section of this screen, type in the detailed information you confirmed with the service’s provider. 
For this example, if you want to open port 90 for only one of your devices 192.168.0.106, you can configure it like below:
<img src="https://static.tp-link.com/upload/faq/image-20211025190704-9_20211025111131e.png">

<b>Service Type: </b>Select the service you want to use from the <b>View Existing Services</b> list. 
If the<b> View Existing Services</b> menu does not list the service that you want to use, you can enter the <b>Service Type</b> manually.

<b>External Port and Internal Port:</b> Select the service you want to use from the <b>View Existing Services </b>list, then the<b> </b><b>External Port</b> and <b>Internal Port</b> will be automatically filled in.

If the <b>View Existing Services</b> menu does not list the service that you want to use, you can enter the <b>External Port and Internal Port</b> manually. 

You should verify the port number that the service needs.
**Note: 
1. If you need to input a port range xx-xx when configuring the port forwarding, please leave the internal port empty.
2. The External Port and Internal Port usually can be the same.

<b>Internal IP: </b>Specify the IP address of the device you are opening the port for.<b> </b>
<b>Protocol: </b>Specify the protocol used for this application from the pull-down list, if you are not sure, choose <b>ALL</b>.
<strong>Step 4</strong> Click the <strong>Save</strong> button to save the settings. 

<strong>Note:</strong> To ensure the Virtual Server entry will take effect all the time. 
You´d better assign a static IP address for your server, because its IP address may change when using the DHCP function. 

Or you can just do an IP address reservation for the server. 
Please refer to the following link to do that:
<a href="https://www.tp-link.com/support/faq/1381/">How to configure Address Reservation on TP-Link wireless router(new logo)?</a>

<strong>Step 5</strong> Go to<b> Advanced-&gt;Status </b>page and check the <strong>WAN IP Address</strong> of the router. 
Now you can try to use the <b>http:// WAN IP: port number</b> (in this example: http:// 218.18.232.154:90) to visit your personal website.
<img src="https://static.tp-link.com/upload/faq/image-20211025190704-10_20211025111130b.png">

If the WAN IP Address of the router is not a public IP Address, but a Private IP Address, that means there is another NAT device connected to the WAN port of the TP-Link router, you need to open the service ports on that device as well.
Note： For the CG-NAT ISP: <strong>Comporium</strong> and <strong>Direct link - radio service</strong>, provide the customer a private IP, that will cause you can’t use the OpenVPN or port forwarding and affect the NAT Type. 
You can contact the ISP and ask them to offer a Static IP address.

For how to find out the IP Address is a public one or a private one, please refer to this link:
<a href="http://en.wikipedia.org/wiki/Private_network">http://en.wikipedia.org/wiki/Private_network</a>

<strong>Note:</strong>
A) If you want to open port 80 for a local device, please change the router’s remote management port number first since its default number is 80. 
As for the internal port, 80 is reserved for the local management and cannot be modified although the remote management port has changed.

<img  src="https://static.tp-link.com/upload/faq/image-20211025190704-11_20211025111129f.png" >
Go to <b>Advanced-&gt;System Tools-&gt;Administration</b>, and then change the <strong>HTTP Port</strong> to other ports such as 8080 and <strong>Save</strong>.
<img src="https://static.tp-link.com/upload/faq/image-20211025190704-12_20211025111131p.png">

B) Some models support different External Ports and Internal ports. 
Here we will explain this configuration under different situations.
For example, if you want to open port 90 for only one of your devices 192.168.0.106, you can configure it like the instruction above.

If you have two or more devices (192.168.0.106 &amp;192.168.0.103 in this example) want the same port to be opened for a certain service, then you will have to use different External Ports
For the Internal Port, please put in the actual port number (90 in this example), then create different Service port numbers for the two devices (like 9000 and 9001 in this example).
<img src="https://static.tp-link.com/upload/faq/image-20211025190704-13_20211025111130t.png">

<img src="https://static.tp-link.com/upload/faq/image-20211025190704-14_20211025111131v.png">
After this configuration, you can access the two devices using different External ports. 
In this case, you can use 218.18.232.154:9000 to access 192.168.0.106 and 218.18.232.154:9001 to access 192.168.0.103.

<h1>Port Forwarding feature on TP-Link</h1>

Virtual servers can be used for setting up public services on your LAN. 
A virtual server is defined as a service port, and all requests from internet to this service port will be redirected to the computer specified by the server IP.

Here takes TL-MR6400 as demonstration.

1. Log into the router's web management page:

2. Go to <b>Forwarding</b> &rarr; <b>Virtual Servers</b>, you can view and add virtual servers.

<img src="https://static.tp-link.com/image001_1495592442505f.jpg">

<b>Service Port</b> - The numbers of External Service Ports. 
You can enter a service port or a range of service ports (the format is XXX - YYY, XXX is Start port, YYY is End port).

<b>Internal Port</b> - The Internal Service Port number of the PC running the service application. 
You can enter a specific port number, or leave it blank if the <b>Internal Port</b> is the same as the <b>Service Port</b>.

<b>IP Address</b> - The IP Address of the PC providing the service application.

<b>Protocol</b> - The protocol used for this application, either <b>TCP</b>, <b>UDP</b>, or <b>All</b> (all protocols supported by the router).

<b>Status</b> - The status of this entry, &quot;Enabled&quot; means the virtual server entry is enabled. 
The status of this entry is either <b>Enabled</b> or <b>Disabled</b>.

<b>To setup a virtual server entry:</b>

1. Click <b>Add New&hellip;.</b>

<img src="https://static.tp-link.com/image002_1495592451169e.jpg">

2. Select the service you want to use from the <b>Common Service Port</b> list. 
If the Common Service Port list does not have the service that you want to use, type the number of the service port or service port range in the <b>Service Port</b> box.

3. Type the IP Address of the computer in the <b>IP Address</b> box.

4. Select the protocol used for this application, either <b>TCP</b> or <b>UDP</b>, or <b>All</b>.

5. Select <b>Enabled</b> to enable the virtual server.
6. Click <b>Save</b>.

<b>Note:</b>

1. You&acute;d better assign a static IP address for your server, so the Virtual Server entry will take effect all the time. 
Or you can just do an IP address reservation for the server. 

2. If you set the service port of the virtual server as 80, you must set the web management port on <b>Security</b> &rarr; <b>Remote Management</b> page to be any other value except 80 such as 8080. Otherwise there will be a conflict to disable the virtual server.

<h2>To open a port in the Windows firewall for TCP access</h2>
On the <b>Start</b> menu, select <b>Run</b>, type <b>WF.msc</b>, and then select <b>OK</b>.

In the <b>Windows Firewall with Advanced Security</b>, in the left pane, right-click <b>Inbound Rules</b>, and then select <b>New Rule</b> in the action pane.

In the <b>Rule Type</b> dialog box, select <b>Port</b>, and then select <b>Next</b>.

In the <b>Protocol and Ports</b> dialog box, select <b>TCP</b>. 
Select <b>Specific local ports</b>, and then type the port number of the instance of the Database Engine, such as <b>1433</b> for the default instance. 
Select <b>Next</b>.

In the <b>Action</b> dialog box, select <b>Allow the connection</b>, and then select <b>Next</b>.

In the <b>Profile</b> dialog box, select any profiles that describe the computer connection environment when you want to connect to the Database Engine, and then select <b>Next</b>.

In the <b>Name</b> dialog box, type a name and description for this rule, and then select <b>Finish</b>.

<h2>To open access to SQL Server when using dynamic ports</h2>
On the <b>Start</b> menu, select <b>Run</b>, type <b>WF.msc</b>, and then select <b>OK</b>.

In the <b>Windows Firewall with Advanced Security</b>, in the left pane, right-click <b>Inbound Rules</b>, and then select <b>New Rule</b> in the action pane.

In the <b>Rule Type</b> dialog box, select <b>Program</b>, and then select <b>Next</b>.

In the <b>Program</b> dialog box, select <b>This program path</b>. 
Select <b>Browse</b>, and navigate to the instance of SQL Server that you want to access through the firewall, and then select <b>Open</b>. 
By default, SQL Server is at <b>C:\Program Files\Microsoft SQL Server\MSSQLXX.MSSQLSERVER\MSSQL\Binn\Sqlservr.exe</b>. 
Select <b>Next</b>. 
The <code>MSSQLXX</code> version will be specific to your version of SQL Server.

In the <b>Action</b> dialog box, select <b>Allow the connection</b>, and then select <b>Next</b>.

In the <b>Profile</b> dialog box, select any profiles that describe the computer connection environment when you want to connect to the Database Engine, and then select <b>Next</b>.

In the <b>Name</b> dialog box, type a name and description for this rule, and then select <b>Finish</b>.


<h2>host your own website using WAMP Server</h2>
<h3>Configure Windows Firewall to allow wampmanager, port 80 and 443</h3>
Port 80 and 443 must be allow for both TCP and UDP packets. 
To do this, create 2 <b>inbound rules</b> for TPC and UDP on Windows Firewall for port 80 and 443.
<img src="https://i0.wp.com/blog.hsnyc.co/wp-content/uploads/2015/04/windows-firewall-inbound-rule-port-80.png">
Also, allow <b>wampmanager.exe</b> found in the wamp installation folder, in my case that is C:\wamp.
<img src="https://i0.wp.com/blog.hsnyc.co/wp-content/uploads/2015/03/windows-firewall-inbound-rules.png">

<h3>Configure Apache</h3>
Now we need to make Apache listen to port 80 on our host machine. 
For this, open your <b>httpd.conf</b> file found under C:\wamp\bin\apache\apache[version#]\conf and edit the following lines:
Listen 0.0.0.0:80
ServerName localhost:80

Change it to..
Listen <b>youripaddress</b>:80
ServerName <b>youripaddress</b>

where <b>youripaddress</b> is equal to the local ip address of your web server.
Find &lt;Directory &#8220;c:/wamp/www/&#8221;&gt; and enter:
Order Allow,Deny
Allow from all

right before &lt;/Directory&gt;
Save the file.

<h3>Configure PHPMyAdmin Alias file</h3>
This will allow us to access PHPMyAdmin from the web. 
Open <b>phpmyadmin.conf </b>found in<b> </b>C:\wamp\alias and edit the following line:
Require local

and replace it with..
Require all granted

Save the file. 
You should now be able to access the site via http://youripaddress and PHPMyAdmin via http://youripaddress/phpmyadmin

<h3>Put WAMP Server online</h3>
The last step is to put WAMP server online.
<img src="https://i0.wp.com/blog.hsnyc.co/wp-content/uploads/2015/03/wamp-server-put-online.png">

<h2>Common and top web server software on the market</h2>
There are a number of common web servers available, some including:

<b>Apache HTTP Server.</b> Developed by Apache Software Foundation, it is a free and open source web server for Windows, Mac OS X, Unix, Linux, Solaris and other operating systems; it needs the Apache license.

<b>Microsoft Internet Information Services (IIS).</b> Developed by Microsoft for Microsoft platforms; it is not open sourced, but widely used.

<b>Nginx.</b> A popular open source web server for administrators because of its lightresource utilization and scalability. 
It can handle many concurrent sessions due to its event-driven architecture. 
Nginx also can be used as a proxy server and load balancer.

<b> Lighttpd. </b>A free web server that comes with the FreeBSD operating system. 
It is seen as fast and secure, while consuming less CPU power.

<b>Sun Java System Web Server. </b>
A free web server from Sun Microsystems that can run on Windows, Linux and Unix. 
It is well-equipped to handle medium to large websites.

Leading web servers include:
Apache, Microsoft's Internet Information Services (IIS) and Nginx-- pronounced <em>engine X</em>. 

Other web servers include:
Novell's NetWare server,
Google Web Server (GWS) and
IBM's family of Domino servers.



<h2>create HTTP Server</h2>
<div id="HTTPServertoc" class="toc"><a href="#HTTPServertopic-0" target="_self">Basic HTTP Server</a><br><a href="#HTTPServertopic-1" target="_self">Returning Different Types of Content</a><br><a href="#HTTPServertopic-2" target="_self">Serving JSON</a><br><a href="#HTTPServertopic-3" target="_self">Serving CSV</a><br><a href="#HTTPServertopic-4" target="_self">Serving HTML</a><br><a href="#HTTPServertopic-5" target="_self">Serving an HTML Page From a File</a><br><a href="#HTTPServertopic-6" target="_self">Serving HTML Efficiently</a><br><a href="#HTTPServertopic-7" target="_self">Managing Routes Using an HTTP Request Object</a><br></div></center><br><br>

<h3 id="HTTPServertopic-0">Basic HTTP Server</h3>
In the terminal, create a folder called <code>first-servers</code>:
<code>mkdir first-servers
cd first-servers</code>

Now, create the file hello.js that will house the code:
Add the following line to <code>hello.js</code>:
<code>const http = require("http");</code>
The <code>http</code> module contains the function to create the server. 
The next step will be to define two constants, the host and port that our server will be bound to hello.js
<code>
const host = 'localhost';
const port = 8000;</code>

Let’s add a special function, which in Node.js we call a <em>request listener</em>. 
This function is meant to handle an incoming HTTP request and return an HTTP response. 
This function must have two arguments, a request object and a response object. 

The request object captures all the data of the HTTP request that’s coming in. 
The response object is used to return HTTP responses for the server.
We want our first server to return this message whenever someone accesses it: <code>"My first server!"</code>.

Let’s add that function next:
<code>
const requestListener = function (req, res) {
 res.writeHead(200);
 res.end("My first server!");
};</code>
The function would usually be named based on what it does. 

For example, if we created a request listener function to return a list of books, we would likely name it <code>listBooks()</code>. 
Since this one is a sample case, we will use the generic name <code>requestListener</code>.
All request listener functions in Node.js accept two arguments: <code>req</code> and <code>res</code> (we can name them differently if we want). 

The HTTP request the user sends is captured in a Request object, which corresponds to the first argument, <code>req</code>. 
The HTTP response that we return to the user is formed by interacting with the Response object in second argument, <code>res</code>.
The first line <code>res.writeHead(200);</code> sets the HTTP status code of the response. 

HTTP status codes indicate how well an HTTP request was handled by the server. 
In this case, the status code <code>200</code> corresponds to <code>"OK"</code>. 

The next line of the function, <code>res.end("My first server!");</code>, writes the HTTP response back to the client who requested it. 
This function returns any data the server has to return. 
In this case, it’s returning text data.

Finally, we can now create our server and make use of our request listener:
<code>
const server = http.createServer(requestListener);
 server.listen(port, host, () =&gt; {
 console.log(`Server is running on http://${host}:${port}`);
});</code>
Save and exit.

In the first line, we create a new <code>server</code> object via the <code>http</code> module’s <code>createServer()</code> function. 
This server accepts HTTP requests and passes them on to our <code>requestListener()</code> function.
After we create our server, we must bind it to a network address. 

We do that with the <code>server.listen()</code> method. 
It accepts three arguments: <code>port</code>, <code>host</code>, and a callback function that fires when the server begins to listen.
All of these arguments are optional, but it is a good idea to explicitly state which port and host we want a web server to use. 

When deploying web servers to different environments, knowing the port and host it is running on is required to set up load balancing or a DNS alias.
The callback function logs a message to our console so we can know when the server began listening to connections.
<strong>Note:</strong> Even though <code>requestListener()</code> does not use the <code>req</code> object, it must still be the first argument of the function.

With less than fifteen lines of code, we now have a web server. 
Let’s see it in action and test it end-to-end by running the program:
<code>node hello.js</code>

In the console, we will see this output:
<code>OutputServer is running on http://localhost:8000</code>

Notice that the prompt disappears. 
This is because a Node.js server is a long running process. 
It only exits if it encounters an error that causes it to crash and quit, or if we stop the Node.js process running the server.

In a separate terminal window, we’ll communicate with the server using cURL, a CLI tool to transfer data to and from a network. 

Enter the command to make an HTTP <code>GET</code> request to our running server:
<code>curl http://localhost:8000</code>
When we press <code>ENTER</code>, our terminal will show the following output:
<code>OutputMy first server!</code>
We’ve now set up a server and got our first server response.
Before we continue, let’s exit our running server by pressing <code>CTRL+C</code>. 

This interrupts our server’s execution, bringing us back to the command line prompt.
In most web sites we visit or APIs we use, the server responses are seldom in plain text. 
We get HTML pages and JSON data as common response formats. 

In the next step, we will learn how to return HTTP responses in common data formats we encounter in the web.
<h3 id="HTTPServertopic-1">Returning Different Types of Content</h3>
The response we return from a web server can take a variety of formats. 

JSON and HTML were mentioned before, and we can also return other text formats like XML and CSV. 
Finally, web servers can return non-text data like PDFs, zipped files, audio, and video.
In this article, in addition to the plain text we just returned, you’ll learn how to return the following types of data:

JSON, CSV, HTML
The three data types are all text-based, and are popular formats for delivering content on the web. 

Many server-side development languages and tools have support for returning these different data types. 
In the context of Node.js, we need to do two things:

Set the <code>Content-Type</code> header in our HTTP responses with the appropriate value.
Ensure that <code>res.end()</code> gets the data in the right format.

Let’s see this in action with some examples. 
The code we will be writing in this section and later ones have many similarities to the code we wrote previously. 
Most changes exist within the <code>requestListener()</code> function. 

Let’s create files with this “template code” to make future sections easier to follow.
Create a new file called <code>html.js</code>. 
This file will be used later to return HTML text in an HTTP response. 

We’ll put the template code here and copy it to the other servers that return various types.
In the terminal, enter the following:
<code>touch html.js</code>
Now open this file in a text editor:

<code>nano html.js</code>

Let’s copy the “template code.” Enter this in <code>nano</code>:
first-servers/html.js
<code>const http = require("http");

const host = 'localhost';
const port = 8000;
const requestListener = function (req, res) {};

const server = http.createServer(requestListener);
server.listen(port, host, () =&gt; {
console.log(`Server is running on http://${host}:${port}`);
});</code>
Save and exit <code>html.js</code> with <code>CTRL+X</code>, then return to the terminal.

Now let’s copy this file into two new files. 
The first file will be to return CSV data in the HTTP response:
<code>cp html.js csv.js</code>
The second file will return a JSON response in the server:

<code>cp html.js json.js</code>

The remaining files will be for later exercises:
<code>cp html.js htmlFile.js
cp html.js routes.js</code>
We’re now set up to continue our exercises. 

Let’s begin with returning JSON.
<h3 id="HTTPServertopic-2">Serving JSON</h3>
<em>JavaScript Object Notation</em>, commonly referred to as JSON, is a text-based data exchange format. 

As its name suggests, it is derived from JavaScript objects, but it is language independent, meaning it can be used by any programming language that can parse its syntax.
JSON is commonly used by APIs to accept and return data. 
Its popularity is due to lower data transfer size than previous data exchange standards like XML, as well as the tooling that exists that allow programs to parse them without excessive effort. 

If you’d like to learn more about JSON, you can read our guide on How To Work with JSON in JavaScript.
Open the <code>json.js</code> file json.js
We want to return a JSON response. 

Let’s modify the <code>requestListener()</code> function to return the appropriate header all JSON responses have by changing the highlighted lines like so:
first-servers/json.js
<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "application/json");
};</code>
The <code>res.setHeader()</code> method adds an HTTP header to the response. 

HTTP headers are additional information that can be attached to a request or a response. 
The <code>res.setHeader()</code> method takes two arguments: the header’s name and its value.
The <code>Content-Type</code> header is used to indicate the format of the data, also known as media type, that’s being sent with the request or response. 

In this case our <code>Content-Type</code> is <code>application/json</code>.
Now, let’s return JSON content to the user. 
Modify <code>json.js</code> so it looks like this:

first-servers/json.js
<code>const requestListener = function (req, res) {

res.setHeader("Content-Type", "application/json");
 res.writeHead(200);
 res.end(`{"message": "This is a JSON response"}`);
};</code>

Like before, we tell the user that their request was successful by returning a status code of <code>200</code>. 
This time in the <code>response.end()</code> call, our string argument contains valid JSON.
Save and exit <code>json.js</code> by pressing <code>CTRL+X</code>. 

Now, let’s run the server with the <code>node</code> command:
<code>node json.js</code>
In another terminal, let’s reach the server by using cURL:
<code>curl http://localhost:8000</code>
As we press <code>ENTER</code>, we will see the following result:

<code>Output{"message": "This is a JSON response"}</code>
We now have successfully returned a JSON response, just like many of the popular APIs we create apps with. 

Be sure to exit the running server with <code>CTRL+C</code> so we can return to the standard terminal prompt. 
Next, let’s look at another popular format of returning data: CSV.
<h3 id="HTTPServertopic-3">Serving CSV</h3>

The <em>Comma Separated Values</em> (CSV) file format is a text standard that’s commonly used for providing tabular data. 
In most cases, each row is separated by a newline, and each item in the row is separated by a comma.
In our workspace, open the <code>csv.js</code> file with a text editor:

<code>nano csv.js</code>

Let’s add the following lines to our <code>requestListener()</code> function:
first-servers/csv.js
<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "text/csv");
res.setHeader("Content-Disposition", "attachment;filename=oceanpals.csv");
};</code>

This time, our <code>Content-Type</code> indicates that a CSV file is being returned as the value is <code>text/csv</code>. 
The second header we add is <code>Content-Disposition</code>. 
This header tells the browser how to display the data, particularly in the browser or as a separate file.

When we return CSV responses, most modern browsers automatically download the file even if the <code>Content-Disposition</code> header is not set. 
However, when returning a CSV file we should still add this header as it allows us to set the name of the CSV file. 
In this case, we signal to the browser that this CSV file is an attachment and should be downloaded. 

We then tell the browser that the file’s name is <code>oceanpals.csv</code>.
Let’s write the CSV data in the HTTP response:
first-servers/csv.js

<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "text/csv");

res.setHeader("Content-Disposition", "attachment;filename=oceanpals.csv");
res.writeHead(200);
res.end(`id,name,email\n1,Sammy Shark,shark@ocean.com`);
};</code>

Like before we return a <code>200</code>/<code>OK</code> status with our response. 
This time, our call to <code>res.end()</code> has a string that’s a valid CSV. 
The comma separates the value in each column and the new line character (<code>\n</code>) separates the rows. 

We have two rows, one for the table header and one for the data.
We’ll test this server in the browser. 
Save <code>csv.js</code> and exit the editor with <code>CTRL+X</code>.

Run the server with the Node.js command:
<code>node csv.js</code>
In another Terminal, let’s reach the server by using cURL:
<code>curl http://localhost:8000</code>
The console will show this:

<code>Outputid,name,email
1,Sammy Shark,shark@ocean.com</code>

If we go to <code>http://localhost:8000</code> in our browser, a CSV file will be downloaded. 
Its file name will be <code>oceanpals.csv</code>.
Exit the running server with <code>CTRL+C</code> to return to the standard terminal prompt.

Having returned JSON and CSV, we’ve covered two cases that are popular for APIs. 
Let’s move on to how we return data for websites people view in a browser.
<h3 id="HTTPServertopic-4">Serving HTML</h3>

HTML, HyperText Markup Language, is the most common format to use when we want users to interact with our server via a web browser. 
It was created to structure web content. 
Web browsers are built to display HTML content, as well as any styles we add with CSS, another front-end web technology that allows us to change the aesthetics of our websites.

Let’s reopen <code>html.js</code> with our text editor:
<code>nano html.js</code>
Modify the <code>requestListener()</code> function to return the appropriate <code>Content-Type</code> header for an HTML response:
first-servers/html.js

<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "text/html");
};</code>

Now, let’s return HTML content to the user. 
Add the highlighted lines to <code>html.js</code> it looks
first-servers/html.js

<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "text/html");

res.writeHead(200);
res.end(`&lt;html&gt;&lt;body&gt;&lt;h1&gt;This is HTML&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;`);
};</code>
We first add the HTTP status code. 

We then call <code>response.end()</code> with a string argument that contains valid HTML. 
When we access our server in the browser, we will see an HTML page with one header tag containing <code>This is HTML</code>.
Let’s save and exit by pressing <code>CTRL+X</code>. 

Now, let’s run the server with the <code>node</code> command:
<code>node html.js</code>
We will see <code>Server is running on http://localhost:8000</code> when our program has started.
Now go into the browser and visit <code>http://localhost:8000</code>. 

Our page will look like this:
<img src="https://assets.digitalocean.com/articles/67009/html-response.png">
Let’s quit the running server with <code>CTRL+C</code> and return to the standard terminal prompt.

It’s common for HTML to be written in a file, separate from the server-side code like our Node.js programs. 
Next, let’s see how we can return HTML responses from files.
<h3 id="HTTPServertopic-5">Serving an HTML Page From a File</h3>
We can serve HTML as strings in Node.js to the user, but it’s preferable that we load HTML files and serve their content. 
This way, as the HTML file grows we don’t have to maintain long strings in our Node.js code, keeping it more concise and allowing us to work on each aspect of our website independently. 
This “separation of concerns” is common in many web development setups, so it’s good to know how to load HTML files to support it in Node.js

To serve HTML files, we load the HTML file with the <code>fs</code> module and use its data when writing our HTTP response.
First, we’ll create an HTML file that the web server will return. 
Create a new HTML file:

<code>touch index.html</code>
Now open <code>index.html</code> in a text editor:
Our web page will be minimal. 
It will have an orange background and will display some greeting text in the center. 

Add this code to the file:
first-servers/index.html
<code>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;title&gt;My Website&lt;/title&gt;
&lt;style&gt;
*, html { margin: 0; padding: 0; border: 0; }
html { width: 100%; height: 100%; }
body { width: 100%; height: 100%; position: relative;
       background-color: rgb(236, 152, 42); }
.center { width: 100%; height: 50%; margin: 0; position:
    absolute; top: 50%; left: 50%; transform:
    translate(-50%, -50%); color: white;
    font-family: "Trebuchet MS", Helvetica, sans-serif;
    text-align: center; }
h1 { font-size: 144px; }
p { font-size: 64px; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div class="center"&gt;
&lt;h1&gt;Hello Again!&lt;/h1&gt;
&lt;p&gt;This is served from a file&lt;/p&gt;
&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;</code>
This single webpage shows two lines of text: <code>Hello Again!</code> and <code>This is served from a file</code>. 

The lines appear in the center of the page, one above each other. 
The first line of text is displayed in a heading, meaning it would be large. 
The second line of text will appear slightly smaller. 

All the text will appear white and the webpage has an orange background.
While it’s not the scope of this article or series, if you are interested in learning more about HTML, CSS, and other front-end web technologies, you can take a look at Mozilla’s Getting Started with the Web guide.
That’s all we need for the HTML, so save and exit the file with <code>CTRL+X</code>. 

We can now move on to the server code.
For this exercise, we’ll work on <code>htmlFile.js</code>. 
Open it with the text editor:

As we have to read a file, let’s begin by importing the <code>fs</code> module:
first-servers/htmlFile.js
<code>const http = require("http");

const fs = require('fs').promises;</code>

This module contains a <code>readFile()</code> function that we’ll use to load the HTML file in place. 
We import the promise variant in keeping with modern JavaScript best practices. 
We use promises as its syntactically more succinct than callbacks, which we would have to use if we assigned <code>fs</code> to just <code>require('fs')</code>. 

To learn more about asynchronous programming best practices, you can read our How To Write Asynchronous Code in Node.js guide.
We want our HTML file to be read when a user requests our system. 
Let’s begin by modifying <code>requestListener()</code> to read the file:

first-servers/htmlFile.js
<code>const requestListener = function (req, res) {

fs.readFile(__dirname + "/index.html")
};</code>
We use the <code>fs.readFile()</code> method to load the file. 
Its argument has <code>__dirname + "/index.html"</code>. 

The special variable <code>__dirname</code> has the absolute path of where the Node.js code is being run. 
We then append <code>/index.html</code> so we can load the HTML file we created earlier.
Now let’s return the HTML page once it’s loaded:

first-servers/htmlFile.js
<code>const requestListener = function (req, res) {

fs.readFile(__dirname + "/index.html")
.then(contents =&gt; {
res.setHeader("Content-Type", "text/html");

res.writeHead(200);
res.end(contents);
})
};</code>

If the <code>fs.readFile()</code> promise successfully resolves, it will return its data. 
We use the <code>then()</code> method to handle this case. 
The <code>contents</code> parameter contains the HTML file’s data.

We first set the <code>Content-Type</code> header to <code>text/html</code> to tell the client that we are returning HTML data. 
We then write the status code to indicate the request was successful. 
We finally send the client the HTML page we loaded, with the data in the <code>contents</code> variable.

The <code>fs.readFile()</code> method can fail at times, so we should handle this case when we get an error. 
Add this to the <code>requestListener()</code> function:
first-servers/htmlFile.js

<code>const requestListener = function (req, res) {
fs.readFile(__dirname + "/index.html")

.then(contents =&gt; {
res.setHeader("Content-Type", "text/html");
res.writeHead(200);

res.end(contents);
})
.catch(err =&gt; {

res.writeHead(500);
res.end(err);
return;
});
};</code>
Save the file and exit <code>nano</code> with <code>CTRL+X</code>.
When a promise encounters an error, it is rejected. 

We handle that case with the <code>catch()</code> method. 
It accepts the error that <code>fs.readFile()</code> returns, sets the status code to <code>500</code> signifying that an internal error was encountered, and returns the error to the user.
Run our server with the <code>node</code> command:

<code>node htmlFile.js</code>

In the web browser, visit <code>http://localhost:8000</code>. 
You will see this page:
<img src="https://assets.digitalocean.com/articles/67009/html-file.png">

You have now returned an HTML page from the server to the user. 
You can quit the running server with <code>CTRL+C</code>. 
You will see the terminal prompt return when you do.

When writing code like this in production, you may not want to load an HTML page every time you get an HTTP request. 
While this HTML page is roughly 800 bytes in size, more complex websites can be megabytes in size. 
Large files can take a while to load. 

If your site is expecting a lot of traffic, it may be best to load HTML files at startup and save their contents. 
After they are loaded, you can set up the server and make it listen to requests on an address.
To demonstrate this method, let’s see how we can rework our server to be more efficient and scalable.

<h3 id="HTTPServertopic-6">Serving HTML Efficiently</h3>
Instead of loading the HTML for every request, in this step we will load it once at the beginning. 
The request will return the data we loaded at startup.

In the htmlFile.js

Let’s begin by adding a new variable before we create the <code>requestListener()</code> function:
first-servers/htmlFile.js

<code>let indexFile;
const requestListener = function (req, res) {</code>
When we run this program, this variable will hold the HTML file’s contents.

Now, let’s readjust the <code>requestListener()</code> function. 
Instead of loading the of <code first-servers="" htmlfile.js="" <code="">const requestListener = function (req, res) {
res.setHeader("Content-Type", "text/html");

res.writeHead(200);
res.end(indexFile);
};</code>
Next, we shift the file reading logic from the <code>requestListener()</code> function to our server startup. 

Make the following changes as we create the server:
first-servers/htmlFile.js
<code>const server = http.createServer(requestListener);
fs.readFile(__dirname + "/index.html")
.then(contents =&gt; {

indexFile = contents;
server.listen(port, host, () =&gt; {
console.log(`Server is running on http://${host}:${port}`);
});
})
.catch(err =&gt; {

console.error(`Could not read index.html file: ${err}`);
process.exit(1);
});</code>
Save the file and exit <code>nano</code> with <code>CTRL+X</code>.
The code that reads the file is similar to what we wrote in our first attempt. 

However, when we successfully read the file we now save the contents to our global <code>indexFile</code> variable. 
We then start the server with the <code>listen()</code> method. 
The key thing is that the file is loaded before the server is run. 

This way, the <code>requestListener()</code> function will be sure to return an HTML page, as <code>indexFile</code> is no longer an empty variable.
Our error handler has changed as well. 
If the file can’t be loaded, we capture the error and print it to our console. 

We then exit the Node.js program with the <code>exit()</code> function without starting the server. 
This way we can see why the file reading failed, address the problem, and then start the server again.
We’ve now created different web servers that return various types of data to a user. 

So far, we have not used any request data to determine what should be returned. 
We’ll need to use request data when setting up different routes or paths in a Node.js server, so next let’s see how they work together.
<h3 id="HTTPServertopic-7">Managing Routes Using an HTTP Request Object</h3>
Most websites we visit or APIs we use usually have more than one endpoint so we can access various resources. 
A good example would be a book management system, one that might be used in a library. 
It would not only need to manage book data, but it would also manage author data for cataloguing and searching convenience.

Even though the data for books and authors are related, they are two different objects. 
In these cases, software developers usually code each object on different endpoints as a way to indicate to the API user what kind of data they are interacting with.
Let’s create a new server for a small library, which will return two different types of data. 

If the user goes to our server’s address at <code>/books</code>, they will receive a list of books in JSON. 
If they go to <code>/authors</code>, they will receive a list of author information in JSON.
So far, we have been returning the same response to every request we get. 

Let’s illustrate this quickly.
Re-run our JSON response example:
<code>node json.js</code>
In another terminal, let’s do a cURL request like before:

<code>curl http://localhost:8000</code>

You will see:
<code>Output{"message": "This is a JSON response"}</code>

Now let’s try another curl command:
<code>curl http://localhost:8000/todos</code>
After pressing <code>Enter</code>, you will see the same result:
<code>Output{"message": "This is a JSON response"}</code>
We have not built any special logic in our <code>requestListener()</code> function to handle a request whose URL contains <code>/todos</code>, so Node.js returns the same JSON message by default.
As we want to build a miniature library management server, we’ll now separate the kind of data that’s returned based on the endpoint the user accesses.

First, exit the running server with <code>CTRL+C</code>.
Now open <code>routes.js</code> in your text editor:
<code>nano routes.js</code>
Let’s begin by storing our JSON data in variables before the <code>requestListener()</code> function:

first-servers/routes.js
<code>const books = JSON.stringify([

{ title: "The Alchemist", author: "Paulo Coelho", year: 1988 },
{ title: "The Prophet", author: "Kahlil Gibran", year: 1923 }
]);

const authors = JSON.stringify([
{ name: "Paulo Coelho", countryOfBirth: "Brazil", yearOfBirth: 1947 },
{ name: "Kahlil Gibran", countryOfBirth: "Lebanon", yearOfBirth: 1883 }

]);</code>

The <code>books</code> variable is a string that contains JSON for an array of book objects. 
Each book has a title or name, an author, and the year it was published.
The <code>authors</code> variable is a string that contains the JSON for an array of author objects. 

Each author has a name, a country of birth, and their year of birth.
Now that we have the data our responses will return, let’s start modifying the <code>requestListener()</code> function to return them to the correct routes.
First, we’ll ensure that every response from our server has the correct <code>Content-Type</code> header:

first-servers/routes.js
<code>const requestListener = function (req, res) {

res.setHeader("Content-Type", "application/json");
}</code>
Now, we want to return the right JSON depending path the
Let’s create a <code>switch</code> statement on the request’s URL:

first-servers/routes.js
<code>const requestListener = function (req, res) {

res.setHeader("Content-Type", "application/json");
switch (req.url) {}
}</code>
To get the URL path from a request object, we need to access its <code>url</code> property. 

We can now add cases to the <code>switch</code> statement to return the appropriate JSON.
JavaScript’s <code>switch</code> statement provides a way to control what code is run depending on the value of an object or JavaScript expression (for example, the result of mathematical operations). 
If you need a lesson or reminder on how to use them, take a look at our guide on How To Use the Switch Statement in JavaScript.

Let’s continue by adding a <code>case</code> for when the user wants to get our list of books:
first-servers/routes.js
<code>const requestListener = function (req, Type"
switch (req.url) {

case "/books":
res.writeHead(200);
res.end(books);

break
}
}</code>
We set our status code to <code>200</code> to indicate the request is fine and return the JSON containing the list of our books. 

Now let’s add another <code>case</code> for our authors:
first-servers/routes.js
<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "application/json");
switch (req.url) {

case "/books":
res.writeHead(200);
res.end(books);

break
case "/authors":
res.writeHead(200);

res.end(authors);
break
}
}</code>

Like before, the status code will be <code>200</code> as the request is fine. 
This time we return the JSON containing the list of our authors.
We want to return an error if the user tries to go to any other path. 

Let’s add the default case to do this:
routes.js
<code>const requestListener = function (req, res) {
res.setHeader("Content-Type", "application/json");
switch (req.url) {

case "/books":
res.writeHead(200);
res.end(books);

break
case "/authors":
res.writeHead(200);

res.end(authors);
break
default:

res.writeHead(404);
res.end(JSON.stringify({error:"Resource not found"}));
}
}</code>

We use the <code>default</code> keyword in a <code>switch</code> statement to capture all other scenarios not captured by our previous cases. 
We set the status code to <code>404</code> to indicate that the URL they were looking for was not found. 
We then set a JSON object that contains an error message.

Let’s test our server to see if it behaves as we expect. 
In another terminal, let’s first run a command to see if we get back our list of books:
<code>curl http://localhost:8000/books</code>
Press <code>Enter</code> to see the following output:

<code>Output[{"title":"The Alchemist","author":"Paulo Coelho","year":1988},{"title":"The Prophet","author":"Kahlil Gibran","year":1923}]</code>
So far so good. 

Let’s try the same for <code>/authors</code>. 
Type the following command in the terminal:
<code>curl http://localhost:8000/authors</code>
You will see the following output when the command is complete:

<code>Output[{"name":"Paulo Coelho","countryOfBirth":"Brazil","yearOfBirth":1947},{"name":"Kahlil Gibran","countryOfBirth":"Lebanon","yearOfBirth":1883}]</code>
Last, let’s try an erroneous URL to ensure that <code>requestListener()</code> returns the error response:

<code>curl http://localhost:8000/notreal</code>

Entering that command will display this message:
<code>Output{"error":"Resource not found"}</code>

You can exit the running server with <code>CTRL+C</code>.
We’ve now created different avenues for users to get different data. 
We also added a default response that returns an HTTP error if the user enters a URL that we don’t support.

<h2>Setting up a static server using R</h2>
<h3>Installing the <code>servr</code> package</h3>
The “R console” panel in RGui is use to type R code and execute it, much like the JavaScript console. 
The first thing we need to do is install the <code>servr</code> package, which includes the static server function. 
Type the following expression into the R Console and press Enter:
<code>install.packages("servr")</code>

<h3>Starting the server</h3>
To use the <code>servr</code> package, you need to load it into the R session:
<code>library(servr)</code>

Next, navigate to the directory on your computer where you want to start the static server, using the <code>setwd</code> function. 
For example, if the directory you wish to serve is located at <code>C:\tmp\examples</code>, then you need to execute the following expression:

<code>setwd("C:\\Users\\dorman\\Downloads")</code>

Note that the path parts need to be separated with <code>\\</code> (or <code>/</code>), not with <code>\</code>!

Finally, the server is started with the <code>httd</code> function:

<code>httd()</code>
To allow other computers to connect to the server, use the following expression instead:

<code>httd(host="0.0.0.0")</code>

Running either of the that last expressions should open the browser window with the served directory automatically. 
Otherwise, you can open the served site by browsing to the following URL (Figure I.2):

<code>http://localhost:4321/</code>
<img class="lazy" data-src="https://geobgu.xyz/web-mapping2/images/servr-localhost.png">
FIGURE I.2: Page served using R package <code>servr</code>

To some degree, this package is like python -m SimpleHTTPServer or python -m http.server.

You can either run servr::httd() in an interactive R session, or run from command line:

# default: port 4321, do not launch browser
Rscript -e "servr::httd()"

# open a web browser
Rscript -e "servr::httd()" -b

# listen on port 4000
Rscript -e "servr::httd()" -p4000

# pass arguments to the httd() function
Rscript -e "servr::httd(,4000,TRUE)"

There is also a shell script under system.file('bin', package = 'servr'); if it is added to PATH, you can simply run

servr  # serve the current directory
servr -b  # launch the browser
servr -b -p4000  # change port to 4000

<h2>cURL, a CLI tool</h2>
curl 138.19.128.21:7000 >> txt.html

curl https://www.hepingribao.com/home/  --insecure >>txt.txt

<h2>Turn Microsoft Defender Firewall on or off</h2>

Select <b>Start </b> , then open <b>Settings </b> . 
Under <b>Privacy & security </b> , select <b>Windows Security </b> > <b>Firewall & network protection</b>.

Select a network profile: <b>Domain network</b>, <b>Private network</b>, or <b>Public network</b>.

Under <b>Microsoft Defender Firewall</b>, switch the setting to <b>On</b>. 

If your device is connected to a network, network policy settings might prevent you from completing these steps. 
For more info, contact your administrator.

To turn it off, switch the setting to <b>Off</b>. 
Turning off Microsoft Defender Firewall could make your device (and network, if you have one) more vulnerable to unauthorized access. 
If there's an app you need to use that's being blocked, you can allow it through the firewall, instead of turning the firewall off.

Select the <b>Start </b> button > <b>Settings </b> > <b>Update & Security </b> > <b>Windows Security</b> and then <b>Firewall & network protection</b>. 

Select a network profile: <b>Domain network</b>, <b>Private network</b>, or <b>Public network</b>.

Under <b>Microsoft Defender Firewall</b>, switch the setting to <b>On</b>. 
If your device is connected to a network, network policy settings might prevent you from completing these steps. 
For more info, contact your administrator.

To turn it off, switch the setting to <b>Off</b>. 
Turning off Microsoft Defender Firewall could make your device (and network, if you have one) more vulnerable to unauthorized access. 
If there's an app you need to use that's being blocked, you can allow it through the firewall, instead of turning the firewall off.

<b>Note:</b> If you get errors, or if the setting won't turn on, you can <a href="https://support.microsoft.com/help/17613" target="_blank">use the troubleshooter</a> and then try again.

<h2>Block or Allow TCP/IP Port in Windows Firewall</h2>
Windows Firewall allows you to restrict outgoing/incoming network traffic for a specific application or TCP/IP port. 

Navigate to the <i>Advanced Settings</i> of the firewall. 
Start by opening up the control panel and typing 'Firewall' into the search box type. 
Then, open Firewall and click on the ‘Advanced Settings’ link.

<i>1. Open Windows Firewall and find the Advanced Settings. 
</i>To open Windows Firewall, type 'firewall.cpl' into the search bar and press the Enter key.
When 'Advanced Settings' opens, click the <i>Advanced Settings</i> link in the left-hand pane of the main firewall dialog box. 

This will bring up the 'Windows Firewall with Advanced Security' window.
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/click-the-Advanced-Settings-link.png.webp">

<i>2. Open the List of Inbound Rules.</i>
On the left-hand pane of the window, click on '<i>Inbound Rules</i>' to bring up the list of rules.
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/click-on-Inbound-Rules.png.webp">

<i>3. Set up a New Rule.</i>
From the Actions pane on the right-hand side, select ‘<i>New Rule</i>&#8230;’

<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/Select-New-Rule.png.webp">

<i>4. Open the New Inbound Rule Wizard.</i>

Select '<i>Port</i>' and then click '<i>Next</i>.' This will open the ‘<i>New Inbound Rule Wizard</i>’ window.
From there, select ‘<i>Port</i>’ as the new <i>Rule Type</i> and click '<i>Next</i>.'
Click on '<i>Specific local ports</i>.' Then choose a port number (e.g., 80).

Click '<i>Next</i>' to continue.
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/Open-the-New-Inbound-Rule-Wizard.png.webp">

<i>5. Block the Connection.</i>
In the Action window, select ‘<i>Block the connection</i>’ and click '<i>Next</i>.'
<i>6. Apply Your New Rule to Each Profile Type.</i>
In the Profile window, tick the boxes to apply your rule to each of the three profile types: Domain, Private, and Public. 
Click '<i>Next</i>' to continue.

<i>7. Name Your Rule and Configure the Settings.</i>
Choose a name for your new rule, e.g., ‘<i>block suspicious ports</i>.’

If you want, you can also add an optional description to your rule.
When you're done, click '<i>Finish</i>' to configure the settings.
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/Name-your-rule-and-configure-the-settings.png.webp">

<h3>Open a Port in Windows Firewall</h3>
You may want to open a port in the Windows Firewall in order to let a specific IP address communicate with your computer (e.g., when you're playing games). 
The procedure to open a port remains more or less the same. 

All you need to do is follow the instructions in the New Inbound Rule wizard, specify the Port, and select 'Allow the connection.'
<h3>Turn off TCP/IP Port in Windows Firewall with Action1</h3>
Follow the steps below to turn off the TCP/IP Port in Windows Firewall:

1. Log in to the Action1 dashboard.
2. In the menu on the left-hand side, select '<i>Managed Endpoints</i>.'
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/managed-endpoints-2.png.webp">

3. Mark the endpoint for the port you want to block.
4. Click the '<i>More Actions</i>' button and then select the <i>Run Command</i> option.

<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/run-command-1.png.webp">

5. In the window that opens, enter the command <i>netsh advfirewall firewall add rule name=&#8221;BlockAIM&#8221; protocol=TCP dir=out remoteport=4099 action=block</i>. 

(In this case, we're blocking port 4099).
<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/netsh-advfirewall-firewall-add-rule-name-BlockAIM.png.webp">

6. Click '<i>Next Step</i>.'
7. Click '<i>Add Endpoints</i>' and then select the endpoints to which you will apply this blocking rule.

<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/select-managed-endpoints-2.png.webp">

8. Click '<i>Next Step</i>' and schedule the execution time of your command.

<img class="lazy" data-src="https://www.action1.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/05/schedule-and-finish-1.png.webp">

9. Click 'Finish.'

<h2>block a port</h2>
1.Click "Start | Control Panel | System and Security | Windows Firewall."
2.Select "Advanced Settings." Click "Inbound Rules" to block an inbound port; click "Outbound Rules" to block an outbound port.
3.Select "New Rule." Choose "Port" from the options and then click "Next."
4.Choose "TCP" or "UDP," depending on which protocol the port uses. 
Click "Specific Local Ports."
5.Enter the port number or numbers into the available field; separate multiple numbers with a comma (e.g., "80, 20, 443"). 
Click "Next."
6.Click "Block the Connection," then "Next." Choose which network location or locations – public, private or domain – the rule applies to and then click "Next."
7.Create a name for the rule and enter an optional description. 
Click "Finish" to block the ports on the computer.

<h2>On-link on the result of "route print"</h2>
They are addresses that can be resolved locally. 
They don't need a gateway because they don't need to be routed.

It's just a route that's directly reachable (the NIC is in direct contact with it; on the same subnet). 
The routes that have a gateway IP listed must be contacted through that gateway.

The destination machine would see the packet, and take it off the network directly.

<h2>Windows IP Commands ipconfig, nslookup, ping, tracert, netstat</h2>
<div id="netCmdstoc" class="toc"><a href="#netCmdstopic-0" target="_self">ipconfig</a><br><a href="#netCmdstopic-1" target="_self">nslookup</a><br><a href="#netCmdstopic-2" target="_self">ping command</a><br><a href="#netCmdstopic-3" target="_self">tracert command</a><br><a href="#netCmdstopic-4" target="_self">netstat command</a><br><a href="#netCmdstopic-5" target="_self">route command</a><br><a href="#netCmdstopic-6" target="_self">arp command</a><br><a href="#netCmdstopic-7" target="_self">HOSTNAME</a><br></div></center><br><br>

The most popular Windows CMD commands (from the DOS prompt) that are related to networking etc:

<h3 id="netCmdstopic-0">ipconfig</h3>
This is one of the most useful IP commands on Windows. 
It displays tons of useful information about the current network settings on the machine such as IPv4 and IPv6 address of all network interface cards (Ethernet adapters, WiFi adapters, virtual network adapters etc), MAC address, default gateway, subnet mask, DNS server, DHCP information etc.

If you want to find the local IP address assigned to your computer or the MAC address of your Ethernet Adapter (shown as “<i>Physical Address</i>” in the command output as shown in the picture below), this is the quickest way to find this information.

Here is a screenshot example of what you can expect as output from ipconfig:

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/ipconfig-command.jpg">

As shown above, you get information such as IPv4 and IPv6 address, MAC address, Default Dateway, DNS Servers etc.

Here are some different options of this command:

<i>ipconfig /?</i>  : Displays all available options.

<i>ipconfig /all</i>  : This will display output as shown on the screenshot above but for ALL network connection adapters of the computer (Wired Ethernet, WiFi, Vmware adapters etc).

<i>ipconfig /release</i>  : This will release the current IPv4 addresses which were assigned dynamically from a DHCP server. 
If you specify also a connection name at the end, it will release only the IP of that connection adapter.

<i>ipconfig /release6</i>  : Same as above but for the IPv6 address.

<i>ipconfig /renew</i>  : This usually comes after the above command and is used to request a new IP address from a DHCP server.

<i>ipconfig /renew6</i>  : Same as above but for the IPv6 address.

<i>ipconfig /flushdns</i>  : This deletes the local DNS resolver cache of the computer. 
This cache stores DNS entries of frequently accessed internet resources so that the computer will not query an external DNS server every time you try to access an internet resource (website etc). 
This command is useful when troubleshooting DNS connection problems.

<i>ipconfig /</i><i>displaydns </i>  : It shows the local DNS resolver cache entries as explained above.

<i>ipconfig /register</i><i>dns </i> : Refreshes all DHCP addresses and also communicates again with the external DNS server to make sure its reachable etc. 
Very useful when troubleshooting DNS and network connectivity problems of the local computer.

<h3 id="netCmdstopic-1">nslookup</h3>
<i> </i>“nslookup” stands for “Name System Lookup” and is very useful in obtaining Domain Name System (DNS) related information about a domain or about an IP address (reverse DNS lookup).

<i>nslookup [domain name]: </i>The most popular usage of this command is to find quickly the IP address of a specific domain name (A-record) as shown below:

Example: 

<i>nslookup www.networkstraining.com</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/nslookup-command.jpg">

As shown above, the “nslookup” command followed by a domain name will show you the IPv4 and IPv6 addresses  (A records and AAAA records) assigned to the specific domain.

<i>nslookup [IP Address]:</i> This will perform a reverse-DNS lookup and will try to match the given IP address in the command with its corresponding domain name.

Example: 

<i>nslookup 8.8.8.8</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/nslookup-reverse-dns.jpg">

As shown on the screenshot above, the IP address 8.8.8.8 is mapped with the name “<i>google-public-dns-a.google.com</i>”. 
You should note however that not all IP addresses are assigned to a domain name so a lot of times you will not get any information from the command above.

There are several other interesting features of the nslookup command such as finding the authoritative DNS servers of a domain, the SOA and MX records of a domain and much more.

<h3 id="netCmdstopic-2">ping command</h3>
Now let's examine one of the most popular utilities related to network connectivity.

Probably the first command that every computer user runs on the command line when having connectivity problems is the “<i>ping</i>” command.

This will quickly show you if can send and receive packets (<i>icmp</i> packets to be exact) from your computer and hence shows whether you have network connectivity or not.

Note also that “ping” is useful for testing connectivity for both the local computer from where you execute the command and also for a remote computer or server which you try to reach.

If for example you try to “ping” your local default gateway IP address and you get replies back (icmp echo replies), this means your local computer is properly connected to the network.

Now, if you “ping” a remote server on the Internet and you get replies back, it means that the remote server is properly connected to its network as well.

<i>ping /?</i>  : Displays all available options as shown below:

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/ping-help.jpg">

<i>ping [IP Address]</i>  : By default it will send 4 ICMP packets to the stated IP address.

Example: 

<i>ping 8.8.8.8</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/ping-ip.jpg">

As you can see from the screenshot above, pinging the IP 8.8.8.8 results in sending 4 packets and then receiving back 4 packets from that IP.

<i>ping [hostname or domain]</i>  : When “pinging” a hostname or domain name, the command will resolve first the name to IP address and then send the icmp packets to that IP.

Example: 

<i>ping www.networkstraining.com</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/ping-domain.jpg">

<i>ping [IP address] -t</i>  :This will send ping packets (icmp echo requests) continuously to the target IP.

<i>ping -n 10 [IP address]</i> :This will send 10 ping packets (icmp echo requests) to the target IP.

<i>ping -l 1500 [IP address]</i> :This will send ping packets (icmp echo requests) with size of 1500 bytes length to the target IP.

<i>ping -a [IP address]</i> :The -a switch tells the computer to try to find the hostname assigned to the specific IP address and then ping the IP.

<i>ping -6 [domain or IP]</i> :The -6 switch tells the computer to send IPv6 packets to the target.

<h3 id="netCmdstopic-3">tracert command</h3>
“<i>tracert</i>” in Windows stands for “Trace Route”. 
In Linux, the same command is “<i>traceroute</i>”.

The command traces the path that a TCP/IP packet takes towards a destination target and shows some information (if available) of the routing nodes within this path.

Just like the “ping” command, “tracert” sends also ICMP echo packets to the destination with varying Time-to-Live (TTL) values.

<i>tracert [domain or IP]</i> : Traces the TCP/IP path to the specified destination target IP or domain.

Example: 

<i>tracert www.networkstraining.com</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/tracert-domain.jpg">

As shown above, tracing the path to domain <i>www.networkstraining.com</i> shows all the intermediary routing nodes (with their hostname and IP address) until the final target destination.

When troubleshooting connection problems in a large network, you can use tracert to see where the packets stop before reaching the target and focus your efforts to find the problem on the node which does not route packets.

<h3 id="netCmdstopic-4">netstat command</h3>
Another important command is the Network Statistics (“netstat”) utility found in both Windows and Linux OS.

It shows the established network TCP/IP connections of the local computer with remote hosts, open ports on the machine, the process ID (PID) of each connection etc.

Personally I use this command mostly for security forensic purposes to identify if there are backdoors running on the computer, malicious connections to external Command-and-Control servers etc.

Here are some popular usages of this command:

<i>netstat -ano</i> : Displays all connections and listening ports (-a), addresses and ports in numerical form (-n) and also the process ID of each connection (-o).

<i>netstat -vb</i> : Very useful to examine also which executable and which sequence created each connection and each port.

Example:

C:\WINDOWS\system32&gt;<i>netstat -vb</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/netstat-vb.jpg">

As shown above, for each established connection you can see the executable (e.g <i>chrome.exe</i>, <i>googledrivesync.exe</i> etc) that created the connection.

<i>netstat -p tcp -f</i> : The “<i>-p tcp</i>” switch will show only TCP connections and the “<i>-f</i>” switch will show the FQDN name of each connection instead of just IP address.

Example:

C:\WINDOWS\system32&gt;<i>netstat -p tcp -f</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/netstat-pf.jpg">

<h3 id="netCmdstopic-5">route command</h3>
The “route” command is used to manipulate the local routing table of the computer. 
You can print the current routing table, add new static routes, delete entries etc.

Personally, the way I use the “route” command is to add a permanent static route entry in a computer. 
For example, there might be a specific network subnet which is not accessible via the default gateway of the computer. 
Instead, this remote subnet might be accessible via a different gateway IP. 
By adding a static route in the computer’s routing table you will be able to reach that remote subnet from a different gateway.

<i>route PRINT</i> : Displays the current routing table of the computer

<i>route ADD [Destination network] MASK [mask] [gatewayIP]</i>: This adds a static route in the table.

Example:

<i>route ADD 10.10.10.0 MASK 255.255.255.0 192.168.1.2</i>

The above command will add a static route for destination subnet 10.10.10.0/24 via gateway 192.168.1.2

<h3 id="netCmdstopic-6">arp command</h3>
ARP stands for “Address Resolution Protocol” and is one of the core networking protocols that work in Layer 2 level and facilitate communication in a LAN.

The job of ARP is to find the physical address (MAC address) of the target and map it with its corresponding Layer 3 IP address when communicating in a LAN. 
The ARP cache table stores mappings of IP addresses with their corresponding MAC address.

<i>arp -a </i>: Displays all ARP cache mappings (IP to MAC address)

Example:

C:\WINDOWS\system32&gt;<i>arp -a</i>

<img class="lazy" data-src="https://www.networkstraining.com/wp-content/uploads/2018/07/arp-a.jpg">

As you can see from above, the local computer has learned dynamically (type=dynamic) using the ARP protocol two other local devices (192.168.10.7 and 192.168.10.254) and has stored their MAC address (Physical Address) in the ARP table.

<i>arp -d [IP address] </i>: This will delete the arp entry for the specified IP address.

The above is useful when you changed hardware on a specific node (e.g you have changed the default gateway router) and you want to remove old arp entries. 
Usually it’s not needed to do anything in such a case but sometimes its required on some older computers.

<h3 id="netCmdstopic-7">HOSTNAME</h3>
The HOSTNAME command displays the hostname of the system. The hostname command is much easier to use than going into the system settings to search for it.

<h2>NETSTAT</h2>
NETSTAT [-a] [-b] [-e] [-f] [-n] [-o] [-p proto] [-r] [-s] [-t] [-x] [-y] [interval]

Displays protocol statistics and current TCP/IP network connections.

-a
Displays all connections and listening ports.

-b
Displays the executable involved in creating each connection or listening port.

In some cases well-known executables host multiple independent components, and in these cases the sequence of components involved in creating the connection or listening port is displayed.

In this case the executable name is in [] at the bottom, on top is the component it called, and so forth until TCP/IP was reached.

Note that this option can be time-consuming and will fail unless you have sufficient permissions.

-e
Displays Ethernet statistics.
This may be combined with the -s option.

-f
Displays Fully Qualified Domain Names (FQDN) for foreign addresses.

-n
Displays addresses and port numbers in numerical form.

-o
Displays the owning process ID associated with each connection.

-p proto
Shows connections for the protocol specified by proto; proto may be any of: TCP, UDP, TCPv6, or UDPv6.
If used with the -s option to display per-protocol statistics, proto may be any of: IP, IPv6, ICMP, ICMPv6, TCP, TCPv6, UDP, or UDPv6.

-q
Displays all connections, listening ports, and bound nonlistening TCP ports.
Bound nonlistening ports may or may not be associated with an active connection.

-r
Displays the routing table.

-s
Displays per-protocol statistics.
By default, statistics are shown for IP, IPv6, ICMP, ICMPv6, TCP, TCPv6, UDP, and UDPv6; the -p option may be used to specify a subset of the default.

-t
Displays the current connection offload state.

-x
Displays NetworkDirect connections, listeners, and shared endpoints.

-y
Displays the TCP connection template for all connections.
Cannot be combined with the other options.

interval
Redisplays selected statistics, pausing interval seconds between each display.
Press CTRL+C to stop redisplaying statistics.
If omitted, netstat will print the current configuration information once.









<script type='text/javascript' src='readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>

<script type='text/javascript' src='readbookNewMarker.js'></script>
</body>
</html>
