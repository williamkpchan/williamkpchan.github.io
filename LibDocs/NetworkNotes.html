<base target="_blank"><html><head><title>Network Notes</title>
<meta http-equiv="Content-Type" content="tex沐舒坦mustt/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="../lazyload.min.js"></script>
<script type='text/javascript' src='../mainscript.js'></script>
<script>
  var showTopicNumber = true;
  var bookid = "Network Notes" 
</script>
<style>
body{width:80%;margin-left: 10%; font-size:22px;}
h1, h2 {color: gold;}
strong {color: orange;}
img {max-width:90%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>Network Notes</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a>
<br><br>
<div id="toc"></div></center>
<br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br>
<a href="https://www.youtube.com/watch?v=1nRyrDGyAbI" class="whitebut ">更快的網路速度技巧</a>

<a href="https://www.youtube.com/watch?v=5a5tdJh8mKY" class="whitebut ">Oracle Cloud—for free tutorial</a>

<a href="https://www.oracle.com/hk/cloud/free/" class="whitebut ">Oracle Cloud—for free.</a>

<a href="https://www.youtube.com/watch?v=X9sexl1wXyE" class="whitebut ">永久免费的甲骨文云服务器该</a>
K..Oracle!

<a href="http://www.5gaia.org.cn/BloomingCup/Home" class="whitebut ">绽放杯 5G应用</a>

<a href="https://www.youtube.com/watch?v=ZPi56hSm__E" class="whitebut ">全局上网 Proxifier+Trojan</a>
<a href="https://wp.for-get.com/564.html" class="whitebut ">全局上网</a>

<a href="https://mp.weixin.qq.com/s/X-xF2JR3g7x33pW_7EiBkg" class="whitebut ">Nginx 可视化配置工具</a>

<a href="https://www.guru99.com/best-free-proxy.html" class="whitebut ">Proxy Server Service</a>

<a href="https://www.youtube.com/watch?v=-cRMD40Se80" class="whitebut ">Xender 無線傳輸APP</a>
<a href="https://www.youtube.com/watch?v=156s1hphwHg" class="whitebut ">免費創建自己的私人云盤</a>
<a href="https://www.youtube.com/watch?v=O4Y6UXjVlFQ" class="whitebut ">隱藏自己真實的IP地址5種方法</a>
<pre>

/F现代化智慧渔港，赋能海上执法管控
700M 零信任架构的关键信息基础设施安全管控系统
700M+900M的专网助力乌兰集团煤矿安全高效生产
700MHz与2.6GHz 融合组网的石化工业互联网应用
700M专网的海上智慧风电
AI智慧养殖平台
AR/VR红旗渠精神研学营地
AR实景导航在医疗行业的应用
AR眼镜，开拓行业新世代
C-V2X车联网，让人民生活更幸福
CBA体育赛事VR直播和体验
CIM的住建领域应用创新
eVPN技术实现固定IP通信的边缘计算网关
HIFIVE音乐开放平台
L2层实现全国跨域快速接入的-商企专网
LAN设备点控大大降低远程手术机器人时延
MEC+元宇宙释放消费新活力，加快建设全国统一大市场
MEC+区块链构建的广州市第一人民医院高水平智慧医院体系
MEC+数字孪生的广东智慧河长
MEC助力三峡集团打造国内首个大型绿色零碳数据中心
MEC打造金融行业智慧金库
MEC的双园区离散制造企业应用实践
MEC的规模应用引领家电产业链协同转型
MEC行业专网赋能新疆“丝路智港”全面升级
MEC赋能智慧校园
MEC赋能武汉市桥梁智慧管理
MEC边缘计算在唐山河钢乐钢的应用
NanoAR© ： 透明高清和AR显示的革命技术
OneBox 工业网关
OneLink 连接管理通用平台
OneMO工业互联网行业模组
OneNET城市物联网平台
OPPO柔性全连接智慧工厂
PCB智能工厂场景化解决方案
PLC边缘控制网关
R16的 LAN网关
Rokid 版AR眼镜
SUL和 NTN在海空通航运营的应用
TICloud全新技术，打造山东样板智慧化工园区
UIS不间断网关 助力人人享有连接
UPF+ 赋能新时代煤矿安全高效
V2X车规级模组
WEB3.0纺织产业互联网新模态
XR赋能南航智慧维修创新实践工程
X赋能三代核电规范建设与安全运营
ZTE XRExplore
“下井”，智慧煤矿“升级”
“功夫+智慧”开启少林
“北斗”智慧农业示范应用
“无人机”云网边端解决方案
“智能建造”虚拟仿真实训场景应用
“绿色智造，洁净生产”智慧钢铁创新港
“老师傅”重焕新活力-郑州瑞泰智慧工厂
“花园模式”创先锋 助推实施数字乡村战略
“虚拟与现实的融合”——在线教育元宇宙创新实践
“行业虚拟专网”实现宜宾三江新区车路协同智慧接驳、智慧物流示范应用
“让梦走得更远”—携手广汽本田共赴匠心智造新征程
ⁿ智慧塔吊引领山西建投绿色发展之路
《谍影成双》互动影游项目 序号 项目编号 项目名称
一体化移动智慧口腔医疗服务助力健康新农村
一体构架的专网创新实践
一汽-大众汽车生产能源与节能 左志军
一种基于的CPE+调度控制器产品在专线抢修及开通中的应用
一部手机趣旅行，信息助推全域旅游示范县乡村振兴(青川县4A级青溪古城提升项目)
一隅千象：元宇宙裸眼混合现实交互
万兆光网双核驱动煤矿安全生产
万华禾香板业智慧工厂
万物互联 智管全城—助力城市“一网统管”
三山岛金矿智慧矿山
专科联盟建设
东平县盛鑫铁矿智慧矿山
东源县 OnePARK   智慧园区
东莞市公安局“辅警通”智慧执法
东莞新沙港智慧港口
东风日产数字智能化设备生产系统
中交四航局首个全球智慧工地指挥调度平台
中原内配工厂数字化生产新基石
中原智行智行网联云控平台
中国电信固移融合网关
中国石油锦州石化公司智慧石化
中国移动专网运营平台
中国移动全国产化通用模组
中国移动医疗行业模组应用与解决方案
中国移动煤矿行业通信模组
中国移动物联卡风险防控平台
中国联通物联网智连连接管理平台
中国联通物联网格物设备管理平台
中国联通自主品牌终端 CPE VN007+
中国联通雁飞 CPE
中国联通雁飞工业CPE
中国联通雁飞智能网关助力油田数智化转型
中国银行股份有限公司消息
中天科技工业互联网能源管控示范基地
中广核大亚湾核电智慧核电创新应用
中广核智慧核电应用
中石化胜利油田智能油田联合创新应用
中药产业数字化转型升级
中骏世界城室分地下北斗定位
丰县师寨镇东渡希望初级中学桌面云
为乡村插上共富翅膀，促进产业振兴
乐活岛打造新型社交生态圈
乡镇“赤脚医生”的云巡诊包创新应用
云边协同下全生命周期的数智医疗应用
云边协同的多院区智慧PICU 一体化平台
云边协同的新一代智慧医院基础设施云平台
云边端的智慧娱乐
京东智慧物流园
人工智能在智慧物业服务运营场景的创新应用
仁和化工园“双碳”智慧园区，搭建“化学家创新创业平台”
以MEC+校园专网多云能力，打造山东“三个课堂”信息化改革创新示范
企业外网基础服务平台
伺服电机智能生产线
低空智联网及飞控平台
余东镇数字化智慧农场
佛山市乡村振兴示范
供水-助力百年水司出新出彩
便携式随行热点&MiFi终端
保险系统
信发集团构建产业融合创新实践
停车赋能上蔡县停车管理转型升级
健力宝“现场、现物、现实“管理和人工智能视觉质检建设
元宇宙才艺社交
元宇宙掌上一体机
元宇宙社交沉浸娱乐平台
光伏村
光威渔具工业互联网平台
克拉玛依百口泉智慧油田
兖州区社会治理大数据平台
党建引领基层治理网格化信息系统
全国蔬菜质量标准中心AI智慧农业示范
全流程数据采集的船舶工业智能平台
全面赋能智慧工地,为安全保驾护航
公交三维动态巡视系统
公共卫生防控
公共文化云,赋能乡村文化振兴
公证链执法仪
兰州石化榆林化工智慧化工
养殖助力阳澄湖大闸蟹标准化生产
农业产业园番茄种植
农业硅谷—浦口国家农创中心
农业种植助力乡村振兴
农产品全程可信溯源
凉山州青花椒现代农业园区
凉山精准养殖科研基地建设
出行新开始，MEC助力车路协同建设
分布式光伏大规模推进的应用实践
分布式光伏数字化升级
切片+TETRA融合实现关键通信高质量应用
切片技术的未来电力变革
切片的远程医疗技术
创新产品实践
利用技术打造国星光电新一代智能制造工厂
加油机税控 助力智慧税务建设
加速新郑煤电智慧化矿山发展
助力废钢智能判级技术演进
化工行业智慧化转型
化工行业生产更绿色、更安全、更高效
化零碎为统一 ——以物联优化能源管理
北京市属公园智慧游园新态势
北斗的“空天地”三位一体智慧林业管理示范应用
北斗的电力作业现场智能管控系统
北斗融合数字孪生赋能山东水利安澜
北斗高精度定位的农发集团无人农场
区块链一体机：让上链更简单，让信息更安全
区域“海陆空”一体化急诊急救平台
区域工业云推动区域经济结构调整
医学影像互认云服务平台
医护场景的实践
医疗急救新模式
医院应用
医院运营管理系统（HOMS）平台
千兆赋能大运河数字航道
千岛湖月光群岛“月光之恋”沉浸式农旅融合促共富
华侨城集团AI技术的多业态数据管理平台
华勤云化智慧能耗管理云平台
华北电力大学零碳校园智慧能源
华欣环保钢渣处理天车智能化
华能山东石岛湾核电“智慧电厂”
华腾未来数字牧场
华茂陶瓷智慧工厂
南方海洋科学与工程广东省实验室（珠海）移动网络建设
南方电网（汕头）配网自动化
南通海安凤山村新通扬河滨河风光带打造
博物馆，BIM加持启新篇
博鳌东屿岛车联网
卫棉集团智慧纺织工厂
印染行业智脑平台建设
县域自然资源防护平台
双千兆助力永联村“种好”乡村振兴“示范田”
双域专网的油气开采智慧测井
双碳形势下智慧能源助力盐化工产业园节能发展
双碳智慧公共建筑监管平台
台州市未来乡村建设
叶集智慧党校专网
合肥滨湖国际会展中心智慧工地
同一条河
唐山首钢京唐智慧钢铁
唐闸古镇乡村智慧文旅
嘉陵江亭子口水利枢纽智慧电站
四信F-SC241和F-NVR1105的视频监控系统
固移融合医疗专网
国内首个多式联运智慧港口
国家高原云果产业园智慧农业
国电联合动力双碳平台
国网新源控股集团山东沂蒙抽水蓄能发电站专网
国网电力 虚拟专网
国网电力分布式光伏云网新飞跃
国网电力鞍山公司菱镁工业互联网示范性
国网辽宁阜新“能源互联网小镇”示范
国能黄金埠智慧火力电厂
城建中的创新应用
培育AI互动空间
基因测序助力乡村健康
塔里木河河湖长制的探索与实践
多DNN技术的多通道接入 CPE产品
多功能智能杆构建深圳智慧城市“神经元大脑”
多氟多傲立氟化工国际舞台
多类型机器人联合巡检助力能源行业转型升级
大数据养虾管理平台
大数据分析赋能分布式光伏电站“智能云运维”
大数据打造更加精细智能化农业
大数据的智慧渔业水产种业研究
大时代来临，乡村焕然N新
大湾区智慧虚拟法庭和区块链物证系统建设
大禹“智”水-水务集团云网协同智慧“jie”水
大象智慧文旅，让文旅走进每一家
大足区国家数字乡村试点项目 15（并列）
天中高标准农田，农民挑上“金扁担”
奇瑞一路捷途
妇幼手拉手工作平台
媒制播
宁德时代灯塔工厂
宁津县天空地一体化乡村振兴建设
宁阳化工产业园有毒气体智能监控云平台
宇通智慧环卫 助力智慧城市建设
守护长三角“白菜心”智慧
安全专网的AI智能信息播报系统
安全生产，领航矿业新征程
安全认证的电力虚拟专网与智能电网全业务深度融合
完善农业物联网管理体系，提升农业专家服务
定制专网的河南中烟智能检测创新实践
实景化房屋质量风险评估
富士康——核心网下沉的“芯”工厂
富士康柔性“智”造释放生产力
屋顶智慧光伏
山东东营联通智慧城市建设
山东大学教育新基建助力构智慧教育新生态
山东工商学院绿色能源校园
山东正凯新材料园区 工业场景应用
山东港口集团日照港智慧港口园区
山东港口集团青岛港 LAN在多AGV调度等场景的应用
山东省临沂大学智慧校园
山东省京博控股集团定制网
山东胜利职业学院虚拟实训
山东西曼克技术有限公司智慧园区
山东首家 VR线上智慧法院
山东鲁西化工集团智慧炼化专网应用
山东龙口裕龙石化工业园智慧园区
山窝里下金蛋—基于的蛋鸭智慧养殖
山钢莱芜分公司智慧冶金
山钢集团板带厂1500mm宽带生产线智能无人库区
岸电清洁能源
峄城峨山智慧化工园区
工业智能终端MX880
工业机器控制
工业级室外CPE 赋能垂直行业
工业网关
工业自然导航AGV，赋能行业、协同高效
工业行业的通用DTU
工业路由器
工业路由器F-NR100
工地筑造新未来
常州市长江流域禁捕退捕信息化防控
平高电气依托网络打造虚拟电厂
广东海上风电创新
广东电网有限责任公司广州供电局基建工程通信技术研究及应用
广东省中建三局华南公司保利广钢新城智慧工地
广东省佛山市智能家居产业集群工业互联网示范
广东省西可通信工业互联网智能制造应用
广东移动海上宽带赋能智慧海洋
广东韶关钢铁电信定制网产品
广和通模组FM160的四信F-NR130全面赋能工业物联
广州市黄埔区基于的城市公共交通智慧云脑应用示范
广州方舱医院智慧防疫一体化
广汽丰田铸就全价值链数字化工厂
库卡机器人智能生产
应急互助信息服务
应急总医院基于专网的应急救治体系应用实例
应急通信指挥平台，应急救援新力量
应用的工业互联网标识解析二级节点
建筑质量安全管理系统
建设演示机智慧运营平台推进管理创新提质增效
徐州市农业农村局物联网智能化调度系统服务
德州大运河德城段文旅融合全域旅游
德州小森精工智能制造运营管理服务车间建设
德州市北斗+AICDE的国省道公路信息数字化孪生
德州移动远程医疗应用平台
心连心园区管理“智慧化”
思克奇食品科技（山东）有限公司智慧工厂
成就哈尔滨工程大学跨校区一体化智慧校园
成武县人民医院专网+医共体+医疗应用
扬帆“十大数智应用”，启航羊城智慧安全城市
扬帆十大数智应用，启航羊城智慧城市服务
技术实现预警防灾场景必达消息
技术的数字孪生交通仿真系统
拓普泰尔RG2000
改性塑料智能生产车间示范
政务随行专网的数字政府智慧应用
教培实验室赋能人才培养
数字一汽管理、生产全流程创新探索与实践
数字乡村，共展乡村美丽画卷
数字化连接工厂，助力企业数字化腾飞
数字孪生智慧矿山
数字孪生的盾构智慧园区
数字孪生的综合掘进机器人应用 -三等奖名单- （30个，排名不分先后） 项目编码 项目名称
数字律证保险箱
数字赋能 开启化工智慧巡检新时代
数字驾驶舱载着一方百姓驶向富裕
数字高速与济青中线高速全场景融合实践
数智双柏生态振兴
数智混动，筑造城管壁垒
数智赋能一池春水—泗阳县国家数字水产试点基地
数智转型新引擎
数智鸬鸟:创乡村振兴标杆示范
文旅开放平台，助力河南文旅高质量发展
文旅行业的三维数字展览应用实践
新乡移动鼎力智能管控升级改造
新农村综合服务平台
新型政务外网助力山东数字政府智能化发展
新型高标准农田助力农户“旱涝保收”
新旧动能转换
新材料产业园区发展
新能源新工厂，新新未来
新金融发展
施工远程协作监管助力建筑业复工复产
施耐德多园区协同专网应用
无人养殖场试点基地建设
无人农机在乡村振兴项目中的应用
无人机的输电线路点云数据实时处理
无人电机车把握山东能源临沂会宝岭铁矿智慧矿山新机缘
无人驾驶农机作业平台
无介质全息 虚拟与现实的交互
无锡市滨湖区农业大数据平台
日照汇丰电子有限公司机器视觉
日照港建设国际一流港口
时代 ，Rokid让美好生活更具“智”感
时尚女装“1天下货”生产模式
明珞数字制造与工业互联网全球总部项目-以工业互联网赋能汽车制造产业集群
智作系统开创融媒新未来
智影-云端智能视频创作平台
智慧医院，提升患者就诊体验
智慧生态环境监测应用
智慧高速建设管理平台应用
智绘乡村新画卷-实践“乡村振兴”新方案
智联高标准农田，“建管营一体化”打造数智化新粮仓
智能农业园区应用
智能化房屋安全综合管理平台
智能化，打造智慧教学新模式
智能客服
智能巡检机器人
智能巡检车赋能智慧工程巡检
智能智联  助力中国汽车零部件行业数字化转型
智能模组SRM815
智能矿山
智能计量仪表工业互联网平台赋能新天科技智能制造与服务新模式
智能车联网技术研究及科技冬奥创新应用示范
智能边缘计算产品
智造“伯乐慧眼”，助力消除城市“顽疾”
服务乡村振兴的现代农业虚拟仿真职业教育共享示范基地
服务机器人
未来创新实验室，科技为教育赋能
机器人楼宇服务专家
机器视觉产品外观缺陷检测应用
机器视觉技术在玉米油产业的应用
机场应用示范
机械加工转型升级
极氪汽车迈入未来工厂
构建“平台”乡村产品体系，打造乡村治理新模式
构建多维度疫情防控体系，筑牢公共卫生“力量大厦”基石
构建数智化建筑工地
构建的智慧供水运营管理系统
构筑食品安全防火墙 撑起健康生活保护伞
果园，助推乡村振兴高质量发展
枣庄市市中区水处理剂产业园有毒有害气体环境风险预警
枣庄市立医院专网+智慧云医院
枣庄科技职业学院基于双域专网的校园数据大脑融合创新应用
柑橘农业
校园安防
校园电视台打造智慧家校应用 三等奖获奖名单 （排名不分先后，以项目编号为序） 项目编号 项目名称
校园虚拟专网助力高校智慧教育新突破
校园虚拟专网的示范应用实践
格创智慧能源管理
森林河南生态文明建设
民航领域车路协同及自动驾驶试点示范
水利全感知赋能千秋古堰焕新机，助力都江堰灌区“四预”智慧管理新突破
水务低碳转型，实现成都天府新区下沉式水厂数智化、精细化管理升级
水泥
水质在线监测保护乡村绿水长流
汇丰石化智慧炼厂
汇川技术专网及工业互联网创新应用
汇川技术虚拟专网赋能智能智造
江苏三仓农业现代产业园智慧农业
江苏南沈灶智慧农业
江苏智慧高标准农田建设
江苏省溧水农白马镇农高区数字乡村区块链
江阴乡村教育全场景互动教学
汽车制造供应链创新融合应用
河南利源智慧工厂，树立焦化行业标杆
河南省域电力虚拟专网，构建“源网荷储”友好互动的新型电力系统
河南省生态环境无人机执法
河南航天室内外安全可信无人运输
河南警察学院VR省域互联训练系统
河钢唐钢专网应用建设
河长制平台打造秀美河湖，助力乡村振兴
油气装备行业新生
泛在物联的精细化医院管理
泛在高可靠 UIS CPE  倾“芯”赋能数智化
泛智能园区标准产品
泰兴市黄桥镇智慧农业产业园区建设
泰安中联水泥智慧矿山
泰安市中心医院专网智慧医院
泰安市智慧城市应急指挥平台
泰豪VR社交游戏平台 《34空间站》
洛宁县马店镇关庙村 “智慧果园”建设
洛阳智慧河湖
济南新航实验外国语学校智慧校园
济宁市新材料产业园区智慧园区
济宁市金桥煤矿智慧矿山
济宁能源发展集团专网赋能高质量能源集团
济宁能源发展集团智慧能源
济宁艾坦姆合金有限公司智慧工厂
浙里人家，诗画乡村，匠心塑造“诗画浙江大花园最美核心区
海上智慧数字油田建设
海上智慧油田升级
海上风电创新性应用
海上风电北斗一体化立体空间资源应用
海关监控指挥
海南昌江核电厂生产无线网络
海天产品全链条质量智控
海尔日日顺中德智慧园区
海岛双域乡村旅游
海洋渔业空天地海一体化网络信息服务
海虞优质稻米高质量发展示范区 二等奖获奖名单 名次 项目编号 项目名称
海陆油田全业务联合创新应用
消息在电力服务中的应用
消防应急智会系统云平台
润扬大桥智慧管理应用
淄博齐鲁石化智慧化工园区
深圳地铁数字化转型基于技术的探索与实践
深圳大学算力网络构建的国家级半导体材料虚拟仿真实验互动教学示范
深圳招商智慧园区建设与实践
深圳智慧城市新示范
深圳蓝谷“行业虚拟专网”在智慧海洋牧场领域的应用
混合专网及自组网基站的重特大及城市消防应急救援通信系统
渔政核查核录系统
渤海科技大学智慧校园
港口
湛江化工厂专网建设
源网荷储互动的虚拟电厂助力数据中心零碳经济运行
潍坊联通智慧农业产业园
激发数智转型新动能
炼钢系统
焦作市解放区智慧社区
燃气，数字赋能城市安全保障
燃气，数字赋能城市安全保障 注：入围项目将在决赛中角逐一二等奖 三等奖获奖名单 （30个，排名不分先后） 序号 项目编号 项目名称
燃电-赋能乌沙山电厂大型斗轮机双碳技改
物业技术赋能，推动社区治理数字化
物品标识、定位芯片、运营商大数据等能力的一体化助农综合解决方案
物联时代的大国重器
物联网数字底座
物联网的无人售卖现磨咖啡机器人
玉田海泰智慧工厂应用
珠海商业园区综合体智慧系统
珠海大型桥隧交通工程建设大数据保障指挥系统
琼中黎族苗族自治县“数字乡村”建设
生态环境溯源云平台
用算力换能力分身舱带你畅游朋友圈
电力供电应用解决方案
电力系统的省域专网及示范应用
电力能源应用解决方案
电力虚拟专网安全防护体系
电力行业的通用授时终端产品应用方案
电网差动保护应用
益海嘉里智慧工厂及数字化车间
直流微电网赋能打造杭州亚运全绿电零碳示范园区
省林业局广东省林业综合服务能力建设工程——林业物联网监测管理平台
睢宁县技防村(社区)提档升级二期
石化行业的OneCyber专网平台应用
石油大学智慧校园
矿山助力中原能矿迈入4.0时代
矿山变“金山”，巩固水泥现代化生产
硬切片助力大陈岛“零碳岛”建设
硬切片赋能双碳高弹性电网
碳路先锋，智云光伏赋能广西千亿钢铁行业可持续性发展
祁连山水泥数字化矿山智能管控
种植辅助+产销一体化管理打造春秋智慧葡萄园
科大讯飞新零售智能办公终端
科技动力火力全开秦皇岛京能热电智慧发电
科技抗疫智慧防线
移动机器人Oasis 600C-
空天地一体化指挥调度系统
端网协同认证与安全通道系统  护航车联网证书下载安全
管控煤炭安全生产
红旗渠智慧旅游
纺丝全流程柔性升级
经区智慧企业用电
维尚数字化工厂
绿色移动空间
绿色高效加持智慧神华，助力“能源老大”高质量发展
网易瑶台元宇宙会议系统
网络信号质量测试及上网应用方案
美丽乡村VR名片
美育协同创新基地建设
肇庆小鹏汽车智慧工厂
胜利油田智慧油井
能力魔方，规模化发展的新路径
能源云应用助力密云区打造绿色双碳城市
能源行业大数据集控管理
能源行业的工业CPE
能源边缘计算多站合一
腾讯云创
腾讯先锋云互动数字场景创新应用
自主创新的“边缘云网一体化”智慧化工园区
自动行驶及配矿行车应用推动有色金属冶炼行业转型升级
自动驾驶的智能出行系统
自动驾驶，智能配矿行车 ——直击行业痛点，引领转型升级
自动驾驶，让生活驶上“快车道”
航油加注作业智能化创新示范
艺术文化数字化升级
苏州农业职业技术学院远程教育助力乡村振兴
茶溪川插上乡村振兴的科技翅膀
菏泽市东明县智慧城市
菏泽市定陶区医药港管理服务中心智慧园区
虚拟专网+智慧城市
虚拟专网助力高校教育发展
融合通信在应急消防领域的应用
融媒体社交融合 赋能传统媒体行业数字化升级
行业专网的“智慧金农”乡村振兴金融科技赋能
行业专网赋能齐鲁化工园区实现数字化转型
行业虚拟专网的全连接工厂示范
行李智能输送系统，助力航港再升级
装配式建筑智能制造新基建研发创新产业园
西南民族大学校园能耗智慧治理
西门子赋能智慧能源
让煤黑子焕新颜
让电厂更“聪明”更“灵动”
课堂助力教育公平，促进乡村振兴
负压救护车更安全，移动核酸车更智能-
贵州省教育资源公共服务平台
赋予园区生命 创造尼龙城无限可能
赋能LNG“工业互联网+安全生产”
赋能“利通”智造，打造螺湾“流体之都”
赋能“地下蛟龙”，大国重器再遨游
赋能“阳光政府”，打造智慧政务新标杆
赋能三代核电的安全建设
赋能乡村智慧出行
赋能交通实现无人驾驶
赋能信钢 探索钢铁行业高能效新路径
赋能农业，构建现代农业产业园
赋能助力濮阳同力升级转型
赋能区域医疗远程诊疗体系
赋能博山“一区四园”绽放新活力
赋能城市水务高品质运营应用示范
赋能山东重工高端装备制造产业链数字化升级
赋能引领中国梦，乡村振兴呼唤燕归巢
赋能政务治理，渗透抗疫最后一公里
赋能数字延伸，助力临颍乡村振兴
赋能智慧园区“新生态”
赋能智慧工厂，助推“智改数转”
赋能智慧钢铁，带动广西千亿级钢铁产业腾飞
赋能江南农村商业银行多元化融合创新应用
赋能电力智能升级，助力构建新型电力系统
赋能矿企智慧化矿山建设
赋能美丽南屯，数字引领乡村振兴
赋能耐火砖，中国耐材绿色新名片
赋能自动驾驶商用化运营实践
赋能航油安全数字化应用
赋能英皇新娱乐，绽放粤港澳大湾区新魅力
赋能郑煤机，开创“智能超级装备”的新时代
赋能钢丝绳探伤，保驾护航“生命线”
赛事风向标
赛轮集团基于的智能制造智慧生产
超便携直播盒子
超便携高性能游牧专网产品
超小尺寸可编程可快速部署行业５G数据传输终端
超级QQ秀
超级SIM和国产密码技术构建安全可控政务外网
超级物联卡
超融合专网的教管评教育生态体系
超视界云化赋能工厂
超高层建筑智慧工地多场景应用
跨境报关货物智能查验系统
跨时空视频直播
践行双碳战略，专网结合智慧应用赋能园区节能降耗
车联网的 RSU路侧单元终端产品
轻量化移动热点&dongle终端
轻量级UPF助力行业数字化转型创新探索与规模实践
辰欣药业智慧工厂
边缘AI智能终端产品
边缘智脑终端
边缘计算的工业设备故障诊断与健康管理方案
边缘计算，智慧出行管控综合解决方案
边远山区全域专递课堂-古蔺共享课堂
达能开启智慧工厂新时代
运维的轨道交通关键技术创新研究
远程病理诊断与新冠筛查服务应用及赋能
连云港东旺奶牛养殖有限公司第三养殖场牧业养殖物联网
连云港市双碳绿色农业
连接“人机料法环”生产要素，全连接平台助力数字制造
连海平 应用共潮生
连海平 应用共潮生 二等奖获奖名单 序号 项目编号 项目名称
通信资源深度共享，推动智能电网建设 项目编号 项目名称
通则康威 工业路由器ZLT IR101
通用型 CPE产品应用方案
邳州市乡村振兴村级电商综合运营平台服务
郑州大学“新生态智慧校园”的探索与实践
郑州轨道交通高位智能视频监控系统服务
郑煤机智慧工厂-撑起智能制造的“钢铁脊梁”
配电站房智能辅助与人工智能可视化网关
重点人员管控
重症监护区域协同示范平台
重装生产解法，离散制造创新模式
量子通信视频会议在政务服务领域的应用
金华供销社智慧菜篮子项目 优秀奖获奖名单 （排名不分先后，以项目编号为序）
金石集团绿色矿业
金马智慧工厂打造数智化煤化工企业
钢厂智慧升级开启超低排放绿色时代
钢构行业“智造”引擎
钢研纳克（苏州）全连接工厂
钢铁应用
钢铁行业的应用
银行网点转型升级
锡山区数字化综合运营服务平台
镇江市丹徒区宝偃村智慧乡村
长城汽车日照魏牌打造智能工厂
防爆AR全景智能摄像机
防爆虚拟专网 提升化工运维质效
雄安新区天地一体化生态环境智慧监测体系
雄安新区生态环境多维监测
集成信息平台的全病程管理创新示范
集群化智能管理 烟草生产线跨越式升级
青岛中加特全流程数字化创新智能制造之路
青岛亚洲杯智慧场馆建设
青岛地铁全面自主革新的新一代调度及列控应用示范
青岛大学附属医院远程手术+智慧后勤
青岛胶州市农村污水管理平台
青海省“青智119”智慧消防平台建设
青海省数字乡村试点支撑
首个火电风筝专网：潮涌东海两岸阔、能源航母焕新生
首创上船——开创邮轮旅游
高可靠高安全专网下铁路行业新应用
高算力智能模组-SRM900
高速公路气象监测预警系统
高速荣乌新线示范应用建设
高铁核心区新型电力系统示范区全域感知互动数字配电网示范工程
魅力乡村—特色田园乡村解决方案
鹤壁汽车电子产业转型升级
黄山市徽州区西溪南镇坑上智慧茶园
黄河流域生态保护智慧生态
黑龙江哈电集团MPM焊缝纠偏
黑龙江哈电集团实训基地
鼎桥 CPE Max
鼎桥模组 MH5000-82
齐鲁生态茶园

</pre>
</div>
<pre>
<br>
<br>
<h2>5 Tools to Manage Multiple Network Connection Profiles</h2>
Every home or work network you connect to can conceivably have different settings for the connection. 
At home you might <a href="https://www.raymond.cc/blog/how-do-i-know-if-someone-is-using-my-wireless-network-wifi/">use a WiFi connection</a> with default or automatic settings, for work you might have a manually set IP address and gateway or <a href="https://www.raymond.cc/blog/test-change-dns-servers-quickly-dns-jumper/">custom DNS servers</a>. 
Each different network configuration you come across requires the settings in Windows to be adjusted to match. 
While this isn&#8217;t a major problem because Windows allows you to change these types of settings, it isn&#8217;t the quickest thing to get at and change regularly.
Manual reconfiguration each time through <a href="https://www.raymond.cc/blog/repair-xp-and-vista-internet-connection-problems-with-icr/">Windows Network Connections</a> is both time consuming and inefficient. 
It requires you to remember each individual setting or the network might not connect properly. 
An easy solution is being able to create different network profiles for different scenarios, so you can save <a href="https://www.raymond.cc/blog/6-free-websites-to-map-ip-addresses-to-geographical-locations/">IP address</a>, DNS, default gateway and other settings for each network connection you encounter. 
When you need to change to a different network, a different profile can easily be applied which changes all the required settings automatically.
Here are 5 free tools for you to create and apply network profiles.

<h3>1. TCP/IP Manager</h3>
TCP/IP Manager has a good mix of the ability to easily save network settings into a series of profiles and enough features and functions to cater for most users. 
The program is open source and available in both setup installer and portable versions. 
Make sure to get the correct 32-bit or 64-bit version for your system.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/tcpip_manager.png">

After launching the program click Create a new profile and give it a name. 
Choose a network adapter from the drop down and configure the IP address, subnet, gateway and DNS servers. 
Automatic options are also available like in Windows. 
Optionally go to the Profile settings tab and choose to show the profile in the tray menu and give it a keyboard shortcut so you can launch the profile by a key combination. 
Finally click Save current profile. 
When you want to launch a profile click Apply in the window, press the hotkey combination or select from the tray icon context menu.
Proxy servers can be configured from the corresponding tab, advanced settings include changing the computer name, changing the workgroup name and possibly a unique feature of allowing MAC spoofing on the network adapter. 
TCP/IP Manager was quite reasonable on memory usage consuming around 4MB while sitting in the tray.
<a href="https://www.raymond.cc/blog/download/did/2089/" rel="nofollow">Download TCP/IP Manager</a>

<h3>2. IP Shifter</h3>
If you just want a nice and simple network connection changer, IP Shifter is relatively easy to use and doesn&#8217;t require tons of knowledge to configure. 
It also has a portable version so installation isn&#8217;t necessary either.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/ip_shifter.png">

Start the program, click the button to create a new profile and give it a name. 
The standard options allow you to select the network adapter from the drop down and then obtain an automatic or manual IP address and DNS server. 
This window is similar to the Windows Internet Protocol 4 Properties dialog and has boxes for IP address, subnet mask, gateway and DNS servers. 
Proxies for Internet Explorer and Firefox can be setup by clicking on Settings and the check box near the bottom.
Once all the profiles are setup you can switch between them by selecting and clicking Apply in the main window or minimize the program to the tray and right click on the tray icon. 
IP Shifter used around 3MB of memory while in the tray. 
A couple of useful extras are in the Tools menu to Ping an address, scan the LAN for computers and obtain your public IP address.
<a href="https://www.raymond.cc/blog/download/did/3631/" rel="nofollow">Download IP Shifter</a>

<h3>3. NetSetMan</h3>
In contrast to IP Shifter, NetSetMan is loaded with tons of options and may be a bit too much for the average user. 
For geeks and advanced users though, it&#8217;s one of the most feature rich network profiling tools around. 
Only a setup installer is available but it can create a portable version because the program can be extracted to the folder of your choice.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/netsetman.png">

Most of the settings can be left alone if you only want a simple IP and DNS changer. 
Choose a renamable SET tab to edit the profile and enter enter the IP, gateway and DNS information or leave what you don&#8217;t need on automatic. 
Use the Activate button or the tray context menu to choose between them. 
The IP+ button takes you to an advanced settings window where extra functions such as routing tables, DNS suffixes and expert settings like running Windows ipconfig commands are available.
Other more advanced networking options like a built in WiFi connection manager, computer name and workgroup changer, create network drives, append to the HOSTS file and a dedicated IPv6 settings window could all prove useful. 
Other options like changing the default printer, changing dozens of system settings or running a script/program are nice additions but not strictly necessary. 
NetSetMan uses around 8MB of memory in the background. 
The free personal use only version cannot change proxies, browser home pages and network domains.
<a href="https://www.raymond.cc/blog/download/did/3632/" rel="nofollow">Download NetSetMan</a>

<h3>4. Net Profiles Mod</h3>
This is a modified and forked version of the discontinued Net Profiles tool which has not been updated since 2011. 
Luckily this open source modded version is still in active development so there&#8217;s a fair chance bugs and issues will be fixed in future.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/net_profiles_mod.png">

Setting up a new profile is easy and for basic usage you only have to give it a name, select a network (if there are multiple) and enter the IP and DNS details manually if required. 
Use the Get Current Settings button to create a profile of your current network configuration. 
Additional options include proxies, default browser homepage, mapped drives, default printer, running an application, desktop resolution/wallpaper and connection to a specific SSID. 
File &gt; Create Desktop Shortcut allows launching a profile via shortcut without having the program running in the background.
There are a couple of issues we had with Net Profiles Mod. 
Firstly, our WiFi adapter was not recognized unless it was connected to a wireless network. 
Secondly, you cannot obtain an IP address automatically through DHCP and set the DNS servers manually, or vice versa. 
This is easily possible through Windows and a drawback if you want to change the DNS but leave the IP alone.
<a href="https://www.raymond.cc/blog/download/did/3633/" rel="nofollow">Download Net Profiles Mod</a>

<h3>5. Argon Network Switcher</h3>
Argon Network Switcher is a middle of the road type of tool in terms of features. 
It has enough to satisfy all but the most advanced users but not too many to confuse people.
<img src="https://img.raymond.cc/blog/wp-content/uploads/2012/05/argon_network_switcher.png">

Usage is similar to the other tools here. 
Click New to create a new profile, enter a name, select the network adapter and then enter the IP, subnet, gateway and DNS addresses. 
Click Save to add the profile. 
Additional options include assigning a specific WiFi SSID, proxy settings, map a drive, set the default printer, start and stop system services, run scripts and applications and also disabling a specific network adapter on running the profile. 
An interesting feature is Autorun which leaves it up to the program to determine the best profile to launch.
We did notice a couple of bugs during usage. 
One was the WiFi SSID profiles are not displayed for everyone so you can&#8217;t associate a wireless SSID with the network profile. 
Another was using the Test button in the Drive Map tab freezes the program. 
However, mounting and unmounting networked drives does work fine. 
Network Switcher consumes about 10-15MB of RAM when minimized to the tray.
<a href="https://www.raymond.cc/blog/download/did/3634/" rel="nofollow">Download Argon Network Switcher</a>
<em>Final Note: </em>We did also look at a few other network connection profiling tools, one we almost included was <a href="https://www.raymond.cc/blog/download/did/3635/" rel="nofollow">Eusing Free IP Switcher</a>. 
This tool is like an easier to use version of NetSetMan but a major issue is a donate popup nag every time the program launches. 
This is a shame as it has a good blend of ease of use and features to make it useful.

<h2>开源的社区网盘</h2>
在gitee上发现了开源的 KodExplorer 可道云（https://gitee.com/kalcaddle/KODExplorer），发现非常适合作为小型文件共享，也很适合作为社区网盘。

它不需要安装任何程序或者插件，也不需要特殊的软件或者权限，只要有一个浏览器（主流的网络浏览器都可以，推荐chrome或firefox），就可以在线查看pdf、图片，编辑文件，共享文件等，使用方式和windows的文件管理器类似，无需学习就可以掌握。

https://www.micropython.org.cn/pan


<h2>Find the IP address</h2>
Windows
Type in “ipconfig” and hit Enter.
Look for the line that reads “IPv4 Address.”

192.168.0.100

Find the IP address of an iPad or Android Tablet

Go to setting on your iPad
Select ” WiFi ” from the sidebar.
Tap on the arrow next to the network name.
Your IP address will be displayed to the right of "IP address"

<h2>Accessing WAMP From Computers on Your LAN</h2>
<a href="https://john-dugan.com/access-wamp-from-lan-computers/" class="whitebut ">Accessing WAMP From Computers on Your LAN</a>

<a href="https://stackoverflow.com/questions/24005828/how-to-enable-local-network-users-to-access-my-wamp-sites" class="whitebut ">enable local network users to access my WAMP sites</a>

<a href="https://stackoverflow.com/questions/36810669/why-wamp-server-put-online-offline-option-is-missing/36825283" class="whitebut ">wamp server put online/ offline</a>

Right click Wampmanager -> WAMPSetting -> Menu Item: Online/Offline

If you click it so there is a Tick beside it, you will see the Online/Offline menu on the left click menu.

However it was made optional as its use is defunct.

You should create Virtual Hosts for each of your projects, then you can amend each of those individually to control the Apache access rules.

In fact in WAMPServer 3 or greater, there is a Virtual Host defined for localhost so this old Online/Offline process wont actually do what you want.

You now have to go to the wamp\bin\apache\apache{version}\conf\extra\httpd-vhosts.conf file and manually amend that entry

&lt;VirtualHost *:80>
    ServerName localhost
    DocumentRoot D:/wamp/www
    &lt;Directory  "D:/wamp/www/">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require all granted                  #&lt;-- changed line
    &lt;/Directory>
&lt;/VirtualHost>

This file can be edited using the wampmanager menus like this
wampmanager -> Apache -> httpd-vhosts.conf

However it is not recommended to allow this sort of access to localhost. It is better to create a Virtual Hosts for each of your projects eg

&lt;VirtualHost *:80>
    ServerName localhost
    DocumentRoot D:/wamp/www
    &lt;Directory  "D:/wamp/www/">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require local
    &lt;/Directory>
&lt;/VirtualHost>

&lt;VirtualHost *:80>
    ServerName project1.dev
    DocumentRoot D:/wamp/www/project1
    &lt;Directory  "D:/wamp/www/project1">
        Options Indexes FollowSymLinks MultiViews
        AllowOverride All
        Require all granted
    &lt;/Directory>
&lt;/VirtualHost>

<h2>Setup a Virtual Host</h2>
<a href="https://john-dugan.com/wamp-vhost-setup/" class="whitebut ">Setup a Virtual Host on WAMP in 3 Steps</a>
<a href="https://www.techrepublic.com/blog/smb-technologist/create-virtual-hosts-in-a-wamp-server/" class="whitebut ">Create virtual hosts in a WAMP server</a>

<a href="http://forum.wampserver.com/read.php?2,146746" class="whitebut ">WAMPServer 3 Create a Virtual Host, the easy way</a>

<h2>Sci-Hub 用上了分布式网络</h2>
在网站域名屡次被撤销之后， Sci-Hub 创始人 Alexandra Elbakyan 在分布式域名网络 Handshake 上注册了新的网站。

现在，每个用户都可以直接通过服务门户和 NextDNS 直接访问 Sci-Hub。

<img class="lazy" data-src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9mkBqdBCp94269UtFWSXwVKf5bzAj8gh8YzGa7V5KvCricAp7ViaI0O9qrEv3Q8s5YrVOHiafdAdHKQ/640">

NextDNS：https://learn.namebase.io/starting-from-zero/how-to-access-handshake-sites#level-3-dns
HNS 网关 http://sci-hub.hns.hns.to/
这些年来，一直是 Alexandra Elbakyan 在维护 Sci-Hub，目前所有用户只能通过俄罗斯的 Yandex 和比特币赞助网站的运营。

此前，Sci-Hub 被多次撤销域名，推特账户又被封禁且无法申诉，传统域名系统显然不那么满足这个「盗版学术论文数据库」的需求，能够对抗审查的 DNS 成为 Sci-Hub 保持可访问状态的方法之一。
Handshake 工作原理Tieshun Roquerre 介绍说，Handshake 实际上是一个分布式的域名服务器。
它不使用 web 标准证书颁发机构来验证用户与服务器的连接，而是存储对在其系统中注册的网站的 IP 地址的引用。
这样一来，如果证书颁发机构公司试图通过旧版系统审查 Sci-Hub 的域名，那么想要访问网站的人仍然可以通过 Handshake 的记录访问。
Namebase 则是为用户提供访问 Handshake 网络的平台，这个名字对于国内开发者来说不算陌生。

去年，关于「Namebase 羊毛现金福利」的消息一度引起热议，「满足条件的 GitHub 开发者可以获得大约 4200 个 HNS 代币的奖励」，折合人民币 5000 元左右，还有成功领取者写出了「从天上接馅饼」的教程。
Namebase CEO Tieshun Roquerre 介绍说：「DNS 就像互联网的电话簿，电话簿中的地址是服务器 IP 地址。
DNS 的创建是为了给 IP 地址提供人类可读的名称，因此在这一平台上，用户可以通过 Handshake 找到 IP 地址，而不是通过证书颁发机构。
」Roquerre 提到：「如果你的服务器级别受到限制，则可以切换服务器。
但如果你的域名被删除，就没人能访问你的网站了。

只要名称完好无损，就可以将其指向任何服务器。
」即使 band 网站找到了一个新域名，但用户也不确定其真实性（例如 Sci-Hub 也经常被冒名顶替）。
要注册一个 Handshake 域名，任何人都可以提出一个网站名称，并在 Handshake 的市场上用其同名 HNS token 对该网站进行竞标。
据外媒 CoinDesk 统计，目前共有 6818 个 Handshake 域名处于活跃使用状态，已注册的域名达到了 375000 个。
数据显示，其市场交易量每月平均增长 60%，近期将突破 14 万美元。
像 Handshake 这样的分布式（decentralized）域名系统，可能会成为分布式网络的标志性胜利。
该项目是众多所谓「Web 3.0」应用程序的一部分，当然，「Web 3.0」这个概念还存在很多争议，比如创建某些未经审查的互联网搜索，是否会带来更多的隐患？正如 Sci-Hub 的经历所证明的问题一样，分布式的网络是出于去平台化的担忧而构建的。
随着互联网访问接入点越来越集中在「少数玩家」的手上，最近也有一些应用受到了 Web 服务器提供、应用商店和 DNS 证书颁发机构的审查。
参考链接：https://www.nasdaq.com/articles/pirated-academic-database-sci-hub-is-now-on-the-uncensorable-web-2021-01-11https://www.coindesk.com/pirated-academic-sci-hub-handshake

<h2>create simple file server</h2>
C:\Windows\System32
run ipconfig to find ip address

<a href="https://stackoverflow.com/questions/15328623/simple-file-server-to-serve-current-directory" class="whitebut ">Simple file server to serve current directory</a>

python -m SimpleHTTPServer 8000
will serve the contents of the current working directory over HTTP on port 8000.

If you use Python 3, you should instead write
python -m http.server 8000

acer:
http://192.168.128.93:8000/

For Node, there's http-server:
$ npm install -g http-server
$ http-server Downloads -a localhost -p 8080
Starting up http-server, serving Downloads on port: 8080
Hit CTRL-C to stop the server

<h2>enable FTP through Chrome on all Windows devices</h2>

In Chrome 81, FTP support is disabled by default, but you can enable it using the # enable-ftp flag.

Open Chrome and type “chrome://flags” in the address bar.
Once in the flags area, type “enable-ftp” in the search bar stating “search flags”.
When you see the “Enable support for FTP URLs” option tap where it says “Default”.
Tap “Enable” option.
Hit “Relaunch Now” option at the bottom of the page.


<b>To transfer files via FTP using your web browser:</b>

From the File menu, choose Open Location....
In the "Location" field, type a URL like the following:
  ftp://username@name-of-server
For example, if your username is dvader, and you want to reach your account on deathstar.empire.gov, enter:

  ftp://dvader@deathstar.empire.gov
Note: Do not close the URL with a /, or you will connect to the root directory rather than your home directory.

You will be prompted for your password.
After you supply the password, you will see the contents of your home directory on the remote machine.
To change directories, click the appropriate yellow folder icon.
To download a file, drag the file from the browser window to the desktop.
You can also double-click the filename, and you will be prompted to either save or open the file.
To upload a file, drag the file from your hard drive to the browser window.


<h2>Net Command Syntax</h2>
The command takes the following general form:
net [accounts | computer | config | continue | file | group | help | helpmsg | localgroup | name | pause | print | send | session | share | start | statistics | stop | time | use | user | view]
Net Command Options
<table>
<tr><td><b>Option</b></td><td><b>Explanation</b></td></tr>
<tr><td><b>net</b></td><td>Execute the net command alone to show information about how to use the command which, in this case, is simply a list of the net subset commands.</td></tr>
<tr><td><b>accounts</b></td><td>The net accounts command is used to set password and logon requirements for users. For example, the net accounts command can be used to set the minimum number of characters that users can set their password to. Also supported is password expiration, minimum number of days before a user can change their password again, and the unique password count before the user can use the same old password.</td></tr>
<tr><td><b>computer</b></td><td>The net computer command is used to add or remove a computer from a domain.</td></tr>
<tr><td><b>config</b></td><td>Use the net config command to show information about the configuration of the<em>Server</em> or<em>Workstation</em> service.</td></tr>
<tr><td><b>continue</b></td><td>The net continue command is used to restart a service that was put on hold by the net pause command.</td></tr>
<tr><td><b>file</b></td><td>Net file is used to show a list of open files on a server. The command can also be used to close a shared file and remove a file lock.</td></tr>
<tr><td><b>group</b></td><td>The net group command is used to add, delete, and manage global groups on servers.</td></tr>
<tr><td><b>localgroup</b></td><td>The net localgroup command is used to add, delete, and manage local groups on computers.</td></tr>
<tr><td><b>name</b></td><td>Net name is used to add or delete a messaging alias at a computer. The net name command was removed in conjunction with the removal of net send beginning in Windows Vista. See the net send command for more information.</td></tr>
<tr><td><b>pause</b></td><td>The net pause command puts on hold a Windows resource or service.</td></tr>
<tr><td><b>print</b></td><td>Net print is used to display and manage network print jobs. The net print command was removed beginning in Windows 7. According to Microsoft, the tasks performed with net print can be performed in Windows 10, Windows 8, and Windows 7 using the<em>prnjobs.vbs</em> and other cscript commands, Windows PowerShell cmdlets, or Windows Management Instrumentation (WMI).</td></tr>
<tr><td><b>send</b></td><td>
<a href="https://www.lifewire.com/net-send-2618095" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">Net send</a> is used to send messages to other users, computers, or net name created messaging aliases. The net send command is not available in Windows 10, Windows 8, Windows 7, or Windows Vista but the
<a href="https://www.lifewire.com/msg-command-2618093" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="2">msg command</a> accomplishes the same thing.</td></tr>
<tr><td><b>session</b></td><td>The net session command is used to list or disconnect sessions between the computer and others on the network.</td></tr>
<tr><td><b>share</b></td><td>The net share command is used to create, remove, and otherwise manage shared resources on the computer.</td></tr>
<tr><td><b>start</b></td><td>The net start command is used to start a network service or list running network services.</td></tr>
<tr><td><b>statistics</b></td><td>Use the net statistics command to show the network statistics log for the<em>Server</em> or<em>Workstation</em> service.</td></tr>
<tr><td><b>stop</b></td><td>The net stop command is used to stop a network service.</td></tr>
<tr><td><b>time</b></td><td>Net time can be used to display the current time and date of another computer on the network.</td></tr>
<tr><td><b>use</b></td><td>The<a href="https://www.lifewire.com/net-use-command-2618096" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">net use command</a> is used to display information about shared resources on the network that you're currently connected to, as well as connect to new resources and disconnect from connected ones.
In other words, the net use command can be used to show the shared drives you've mapped to as well as allow you to manage those mapped drives.</td></tr>
<tr><td><b>user</b></td><td>The<a href="https://www.lifewire.com/net-user-command-2618097" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">net user command</a> is used to add, delete, and otherwise manage the users on a computer.</td></tr>
<tr><td><b>view</b></td><td>Net view is used to show a list of computers and network devices on the network.</td></tr>
<tr><td><b>helpmsg</b></td><td>The net helpmsg is used to display more information about the numerical network messages you might receive when using net commands. For example, when executing
<b>net group</b> on a standard Windows workstation, you'll receive a
<em>3515</em> help message. To decode this message, type
<b>net helpmsg 3515</b> which displays
<em>"This command can be used only on a Windows Domain Controller."</em> on screen.</td></tr>
<tr><td><b>/?</b></td><td>Use the
<a href="https://www.lifewire.com/help-switch-2625896" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">help switch</a> with the net command to show detailed help about the command's several options.</td></tr>
</tbody>
</table>
Save to a file whatever a <strong>net </strong>command shows on screen using a <a href="https://www.lifewire.com/redirection-operator-2625979" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">redirection operator</a> with the command. Learn&nbsp;<a href="https://www.lifewire.com/how-to-redirect-command-output-to-a-file-2618084" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="2">how to redirect command output to a file</a> or see&nbsp;our list of&nbsp;<a href="https://www.lifewire.com/command-prompt-tricks-and-hacks-2618104" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="3">command prompt tricks</a>&nbsp;for more tips.
Only in Windows NT and Windows 2000 was there a difference in the <strong>net </strong>command and the <strong>net1</strong> command. The net1 command was made available in these two operating systems as a temporary fix for a Y2K problem that affected the <strong>net </strong>command.
<h2>  Net Command Examples  </h2>
net view
This is one of the simplest net commands that lists all the networked devices.
net share Downloads=Z:\Downloads&nbsp;/GRANT:everyone,FULL
In the above example, I'm sharing the&nbsp;<em>Z:\Downloads</em>&nbsp;folder with&nbsp;everyone&nbsp;on the network and giving all of them&nbsp;full&nbsp;read/write access. You could modify this one by replacing&nbsp;<em>FULL</em>&nbsp;with&nbsp;<em>READ</em>&nbsp;or&nbsp;<em>CHANGE</em>&nbsp;for those rights only, as well as replace&nbsp;<em>everyone</em>&nbsp;with a specific username to give share access to just that one user account.
net accounts /MAXPWAGE:180
This example of the net accounts command forces a user's password to expire after 180 days. This number can be anywhere from&nbsp;<em>1</em>&nbsp;to&nbsp;<em>49,710</em>, or <em>UNLIMITED</em>&nbsp;can be used so that the password never expires. Default is 90 days.
net stop&nbsp;"print spooler"
The above net command example is how you'd stop the Print Spooler service from the command line.&nbsp;Services can also be started, stopped, and restarted via the Services graphical tool in Windows (services.msc), but using the net stop command lets you control them from places like Command Prompt and <a href="https://www.lifewire.com/bat-file-2619796" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">BAT&nbsp;files</a>.

net start
Executing the net start command without any options following it (e.g. net start "print spooler")&nbsp;is useful if you want to see a list of currently running services. This list can be helpful when managing services because you don't have to leave the command line to see which services are running.

<h2>send a pop up message to another computer</h2>
<h3>Send a Message to Another PC on a Local Network</h3>
run cmd
type <b>Net send</b> followed by the name of the computer to which you wish to send the message. Next, enter the message.

msg /SERVER:DestinationPC * /TIME:60 “This is the message to be sent to a PC named DestinationPC and closes in 60 seconds."

You will need to replace DestinationPC with the name of the desired PC (you can find this in the list of computers that are currently sharing your network, if you don't already know the PC name).
Now, replace the value for TIME with how long you want the message to appear on the other screen for. For example TIME:30 for 30seconds
Then replace the text between the quotation marks with the message that you want to send.
Finally, you can hit enter, and the message will be sent.

<h3>to list all computers in a windows wi-fi network</h3>
run cmd
<b>net view</b> will probably show most of them.

Ping the server if you know or your gateway.
Type the command <b>arp -a</b>
It will usually list down all the IP's and Computers with their Mac Addresses.

If you want to use a GUI tool. I recommend <b>IPScan</b>.
Although it is a light application (433KB), it is freeware that's always worked for me.
You can also use another GUI Tool, Advance IP Scanner.

<h3>how do I send a pop up message</h3>
To send a popup message:
Select one or more users from the user list.
Issue the Send popup message command by right-clicking on any selected user and selecting the 'Popup Message' menu item.

The 'Send popup message' window will appear.
Enter message text and click on the 'Send' button.

<h3>can I send a message to an IP address? </h3>
The IP Message no longer works.
The idea behind it is that you type a message and sort of password protect using some IP address.
Only the person with that IP address will be able to see the message.

Likewise, people ask, how can I see messages from another computer using CMD?
Start command prompt
Type the command as follows:
Hit enter and voila, the message is sent.
How can I communicate with another computer on the same network?

Method 1 Sharing Internet from Windows

Connect the two computers with an Ethernet cable.
Open Start.
Open Control Panel.
Click Network and Internet.
Click Network and Sharing Center.
Click Change adapter settings.
Select both the Wi-Fi connection and the Ethernet connection.
Right-click the Wi-Fi connection.

Alternatives for Older Versions of Windows
Alternative 1
Here is the first alternative way of sending messages that may work if you have an older version of Windows. Here's how:

Click Start > Run.
Type cmd, and press Enter.
In the window that opens, type Net send followed by the name of the computer to which you wish to send the message.
Next, enter the message. For example, the format should resemble "Net send PC01 can you read this message?"
Alternative 2
It is easy to send messages through cmd prompt to other systems here is the answer first we have to set our systems messenger ACTIVE. For it, follow these steps:

1. Go to RUN
2. Type services.msc
3. Scroll down and right click on MESSENGER
4. Select PROPERTIES
5. Then for enabling it go to STARTUP TYPE and select AUTOMATIC
6. Then OK
And this should be performed on both sides (SENDER & RECEIVER). After that if you want to send message then do the following steps:

1. Go to cmd prompt
2. Type syntax as follows: net send <ipaddress of reciever> <message to be send>
Ex:

net send 172.16.6.99 "hello"

<h2>FileZilla</h2>
<a href="https://filezilla-project.org/download.php?show_all=1" class="whitebut ">downoad filezilla client</a>

<a href="https://filezilla-project.org/download.php?type=server" class="whitebut ">Download FileZilla Server for Windows</a>
<a href="https://dl4.cdn.filezilla-project.org/server/FileZilla_Server-0_9_60_2.exe?h=Q49drOcs8bOUZF_nd8ry1A&x=1626777411" class="whitebut ">FileZilla Server file</a>

<h2>Turn Wi-Fi Router USB Port into a NAS Server</h2>
<div id="routertoc">0 <a href="#routertopic-0" target="_self">Turn Wi-Fi Router USB Port into a NAS Server</a><br>1 <a href="#routertopic-1" target="_self">What's the use of a Wi-Fi router USB port?</a><br>2 <a href="#routertopic-2" target="_self">Host that (old) printer</a><br>3 <a href="#routertopic-3" target="_self">Cellular connection</a><br>4 <a href="#routertopic-4" target="_self">Network-attached storage (NAS) server</a><br>5 <a href="#routertopic-5" target="_self">How to best turn a Wi-Fi router USB port into a NAS server</a><br>6 <a href="#routertopic-6" target="_self">Get expectations straight</a><br>7 <a href="#routertopic-7" target="_self">Get a good external drive</a><br>8 <a href="#routertopic-8" target="_self">Get the right router</a><br>9 <a href="#routertopic-9" target="_self">Use the correct settings</a><br>10 <a href="#routertopic-10" target="_self">How to access your router-based NAS server</a><br>11 <a href="#routertopic-11" target="_self">Accessing your NAS server on a Windows computer</a><br>12 <a href="#routertopic-12" target="_self">Accessing your NAS server on a Mac</a><br>13 <a href="#routertopic-13" target="_self">Best USB-enabled routers that can work as a NAS server</a><br></div></center>

When it comes to network storage, I'd recommend a <a href="https://dongknows.com/dong-ngos-most-important-gadget-is-a-synology-nas-server/#Whats_a_NAS_server" target="_blank">NAS server</a>. 
But a good server can be expensive; plus, not everyone wants or has time to configure all the features. 
So the second-best option is to make use of what you likely already have: the Wi-Fi router USB port.

Indeed, there are many routers on the market that can simultaneously deliver both Wi-Fi <em>and</em> storage space for your entire home. 
Specifically, they allow you to share files stored on an external drive with the rest of the network.
This post, among other things, talks about the storage-related use of a USB-ready Wi-Fi router. 
You'll also find the link to my list of recommended routers and tips on how to best set up one as a NAS server.

<img class="lazy loaded" data-src="https://dongknows.com/wp-content/uploads/2020/12/Asus-RT-AX89X-USB-768x1024.jpg" src="https://dongknows.com/wp-content/uploads/2020/12/Asus-RT-AX89X-USB-768x1024.jpg" data-was-processed="true">
Router USB port: These little ports can bring about extra values.

<h3>What's the use of a Wi-Fi router USB port?</h3>
Not every Wi-Fi router has a USB port, but if yours happens to have one, chances are you can use it for (at least one of) the followings:
<h3>Host that (old) printer</h3>

Print serving is the original function of a router USB port. 
Connect a USB printer to this port, and it's now available to the entire network. 
There's no need to buy a printer for each person anymore.
Five or six years ago, this feature was a big deal since printers at the time were mostly USB-only. 

Nowadays, those with a built-in network port or Wi-Fi are commonplace. 
With that, some new Wi-Fi routers don't offer the print serving feature anymore, though many still do.
<h3>Cellular connection</h3>
This feature allows the router to host a cellular USB modem and share the mobile Internet to the entire network. 

A cellular connection is a great way to have a backup Internet when your broadband service, like DSL or cable, is down.
Note that a router with this feature only supports specific cellular modems. 
Make sure you check the manual to know which one to get.
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/08/Wi-Fi-Router-USB-NAS.jpg">

Picking the right external storage device is the first step to turn a Wi-Fi router USB port into a mini NAS server.
<h3>Network-attached storage (NAS) server</h3>
This feature is, by far, the most common and useful. 
Similar to the case of printing, plugging an external hard drive into the router USB port can also make its storage available to the entire network.

On top of that, you can use that public storage space for other applications, such as a backup destination (including Time Machine backup, in some cases,) PC-less downloading, or even a personal cloud.<a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/">See also How to Turn your USB-enabled Wi-Fi Router into a Time Capsule</a>
<h3>How to best turn a Wi-Fi router USB port into a NAS server</h3>
There are a couple of things to keep in mind about using a router as a NAS server.
<h3>Get expectations straight</h3>

The first and most important thing to remember is a router's primary function is to host your network. 
For this reason, even a high-end router tends to have limited processing power for non-networking tasks. 
<h4>It's a router you're using!</h4>
Naturally, a router is not as capable as a dedicated NAS server when hosting storage space. 

Also, just because the router USB port or ports support a few functions -- like NAS, printing, or cellular modem, and so on -- doesn't mean you should expect to use <em>all of them at the same time</em>, nor should you expect the top performance of each when you use them all together. 
(For the same reason, you can't, either, expect to have the same storage performance via Wi-Fi as via a wired connection. 
In the former, the router has to use its power to broadcast the Wi-Fi signals at the same time.)
By the way, if a router has multiple USB ports, chances are they all share a single USB hub. 

So, you can't use more than one bus-powered devices with it, and each port only has its share of the hub's total bandwidth.
Again, it's a router you're looking at. 
Just because there are ports doesn't mean you can use them all at your expected performance.
<h4>Security</h4>

Security can also be a concern. 
For example, some routers still use <a rel="noopener noreferrer nofollow" href="https://en.wikipedia.org/wiki/Server_Message_Block#SMB_/_CIFS_/_SMB1" target="_blank">SMBv1</a>, which is the original and ancient version of the popular Server Message Block protocol used in the Windows environment for network file and printer sharing. 
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/09/SMBv1-required.png">
Router USB port: Some routers still require the old and vulnerable SMBv1 protocol for the USB-based file sharing.

Due to security holes, for about a decade now, SMBv1 has been replaced by SMBv2 and newer versions and recently even disabled by default in most modern operating systems. 
That doesn't mean using SMBv1 will get you in trouble immediately, but it sure is not ideal. 
(Note, though, that many Asus routers might have the warning about enabling SMBv1, but they don't require it to work. 
In my experience, all Asus Wi-Fi 6 routers can work with newer SMB versions.)

Another security concern is when you use the NAS feature via the Internet. 
In this case, make sure you create an account for each user access. 
But if you're not sure, just don't turn on any “cloud” feature or FTP access. 
Use those only when you know what you're doing.

The bottom line is, if you want to do a lot of things with your network storage, it's a good idea to get a real dedicated <a href="https://dongknows.com/dong-ngos-most-important-gadget-is-a-synology-nas-server/" target="_blank">NAS server</a>. 
But if you only wish to use some casual network storage, it's quite fun and sensible to get even more use out of our router.
<h3>Get a good external drive</h3>
Any good external storage device, namely desktop or laptop (portable) USB drives, will work. 

You don't need to get a NAS-specific drive. 
So, if you want the fastest possible speed, get a fast SSD-based portable drive, such as one of those on this list. 
However, keep in mind that the performance depends on the network connection or the router's processing power.
That said, a fast external storage device doesn't always translate into better performance. 

In most cases, an affordable hard-drive-based portable drive, like the <a href="https://dongknows.com/wd-my-passport-2019-portable-drive-review/" class="rank-math-link">WD My Passport</a> or the <a href="https://dongknows.com/g-tech-g-drive-mobile-usb-c-review/" class="rank-math-link">G-Tech Mobile</a>, will do. 
Generally, a router USB port has enough juice to power one bus-powered drive. 
But you can also use desktop external drives that have a power adapter of their own. 
In this case, you can use one with each of a router's USB ports.

<a href="https://dongknows.com/best-portable-drives/">See also Best Portable Drives of 2021: The Ultra-secure, Extra-rugged, and Super-fast</a>
When it comes to storage space, the more, the better, so get the drive with the most capacity you can afford. 
If you're serious about your data, you can also choose an external drive with <a href="https://dongknows.com/why-you-would-want-a-synology-nas-server/#Redundancy_via_the_use_of_RAID_explained" target="_blank">redundancy</a>, such as a dual-drive RAID 1 external storage device, like the <a rel="noopener noreferrer nofollow" href="https://amzn.to/2lpFRrN" target="_blank">WD My Book Duo</a>.
<strong>Note: </strong>You will need to configure the hardware RAID setup <em>before</em> plugging it into the router. 

So do that on a computer first. 
<h3>Get the right router</h3>
Not all routers are equal, especially when it comes to raw power. 
That said, get a router that has a lot of processing power. 

Generally, the higher the specs, the better.<a href="https://dongknows.com/usb-c-vs-thunderbolt-3-explained/">See also Device Connections Explained: Thunderbolt or Not, It's All about USB-C</a>
Also, make sure you get a router that supports <a href="https://dongknows.com/peripheral-connection-explained-usb-c-vs-thunderbolt-3/" target="_blank">USB 3.2 Gen 1</a>, a.k.a USB 3.0, or faster. 
Some router also has an eSATA or USB-C port. 
So, find one that suits your needs. 

And finally, get the router that includes the storage features you want, such as the <a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/" target="_blank">support for Time Machine backup</a>.
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2019/01/Asus-RT-AX88U-USB-mode-1024x858.png">
Router USB port: Steps to make an Asus Wi-Fi router USB port work in USB 3.0 (a.k.a USB 3.2 Gen 1) mode.
<h3>Use the correct settings</h3>

By default, many routers -- especially those from Asus and Synology -- automatically set the connected drive to work in USB 2.0 mode. 
This mode won't affect the router's NAS functionality but has a theoretical cap speed of just 480 Mbps (60 MB/s) -- the real-world rate will be just about half of that. 
The USB 3.2 Gen 1 (formerly USB 3.0) mode, which the cap of 5 Gbps (625 MB/s), unfortunately, can adversely affect the router's 2.4GHz Wi-Fi band. 
That said, if you want to get the most out of the router's storage feature, you'll need to enable the faster USB mode manually -- we use mostly the 5GHz band these days anyway.

Also, make sure you use the external drive with the right setting. 
For one, use it in the <a href="https://dongknows.com/file-system-explained-and-how-to-format-your-drive/" target="_blank">correct file system</a> that the router supports. 
Most, if not all routers, support NTFS. 
<a href="https://dongknows.com/disk-partition-and-file-system-explained/">See also File System and Partition Explained: Take Control of Your Storage</a>

By the way, it's worth noting that you only need to use the file system that the router supports, and not the one your computer supports. 
That's because the file system used by the server has nothing to do with the client. 
So, for example, if you use an NTFS (Windows) external drive with your router and share its storage, over the network, your Mac will be able to read, write to the shared folder, and use the space for Time Machine backup (if supported) just fine. 
Finally, don't turn on the external storage device's security feature if it has one. 

A router has no mechanism to unlock it.
<h3>How to access your router-based NAS server</h3>
Once you've connected a storage device to a router and turned on the data sharing feature -- often referred to as Windows-based, or SAMBA (SMB), file sharing -- it's easy to access that share space from any computer within the network. 
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2021/01/Asus-RT-AX92U-USB-Features-836x1024.jpg">

The USB-related features of an Asus router. 
For NAS, the Samba option is in the second (Servers Center) from top.
A couple of things to note here:
<ul><li>Depending on the router, there might be more features than just data sharing. 

Another popular option is the media server -- where the router shares video and audio files stored on the connected drive via media streaming protocol. 
In this case, just follow the instruction to turn the desired feature on.</li><li>Here I assume you know how to set up a router, access its web interface, etc -- enabling the NAS feature is part of working with the router's interface. 
If not, this <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener" href="https://dongknows.com/home-wi-fi-router-setup/" target="_blank">post on how to build a network from scratch</a> will help you with that.</li></ul>
But data sharing is the most useful and popular, and I'll cover it here. 

It's fairly easy. 
To make it work, the only next thing you need is the router's IP address, which is the same one you've used to access its interface. 
Alternatively, you can also use the router's network name. 
But the IP is always the <em>sure</em> way. 

For this post, let's say the IP address in question is <em>192.168.1.1</em>. 
(Chances are yours is a different one. 
If you don't know what it is, this post on IP addresses includes detailed steps to figure that out.)
Once you've got the IP address, the steps below are the standard ways to access your newly-minted NAS server from a Windows or Mac computer within your local network hosted by the router.

<h3>Accessing your NAS server on a Windows computer</h3>
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2020/07/Access-Server-Windows.png">
You can access the shared folder via the router's IP address.
1. 

Open Explorer.
2. 
On the address bar type in this command then press Enter:
<strong><em>\\192.168.1.1</em></strong>

(Alternatively, you can also use <strong>\\RouterName</strong> and the Windows search field under the Start Menu instead of Explorer. 
Don't forget the \\ (<strong>not</strong> //) and remember there's no space in the command.)
3. 
Enter the username and password if prompted. 

If you haven't set up an account for the data sharing, or if the router doesn't support that, you can just use the<em> admin username and password of the router</em>‘s web interface.
<h3>Accessing your NAS server on a Mac</h3>
<img class="lazy" data-src="https://dongknows.com/wp-content/uploads/2020/07/Access-Server-Mac-1024x768.jpg">
1. 

Click on an empty spot on the desktop then press&nbsp;<em>Command + K</em>, and the “Connect to Server” window will appear.
2. 
Under <em>Server address</em>&nbsp;type in
<strong><em> smb://192.168.1.1&nbsp;</em></strong>

(Again, you can also substitute the IP address with the router's network name.)
3. 
Click on <em>Connect</em> and enter username and password (of the account you've created or the router's admin account) if prompted.
And that's it. 

Happy data sharing!
<h3>Best USB-enabled routers that can work as a NAS server</h3>
Now that you know how to turn a USB-enabled router into a NAS server, you probably wonder which router or routers you should get for the job. 
I addressed that big question in this separate, frequently updated post on <a href="https://dongknows.com/best-wi-fi-routers-for-nas/">the best Wi-Fi routers for NAS features</a>. 

Check it out!
<a href="https://dongknows.com/best-wi-fi-router-nas-solutions/">
See also Best 13 Router NAS Options: Add Some Cool Storage to Your Wi-Fi Today!</a>
By the way, again, many routers can also work as a <a href="https://dongknows.com/all-you-need-to-know-about-macs-time-machine-backup/" target="_blank" rel="noreferrer noopener">Time Machine backup</a> destination. 
For more, check out this post on how to <a href="https://dongknows.com/how-to-turn-your-wi-fi-router-into-a-time-capsule/">turn a router into a Time Capsule.</a>

'<h2>Wi-Fi Direct</h2><br>Windows 10 boasts another feature that most people don\'t know about, called <strong>Wi-Fi Direct</strong>, a wireless connectivity system that helps you effortlessly hook devices up and transfer huge amounts of data.<br><br><h3>How Does Wi-Fi Direct Work?</h3><br>For Wi-Fi Direct technology to work, you\'ll need at least a single device that\'s compatible with its protocols.3<br><br>Wi-Fi Direct is built on top of Wi-Fi. <br>The only thing that separates it from regular Wi-Fi is that while you need a router to connect your devices to the internet, Wi-Fi Direct doesn\'t have any limitations.<br><br><h3>Check If Your Windows 10 PC Is Wi-Fi Direct Compatible</h3><br>You can do this by pressing<strong> Windows Key +R</strong>, entering <strong>CMD</strong> to <a href="https://www.makeuseof.com/tag/a-beginners-guide-to-the-windows-command-line/">open the Command Prompt</a> then entering <strong>ipconfig /all</strong>.<br><img src="https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2021/06/windows-command-prompt.png"><br>If Wi-Fi Direct is available, you should see an entry labeled <strong>Microsoft Wi-Fi Direct Virtual Adapter.</strong><br><br>Next, you\'ll need to start transferring data over Wi-Fi Direct. <br><br><h3>How to Transfer Files From Android to Windows With Wi-Fi Direct</h3><br><br>As you\'ll need a third-party app to use Wi-Fi Direct, choosing the right option is important.<br><a href="https://feem.io/">Feem</a> is a software that has provided Wi-Fi Direct support to Windows PC and laptop users since the days of Windows 7 and Windows 8.<br>Feem is free to use, although it has various premium options. <br><br>Wi-Fi Direct in Feem is free, as is live chat. <br><br>Set your Android device as a mobile hotspot via <strong>Settings &gt; Network &amp; Internet &gt; Hotspot &amp; tethering</strong>. <br>Connect your Windows computer to this network.<br>Launch Feem on Android and Windows. <br><br>You\'ll notice that both devices are given unusual names by the app (e.g., Junior Raccoon) and a password. <br>Keep a note of the password, as you\'ll need it to establish the initial connection.<br>Send a file from Android to Windows using Wi-Fi Direct, choose the destination device, and tap <strong>Send File</strong>. <br><br>Browse for the file or files, then tap <strong>Send</strong>.<br>Moments later, the data will be sent to your PC. <br>It\'s as simple as that—and it works backwards, too.<br><br><strong>Download:</strong> <a href="https://feem.io/#download">Feem</a> (for Windows, macOS, Linux, Android, iOS, Windows Phone)<br><h3>Don\'t Have Wi-Fi Direct? Transfer Files With Bluetooth!</h3><br>If your devices don\'t support Wi-Fi Direct, a smart solution (in the absence of a USB cable) is Bluetooth. <br><br>This is particularly useful if you\'re trying to use Wi-Fi Direct on Windows 7 or 8 and find that the feature isn\'t there or it doesn\'t work.<br><br>First, ensure your computer is paired to a suitable Bluetooth device (phone, tablet, computer, etc.) before sending a file to it. <br>The methodology for this is largely the same across devices and requires that both are set to "discoverable."<br><br>Both devices will then search for one another and, if successful, connect following input of a confirmation code.<br>For more information, here\'s a list of how you can <a href="https://www.makeuseof.com/tag/transfer-files-android-pc/">transfer data between a PC and Android</a>.<br>If you\'re not sure where the controls for Bluetooth can be found on your Windows 10 computer, open <strong>Settings &gt; Devices. <br><br></strong>After you\'re in the <strong>Bluetooth &amp; other devices</strong> section, turn on the Bluetooth, and pair your device with the computer. <br>For that, click on <strong>Add Bluetooth or other device </strong>and go ahead with the pairing up.<br><br>Then click on <strong>Send or receive files via Bluetooth &gt; Send Files. <br><br>Next, select</strong> a device that you want to share files with, choose the file to be sent, and click on <strong>Next </strong>to go ahead with the transmission.<br><img src="https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2021/06/send-a-file-by-bluetooth.png"><br>On sending the file, the device receiving your data file will ask you to confirm that you wish to save the data. <br><br>Agree to this, and wait for the transfer to complete.<br>Note that due to the shorter range of Bluetooth, the best results will be enjoyed by keeping both devices close together.<br><h3>No Wi-Fi Direct? Transfer Files From Android to Windows PC With FTP</h3><br><br>FTP is another handy file transfer option for Android users attempting to transfer files to their Windows 10 PC (or other operating systems, for that matter).<br><a href="http://www.estrongs.com/#/">ES File Explorer</a> is a popular third-party <a href="https://www.makeuseof.com/tag/es-file-explorer-the-best-file-manager-for-android-android/">file manager for Android</a>. <br>This comes with several file management features for local and network use. <br><br>Among these is FTP, which provides a direct network connection between two devices.<br>Use ES File Explorer\'s <strong>Network &gt; FTP</strong> feature to display your Android device\'s IP address.<br>Paste this into a file transfer program such as <strong>FileZilla</strong> to browse the contents. <br><br>You can then effortlessly transfer files between the two devices.<br>So, try ES File Explorer if you want to transfer data from a mobile device to your laptop through Wi-Fi and don\'t have Wi-Fi Direct.<br><h3>Data Transfer Speeds: Which Is Best?</h3><br><br>You will probably notice while trying these two methods that Wi-Fi Direct is considerably quicker than Bluetooth. <br>Indeed, recent tests have demonstrated that <a href="https://www.dignited.com/23330/bluetooth-5-vs-wifi-direct-which-is-the-best-for-sharing-files-between-smartphones/#:~:text=Bluetooth%20is%20a%20peer%2Dto,a%20phone%20for%20a%20while.&amp;text=With%20WiFi%20Direct%2C%20you%20can,point%20or%20Router%20or%20Mifi.">Bluetooth speed is like a tortoise in comparison</a>.<br>While Wi-Fi Direct isn\'t quicker than any cable data transfer (such as USB 2.0 or USB 3.0), it is certainly capable of transferring a 1.5 GB file within 10 minutes; in contrast, Bluetooth takes almost 125 minutes to shift the same data.<br>',

<h2>The share option is greyed out</h2>
From the Properties window, set the Advanced Shared Permissions
a. 
From the Properties window, Click the Advanced Sharing button.
b. 
The Advanced Sharing window appears. 
First, select the check box beside the Share this folder option. 
Next, you need to type in a share name. 
By default, Windows 7 uses the name of the folder as the share name, but you can change the name by typing a new name in the Share name field.
c. 
Now you’re ready to set the permissions. 
Click the Permissions button from the Advanced Sharing window
d. 
Select the Everyone group in the Group or user names list, and then click Remove. 
Click Add to display the Select users or groups window. 
Within the Enter the object names to select text box, type the name of the user or users you want to give permission to access the shared folder (separate multiple usernames with semicolons). 
Click OK when you’re done to return to the Permissions window.
e. 
Next select the appropriate user in the Group or user names list. 
You can now use the permissions list to allow or deny one of the following permissions: Read, Change, or Full Control. 
Click OK if you’re done. 
If you want to assign permissions to additional users or group, repeat these steps to assign them the appropriate permissions.
f. 
Click OK to return to the Advanced Sharing window and click OK again to return to the Sharing tab. 
Finally, when you click Close, the folder or file is accessible to others on the network.
g. 
Click OK to return to the Sharing tab, and then click Close to share the resource with the network.


<h2>Find all Wi-Fi passwords with only 1 command</h2>
netsh wlan show profile
netsh wlan export profile folder=C:\ key=clear


<h2>Github Actions</h2>
<div id="GitActionstoc"><a href="#GitActionstopic-0" target="_self" >Terminology</a><br><a href="#GitActionstopic-1" target="_self" >Documentation</a><br><a href="#GitActionstopic-2" target="_self" >Experimenting</a><br><a href="#GitActionstopic-3" target="_self" >Workflows</a><br><a href="#GitActionstopic-4" target="_self" >Events</a><br><a href="#GitActionstopic-5" target="_self" >Environment</a><br><a href="#GitActionstopic-6" target="_self" >Example Job</a><br><a href="#GitActionstopic-7" target="_self" >Environment Variables</a><br><a href="#GitActionstopic-8" target="_self" >Secrets</a><br><a href="#GitActionstopic-9" target="_self" >Third Party Actions</a><br><a href="#GitActionstopic-10" target="_self" >Conditions</a><br><a href="#GitActionstopic-11" target="_self" >Persisting Data</a><br><a href="#GitActionstopic-12" target="_self" > Using shared job data to determine if subsequent job should run</a><br><a href="#GitActionstopic-13" target="_self" > Persist data using <code>strategy.matrix</code></a><br><a href="#GitActionstopic-14" target="_self" > Clarify the cache action</a><br><a href="#GitActionstopic-15" target="_self" >Reusable Workflows</a><br><a href="#GitActionstopic-16" target="_self" >Conclusion</a><br></div>

<a href="https://github.com/features/actions">GitHub Actions</a> makes it easy to automate all your software workflows, now with world-class CI/CD. 
Build, test, and deploy your code right from GitHub.
I've been using GitHub Actions a lot recently and I've found it to be immensely flexible and feature rich. 
I think it's well worth your time learning how to run your CI/CD pipelines via GitHub Actions, and in this post that's exactly what we're going to dig into.
<h3 id="GitActionstopic-0">Terminology</h3>
It all starts with a 'workflow'.
A workflow is a yaml configuration file that defines:
<strong>Jobs</strong>: a job represents a collection of 'steps'.
<strong>Steps</strong>: each 'step' does something useful (e.g. executes a piece of code).
<strong>Events</strong>: an event determines when your 'jobs' should run.
GitHub has a nice visualisation of this..
<img src="https://www.integralist.co.uk/images/overview-actions-simple.png">
<strong>NOTE</strong>: Each job you define will run in parallel. 
If you need jobs to run sequentially, then you'll need to configure a job to depend on another job using the <code>needs</code> property (we'll see an example of this later).
<h3 id="GitActionstopic-1">Documentation</h3>
I would strongly suggest bookmarking the <a href="https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions">official documentation</a> because it's very thorough. 
Unfortunately it's so thorough that it can be a bit overwhelming, but don't worry, once you've gotten familiar with the various concepts you'll start to remember where the important information is located.
The pages I use the most are:
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/expressions">Expressions</a></strong>: explains how to use GitHub's builtin functions, like <code>contains()</code>, <code>fromJSON()</code>, and functions like <code>success()</code> and <code>failure()</code> that tell you the state of previous steps that have run.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/contexts">Contexts</a></strong>: there are lots of contextual objects your jobs can use, such as objects for getting information about git (what branch we're dealing with, the commit SHA etc), environment variables, secrets, data exposed by other jobs and lots more.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions">Syntax</a></strong>: this is the most important page as it details all the yaml configuration syntax (so I come here often).
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/workflow-commands-for-github-actions">Commands</a></strong>: when executing a shell command (or script) you can use <code>echo</code> with a specific format and, depending on the format used, it'll take on special meaning to the workflow runner and can be used (among other things) for displaying rich messaging in the GitHub UI.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/environment-variables">Environment variables</a></strong>: most of the 'context' properties are also exposed as environment variables to make it easier for your shell commands/scripts to utilise.
<strong><a href="https://docs.github.com/en/actions/learn-github-actions/reusing-workflows">Reusing workflows</a></strong>: If you have a bunch of jobs all doing a similar thing (e.g. you've three jobs and each of them setup a specific set of environment variables before installing the rust programming language), then you can move that duplication into a separate workflow file that your main workflow can call out to.
<h3 id="GitActionstopic-2">Experimenting</h3>
The best thing to do when it comes to learning GitHub Actions is to create a test repo as a playground, like I did here: <a href="https://github.com/Integralist/actions-testing">https://github.com/Integralist/actions-testing</a>.
You can of course use an existing repo if you want, but I prefer to use something completely decoupled when I'm testing a new tool.
<h3 id="GitActionstopic-3">Workflows</h3>
As I mentioned earlier: everything starts with a workflow.
To create a workflow you must save a yaml file into the <code>.github/workflows</code> directory of your project's git repo.
In the following example you'll see I have created three separate workflows:
<code>├── .github
│   └── workflows
│       ├── my-first-workflow.yaml
│       ├── my-second-workflow.yaml
│       └── my-third-workflow.yaml
</code>
You can create as many workflows as you need to, and you can name a workflow file anything you like.
<h3 id="GitActionstopic-4">Events</h3>
Once we create a workflow file, let's see how we can trigger any jobs that are defined within the workflow. 
Be aware that in the following example workflow I have not defined any jobs, I'm focusing on the events configuration only:
<code>name: My Workflow
on:
  push:
  schedule:
    - cron: "0 0 1 * *"   # https://crontab.guru/every-month
    - cron: "*/5 * * * *" # https://crontab.guru/every-5-minutes
</code>
So we can see I've given my workflow a name using the <code>name</code> key, and I've defined some events using the <code>on</code> key:
<code>push</code>: any push to your repo, whether it be to your <code>main</code> branch or a pull-request branch, will trigger your job(s) to run.
<code>schedule</code>: run your job(s) on a schedule using cron syntax, which in this example triggers job(s) every five minutes and monthly.
<strong>NOTE</strong>: <a href="https://crontab.guru/">https://crontab.guru/</a> makes dealing with cron syntax easy.
Refer to GitHub's <a href="https://docs.github.com/en/actions/learn-github-actions/events-that-trigger-workflows">events documentation</a> to learn more about the various events you can configure. 
For example, you can restrict a workflow to only execute against a specific branch.
<h3 id="GitActionstopic-5">Environment</h3>
Each job runs inside its own virtual machine 'runner', which means (just as an example) files you create, or data you produce, will not persist across jobs. 
This includes things like environment variables.
<h3 id="GitActionstopic-6">Example Job</h3>
Let's take a look at a very simple job:
<code>name: Test Workflow
on: push
jobs:
  simple-job:
    runs-on: ubuntu-latest
    steps:
      - name: Say Hello
        run: echo 'hello'
</code>
Let's now break apart this workflow to understand what it's doing..
<code>name</code>: the name for the workflow.
<code>on</code>: the event(s) we want to have trigger our job(s).
<code>jobs</code>: a list of jobs we want to be executed under this workflow.
<code>simple-job</code>: a job that consists of nested configuration.
<code>runs-on</code>: the environment I want the job to run in.
<code>steps</code>: a list of steps to run under the job.
<code>name</code>: the name of the step, which can be omitted but it makes the output in the GitHub UI nicer.
<code>run</code>: the shell command/script I want to run (in this example, my command prints the string <code>hello</code>).
<strong>NOTE</strong>: Refer to the GitHub <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#github-hosted-runners">runner documentation</a> to see what other environments are available. 
Also refer to the <a href="https://github.com/actions/virtual-environments">virtual-environments</a> repo to see what is installed on each runner's operating system.
As you can see, defining a workflow and its jobs/steps is actually very simple and intuitive. 
Now we can start looking at using more features and how to take advantage of the platform.
<h3 id="GitActionstopic-7">Environment Variables</h3>
GitHub Actions let you configure environment variables in multiple places depending on the scope they should have.
You can define environment variables globally, so they're available to all jobs (and all steps within those jobs), or at a job level (so they can be accessed by all steps within the specific job) or at a step level, meaning only a specific step will have access to them.
I'll demonstrate environment variable configuration in the following example:
<code>name: Testing Environment Variables
on: push
env:
  FOO: bar
jobs:
  validate-env-vars:
    runs-on: ubuntu-latest
    env:
      LITERAL: whatever
      INTERPOLATION: ${{ github.ref_name }}
      EXPRESSION: $(echo ${{ github.ref_name }} | perl -pe 's/[^a-zA-Z0-9]+/-/g' | perl -pe 's/(\A-|-\Z)//g' | awk '{print tolower($0)}')
    steps:
      - name: Print Global Environment Variables
        run: echo $FOO
      - name: Print Job Environment Variables
        run: |
          echo ${{ env.LITERAL }}
          echo ${{ env.INTERPOLATION }}
          echo ${{ env.EXPRESSION }}
          echo $LITERAL
          echo $INTERPOLATION
          echo $EXPRESSION          
      - name: Print Step Environment Variables:
        env:
          STEPVAR: my step
        run: |
          echo ${{ env.STEPVAR }}
          echo $STEPVAR          
</code>
OK, so there's a few things to unpack from the above example workflow.
The first thing I want to clarify is that when running shell commands/scripts using <code>steps.run</code> you can either define multiple steps like so:
<code>- run: echo hello
- run: echo world
</code>
Or alternatively you can use the pipe <code>|</code> character to indicate the value spans multiple lines, like so:
<code>- run: |
  echo hello
  echo world  
</code>
I would tend towards using separate <code>run</code> steps rather than one long multi-line <code>run</code> because it's harder to handle errors (or know where an error occurred) in the latter approach.
The next thing to clarify is that there are two ways to access an environment variable:
<ol>
<strong>Interpolation</strong>: <code>${{ ... 
}}</code> (e.g. <code>echo ${{ env.LITERAL }}</code>).
<strong>Variable reference</strong>: <code>$VARNAME</code> (e.g. <code>echo $LITERAL</code>).
</ol>
It's important to understand that although the output between the two approaches is the same, there is still a distinction worth being aware of.
With interpolation the value is acquired by looking up the relevant key within the <a href="https://docs.github.com/en/actions/learn-github-actions/contexts#env-context"><code>env</code> context object</a>, and then the value is injected into the shell command to be executed, while the more traditional variable reference approach works by the shell instance looking up the environment variable to access the value.
So when you look at the GitHub Actions GUI (e.g. <code>https://github.com/&lt;USER&gt;/&lt;REPO&gt;/actions/runs/&lt;ID&gt;</code>) and you look through the job output for the <code>LITERAL</code> example, then you'll see something like:
<code data-lang="bash">echo whatever
echo $LITERAL
</code>
This is because the first line used interpolation, so really the shell command was just echo'ing the literal value, where as the second line was echo'ing the <em>result</em> of looking up the environment variable.
In our example workflow you can see we defined a global environment variable called <code>FOO</code>, we also defined a job level set of environment variables (<code>LITERAL</code>, <code>INTERPOLATED</code> and <code>EXPRESSION</code>), and finally we defined a step level environment variable called <code>STEPVAR</code>.
Let's take a moment to clarify the job level environment variables as these demonstrate something important, which is although the <code>EXPRESSION</code> variable was assigned a shell command, that command isn't <em>evaluated</em> and so the literal characters are assigned as the value.
If you thought the <em>result</em> of the shell command (e.g. acquire the branch name from the <code>github</code> context object, and then do some normalisation of the name using a combination of <code>perl</code> and <code>awk</code>) would be assigned to the environment variable, then you would have been wrong.
Only the <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idstepsrun"><code>steps.run</code></a> key will actually evaluate a given shell command/script.
Now if the only way to evaluate a shell command is via <code>steps.run</code>, then how can we dynamically assign a value to an environment variable?
Consider this example, you're a <a href="https://nodejs.org/en/">Node.js</a> developer and you're using the Node version manager <code>nvm</code> along with a <a href="https://github.com/nvm-sh/nvm#nvmrc"><code>.nvmrc</code> file</a> to control which version of Node your project uses.
You're also using GitHub actions and you want to use a pre-existing action to manage installing Node on your job runner (we'll dig into third-party actions later, but for now just know that they are a thing).
This is where things get a little funky, because third-party actions can't evaluate shell commands given as inputs. 
So the most popular third-party action for installing Node is <a href="https://github.com/actions/setup-node"><code>actions/setup-node</code></a> and it allows you to specify the version of Node to install but it has to be a literal value.
The following example demonstrates how to side-step this restriction by using a <code>steps.run</code> to dynamically access the value inside the <code>.nvmrc</code> file and to then update the local environment with a new variable holding that value. 
This means you can then use interpolation to access that value and pass it into the <code>actions/setup-node</code> action:
<code>name: Testing Dynamic Environment Variable Value
on: push
jobs:
  validate-env-vars:
    runs-on: ubuntu-latest
    steps:
      - name: Generate Dynamic Environment Variable
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - name: Print NODE_VERSION
        run: |
          echo ${{ env.NODE_VERSION }}
          echo $NODE_VERSION          
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
</code>
The trick is to update a GitHub Actions provided environment variable called <code>$GITHUB_ENV</code>. 
All the following steps will then have an environment that includes whatever is in <code>$GITHUB_ENV</code>.
<strong>NOTE</strong>: You could also use the output of a step as the input to the <code>actions/setup-node</code> action, but we'll look at that feature later.
<h3 id="GitActionstopic-8">Secrets</h3>
The previous Node.js example workflow actually leads us quite nicely into this section about <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets#using-encrypted-secrets-in-a-workflow">secrets</a>.
Let's see a common solution to accessing a private NPM repository..
<code>name: Testing GITHUB_TOKEN access restrictions
on: push
jobs:
  testing:
    runs-on: ubuntu-latest
    steps:
      - name: Acquire Node Version
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
      - name: Authorize access to private packages
        run: echo "//npm.pkg.github.com/:_authToken=${{ secrets.GITHUB_TOKEN }}" &gt; ~/.npmrc
</code>
What we're doing here is installing Node.js and then modifying a <code>.npmrc</code> file so that it knows, when we do an <code>npm install</code>, to use an authentication token because the repository we want to use to get at our dependencies is otherwise private.
You'll see we're using a <a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets"><code>secrets</code> context object</a> to access a <code>GITHUB_TOKEN</code> value to use as our authentication token. 
This should be fine, but it doesn't work and our authentication with the private NPM repository fails.
Let's take a moment to learn a bit about GitHub 'secrets'..
In the GitHub UI for a repo/project you can add secrets that are encrypted and made accessible to your workflow via the <code>secrets</code> context object. 
But additionally GitHub Actions provides access to a secret called <a href="https://docs.github.com/en/actions/security-guides/automatic-token-authentication#about-the-github_token-secret"><code>GITHUB_TOKEN</code></a>.
I'll just refer you to the GitHub documentation, as it explains it best:
At the start of each workflow run, GitHub automatically creates a unique GITHUB_TOKEN secret to use in your workflow. 
When you enable GitHub Actions, GitHub installs a GitHub App on your repository. 
The GITHUB_TOKEN secret is a GitHub App installation access token. 
You can use the installation access token to authenticate on behalf of the GitHub App installed on your repository. 
The token's permissions are limited to the repository that contains your workflow.
That last sentence is the important bit! What essentially it means is that you can't use <code>secrets.GITHUB_TOKEN</code> to access things outside of the project repo.
So to solve our problem we still need to use the <code>secrets</code> context object, but instead of using the default <code>GITHUB_TOKEN</code> we're going to need to create a new <a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token">Personal Access Token</a> (PAT).
Once you create a PAT, as long as the user account that creates the PAT has access to the private repository, we can paste the PAT into the GitHub secrets UI.
For the sake of an example let's say you create a new secret called <code>NPM_AUTH_TOKEN</code> and paste the PAT value into it. 
We can now reference the secret token value via the <code>secrets</code> context object in our workflow file:
<code>name: Testing with Personal Access Token
on: push
jobs:
  testing:
    runs-on: ubuntu-latest
    steps:
      - name: Acquire Node Version
        run: echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - uses: actions/setup-node@v2
        with:
          node-version: "${{ env.NODE_VERSION }}"
      - name: Authorize access to private packages
        run: echo "//npm.pkg.github.com/:_authToken=${{ secrets.NPM_AUTH_TOKEN }}" &gt; ~/.npmrc
</code>
Notice that the workflow file basically hasn't changed, except we swapped <code>secrets.GITHUB_TOKEN</code> for <code>secrets.NPM_AUTH_TOKEN</code>.
<h3 id="GitActionstopic-9">Third Party Actions</h3>
An action is just code that interacts with your repository. 
It's possible to write your own custom actions and to share them with the community.
If you want to learn more about creating your own actions, then refer to GitHub's “<a href="https://docs.github.com/en/actions/creating-actions/about-custom-actions">About custom actions</a>”.
There are a bunch of third-party actions that you'll see used a lot..
<a href="https://github.com/actions/checkout"><code>actions/checkout</code></a>
<a href="https://github.com/actions/cache"><code>actions/cache</code></a>
<a href="https://github.com/actions/setup-go"><code>actions/setup-go</code></a>
<a href="https://github.com/actions/setup-node"><code>actions/setup-node</code></a>
<a href="https://github.com/actions-rs/toolchain"><code>actions-rs/toolchain</code></a>
All of the above actions, with the exception of the last, are official GitHub maintained actions. 
This means they are considered safe to use in your workflows (remember that an action runner will be able to use your <code>secrets.GITHUB_TOKEN</code>). 
See also <a href="https://github.com/actions">https://github.com/actions</a> for more official/verified actions you can use.
<strong>NOTE</strong>: I've no idea why they don't provide a Rust action.
<h3 id="GitActionstopic-10">Conditions</h3>
You can use an <code>if</code> conditional statement to control whether a job or step is run. 
It's best to use this feature if you need to <em>skip</em> a job/step apposed to using an exit code from within a <code>run</code> shell command/script to stop a job/step that has already started to run.
One important caveat to using <code>if</code> in a workflow is that you <em>must</em> use single quotes and not double quotes. 
Consider the following example, which you might expect to only run the job if the GitHub branch affected is <code>main</code>..
<code>name: Testing with Double Quotes
on: push
jobs:
  run-if-main:
    if: ${{ github.ref_name == "main" }}
    runs-on: ubuntu-latest
    steps:
      - run: echo hello
</code>
<strong>NOTE</strong>: Expressions can omit the surrounding <code>${{ ... 
}}</code> but I tend to include it.
The above example won't work simply because the string <code>"main"</code> is using double quotes. 
You'll find the requirement for using single quotes is mentioned in the GitHub documentation for “<a href="https://docs.github.com/en/actions/learn-github-actions/expressions#literals">Literals</a>”.
If you want to learn more about the available operators, like <code>==</code>, <code>!=</code> and <code>&amp;&amp;</code> etc, then refer to the <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#operators">operators documentation</a>.
<h3 id="GitActionstopic-11">Persisting Data</h3>
A GitHub Action job does not persist data by default, as each job runs within its own 'runner'. 
To persist data we can use either a:
<ol>
Cache (<a href="https://github.com/actions/cache"><code>actions/cache</code></a>)
Artifact (<a href="https://github.com/actions/upload-artifact"><code>actions/upload-artifact</code></a>, <a href="https://github.com/actions/download-artifact"><code>actions/download-artifact</code></a>)
Job Output (<a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idoutputs"><code>outputs</code> documenation</a>)
</ol>
Caching is quick but isn't always ideal as it requires the use of I/O to create files to be cached, and then also we have to coordinate reading values back from disk and parsing the data contained within those files etc. 
Caching is best used for simple situations such as caching installed programming language dependencies.
Artifacts are slow as they need to upload and download files from GitHub's servers and also this requires two separate external actions to configure, making them not ideal for quick data persistence (and also makes 'simple' data persistence scenarios tedious).
To persist data using a job's output requires a job to produce some data and to expose that data via the job's <code>outputs</code> field. 
A consumer can then use and parse that data however they see fit. 
This approach can also be useful for dynamically generating job matrix variants using a job's <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobsjob_idstrategy"><code>strategy.matrix</code></a> field.
<strong>NOTE</strong>: A job has an <code>outputs</code> field, but also individual steps can access the output from a previous step by way of the same mechanism, which is a step needs to set an <code>id</code> field which either another step or the job itself can reference.
The way your <code>run</code> code (or an external shell script) can produce data that the GitHub job can reference is to <code>echo</code> a specially formatted string:
<code data-lang="bash">echo "::set-output name=&lt;name&gt;::&lt;data&gt;"
</code>
So in the following example we produce the data <code>bar</code> and we make it accessible via the name <code>foo</code>:
<code data-lang="bash">echo "::set-output name=foo::bar"
</code>
Now in the following example our GitHub job has two steps, and the latter step is accessing data produced by the first step:
<code>name: Produce Data
on: push
jobs:
  example:
    runs-on: ubuntu-latest
    steps:
      - id: produce-data
        run: echo "::set-output name=foo::bar"
      - run: echo ${{ steps.produce-data.outputs.foo }}
</code>
<strong>NOTE</strong>: Be sure to use the <code>id</code> field so the second step can use it to reference the first step's output!
<h3 id="GitActionstopic-12"> Using shared job data to determine if subsequent job should run</h3>
In the following example the <code>bar</code> job will not run if the required fields <code>foo</code> and <code>baz</code> aren't set to <code>true</code>.
Notice the data I produce within job <code>foo</code> is a simple array/list whose elements are strings who have a format of <code>key=value</code>:
<code>name: Produce Data To Control Job Run
on: push
jobs:
  foo:
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.footest.outputs.data }}
    steps:
      - run: |
          echo "FOO=true" &gt;&gt; $GITHUB_ENV
          echo "BAR=false" &gt;&gt; $GITHUB_ENV
          echo "BAZ=true" &gt;&gt; $GITHUB_ENV          
      - id: footest
        run: echo ::set-output name=data::[\"foo=$FOO\", \"bar=$BAR\", \"baz=$BAZ\"]
  bar:
    needs: foo
    if: ${{ contains(needs.foo.outputs.data, 'foo=true') &amp;&amp; contains(needs.foo.outputs.data, 'baz=true') }}
    runs-on: ubuntu-latest
    steps:
      - run: echo 'yay! we ran because the fields were set to true'
  build:
    needs: bar
    runs-on: ubuntu-latest
    steps:
      - run: echo 'yay! this job ran as the bar job was successful'
</code>
The key part to getting job <code>bar</code> to determine if it should run is to use an <code>if</code> along with one of GitHub's native functions called <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#contains"><code>contains()</code></a>. 
You can see I use it twice to check if the persisted data contains the values I'm looking for.
<strong>NOTE</strong>: You'll likely want to use the <code>needs</code> property to help make the jobs run sequentially. 
Otherwise without it the jobs will run in parallel and this means there would be a data race in <code>bar</code> trying to access the <code>foo</code> job's output which might not yet be available and this would cause both the <code>bar</code> job and its dependant <code>build</code> job to not be run.
<h3 id="GitActionstopic-13"> Persist data using <code>strategy.matrix</code></h3>
Below is an example of using JSON data from <code>job1</code> and exposing it to <code>job2</code>. 
This approach of using <a href="https://docs.github.com/en/actions/learn-github-actions/expressions#fromjson"><code>fromJSON</code></a> with data from another job to create a matrix is really cool, but otherwise this approach (as far as data persistence is concerned) isn't ideal because it requires the JSON data produced by the first job to have a very specific structure that the <code>strategy.matrix</code> expects. 
So to reiterate I'm not using <code>strategy.matrix</code> in this example because I want a matrix but just to demonstrate a clever way to persist data without having to resort to using either caching or artifacts.
With this in mind I needed to ensure I set the value of each matrix field to be a <em>list</em> type that contains a <em>single</em> entry.
If I didn't use a list type then the <code>strategy.matrix</code> would fail to parse my JSON data. 
I purposely ensure there is only a single value within the list because I don't actually need my data to cause the job to be run multiple times. 
This is because a <code>strategy.matrix</code> is typically used to generate multiple 'variants' of a job. 
By setting a single value inside a list, we ensure there is only ever one job variant generated (i.e. only one job is created), and that single job can simply reference the fields within the matrix as data points of interest.
<code>name: example
on: push
jobs:
  job1:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - id: set-matrix
        run: echo "::set-output name=matrix::{\"FOO\":["abc"],\"BAR\":["xyz"]}"
  job2:
    needs: job1
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{fromJSON(needs.job1.outputs.matrix)}}
    env:
      FOO: ${{ matrix.FOO }}
      BAR: ${{ matrix.BAR }}
    steps:
      - run: echo ${{ matrix.FOO }} # abc
      - run: echo ${{ matrix.BAR }} # xyz
</code>
<h3 id="GitActionstopic-14"> Clarify the cache action</h3>
OK, so as far as data persistence is concerned, we have the <code>actions/cache</code> action we can use as an option. 
It's actually not very obvious how this action works and so I thought I'd take a brief moment to clarify my understanding, which then helped me to better understand how I could use it for data persistence outside of just caching language dependencies (which is what most examples are based on).
The <code>actions/cache@v2</code> works like so, you have to define a new step like so:
<code>- uses: actions/cache@v2
  with:
    path: path/to/be/cached
    key: ${{ runner.os }}-my-cache-key
</code>
When the step that implements the action is executed (see above snippet), the cache action simply looks up the cache key (e.g. <code>Linux-my-cache-key</code>) and if it finds something in the cache, then it restores the cache to the path you specified (e.g. <code>path/to/be/cached</code>).
If the cache action doesn't find anything in the cache, then nothing happens.
Now the important bit: the cache action has a 'post run' event that executes once your job has finished successfully. 
The cache action will be run again and this time it stores whatever was in your given path into the cache using the key you said it should be stored under.
This means, when it comes to running another job, you need to ensure you define the cache action <em>again</em> (the same as you defined it in your first job). 
This is so all of what I've just explained will happen again in your second job (i.e. it'll lookup the key but this time it'll find something in the cache thanks to the 'post run' step from the first job). 
The only difference now in the second job is that in the 'post run' event, when the action gets run again, you'll now see something like..
Cache hit occurred on the primary key <code>Linux-my-cache-key</code>, not saving cache.
Meaning there was nothing else to do. 
I imagine if there were changes to the files in the given path then it would indicate the cache was updated with the latest files.
<h3 id="GitActionstopic-15">Reusable Workflows</h3>
If you have a bunch of setup configuration that is the same between jobs, then you can move that configuration into a separate workflow file that can then be imported and used by each job in your main workflow file.
The following example, demonstrates how to <em>call</em> (i.e. import) a reusable workflow:
<code>jobs:
  build:
    ...
  deploy:
    ...
  validate-foo:
    uses: integralist/actions-testing/.github/workflows/resuable-setup@main # install node, rust, setup env vars etc
    steps: 
      - ...
  validate-bar:
    uses: integralist/actions-testing/.github/workflows/resuable-setup@main # install node, rust, setup env vars etc
    steps: 
      - ...
</code>
An example implementation of a reusable workflow would be:
<code>name: Reusable workflow for validation scripts
on:
  workflow_call:
    inputs:
      install_node:
        type: bool
      name:
        required: true
        type: string
      description:
        required: true
        type: string
      script:
        required: true
        type: string
jobs:
  validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - if: ${{ github.event_name != 'schedule' }}
        run: exit 1
      - if: ${{ inputs.install_node }}
        name: Environment
        run: |
                    echo "NODE_VERSION=$(cat .nvmrc)" &gt;&gt; $GITHUB_ENV
      - if: ${{ inputs.install_node }}
        uses: actions/setup-node@v2
        id: node-yarn
        with:
          node-version: "${{ env.NODE_VERSION }}"
          cache: yarn
      - name: status update
        uses: ouzi-dev/commit-status-updater@v1.1.2
        with:
          name: ${{ inputs.name }}
          description: ${{ inputs.description }}
          status: pending
      - id: validator
        run: ${{ inputs.script }}
      - if: ${{ success() }}
        name: status update
        uses: ouzi-dev/commit-status-updater@v1.1.2
        with:
          name: ${{ inputs.name }}
          description: ${{ steps.validator.outputs.description }}
          status: ${{ steps.validator.outputs.status }}
</code>
Notice that in the reusable workflow we have a new event <code>workflow_call</code> that helps us to define <em>inputs</em> for the job being called.
In this reusable job we define a bunch of inputs which helps us to control whether the steps in the job are run (making the reusable job even more flexible) by utilising a step's <code>if</code> condition and interpolating the input value.
For example, we don't always install the Node.js programming language, only if the caller requests it:
<code>- if: ${{ inputs.install_node }}
  uses: actions/setup-node@v2
  id: node-yarn
  with:
    node-version: "${{ env.NODE_VERSION }}"
    cache: yarn
</code>
Now one important consideration is that the reusable workflow will not inherit the parent workflow's environment. 
This means secrets and environment variables need to be passed in via either <code>workflow_call.inputs</code> or <code>workflow_call.secrets</code>.
Annoyingly you can't just set an input with <code>${{ env.FOO }}</code> because the <code>env</code> context object can't be referenced. 
So if your reusable job is used a lot then you either have to hardcode the value as an <code>input</code> to the reusable workflow or you store the environment variable as a secret in the GitHub UI so that you can reference it from the <code>workflow_call.secrets</code> property.
<h3 id="GitActionstopic-16">Conclusion</h3>
There is so much more to explore with GitHub Actions. 
The bits I've mentioned here are just the tip of the iceberg. 
I strongly recommend you read the documentation and have a play around with these, and other features. 
Let me know on twitter what you think of GitHub Actions and whether you're using it in your projects.


<h2>Using branches in Git</h2>
<div id="Usingbranchestoc"><a href="#Usingbranchestopic-0" target="_self">Using branches in Git</a><br><a href="#Usingbranchestopic-1" target="_self">Why and how branches are used in Git</a><br><a href="#Usingbranchestopic-3" target="_self">Pre-requisites:</a><br><a href="#Usingbranchestopic-4" target="_self">What are Git branches</a><br><a href="#Usingbranchestopic-5" target="_self">Commands used with branches</a><br><a href="#Usingbranchestopic-6" target="_self">Using branches for pull requests</a><br><a href="#Usingbranchestopic-7" target="_self">Resources:</a><br><a href="#Usingbranchestopic-8" target="_self">Glossary:</a><br><a href="#Usingbranchestopic-9" target="_self">Links:</a><br></div>
<h3 id="Usingbranchestopic-1">Why and how branches are used in Git</h3>
Version control systems like Git help manage changes to files. 
Sometimes, you’ll want (or need) to make some ‘feature’ or ‘patches’ to a collaborative research project. 
Or maybe you want to make some experimental changes to your code, but don’t want to touch your main code. 

This, and more, is where branches come into play.
In this code-along we’ll go over what branches are, and how and why you would use them.
<h3 id="Usingbranchestopic-3">Pre-requisites:</h3>
Obviously, have <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">Git installed</a>
Make sure to <a href="http://codeasmanuscript.org/lessons/git/cheatsheet/">configure your git</a>
<h3 id="Usingbranchestopic-4">What are Git branches</h3>
In very simple terms, git branches are individual projects within a git repository. 
Different branches within a repository can have completely different files and folders, or it could have everything the same except for some lines of code in a file.

Let’s use a few real world examples (at least that I’ve used before, others may have used them differently):
Pretend you submitted a research article to a journal and they want you to revise it based on some reviewers comments. 
There are several ways to deal with the comments, so instead of changing your main manuscript, you create a
<code>revision</code> branch in your manuscript git repository. 
In that branch you make the changes to your manuscript in response to the reviewers. 
Once you are satisfied,
you merge the branch into the <code>master</code> branch and resubmit the article.
Imagine you have a dataset that multiple people work off of but that is also often updated with more data. 

You think you found a problem with the dataset, but aren’t sure. 
So you create a new branch <code>fixing</code> to fix the problems without messing with the master dataset. 
After you confirm the problem is real and that you have the solution, you submit a pull request of the <code>fixing</code> branch to be merged with the <code>master</code> branch.
What is often the case in software development, a bug or missing feature in the software gets identified. 
Because the software is already in production use (fairly stable, other people rely on it, etc), you can’t just make changes to the main software code. 

So a <code>hotfix</code> or <code>feature</code> branch is created to address these problems, which will eventually get merged in with the <code>master</code> branch for the next version of the software. 
This ensures that other people’s code isn’t broken everytime a bug gets fixed.
There are many uses of branches in Git. 
The nice (and very powerful) thing about Git is the fact that branches are very cheap compared to other version control systems. 

By cheap, I mean they don’t take up much disk space, it’s computationally easy to move between branches, and it’s (relatively) easy to merge branches together. 
This is because of how Git represents branches, since they are simply <em>pointers</em> or an individual commit. 
<em>That’s it.</em> Just a pointer… Git commit history is a 
<a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graph</a>, 
which means that every single commit always has a ‘parent’ commit (the previous commit in the history, or multiple parents when a merge happens), and any individual commit can have multiple ‘children’. 
This history can be traced back through the ‘lineage’ or ‘ancestry’. 
The branch just gives a name to each ‘lineage’ when a commit has multiple children.

When you merge two branches together, the commit histories get merged together as well. 
Which means that all the changes you made in each branch gets combined back into a single lineage, rather than two. 
This makes it easier to work collaboratively on a project, since each individual could work on their own branches, without dealing with the messiness that could come from working all on one branch.
<h3 id="Usingbranchestopic-5">Commands used with branches</h3>
Branches are best understood visually. 
So let’s first start with using 
<a href="https://onlywei.github.io/explain-git-with-d3/">this website</a> to see what the 
<code>branch</code>, <code>checkout</code>, and <code>merge</code> commands are doing.
After we’ve tried that, let’s do it locally (on your own computer). 
Here is a sequence of commands to try out:
<div><div><code>cd ~/Desktop mkdir 
git-branches
cd git-branches 
git init # start a repo 
git add .
git commit -m "First commit" # make the first commit 
git branch testBranch # create branch 
git checkout testBranch # move to branch
## can also do git checkout -b testBranch
echo "Some text" > file.txt 
git add file.txt
git commit -m "Added a file with text"
git checkout master
echo "Text in another file" > new-file.txt 
git add new-file.txt 
git commit -m "Added another file"
git log --graph --oneline --decorate --all
# This command is long, so shorten it using aliases 
git config --global alias.lg 'log --graph --oneline --decorate --all'
git merge testBranch 
git lg 
git branch -d testBranch # delete the branch</code>

<h3 id="Usingbranchestopic-6">Using branches for pull requests</h3>
I mentioned this already, but branches are best used when doing a 
<a href="https://help.github.com/articles/using-pull-requests/">pull request</a> (unless the pull request is very small or few people work on the repository).
The steps to take would be:
Fork a repository on GitHub Clone it onto your computer Make a branch and move to it: <code>git checkout -b fixingBranch</code>
Make changes to the files Commit the changes to the history Push the branch up to your forked version: <code>git push origin fixingBranch</code>
On GitHub, submit a Pull Request of your <code>fixingBranch</code>
Once the pull request is merged, 
<a href="https://github.com/blog/1377-create-and-delete-branches">delete</a> 
the <code>fixingBranch</code> on your forked repo on GitHub and on your computer 
(<code>git checkout master &amp;&amp; 
git pull upstream master &amp;&amp; 
git branch -d fixingBranch</code>)

<h3 id="Usingbranchestopic-7">Resources:</h3>
If you have any questions, often one of the best places to start is either<br>
<a href="https://stackoverflow.com/questions/tagged/git">StackOverflow</a> or Google (which more likely links to StackOverflow).
<h3 id="Usingbranchestopic-8">Glossary:</h3>
<code>cd</code> - change directory directory - the same thing as a folder
<code>mkdir</code> - make a directory
<code>echo</code> - print a message to the screen or to a file if <code>></code> (redirect) is present.
<code>git init</code> - start or initialize a git repository
<code>git add</code> - put a file into the staging area, so that git starts tracking it
<code>git commit</code> - send files in the staging/index area into the history (the git repository)
<code>git log --graph --oneline --decorate --all</code> - view the commit history in the git repository and the branches, with each commit as one line.
<code>git branch</code> - An individual line of commit history that contains files that may differ from other branches.
<code>git checkout</code> - A way to move across the git commits and branches.
<code>git merge</code> - Combine a branch into the current checked out branch (i.e. the branch you are on).
<h3 id="Usingbranchestopic-9">Links:</h3>
<a href="https://pcottle.github.io/learnGitBranching/">Interactive, visual tutorial on branching</a>
<a href="https://www.atlassian.com/git/tutorials/using-branches/git-branch">Brief explanation of branching</a>


<h2>create an orphan branch</h2>
git checkout --orphan <branchname>
This will create a new branch with no parents.
Then, clear everything in the orphan branch

git rm --cached -r
or
git rm -rf

and add the documentation files, commit them and push them up to github.

to check log
git log

A pull or fetch will always update the local information about all the remote branches.
If you only want to pull/fetch the information for a single remote branch, you need to specify it.

To switch back to your master branch
git checkout master

return to the orphan branch
git checkout mybranch

added first file in the new branch
git commit -m

git push origin new_branch_name






<h2>What are SSH Keys?</h2>
<div id="SSHKeystoc"><a href="#SSHKeystopic-1" target="_self">The History of The SSH Protocol</a> <a href="#SSHKeystopic-2" target="_self">What are SSH keys?</a> <a href="#SSHKeystopic-3" target="_self">How User Keys Work</a> <a href="#SSHKeystopic-4" target="_self">First Steps – SSH Key Generation</a> <a href="#SSHKeystopic-5" target="_self">Linux/Mac Instructions:</a> <a href="#SSHKeystopic-6" target="_self">Windows Instructions:</a> <a href="#SSHKeystopic-7" target="_self">How SSH Key Authentication Works</a> <a href="#SSHKeystopic-8" target="_self">Managing SSH Keys</a> <a href="#SSHKeystopic-9" target="_self">Cloud IAM offers SSH Key Management</a> </div>
If you spend enough time in an IT environment and with the rise of cloud infrastructure such as AWS, you will likely come across the term SSH keys. 
If you’ve already come across this IT term, then you might find yourself wondering, what are SSH keys?

SSH (Secure Shell) keys are an access credential that is used in the SSH protocol and they are foundational to modern Infrastructure-as-a-Service platforms such as AWS, Google Cloud, and Azure.
Before this post delves into an explanation on what are SSH keys, let’s take a quick look at the SSH protocol.

<h3 id="SSHKeystopic-1">The History of The SSH Protocol</h3>
The first version of the SSH protocol was developed in the summer of 1995 by Tatu Ylonen. 
Tatu was a researcher at the University of Helsinki when a sniffing attack was discovered on the university network. 

A sniffing attack intercepts and logs the traffic that takes place on a network and can provide attackers with usernames and passwords which can then be used to gain access to critical IT assets.
Thousands of credentials were impacted, including those belonging to community partnerships. 
This sniffing attack motivated Tatu to figure out how to make networks more secure, and this ultimately led to the creation of the SSH protocol (<a href="https://youtu.be/OHBdKM7s5V4">SSH.com</a>).

Today, the SSH protocol is widely used to login remotely from one system into another, and its strong encryption makes it ideal to carry out tasks such as issuing remote commands and remotely managing network infrastructure and other vital system components. 
This is especially important in the era of cloud infrastructure and remote work.
To use the SSH protocol, a couple pieces of software need to be installed. 

The remote systems need to have a piece of software called an SSH daemon, and the system used to issue commands and manage the remote servers needs to have a piece of software called the SSH client. 
These pieces of software are necessary to create a proper communication channel using the SSH protocol (<a href="https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#ssh-overview">DigitalOcean</a>).
Essentially, SSH keys are an authentication method used to gain access to an encrypted connection between systems and then ultimately use that connection to manage the remote system.

<h3 id="SSHKeystopic-2">What are SSH keys?</h3>
SSH keys come in many sizes, but a popular choice is an<a href="https://www.linkedin.com/pulse/2048-bit-encryption-what-why-does-matter-srini-vasan"> RSA 2048-bit encryption</a>, which is comparable to a 617 digit long password. 
On Windows systems, it is possible to<a href="http://statistics.berkeley.edu/computing/ssh-keys"> generate your own SSH key pair</a> by downloading and using an SSH client like PuTTY. 

On Mac and Linux systems, it is possible to generate an SSH key pair using a terminal window. 
Watch the video below to find out how to generate your own RSA key pair on Mac and Linux.
<iframe src="https://www.youtube.com/embed/FocgH8gTFVw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

SSH keys always come in pairs, and every pair is made up of a private key and a public key. 
Who or what possesses these keys determines the type of SSH key pair. 
If the private key and the public key remain with the user, this set of SSH keys is referred to as user keys.

If the private and public keys are on a remote system, then this key pair is referred to as<a href="https://www.ssh.com/ssh/host-key"> host keys</a>. 
Another type of SSH key is<a href="https://www.ssh.com/ssh/session-key"> a session key</a>. 
When a large amount of data is being transmitted, session keys are used to encrypt this information.

Now let’s take a closer look at how a private key and public key work. 
To keep things simple, we will focus on how user keys work.

<h3 id="SSHKeystopic-3">How User Keys Work</h3>
In a user key set, the private key remains on the system being used to access the remote system (i.e. the user’s desktop or laptop) and is used to decrypt information that is exchanged in the SSH protocol.
Private keys should never be shared with anyone and should be secured on a system – i.e. the system is secured (full disk encryption,<a href="https://jumpcloud.com/platform/multi-factor-authentication-mfa"> MFA</a>), in the user’s possession, and the private key is secured via passphrase.
A public key is used to encrypt information, can be shared, and is used by the user and the remote server. 
On the server end, the public key is saved in a file that contains a list of authorized public keys. 

<h3 id="SSHKeystopic-4">First Steps – SSH Key Generation</h3>
Before you can start using SSH keys, first you need to generate your own SSH key pair on the system you would like to use to access a remote system. 
Please see the instructions below.

<h3 id="SSHKeystopic-5">Linux/Mac Instructions:</h3>
<strong>Recommended</strong>: Install or Update OpenSSH
<code>sudo apt-get update
sudo apt-get install openssh-server</code>

First, load a command line terminal and type the following command:
<img src="https://lh4.googleusercontent.com/j4-CVJ1I-xRjdZOaZ8cXqN2hSUpCCYWDFe2oQK9i4XFt84BhrimIatRnpfRcKwMgVsJwCoMReFzODKRTPt5sHAy0oHyWN3Vgt7NrqBpDJ-CgBmYfTYdO2kj8gdGJtPw0juumpuQt">
Your two key files will be created in the /HOME/.ssh/ directory by default, including your private key, but you may specify a direct location. 

<strong>Never share your private key.</strong>
<strong>$HOME/.ssh/id_rsa.pub (public key</strong>
<strong>$HOME/.ssh/id_rsa (private net)</strong>

<img src="https://lh3.googleusercontent.com/8ve6RT8yo_KzV422Ute-qa_mZoI6eJVAZQXqu0SSKnbCZGDLVSKyAPcyipPYWSE-m0nRbemjldlHlASXaMhmq9ShIEJWydAfgvw8EgZmNTqhUrcY4S1MfXVW48c-H_j_lFvKVE98">

Per above, you’ll be given the option to set a passphrase to make it more difficult for unauthorized users to log into your accounts by protecting the confidentiality of your keypairs.
Your public key is uploaded to your server to use SSH key authentication for access control. 

The <a href="https://linuxhint.com/use-ssh-copy-id-command/">ssh-copy-id command</a>, which is part of the OpenSSH package, can be used to automate the transfer process in the syntax of:
<code>ssh-copy-id username@host</code>
You may also add the key to your account using<a href="https://support.jumpcloud.com/support/s/article/how-do-i-add-an-ssh-key-to-my-jumpcloud-account"> JumpCloud</a>, or by manually placing the public SSH key on the remote server (<a href="https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#basic-connection-instructions">DigitalOcean</a>).
<a href="https://jumpcloud-1.wistia.com/medias/5usy6ga9lo?wvideo=5usy6ga9lo"><img src="https://embedwistia-a.akamaihd.net/deliveries/c8719e08ca0f214b1cab32d7d9f7cf71.jpg?image_play_button_size=2x&amp;image_crop_resized=960x540&amp;image_play_button=1&amp;image_play_button_color=41c8c6e0"></a>

<a href="https://jumpcloud-1.wistia.com/medias/5usy6ga9lo?wvideo=5usy6ga9lo">Mac and Linux with CLI – jumpcloud-1</a>
<h3 id="SSHKeystopic-6">Windows Instructions:</h3>
<img src="https://lh4.googleusercontent.com/Xxs3ElpyXtbw_A92tJBEaHIr0rfnQ0klXz5DV5HRYCPQpDgYQYY-ulqCj7kfNek5m5B2fVBv3jNsUahOQhWZoIV3nS1YFYvVuzlHqnrWvMwb_eBa_PsV3XDweV1BPE3TBYSXyR4z">

Download and install the PuTTY SSH keygen program.

Load the PuTTYgen program
Click the <strong>Generate</strong> button and select RSA (SSH-2)
You may opt for a 4096 bit key, but some applications may not accept it and it may result in increased CPU usage during the ‘handshake’ process.
Key in a passphrase for additional security
You must select <strong>Save private key</strong> and specify a location
<strong>Do not share this file with unauthorized individuals</strong>
You can copy and paste your public key from the field above with <strong>Select All </strong>or hit the <strong>Save public key</strong> button.
You may add the key to your account using<a href="https://support.jumpcloud.com/support/s/article/how-do-i-add-an-ssh-key-to-my-jumpcloud-account"> JumpCloud</a>
<a href="https://jumpcloud-1.wistia.com/medias/gi8wc7hlbe?wvideo=gi8wc7hlbe"><img src="https://embed-fastly.wistia.com/deliveries/af124ab6985c9e4c76abe3183720f6cb.jpg?image_play_button_size=2x&amp;image_crop_resized=960x540&amp;image_play_button=1&amp;image_play_button_color=41c8c6e0"></a>
<a href="https://jumpcloud-1.wistia.com/medias/gi8wc7hlbe?wvideo=gi8wc7hlbe">Windows SSH Pair Keygen using PuTTY – jumpcloud-1</a>

<h3 id="SSHKeystopic-7">How SSH Key Authentication Works</h3>
After completing the steps mentioned above, use your terminal to enter in your ssh username and the IP address of the remote system in this format: <code>ssh username@my_ip_address</code>. 
This will initiate a connection to the remote system using the SSH protocol. 
The protocol and specified username will then tell the remote server which public key to use to authenticate you. 
Then the remote server will use that public key to encrypt a random challenge message that is sent back to the client. 

This challenge message is decrypted using the private key on your system.
Once the message is decrypted, it is combined with a previously arranged session ID and then sent back to the server. 
If the message matches with what the server sent out, the client is authenticated, and you will gain access to the remote server. 

This process proves to the server that you have the corresponding private key to the public key it has on file.
However, the security that this authentication process provides can be undermined when SSH keys are not properly managed. 

<h3 id="SSHKeystopic-8">Managing SSH Keys</h3>
It is imperative that proper SSH key management is in place because they often grant access to mission-critical digital assets. 
Also, companies tend to have a lot of SSH keys. 
In fact, Fortune 500 companies will often have <em>several millions</em> of these.

Despite the difficulty in trying to manually manage millions of SSH keys, having an SSH key management system in place is continuously overlooked. 
SSH.com did some digging and discovered a company that had 3 million SSH keys “that granted access to live production servers.
Of those, 90% were no longer used. 

Root access was granted by 10% of the keys ”. 
An effective SSH key management system in place would have gone a long way in reducing this concerning security risk.
IT has a couple options to<a href="https://jumpcloud.com/blog/identity-service-function-ssh-key-management/"> gain control over SSH keys</a> in their environment. 

One of these includes using an SSH key management tool. 
However this means having to manage one more platforms in addition to managing an SSO provider, a directory service, and maybe a system management solution. 
A new solution has emerged that is providing IT with a second option:<a href="https://jumpcloud.com/platform"> JumpCloud Directory Platform</a>.

<h3 id="SSHKeystopic-9">Cloud IAM offers SSH Key Management</h3>
This <a href="https://jumpcloud.com/blog/cloud-identity-and-access-management/">cloud-based identity and access management solution</a> provides IT with one central place to manage SSH keys. 
Furthermore, IT can also centralize user authentication to Mac, Linux, and Windows <a href="https://jumpcloud.com/blog/centralized-system-and-user-management/">devices</a>, cloud <a href="https://jumpcloud.com/blog/idaas-and-aws-cloud-servers/">servers</a>, wired and WiFi <a href="https://jumpcloud.com/blog/secure-wifi-networks-cloud-radius/">networks</a>, web-based and on-prem <a href="https://jumpcloud.com/blog/true-single-sign-on-systems-apps-network/">applications</a>, and virtual and on-prem storage. 
With one central place to manage a user’s authentication to all of their resources, it becomes a si
mple matter of a few clicks to deprovision users from all of their resources, including SSH key access to remote systems.


<h2>ModemPOOL</h2>
猫池
就是将相当数量的Modem使用特殊的拨号请求接入设备连接在一起，可以同时接受多个用户拨号连接的设备。

<a href="https://www.aliexpress.com/w/wholesale-16-port-gsm-modem-pool.html" class="whitebut ">16-port-gsm-modem-pool</a>
<a href="https://ozeki.hu/p_7672-how-to-send-sms-with-a-gsm-modem-pool.html" class="whitebut ">send-sms-with-a-gsm-modem-pool</a>

<h2>network address translation or port forwarding</h2>
Enabling outside access to an internal computer

Please note: this tutorial is for advanced users. 
Your router's firewall is there to protect you from evildoers who try to control your computer over the Internet. 
Make sure that any service you expose to the Internet is secured with a strong password.

Enabling outside access to an internal computer on a home network requires that you set up NAT - "network address translation," or port forwarding. 

Forwarding sends requests for ports on the outside of your firewall to the right computer on the inside.

For instance, someone on the outside requests a page from a web server at your router's IP address. 
With port forwarding set up, your router knows to forward requests for port 80 (a web server's default port) to the computer with the web server running only - and none of the others on your network.

Port forwarding is only necessary when you want to expose a service to computers on the Internet outside your firewall. 

set up port forwarding:

Step 1. 
Determine your server's internal IP address.

All the computers on your internal network have an IP address which looks something like 192.168.0.XXX. 
Get on the computer with the server running and open a command window. 

Then type ipconfig to determine the machine's internal address, like so:


C:\\Gina&gt;ipconfig

Windows IP Configuration

Ethernet adapter Local Area Connection:

        Connection-specific DNS Suffix  . 
:
        IP Address. 
. 

. 
. 
. 

. 
. 
. 

. 
. 
. 

. 
: 192.168.0.11
        Subnet Mask . 
. 

. 
. 
. 

. 
. 
. 

. 
. 
. 

: 255.255.255.0
        Default Gateway . 
. 
. 

. 
. 
. 

. 
. 
. 

: 192.168.0.1


In this case, as you can see, the server's internal IP address is 192.168.0.11.

Step 2. 
Configure your router.

Most routers have an web-based administrative interface that's located at http://192.168.0.1. 
(This address does depend on your model. 

Consult your router user guide for more info.)

Once you've gone to the router administration, entered the password (if one is set up), there should be an area called "Port forwarding." There, you'll set the port number that requests from the Internet will come in, and the internal computer that should fulfill those requests. 
Here's a screenshot of my Netgear router set up to port forward 5900 to my VNC server, which is at 192.168.0.11 (see above). 
Click on the image to see a larger version.

Here's a table of common services and their default port numbers.

Any other services you port forward for that I missed? Add it in the comments to this article or drop me a note at tips at lifehacker.com.

<h2>How exactly do TCP connections work?</h2>
https://www.ionos.com/digitalguide/server/know-how/introduction-to-tcp/
Transmission Control Protocol
TCP allows for transmission of information in both directions. 
This means that computer systems that communicate over TCP can send and receive data at the same time, similar to a telephone conversation. 

The protocol uses segments (packets) as the basic units of data transmission. 
In addition to the payload, segments can also contain control information and are limited to 1,500 bytes. 
The TCP software in the network protocol stack of the operating system is responsible for establishing and terminating the end-to-end connections as well as transferring data.

The TCP software is controlled by the various network applications, such as web browsers or servers, via specific interfaces. 
Each connection must always be identified by two clearly defined endpoints (client and server). 
It doesn’t matter which side assumes the client role and which assumes the server role. 

All that matters is that the TCP software is provided with a unique, ordered pair consisting of IP address and port (also referred to as "2-tuple" or "socket") for each endpoint.

<h3>The three-way handshake: How a TCP connection is established in detail</h3>
Prerequisites for establishing a valid TCP connection: Both endpoints must already have a unique IP address (IPv4 or IPv6) and have assigned and enabled the desired port for data transfer. 

The IP address serves as an identifier, whereas the port allows the operating system to assign connections to the specific client and server applications.
The actual process for establishing a connection with the TCP protocol is as follows:
First, the requesting client sends the server a SYN packet or segment (SYN stands for synchronize) with a unique, random number. 

This number ensures full transmission in the correct order (without duplicates).
If the server has received the segment, it agrees to the connection by returning a SYN-ACK packet (ACK stands for acknowledgment) including the client's sequence number plus 1. 
It also transmits its own sequence number to the client.

Finally, the client acknowledges the receipt of the SYN-ACK segment by sending its own ACK packet, which in this case contains the server's sequence number plus 1. 
At the same time, the client can already begin transferring data to the server.

<img class="lazy" data-src="https://www.ionos.com/digitalguide/fileadmin/_processed_/d/e/csm_EN-tcp_1f6b3edf44.png">
Process of establishing a TCP connection (three-way handshake)

Since the TCP connection is established in three steps, the connection process is called a three-way handshake.

Note
If the server port is closed or access is blocked, the client receives a TCP RST packet (reset) instead of an acknowledgment packet.









<script type='text/javascript' src='readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>

<script type='text/javascript' src='readbookNewMarker.js'></script>
</body>
</html>
