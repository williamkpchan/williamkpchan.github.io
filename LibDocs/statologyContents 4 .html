<base target="_blank"><html><head><title>statologyContents 4</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://williamkpchan.github.io/maincss.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script src="https://williamkpchan.github.io/lazyload.min.js"></script>
<script src='https://williamkpchan.github.io/mainscript.js'></script>
<script src="https://williamkpchan.github.io/commonfunctions.js"></script>
<script>
  var showTopicNumber = true;
  var topicEnd = "<br>";
  var bookid = "statologyContents 4"
  var markerName = "h2, h3"
</script>
<style>
body{width:70%;margin-left: 15%; font-size:20px;}
h1, h2 {color: gold;}
strong {color: orange;}
b {color: brown;}
img {max-width:60%; display: inline-block; margin-top: 2%;margin-bottom: 1%; border-radius:3px;}
</style></head><body onkeypress="chkKey()"><center>
<h1>statologyContents 4</h1>
<a href="#mustWatch" class="red goldbs" target="_self">Must Watch!</a><br><br>
<div id="toc"></div></center><br><br>
<div id="mustWatch"><center><span class="red">MustWatch</span></center><br></div>
<pre><br><br>
<h2><span class="orange">A Guide to dnorm, pnorm, qnorm, and rnorm in R</span></h2>
The  normal distribution  is the most commonly used distribution in statistics. This tutorial explains how to work with the normal distribution in R using the functions <b>dnorm</b>, <b>pnorm</b>, <b>rnorm</b>, and <b>qnorm</b>.
<h2>dnorm</h2>
The function <b>dnorm</b> returns the value of the probability density function (pdf) of the normal distribution given a certain random variable <em>x</em>, a population mean <em>μ </em>and population standard deviation <em>σ</em>. The syntax for using dnorm is as follows:
<b>dnorm(x, mean, sd) </b>
The following code illustrates a few examples of <b>dnorm</b> in action:
<b>#find the value of the standard normal distribution pdf at x=0
dnorm(x=0, mean=0, sd=1)
# [1] 0.3989423
#by default, R uses mean=0 and sd=1
dnorm(x=0)
# [1] 0.3989423
#find the value of the normal distribution pdf at x=10 with mean=20 and sd=5
dnorm(x=10, mean=20, sd=5)
# [1] 0.01079819
</b>
Typically when you’re trying to solve questions about probability using the normal distribution, you’ll often use <b>pnorm</b> instead of <b>dnorm</b>. One useful application of <b>dnorm</b>, however, is in creating a normal distribution plot in R. The following code illustrates how to do so:
<b>#Create a sequence of 100 equally spaced numbers between -4 and 4
x &lt;- seq(-4, 4, length=100)
#create a vector of values that shows the height of the probability distribution
#for each value in x
y &lt;- dnorm(x)
#plot x and y as a scatterplot with connected lines (type = "l") and add
#an x-axis with custom labels
plot(x,y, type = "l", lwd = 2, axes = FALSE, xlab = "", ylab = "")
axis(1, at = -3:3, labels = c("-3s", "-2s", "-1s", "mean", "1s", "2s", "3s"))</b>
This generates the following plot:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/normalPlot1.png">
<h2>pnorm</h2>
The function <b>pnorm</b> returns the value of the cumulative density function (cdf) of the normal distribution given a certain random variable <em>q</em>, a population mean <em>μ </em>and population standard deviation <em>σ</em>. The syntax for using pnorm is as follows:
<b>pnorm(q, mean, sd) </b>
Put simply, <b>pnorm</b> returns the area to the left of a given value <em>x </em>in the normal distribution. If you’re interested in the area to the right of a given value <em>q</em>, you can simply add the argument <b>lower.tail = FALSE</b>
<b>pnorm(q, mean, sd, lower.tail = FALSE) </b>
The following examples illustrates how to solve some probability questions using pnorm.
<b>Example 1:</b><em> Suppose the height of males at a certain school is normally distributed with a mean of <span><span><span>μ<span>=70 inches and a standard deviation of <span><span><span>σ = 2 inches. </em><em><span><span><span>Approximately what percentage of males at this school are taller than 74 inches?</em>
<b>#find percentage of males that are taller than 74 inches in a population with
#mean = 70 and sd = 2
pnorm(74, mean=70, sd=2, lower.tail=FALSE)
# [1] 0.02275013</b>
At this school, 2.275% of males are taller than 74 inches.
<b>Example 2:</b><em>  Suppose the weight of a certain species of otters is normally distributed with a mean of <span><span><span>μ<span>=30 lbs  and a standard deviation of <span><span><span>σ = 5 lbs. Approximately what percentage of this species of otters weight less than 22 lbs?</em>
<b>#find percentage of otters that weight less than 22 lbs in a population with
#mean = 30 and sd = 5
pnorm(22, mean=30, sd=5)
# [1] 0.05479929</b>
Approximately 5.4799% of this species of otters weigh less than 22 lbs.
<b>Example 3:</b><em>  Suppose the height of plants in a certain region is normally distributed with a mean of <span><span><span>μ<span>=13 inches  and a standard deviation of <span><span><span>σ = 2 inches. Approximately what percentage of plants in this region are between 10 and 14 inches tall?</em>
<b>#find percentage of plants that are less than 14 inches tall, then subtract the
#percentage of plants that are less than 10 inches tall, based on a population
#with mean = 13 and sd = 2
pnorm(14, mean=13, sd=2) - pnorm(10, mean=13, sd=2)
# [1] 0.6246553</b>
Approximately 62.4655% of plants in this region are between 10 and 14 inches tall.
<h2>qnorm</h2>
The function <b>qnorm</b> returns the value of the inverse cumulative density function (cdf) of the normal distribution given a certain random variable <em>p</em>, a population mean <em>μ </em>and population standard deviation <em>σ</em>. The syntax for using qnorm is as follows:
<b>qnorm(p, mean, sd) </b>
Put simply, you can use <b>qnorm </b>to find out what the Z-score is of the p<sup>th</sup> quantile of the normal distribution.
The following code illustrates a few examples of <b>qnorm</b> in action:
<b>#find the Z-score of the 99th quantile of the standard normal distribution 
qnorm(.99, mean=0, sd=1)
# [1] 2.326348
#by default, R uses mean=0 and sd=1
qnorm(.99)
# [1] 2.326348
#find the Z-score of the 95th quantile of the standard normal distribution 
qnorm(.95)
# [1] 1.644854
#find the Z-score of the 10th quantile of the standard normal distribution 
qnorm(.10)
# [1] -1.281552
</b>
<h2>rnorm</h2>
The function <b>rnorm</b> generates a vector of normally distributed random variables given a vector length <em>n</em>, a population mean <em>μ </em>and population standard deviation <em>σ</em>. The syntax for using rnorm is as follows:
<b>rnorm(n, mean, sd) </b>
The following code illustrates a few examples of <b>rnorm</b> in action:
<b>#generate a vector of 5 normally distributed random variables with mean=10 and sd=2
five &lt;- rnorm(5, mean = 10, sd = 2)
five
# [1] 10.658117 8.613495 10.561760 11.123492 10.802768
#generate a vector of 1000 normally distributed random variables with mean=50 and sd=5
narrowDistribution &lt;- rnorm(1000, mean = 50, sd = 15)
#generate a vector of 1000 normally distributed random variables with mean=50 and sd=25
wideDistribution &lt;- rnorm(1000, mean = 50, sd = 25)
#generate two histograms to view these two distributions side by side, specify
#50 bars in histogram and x-axis limits of -50 to 150
par(mfrow=c(1, 2)) #one row, two columns
hist(narrowDistribution, breaks=50, xlim=c(-50, 150)) 
hist(wideDistribution, breaks=50, xlim=c(-50, 150))
</b>
This generates the following histograms:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/03/rnorm.jpg">
Notice how the wide distribution is much more spread out compared to the narrow distribution. This is because we specified the standard deviation in the wide distribution to be 25 compared to just 15 in the narrow distribution. Also notice that both histograms are centered around the mean of 50.
<h2><span class="orange">How to Use do.call in R (3 Examples)</span></h2>
You can use <b>do.call()</b> in R to apply a given function to a list as a whole.
This function uses the following basic syntax:
<b>do.call(function, list)</b>
The following examples show how to use <b>do.call()</b> in practice.
<h2>Example 1: Use do.call() with sum</h2>
The following code shows how to use <b>do.call()</b> to calculate the sum of values in a list:
<b>#create list
values_list &lt;- list(A=c(1, 2, 3), B=c(7, 5, 10), C=c(9, 9, 2))
#calculate sum of values in list
do.call(sum, values_list)
[1] 48</b>
The sum of the values in the list is <b>48</b>.
Note that we would receive an error if we just tried to use <b>sum()</b> directly with the list:
<b>#create list
values_list &lt;- list(A=c(1, 2, 3), B=c(7, 5, 10), C=c(9, 9, 2))
#attempt to sum values in list
sum(values_list)
Error in sum(values_list) : invalid 'type' (list) of argument
</b>
<h2>Example 2: Use do.call() with mean</h2>
The following code shows how to use <b>do.call()</b> to calculate the mean of values in a list:
<b>#define argument to use in do.call
args &lt;- list(1:20, na.rm=TRUE)
#calculate mean of values in list
do.call(mean, args)
[1] 10.5
</b>
The mean of the values in the list is <b>10.5</b>.
Note that we would receive an error if we just tried to use <b>mean()</b> directly with the list:
<b>#attempt to calculate mean of values in list
mean(list(1:20), na.rm=TRUE)
[1] NA
Warning message:
In mean.default(list(1:20), na.rm = TRUE) :
  argument is not numeric or logical: returning NA</b>
<h2>Example 3: Use do.call() with rbind</h2>
The following code shows how to use <b>do.call()</b> to row bind together several data frames in R:
<b>#create three data frames
df1 &lt;- data.frame(team=c('A', 'B', 'C'),  points=c(22, 27, 38))
df2 &lt;- data.frame(team=c('D', 'E', 'F'),  points=c(22, 14, 20))
df3 &lt;- data.frame(team=c('G', 'H', 'I'),  points=c(11, 15, 18))
#place three data frames into list
df_list &lt;- list(df1, df2, df3)
#row bind together all three data frames
do.call(rbind, df_list)
  team points
1    A     22
2    B     27
3    C     38
4    D     22
5    E     14
6    F     20
7    G     11
8    H     15
9    I     18
</b>
The result is one data frame that contains the rows from each of the three data frames.
Note that we would not receive the desired data frame if we tried to use <b>rbind()</b> directly with the list:
<b>#create three data frames
df1 &lt;- data.frame(team=c('A', 'B', 'C'),  points=c(22, 27, 38))
df2 &lt;- data.frame(team=c('D', 'E', 'F'),  points=c(22, 14, 20))
df3 &lt;- data.frame(team=c('G', 'H', 'I'),  points=c(11, 15, 18))
#place three data frames into list
df_list &lt;- list(df1, df2, df3)
#attmempt to row bind together all three data frames
rbind(df_list)
        [,1]   [,2]   [,3]  
df_list List,2 List,2 List,2
</b>
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Use paste & paste0 Functions in R 
 How to Use the replace() Function in R 
 How to Use the View() Function in R 
 How to Use rep() Function in R 
<h2><span class="orange">Does Causation Imply Correlation? (3 Examples)</span></h2>
It’s well-known that  correlation does not imply causation .
As a simple example, if we collect data for the total number of high school graduates and total pizza consumption in the U.S. each year, we would find that the two variables are highly correlated:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/corrCause5.png">
This doesn’t mean that an increased number of high school graduates is <em>causing</em> more pizza consumption.
The more likely explanation is that U.S. population has been increasing over time, which means that the number of people receiving a high school degree and the total pizza being consumed are both increasing as population increases.
But what about the reverse statement: <b>Does causation imply correlation?</b>
If one variable causes another variable, does it necessarily mean that the two variables will be correlated?
The short answer: <b>No</b>. 
The following examples show why.
<h3>Example 1: Quadratic Relationship</h3>
Suppose some variable, X, causes variable Y to take on a value equal to X<sup>2</sup>.
For example:
If X = -10 then Y = -10<sup>2</sup> = 100
If X = 0 then Y = 0<sup>2</sup> = 0
If X = 10 then Y = 10<sup>2</sup> = 100
And so on.
If we plotted the relationship between X and Y, it would look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/caus1.png">
If we calculated the  Pearson correlation coefficient  between the two variables, we would find that the correlation is <b>zero</b>.
Although X causes Y, the linear correlation between the two variables is zero.
<h3>Example 2: Quartic Relationship</h3>
Suppose some variable, X, causes variable Y to take on a value equal to X<sup>4</sup>.
For example:
If X = -10 then Y = -10<sup>4</sup> = 10,000
If X = 0 then Y = 0<sup>4</sup> = 0
If X = 10 then Y = 10<sup>4</sup> = 10,000
And so on.
If we plotted the relationship between X and Y, it would look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/caus2.png">
If we calculated the  Pearson correlation coefficient  between the two variables, we would find that the correlation is <b>zero</b>.
We know that X causes Y, but the linear correlation between the two variables is zero.
<h3>Example 3: Cosine Relationship</h3>
Suppose some variable, X, causes variable Y to take on a value equal to cos(X).
For example:
If X = -10 then Y = cos(-10) = -0.83907
If X = 0 then Y = cos(0) = 1
If X = 10 then Y = cos(10) = -0.83907
And so on.
If we plotted the relationship between X and Y, it would look like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/11/caus3.png">
If we calculated the  Pearson correlation coefficient  between the two variables, we would find that the correlation is <b>zero</b>.
We know that X causes Y, but the linear correlation between the two variables is zero.
<h2><span class="orange">How to Use Dollar Sign ($) Operator in R</span></h2>
You can use the dollar sign operator (<b>$</b>) in R to create and access variables in lists and data frames.
The following examples shows four common way to use this operator in practice.
<h3>Example 1: Use Dollar Sign to Create Variable in List</h3>
Suppose we create the following list in R:
<b>#create list
my_list &lt;- list(A= c('X', 'Y', 'Z'),
                B=20,
                C=1:5)
#view list
my_list
$A
[1] "X" "Y" "Z"
$B
[1] 20
$C
[1] 1 2 3 4 5</b>
We can use the dollar sign operator (<b>$</b>) to create a new variable in this list:
<b>#create new variable in list
my_list$D &lt;- c('Hey', 'Hi', 'Hello')
#view updated list
my_list
$A
[1] "X" "Y" "Z"
$B
[1] 20
$C
[1] 1 2 3 4 5
$D
[1] "Hey"   "Hi"    "Hello"
</b>
Notice that the new variable <b>D</b> has been added to the list.
<h3>Example 2: Use Dollar Sign to Access Variable in List</h3>
We can also use the dollar sign operator (<b>$</b>) to access a specific variable in a list.
For example, we can use the following code to access the variable <b>C</b> in the list:
<b>#create list
my_list &lt;- list(A= c('X', 'Y', 'Z'),
                B=20,
                C=1:5)
#access variable C
my_list$C
[1] 1 2 3 4 5</b>
Notice that only the values for variable <b>C</b> are returned.
<h3>Example 3: Use Dollar Sign to Create Variable in Data Frame</h3>
Suppose we create the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Spurs', 'Rockets', 'Nets'), points=c(140, 115, 109, 98))
#view data frame
df
     team points
1    Mavs    140
2   Spurs    115
3 Rockets    109
4    Nets     98
</b>
We can use the dollar sign operator (<b>$</b>) to create a new variable in the data frame called <b>assists</b>:
<b>#create new variable called assists
df$assists &lt;- c(20, 25, 29, 49)
#view updated data frame
df
     team points assists
1    Mavs    140      20
2   Spurs    115      25
3 Rockets    109      29
4    Nets     98      49</b>
Notice that the new variable <b>assists</b> has been added to the data frame.
<h3>Example 4: Use Dollar Sign to Access Variable in Data Frame</h3>
We can also use the dollar sign operator (<b>$</b>) to access a specific variable in a data frame.
For example, we can use the following code to access the <b>points</b> variable in the data frame:
<b>#create data frame
df &lt;- data.frame(team=c('Mavs', 'Spurs', 'Rockets', 'Nets'), points=c(140, 115, 109, 98))
#access values for points
df$points
[1] 140 115 109  98
</b>
Notice that only the values for the <b>points</b> variable are returned.
<h2><span class="orange">How to Create a Dot Plot in Excel</span></h2>
A <b>dot plot </b>is a type of plot that displays frequencies using dots.
This tutorial explains how to create the following dot plot in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel5.png">
<h3>Example: Dot Plot in Excel</h3>
Suppose we have the following frequency table in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel1.png">
Use the following steps to create a dot plot for this frequency table.
<b>Step 1: Reorganize the data.</b>
First, we need to reorganize the data into a “long” format:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel2.png">
<b>Step 2: Create a dot plot using the “scatterplot” option.</b>
Highlight cells D2:E17. Along the top ribbon, click <b>Insert</b>. Within the <b>Charts </b>group, select the first chart within the <b>Scatter </b>group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel3.png">
The following plot will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel4.png">
<b>Step 3: Customize the chart.</b>
Lastly, we can customize the chart to make it a bit more visually appealing. Namely:
Delete the gridlines.
Delete the title.
Increase the size of the individual dots.
Change the x-axis to only span from 1 to 7.
This will leave us with a dot plot that looks like this:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/dotplotexcel5.png">
The individual values are shown along the x-axis and the frequencies of those values are represented by the number of dots.
<h2><span class="orange">How to Create a Dot Plot in Google Sheets (Easiest Method)</span></h2>
A <b>dot plot </b>is a type of plot that displays frequencies using dots.
The following step-by-step example shows how to create the following dot plot in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle7.png">
<h3>Step 1: Enter the Data</h3>
Suppose we have the following frequency table in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle1.png">
Before we create a dot plot, we need to first reorganize the data into a “long” format:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle2.png">
<h3>Step 2: Create Dot Plot</h3>
Highlight cells <b>E2:F17</b>. Then click the <b>Insert</b> tab, then click <b>Chart</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle3.png">
Google Sheets will insert a histogram by default. To turn this into a dot plot, click anywhere on the chart and then click the three vertical dots in the top right corner, then click <b>Edit chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle4.png">
In the <b>Chart editor</b> panel that appears on the right side of the screen, click the <b>Chart type</b> option and then click <b>Scatter chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle5.png">
The following plot will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle6.png">
This is a rough version of a dot plot.
<h3>Step 3: Customize Dot Plot</h3>
Make the following changes to make the dot plot more aesthetically pleasing:
Double click the y-axis label and delete it.
Double click the values on the y-axis and change the min value to .75 and the max value to 5.
Double click the major and minor gridlines and delete both.
Double click one of the dots in the plot and change the Point size to 14px.
Double click the title and change it to whatever name you’d like.
Once we make each of these changes, here’s what our final dot plot looks like:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotGoogle7.png">
The individual values are shown along the x-axis and the frequencies of those values are represented by the number of dots.
<h2><span class="orange">Dot Plots: How to Find Mean, Median, & Mode</span></h2>
A <b>dot plot</b> is a type of plot that displays the distribution of values in a dataset using dots.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotHist1.png">
The x-axis shows the individual data values and the y-axis shows the frequency of each value.
This tutorial explains how to calculate the mean, median, and mode of a dot plot.
<h3>Example: Calculate Mean, Median & Mode of Dot Plot</h3>
Suppose we have the following dot plot that shows the distribution of values for a given dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotHist1.png">
In order to calculate the mean, median, and mode for this dot plot, we must first write out the values for the dataset.
For example, we can see that the value “1” occurs four times, the value “2” occurs three times, the value “3” occurs one time, and so on.
We can write out the following values for this dataset:
<b>Values:</b> 1, 1, 1, 1, 2, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 10
We can now calculate the mean, median, and mode.
<h3>Mean</h3>
To find the mean of this dataset, we can add up all of the individual values and divide by the total sample size of 18:
Mean = (1+1+1+1+2+2+2+3+4+5+5+6+6+6+6+7+8+10) / 18 = <b>4.22</b>.
The mean turns out to be <b>4.22</b>. This is the average value of the dataset.
<h3>Median</h3>
To find the median of this dataset, we can write out all of the individual values in order and identify the value that lies directly in the middle:
1, 1, 1, 1, 2, 2, 2, 3, <b>4</b>, <b>5</b>, 5, 6, 6, 6, 6, 7, 8, 10
There are two values in the middle: 4 and 5. Thus, the median is the average of these two values, which is 4.5.
Thus, the median is <b>4.5</b>. This is the value located directly in the middle of the dataset.
<h3>Mode</h3>
To find the mode of this dataset, we can identify the values that occur most often:
<b>1</b>, <b>1</b>, <b>1</b>, <b>1</b>, 2, 2, 2, 3, 4, 5, 5, <b>6</b>, <b>6</b>, <b>6</b>, <b>6</b>, 7, 8, 10
This dataset has two modes: <b>1</b> and <b>6</b>. Each of these values occurs four times in the dataset.
<h2><span class="orange">Dot Plot vs. Histogram: What’s the Difference?</span></h2>
Two plots that are commonly used to visualize the distribution of values in a dataset are <b>dot plots</b> and <b>histograms</b>.
A <b>dot plot</b> displays individual data values along the x-axis and uses dots to represent the frequencies of each individual value.
A <b>histogram</b> displays data ranges along the x-axis and uses rectangular bars to represent the frequencies of values that fall into each range.
The following example shows how to create a dot plot and histogram for the same dataset.
<h3>Example: Creating a Dot Plot & Histogram for Same Dataset</h3>
Suppose we have the following dataset with 18 values:
<b>Data:</b> 1, 1, 1, 1, 2, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 10
Here is what a dot plot would look like for this dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotHist1.png">
The x-axis shows the individual data values and the y-axis shows the frequency of each value.
For example, we can see the value “2” occurs three times in the dataset because there are three dots above it. Similarly, we can see that the value “3” occurs just once because there is only one dot above it.
And here is what a histogram would look like for this dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotHist2.png">
The x-axis shows ranges of values (0-2, 2-4, 4-6, 6-8 , 8-10) and the y-axis uses rectangular bars to represent the frequency of individual values in the dataset that fall into each range.
For example, we can see that seven values are between 0 and 2, two values are between 2 and 4, and so on.
<b>Bonus</b>: For those who are curious, we used the following R code to create the dot plot and histogram shown above:
<b>#define dataset
data &lt;- c(1, 1, 1, 1, 2, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 10)
#create dot plot
stripchart(data, method = "stack", offset = .5, at = 0, pch = 19, cex=5,
           col = "steelblue", main = "Dot Plot",
           xlab = "Data Values", ylab="Frequency")
#create histogram
hist(data, col='steelblue', main='Histogram', xlab='Data Values')
</b>
<h3>Dot Plot vs. Histogram: Which Should You Use?</h3>
As mentioned earlier, both a dot plot and a histogram can be used to visualize the distribution of values in a dataset.
As a rule of thumb, <b>we typically use dot plots when our dataset is small</b> because it allows us to see exactly how many times each individual value occurs.
Conversely, <b>we typically use histograms when our dataset is large</b> because it’s cumbersome to create a dot to represent every single individual value in a large dataset.
Keep in mind that the one drawback of using a histogram is that we can’t tell exactly how many times each individual value occurs.
For example, in the histogram from earlier we saw that seven values fell in the range of 0 to 2, but we don’t know exactly how many values were equal to 1 and how many values were equal to 2.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dotHist2.png">
If we’re just interested in understanding the general “shape” of a distribution, then it usually isn’t a big deal that we don’t know the individual values in a dataset.
Also keep in mind that we can’t calculate the exact median or average by just looking at a histogram because we don’t know the individual values.
<h2><span class="orange">How to Easily Calculate the Dot Product in Google Sheets</span></h2>
This tutorial explains how to calculate the dot product in Google Sheets.
<h3>What is the Dot Product?</h3>
Given vector <em>a</em> = [a<sub>1</sub>, a<sub>2</sub>, a<sub>3</sub>] and vector <em>b</em> = [b<sub>1</sub>, b<sub>2</sub>, b<sub>3</sub>], the <b>dot product</b> of vector a and vector b, denoted as <b>a · b</b>, is given by:
<b>a · b</b> = a<sub>1</sub> * b<sub>1</sub> + a<sub>2</sub> * b<sub>2</sub> + a<sub>3</sub> * b<sub>3</sub>
For example, if <em>a</em> = [2, 5, 6] and <em>b</em> = [4, 3, 2], then the dot product of <em>a</em> and <em>b</em> would be equal to:
<b>a · b = </b>2*4 + 5*3 + 6*2
<b>a · b = </b>8 + 15 + 12
<b>a · b = </b>35
In essence, the <b>dot product </b>is the sum of the products of the corresponding entries in two vectors.
<h3>How to Find the Dot Product in Google Sheets</h3>
To find the dot product of two vectors in Google Sheets, we can use the followings steps:
<b>1. Enter the data</b>.
First, enter the data values for the first vector in one column and the data values for the second vector in the second column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/dotProdSheets1.png">
<b>2. Calculate the dot product.</b>
To calculate the dot product, we can use the <b>SUMPRODUCT() </b>function, which uses the following syntax:
<b>SUMPRODUCT(array1, [array2], …)</b>
<b>array </b>– the first array or range to multiply, then add.
<b>array2 </b>– the second array or range to multiply, then add.
The following image shows how to use this function to calculate the dot product between these two vectors:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/dotProdSheets2.png">
This produces the value <b>35</b>, which matches the answer we got by hand.
Note that the <b>SUMRRODUCT() </b>function works for vectors of any length. For example, we could use this function to calculate the dot product between two vectors both of length 20:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/10/dotProdSheets3.png">
<h3>Potential Errors in Calculating the Dot Product</h3>
The function <b>SUMPRODUCT() </b>will return a <b>#VALUE!</b> error if the vectors do not have equal length.
For example, if the first vector has length 20 and the second vector<i> </i>has length 19, then the formula <b>=SUMPRODUCT(A1:A20, B1:B19)</b> will return an error.
The two vectors need to have the same length in order for the dot product to be calculated.
<b>Related: </b> How to Calculate the Dot Product in Excel 
<h2><span class="orange">How to Calculate the Dot Product in R (With Examples)</span></h2>
Given vector <em>a</em> = [a<sub>1</sub>, a<sub>2</sub>, a<sub>3</sub>] and vector <em>b</em> = [b<sub>1</sub>, b<sub>2</sub>, b<sub>3</sub>], the <b>dot product</b> of vector a and vector b, denoted as <b>a · b</b>, is given by:
<b>a · b</b> = a<sub>1</sub> * b<sub>1</sub> + a<sub>2</sub> * b<sub>2</sub> + a<sub>3</sub> * b<sub>3</sub>
For example, if <em>a</em> = [2, 5, 6] and <em>b</em> = [4, 3, 2], then the dot product of <em>a</em> and <em>b</em> would be equal to:
<b>a · b = </b>2*4 + 5*3 + 6*2
<b>a · b = </b>8 + 15 + 12
<b>a · b = </b>35
In essence, the dot product is the sum of the products of the corresponding entries in two vectors.
<h2>How to Calculate the Dot Product in R</h2>
There are two ways to quickly calculate the dot product of two vectors in R:
<b>Method 1: Use %*%</b>
The following code shows how to use the <b>%*% </b>function to calculate the dot product between two vectors in R:
<b>#define vectors
a &lt;- c(2, 5, 6)
b &lt;- c(4, 3, 2)
#calculate dot product between vectors
a %*% b
     [,1]
[1,]   35</b>
The dot product turns out to be <b>35</b>.
Note that this function works for data frame columns as well:
<b>#define data
df &lt;- data.frame(a=c(2, 5, 6), b=c(4, 3, 2))
#calculate dot product between columns 'a' and 'b' of data frame
df$a %*% df$b
     [,1]
[1,]   35</b>
<b>Method 2: Use the dot() function</b>
We can also calculate the dot product between two vectors by using the <b>dot() </b>function from the <b>pracma </b>library:
<b>library(pracma)
#define vectors
a &lt;- c(2, 5, 6)
b &lt;- c(4, 3, 2)
#calculate dot product between vectors
dot(a, b)
[1] 35</b>
Once again, the dot product between the two vectors turns out to be <b>35</b>.
<b>Related:</b>  How to Calculate a Cross Product in R 
<h2><span class="orange">How to Calculate a Dot Product on a TI-84 Calculator</span></h2>
Given vector <em>a</em> = [a<sub>1</sub>, a<sub>2</sub>, a<sub>3</sub>] and vector <em>b</em> = [b<sub>1</sub>, b<sub>2</sub>, b<sub>3</sub>], the <b>dot product</b> of vector a and vector b, denoted as <b>a · b</b>, is given by:
<b>a · b</b> = a<sub>1</sub> * b<sub>1</sub> + a<sub>2</sub> * b<sub>2</sub> + a<sub>3</sub> * b<sub>3</sub>
For example, if <em>a</em> = [2, 5, 6] and <em>b</em> = [4, 3, 2], then the dot product of <em>a</em> and <em>b</em> would be equal to:
<b>a · b = </b>2*4 + 5*3 + 6*2
<b>a · b = </b>8 + 15 + 12
<b>a · b = </b>35
We can use the following syntax to calculate the dot product of two vectors on a TI-84 calculator:
<b>sum({2, 5, 6}*{4, 3, 2})
</b>
The following step-by-step example shows how to use this syntax in practice.
<h3>Example: Calculate Dot Product on TI-84 Calculator</h3>
Use the following steps to calculate the dot product between two vectors:
<b>Step 1: Enter the sum( command.</b>
First, press 2nd then press STAT then scroll over to MATH and press sum:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/dot1.png">
<b>Step 2: Enter the left curly brace.</b>
Next, press 2nd then press ( to enter the first curly brace:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/dot2.png">
<b>Step 3: Enter the Data</b>
Next, enter the following values for each vector:
Vector a: 2, 5, 6
Vector b: 4, 3, 2
 Be sure to include a multiplication sign between the two vectors and close off the end of the sum() command with a parenthesis on the right. Then press ENTER:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/05/dot3.png">
The dot product turns out to be <b>35</b>. This matches the value that we calculated by hand.
<h2><span class="orange">How to Create a Double Bar Graph in Google Sheets</span></h2>
A <b>double bar graph</b> is useful for visualizing two datasets on one graph.
The following step-by-step example shows how to create a double bar graph in Google Sheets.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the values for the following dataset:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double1.png">
<h3>Step 2: Create the Double Bar Graph</h3>
To create a double bar graph for this dataset, we can first highlight the values in the range <b>A1:C6</b>. Then click the <b>Insert</b> tab, then click <b>Chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double2.png">
The following double bar graph will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double3.png">
The x-axis displays the various metrics and the y-axis shows the values of those metrics for both Team 1 and Team 2.
<h3>Step 3: Customize the Double Bar Graph</h3>
To customize the graph, first click anywhere on the graph. Then click the three vertical dots in the top right corner. Then click <b>Edit chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double4.png">
In the <b>Chart editor</b> panel that appears on the right side of the screen, click the <b>Customize</b> tab to see a variety of options for customizing the appearance of the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double5.png">
For example, we can change the chart title, the colors of the bars, and the location of the legend:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/double6.png">
Feel free to modify the chart in any way you’d like so that it looks best for your particular situation.
<h2><span class="orange">How to Create a Double Doughnut Chart in Excel</span></h2>
A <b>doughnut chart </b>is a circular chart that uses “slices” to display the relative sizes of data. It’s similar to a pie chart except it has a hole in the center, which makes it look more like a doughnut.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut1.png">
A <b>double doughnut chart </b>is exactly what it sounds like: a doughnut chart with two layers, instead of one.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut2.png">
This tutorial explains how to create a double doughnut chart in Excel.
<h3>Example: Double Doughnut Chart in Excel</h3>
Perform the following steps to create a double doughnut chart in Excel.
<b>Step 1: Enter the data.</b>
Enter the following data into Excel, which displays the percentage of a company’s revenue that comes from four different products during two sales quarters:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut3.png">
<b>Step 2: Create a doughnut chart.</b>
Highlight the first two columns of data.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut4.png">
On the <b>Data </b>tab, in the <b>Charts </b>group, click the icon that says <b>Insert Pie or Doughnut Chart</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut5.png">
Click on the icon that says <b>Doughnut</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut6.png">
The following doughnut chart will automatically appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut7.png">
<b>Step 3: Add a layer to create a double doughnut chart.</b>
Right click on the doughnut chart and click <b>Select Data</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut8.png">
In the new window that pops up, click <b>Add </b>to add a new data series.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut9.png">
For <b>Series values</b>, type in the range of values fpr Quarter 2 revenue:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut10.png">
Click <b>OK</b>. The doughnut chart will automatically update with a second outer layer:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut11.png">
<b>Step 4: Modify the appearance (optional).</b>
Once you create the double doughnut chart, you may decide to add a title and labels, and decrease the size of the hole in the middle slightly to make the chart easier to read:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/04/doughnut2.png">
<h2><span class="orange">How to Download Files from the Internet Using R</span></h2>
You can use the following basic syntax to download a file from the internet using the R programming language:
<b>download.file(url, destfile)</b>
where:
<b>url</b>: A character string that contains the URL of the file
<b>destfile</b>: A character string that contains the location of where to save the file
The following step-by-step example shows how to use this syntax in practice.
<h3>Step 1: Find URL of File</h3>
For this example, I’ll download a CSV file that contains information about model aircraft fields in New York located at the following URL:
 <b>https://catalog.data.gov/dataset?res_format=CSV&organization=city-of-new-york</b> 
To get the exact URL for this CSV file, I’ll right click on the CSV button and then click <b>Copy link address</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/url1.jpg"564">
I’ll then save this URL as a string variable in R:
<b>#define URL location
url&lt;-"https://data.cityofnewyork.us/api/views/brsj-szf5/rows.csv?accessType=DOWNLOAD"
</b>
<h3>Step 2: Define Destination for File</h3>
Next, I’ll define the destination to save the file to:
<b>#define destination for file
destfile &lt;- "C:/Users/Bob/Downloads"
</b>
<h3>Step 3: Download and View File</h3>
Next, I’ll use the following code to download the file:
<b>#download file and save in specified destination
download.file(url, destfile)
</b>
Lastly, I’ll navigate to the Downloads file where I saved the CSV file:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/url2.jpg"566">
If I double click the file, I can open and view the contents:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/url3.jpg"623">
<h2><span class="orange">How to Use the across() Function in dplyr (3 Examples)</span></h2>
You can use the  across()  function from the  dplyr  package in R to apply a transformation to multiple columns.
There are countless ways to use this function, but the following methods illustrate some common uses:
<b>Method 1: Apply Function to Multiple Columns</b>
<b>#multiply values in col1 and col2 by 2
df %>% 
  mutate(across(c(col1, col2), function(x) x*2))
</b>
<b>Method 2: Calculate One Summary Statistic for Multiple Columns</b>
<b>#calculate mean of col1 and col2
df %>%
  summarise(across(c(col1, col2), mean, na.rm=TRUE))
</b>
<b>Method 3: Calculate Multiple Summary Statistics for Multiple Columns</b>
<b>#calculate mean and standard deviation for col1 and col2
df %>%
  summarise(across(c(col1, col2), list(mean=mean, sd=sd), na.rm=TRUE))
</b>
The following examples show how to each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(conf=c('East', 'East', 'East', 'West', 'West', 'West'), points=c(22, 25, 29, 13, 22, 30), rebounds=c(12, 10, 6, 6, 8, 11))
#view data frame
df
  conf points rebounds
1 East     22       12
2 East     25       10
3 East     29        6
4 West     13        6
5 West     22        8
6 West     30       11</b>
<h2>Example 1: Apply Function to Multiple Columns</h2>
The following code shows how to use the <b>across()</b> function to multiply the values in both the <b>points</b> and <b>rebounds</b> columns by 2:
<b>library(dplyr)
#multiply values in points and rebounds columns by 2
df %>% 
  mutate(across(c(points, rebounds), function(x) x*2))
  conf points rebounds
1 East     44       24
2 East     50       20
3 East     58       12
4 West     26       12
5 West     44       16
6 West     60       22
</b>
<h2>Example 2: Calculate One Summary Statistic for Multiple Columns</h2>
The following code shows how to use the <b>across()</b> function to calculate the mean value for both the <b>points</b> and <b>rebounds</b> columns:
<b>library(dplyr) 
#calculate mean value of points an rebounds columns
df %>%
  summarise(across(c(points, rebounds), mean, na.rm=TRUE))
  points rebounds
1   23.5 8.833333</b>
Note that we can also use the <b>is.numeric</b> function to automatically calculate a summary statistic for all of the numeric columns in the data frame:
<b>library(dplyr) 
#calculate mean value for every numeric column in data frame
df %>%
  summarise(across(where(is.numeric), mean, na.rm=TRUE))
  points rebounds
1   23.5 8.833333
</b>
<h2>Example 3: Calculate Multiple Summary Statistics for Multiple Columns</h2>
The following code shows how to use the <b>across()</b> function to calculate the mean and standard deviation of both the <b>points</b> and <b>rebounds</b> columns:
<b>library(dplyr) 
#calculate mean and standard deviation for points and rebounds columns
df %>%
  summarise(across(c(points, rebounds), list(mean=mean, sd=sd), na.rm=TRUE))
  points_mean points_sd rebounds_mean rebounds_sd
1        23.5  6.156298      8.833333    2.562551</b>
<b>Note</b>: You can find the complete documentation for the <b>across()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions using dplyr:
 How to Remove Rows Using dplyr 
 How to Arrange Rows Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
<h2><span class="orange">How to Add Columns to Data Frame in R Using dplyr</span></h2>
You can use the <b>mutate()</b> function from the dplyr package to add one or more columns to a data frame in R.
This function uses the following basic syntax:
<b>Method 1: Add Column at End of Data Frame</b>
<b>df %>%
  mutate(new_col=c(1, 3, 3, 5, 4))
</b>
<b>Method 2: Add Column Before Specific Column</b>
<b>df %>%
 mutate(new_col=c(1, 3, 3, 5, 4),
        .before=col_name)
</b>
<b>Method 3: Add Column After Specific Column</b>
<b>df %>%
 mutate(new_col=c(1, 3, 3, 5, 4),
        .after=col_name)
</b>
<b>Method 4: Add Column Based on Other Columns</b>
<b>df %>%
  mutate(new_col= if_else(.$col_name > 10, 'A', 'B'))
</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(12, 14, 19, 24, 24, 22, 30, 9), assists=c(4, 6, 6, 8, 3, 7, 8, 11))
#view data frame
df
  team points assists
1    A     12       4
2    A     14       6
3    A     19       6
4    A     24       8
5    B     24       3
6    B     22       7
7    B     30       8
8    B      9      11
</b>
<h3>Example 1: Add Column at End of Data Frame</h3>
The following code shows how to add a column at the end of the data frame:
<b>#add 'blocks' column at end of data frame
df &lt;- df %>%
        mutate(blocks=c(1, 3, 3, 2, 4, 3, 6, 2))
#view data frame
df
  team points assists blocks
1    A     12       4      1
2    A     14       6      3
3    A     19       6      3
4    A     24       8      2
5    B     24       3      4
6    B     22       7      3
7    B     30       8      6
8    B      9      11      2</b>
Note that you can add an empty column by simply assigning NA to every value in the new column:
<b>#add empty column at end of data frame
df &lt;- df %>%
        mutate(blocks=NA)
#view data frame
df
  team points assists blocks
1    A     12       4     NA
2    A     14       6     NA
3    A     19       6     NA
4    A     24       8     NA
5    B     24       3     NA
6    B     22       7     NA
7    B     30       8     NA
8    B      9      11     NA
</b>
<h3>Example 2: Add Column Before Specific Column</h3>
The following code shows how to add a column before a specific column in the data frame:
<b>#add 'blocks' column before 'points' column
df &lt;- df %>%
        mutate(blocks=c(1, 3, 3, 2, 4, 3, 6, 2),
              .before=points)
#view data frame
df
  team blocks points assists
1    A      1     12       4
2    A      3     14       6
3    A      3     19       6
4    A      2     24       8
5    B      4     24       3
6    B      3     22       7
7    B      6     30       8
8    B      2      9      11
</b>
<h3>Example 3: Add Column After Specific Column</h3>
The following code shows how to add a column after a specific column in the data frame:
<b>#add 'blocks' column after 'points' column
df &lt;- df %>%
        mutate(blocks=c(1, 3, 3, 2, 4, 3, 6, 2),
              .after=points)
#view data frame
df
  team points blocks assists
1    A     12      1       4
2    A     14      3       6
3    A     19      3       6
4    A     24      2       8
5    B     24      4       3
6    B     22      3       7
7    B     30      6       8
8    B      9      2      11
</b>
<h3>Example 4: Add Column Based on Other Columns</h3>
The following code shows how to add a column based on another column in the data frame:
<b>#add 'status' column whose values depend on value in 'points' column
df &lt;- df %>%
        mutate(status= if_else(.$points > 20, 'Good', 'Bad'))
#view data frame
df
  team points assists status
1    A     12       4    Bad
2    A     14       6    Bad
3    A     19       6    Bad
4    A     24       8   Good
5    B     24       3   Good
6    B     22       7   Good
7    B     30       8   Good
8    B      9      11    Bad
</b>
<h2><span class="orange">dplyr: How to Use anti_join to Find Unmatched Records</span></h2>
You can use the <b>anti_join()</b> function from the  dplyr  package in R to return all rows in one data frame that do not have matching values in another data frame.
This function uses the following basic syntax:
<b>anti_join(df1, df2, by=<span>'col_name')
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Use anti_join() with One Column</h3>
Suppose we have the following two data frames in R:
<b>#create data frames
df1 &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'),  points=c(12, 14, 19, 24, 36))
df2 &lt;- data.frame(team=c('A', 'B', 'C', 'F', 'G'),  points=c(12, 14, 19, 33, 17))</b>
We can use the <b>anti_join()</b> function to return all rows in the first data frame that do not have a matching team in the second data frame:
<b>library(dplyr)
#perform anti join using 'team' column
anti_join(df1, df2, by='team')
  team points
1    D     24
2    E     36
</b>
We can see that there are exactly two teams from the first data frame that do not have a matching team name in the second data frame.
<h3>Example 2: Use anti_join() with Multiple Columns</h3>
Suppose we have the following two data frames in R:
<b>#create data frames
df1 &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'),  position=c('G', 'G', 'F', 'G', 'F', 'C'),  points=c(12, 14, 19, 24, 36, 41))
df2 &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'),  position=c('G', 'G', 'C', 'G', 'F', 'F'),  points=c(12, 14, 19, 33, 17, 22))</b>
We can use the <b>anti_join()</b> function to return all rows in the first data frame that do not have a matching team <em>and</em> position in the second data frame:
<b>library(dplyr)
#perform anti join using 'team' and 'position' columns
anti_join(df1, df2, by=c('team', 'position'))
  team position points
1    A        F     19
2    B        C     41
</b>
We can see that there are exactly two records from the first data frame that do not have a matching team name <em>and</em> position in the second data frame.
<h2><span class="orange">How to Apply Function to Each Row Using dplyr</span></h2>
You can use the following basic syntax to apply a function to each row in a data frame in R using functions from dplyr:
<b>df %>%
  rowwise() %>% 
  mutate(mean_value = mean(c(col1, col2, col3), na.rm=TRUE))
</b>
This particular example calculates the mean value of <b>col1</b>, <b>col2,</b> and <b>col3</b> for each row in the data frame, but you can replace the <b>mean()</b> function with any function you’d like to calculate a different metric.
The following examples show how to use this syntax in practice with the following data frame that contains information about points scored by various basketball players during different games:
<b>#create data frame
df &lt;- data.frame(game1=c(22, 25, 29, 13, 22, 30), game2=c(12, 10, 6, 6, 8, 11), game3=c(NA, 15, 15, 18, 22, 13))
#view data frame
df
  game1 game2 game3
1    22    12    NA
2    25    10    15
3    29     6    15
4    13     6    18
5    22     8    22
6    30    11    13
</b>
<h2>Example 1: Mean of Specific Columns in Each Row</h2>
The following code shows how to calculate the mean value of the <b>game1 </b>and <b>game3</b> columns for each row in the data frame:
<b>library(dplyr)
#calculate mean of game1 and game3
df %>%
  rowwise() %>% 
  mutate(mean_points = mean(c(game1, game3), na.rm=TRUE))
# A tibble: 6 x 4
# Rowwise: 
  game1 game2 game3 mean_points
           
1    22    12    NA        22  
2    25    10    15        20  
3    29     6    15        22  
4    13     6    18        15.5
5    22     8    22        22  
6    30    11    13        21.5</b>
From the output we can see:
The mean value of game1 and game3 in the first row is <b>22</b>.
The mean value of game1 and game3 in the second row is <b>20</b>.
The mean value of game1 and game3 in the third row is <b>22</b>.
And so on.
<h2>Example 2: Max of Specific Columns in Each Row</h2>
The following code shows how to calculate the max value of the <b>game2 </b>and <b>game3</b> columns for each row in the data frame:
<b>library(dplyr)
#calculate max of game2 and game3
df %>%
  rowwise() %>% 
  mutate(max_points = max(c(game2, game3), na.rm=TRUE))
# A tibble: 6 x 4
# Rowwise: 
  game1 game2 game3 max_points
          
1    22    12    NA         12
2    25    10    15         15
3    29     6    15         15
4    13     6    18         18
5    22     8    22         22
6    30    11    13         13</b>
From the output we can see:
The max value of game2 and game3 in the first row is <b>12</b>.
The max value of game2 and game3 in the second row is <b>15</b>.
The max value of game2 and game3 in the third row is <b>15</b>.
And so on.
<h2>Example 3: Standard Deviation of Specific Columns in Each Row</h2>
The following code shows how to calculate the standard deviation of the values in the <b>game2 </b>and <b>game3</b> columns for each row in the data frame:
<b>library(dplyr)
#calculate standard deviation of game2 and game3
df %>%
  rowwise() %>% 
  mutate(sd_points = sd(c(game2, game3), na.rm=TRUE))
# A tibble: 6 x 4
# Rowwise: 
  game1 game2 game3 sd_points
         
1    22    12    NA     NA   
2    25    10    15      3.54
3    29     6    15      6.36
4    13     6    18      8.49
5    22     8    22      9.90
6    30    11    13      1.41</b>
From the output we can see:
The standard deviation of game2 and game3 in the first row is NA (since standard deviation can’t be calculated from only one value).
The standard deviation of game2 and game3 in the second row is <b>3.54</b>.
The standard deviation of game2 and game3 in the first row <b>6.36</b>.
And so on.
<b>Note</b>: You can find the complete documentation for the <b>rowwise()</b> function in dplyr  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Count Distinct Values Using dplyr 
 How to Sum Across Multiple Columns Using dplyr 
 How to Replace Multiple Values in Data Frame Using dplyr 
<h2><span class="orange">How to Arrange Rows by Group Using dplyr (With Examples)</span></h2>
You can use the following methods to arrange rows by group in dplyr:
<b>Method 1: Arrange Rows in Ascending Order by Group</b>
<b>library(dplyr)
#arrange rows in ascending order based on col2, grouped by col1
df %>%
  group_by(col1) %>%
  arrange(col2, .by_group=TRUE)</b>
<b>Method 2: Arrange Rows in Descending Order by Group</b>
<b>library(dplyr)
#arrange rows in descending order based on col2, grouped by col1
df %>%
  group_by(col1) %>%
  arrange(desc(col2), .by_group=TRUE)</b>
<b>Method 3: Arrange Rows by Multiple Groups</b>
<b>library(dplyr)
#arrange rows based on col3, grouped by col1 and col2
df %>%
  group_by(col1, col2) %>%
  arrange(col3, .by_group=TRUE)</b>
This tutorial explains how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'F', 'G', 'G', 'F', 'F'), points=c(10, 12, 3, 14, 22, 15, 17, 17))
#view data frame
df
  team position points
1    A        G     10
2    A        G     12
3    A        F      3
4    A        F     14
5    B        G     22
6    B        G     15
7    B        F     17
8    B        F     17</b>
<h2>Example 1: Arrange Rows in Ascending Order by Group</h2>
The following code shows how to arrange the rows in ascending order based on <b>points</b>, grouped by the <b>team</b> column:
<b>library(dplyr)
#arrange rows in ascending order by points, grouped by team
df %>%
  group_by(team) %>%
  arrange(points, .by_group=TRUE)
# A tibble: 8 x 3
# Groups:   team [2]
  team  position points
        
1 A     F             3
2 A     G            10
3 A     G            12
4 A     F            14
5 B     G            15
6 B     F            17
7 B     F            17
8 B     G            22
</b>
The rows are arranged in ascending order (smallest to largest) by <b>points</b>, grouped by the <b>team</b> column.
<h2>Example 2: Arrange Rows in Descending Order by Group</h2>
The following code shows how to arrange the rows in descending order based on <b>points</b>, grouped by the <b>team</b> column:
<b>library(dplyr)
#arrange rows in descending order by points, grouped by team
df %>%
  group_by(team) %>%
  arrange(desc(points), .by_group=TRUE)
# A tibble: 8 x 3
# Groups:   team [2]
  team  position points
        
1 A     F            14
2 A     G            12
3 A     G            10
4 A     F             3
5 B     G            22
6 B     F            17
7 B     F            17
8 B     G            15
</b>
The rows are arranged in descending order (largest to smallest) by <b>points</b>, grouped by the <b>team</b> column.
<h2>Example 3: Arrange Rows by Multiple Groups</h2>
The following code shows how to arrange the rows in ascending order based on <b>points</b>, grouped by the <b>team</b> <em>and</em> <b>position</b> columns:
<b>library(dplyr)
#arrange rows in descending order by points, grouped by team and position
df %>%
  group_by(team, position) %>%
  arrange(points, .by_group=TRUE)
# A tibble: 8 x 3
# Groups:   team, position [4]
  team  position points
        
1 A     F             3
2 A     F            14
3 A     G            10
4 A     G            12
5 B     F            17
6 B     F            17
7 B     G            15
8 B     G            22
</b>
The rows are arranged in ascending order (smallest to largest) by <b>points</b>, grouped by the <b>team</b> <em>and</em> <b>position</b> columns.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter for Unique Values Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Count Number of Occurrences in Columns in R 
<h2><span class="orange">How to Use bind_rows and bind_cols in dplyr (With Examples)</span></h2>
You can use the <b>bind_rows()</b> function from the  dplyr  package in R to bind together two data frames by their rows:
<b>bind_rows(df1, df2, df3, ...)
</b>
Similarly, you can use the <b>bind_cols()</b> function from dplyr to bind together two data frames by their columns:
<b>bind_cols(df1, df2, df3, ...)</b>
The following examples show how to use each of these functions in practice.
<h3>Example 1: Use bind_rows()</h3>
The following code shows how to use the <b>bind_rows()</b> function to bind three data frames together based on their rows:
<b>library(dplyr)
#create data frames
df1 &lt;- data.frame(team=c('A', 'A', 'B', 'B'),  points=c(12, 14, 19, 24))
df2 &lt;- data.frame(team=c('A', 'B', 'C', 'C'),  points=c(8, 17, 22, 25))
df3 &lt;- data.frame(team=c('A', 'B', 'C', 'C'),  assists=c(4, 9, 12, 6))
#row bind together data frames
bind_rows(df1, df2, df3)
   team points assists
1     A     12      NA
2     A     14      NA
3     B     19      NA
4     B     24      NA
5     A      8      NA
6     B     17      NA
7     C     22      NA
8     C     25      NA
9     A     NA       4
10    B     NA       9
11    C     NA      12
12    C     NA       6
</b>
Notice that this function automatically fills in missing values with NA if the data frames do not all have the same column names.
<h3>Example 2: Use bind_cols()</h3>
The following code shows how to use the <b>bind_cols()</b> function to bind three data frames together based on their columns:
<b>library(dplyr)
#create data frames
df1 &lt;- data.frame(team=c('A', 'A', 'B', 'B'),  points=c(12, 14, 19, 24))
df2 &lt;- data.frame(team=c('A', 'B', 'C', 'C'),  points=c(8, 17, 22, 25))
df3 &lt;- data.frame(team=c('A', 'B', 'C', 'C'),  assists=c(4, 9, 12, 6))
#column bind together data frames
bind_cols(df1, df2, df3)
  team points assists steals blocks rebounds
1    A     12       A      8      A        4
2    A     14       B     17      B        9
3    B     19       C     22      C       12
4    B     24       C     25      C        6
</b>
Notice that the original columns from each data frame appear in the final data frame in the order that we specified them in the <b>bind_cols()</b> function.
 How to Use rbind in R 
 How to Use cbind in R 
The following tutorials explain how to perform other common functions in dplyr:
 How to Add Columns to Data Frame in R Using dplyr 
 How to Rename Column by Index Position Using dplyr 
 How to Remove Rows Using dplyr (With Examples) 
<h2><span class="orange">How to Use case_when() in dplyr</span></h2>
The <b>case_when()</b> function from the  dplyr  package in R can be used to create new variables from existing variables.
This function uses the following basic syntax:
<b>library(dplyr)
df %>%
  mutate(new_var = case_when(var1 &lt; 15 ~ 'low',             var2 &lt; 25 ~ 'med',             TRUE ~ 'high'))
</b>
Note that <b>TRUE</b> is equivalent to an “else” statement.
The following examples show how to use this function in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(player = c('AJ', 'Bob', 'Chad', 'Dan', 'Eric', 'Frank'), position = c('G', 'F', 'F', 'G', 'C', NA), points = c(12, 15, 19, 22, 32, NA), assists = c(5, 7, 7, 12, 11, NA))
#view data frame
df
  player position points assists
1     AJ        G     12       5
2    Bob        F     15       7
3   Chad        F     19       7
4    Dan        G     22      12
5   Eric        C     32      11
6  Frank       NA     NA      NA</b>
<h3>Example 1: Create New Variable from One Existing Variable</h3>
The following code shows how to create a new variable called <b>quality</b> whose values are derived from the <b>points</b> column:
<b>df %>%
  mutate(quality = case_when(points > 20 ~ 'high',             points > 15 ~ 'med',             TRUE ~ 'low' ))
  player position points assists quality
1     AJ        G     12       5     low
2    Bob        F     15       7     low
3   Chad        F     19       7     med
4    Dan        G     22      12    high
5   Eric        C     32      11    high
6  Frank       NA     NA      NA     low
</b>
Here is exactly how the <b>case_when()</b> function created the values for the new column:
If the value in the points column is greater than 20, then the value in the quality column is “high”
Else, if the value in the points column is greater than 15, then the value in the quality column is “med”
Else, if the value in the points column is less than or equal to 15 (or a missing value like NA), then the value in the quality column is “low”
<h3>Example 2: Create New Variable from Multiple Variables</h3>
The following code shows how to create a new variable called <b>quality</b> whose values are derived from both the <b>points</b> and <b>assists</b> column:
<b>df %>%
  mutate(quality = case_when(points > 15 & assists > 10 ~ 'great',             points > 15 & assists > 5 ~ 'good',             TRUE ~ 'average' ))
  player position points assists quality
1     AJ        G     12       5 average
2    Bob        F     15       7 average
3   Chad        F     19       7    good
4    Dan        G     22      12   great
5   Eric        C     32      11   great
6  Frank       NA     NA      NA average
</b>
Note that we can also use the <b>is.na()</b> function to explicitly assign strings to NA values:
<b>df %>%
  mutate(quality = case_when(is.na(points) ~ 'missing',             points > 15 & assists > 10 ~ 'great',             points > 15 & assists > 5 ~ 'good',             TRUE ~ 'average' ))
  player position points assists quality
1     AJ        G     12       5 average
2    Bob        F     15       7 average
3   Chad        F     19       7    good
4    Dan        G     22      12   great
5   Eric        C     32      11   great
6  Frank       NA     NA      NA missing</b>
<h2><span class="orange">How to Use the coalesce() Function in dplyr (With Examples)</span></h2>
You can use the <b>coalesce()</b> function from the  dplyr  package in R to return the first non-missing value in each position of one or more vectors.
There are two common ways to use this function:
<b>Method 1: Replace Missing Values in Vector</b>
<b>library(dplyr)
#replace missing values with 100
coalesce(x, 100)
</b>
<b>Method 2: Return First Non-Missing Value Across Data Frame Columns</b>
<b>library(dplyr)
#return first non-missing value at each position across columns A and B
coalesce(df$A, df$B)</b>
The following examples show how to each method in practice.
<h2>Example 1: Use coalesce() to Replace Missing Values in Vector</h2>
The following code shows how to use the <b>coalesce()</b> function to replace all missing values in a vector with a value of 100:
<b>library(dplyr)
#create vector of values
x &lt;- c(4, NA, 12, NA, 5, 14, 19)
#replace missing values with 100
coalesce(x, 100)
[1]   4 100  12 100   5  14  19
</b>
Notice that each <b>NA</b> value in the original vector has been replaced with a value of <b>100</b>.
<h2>
<b>Example 2: Use coalesce() to Return First Non-Missing Value Across Data Frame Columns</b>
</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(A=c(10, NA, 5, 6, NA, 7, NA), B=c(14, 9, NA, 3, NA, 10, 4))
#view data frame
df
   A  B
1 10 14
2 NA  9
3  5 NA
4  6  3
5 NA NA
6  7 10
7 NA  4
</b>
The following code shows how to use the <b>coalesce()</b> function to return the first non-missing value across columns A and B in the data frame:
<b>library(dplyr)
#create new column that coalesces values from columns A and B
df$C &lt;- coalesce(df$A, df$B)
#view updated data frame
df
   A  B  C
1 10 14 10
2 NA  9  9
3  5 NA  5
4  6  3  6
5 NA NA NA
6  7 10  7
7 NA  4  4</b>
The resulting column C contains the first non-missing value across columns A and B.
Notice that row 5 has a value of NA in column C since columns A and B both had NA values in that row.
We can simply add one more value to the<b> coalesce()</b> function to use as the value if there happen to be NA values in each column:
<b>library(dplyr)
#create new column that coalesces values from columns A and B
df$C &lt;- coalesce(df$A, df$B, 100)
#view updated data frame
df
   A  B   C
1 10 14  10
2 NA  9   9
3  5 NA   5
4  6  3   6
5 NA NA 100
6  7 10   7
7 NA  4   4
</b>
Notice that the NA value in row 5 of column C has now been replaced by a value of <b>100</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions using dplyr:
 How to Remove Rows Using dplyr 
 How to Arrange Rows Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
<h2><span class="orange">How to Count Distinct Values Using dplyr (With Examples)</span></h2>
You can use one of the following methods to count the number of distinct values in an R data frame using the <b>n_distinct()</b> function from  dplyr :
<b>Method 1: Count Distinct Values in One Column</b>
<b>n_distinct(df$column_name)
</b>
<b>Method 2: Count Distinct Values in All Columns</b>
<b>sapply(df, function(x) n_distinct(x))</b>
<b>Method 3: Count Distinct Values by Group</b>
<b>df %>%</b>
<b>  group_by(grouping_column) %>%</b>
<b>  summarize(count_distinct = n_distinct(values_column))</b>
The following examples show how to use each of these methods in practice with the following data frame:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(6, 6, 8, 10, 9, 9, 12, 12), assists=c(3, 6, 4, 2, 4, 5, 5, 9))
#view data frame
df
  team points assists
1    A      6       3
2    A      6       6
3    A      8       4
4    A     10       2
5    B      9       4
6    B      9       5
7    B     12       5
8    B     12       9
</b>
<h3>Method 1: Count Distinct Values in One Column</h3>
The following code shows how to use <b>n_distinct()</b> to count the number of distinct values in the ‘team’ column:
<b>#count distinct values in 'team' column
n_distinct(df$team)
[1] 2
</b>
There are <b>2</b> distinct values in the ‘team’ column.
<h3>Method 2: Count Distinct Values in All Columns</h3>
The following code shows how to use the <b>sapply()</b> and <b>n_distinct()</b> functions to count the number of distinct values in each column of the data frame:
<b>#count distinct values in every column
sapply(df, function(x) n_distinct(x))
   team  points assists 
      2       5       6</b>
From the output we can see:
There are <b>2</b> distinct values in the ‘team’ column
There are <b>5</b> distinct values in the ‘points’ column
There are <b>6</b> distinct values in the ‘assists’ column
<h3>Method 3: Count Distinct Values by Group</h3>
The following code shows how to use the <b>n_distinct()</b> function to count the number of distinct values by group:
<b>#count distinct 'points' values by 'team'
df %>%
  group_by(team) %>%
  summarize(distinct_points = n_distinct(points))
# A tibble: 2 x 2
  team  distinct_points 
1 A                   3
2 B                   2
</b>
From the output we can see:
There are <b>3</b> distinct points values for team A.
There are <b>2</b> distinct points values for team B.
<h2><span class="orange">How to Create a Crosstab Using dplyr (With Examples)</span></h2>
You can use the following basic syntax to produce a crosstab using functions from the  dplyr  and  tidyr  packages in R:
<b>df %>%
  group_by(var1, var2) %>%
  tally() %>%
  spread(var1, n)
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Create Basic Crosstab</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'C', 'G', 'F', 'F', 'C'), points=c(7, 7, 8, 11, 13, 15, 19, 13))
#view data frame
df
  team position points
1    A        G      7
2    A        G      7
3    A        F      8
4    A        C     11
5    B        G     13
6    B        F     15
7    B        F     19
8    B        C     13
</b>
We can use the following syntax to create a crosstab for the ‘team’ and ‘position’ variables:
<b>library(dplyr)
library(tidyr)
#produce crosstab </b>
<b>df %>%</b>
<b>  group_by(team, position) %>%</b>
<b>  tally() %>%</b>
<b>  spread(team, n)
# A tibble: 3 x 3
  position     A     B
1 C            1     1
2 F            1     2
3 G            2     1
</b>
Here’s how to interpret the values in the crosstab:
There is <b>1</b> player who has a position of ‘C’ and belongs to team ‘A’
There is <b>1</b> player who has a position of ‘C’ and belongs to team ‘B’
There is <b>1</b> player who has a position of ‘F’ and belongs to team ‘A’
There are <b>2</b> players who have a position of ‘F’ and belong to team ‘B’
There are <b>2</b> players who have a position of ‘G’ and belong to team ‘A’
There is <b>1</b> player who has a position of ‘G’ and belongs to team ‘B’
Note that we can switch the rows and columns of the crosstab by switching the variable used in the <b>spread()</b> function:
<b>library(dplyr)
library(tidyr)
#produce crosstab with 'position' along columns</b>
<b>df %>%</b>
<b>  group_by(team, position) %>%</b>
<b>  tally() %>%</b>
<b>  spread(position, n)
# A tibble: 2 x 4
# Groups:   team [2]
  team      C     F     G     
1 A         1     1     2
2 B         1     2     1
</b>
<b>Related:</b>  How to Use Spread Function in tidyr 
Additional Resources</b>
The following tutorials explain how to perform other common functions in dplyr:
 How to Calculate Relative Frequencies Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Remove Rows Using dplyr 
<h2><span class="orange">How to Calculate a Cumulative Sum Using dplyr</span></h2>
You can use the following methods to calculate the cumulative sum of a column in R using the  dplyr  package:
<b>Method 1: Calculate Cumulative Sum of One Column</b>
<b>df %>% mutate(cum_sum = cumsum(var1))
</b>
<b>Method 2: Calculate Cumulative Sum by Group</b>
<b>df %>% group_by(var1) %>% mutate(cum_sum = cumsum(var2))
</b>
The following examples show how to use each method in practice.
<h3>Example 1: Calculate Cumulative Sum Using dplyr</h3>
Suppose we have the following data frame in R:
<b>#create dataset
df &lt;- data.frame(day=c(1, 2, 3, 4, 5, 6, 7, 8), sales=c(7, 12, 10, 9, 9, 11, 18, 23))
#view dataset
df
  day sales
1   1     7
2   2    12
3   3    10
4   4     9
5   5     9
6   6    11
7   7    18
8   8    23
</b>
We can use the following code to create a new column that contains the cumulative sum of the values in the ‘sales’ column:
<b>library(dplyr)
#calculate cumulative sum of sales
df %>% mutate(cum_sales = cumsum(sales))
  day sales cum_sales
1   1     7         7
2   2    12        19
3   3    10        29
4   4     9        38
5   5     9        47
6   6    11        58
7   7    18        76
8   8    23        99
</b>
<h3>Example 2: Calculate Cumulative Sum by Group Using dplyr</h3>
Suppose we have the following data frame in R:
<b>#create dataset
df &lt;- data.frame(store=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), day=c(1, 2, 3, 4, 1, 2, 3, 4), sales=c(7, 12, 10, 9, 9, 11, 18, 23))
#view dataset
df
  store day sales
1     A   1     7
2     A   2    12
3     A   3    10
4     A   4     9
5     B   1     9
6     B   2    11
7     B   3    18
8     B   4    23</b>
We can use the following code to create a new column that contains the cumulative sum of the values in the ‘sales’ column, grouped by the ‘store’ column:
<b>library(dplyr)
#calculate cumulative sum of sales by store
df %>% group_by(store) %>% mutate(cum_sales = cumsum(sales))
# A tibble: 8 x 4
# Groups:   store [2]
  store   day sales cum_sales   
1 A         1     7         7
2 A         2    12        19
3 A         3    10        29
4 A         4     9        38
5 B         1     9         9
6 B         2    11        20
7 B         3    18        38
8 B         4    23        61
</b>
<h2><span class="orange">How to Select Columns that Do Not Start with String in dplyr</span></h2>
You can use the following functions from the  dplyr  package in R to select columns that do not start with a specific string:
<b>Method 1: Select Columns that Do Not Start with One Specific String</b>
<b>df %>%
  select(-starts_with("string1"))
</b>
<b>Method 2: Select Columns that Do Not Start with One of Several Strings</b>
<b>df %>%
  select(-starts_with(c("string1", "string2", "string3")))</b>
The following examples show how to use each of these methods in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(store1_sales=c(12, 10, 14, 19, 22, 25, 29), store1_returns=c(3, 3, 2, 4, 3, 2, 1), store2_sales=c(8, 8, 12, 14, 15, 13, 12), store2_returns=c(1, 2, 2, 1, 2, 1, 3), promotions=c(0, 1, 1, 1, 0, 0, 1))
#view data frame
df
  store1_sales store1_returns store2_sales store2_returns promotions
1           12              3            8              1          0
2           10              3            8              2          1
3           14              2           12              2          1
4           19              4           14              1          1
5           22              3           15              2          0
6           25              2           13              1          0
7           29              1           12              3          1
</b>
<h2>Example 1: Select Columns that Do Not Start with One Specific String</h2>
The following code shows how to use the <b>-starts_with()</b> function to select only the columns that do not start with “store1” in the data frame:
<b>library(dplyr)
#select all columns that do not start with "store1"
df %>%
  select(-starts_with("store1"))
  store2_sales store2_returns promotions
1            8              1          0
2            8              2          1
3           12              2          1
4           14              1          1
5           15              2          0
6           13              1          0
7           12              3          1</b>
Notice that the two columns that start with “store1” are not returned.
<h2>Example 2: Select Columns that Do Not Start with One of Several Strings</h2>
The following code shows how to use the <b>-starts_with()</b> function to select only the columns that do not start with “store1” or “prom” in the data frame:
<b>library(dplyr)
#select all columns that do not start with "store1" or "prom"
df %>%
  select(-starts_with(c("store1", "prom")))
  store2_sales store2_returns
1            8              1
2            8              2
3           12              2
4           14              1
5           15              2
6           13              1
7           12              3</b>
Notice that any columns that start with “store1” or “prom” are not returned.
<b>Note</b>: By default, the <b>starts_with()</b> function is case-insensitive. To make the function case-sensitive, use the <b>ignore.case=FALSE</b> argument within the function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Select Columns by Name Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Use select_if with Multiple Conditions in dplyr 
<h2><span class="orange">How to Drop Multiple Columns Using dplyr (With Examples)</span></h2>
You can use one of the following methods to drop multiple columns from a data frame in R using the <b>dplyr</b> package:
<b>1. Drop Multiple Columns by Name</b>
<b>df_new &lt;- df %>% select(-c(col2, col4))</b>
<b>2. Drop All Columns in Range</b>
<b>df_new &lt;- df %>% select(-c(col2:col4))</b>
The following examples show how to use each of these methods in practice with the following data frame:
<b>#create data frame
df = data.frame(rating = c(90, 85, 82, 88, 94, 90, 76, 75, 87, 86),
                points=c(25, 20, 14, 16, 27, 20, 12, 15, 14, 19),
                assists=c(5, 7, 7, 8, 5, 7, 6, 9, 9, 5),
                rebounds=c(11, 8, 10, 6, 6, 9, 6, 10, 10, 7))
#view data frame
df
   rating points assists rebounds
1      90     25       5       11
2      85     20       7        8
3      82     14       7       10
4      88     16       8        6
5      94     27       5        6
6      90     20       7        9
7      76     12       6        6
8      75     15       9       10
9      87     14       9       10
10     86     19       5        7</b>
<h2>Example 1: Drop Multiple Columns by Name</h2>
The following code shows how to drop the columns named <b>points</b> and <b>rebounds</b> from the data frame:
<b>library(dplyr)
#drop points and rebounds columns
df_new &lt;- df %>% select(-c(points, rebounds))
#view new data frame
new_df
   rating assists
1      90       5
2      85       7
3      82       7
4      88       8
5      94       5
6      90       7
7      76       6
8      75       9
9      87       9
10     86       5</b>
Notice that the columns named <b>points</b> and <b>rebounds</b> have both been dropped from the new data frame.
<h2>Example 2: Drop All Columns in Range</h2>
The following code shows how to drop all columns in the range between the <b>points</b> and <b>rebounds</b> columns:
<b>library(dplyr)
#drop all columns between points and rebounds
df_new &lt;- df %>% select(-c(points:rebounds))
#view new data frame
new_df
   rating
1      90
2      85
3      82
4      88
5      94
6      90
7      76
8      75
9      87
10     86</b>
Notice that all columns between <b>points</b> and <b>rebounds</b> have been dropped from the new data frame.
<b>Note</b>: The <b>MASS</b> package in R also has a <b>select()</b> function. If this package is also loaded, you should use <b>dplyr::select()</b> so that R knows to use the <b>select()</b> function from the <b>dplyr</b> package.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions in dplyr:
 How to Select Columns by Index Using dplyr 
 How to Rename Multiple Columns Using dplyr 
 How to Replace String in Column Using dplyr 
<h2><span class="orange">How to Fix in R: error in select unused arguments</span></h2>
One error you may encounter in R is:
<b>Error in select(., cyl, mpg) : unused arguments (cyl, mpg) 
</b>
This error occurs when you attempt to use the <b>select()</b> function from the <b>dplyr</b> package in R but also have the <b>MASS</b> package loaded.
When this occurs, R attempts to use the select() function from the MASS package instead and an error is produced.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to run the following code to summarize a variable in the mtcars dataset in R:
<b>library(dplyr)
library(MASS)
#find average mpg grouped by 'cyl'
mtcars %>%
  select(cyl, mpg) %>%
  group_by(cyl) %>%
  summarize(avg_mpg = mean(mpg))
Error in select(., cyl, mpg) : unused arguments (cyl, mpg)
</b>
An error occurs because the select() function from the MASS package clashes with the select() function from the dplyr package.
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to explicitly tell R to use the select() function from the dplyr package by using the following code:
<b>library(dplyr)
library(MASS)
#find average mpg grouped by 'cyl'
mtcars %>%
  dplyr::select(cyl, mpg) %>%
  group_by(cyl) %>%
  summarize(avg_mpg = mean(mpg))
# A tibble: 3 x 2
    cyl avg_mpg
1     4    26.7
2     6    19.7
3     8    15.1
</b>
The code successfully runs because <b>dplyr::select</b> explicitly tells R to use the select() function from the dplyr package instead of the MASS package.
<h2><span class="orange">How to Filter by Row Number Using dplyr</span></h2>
You can use the following methods to filter a data frame by row number using the <b>slice</b> function from the  dplyr  package:
<b>Method 1: Filter by Specific Row Numbers</b>
<b>df %>% slice(2, 3, 8)
</b>
This will return row numbers 2, 3, and 8.
<b>Method 2: Filter by Range of Row Numbers</b>
<b>df %>% slice(2:5)
</b>
This will return rows 2 through 5.
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'), points=c(10, 10, 8, 6, 15, 15, 12, 12), rebounds=c(8, 8, 4, 3, 10, 11, 7, 7))
#view data frame
df
  team points rebounds
1    A     10        8
2    B     10        8
3    C      8        4
4    D      6        3
5    E     15       10
6    F     15       11
7    G     12        7
8    H     12        7</b>
<h3>Example 1: Filter by Specific Row Numbers</h3>
We can use the following code to filter for rows 2, 3, and 8:
<b>library(dplyr)
#filter for only rows 2, 3, and 8
df %>% slice(2, 3, 8)
  team points rebounds
1    B     10        8
2    C      8        4
3    H     12        7
</b>
Notice that only rows <b>2</b>, <b>3</b>, and <b>8</b> are returned from the original data frame.
<h3>Example 2: Filter By Range of Row Numbers</h3>
We can use the following code to filter for rows between 2 and 5:
<b>library(dplyr)
#filter for rows between 2 and 5
df %>% slice(2:5)
  team points rebounds
1    B     10        8
2    C      8        4
3    D      6        3
4    E     15       10
</b>
Notice that only the rows between <b>2</b> and <b>5</b> are returned from the original data frame.
<b>Note</b>: You can find the complete documentation for the <b>slice </b>function in dplyr  here .
<h2><span class="orange">How to Filter by Date Using dplyr</span></h2>
You can use the following methods to filter a data frame by dates in R using the  dplyr  package:
<b>Method 1: Filter Rows After Date</b>
<b>df %>% filter(date_column > '2022-01-01')
</b>
<b>Method 2: Filter Rows Before Date</b>
<b>df %>% filter(date_column &lt; '2022-01-01') 
</b>
<b>Method 3: Filter Rows Between Two Dates</b>
<b>df %>% filter(between(date_column, as.Date('2022-01-20'), as.Date('2022-02-20')))
</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(day=seq(as.Date('2022-01-01'), by = 'week', length.out=10), sales=c(40, 35, 39, 44, 48, 51, 23, 29, 60, 65))
#view data frame
df
          day sales
1  2022-01-01    40
2  2022-01-08    35
3  2022-01-15    39
4  2022-01-22    44
5  2022-01-29    48
6  2022-02-05    51
7  2022-02-12    23
8  2022-02-19    29
9  2022-02-26    60
10 2022-03-05    65
</b>
<h3>Example 1: Filter Rows After Date</h3>
We can use the following code to filter for the rows in the data frame that have a date after 1/25/2022:
<b>library(dplyr)
#filter for rows with date after 1/25/2022
df %>% filter(day > '2022-01-25')
         day sales
1 2022-01-29    48
2 2022-02-05    51
3 2022-02-12    23
4 2022-02-19    29
5 2022-02-26    60
6 2022-03-05    65
</b>
Each of the rows in the resulting data frame have a date after 1/25/2022.
<h3>Example 2: Filter Rows Before Date</h3>
We can use the following code to filter for the rows in the data frame that have a date before 1/25/2022:
<b>library(dplyr)
#filter for rows with date before 1/25/2022
df %>% filter(day &lt; '2022-01-25')
         day sales
1 2022-01-01    40
2 2022-01-08    35
3 2022-01-15    39
4 2022-01-22    44
</b>
Each of the rows in the resulting data frame have a date before 1/25/2022.
<h3>Example 3: Filter Rows Between Two Dates</h3>
We can use the following code to filter for the rows in the data frame that have a date between 1/20/2022 and 2/20/2022:
<b>library(dplyr)
#filter for rows with dates between 1/20/2022 and 2/20/2022
df %>% filter(between(date_column, as.Date('2022-01-20'), as.Date('2022-02-20'))) 
         day sales
1 2022-01-22    44
2 2022-01-29    48
3 2022-02-05    51
4 2022-02-12    23
5 2022-02-19    29
</b>
Each of the rows in the resulting data frame have a date between 1/20/2022 and 2/20/2022.
<b>Note #1</b>: If any of the methods above don’t work, then you may need to first convert the dates you’re working with to a recognizable date format using the <b>as.Date()</b> function.
<b>Note #2</b>: You can find the complete documentation for the <b>filter</b> function in dplyr  here .
<h2><span class="orange">How to Filter by Multiple Conditions Using dplyr</span></h2>
You can use the following syntax to filter data frames by multiple conditions using the  dplyr  library:
<b>Method 1: Filter by Multiple Conditions Using OR</b>
<b>library(dplyr)
df %>%
  filter(col1 == 'A' | col2 > 90)
</b>
<b>Method 2: Filter by Multiple Conditions Using AND</b>
<b>library(dplyr)
df %>%
  filter(col1 == 'A' & col2 > 90)</b>
The following example shows how to use these methods in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    B     86      31       24
4    B     88      39       24
5    C     95      34       28
</b>
<h3>Method 1: Filter by Multiple Conditions Using OR</h3>
The following code shows how to use the or ( <b>|</b> ) operator to filter the data frame by rows that meet one of multiple conditions:
<b>library(dplyr)
#filter for rows where team is equal to 'A' or points is greater than 90
df %>%
  filter(team == 'A' | points > 90)
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    C     95      34       28
</b>
The only rows returned are those where the team is equal to ‘A’ <b>or</b> where points is greater than 90.
Note that we can use as many “or” operators as we’d like in the filter function:
<b>library(dplyr)
#filter for rows where team is equal to 'A' or 'C' or points is less than 89
df %>%
  filter(team == 'A' | team == 'C' | points > 90)
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    B     86      31       24
4    C     95      34       28</b>
<h3>Method 2: Filter by Multiple Conditions Using AND</h3>
The following code shows how to use the and ( <b>&</b> ) operator to filter the data frame by rows that meet several conditions:
<b>library(dplyr)
#filter for rows where team is equal to 'A' and points is greater than 90
df %>%
  filter(team == 'A' & points > 90)
  team points assists rebounds
1    A     99      33       30
</b>
Only one row met both conditions in the filter function.
Note that we can also use as many “and” operators as we’d like in the filter function:
<b>library(dplyr)
#filter where team is equal to 'A' and points > 89 and assists &lt; 30
df %>%
  filter(team == 'A' & points > 89 & assists &lt; 30)
  team points assists rebounds
1    A     90      28       28</b>
<b>Note</b>: You can find the complete documentation for the dplyr <b>filter()</b> function  here .
<h2><span class="orange">dplyr: How to Use a “not in” Filter</span></h2>
You can use the following basic syntax in  dplyr  to filter for rows in a data frame that are not in a list of values:
<b>df %>%
  filter(!col_name %in% c('value1', 'value2', 'value3', ...))
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Filter for Rows that Do Not Contain Value in One Column</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'), position=c('G', 'G', 'F', 'G', 'F', 'C', 'C', 'C'), points=c(12, 14, 19, 24, 36, 41, 18, 29))
#view data frame
df
  team position points
1    A        G     12
2    A        G     14
3    B        F     19
4    B        G     24
5    C        F     36
6    C        C     41
7    D        C     18
8    D        C     29
</b>
The following syntax shows how to filter for rows where the team name is not equal to ‘A’ or ‘B’:
<b>#filter for rows where team name is not 'A' or 'B'
df %>%
  filter(!team %in% c('A', 'B'))
  team position points
1    C        F     36
2    C        C     41
3    D        C     18
4    D        C     29</b>
<h3>Example 2: Filter for Rows that Do Not Contain Value in Multiple Columns</h3>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'), position=c('G', 'G', 'F', 'G', 'F', 'C', 'C', 'C'), points=c(12, 14, 19, 24, 36, 41, 18, 29))
#view data frame
df
  team position points
1    A        G     12
2    A        G     14
3    B        F     19
4    B        G     24
5    C        F     36
6    C        C     41
7    D        C     18
8    D        C     29
</b>
The following syntax shows how to filter for rows where the team name is not equal to ‘A’ <em>and</em> where the position is not equal to ‘C’:
<b>#filter for rows where team name is not 'A' and position is not 'C'
df %>%
  filter(!team %in% c('A') & !position %in% c('C'))
  team position points
1    B        F     19
2    B        G     24
3    C        F     36</b>
<h2><span class="orange">How to Filter for Unique Values Using dplyr</span></h2>
You can use the following methods to filter for unique values in a data frame in R using the  dplyr  package:
<b>Method 1: Filter for Unique Values in One Column</b>
<b>df %>% distinct(var1)
</b>
<b>Method 2: Filter for Unique Values in Multiple Columns</b>
<b>df %>% distinct(var1, var2)
</b>
<b>Method 3: Filter for Unique Values in All Columns</b>
<b>df %>% distinct()
</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(10, 10, 8, 6, 15, 15, 12, 12), rebounds=c(8, 8, 4, 3, 10, 11, 7, 7))
#view data frame
df
  team points rebounds
1    A     10        8
2    A     10        8
3    A      8        4
4    A      6        3
5    B     15       10
6    B     15       11
7    B     12        7
8    B     12        7
</b>
<h3>Example 1: Filter for Unique Values in Column</h3>
We can use the following code to filter for unique values in just the <b>team</b> column:
<b>library(dplyr)
#select only unique values in team column
df %>% distinct(team)
  team
1    A
2    B
</b>
Notice that only the unique values in the <b>team</b> column are returned.
<h3>Example 2: Filter for Unique Values in Multiple Columns</h3>
We can use the following code to filter for unique values in the <b>team</b> and <b>points</b> columns:
<b>library(dplyr)
#select unique values in team and points columns
df %>% distinct(team, points)
  team points
1    A     10
2    A      8
3    A      6
4    B     15
5    B     12
</b>
Notice that only the unique values in the <b>team</b> and <b>points</b> columns are returned.
<h3>Example 3: Filter for Unique Values in All Columns</h3>
We can use the following code to filter for unique values across all columns in the data frame:
<b>library(dplyr)
#select unique values across all columns
df %>% distinct()
  team points rebounds
1    A     10        8
2    A      8        4
3    A      6        3
4    B     15       10
5    B     15       11
6    B     12        7
</b>
Notice that the unique values across all three columns are returned.
<b>Note</b>: You can find the complete documentation for the <b>distinct </b>function in dplyr  here .
<h2><span class="orange">How to Find Duplicate Elements Using dplyr</span></h2>
You can use the following methods to find duplicate elements in a data frame using dplyr:
<b>Method 1: Display All Duplicate Rows</b>
<b>library(dplyr)
#display all duplicate rows
df %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()</b>
<b>Method 2: Display Duplicate Count for All Duplicated Rows</b>
<b>library(dplyr)
#display duplicate count for all duplicated rows
df %>%
  add_count(col1, col2, col3) %>%
  filter(n>1) %>%
  distinct()
</b>
This tutorial explains how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), position=c('G', 'G', 'F', 'F', 'G', 'G', 'F', 'F'), points=c(10, 10, 8, 14, 15, 15, 17, 17))
#view data frame
df
  team position points
1    A        G     10
2    A        G     10
3    A        F      8
4    A        F     14
5    B        G     15
6    B        G     15
7    B        F     17
8    B        F     17
</b>
<h2>Example 1: Display All Duplicate Rows</h2>
The following code shows how to display all duplicate rows in the data frame:
<b>library(dplyr)
#display all duplicate rows in data frame
df %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
# A tibble: 6 x 3
  team  position points
        
1 A     G            10
2 A     G            10
3 B     G            15
4 B     G            15
5 B     F            17
6 B     F            17</b>
The result is a data frame that contains 6 rows, each of which is a duplicated row.
<b>Note</b>: If you only want to know which rows have duplicate values across specific columns, you could use something like <b>group_by(team)</b> instead to find rows that have duplicate values in the <b>team</b> column only.
<h2>Example 2: Display Duplicate Count for All Duplicated Rows</h2>
The following code shows how to display the duplicate count for all of the duplicated rows in the data frame:
<b>library(dplyr)
#display duplicate count for each row
df %>%
  add_count(team, position, points) %>%
  filter(n>1) %>%
  distinct()
  team position points n
1    A        G     10 2
2    B        G     15 2
3    B        F     17 2</b>
The <b>n</b> column displays the total number of duplicates for each row.
For example:
The row with values A, G, and 10 occurs <b>2</b> times in the data frame.
The row with values B, G, and 15 occurs <b>2</b> times in the data frame.
The row with values B, F, and 17 occurs <b>2</b> times in the data frame.
<b>Note</b>: If you only want to know which rows have duplicate values across specific columns, then only include those specific columns within the <b>add_count()</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter for Unique Values Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Count Number of Occurrences in Columns in R 
<h2><span class="orange">How to Group By and Filter Data Using dplyr</span></h2>
You can use the following basic syntax to group by and filter data using the dplyr package in R:
<b>df %>%
  group_by(team) %>%
  filter(any(points == 10))
</b>
This particular syntax groups a data frame by the column called <b>team</b> and filters for only the groups where at least one value in the <b>points</b> column is equal to 10.
The following example shows how to use this syntax in practice.
<h2>Example: Group By and Filter Data Using dplyr</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), points=c(10, 15, 8, 4, 10, 10, 12, 12, 7))
#view data frame
df
  team points
1    A     10
2    A     15
3    A      8
4    B      4
5    B     10
6    B     10
7    C     12
8    C     12
9    C      7</b>
We can use the following code to group the data frame by the value in the <b>team</b> column and then filter out all groups that do not have at least one value in the <b>points</b> column equal to 10:
<b>library(dplyr)
#group by team and filter out teams where no points value is equal to 10
df %>%
  group_by(team) %>%
  filter(any(points == 10))
# A tibble: 6 x 2
# Groups:   team [2]
  team  points
    
1 A         10
2 A         15
3 A          8
4 B          4
5 B         10
6 B         10</b>
Notice that all rows where the <b>team</b> is equal to “C” are filtered out because there is no value in the <b>points</b> column for team “C “equal to 10.
Note that this is just one example of a filter that we could apply.
For example, we could apply another filter where we filter for teams where at least one value in the <b>points</b> column is greater than 13:
<b>library(dplyr)
#group by team and filter out teams where no points value is greater than 13
df %>%
  group_by(team) %>%
  filter(any(points > 13))
# A tibble: 3 x 2
# Groups:   team [1]
  team  points
    
1 A         10
2 A         15
3 A          8
</b>
Notice that only the rows where the <b>team</b> is equal to “A” are kept since this is the only team with at least one <b>points</b> value greater than 13.
<b>Note</b>: You can find the complete documentation for the <b>filter </b>function in dplyr  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in dplyr:
 How to Select the First Row by Group Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">How to Join Data Frames on Multiple Columns Using dplyr</span></h2>
You can use the following basic syntax to join data frames in R based on multiple columns using dplyr:
<b>library(dplyr)
left_join(df1, df2, by=c('x1'='x2', 'y1'='y2'))</b>
This particular syntax will perform a left join where the following conditions are true:
The value in the <b>x1</b> column of df1 matches the value in the <b>x2</b> column of df2.
The value in the <b>y1</b> column of df1 matches the value in the <b>y2</b> column of df2.
The following example shows how to use this syntax in practice.
<h2>Example: Join on Multiple Columns Using dplyr</h2>
Suppose we have the following two data frames in R:
<b>#define first data frame
df1 = data.frame(team=c('A', 'A', 'B', 'B'), pos=c('G', 'F', 'F', 'G'), points=c(18, 22, 19, 14))
df1
  team pos points
1    A   G     18
2    A   F     22
3    B   F     19
4    B   G     14
#define second data frame
df2 = data.frame(team_name=c('A', 'A', 'B', 'C', 'C'), position=c('G', 'F', 'F', 'G', 'F'), assists=c(4, 9, 8, 6, 5))
df2
  team_name position assists
1         A        G       4
2         A        F       9
3         B        F       8
4         C        G       6
5         C        F       5</b>
We can use the following syntax in dplyr to perform a left join based on two columns:
<b>library(dplyr)
#perform left join based on multiple columns
df3 &lt;- left_join(df1, df2, by=c('team'='team_name', 'pos'='position'))
#view result
df3
  team pos points assists
1    A   G     18       4
2    A   F     22       9
3    B   F     19       8
4    B   G     14      NA</b>
The resulting data frame contains all rows from <b>df1</b> and only the rows in <b>df2</b> where the team and position values matched.
Also note that if the two data frames share the same column names, you can simply use the following syntax to join on multiple columns:
<b>library(dplyr)
#perform left join based on multiple columns
df3 &lt;- left_join(df1, df2, by=c('team', 'position'))</b>
<h2><span class="orange">How to Calculate Lag by Group Using dplyr</span></h2>
You can use the following syntax to calculate lagged values by group in R using the  dplyr  package:
<b>df %>%
  group_by(var1) %>%
  mutate(lag1_value = lag(var2, n=1, order_by=var1))
</b>
<b>Note</b>: The  mutate()  function adds a new variable to the data frame that contains the lagged values.
The following example shows how to use this syntax in practice.
<h3>Example: Calculate Lagged Values by Group Using dplyr</h3>
Suppose we have the following data frame in R that shows the sales made by two different stores during various days:
<b>#create data frame
df &lt;- data.frame(store=c('A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'), sales=c(7, 12, 10, 9, 9, 11, 18, 23))
#view data frame
df
  store sales
1     A     7
2     B    12
3     A    10
4     B     9
5     A     9
6     B    11
7     A    18
8     B    23</b>
We can use the following code to create a new column that shows the lagged values of sales for each store:
<b>library(dplyr)
#calculate lagged sales by group
df %>%
  group_by(store) %>%
  mutate(lag1_sales = lag(sales, n=1, order_by=store))
# A tibble: 8 x 3
# Groups:   store [2]
  store sales lag1_sales
1 A         7         NA
2 B        12         NA
3 A        10          7
4 B         9         12
5 A         9         10
6 B        11          9
7 A        18          9
8 B        23         11</b>
 Here’s how to interpret the output:
The first value of <b>lag1_sales</b> is <b>NA</b> because there is no previous value for sales for store A.
The second value of <b>lag1_sales</b> is <b>NA</b> because there is no previous value for sales for store B.
The third value of <b>lag1_sales</b> is <b>7 </b>because this is the previous value for sales for store A.
The fourth value of <b>lag1_sales</b> is <b>12 </b>because this is the previous value for sales for store B.
And so on.
Note that you can also change the number of lags used by modifying the value for <b>n</b> in the <b>lag()</b> function.
<h2><span class="orange">dplyr: How to Change Factor Levels Using mutate()</span></h2>
You can use the following basic syntax in  dplyr  to change the levels of a factor variable by using the <b>mutate()</b> function:
<b>library(dplyr)
df &lt;- df %>% mutate(team=recode(team,                'H' = 'Hawks',                'M' = 'Mavs',                'C' = 'Cavs'))
</b>
This particular syntax makes the following changes to the <b>team</b> variable in the data frame:
‘H’ becomes ‘Hawks’
‘M’ becomes ‘Mavs’
‘C’ becomes ‘Cavs’
The following example shows how to use this syntax in practice.
<h2>Example: Change Factor Levels Using mutate()</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(team=factor(c('H', 'H', 'M', 'M', 'C', 'C')), points=c(22, 35, 19, 15, 29, 23))
#view data frame
df
  team points
1    H     22
2    H     35
3    M     19
4    M     15
5    C     29
6    C     23
</b>
We can use the following syntax with the <b>mutate()</b> function from the <b>dplyr</b> package to change the levels of the <b>team</b> variable:
<b>library(dplyr)
#change factor levels of team variable
df &lt;- df %>% mutate(team=recode(team,                'H' = 'Hawks',                'M' = 'Mavs',                'C' = 'Cavs'))
#view updated data frame
df
   team points
1 Hawks     22
2 Hawks     35
3  Mavs     19
4  Mavs     15
5  Cavs     29
6  Cavs     23
</b>
Using this syntax, we were able to make the following changes to the <b>team</b> variable in the data frame:
‘H’ becomes ‘Hawks’
‘M’ becomes ‘Mavs’
‘C’ becomes ‘Cavs’
We can verify that the factor levels have been changed by using the <b>levels()</b> function:
<b>#display factor levels of team variable
levels(df$team)
[1] "Cavs"  "Hawks" "Mavs" 
</b>
Also note that you can choose to change just one factor level instead of all of them.
For example, we can use the following syntax to only change ‘H’ to ‘Hawks’ and leave the other factor levels unchanged:
<b>library(dplyr)
#change one factor level of team variable
df &lt;- df %>% mutate(team=recode(team, 'H' = 'Hawks'))
#view updated data frame
df
   team points
1 Hawks     22
2 Hawks     35
3     M     19
4     M     15
5     C     29
6     C     23
</b>
Notice that ‘H’ has been changed to ‘Hawks’ but the other two factor levels remained unchanged.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in dplyr:
 How to Remove Rows Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">dplyr: How to Mutate Variable if Column Contains String</span></h2>
You can use the following basic syntax in  dplyr  to mutate a variable if a column contains a particular string:
<b>library(dplyr)
df %>% mutate_at(vars(contains('starter')), ~ (scale(.) %>% as.vector))
</b>
This particular syntax applies the <b>scale()</b> function to each variable in the data frame that contains the string ‘starter’ in the column name.
The following example shows how to use this syntax in practice.
<h2>Example: Mutate Variable if Column Contains String</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F'), starter_points=c(22, 26, 25, 13, 15, 22), starter_assists=c(4, 5, 10, 14, 12, 10), bench_points=c(7, 7, 9, 14, 13, 10), bench_assists=c(2, 5, 5, 4, 9, 14))
#view data frame
df
  team starter_points starter_assists bench_points bench_assists
1    A             22               4            7             2
2    B             26               5            7             5
3    C             25              10            9             5
4    D             13              14           14             4
5    E             15              12           13             9
6    F             22              10           10            14</b>
We can use the following syntax to apply the <b>scale()</b> function to each variable in the data frame that contains the string ‘starter’ in the column name.
<b>library(dplyr)
#apply scale() function to each variable that contains 'starter' in the name
df %>% mutate_at(vars(contains('starter')), ~ (scale(.) %>% as.vector))
  team starter_points starter_assists bench_points bench_assists
1    A      0.2819668      -1.3180158            7             2
2    B      1.0338784      -1.0629159            7             5
3    C      0.8459005       0.2125832            9             5
4    D     -1.4098342       1.2329825           14             4
5    E     -1.0338784       0.7227828           13             9
6    F      0.2819668       0.2125832           10            14
</b>
Using this syntax, we were able to apply the <b>scale()</b> function to scale each column that contained ‘starter’ such that their values now have a mean of 0 and standard deviation of 1.
Notice that the following columns were modified:
<b>starter_points</b>
<b>starter_assists</b>
All other columns remained unchanged.
Also note we can apply any function we’d like using this syntax.
In the previous example, we chose to scale each column with the string ‘starter’ in the name.
However, we could do something simpler such as multiply the values by two for each column with ‘starter’ in the name:
<b>library(dplyr)
#multiply values by two for each variable that contains 'starter' in the name
df %>% mutate_at(vars(contains('starter')), ~ (. * 2))
  team starter_points starter_assists bench_points bench_assists
1    A             44               8            7             2
2    B             52              10            7             5
3    C             50              20            9             5
4    D             26              28           14             4
5    E             30              24           13             9
6    F             44              20           10            14
</b>
Notice that the values in the <b>starter_points</b> and <b>starter_assists</b> columns have been multiplied by two, while all other columns have remained unchanged.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in dplyr:
 How to Remove Rows Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">How to Use the ntile() Function in dplyr (With Examples)</span></h2>
You can use the <b>ntile()</b> function from the  dplyr  package in R to break up an input vector into <em>n</em> buckets.
This function uses the following basic syntax:
<b>ntile(x, n)</b>
where:
<b>x</b>: Input vector
<b>n</b>: Number of buckets
<b>Note</b>: The size of the buckets can differ by up to one.
The following examples show how to use this function in practice.
<h2>Example 1: Use ntile() with a Vector</h2>
The following code shows how to use the <b>ntile()</b> function to break up a vector with 11 elements into 5 different buckets:
<b>library(dplyr)
#create vector
x &lt;- c(1, 3, 4, 6, 7, 8, 10, 13, 19, 22, 23)
#break up vector into 5 buckets
ntile(x, 5)
 [1] 1 1 1 2 2 3 3 4 4 5 5
</b>
From the output we can see that each element from the original vector has been placed into one of five buckets.
The smallest values are assigned to bucket 1 while the largest values are assigned to bucket 5.
For example:
The smallest values of 1, 3, and 4 are assigned to bucket <b>1</b>.
The largest values of 22 and 23 are assigned to bucket <b>5</b>.
<h2>Example 2: Use ntile() with a Data Frame</h2>
Suppose we have the following data frame in R that shows the points scored by various basketball players:
<b>#create data frame
df &lt;- data.frame(player=LETTERS[1:9], points=c(12, 19, 7, 22, 24, 28, 30, 19, 15))
#view data frame
df
  player points
1      A     12
2      B     19
3      C      7
4      D     22
5      E     24
6      F     28
7      G     30
8      H     19
9      I     15
</b>
The following code shows how to use the <b>ntile()</b> function to create a new column in the data frame that assigns each player into one of three buckets, depending on their points scored:
<b>library(dplyr)
#create new column that assigns players into buckets based on points
df$bucket &lt;- ntile(df$points, 3)
#view updated data frame
df
  player points bucket
1      A     12      1
2      B     19      2
3      C      7      1
4      D     22      2
5      E     24      3
6      F     28      3
7      G     30      3
8      H     19      2
9      I     15      1</b>
The new <b>bucket</b> column assigns a value between 1 and 3 to each player.
The players with the lowest points receive a value of <b>1</b> and the players with the highest points receive a value of <b>3</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in R:
 How to Use the across() Function in dplyr 
 How to Use the relocate() Function in dplyr 
 How to Use the slice() Function in dplyr 
<h2><span class="orange">How to Pass a String as Variable Name in dplyr</span></h2>
You can use one of the following methods to pass a string as a variable name in dplyr:
<b>Method 1: Use get()</b>
<b>df %>% filter(get(my_var) == 'A')
</b>
<b>Method 2: Use .data</b>
<b>df %>% filter(.data[[my_var]] == 'A')
</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    A     86      31       24
4    B     88      39       24
5    B     95      34       28
</b>
<h2>Example 1: Pass a String as Variable Name in dplyr Using get()</h2>
If we attempt to filter a data frame by passing a string as a variable name to the <b>filter()</b> function in dplyr, we’ll get an empty data frame as a result:
<b>library(dplyr)
#define variable
my_var &lt;- 'team'
#attempt to filter for rows where team is equal to a variable
df %>% filter(my_var == 'A')
[1] team     points   assists  rebounds
&lt;0 rows> (or 0-length row.names)
</b>
One way to get around this is to wrap the variable name in the <b>get()</b> function:
<b>library(dplyr)
#define variable
my_var &lt;- 'team'
#filter for rows where team is equal to a variable
df %>% filter(get(my_var) == 'A')
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    A     86      31       24
</b>
By using the <b>get()</b> function within the <b>filter()</b> function, we’re able to successfully filter the rows in the data frame for only the rows where team is equal to A.
<h2>Example 2: Pass a String as Variable Name in dplyr Using .data</h2>
Another way to pass a string as a variable name to the <b>filter()</b> function in dplyr is to use the <b>.data</b> function as follows:
<b>library(dplyr)
#define variable
my_var &lt;- 'team'
#filter for rows where team is equal to a variable
df %>% filter(.data[[my_var]] == 'A')
  team points assists rebounds
1    A     99      33       30
2    A     90      28       28
3    A     86      31       24
</b>
By using the <b>.data</b> function within the <b>filter()</b> function, we’re able to successfully filter the rows in the data frame for only the rows where team is equal to A.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in dplyr:
 How to Select the First Row by Group Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">How to Rank Variables by Group Using dplyr</span></h2>
You can use the following basic syntax to rank variables by group in dplyr:
<b>df %>% arrange(group_var, numeric_var) %>%
    group_by(group_var) %>% 
    mutate(rank = rank(numeric_var))
</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team = c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'), points = c(12, 28, 19, 22, 32, 45, 22, 28, 13, 19), rebounds = c(5, 7, 7, 12, 11, 4, 10, 7, 8, 8))
#view data frame
df
   team points rebounds
1     A     12        5
2     A     28        7
3     A     19        7
4     A     22       12
5     B     32       11
6     B     45        4
7     B     22       10
8     C     28        7
9     C     13        8
10    C     19        8
</b>
<h3>Example 1: Rank in Ascending Order</h3>
The following code shows how to rank the points scored by players in ascending order, grouped by team:
<b>library(dplyr)
#rank points scored, grouped by team
df %>% arrange(team, points) %>%
    group_by(team) %>% 
    mutate(rank = rank(points))
# A tibble: 10 x 4
# Groups:   team [3]
   team  points rebounds  rank
          
 1 A         12        5     1
 2 A         19        7     2
 3 A         22       12     3
 4 A         28        7     4
 5 B         22       10     1
 6 B         32       11     2
 7 B         45        4     3
 8 C         13        8     1
 9 C         19        8     2
10 C         28        7     3</b>
<h3>Example 2: Rank in Descending Order</h3>
We can also rank the points scored in descending order by group, using a negative sign within the <b>rank()</b> function:
<b>library(dplyr)
#rank points scored in reverse, grouped by team
df %>% arrange(team, points) %>%
    group_by(team) %>% 
    mutate(rank = rank(-points))
# A tibble: 10 x 4
# Groups:   team [3]
   team  points rebounds  rank
          
 1 A         12        5     4
 2 A         19        7     3
 3 A         22       12     2
 4 A         28        7     1
 5 B         22       10     3
 6 B         32       11     2
 7 B         45        4     1
 8 C         13        8     3
 9 C         19        8     2
10 C         28        7     1
</b>
<h3>How to Handle Ties in Ranking</h3>
We can use the <b>ties.method</b> argument to specify how we should handle ties when ranking numerical values.
<b>rank(points, ties.method='average')
</b>
You can use one of the following options to specify how to handle ties:
<b>average</b>: (Default) Assigns each tied element to the average rank (elements ranked in the 3rd and 4th position would both receive a rank of 3.5)
<b>first</b>: Assigns the first tied element to the lowest rank (elements ranked in the 3rd and 4th positions would receive ranks 3 and 4 respectively)
<b>min</b>: Assigns every tied element to the lowest rank (elements ranked in the 3rd and 4th position would both receive a rank of 3)
<b>max</b>: Assigns every tied element to the highest rank (elements ranked in the 3rd and 4th position would both receive a rank of 4)
<b>random</b>: Assigns every tied element to a random rank (either element tied for the 3rd and 4th position could receive either rank)
<h2><span class="orange">How to Use the relocate() Function in dplyr (With Examples)</span></h2>
You can use the  relocate()  function from the  dplyr  package in R to change the column positions in a data frame.
You can use the following methods to change the column positions:
<b>Method 1: Move One Column to Front</b>
<b>#move 'x' column to front
df %>% relocate(x)
</b>
<b>Method 2: Move Several Columns to Front</b>
<b>#move 'x' and 'y' columns to front
df %>% relocate(x, y)
</b>
<b>Method 3: Move Column to Position After Another Column</b>
<b>#move 'x' column to position after 'y' column
df %>% relocate(x, .after=y)
</b>
<b>Method 4: Move Column to Position Before Another Column</b>
<b>#move 'x' column to position before 'y' column
df %>% relocate(x, .before=y)</b>
The following examples show how to each method with the following data frame:
<b>#create dataset
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'C', 'C'), points=c(1, 2, 3, 4, 5, 6, 7), assists=c(1, 5, 2, 3, 2, 2, 0), rebounds=c(6, 6, 10, 12, 8, 8, 3))
#view dataset
df
  team points assists rebounds
1    A      1       1        6
2    A      2       5        6
3    A      3       2       10
4    B      4       3       12
5    B      5       2        8
6    C      6       2        8
7    C      7       0        3
</b>
<h3>Example 1: Move One Column to Front</h3>
The following code shows how to use the <b>relocate()</b> function to move one column to the front:
<b>#move 'assists' column to front
df %>% relocate(assists)
  assists team points rebounds
1       1    A      1        6
2       5    A      2        6
3       2    A      3       10
4       3    B      4       12
5       2    B      5        8
6       2    C      6        8
7       0    C      7        3</b>
<h3>Example 2: Move Several Columns to Front</h3>
The following code shows how to use the <b>relocate()</b> function to move multiple columns to the front:
<b>#move 'points' and 'assists' to front
df %>% relocate(points, assists)
  points assists team rebounds
1      1       1    A        6
2      2       5    A        6
3      3       2    A       10
4      4       3    B       12
5      5       2    B        8
6      6       2    C        8
7      7       0    C        3</b>
<h3>Example 3: Move Column to Position After Another Column</h3>
The following code shows how to use the <b>relocate()</b> function to move one column to a specific position after another column:
<b>#move 'team' column to after 'assists' column
df %>% relocate(team, .after=assists)
  points assists team rebounds
1      1       1    A        6
2      2       5    A        6
3      3       2    A       10
4      4       3    B       12
5      5       2    B        8
6      6       2    C        8
7      7       0    C        3</b>
<h3>Example 4: Move Column to Position Before Another Column</h3>
The following code shows how to use the <b>relocate()</b> function to move one column to a specific position before another column:
<b>#move 'team' column to before 'rebounds' column
df %>% relocate(team, .before=rebounds)
  points assists team rebounds
1      1       1    A        6
2      2       5    A        6
3      3       2    A       10
4      4       3    B       12
5      5       2    B        8
6      6       2    C        8
7      7       0    C        3</b>
<h2><span class="orange">How to Remove Rows with NA Values Using dplyr</span></h2>
You can use the following methods from the  dplyr  package to remove rows with NA values:
<b>Method 1: Remove Rows with NA Values in Any Column</b>
<b>library(dplyr)
#remove rows with NA value in any column
df %>%
  na.omit()
</b>
<b>Method 2: Remove Rows with NA Values in Certain Columns</b>
<b>library(dplyr)
#remove rows with NA value in 'col1' or 'col2'
df %>%
  filter_at(vars(col1, col2), all_vars(!is.na(.)))
</b>
<b>Method 3: Remove Rows with NA Values in One Specific Column</b>
<b>library(dplyr)
#remove rows with NA value in 'col1'
df %>%
  filter(!is.na(col1))</b>
The following examples show how to use these methods in practice with the following data frame:
<b>#create data frame with some missing values
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C'), points=c(99, 90, 86, 88, NA), assists=c(33, NA, 31, 39, 34), rebounds=c(NA, 28, 24, 24, 28))
#view data frame
df
  team points assists rebounds
1    A     99      33       NA
2    A     90      NA       28
3    B     86      31       24
4    B     88      39       24
5    C     NA      34       28</b>
<h3>Method 1: Remove Rows with NA Values in Any Column</h3>
The following code shows how to remove rows with NA values in any column of the data frame:
<b>library(dplyr)
#remove rows with NA value in any column
df %>%
  na.omit()
  team points assists rebounds
3    B     86      31       24
4    B     88      39       24
</b>
The only two rows that are left are the ones without any NA values in any column.
<h3>Method 2: Remove Rows with NA Values in Certain Columns</h3>
The following code shows how to remove rows with NA values in any column of the data frame:
<b>library(dplyr)
#remove rows with NA value in 'points' or 'assists' columns
df %>%
  filter_at(vars(points, assists), all_vars(!is.na(.)))
  team points assists rebounds
1    A     99      33       NA
2    B     86      31       24
3    B     88      39       24
</b>
The only rows left are the ones without any NA values in the ‘points’ or ‘assists’ columns.
<h3>Method 3: Remove Rows with NA Values in One Specific Column</h3>
The following code shows how to remove rows with NA values in one specific column of the data frame:
<b>library(dplyr)
#remove rows with NA value in 'points' column
df %>%
  filter(!is.na(points))
  team points assists rebounds
1    A     99      33       NA
2    A     90      NA       28
3    B     86      31       24
4    B     88      39       24
</b>
The only rows left are the ones without any NA values in the ‘points’ column.
<h2><span class="orange">How to Remove Rows Using dplyr (With Examples)</span></h2>
You can use the following basic syntax to remove rows from a data frame in R using dplyr:
<b>1. Remove any row with NA’s</b>
<b>df %>%
  na.omit()</b>
<b>2. Remove any row with NA’s in specific column</b>
<b>df %>%</b>
<b>  filter(!is.na(column_name))</b>
<b>3. Remove duplicates</b>
<b>df %>%
  distinct()
</b>
<b>4. Remove rows by index position</b>
<b>df %>%</b>
<b>  filter(!row_number() %in% c(1, 2, 4))</b>
<b>5. Remove rows based on condition</b>
<b>df %>%
  filter(column1=='A' | column2 > 8)</b>
The following examples show how to use each of these methods in practice with the following data frame:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'B', 'B', 'C', 'C'), points=c(4, NA, 7, 5, 9, 9), assists=c(1, 3, 5, NA, 2, 2))
#view data frame
df
  team points assists
1    A      4       1
2    A     NA       3
3    B      7       5
4    B      5      NA
5    C      9       2
6    C      9       2
</b>
<h3>Example 1: Remove Any Row with NA’s</h3>
The following code shows how to remove any row with NA values from the data frame:
<b>#remove any row with NA
df %>%
  na.omit()
  team points assists
1    A      4       1
3    B      7       5
5    C      9       2
6    C      9       2</b>
<h3>Example 2: Remove Any Row with NA’s in Specific Columns</h3>
The following code shows how to remove any row with NA values in a specific column:
<b>#remove any row with NA in 'points' column:
df %>%
  filter(!is.na(points))
  team points assists
1    A      4       1
2    B      7       5
3    B      5      NA
4    C      9       2
5    C      9       2</b>
<h3>Example 3: Remove Duplicate Rows</h3>
The following code shows how to remove duplicate rows:
<b>#remove duplicate rows
df %>%
  distinct()
  team points assists
1    A      4       1
2    A     NA       3
3    B      7       5
4    B      5      NA
5    C      9       2</b>
<h3>Example 4: Remove Rows by Index Position</h3>
The following code shows how to remove rows based on index position:
<b>#remove rows 1, 2, and 4
df %>%
  filter(!row_number() %in% c(1, 2, 4))
  team points assists
1    B      7       5
2    C      9       2
3    C      9       2</b>
<h3>Example 5: Remove Rows Based on Condition</h3>
The following code shows how to remove rows based on specific conditions:
<b>#only keep rows where team is equal to 'A' or points is greater than 8
df %>%
  filter(column1=='A' | column2 > 8)
  team points assists
1    A      4       1
2    A     NA       3
3    C      9       2
4    C      9       2</b>
<h2><span class="orange">How to Rename Column by Index Position Using dplyr</span></h2>
You can use the following syntax to rename a column of a data frame by index position using  dplyr :
<b>Method 1: Rename One Column by Index</b>
<b>#rename column in index position 1
df %>%
  rename(new_name1 = 1)
</b>
<b>Method 2: Rename Multiple Columns by Index</b>
<b>#rename column in index positions 1, 2, and 3
df %>%
  rename(new_name1 = 1,
         new_name2 = 2,
         new_name3 = 3)</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: Rename One Column by Index</h3>
The following code shows how to use the <b>rename()</b> function to rename one column by index position:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(12, 14, 19, 24, 24, 22, 30, 9), assists=c(4, 6, 6, 8, 3, 7, 8, 11))
#rename column in index position 1
df &lt;- df %>%
        rename(team_new = 1)
#view updated data frame
df
  team_new points assists
1        A     12       4
2        A     14       6
3        A     19       6
4        A     24       8
5        B     24       3
6        B     22       7
7        B     30       8
8        B      9      11
</b>
Notice that the first column name was changed from <b>team</b> to <b>team_new</b> and all other column names remained the same.
<h3>Example 2: Rename Multiple Columns by Index</h3>
The following code shows how to use the <b>rename()</b> function to rename multiple columns in the data frame by index position:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(12, 14, 19, 24, 24, 22, 30, 9), assists=c(4, 6, 6, 8, 3, 7, 8, 11))
#rename column in index position 1
df&lt;- df %>%
       rename(team_new = 1,
              assists_new = 3)
#view updated data frame
df
  team_new points assists_new
1        A     12           4
2        A     14           6
3        A     19           6
4        A     24           8
5        B     24           3
6        B     22           7
7        B     30           8
8        B      9          11</b>
The column names in index position 1 and 3 changed, while the column name in index position 2 remained the same.
<h2><span class="orange">How to Rename Multiple Columns Using dplyr</span></h2>
You can use the following functions from the  dplyr  package in R to rename multiple columns in a data frame:
<b>Method 1: Use rename()</b>
<b>df %>% rename(new1 = old1, new2 = old2)
</b>
<b>Method 2: Use rename_with()</b>
<b>new &lt;- c('new1', 'new2')
old &lt;- c('old1', 'old2')
df %>% rename_with(~ new, all_of(old))</b>
Both methods produce the same result.
The following examples show how to use each of these methods in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(22, 34, 30, 12, 18), assists=c(7, 9, 9, 12, 14))
#view data frame
df
  team points assists
1    A     22       7
2    B     34       9
3    C     30       9
4    D     12      12
5    E     18      14</b>
<h2>Example 1: Rename Multiple Columns Using rename()</h2>
The following code shows how to use the <b>rename()</b> function to rename the <b>team</b> and <b>points</b> columns in the data frame:
<b>library(dplyr)
#rename team and points columns
df2 &lt;- df %>% rename(team_new = team, points_new = points)
#view updated data frame
df2
  team_new points_new assists
1        A         22       7
2        B         34       9
3        C         30       9
4        D         12      12
5        E         18      14
</b>
The <b>team</b> and <b>points</b> columns have been renamed while the <b>assists</b> column has remained the same.
<h2>Example 2: Rename Multiple Columns Using rename_with()</h2>
The following code shows how to use the <b>rename_with()</b> function to rename the <b>team</b> and <b>points</b> columns in the data frame:
<b>library(dplyr)
#define new names
new &lt;- c('team_new', 'points_new')
#define old names to replace
old &lt;- c('team', 'points')
#rename old names with new names
df2 &lt;- df %>% rename_with(~ new, all_of(old))
#view updated data frame
df2
  team_new points_new assists
1        A         22       7
2        B         34       9
3        C         30       9
4        D         12      12
5        E         18      14
</b>
The <b>team</b> and <b>points</b> columns have been renamed while the <b>assists</b> column has remained the same.
Note that this method may be easier to use when you have a long list of column names you’d like to replace.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Select Columns by Name Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Use select_if with Multiple Conditions in dplyr 
<h2><span class="orange">How to Replace Multiple Values in Data Frame Using dplyr</span></h2>
You can use the following basic syntax to replace multiple values in a data frame in R using functions from the  dplyr  package:
<b>library(dplyr)
df %>%
  mutate(var1 = recode(var1, 'oldvalue1' = 'newvalue1', 'oldvalue2' = 'newvalue2'), 
         var2 = recode(var2, 'oldvalue1' = 'newvalue1', 'oldvalue2' = 'newvalue2'))
</b>
The following example shows how to use this syntax in practice.
<h2>Example: Replace Multiple Values Using dplyr</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(conf=c('East', 'East', 'West', 'West', 'North'), position=c('Guard', 'Guard', 'Guard', 'Guard', 'Forward'), points=c(22, 25, 29, 13, 18))
#view data frame
df
   conf position points
1  East    Guard     22
2  East    Guard     25
3  West    Guard     29
4  West    Guard     13
5 North  Forward     18</b>
Now suppose we would like to replace the following values in the data frame:
<b>‘conf’ column:</b>
Replace ‘East’ with ‘E’
Replace ‘West’ with ‘W’
Replace ‘North’ with ‘N’
<b>‘position’ column:</b>
Replace ‘Guard’ with ‘G’
Replace ‘Forward’ with ‘F’
We can use the <b>mutate()</b> and <b>recode()</b> functions to do so:
<b>library(dplyr) 
#replace multiple values in conf and position columns
df %>%
  mutate(conf = recode(conf, 'East' = 'E', 'West' = 'W', 'North' = 'N'), 
         position = recode(position, 'Guard' = 'G', 'Forward' = 'F'))
  conf position points
1    E        G     22
2    E        G     25
3    W        G     29
4    W        G     13
5    N        F     18
</b>
Notice that each of the values in the ‘conf’ and ‘position’ columns have been replaced with specific values.
Also notice that the values in the ‘points’ column have remain unchanged.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Recode Values Using dplyr 
 How to Replace NA with Zero in dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">How to Replace NA with Mean in dplyr</span></h2>
You can use the following methods to replace NA values with the mean using functions from the <b>dplyr</b> and <b>tidyr</b> packages in R:
<b>Method 1: Replace NA values with Mean in One Column</b>
<b>df %>% mutate(across(col1, ~replace_na(., mean(., na.rm=TRUE))))
</b>
<b>Method 2: Replace NA values with Mean in Several Columns</b>
<b>df %>% mutate(across(c(col1, col2), ~replace_na(., mean(., na.rm=TRUE))))</b>
<b>Method 3: Replace NA values with Mean in All Numeric Columns</b>
<b>df %>% mutate(across(where(is.numeric), ~replace_na(., mean(., na.rm=TRUE))))</b>
The following examples show how to use each method in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'B', 'C', 'D', 'E'), points=c(17, 13, NA, 9, 25), rebounds=c(3, 4, NA, NA, 8), blocks=c(1, 1, 2, 4, NA))
#view data frame
df
  player points rebounds blocks
1      A     17        3      1
2      B     13        4      1
3      C     NA       NA      2
4      D      9       NA      4
5      E     25        8     NA
</b>
<h2>Example 1: Replace NA Values with Mean in One Column</h2>
The following code shows how to replace the NA values in the <b>points</b> column with the mean value of the <b>points</b> column:
<b>library(dplyr)
library(tidyr)
#replace NA values in points column with mean of points column
df &lt;- df %>% mutate(across(points, ~replace_na(., mean(., na.rm=TRUE))))
#view updated data frame
df
  player points rebounds blocks
1      A     17        3      1
2      B     13        4      1
3      C     16       NA      2
4      D      9       NA      4
5      E     25        8     NA</b>
The mean value in the <b>points</b> column was 16, so the one NA value in the <b>points</b> column was replaced with 16.
All other columns remained unchanged.
<h2>Example 2: Replace NA Values with Mean in Several Columns</h2>
The following code shows how to replace the NA values in the <b>points</b>  and <b>blocks</b> columns with their respective column means:
<b>library(dplyr)
library(tidyr)
#replace NA values in points and blocks columns with their respective means
df &lt;- df %>% mutate(across(c(points, blocks), ~replace_na(., mean(., na.rm=TRUE))))
#view updated data frame
df
  player points rebounds blocks
1      A     17        3      1
2      B     13        4      1
3      C     16       NA      2
4      D      9       NA      4
5      E     25        8      2</b>
Notice that the NA values in the <b>points</b> and <b>blocks</b> columns have both been replaced with their respective column means.
<h2>Example 3: Replace NA Values with Mean in All Numeric Columns</h2>
The following code shows how to replace the NA values in every numeric columns with their respective mean value:
<b>library(dplyr)
library(tidyr)
#replace NA values in all numeric columns with their respective means
df &lt;- df %>% mutate(across(where(is.numeric), ~replace_na(., mean(., na.rm=TRUE))))
#view updated data frame
df
  player points rebounds blocks
1      A     17        3      1
2      B     13        4      1
3      C     16        5      2
4      D      9        5      4
5      E     25        8      2</b>
Notice that the NA values in all numeric columns have been replaced with their respective column means.
The one column that was not numeric <b>(player)</b> has remained unchanged.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in dplyr:
 How to Filter Rows that Contain a Certain String Using dplyr 
 How to Calculate Relative Frequencies Using dplyr 
 How to Select the First Row by Group Using dplyr 
<h2><span class="orange">How to Replace NA with Zero in dplyr</span></h2>
You can use the following syntax to replace all NA values with zero in a data frame using the  dplyr  package in R:
<b>#replace all NA values with zero
df &lt;- df %>% replace(is.na(.), 0)
</b>
You can use the following syntax to replace NA values in a specific column of a data frame:
<b>#replace NA values with zero in column named <em>col1</em>
df &lt;- df %>% mutate(col1 = ifelse(is.na(col1), 0, col1))
</b>
And you can use the following syntax to replace NA value in one of several columns of a data frame:
<b>#replace NA values with zero in columns <em>col1</em> and <em>col2</em>
df &lt;- df %>% mutate(col1 = ifelse(is.na(col1), 0, col1),    col2 = ifelse(is.na(col2), 0, col2))</b>
The following examples show how to use these function in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(player=c('A', 'B', 'C', 'D', 'E'), pts=c(17, 12, NA, 9, 25), rebs=c(3, 3, NA, NA, 8), blocks=c(1, 1, 2, 4, NA))
#view data frame
df
  player pts rebs blocks
1      A  17    3      1
2      B  12    3      1
3      C  NA   NA      2
4      D   9   NA      4
5      E  25    8     NA
</b>
<h3>Example 1: Replace All NA Values in All Columns</h3>
The following code shows how to replace all NA values in all columns of a data frame:
<b>library(dplyr)
#replace all NA values with zero
df &lt;- df %>% replace(is.na(.), 0)
#view data frame
df
  player pts rebs blocks
1      A  17    3      1
2      B  12    3      1
3      C   0    0      2
4      D   9    0      4
5      E  25    8      0
</b>
<h3>Example 2: Replace NA Values in a Specific Column</h3>
The following code shows how to replace NA values in a specific column of a data frame:
<b>library(dplyr)
#replace NA values with zero in <em>rebs</em> column only
df &lt;- df %>% mutate(rebs = ifelse(is.na(rebs), 0, rebs))
#view data frame
df
  player pts rebs blocks
1      A  17    3      1
2      B  12    3      1
3      C  NA    0      2
4      D   9    0      4
5      E  25    8     NA</b>
<h3>Example 3: Replace NA Values in One of Several Columns</h3>
The following code shows how to replace NA values in one of several columns of a data frame:
<b>library(dplyr)
#replace NA values with zero in <em>rebs</em> and <em>pts</em> columns
df &lt;- df %>% mutate(rebs = ifelse(is.na(rebs), 0, rebs),    pts = ifelse(is.na(pts), 0, pts))
#view data frame
df
  player pts rebs blocks
1      A  17    3      1
2      B  12    3      1
3      C   0    0      2
4      D   9    0      4
5      E  25    8     NA</b>
<h2><span class="orange">How to Replace String in Column Using dplyr</span></h2>
You can use the following methods to replace a string in a specific column of a data frame using functions from the  dplyr  package:
<b>Method 1: Replace One String with New String</b>
<b>library(dplyr)
library(stringr) 
df %>% 
  mutate(across('column_name', str_replace, 'old_value', 'new_value'))
</b>
<b>Method 2: Replace Multiple Strings with New String</b>
<b>library(dplyr)
library(stringr) 
df %>% 
  mutate(across('column_name', str_replace, 'old_value1|old_value2', 'new_value'))</b>
The following examples show how to use each method with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(conf=c('East', 'East', 'West', 'West'), position=c('P_Guard', 'P_Guard', 'S_Guard', 'S_Guard'), points=c(22, 25, 29, 13))
#view data frame
df
  conf position points
1 East  P_Guard     22
2 East  P_Guard     25
3 West  S_Guard     29
4 West  S_Guard     13
</b>
<h2>Example 1: Replace One String with New String</h2>
The following code shows how to replace the string ‘East’ in the <b>conf</b> column with the string ‘Eastern’:
<b>library(dplyr)
library(stringr)
#replace 'East' with 'Eastern' in conf column
df %>% 
  mutate(across('conf', str_replace, 'East', 'Eastern'))
     conf position points
1 Eastern  P_Guard     22
2 Eastern  P_Guard     25
3    West  S_Guard     29
4    West  S_Guard     13
</b>
Notice that each ‘East’ string has been replaced with ‘Eastern’ in the <b>conf</b> column, while all other columns have remain unchanged.
<h2>Example 2: Replace Multiple Strings with New String</h2>
The following code shows how to replace the string ‘P_’ and ‘S_’ in the <b>conf</b> column with an empty string:
<b>library(dplyr)
library(stringr)
#replace 'P_' and 'S_' with empty string in position column
df %>% 
  mutate(across('position', str_replace, 'P_|S_', ''))
  conf position points
1 East    Guard     22
2 East    Guard     25
3 West    Guard     29
4 West    Guard     13</b>
Notice that each ‘P_’ and ‘S_’ string have been replaced with an empty string in the <b>position </b>column, while all other columns have remain unchanged.
Note that we used the “OR” ( <b>|</b> ) operator to tell R that we’d like to replace any strings equal to ‘P_’ or ‘S_’ with an empty string.
Feel free to use as many “OR” ( <b>|</b> ) operators as you’d like to replace as many values as you’d like in a column at once.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Recode Values Using dplyr 
 How to Replace NA with Zero in dplyr 
 How to Filter Rows that Contain a Certain String Using dplyr 
<h2><span class="orange">How to Select Columns by Index Using dplyr</span></h2>
You can use the following basic syntax in dplyr to select data frame columns by index position:
<b>#select columns in specific index positions
df %>%
  select(1, 4, 5)
#exclude columns in specific index positions
df %>%
  select(-c(1,2))</b>
The following examples show how to use this syntax in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28), blocks=c(14, 19, 22, 18, 15))
#view data frame
df
  team points assists rebounds blocks
1    A     99      33       30     14
2    B     90      28       28     19
3    C     86      31       24     22
4    D     88      39       24     18
5    E     95      34       28     15
</b>
<h3>Example 1: Select Columns in Specific Index Positions</h3>
The following code shows how to select columns in specific index positions:
<b>library(dplyr)
#select columns in position 1, 4, and 5
df %>%
  select(1, 4, 5)
  team rebounds blocks
1    A       30     14
2    B       28     19
3    C       24     22
4    D       24     18
5    E       28     15</b>
<h3>Example 2: Select Columns in Range</h3>
The following code shows how to select columns in a range:
<b>library(dplyr)
#select columns in position 2 through 4
df %>%
  select(2:4)
  points assists rebounds
1     99      33       30
2     90      28       28
3     86      31       24
4     88      39       24
5     95      34       28</b>
<h3>Example 3: Exclude Specific Columns</h3>
The following code shows how to exclude specific columns based on index position:
<b>library(dplyr)
#select all columns <em>except</em> those in position 1 and 2
df %>%
  select(-c(1, 2))
  assists rebounds blocks
1      33       30     14
2      28       28     19
3      31       24     22
4      39       24     18
5      34       28     15</b>
Notice that the first and second column are excluded.
<h2><span class="orange">How to Select Columns by Name Using dplyr</span></h2>
You can use the following methods to select columns of a data frame by name in R using the  dplyr  package:
<b>Method 1: Select Specific Columns by Name</b>
<b>df %>% select(var1, var3)
</b>
<b>Method 2: Select a Range of Columns by Name</b>
<b>df %>% select(var1:var3)
</b>
<b>Method 3: Select All Columns Except Certain Columns</b>
<b>df %>% select(-c(var1, var3))
</b>
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(1, 5, 4, 5, 5, 7, 8), rebounds=c(10, 3, 3, 2, 6, 7, 12), assists=c(5, 5, 7, 6, 7, 9, 15), blocks=c(1, 1, 0, 4, 3, 2, 10))
#view data frame
df
  points rebounds assists blocks
1      1       10       5      1
2      5        3       5      1
3      4        3       7      0
4      5        2       6      4
5      5        6       7      3
6      7        7       9      2
7      8       12      15     10
</b>
<h3>Example 1: Select Specific Columns by Name</h3>
We can use the following code to select only the <b>points</b> and <b>assists</b> columns:
<b>library(dplyr)
#select only points and assists columns
df %>% select(points, assists)
  points assists
1      1       5
2      5       5
3      4       7
4      5       6
5      5       7
6      7       9
7      8      15
</b>
Notice that only the <b>points</b> and <b>assists</b> columns are returned.
<h3>Example 2: Select a Range of Columns by Name</h3>
We can use the following code to select all columns between the names <b>points</b> and <b>assists</b>.
<b>library(dplyr)
#select all columns between points and assists
df %>% select(points:assists)
  points rebounds assists
1      1       10       5
2      5        3       5
3      4        3       7
4      5        2       6
5      5        6       7
6      7        7       9
7      8       12      15
</b>
A range of columns is returned, starting with the <b>points</b> column and ending with the <b>assists</b> column.
<h3>Example 3: Select All Columns Except Certain Columns</h3>
We can use the following code to select all columns except the <b>points</b> and <b>assists</b> columns.
<b>library(dplyr)
#select all columns except points and assists columns
df %>% select(-c(points, assists))
  rebounds blocks
1       10      1
2        3      1
3        3      0
4        2      4
5        6      3
6        7      2
7       12     10
</b>
All of the columns are returned except the <b>points</b> and <b>assists</b> columns.
<b>Note</b>: You can find the complete documentation for the <b>select </b>function in dplyr  here .
<h2><span class="orange">How to Use select_if with Multiple Conditions in dplyr</span></h2>
You can use the following basic syntax with the <b>select_if()</b> function from the  dplyr  package to select columns in a data frame that meet one of several conditions:
<b>df %>% select_if(function(x) condition1 | condition2)</b>
The following examples show how to use this syntax in practice.
<h2>Example 1: Use select_if() with Class Types</h2>
The following code shows how to use the <b>select_if()</b> function to select the columns in a data frame that have a class type of <b>character</b> or <b>numeric</b>:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), conference=as.factor(c('W', 'W', 'W', 'E', 'E')), points_for=c(99, 90, 86, 88, 95), points_against=c(91, 80, 88, 86, 93))
#select all character and numeric columns
df %>% select_if(function(x) is.character(x) | is.numeric(x))
  team points_for points_against
1    A         99             91
2    B         90             80
3    C         86             88
4    D         88             86
5    E         95             93</b>
Notice that the one character column (<b>team</b>) and the two numeric columns (<b>points_for</b> and <b>points_against</b>) are returned while the factor column (<b>conference</b>) is not returned.
<h2>Example 2: Use select_if() with Class Types and Column Names</h2>
The following code shows how to use the <b>select_if()</b> function to select the columns in a data frame that have a class type of <b>factor</b> or have a column name of <b>points_for</b>:
<b>library(dplyr)
#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), conference=as.factor(c('W', 'W', 'W', 'E', 'E')), points_for=c(99, 90, 86, 88, 95), points_against=c(91, 80, 88, 86, 93))
#select all factor columns and 'points_for' column
df %>% select_if(function(x) is.factor(x) | all(x == .$points_for))
  conference points_for
1          W         99
2          W         90
3          W         86
4          E         88
5          E         95
</b>
Notice that the one factor column and the one column titled <b>points_for</b> are returned.
<b>Note</b>: The <b>|</b> symbol is the “OR” logical operator in R. Feel free to use as many <b>|</b> symbols as you’d like to select columns using more than two conditions.
<h2>Additional Resources</h2>
The following tutorials explain how to use other common functions in dplyr:
 How to Use the across() Function in dplyr 
 How to Use the relocate() Function in dplyr 
 How to Use the slice() Function in dplyr 
<h2><span class="orange">How to Select Only Numeric Columns in R Using dplyr</span></h2>
You can use the following function from the  dplyr  package to select only numeric columns from a data frame in R:
<b>df %>% select(where(is.numeric))
</b>
The following example shows how to use this function in practice.
<h2>Example: Select Only Numeric Columns Using dplyr</h2>
Suppose we have the following data frame in R that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E'), points=c(22, 34, 30, 12, 18), assists=c(7, 9, 9, 12, 14), rebounds=c(5, 10, 10, 8, 8))
#view data frame
df
  team points assists rebounds
1    A     22       7        5
2    B     34       9       10
3    C     30       9       10
4    D     12      12        8
5    E     18      14        8
</b>
We can use the following syntax to select only the numeric columns from the data frame:
<b>library(dplyr)
#select only the numeric columns from the data frame
df %>% select(where(is.numeric))
  points assists rebounds
1     22       7        5
2     34       9       10
3     30       9       10
4     12      12        8
5     18      14        8</b>
Notice that only the three numeric columns have been selected – <b>points</b>, <b>assists</b>, and <b>rebounds</b>.
We can verify that these columns are numeric by using the <b>str()</b> function to display the data type of each variable in the data frame:
<b>#display data type of each variable in data frame
str(df)
'data.frame':5 obs. of  4 variables:
 $ team    : chr  "A" "B" "C" "D" ...
 $ points  : num  22 34 30 12 18
 $ assists : num  7 9 9 12 14
 $ rebounds: num  5 10 10 8 8
</b>
From the output we can see that <b>team</b> is a character variable while <b>points</b>, <b>assists</b>, and <b>rebounds</b> are all numeric.
<b>Related:</b>  How to Check Data Type in R (With Examples) 
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Select Columns by Name Using dplyr 
 How to Select Columns by Index Using dplyr 
 How to Use select_if with Multiple Conditions in dplyr 
<h2><span class="orange">How to Select Random Rows in R Using dplyr</span></h2>
You can use the following methods to select random rows from a data frame in R using functions from the  dplyr  package:
<b>Method 1: Select Random Number of Rows</b>
<b>df %>% sample_n(5)
</b>
This function randomly selects <b>5</b> rows from the data frame.
<b>Method 2: Select Random Fraction of Rows</b>
<b>df %>% sample_frac(.25)
</b>
This function randomly selects <b>25%</b> of all rows from the data frame.
The following examples show how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'), points=c(10, 10, 8, 6, 15, 15, 12, 12), rebounds=c(8, 8, 4, 3, 10, 11, 7, 7))
#view data frame
df
  team points rebounds
1    A     10        8
2    B     10        8
3    C      8        4
4    D      6        3
5    E     15       10
6    F     15       11
7    G     12        7
8    H     12        7</b>
<h3>Example 1: Select Random Number of Rows</h3>
We can use the following code to randomly select <b>5</b> rows from the data frame:
<b>library(dplyr)
#randomly select 5 rows from data frame
df %>% sample_n(5)
  team points rebounds
1    F     15       11
2    A     10        8
3    D      6        3
4    G     12        7
5    B     10        8
</b>
Notice that five rows are randomly selected from the data frame.
<h3>Example 2: Select Random Fraction of Rows</h3>
We can use the following code to randomly select <b>25%</b> of all rows from the data frame:
<b>library(dplyr)
#randomly select 25% of all rows from data frame
df %>% sample_frac(.25)
  team points rebounds
1    E     15       10
2    G     12        7
</b>
Since the original data frame had 8 total values, 25% of 8 is equal to 2.
Thus, two rows are randomly selected from the data frame.
<b>Note</b>: You can find the complete documentation for the <b>sample_n </b>and <b>sample_frac</b> functions in dplyr  here .
<h2><span class="orange">How to Select Rows of Data Frame by Name Using dplyr</span></h2>
You can use the following syntax to select rows of a data frame by name using dplyr:
<b>library(dplyr)
#select rows by name
df %>%
  filter(row.names(df) %in% c('name1', 'name2', 'name3'))</b>
The following example shows how to use this syntax in practice.
<h2>Example: Select Rows by Name Using dplyr</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(points=c(99, 90, 86, 88, 95), assists=c(33, 28, 31, 39, 34), rebounds=c(30, 28, 24, 24, 28))
#set row names
row.names(df) &lt;- c('Mavs', 'Hawks', 'Cavs', 'Lakers', 'Heat')
#view data frame
df
       points assists rebounds
Mavs       99      33       30
Hawks      90      28       28
Cavs       86      31       24
Lakers     88      39       24
Heat       95      34       28
</b>
We can use the following code to select the rows where the row name is equal to Hawks, Cavs, or Heat:
<b>library(dplyr)
#select specific rows by name
df %>%
  filter(row.names(df) %in% c('Hawks', 'Cavs', 'Heat'))
      points assists rebounds
Hawks     90      28       28
Cavs      86      31       24
Heat      95      34       28</b>
Notice that dplyr returns only the rows whose names are in the vector we supplied to the <b>filter()</b> function.
Also note that you can use an exclamation point ( <b>!</b> ) to select all rows whose names are <b>not in</b> a vector:
<b>library(dplyr)
#select rows that do not have Hawks, Cavs, or Heat in the row name
df %>%
  filter(!(row.names(df) %in% c('Hawks', 'Cavs', 'Heat')))
       points assists rebounds
Mavs       99      33       30
Lakers     88      39       24</b>
Notice that dplyr returns only the rows whose names are not in the vector we supplied to the <b>filter()</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter for Unique Values Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Count Number of Occurrences in Columns in R 
<h2><span class="orange">How to Use the slice() Function in dplyr (With Examples)</span></h2>
You can use the  slice()  function from the  dplyr  package in R to subset rows based on their integer locations.
You can use the following methods to subset certain rows in a data frame:
<b>Method 1: Subset One Specific Row</b>
<b>#get row 3 only
df %>% slice(3)
</b>
<b>Method 2: Subset Several Rows</b>
<b>#get rows 2, 5, and 6
df %>% slice(2, 5, 6)
</b>
<b>Method 3: Subset A Range of Rows</b>
<b>#get rows 1 through 3
df %>% slice(1:3)
</b>
<b>Method 4: Subset Rows by Group</b>
<b>#get first row by group
df %>%
  group_by(var1) %>%
  slice(1)</b>
The following examples show how to each method with the following data frame:
<b>#create dataset
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'C', 'C'), points=c(1, 2, 3, 4, 5, 6, 7), assists=c(1, 5, 2, 3, 2, 2, 0))
#view dataset
df
  team points assists
1    A      1       1
2    A      2       5
3    A      3       2
4    B      4       3
5    B      5       2
6    C      6       2
7    C      7       0
</b>
<h3>Example 1: Subset One Specific Row</h3>
The following code shows how to use the <b>slice()</b> function to select only row 3 in the data frame:
<b>#get row 3 only
df %>% slice(3)
  team points assists
1    A      3       2
</b>
<h3>Example 2: Subset Several Rows</h3>
The following code shows how to use the <b>slice()</b> function to select several specific rows in the data frame:
<b>#get rows 2, 5, and 6
df %>% slice(2, 5, 6)
  team points assists
1    A      2       5
2    B      5       2
3    C      6       2
</b>
<h3>Example 3: Subset A Range of Rows</h3>
The following code shows how to use the <b>slice()</b> function to select all rows in the range 1 through 3:
<b>#get rows 1 through 3
df %>% slice(1:3)
  team points assists
1    A      1       1
2    A      2       5
3    A      3       2
</b>
<h3>Example 4: Subset Rows by Group</h3>
The following code shows how to use the <b>slice()</b> function to select the first row in certain groups:
<b>#get first row by group
df %>%
  group_by(team) %>%
  slice(1)
# A tibble: 3 x 3
# Groups:   team [3]
  team  points assists
       
1 A          1       1
2 B          4       3
3 C          6       2
</b>
<h2><span class="orange">How to Calculate Standard Deviation Using dplyr (With Examples)</span></h2>
You can use the following methods to calculate the standard deviation of values in a data frame in  dplyr :
<b>Method 1: Calculate Standard Deviation of One Variable</b>
<b>library(dplyr)
df %>%
  summarise(sd_var1 = sd(var1, na.rm=TRUE))</b>
<b>Method 2: Calculate Standard Deviation of Multiple Variables</b>
<b>library(dplyr)
df %>%
  summarise(sd_var1 = sd(var1, na.rm=TRUE),
            sd_var2 = sd(var2, na.rm=TRUE))</b>
<b>Method 3: Calculate Standard Deviation of Multiple Variables, Grouped by Another Variable</b>
<b>library(dplyr)
df %>%
  group_by(var3) %>%
  summarise(sd_var1 = sd(var1, na.rm=TRUE),
            sd_var2 = sd(var2, na.rm=TRUE))</b>
This tutorial explains how to use each method in practice with the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(12, 15, 18, 22, 14, 17, 29, 35), assists=c(4, 4, 3, 6, 7, 8, 3, 10))
#view data frame
df
  team points assists
1    A     12       4
2    A     15       4
3    A     18       3
4    A     22       6
5    B     14       7
6    B     17       8
7    B     29       3
8    B     35      10
</b>
<h2>Example 1: Calculate Standard Deviation of One Variable</h2>
The following code shows how to calculate the standard deviation of the <b>points</b> variable:
<b>library(dplyr)
#calculate standard deviation of points variable
df %>%
  summarise(sd_points = sd(points, na.rm=TRUE))
  sd_points
1  7.995534
</b>
From the output we can see that the standard deviation of values for the <b>points</b> variable is <b>7.995534</b>.
<h2>Example 2: Calculate Standard Deviation of Multiple Variables</h2>
The following code shows how to calculate the standard deviation of the <b>points</b> and the <b>assists</b> variables:
<b>library(dplyr)
#calculate standard deviation of points and assists variables
df %>%
  summarise(sd_points = sd(points, na.rm=TRUE),
            sd_assists = sd(assists, na.rm=TRUE))
  sd_points sd_assists
1  7.995534   2.559994
</b>
The output displays the standard deviation for both the <b>points</b> and <b>assists</b> variables.
<h2>Example 3: Calculate Standard Deviation of Multiple Variables, Grouped by Another Variable</h2>
The following code shows how to calculate the standard deviation of the <b>points</b> and the <b>assists</b> variables:
<b>library(dplyr)
#calculate standard deviation of points and assists variables
df %>%
  group_by(team) %>%
  summarise(sd_points = sd(points, na.rm=TRUE),
            sd_assists = sd(assists, na.rm=TRUE))
# A tibble: 2 x 3
  team  sd_points sd_assists
             
1 A          4.27       1.26
2 B          9.91       2.94
</b>
The output displays the standard deviation for both the <b>points</b> and <b>assists</b> variables for team A and team B.
<b>Note</b>: You can include a list of several variables in the <b>group_by()</b> function if you would like to group by multiple variables.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter for Unique Values Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Count Number of Occurrences in Columns in R 
<h2><span class="orange">How to Sum Across Multiple Columns Using dplyr</span></h2>
You can use the following methods to sum values across multiple columns of a data frame using dplyr:
<b>Method 1: Sum Across All Columns</b>
<b>df %>%
  mutate(sum = rowSums(., na.rm=TRUE))
</b>
<b>Method 2: Sum Across All Numeric Columns</b>
<b>df %>%
  mutate(sum = rowSums(across(where(is.numeric)), na.rm=TRUE))
</b>
<b>Method 3: Sum Across Specific Columns</b>
<b>df %>%
  mutate(sum = rowSums(across(c(col1, col2))))
</b>
The following examples show how to each method with the following data frame that contains information about points scored by various basketball players during different games:
<b>#create data frame
df &lt;- data.frame(game1=c(22, 25, 29, 13, 22, 30), game2=c(12, 10, 6, 6, 8, 11), game3=c(NA, 15, 15, 18, 22, 13))
#view data frame
df
  game1 game2 game3
1    22    12    NA
2    25    10    15
3    29     6    15
4    13     6    18
5    22     8    22
6    30    11    13
</b>
<h2>Example 1: Sum Across All Columns</h2>
The following code shows how to calculate the sum of values across all columns in the data frame:
<b>library(dplyr)
#sum values across all columns
df %>%
  mutate(total_points = rowSums(., na.rm=TRUE))
  game1 game2 game3 total_points
1    22    12    NA           34
2    25    10    15           50
3    29     6    15           50
4    13     6    18           37
5    22     8    22           52
6    30    11    13           54
</b>
<h2>Example 2: Sum Across All Numeric Columns</h2>
The following code shows how to calculate the sum of values across all numeric columns in the data frame:
<b>library(dplyr) 
#sum values across all numeric columns
df %>%
  mutate(total_points = rowSums(across(where(is.numeric)), na.rm=TRUE))
  game1 game2 game3 total_points
1    22    12    NA           34
2    25    10    15           50
3    29     6    15           50
4    13     6    18           37
5    22     8    22           52
6    30    11    13           54</b>
<h2>Example 3: Sum Across Specific Columns</h2>
The following code shows how to calculate the sum of values across the <b>game1</b> and <b>game2</b> columns only:
<b>library(dplyr) 
#sum values across game1 and game2 only
df %>%
  mutate(first2_sum = rowSums(across(c(game1, game2))))
  game1 game2 game3 first2_sum
1    22    12    NA         34
2    25    10    15         35
3    29     6    15         35
4    13     6    18         19
5    22     8    22         30
6    30    11    13         41
</b>
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks using dplyr:
 How to Remove Rows Using dplyr 
 How to Arrange Rows Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
<h2><span class="orange">dplyr: How to Summarise Data But Keep All Columns</span></h2>
When using the <b>summarise()</b> function in  dplyr , all variables not included in the <b>summarise()</b> or <b>group_by()</b> functions will automatically be dropped.
However, you can use the <b>mutate()</b> function to summarize data while keeping all of the columns in the data frame.
The following example shows how to use this function in practice.
<h2>Example: Summarise Data But Keep All Columns Using dplyr</h2>
Suppose we have the following data frame that contains information about various basketball players:
<b>#create data frame
df &lt;- data.frame(team=rep(c('A', 'B', 'C'), each=3), points=c(4, 9, 8, 12, 15, 14, 29, 30, 22), assists=c(3, 3, 2, 5, 8, 10, 4, 5, 12))
#view data frame
df
  team points assists
1    A      4       3
2    A      9       3
3    A      8       2
4    B     12       5
5    B     15       8
6    B     14      10
7    C     29       4
8    C     30       5
9    C     22      12</b>
We can use the following syntax to summarize the mean <b>points</b> scored by <b>team</b>:
<b>library(dplyr)
#summarize mean points values by team
df %>%
  group_by(team) %>%
  summarise(mean_pts = mean(points))
# A tibble: 3 x 2
  team  mean_pts
      
1 A          7  
2 B         13.7
3 C         27
</b>
The column called <b>mean_pts</b> displays the mean points scored by each team.
From the output we can see:
The mean points scored by players on team A is <b>7</b>.
The mean points scored by players on team B is <b>13.7</b>.
The mean points scored by players on team C is <b>27</b>.
However, suppose we would like to keep all other columns from the original data frame.
We can use the following syntax with the <b>mutate()</b> function to do so:
<b>library(dplyr)
#summarize mean points values by team and keep all columns
df %>%
  group_by(team) %>%
  mutate(mean_pts = mean(points)) %>%
  ungroup()
# A tibble: 9 x 4
  team  points assists mean_pts
           
1 A          4       3      7  
2 A          9       3      7  
3 A          8       2      7  
4 B         12       5     13.7
5 B         15       8     13.7
6 B         14      10     13.7
7 C         29       4     27  
8 C         30       5     27  
9 C         22      12     27
</b>
By using the <b>mutate()</b> function, we’re able to create a new column called <b>mean_pts</b> that summarizes the mean points scored by team while also keeping all other columns from the original data frame.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in dplyr:
 dplyr: How to Mutate Variable if Column Contains String 
 dplyr: How to Change Factor Levels Using mutate() 
 dplyr: How to Sum Across Multiple Columns 
<h2><span class="orange">How to Summarise Multiple Columns Using dplyr</span></h2>
You can use the following methods to summarise multiple columns in a data frame using dplyr:
<b>Method 1: Summarise All Columns</b>
<b>#summarise mean of all columns
df %>%
  group_by(group_var) %>%
  summarise(across(everything(), mean, na.rm=TRUE))
</b>
<b>Method 2: Summarise Specific Columns</b>
<b>#summarise mean of col1 and col2 only
df %>%
  group_by(group_var) %>%
  summarise(across(c(col1, col2), mean, na.rm=TRUE))
</b>
<b>Method 3: Summarise All Numeric Columns</b>
<b>#summarise mean and standard deviation of all numeric columns
df %>%
  group_by(group_var) %>%
  summarise(across(where(is.numeric), list(mean=mean, sd=sd), na.rm=TRUE))
</b>
The following examples show how to each method with the following data frame:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), points=c(99, 90, 86, 88, 95, 90), assists=c(33, 28, 31, 39, 34, 25), rebounds=c(NA, 28, 24, 24, 28, 19))
#view data frame
df
  team points assists rebounds
1    A     99      33       NA
2    A     90      28       28
3    A     86      31       24
4    B     88      39       24
5    B     95      34       28
6    B     90      25       19
</b>
<h2>Example 1: Summarise All Columns</h2>
The following code shows how to summarise the mean of all columns:
<b>library(dplyr)
#summarise mean of all columns, grouped by team
df %>%
  group_by(team) %>%
  summarise(across(everything(), mean, na.rm=TRUE))
# A tibble: 2 x 4
  team  points assists rebounds
           
1 A       91.7    30.7     26  
2 B       91      32.7     23.7
</b>
<h2>Example 2: Summarise Specific Columns</h2>
The following code shows how to summarise the mean of only the <b>points</b> and <b>rebounds</b> columns:
<b>library(dplyr)
#summarise mean of points and rebounds, grouped by team
df %>%
  group_by(team) %>%
  summarise(across(c(points, rebounds), mean, na.rm=TRUE))
# A tibble: 2 x 3
  team  points rebounds
        
1 A       91.7     26  
2 B       91       23.7</b>
<h2>Example 3: Summarise All Numeric Columns</h2>
The following code shows how to summarise the mean and standard deviation for all numeric columns in the data frame:
<b>library(dplyr)
#summarise mean and standard deviation of all numeric columns
df %>%
  group_by(team) %>%
  summarise(across(where(is.numeric), list(mean=mean, sd=sd), na.rm=TRUE))
# A tibble: 2 x 7
  team  points_mean points_sd assists_mean assists_sd rebounds_mean rebounds_sd                            
1 A            91.7      6.66         30.7       2.52          26          2.83
2 B            91        3.61         32.7       7.09          23.7        4.51</b>
The output displays the mean and standard deviation for all numeric variables in the data frame.
Note that in this example we used the <b>list()</b> function to list out several summary statistics that we wanted to calculate.
<b>Note</b>: In each example, we utilized the dplyr <b>across()</b> function. You can find the complete documentation for this function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common functions using dplyr:
 How to Remove Rows Using dplyr 
 How to Arrange Rows Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
<h2><span class="orange">How to Use ungroup() in dplyr (With Examples)</span></h2>
You can use the <b>ungroup()</b> function in dplyr to ungroup rows after using the <b>group_by()</b> function to summarize a variable by group.
The following example shows how to use this function in practice.
<h2>Example: How to Use ungroup() in dplyr</h2>
Suppose we have the following data frame in R:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'B', 'B', 'B'), points=c(14, 18, 22, 26, 36, 34), assists=c(5, 4, 4, 8, 7, 3))
#view data frame
df
  team points assists
1    A     14       5
2    A     18       4
3    A     22       4
4    B     26       8
5    B     36       7
6    B     34       3</b>
Now suppose we use the following code to calculate the mean value of <b>points</b>, grouped by <b>team</b>:
<b>library(dplyr)
#calculate mean of points, grouped by team
df_new &lt;- df %>%
            group_by(team) %>%
            summarize(mean_points = mean(points)) %>%
            ungroup()
#view results
df_new
# A tibble: 2 x 2
  team  mean_points
         
1 A              18
2 B              32
</b>
Using this syntax, we’re able to calculate the mean value of <b>points</b> grouped by <b>team</b>, but we’ve lost the <b>assists</b> column.
To retain the <b>assists</b> column, we can use <b>mutate()</b> instead of <b>summarize()</b> and still use <b>ungroup()</b> at the end:
<b>library(dplyr)
#calculate mean of points, grouped by team
df_new &lt;- df %>%
            group_by(team) %>%
            mutate(mean_points = mean(points)) %>%
            ungroup()
#view results
df_new
# A tibble: 6 x 4
  team  points assists mean_points
              
1 A         14       5          18
2 A         18       4          18
3 A         22       4          18
4 B         26       8          32
5 B         36       7          32
6 B         34       3          32
</b>
This time we’re able to retain the <b>assists</b> column and by using the <b>mutate()</b> function we’ve simply added  a new column called <b>mean_points</b> that shows the mean points value for each team.
Since we used the <b>ungroup()</b> function as well, we can perform calculations on this new data frame without worrying about any calculations being affected by any grouped variables.
If we didn’t use the <b>ungroup()</b> function then the rows of the data frame would still be grouped, which could have unintended consequences when we perform more calculations later on.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Filter for Unique Values Using dplyr 
 How to Filter by Multiple Conditions Using dplyr 
 How to Count Number of Occurrences in Columns in R 
<h2><span class="orange">A Guide to dpois, ppois, qpois, and rpois in R</span></h2>
This tutorial explains how to work with the  Poisson distribution  in R using the following functions
<b>dpois</b>: returns the value of the Poisson probability density function.
<b>ppois</b>: returns the value of the Poisson cumulative density function.
<b>qpois</b>: returns the value of the inverse Poisson cumulative density function.
<b>rpois</b>: generates a vector of Poisson distributed random variables.
Here are some examples of cases where you might use each of these functions.
<h2>dpois</h2>
The <b>dpois </b>function finds the probability that a certain number of successes occur based on an average rate of success, using the following syntax:
<b>dpois(x, lambda) </b>
where:
<b>x: </b>number of successes
<b>lambda: </b>average rate of success
Here’s an example of when you might use this function in practice:
<b>It is known that a certain website makes 10 sales per hour. In a given hour, what is the probability that the site makes exactly 8 sales?</b>
<b>dpois(x=8, lambda=10)
#0.112599
</b>
The probability that the site makes exactly 8 sales is <b>0.112599</b>.
<h2>ppois</h2>
The <b>ppois </b>function finds the probability that a certain number of successes <em>or less</em> occur based on an average rate of success, using the following syntax:
<b>ppois(q, lambda) </b>
where:
<b>q: </b>number of successes
<b>lambda: </b>average rate of success
Here’s are a couple examples of when you might use this function in practice:
<b>It is known that a certain website makes 10 sales per hour. In a given hour, what is the probability that the site makes 8 sales or less?</b>
<b>ppois(q=8, lambda=10)
#0.3328197</b>
The probability that the site makes 8 sales or less in a given hour is <b>0.3328197</b>.
<b>It is known that a certain website makes 10 sales per hour. In a given hour, what is the probability that the site makes more than 8 sales?</b>
<b>1 - ppois(q=8, lambda=10)
#0.6671803</b>
The probability that the site makes more than 8 sales in a given hour is <b>0.6671803</b>.
<h2>qpois</h2>
The <b>qpois </b>function finds the number of successes that corresponds to a certain percentile based on an average rate of success, using the following syntax:
<b>qpois(p, lambda) </b>
where:
<b>p: </b>percentile
<b>lambda: </b>average rate of success
Here’s an example of when you might use this function in practice:
<b>It is known that a certain website makes 10 sales per hour. How many sales would the site need to make to be at the 90th percentile for sales in an hour?</b>
<b>qpois(p=.90, lambda=10)
#14
</b>
A site would need to make <b>14 </b>sales to be at the 90th percentile for number of sales in an hour.
<h2>rpois</h2>
The <b>rpois </b>function generates a list of random variables that follow a Poisson distribution with a certain average rate of success, using the following syntax:
<b>rpois(n, lambda) </b>
where:
<b>n: </b>number of random variables to generate
<b>lambda: </b>average rate of success
Here’s an example of when you might use this function in practice:
<b>Generate a list of 15 random variables that follow a Poisson distribution with a rate of success equal to 10.</b>
<b>rpois(n=15, lambda=10)
# [1] 13 8 8 20 8 10 8 10 13 10 12 8 10 10 6
</b>
Since these numbers are generated randomly, the <b>rpois() </b>function will produce different numbers each time. If you want to create a reproducible example, be sure to use the <b>set.seed() </b>command.
<h2><span class="orange">R: How to Draw Circles in Plots (With Examples)</span></h2>
You can use the following methods to draw a circle in a plot in R:
<b>Method 1: Draw Circle Using Base R</b>
<b>library(plotrix)
#create scatter plot
plot(x, y)
#add circle at specific (x, y) coordinates with specific radius
draw.circle(x=3, y=8, radius=.5)
</b>
<b>Method 2: Draw Circle Using ggplot2</b>
<b>library(ggplot2)
library(ggforce)
#create scatter plot with circle at specific location with specific radius
ggplot(data = df, aes(x, y)) +
  geom_point() +
  geom_circle(aes(x0=3, y0=8, r=1), inherit.aes=FALSE) +
  coord_fixed()
</b>
The following examples shows how to use each method in practice.
<h3>Example 1: Draw Circle Using Base R</h3>
To draw a circle on a plot in base R, you need to first install and load the <b>plotrix</b> package:
<b>install.packages('plotrix')
library(plotrix)</b>
Next, we can use the <b>draw.circle()</b> function from the <b>plotrix</b> package to add a circle to a scatter plot in base R:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 3, 4, 8), y=c(2, 4, 5, 4, 7, 9, 10))
#create scatter plot
plot(df$x, df$y)
#add circle
draw.circle(x=3, y=8, radius=.5)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/circleR1.jpg"465">
You can also use the <b>draw.circle()</b> function multiple times to plot multiple circles on the same plot:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 3, 4, 8), y=c(2, 4, 5, 4, 7, 9, 10))
#create scatter plot
plot(df$x, df$y)
#add multiple circles to plot
draw.circle(x=3, y=8, radius=.5)
draw.circle(x=4, y=5, radius=.5, border='red', col='lightblue', lwd=5, lty='dashed')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/circleR2.jpg">
Notice that multiple circles have been added to the plot at the (x, y) coordinates that we specified.
<h3>Example 2: Draw Circle Using ggplot2</h3>
To draw a circle on a plot in ggplot2, you need to first install and load the <b>ggplot2</b> and <b>ggforce </b>packages:
<b>install.packages('ggplot2')
install.packages('ggforce')
library(ggplot2)
library(ggforce)</b>
Next, we can use the <b>geom_circle()</b> function from the <b>ggforce </b>package to add a circle to a scatter plot in ggplot2:
<b>#create data frame
df &lt;- data.frame(x=c(1, 2, 2, 3, 3, 4, 8), y=c(2, 4, 5, 4, 7, 9, 10))
#create scatter plot with circle
ggplot(data = df, aes(x, y)) +
  geom_point() +
  geom_circle(aes(x0=3, y0=8, r=1), linetype='dashed', color='red',
              fill='lightblue', lwd=1.5, inherit.aes=FALSE) +
  coord_fixed()</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/circleR3.jpg">
The circle is placed in the exact (x, y) coordinates that we specified.
<b>Note</b>: If you don’t use the <b>coord_fixed()</b> argument, the circle may appear as an ellipse instead.
<h2><span class="orange">How to Drop Columns in Pandas (4 Examples)</span></h2>
You can use the  drop()  function to drop one or more columns from a pandas DataFrame:
<b>#drop one column by name
df.drop('column_name', axis=1, inplace=True)
#drop multiple columns by name
df.drop(['column_name1', 'column_name2'], axis=1, inplace=True)
#drop one column by index
df.drop(df.columns[[0]], axis=1, inplace=True)
#drop multiple columns by index
df.drop(df.columns[[0,2,5]], axis=1, inplace=True)
</b>
Note the following:
The <b>axis</b> argument specifies whether to drop rows (0) or columns (1).
The <b>inplace</b> argument specifies to drop the columns in place without reassigning the DataFrame.
The following examples show how to use this function in practice with the following pandas DataFrame:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'A': [25, 12, 15, 14, 19, 23, 25, 29],   'B': [5, 7, 7, 9, 12, 9, 9, 4],   'C': [11, 8, 10, 6, 6, 5, 9, 12]})
#view DataFrame
df
ABC
025511
11278
215710
31496
419126
52395
62599
729412
</b>
<h3>Example 1: Drop One Column by Name</h3>
The following code shows how to drop one column from the DataFrame by name:
<b>#drop column named 'B' from DataFrame
df.drop('B', axis=1, inplace=True) 
#view DataFrame
df
AC
02511
1128
21510
3146
4196
5235
6259
72912</b>
<h3>Example 2: Drop Multiple Columns by Name</h3>
The following code shows how to drop multiple columns by name:
<b>#drop columns 'A' and 'C' from DataFrame
df.drop(['A', 'C'], axis=1, inplace=True) 
#view DataFrame
df
        B
05
17
27
39
412
59
69
74</b>
<h3>Example 3: Drop One Column by Index</h3>
The following code shows how to drop one column by index:
<b>#drop first column from DataFrame
df.drop(df.columns[[0]], axis=1, inplace=True) 
#view DataFrame
df
        BC
0511
178
2710
396
4126
595
699
7412</b>
<h3>Example 4: Drop Multiple Columns by Index</h3>
The following code shows how to drop multiple columns by index:
<b>#drop multiple columns from DataFrame
df.drop(df.columns[[0, 1]], axis=1, inplace=True) 
#view DataFrame
df
        C
011
18
210
36
46
55
69
712
</b>
<h2><span class="orange">How to Drop the Index Column in Pandas (With Examples)</span></h2>
Occasionally you may want to drop the index column of a pandas DataFrame in Python.
Since pandas DataFrames and Series always have an index, you can’t actually <em>drop</em> the index, but you can reset it by using the following bit of code:
<b>df.reset_index(drop=True, inplace=True)
</b>
For example, suppose we have the following pandas DataFrame with an index of letters:
<b>import pandas as pd
#create DataFrame
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#set index of DataFrame to be random letters
df = df.set_index([pd.Index(['a', 'b', 'd', 'g', 'h', 'm', 'n', 'z'])])
#display DataFrame
df
        pointsassists rebounds
a255 11
b127 8
d157 10
g149 6
h1912 6
m239 5
n259 9
z294 12
</b>
We can use the  reset_index()  function to reset the index to be a sequential list of numbers:
<b>#reset index
df.reset_index(drop=True, inplace=True)
#display DataFrame
df
        pointsassists rebounds
0255 11
1127 8
2157 10
3149 6
41912 6
5239 5
6259 9
7294 12
</b>
Notice that the index is now a list of numbers ranging from 0 to 7.
As mentioned earlier, the index is not actually a column. Thus, when we use the <b>shape</b> command, we can see that the DataFrame has 8 rows and 3 columns (as opposed to 4 columns):
<b>#find number of rows and columns in DataFrame
df.shape
(8, 3)
</b>
<h3>Bonus: Drop the Index When Importing & Exporting</h3>
Often you may want to reset the index of a pandas DataFrame after reading it in from a CSV file. You can quickly reset the index <em>while</em> importing it by using the following bit of code:
<b>df = pd.read_csv('data.csv', index_col=False) </b>
And you can make sure that an index column is not written to a CSV file upon exporting by using the following bit of code:
<b>df.to_csv('data.csv', index=False) </b>
<h2><span class="orange">How to Drop Rows with NaN Values in Pandas</span></h2>
Often you may be interested in dropping rows that contain NaN values in a pandas DataFrame. Fortunately this is easy to do using the pandas  dropna()  function.
This tutorial shows several examples of how to use this function on the following pandas DataFrame:
<b>import numpy as np
import scipy.stats as stats
#create DataFrame with some NaN values
df = pd.DataFrame({'rating': [np.nan, 85, np.nan, 88, 94, 90, 76, 75, 87, 86],   'points': [np.nan, 25, 14, 16, 27, 20, 12, 15, 14, 19],   'assists': [5, 7, 7, np.nan, 5, 7, 6, 9, 9, 5],   'rebounds': [11, 8, 10, 6, 6, 9, 6, 10, 10, 7]})
#view DataFrame
df
        ratingpointsassistsrebounds
0NaNNaN5.011
185.025.07.08
2NaN14.07.010
388.016.0NaN6
494.027.05.06
590.020.07.09
676.012.06.06
775.015.09.010
887.014.09.010
986.019.05.07
</b>
<h3>Example 1: Drop Rows with Any NaN Values</h3>
We can use the following syntax to drop all rows that have <em>any </em>NaN values:
<b>df.dropna()
ratingpointsassistsrebounds
185.025.07.08
494.027.05.06
590.020.07.09
676.012.06.06
775.015.09.010
887.014.09.010
986.019.05.07
</b>
<h3>Example 2: Drop Rows with All NaN Values</h3>
We can use the following syntax to drop all rows that have <em>all </em>NaN values in each column:
<b>df.dropna(how='all') 
        ratingpointsassistsrebounds
0NaNNaN5.011
185.025.07.08
2NaN14.07.010
388.016.0NaN6
494.027.05.06
590.020.07.09
676.012.06.06
775.015.09.010
887.014.09.010
986.019.05.07
</b>
There were no rows with all NaN values in this particular DataFrame, so none of the rows were dropped.
<h3>Example 3: Drop Rows Below a Certain Threshold</h3>
We can use the following syntax to drop all rows that don’t have a certain <em>at least </em>a certain number of non-NaN values:
<b>df.dropna(thresh=3) 
ratingpointsassistsrebounds
185.025.07.08
2NaN14.07.010
388.016.0NaN6
494.027.05.06
590.020.07.09
676.012.06.06
775.015.09.010
887.014.09.010
986.019.05.07
</b>
The very first row in the original DataFrame did not have at least 3 non-NaN values, so it was the only row that got dropped.
<h3>Example 4: Drop Row with Nan Values in a Specific Column</h3>
We can use the following syntax to drop all rows that have a NaN value in a specific column:
<b>df.dropna(subset=['assists'])
ratingpointsassistsrebounds
0NaNNaN5.011
185.025.07.08
2NaN14.07.010
494.027.05.06
590.020.07.09
676.012.06.06
775.015.09.010
887.014.09.010
986.019.05.07</b>
<h3>Example 5: Reset Index After Dropping Rows with NaNs</h3>
 We can use the following syntax to reset the index of the DataFrame after dropping the rows with the NaN values:
<b>#drop all rows that have any NaN values
df = df.dropna()
#reset index of DataFrame
df = df.reset_index(drop=True)
#view DataFrame
df
        ratingpointsassistsrebounds
085.025.07.08
194.027.05.06
290.020.07.09
376.012.06.06
475.015.09.010
587.014.09.010
686.019.05.077</b>
<em>You can find the complete documentation for the dropna() function  here .</em>
<h2><span class="orange">How to Drop Unnamed Column in Pandas DataFrame</span></h2>
You can use the following two methods to drop a column in a pandas DataFrame that contains “Unnamed” in the column name:
<b>Method 1: Drop Unnamed Column When Importing Data</b>
<b>df = pd.read_csv('my_data.csv', index_col=0)
</b>
<b>Method 2: Drop Unnamed Column After Importing Data</b>
<b>df = df.loc[:, ~df.columns.str.contains('^Unnamed')]</b>
The following examples show how to use each method in practice.
<h3>Example 1: Drop Unnamed Column When Importing Data</h3>
Suppose we create a simple pandas DataFrame and export it to a CSV file:
<b>import pandas as pd
#create DataFrame
df1 = pd.DataFrame({'team': ['A', 'B', 'C', 'D', 'E', 'F'],    'points': [4, 4, 6, 8, 9, 5],    'rebounds': [12, 7, 8, 8, 5, 11]})
#view DataFrame
print(df1)
  team  points  rebounds
0    A       4        12
1    B       4         7
2    C       6         8
3    D       8         8
4    E       9         5
5    F       5        11
#export DataFrame to CSV file
df1.to_csv('my_data.csv')
</b>
Now when we attempt to read the file into a pandas DataFrame, the first column has a name of <b>Unnamed: 0</b>
<b>#import CSV file
df2 = pd.read_csv('my_data.csv')
#view DataFrame
print(df2)
   Unnamed: 0 team  points  rebounds
0           0    A       4        12
1           1    B       4         7
2           2    C       6         8
3           3    D       8         8
4           4    E       9         5
5           5    F       5        11
</b>
To avoid this, we can specify<b> index_col=0</b> to tell pandas that the first column is actually the index column:
<b>#import CSV file
df2 = pd.read_csv('my_data.csv', index_col=0)
#view DataFrame
print(df2)
  team  points  rebounds
0    A       4        12
1    B       4         7
2    C       6         8
3    D       8         8
4    E       9         5
5    F       5        11</b>
<h3>Example 2: Drop Unnamed Column After Importing Data</h3>
Suppose we create a simple pandas DataFrame and export it to a CSV file:
<b>import pandas as pd
#create DataFrame
df1 = pd.DataFrame({'team': ['A', 'B', 'C', 'D', 'E', 'F'],    'points': [4, 4, 6, 8, 9, 5],    'rebounds': [12, 7, 8, 8, 5, 11]})
#export DataFrame to CSV file
df1.to_csv('my_data.csv')
</b>
Now suppose we import this file into a pandas DataFrame:
<b>#import CSV file
df2 = pd.read_csv('my_data.csv')
#view DataFrame
print(df2)
   Unnamed: 0 team  points  rebounds
0           0    A       4        12
1           1    B       4         7
2           2    C       6         8
3           3    D       8         8
4           4    E       9         5
5           5    F       5        11
</b>
To drop the column that contains “Unnamed” in the name, we can use the following syntax:
<b>#drop any column that contains "Unnamed" in column name
df2 = df2.loc[:, ~df2.columns.str.contains('^Unnamed')]
#view updated DataFrame
print(df2)
  team  points  rebounds
0    A       4        12
1    B       4         7
2    C       6         8
3    D       8         8
4    E       9         5
5    F       5        11
</b>
Notice that the “Unnamed: 0” column has been dropped from the DataFrame.
<h2><span class="orange">R: How to Use drop_na to Drop Rows with Missing Values</span></h2>
You can use the <b>drop_na()</b> function from the  tidyr  package in R to drop rows with missing values in a data frame.
There are three common ways to use this function:
<b>Method 1: Drop Rows with Missing Values in Any Column</b>
<b>df %>% drop_na()
</b>
<b>Method 2: Drop Rows with Missing Values in Specific Column</b>
<b>df %>% drop_na(col1)</b>
<b>Method 3: Drop Rows with Missing Values in One of Several Specific Columns</b>
<b>df %>% drop_na(c(col1, col2))</b>
The following examples show how to use each of these methods in practice with the following data frame:
<b>#create data frame
df &lt;- data.frame(points=c(10, NA, 15, 15, 14, 16), assists=c(4, NA, 4, NA, 9, 3), rebounds=c(NA, 5, 10, 7, 7, NA))
#view data frame
df
  points assists rebounds
1     10       4       NA
2     NA      NA        5
3     15       4       10
4     15      NA        7
5     14       9        7
6     16       3       NA</b>
<h2>Example 1: Drop Rows with Missing Values in Any Column</h2>
The following code shows how to use <b>drop_na()</b> to drop rows with missing values in any column:
<b>library(tidyr)
#drop rows with missing values in any column
df %>% drop_na()
  points assists rebounds
1     15       4       10
2     14       9        7
</b>
The only rows left are the ones with no missing values in any column.
<h2>Example 2: Drop Rows with Missing Values in Specific Column</h2>
The following code shows how to use <b>drop_na()</b> to drop rows with missing values in the <b>rebounds </b>column:
<b>library(tidyr)
#drop rows with missing values in rebounds column
df %>% drop_na(rebounds)
  points assists rebounds
1     NA      NA        5
2     15       4       10
3     15      NA        7
4     14       9        7
</b>
The only rows left are the ones with no missing values in the <b>rebounds </b>column.
<h2>Example 3: Drop Rows with Missing Values in One of Several Specific Columns</h2>
The following code shows how to use <b>drop_na()</b> to drop rows with missing values in the <b>points</b> <i>or </i><b>assists</b> columns:
<b>library(tidyr)
#drop rows with missing values in the points or assists columns
df %>% drop_na(c(points, assists))
  points assists rebounds
1     10       4       NA
2     15       4       10
3     14       9        7
4     16       3       NA
</b>
The only rows left are the ones with no missing values in the <b>points</b> <em>or</em> <b>assists</b> columns.
<b>Note:</b> You can find the complete online documentation for the <b>drop_na()</b> method  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in R:
 How to Retrieve Row Numbers in R 
 How to Append Rows to a Data Frame in R 
 How to Apply Function to Each Row in Data Frame in R 
<h2><span class="orange">How to Use the droplevels Function in R (With Examples)</span></h2>
The <b>droplevels()</b> function in R can be used to drop unused factor levels.
This function is particularly useful if we want to drop factor levels that are no longer used due to subsetting a vector or a data frame.
This function uses the following syntax:
<b>droplevels(x)</b>
where <em>x</em> is an object from which to drop unused factor levels.
This tutorial provides a couple examples of how to use this function in practice.
<h3>Example 1: Drop Unused Factor Levels in a Vector</h3>
Suppose we create a vector of data with five factor levels. Then suppose we define a new vector of data with just three of the original five factor levels.
<b>#define data with 5 factor levels
data &lt;- factor(c(1, 2, 3, 4, 5))
#define new data as original data minus 4th and 5th factor levels
new_data &lt;- data[-c(4, 5)]
#view new data
new_data
[1] 1 2 3
Levels: 1 2 3 4 5
</b>
Although the new data only contains three factors, we can see that it still contains the original five factor levels.
To remove these unused factor levels, we can use the <b>droplevels()</b> function:
<b>#drop unused factor levels
new_data &lt;- droplevels(new_data)
#view data
new_data
[1] 1 2 3
Levels: 1 2 3</b>
The new data now contains just three factor levels.
<h3>Example 2: Drop Unused Factor Levels in a Data Frame</h3>
Suppose we create a data frame in which one of the variables is a factor with five levels. Then suppose we define a new data frame that happens to remove two of these factor levels:
<b>#create data frame
df &lt;- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')), sales = c(13, 16, 22, 27, 34))
#view data frame
df
  region sales
1      A    13
2      B    16
3      C    22
4      D    27
5      E    34
#define new data frame
new_df &lt;- subset(df, sales &lt; 25)
#view new data frame
new_df
  region sales
1      A    13
2      B    16
3      C    22
#check levels of region variable
levels(new_df$region)
[1] "A" "B" "C" "D" "E"
</b>
Although the new data frame contains only three factors in the <em>region</em> column, it still contains the original five factor levels. This would create some problems if we tried to create any plots using this data.
To remove the unused factor levels from the <em>region</em> variable, we can use the <b>droplevels()</b> function:
<b>#drop unused factor levels
new_df$region &lt;- droplevels(new_df$region)
#check levels of region variable
levels(new_df$region)
[1] "A" "B" "C"
</b>
Now the <em>region</em> variable only contains three factor levels.
You can find more R tutorials on  this page .
<h2><span class="orange">What is the Dummy Variable Trap? (Definition & Example)</span></h2>
 Linear regression  is a method we can use to quantify the relationship between one or more predictor variables and a  response variable .
Typically we use linear regression with  quantitative variables . Sometimes referred to as “numeric” variables, these are variables that represent a measurable quantity. Examples include:
Number of square feet in a house
Population size of a city
Age of an individual
However, sometimes we wish to use categorical variables as predictor variables. These are variables that take on names or labels and can fit into categories. Examples include:
Eye color (e.g. “blue”, “green”, “brown”)
Gender (e.g. “male”, “female”)
Marital status (e.g. “married”, “single”, “divorced”)
When using categorical variables, it doesn’t make sense to just assign values like 1, 2, 3, to values like “blue”, “green”, and “brown” because it doesn’t make sense to say that green is twice as colorful as blue or that brown is three times as colorful as blue.
Instead, the solution is to use  dummy variables . These are variables that we create specifically for regression analysis that take on one of two values: zero or one.
The number of dummy variables we must create is equal to <em>k</em>-1 where <em>k</em> is the number of different values that the categorical variable can take on.
For example, suppose we have the following dataset and we would like to use <em>marital status</em> and <em>age</em> to predict <em>income</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy4.png">
To use <i>marital status </i>as a predictor variable in a regression model, we must convert it into a dummy variable. 
Since it is currently a categorical variable that can take on three different values (“Single”, “Married”, or “Divorced”), we need to create <em>k</em>-1 = 3-1 = 2 dummy variables.
To create this dummy variable, we can let “Single” be our baseline value since it occurs most often. Thus, here’s how we would convert <em>marital status</em> into dummy variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy6.png">
We could then use <em>Age</em>, <em>Married</em>, and <em>Divorced </em>as predictor variables in a regression model.
When creating dummy variables, a problem that can arise is known as the <b>dummy variable trap</b>. This occurs when we create <em>k</em> dummy variables instead of <em>k</em>-1 dummy variables.
When this happens, at least two of the dummy variables will suffer from perfect  multicollinearity . That is, they’ll be perfectly correlated. This causes incorrect calculations of regression coefficients and their corresponding p-values.
<b>Dummy Variable Trap:</b> When the number of dummy variables created is equal to the number of values the categorical value can take on. This leads to multicollinearity, which causes incorrect calculations of regression coefficients and p-values.
For example, suppose we converted <em>marital status</em> into the following dummy variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyvartrap1.png">
In this case, <em>Single</em> and <em>Married</em> are perfectly correlated and have a correlation coefficient of -1.
Thus, when we go to perform multiple linear regression the calculations for the regression coefficients will be incorrect.
<h3>How to Avoid the Dummy Variable Trap</h3>
You only need to remember one rule to avoid the dummy variable trap:
<b>If a categorical variable can take on <em>k</em> different values, then you should only create <em>k-1</em> dummy variables to use in the regression model.</b>
For example, suppose you’d like to convert a categorical variable “school year” into dummy variables. Suppose this variable takes on the following values:
Freshman
Sophomore
Junior
Senior
Since this variable can take on 4 different values, we will only create 3 dummy variables. For example, our dummy variables might be:
<b>X<sub>1</sub></b> = 1 if Sophomore; 0 otherwise
<b>X<sub>2</sub></b> = 1 if Junior; 0 otherwise
<b>X<sub>3</sub></b> = 1 if Senior; 0 otherwise
Since the number of dummy variables is one less than the number of values that “school year” can take on, we can avoid the dummy variable trap and the problem of multicollinearity.
<h2><span class="orange">How to Create Dummy Variables in Excel (Step-by-Step)</span></h2>
A  dummy variable  is a type of variable that we create in regression analysis so that we can represent a categorical variable as a numerical variable that takes on one of two values: zero or one.
For example, suppose we have the following dataset and we would like to use <em>age</em> and <em>marital status </em>to predict <em>income</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy4.png">
To use <em>marital status</em> as a predictor variable in a regression model, we must convert it into a dummy variable.
Since it is currently a categorical variable that can take on three different values (“Single”, “Married”, or “Divorced”), we need to create <em>k</em>-1 = 3-1 = 2 dummy variables.
To create this dummy variable, we can let “Single” be our baseline value since it occurs most often. Here’s how we would convert <em>marital status</em> into dummy variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy6.png">
This tutorial provides a step-by-step example of how to create dummy variables for this exact dataset in Excel and then perform regression analysis using these dummy variables as predictors.
<h3>Step 1: Create the Data</h3>
First, let’s create the dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyExcel1-1.png">
<h3>Step 2: Create the Dummy Variables</h3>
Next, we can copy the values in columns A and B to columns E and F, then use the <b>IF()</b> function in Excel to define two new dummy variables: Married and Divorced.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyExcel2.png">
Here is the formula we used in cell <b>G2</b>, which we copied down to the rest of the cells in column G:
<b>=IF(C2 = "Married", 1, 0)
</b>
And here is the formula we used in cell <b>H2</b>, which we copied down to the rest of the cells in column H: 
<b>=IF(C2 = "Divorced", 1, 0)</b>
Next, we can use these dummy variables in a regression model to predict income.
<h3>Step 3: Perform Linear Regression</h3>
To perform multiple linear regression, we need to click the <b>Data</b> tab along the top ribbon, then <b>Data Analysis</b> within the <b>Analysis</b> section:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see this option available, you need to first load the  Analysis Toolpak .
In the window that pops up, click <b>Regression</b> and then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyExcel3.png">
Next, fill in the following information and then click <b>OK</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyExcel4.png">
This produces the following output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummyExcel5.png">
From the output we can see that the fitted regression line is:
Income = 14,276.12 + 1,471.67*(age) + 2,479.75*(married) – 8,397.40*(divorced)
We can use this equation to find the estimated income for an individual based on their age and marital status. For example, an individual who is 35 years old and married is estimated to have an income of <b>$68,264</b>:
Income = 14,276.12 + 1,471.67*(35) + 2,479.75*(1) – 8,397.40*(0) = $68,264
Here is how to interpret the regression coefficients from the table:
<b>Intercept:</b> The intercept represents the average income for a single individual who is zero years old. Since an individual can’t be zero years old, it doesn’t make sense to interpret the intercept by itself in this particular regression model.
<b>Age:</b> Each one year increase in age is associated with an average increase of $1,471.67 in income. Since the p-value (.004) is less than .05, age is a statistically significant predictor of income.
<b>Married: </b>A married individual, on average, earns $2,479.75 more than a single individual. Since the p-value (0.800) is not less than .05, this difference is not statistically significant.
<b>Divorced: </b>A divorced individual, on average, earns $8,397.40 less than a single individual. Since the p-value (0.532) is not less than .05, this difference is not statistically significant.
Since both dummy variables were not statistically significant, we could drop <em>marital status</em> as a predictor from the model because it doesn’t appear to add any predictive value for income.
<h2><span class="orange">How to Create Dummy Variables in R (Step-by-Step)</span></h2>
A  dummy variable  is a type of variable that we create in regression analysis so that we can represent a categorical variable as a numerical variable that takes on one of two values: zero or one.
For example, suppose we have the following dataset and we would like to use <em>age</em> and <em>marital status </em>to predict <em>income</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy4.png">
To use <em>marital status</em> as a predictor variable in a regression model, we must convert it into a dummy variable.
Since it is currently a categorical variable that can take on three different values (“Single”, “Married”, or “Divorced”), we need to create <em>k</em>-1 = 3-1 = 2 dummy variables.
To create this dummy variable, we can let “Single” be our baseline value since it occurs most often. Thus, here’s how we would convert <em>marital status</em> into dummy variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy6.png">
This tutorial provides a step-by-step example of how to create dummy variables for this exact dataset in R and then perform regression analysis using these dummy variables as predictors.
<h3>Step 1: Create the Data</h3>
First, let’s create the dataset in R:
<b>#create data frame
df &lt;- data.frame(income=c(45000, 48000, 54000, 57000, 65000, 69000,          78000, 83000, 98000, 104000, 107000), age=c(23, 25, 24, 29, 38, 36, 40, 59, 56, 64, 53), status=c('Single', 'Single', 'Single', 'Single',          'Married', 'Single', 'Married', 'Divorced',          'Divorced', 'Married', 'Married'))
#view data frame
df
   income age   status
1   45000  23   Single
2   48000  25   Single
3   54000  24   Single
4   57000  29   Single
5   65000  38  Married
6   69000  36   Single
7   78000  40  Married
8   83000  59 Divorced
9   98000  56 Divorced
10 104000  64  Married
11 107000  53  Married</b>
<h3>Step 2: Create the Dummy Variables</h3>
Next, we can use the <b>ifelse()</b> function in R to define dummy variables and then define the final data frame we’d like to use to build the regression model:
<b>#create dummy variables
married &lt;- ifelse(df$status == 'Married', 1, 0)
divorced &lt;- ifelse(df$status == 'Divorced', 1, 0)
#create data frame to use for regression
df_reg &lt;- data.frame(income = df$income,     age = df$age,     married = married,     divorced = divorced)
#view data frame
df_reg
   income age married divorced
1   45000  23       0        0
2   48000  25       0        0
3   54000  24       0        0
4   57000  29       0        0
5   65000  38       1        0
6   69000  36       0        0
7   78000  40       1        0
8   83000  59       0        1
9   98000  56       0        1
10 104000  64       1        0
11 107000  53       1        0
</b>
<h3>Step 3: Perform Linear Regression</h3>
Lastly, we can use the <b>lm()</b> function to fit a multiple linear regression model:
<b>#create regression model
model &lt;- lm(income ~ age + married + divorced, data=df_reg)
#view regression model output
summary(model)
Call:
lm(formula = income ~ age + married + divorced, data = df_reg)
Residuals:
    Min      1Q  Median      3Q     Max 
-9707.5 -5033.8    45.3  3390.4 12245.4 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)  14276.1    10411.5   1.371  0.21266   
age           1471.7      354.4   4.152  0.00428 **
married       2479.7     9431.3   0.263  0.80018   
divorced     -8397.4    12771.4  -0.658  0.53187   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 8391 on 7 degrees of freedom
Multiple R-squared:  0.9008,Adjusted R-squared:  0.8584 
F-statistic:  21.2 on 3 and 7 DF,  p-value: 0.0006865
</b>
The fitted regression line turns out to be:
Income = 14,276.1 + 1,471.7*(age) + 2,479.7*(married) – 8,397.4*(divorced)
We can use this equation to find the estimated income for an individual based on their age and marital status. For example, an individual who is 35 years old and married is estimated to have an income of <b>$68,264</b>:
Income = 14,276.2 + 1,471.7*(35) + 2,479.7*(1) – 8,397.4*(0) = $68,264
Here is how to interpret the regression coefficients from the table:
<b>Intercept:</b> The intercept represents the average income for a single individual who is zero years old. Obviously you can’t be zero years old, so it doesn’t make sense to interpret the intercept by itself in this particular regression model.
<b>Age:</b> Each one year increase in age is associated with an average increase of $1,471.70 in income. Since the p-value (.004) is less than .05, age is a statistically significant predictor of income.
<b>Married: </b>A married individual, on average, earns $2,479.70 more than a single individual. Since the p-value (0.800) is not less than .05, this difference is not statistically significant.
<b>Divorced: </b>A divorced individual, on average, earns $8,397.40 less than a single individual. Since the p-value (0.532) is not less than .05, this difference is not statistically significant.
Since both dummy variables were not statistically significant, we could drop <em>marital status</em> as a predictor from the model because it doesn’t appear to add any predictive value for income.
<h2><span class="orange">How to Use Dummy Variables in Regression Analysis</span></h2>
 Linear regression  is a method we can use to quantify the relationship between one or more predictor variables and a  response variable .
Typically we use linear regression with  quantitative variables . Sometimes referred to as “numeric” variables, these are variables that represent a measurable quantity. Examples include:
Number of square feet in a house
Population size of a city
Age of an individual
However, sometimes we wish to use categorical variables as predictor variables. These are variables that take on names or labels and can fit into categories. Examples include:
Eye color (e.g. “blue”, “green”, “brown”)
Gender (e.g. “male”, “female”)
Marital status (e.g. “married”, “single”, “divorced”)
When using categorical variables, it doesn’t make sense to just assign values like 1, 2, 3, to values like “blue”, “green”, and “brown” because it doesn’t make sense to say that green is twice as colorful as blue or that brown is three times as colorful as blue.
Instead, the solution is to use <b>dummy variables</b>. These are variables that we create specifically for regression analysis that take on one of two values: zero or one.
<b>Dummy Variables:</b> Numeric variables used in regression analysis to represent categorical data that can only take on one of two values: zero or one.
The number of dummy variables we must create is equal to <em>k</em>-1 where <em>k</em> is the number of different values that the categorical variable can take on.
The following examples illustrate how to create dummy variables for different datasets.
<h3>Example 1: Create a Dummy Variable with Only Two Values</h3>
Suppose we have the following dataset and we would like to use <em>gender</em> and <em>age</em> to predict <em>income</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy1.png">
To use <em>gender</em> as a predictor variable in a regression model, we must convert it into a dummy variable. 
Since it is currently a categorical variable that can take on two different values (“Male” or “Female”), we only need to create <em>k</em>-1 = 2-1 = 1 dummy variable.
To create this dummy variable, we can choose one of the values (“Male” or “Female”) to represent 0 and the other to represent 1.
In general, we usually represent the most frequently occurring value with a 0, which would be “Male” in this dataset.
Thus, here’s how we would convert <em>gender</em> into a dummy variable:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy2.png">
We could then use <em>Age</em> and <em>Gender_Dummy</em> as predictor variables in a regression model.
<h3>Example 2: Create a Dummy Variable with Multiple Values</h3>
Suppose we have the following dataset and we would like to use <em>marital status</em> and <em>age</em> to predict <em>income</em>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy4.png">
To use <i>marital status </i>as a predictor variable in a regression model, we must convert it into a dummy variable. 
Since it is currently a categorical variable that can take on three different values (“Single”, “Married”, or “Divorced”), we need to create <em>k</em>-1 = 3-1 = 2 dummy variables.
To create this dummy variable, we can let “Single” be our baseline value since it occurs most often. Thus, here’s how we would convert <em>marital status</em> into dummy variables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy6.png">
We could then use <em>Age</em>, <em>Married</em>, and <em>Divorced </em>as predictor variables in a regression model.
<h3>How to Interpret Regression Output with Dummy Variables</h3>
Suppose we fit a  multiple linear regression  model using the dataset in the previous example with <em>Age</em>, <em>Married</em>, and <em>Divorced</em> as the predictor variables and <em>Income</em> as the response variable.
Here’s the regression output:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/dummy7.png">
The fitted regression line is defined as:
Income = 14,276.21 + 1,471.67*(Age) + 2,479.75*(Married) – 8,397.40*(Divorced)
We can use this equation to find the estimated income for an individual based on their age and marital status. For example, an individual who is 35 years old and married is estimated to have an income of <b>$68,264</b>:
Income = 14,276.21 + 1,471.67*(35) + 2,479.75*(1) – 8,397.40*(0) = $68,264
Here is how to interpret the regression coefficients from the table:
<b>Intercept:</b> The intercept represents the average income for a single individual who is zero years old. Obviously you can’t be zero years old, so it doesn’t make sense to interpret the intercept by itself in this particular regression model.
<b>Age:</b> Each one year increase in age is associated with an average increase of $1,471.67 in income. Since the p-value (.00) is less than .05, age is a statistically significant predictor of income.
<b>Married: </b>A married individual, on average, earns $2,479.75 more than a single individual. Since the p-value (0.80) is not less than .05, this difference is not statistically significant.
<b>Divorced: </b>A divorced individual, on average, earns $8,397.40 less than a single individual. Since the p-value (0.53) is not less than .05, this difference is not statistically significant.
Since both dummy variables were not statistically significant, we could drop <em>marital status</em> as a predictor from the model because it doesn’t appear to add any predictive value for income.
<h2><span class="orange">How to Perform Dunnett’s Test in R</span></h2>
A  post-hoc test  is a type of test that is performed following an  ANOVA  to determine which group means are statistically significantly different from each other.
If one of the groups in the study is considered the <em>control group</em>, then we should use  Dunnett’s test  as the post-hoc test.
This tutorial explains how to perform Dunnett’s test in R.
<h3>Example: Dunnett’s Test in R</h3>
Suppose a teacher wants to know whether or not two new studying techniques have the potential to increase exam scores for her students. To test this, she randomly splits her class of 30 students into the following three groups:
Control Group: 10 students
New Study technique 1: 10 students
New Study Technique 2: 10 students
After one week of using their assigned study technique, each student takes the same exam.
We can use the following steps in R to create a dataset, visualize the group means, perform a one-way ANOVA, and lastly perform Dunnett’s test to determine which (if either) new studying technique produces different results compared to the control group.
<b>Step 1: Create the dataset.</b>
The following code shows how to create a dataset that contains exam scores for all 30 students:
<b>#create data frame
data &lt;- data.frame(technique = rep(c("control", "new1", "new2"), each = 10),   score = c(76, 77, 77, 81, 82, 82, 83, 84, 85, 89,             81, 82, 83, 83, 83, 84, 87, 90, 92, 93,             77, 78, 79, 88, 89, 90, 91, 95, 95, 98))
#view first six rows of data frame
head(data)
  technique score
1   control    76
2   control    77
3   control    77
4   control    81
5   control    82
6   control    82
</b>
<b>Step 2: Visualize the exam scores for each group.</b>
The following code shows how to produce boxplots to visualize the distribution of exam scores for each group:
<b>boxplot(score ~ technique,
        data = data,
        main = "Exam Scores by Studying Technique",
        xlab = "Studying Technique",
        ylab = "Exam Scores",
        col = "steelblue",
        border = "black")
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/dunnettsR.png">
Just from the boxplots we can see that the distribution of exam scores is quite different for each studying technique. Next, we’ll perform a one-way ANOVA to determine if these differences are statistically significant.
<b>Related: </b> How to Plot Multiple Boxplots in One Chart in R 
<b>Step 3: Perform a one-way ANOVA.</b>
The following code shows how to perform a one-way ANOVA to test for differences among mean exam scores in each group:
<b>#fit the one-way ANOVA model
model &lt;- aov(score ~ technique, data = data)
#view model output
summary(model)
            Df Sum Sq Mean Sq F value Pr(>F)  
technique    2  211.5  105.73   3.415 0.0476 *
Residuals   27  836.0   30.96                 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</b>
Since the overall p-value (<b>0.0476</b>) is less than .05, this is an indication that each group does not have the same average exam score. Next, we will perform Dunnett’s Test to determine which studying technique produces mean exam scores that differ from the control group.
<b>Step 4: Perform Dunnett’s Test.</b>
To perform Dunnett’s Test in R we can use the <b>DunnettTest() </b>function from the <b>DescTools </b>library which uses the following syntax:
<b>DunnettTest(x, g)</b>
where:
<b>x:</b> A numeric vector of data values (e.g. exam scores)
<b>g:</b> A vector that specifies the group names (e.g. studying technique)
The following code shows how to use this function for our example:
<b>#load DescTools library
library(DescTools)
#perform Dunnett's Test
DunnettTest(x=data$score, g=data$technique)
  Dunnett's test for comparing several treatments with a control :  
    95% family-wise confidence level
$control
             diff     lwr.ci   upr.ci   pval    
new1-control  4.2 -1.6071876 10.00719 0.1787    
new2-control  6.4  0.5928124 12.20719 0.0296 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.' 0.1 ' ' 1</b>
The way to interpret the output is as follows:
The mean difference in exam scores between the new studying technique 1 and the control group is <b>4.2</b> The corresponding p-value is <b>0.1787</b>.
The mean difference in exam scores between the new studying technique 2 and the control group is <b>6.4</b> The corresponding p-value is <b>0.0296</b>.
Based on the output, we can see that studying technique 2 is the only technique that produces significantly (p = .0296) different mean exam scores compared to the control group.
<h2><span class="orange">How to Use Dunnett’s Test for Multiple Comparisons</span></h2>
An  ANOVA (Analysis of Variance)  is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups. 
If the  p-value  from the ANOVA is less than some chosen significance level, we can reject the null hypothesis and conclude that we have sufficient evidence to say that at least one of the means of the groups is different from the others.
However, this doesn’t tell us <em>which </em>groups are different from each other. It simply tells us that not all of the group means are equal. In order to find out exactly which groups are different from each other, we must conduct a  post-hoc test .
If one of the groups in the study is considered the <em>control group</em>, then we should use <b>Dunnett’s test </b>as the post-hoc test following the ANOVA.
<h3>Dunnett’s Test: Definition</h3>
We can use the following two steps to perform Dunnett’s test:
<b>Step 1: Find Dunnett’s critical value.</b>
First, we must find Dunnett’s critical value. This is calculated as:
<b>Dunnett’s Critical value: t<sub>d</sub>√2MS<sub>w</sub>/n</b>
where:
<b>t<sub>d</sub>: </b>The value found in  Dunnett’s Table  for a given alpha level, number of groups, and group sample sizes.
<b>MS<sub>w</sub>: </b>The Mean Squares of the “Within Group” in the ANOVA output table
<b>n: </b>The size of the group samples
<b>Step 2: Compare the differences in group means to Dunnett’s critical value.</b>
Next, we calculate the absolute difference between the mean of each group with the mean of the control group. If the difference exceeds Dunnett’s critical value, then that difference is said to be statistically significant.
The following example shows how to perform Dunnett’s test in practice.
<h3>Dunnett’s Test: Example</h3>
Suppose a teacher wants to know whether or not two new studying techniques have the potential to increase exam scores for her students. To test this, she randomly splits her class of 30 students into the following three groups:
Control Group: 10 students
New Study technique 1: 10 students
New Study Technique 2: 10 students
After one week of using their assigned study technique, each student takes the same exam. The results are as follows:
Mean exam score of control group: <b>81.6</b>
Mean exam score of new study technique 1 group: <b>85.8</b>
Mean exam score of new study technique 2 group: <b>87.7</b>
Mean Squares of the “Within Group” in the ANOVA output table: <b>23.3</b>
Using this information, we can perform Dunnett’s test to determine if either of the two new study techniques produce significantly different mean exam scores compared to the control group.
<b>Step 1: Find Dunnett’s critical value.</b>
Using α = .05, group sample size n = 10 and total groups = 3,  Dunnett’s table  tells us to use a value of <b>2.57 </b>in the critical value calculation.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/09/dunnets1.png">
Next, we can plug this number into the formula to find Dunnett’s Critical value:
<b>Dunnett’s Critical value: </b>t<sub>d</sub>√2MS<sub>w</sub>/n  =  2.57√2(23.3)/10  =<b>  5.548</b>
<b>Step 2: Compare the differences in group means to Dunnett’s critical value.</b>
The absolute difference between the means of each study technique and the control group are as follows:
Abs. diff between new technique 1 and control: |85.8 – 81.6| = <b>4.2</b>
Abs. diff between new technique 2 and control: |87.7 – 81.6| = <b>6.1</b>
Only the absolute difference between technique 2 and the control group is greater than Dunnett’s critical value of <b>5.548</b>.
Thus, we can say that the new studying technique #2 produces significantly different exam scores compared to the control group, but the new studying technique #1 does not.
<h2><span class="orange">How to Perform Dunn’s Test in R</span></h2>
A  Kruskal-Wallis test  is used to determine whether or not there is a statistically significant difference between the medians of three or more independent groups. It is considered to be the non-parametric equivalent of the  One-Way ANOVA .
If the results of a Kruskal-Wallis test are statistically significant, then it’s appropriate to conduct  Dunn’s Test  to determine exactly which groups are different.
This tutorial explains how to perform Dunn’s Test in R.
<h3>Example: Dunn’s Test in R</h3>
A researcher wants to know whether or not three drugs have different effects on back pain, so he recruits 30 individuals who all experience similar back pain and randomly splits them up into three groups to receive either Drug A, Drug B, or Drug C. After one month of taking the drug, the researcher asks each individual to rate their back pain on a scale of 1 to 100, with 100 indicating the most severe pain.
The researcher conducts a Kruskal-Wallis test using a .05 significance level to determine if there is a statistically significant difference between the median back pain ratings across these three groups.
The following code shows how to create the data frame in R and perform a Kruskal-Wallis test:
<b>#make this example reproducible
set.seed(0)
#create data frame
data &lt;- data.frame(drug = rep(c("A", "B", "C"), each = 10),   pain = c(runif(10, 40, 60),            runif(10, 45, 65),            runif(10, 55, 70)))
#view first six rows of data frame
head(data)
#  drug     pain
#1    A 57.93394
#2    A 45.31017
#3    A 47.44248
#4    A 51.45707
#5    A 58.16416
#6    A 44.03364
#perform Kruskal-Wallis Test
kruskal.test(pain ~ drug, data = data)
Kruskal-Wallis rank sum test
data:  pain by drug
Kruskal-Wallis chi-squared = 11.105, df = 2, p-value = 0.003879
</b>
Since the overall p-value (<b>0.003879</b>) is less than .05, this means there is a statistically significant difference between the reported pain levels among the three drugs. Thus, we can perform Dunn’s test to determine exactly which drugs are different.
The following code shows how to perform Dunn’s Test in R by using the  dunnTest()  function from the <b>FSA()</b> library:
<b>#load library
library(FSA)
#perform Dunn's Test with Bonferroni correction for p-values
dunnTest(pain ~ drug,
         data=data,
         method="bonferroni")
Dunn (1964) Kruskal-Wallis multiple comparison
  p-values adjusted with the Bonferroni method.
  Comparison          Z     P.unadj       P.adj
1      A - B -0.8890009 0.374002602 1.000000000
2      A - C -3.2258032 0.001256197 0.003768591
3      B - C -2.3368023 0.019449464 0.058348393</b>
Note that we chose to use a Bonferroni correction for the p-values of the multiple comparisons, but other possible options include:
“sidak” (Sidak adjustment)
“holm” (Holm Adjustment)
“hs’ (Holm-Sidak Adjustment)
“bs” (Bonferroni-Sidak Adjustment)
“by” (Benjamini-Yekuteili Adjustment)
“bh” ( Benjamini-Hochberg procedure )
At α = .05, drugs A and C are the only two drugs that are statistically significantly different from each other (adjusted p-value = <b>.003768</b>).
<h2><span class="orange">How to Perform Dunn’s Test in Python</span></h2>
A  Kruskal-Wallis test  is used to determine whether or not there is a statistically significant difference between the medians of three or more independent groups. It is considered to be the non-parametric equivalent of the  One-Way ANOVA .
If the results of a Kruskal-Wallis test are statistically significant, then it’s appropriate to conduct  Dunn’s Test  to determine exactly which groups are different.
This tutorial explains how to perform Dunn’s Test in Python.
<h3>Example: Dunn’s Test in Python</h3>
Researchers want to know if three different fertilizers lead to different levels of plant growth. They randomly select 30 different plants and split them into three groups of 10, applying a different fertilizer to each group. At the end of one month they measure the height of each plant.
Upon performing a Kruskal-Wallis Test, they find that the overall p-value is statistically significant, which means the median growth is the not same across the three groups. Next, they perform Dunn’s test to determine exactly which groups are different.
To perform Dunn’s test in Python, we can use the  posthoc_dunn()  function from the scikit-posthocs library.
The following code shows how to use this function:
<b>Step 1: Install scikit-posthocs.</b>
First we need to install the scikit-posthocs library:
<b>pip install scikit-posthocs
</b>
<b>Step 2: Perform Dunn’s test.</b>
Next, we can create the data and perform Dunn’s test:
<b>#specify the growth of the 10 plants in each group
group1 = [7, 14, 14, 13, 12, 9, 6, 14, 12, 8]
group2 = [15, 17, 13, 15, 15, 13, 9, 12, 10, 8]
group3 = [6, 8, 8, 9, 5, 14, 13, 8, 10, 9]
data = [group1, group2, group3]
#perform Dunn's test using a Bonferonni correction for the p-values
import scikit_posthocs as sp
sp.posthoc_dunn(data, p_adjust = 'bonferroni')
               1       2       3
11.0000000.5508460.718451
20.5508461.0000000.036633
30.7184510.0366331.000000
</b>
Note that we chose to use a Bonferroni correction for the p-values to control the  family-wise error rate , but other potential choices for the <b>p_adjust </b>argument include:
 sidak
holm-sidak
simes-hochberg
hommel
fdr_bh
fdr_by
fdr_tsbh
Refer to the  documentation  for more details on each of these p-value adjustment methods.
<b>Step 3: Interpret the results.</b>
From the results of Dunn’s test we can observe the following:
The adjusted p-value for the difference between group 1 and group 2 is <b>0.550846</b>.
The adjusted p-value for the difference between group 1 and group 3 is <b>0.718451</b>.
The adjusted p-value for the difference between group 2 and group 3 is <b>0.036633</b>.
Thus, the only two groups that are statistically significantly different at α = .05 are groups 2 and 3.
<h2><span class="orange">Dunn’s Test for Multiple Comparisons</span></h2>
A  Kruskal-Wallis test  is used to determine whether or not there is a statistically significant difference between the medians of three or more independent groups. It is considered to be the non-parametric equivalent of the  One-Way ANOVA .
If the results of a Kruskal-Wallis test are statistically significant, then it’s appropriate to conduct <b>Dunn’s Test</b> to determine exactly which groups are different.
Dunn’s Test performs pairwise comparisons between each independent group and tells you which groups are statistically significantly different at some level of α.
For example, suppose a researcher wants to know whether three different drugs have different effects on back pain. He recruits 30 subjects for the study and randomly assigns them to use Drug A, Drug B, or Drug C for one month and then measures their back pain at the end of the month.
The researcher can perform a Kruskal-Wallis test to determine if the median back pain is equal among the three drugs. If the p-value of the Kruskal-Wallis test is below a certain threshold, it can be said that the three drugs produce different effects. 
Following this, the researcher could then perform Dunn’s Test to determine <em>which </em>drugs produce statistically significant effects.
<h3>Dunn’s Test: The Formula</h3>
You will likely never have to perform Dunn’s Test by hand since it can be performed using statistical software (like R, Python, Stata, SPSS, etc.) but the formula to calculate the z-test statistic for the difference between two groups is:
z<sub>i</sub> = y<sub>i</sub> / σ<sub>i</sub>
where <em>i </em>is one of the 1 to <em>m </em>comparisons, y<sub>i</sub> =W<sub>A</sub> – W<sub>B</sub> (where W<sub>A</sub> is the average of the sum of the ranks for the i<sup>th</sup> group) and σ<sub>i </sub>is calculated as:
σ<sub>i  </sub>=  √((N(N+1)/12) – (ΣT<sup>3</sup><sub>s</sub> – T<sub>s</sub>/(12(N-1)) / ((1/n<sub>A</sub>)+(1/n<sub>B</sub>))
where <em>N </em>is the total number of observations across all groups, <em>r </em>is the number of tied ranks, and T<sub>s</sub> is the number of observations tied at the <em>s</em>th specific tied value.
<h3>How to Control the Family-wise Error Rate</h3>
Whenever we make multiple comparisons at once, it’s important that we control the  family-wise error rate . One way to do so is to adjust the p-values that results from the multiple comparisons.
There are several ways to adjust the p-values, but the two most common adjustment methods are:
<b>1. The Bonferroni Adjustment</b>
Adjusted p-value = p*m
where:
<b>p: </b>The original p-value
<b>m: </b>The total number of comparisons being made
<b>2. The Sidak Adjustment</b>
Adjusted p-value = 1 – (1-p)<sup>m</sup>
where:
<b>p: </b>The original p-value
<b>m: </b>The total number of comparisons being made
By using one of these p-value adjustments, we can dramatically reduce the probability of committing a type I error among the set of multiple comparisons.
<h2><span class="orange">Durbin-Watson Table</span></h2>
The following table provides the critical values for the Durbin-Watson Test for a given sample size (n), number of independent variables (k), and alpha level.
 <img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/01/durbinWatson1.jpg"> 
  
  
<h2><span class="orange">How to Perform a Durbin-Watson Test in Excel</span></h2>
One of the  key assumptions in linear regression  is that there is no correlation between the residuals, e.g. the residuals are independent.
One way to determine if this assumption is met is to perform a  Durbin-Watson test , which is used to detect the presence of autocorrelation in the residuals of a regression. This test uses the following hypotheses:
<b>H<sub>0</sub> (null hypothesis): </b>There is no correlation among the residuals.
<b>H<sub>A</sub> (alternative hypothesis): </b>The residuals are autocorrelated.
This tutorial provides a step-by-step example of how to perform a Durbin-Watson test in Excel.
<h3>Step 1: Enter the Data</h3>
First, we’ll enter the values for a dataset that we’d like to build a  multiple linear regression model :
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/durbinExcel1.png">
<h3>Step 2: Fit a Multiple Linear Regression Model</h3>
Next, we’ll fit a multiple linear regression model using y as the response variable and x1 and x2 as predictor variables.
To do so, click the <b>Data</b> tab along the top ribbon. Then click <b>Data Analysis</b> within the <b>Analyze</b> group.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/02/twoSampExcel3.png">
If you don’t see this as an option, you need to first  load the Analysis ToolPak .
In the window that appears, click <b>Regression</b> and then click <b>OK</b>. In the new window that appears, fill in the following information:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/durbinExcel2.png">
Once you click <b>OK</b>, the regression output will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/durbinExcel3.png">
<h3>Step 3: Perform the Durbin-Watson Test</h3>
The test statistic for the Durbin-Watson test, denoted <em>d</em>, is calculated as follows:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/durbinWatson1.png">
where:
<b>T:</b> The total number of observations
<b>e<sub>t</sub>:</b> The t<sup>th</sup> residual from the regression model
To calculate this test statistic in Excel, we can use the following formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/durbinExcel4.png">
The test statistic turns out to be <b>1.3475</b>.
To determine if a Durbin-Watson test statistic is significantly significant at a certain alpha level, we can refer to  this table  of critical values.
For α = .05, n = 13 observations, and k = 2 independent variables in the regression model, the Durbin-Watson table shows the following upper and lower critical values:
Lower critical value:<b> 0.86</b>
Upper critical value: <b>1.56</b>
Since our test statistic of <b>1.3475</b> does not lie outside of this range, we do not have sufficient evidence to reject the null hypothesis of the Durbin-Watson test.
In other words, there is no correlation among the residuals.
<h3>What to Do if Autocorrelation is Detected</h3>
If you reject the null hypothesis and conclude that autocorrelation is present in the  residuals , then you have a few different options to correct this problem if it’s serious enough:
For positive serial correlation, consider adding lags of the dependent and/or independent variable to the model.
For negative serial correlation, check to make sure that none of your variables are <em>overdifferenced</em>.
For seasonal correlation, consider adding seasonal  dummy variables  to the model.
<h2><span class="orange">How to Perform a Durbin-Watson Test in Python</span></h2>
One of the  assumptions of linear regression  is that there is no correlation between the residuals. In other words, the residuals are assumed to be independent.
One way to determine if this assumption is met is to perform a  Durbin-Watson test , which is used to detect the presence of autocorrelation in the residuals of a  regression . This test uses the following hypotheses:
<b>H<sub>0</sub> (null hypothesis): </b>There is no correlation among the residuals.
<b>H<sub>A</sub> (alternative hypothesis): </b>The residuals are autocorrelated.
The test statistic is approximately equal to 2*(1-r) where r is the sample autocorrelation of the residuals. Thus, the test statistic will always be between 0 and 4 with the following interpretation:
A test statistic of <b>2 </b>indicates no serial correlation.
The closer the test statistics is to <b>0</b>, the more evidence of positive serial correlation.
The closer the test statistics is to <b>4</b>, the more evidence of negative serial correlation.
As a rule of thumb, test statistic values between the range of 1.5 and 2.5 are considered normal. However, values outside of this range could indicate that autocorrelation is a problem.
This tutorial explains how to perform a Durbin-Watson test in Python.
<h3>Example: Durbin-Watson Test in Python</h3>
Suppose we have the following dataset that describes the attributes of 10 basketball players:
<b>import numpy as np
import pandas as pd
#create dataset
df = pd.DataFrame({'rating': [90, 85, 82, 88, 94, 90, 76, 75, 87, 86],   'points': [25, 20, 14, 16, 27, 20, 12, 15, 14, 19],   'assists': [5, 7, 7, 8, 5, 7, 6, 9, 9, 5],   'rebounds': [11, 8, 10, 6, 6, 9, 6, 10, 10, 7]})
#view dataset
df
ratingpointsassistsrebounds
09025511
1852078
28214710
3881686
4942756
5902079
6761266
77515910
88714910
9861957</b>
Suppose we fit a multiple linear regression model using <em>rating </em>as the response variable and the other three variables as the predictor variables:
<b>from statsmodels.formula.api import ols
#fit multiple linear regression model
model = ols('rating ~ points + assists + rebounds', data=df).fit()
#view model summary
print(model.summary())
</b>
We can perform a Durbin Watson using the  durbin_watson() function  from the statsmodels library to determine if the residuals of the regression model are autocorrelated:
<b>from statsmodels.stats.stattools import durbin_watson
#perform Durbin-Watson test
durbin_watson(model.resid)
2.392</b>
The test statistic is <b>2.392</b>. Since this is within the range of 1.5 and 2.5, we would consider autocorrelation not to be problematic in this regression model.
<h3>How to Handle Autocorrelation</h3>
If you reject the null hypothesis and conclude that autocorrelation is present in the residuals, then you have a few different options to correct this problem if you deem it to be serious enough:
<b>1. </b>For positive serial correlation, consider adding lags of the dependent and/or independent variable to the model.
<b>2. </b>For negative serial correlation, check to make sure that none of your variables are <em>overdifferenced</em>.
<b>3. </b>For seasonal correlation, consider adding seasonal dummy variables to the model.
<h2><span class="orange">How to Perform a Durbin-Watson Test in R</span></h2>
One of the  key assumptions in linear regression  is that there is no correlation between the residuals, e.g. the residuals are independent.
One way to determine if this assumption is met is to perform a  Durbin-Watson test , which is used to detect the presence of autocorrelation in the residuals of a regression. This test uses the following hypotheses:
<b>H<sub>0</sub> (null hypothesis): </b>There is no correlation among the residuals.
<b>H<sub>A</sub> (alternative hypothesis): </b>The residuals are autocorrelated.
This tutorial explains how to perform a Durbin-Watson test in R.
<h3>Example: Durbin-Watson Test in R</h3>
To perform a Durbin-Watson test, we first need to fit a linear regression model. We will use the built-in R dataset <b>mtcars </b>and fit a regression model using <b>mpg </b>as the predictor variable and <b>disp </b>and <b>wt </b>as explanatory variables.
<b>#load mtcars dataset
data(mtcars)
#view first six rows of dataset
head(mtcars)
   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
#fit regression model
model &lt;- lm(mpg ~ disp+wt, data=mtcars)
</b>
Next, we can perform a Durbin-Watson test using the <b>durbinWatsonTest() </b>function from the <b>car </b>package:
<b>#load car package
library(car)
#perform Durbin-Watson test
durbinWatsonTest(model)
Loading required package: carData
 lag Autocorrelation D-W Statistic p-value
   1        0.341622      1.276569   0.034
 Alternative hypothesis: rho != 0</b>
From the output we can see that the test statistic is <b>1.276569 </b>and the corresponding p-value is <b>0.034</b>. Since this p-value is less than 0.05, we can reject the null hypothesis and conclude that the residuals in this regression model are autocorrelated.
<h3>What to Do if Autocorrelation is Detected</h3>
If you reject the null hypothesis and conclude that autocorrelation is present in the residuals, then you have a few different options to correct this problem if you deem it to be serious enough:
For positive serial correlation, consider adding lags of the dependent and/or independent variable to the model.
For negative serial correlation, check to make sure that none of your variables are <em>overdifferenced</em>.
For seasonal correlation, consider adding seasonal dummy variables to the model.
<h2><span class="orange">The Durbin-Watson Test: Definition & Example</span></h2>
One of the  main assumptions in linear regression  is that there is no correlation between consecutive  residuals . In other words, it’s assumed that the residuals are independent.
When this assumption is violated, the standard errors of the coefficients in a regression model are likely to be underestimated which means predictor variables are more likely to be deemed  statistically significant  when they’re actually not.
One way to determine if this assumption is met is to perform a <b>Durbin-Watson test</b>, which is used to detect the presence of autocorrelation in the residuals of a regression.
<h3>Steps to Perform a Durbin-Watson Test</h3>
The Durbin-Watson test uses the following hypotheses:
<b>H<sub>0</sub> (null hypothesis): </b>There is no correlation among the residuals.
<b>H<sub>A</sub> (alternative hypothesis): </b>The residuals are autocorrelated.
The test statistic for the Durbin-Watson test, typically denoted <em>d</em>, is calculated as follows:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/01/durbinWatson1.png">
where:
<b>T:</b> The total number of  observations 
<b>e<sub>t</sub>:</b> The t<sup>th</sup> residual from the regression model
The test statistic always ranges from 0 to 4 where:
<em>d</em> = 2 indicates no autocorrelation
<em>d</em> &lt; 2 indicates positive serial correlation
<em>d</em> > 2 indicates negative serial correlation
In general, if <em>d</em> is less than 1.5 or greater than 2.5 then there is potentially a serious autocorrelation problem. Otherwise, if <em>d</em> is between 1.5 and 2.5 then autocorrelation is likely not a cause for concern.
To determine if a Durbin-Watson test statistic is significantly significant at a certain alpha level, you can refer to  this table  of critical values.
If the absolute value of the Durbin-Watson test statistic is greater than the value found in the table, then you can reject the null hypothesis of the test and conclude that  autocorrelation is present.
<h3>What to Do if Autocorrelation is Detected</h3>
If you reject the null hypothesis of the Durbin-Watson test and conclude that autocorrelation is present in the residuals, then you have a few different options to correct this problem if you deem it to be serious enough:
For positive serial correlation, consider adding lags of the dependent and/or independent variable to the model.
For negative serial correlation, check to make sure that none of your variables are <em>overdifferenced</em>.
For seasonal correlation, consider adding seasonal dummy variables to the model.
These strategies are typically sufficient to remove the problem of autocorrelation.
<h3>Examples of Performing a Durbin-Watson Test</h3>
For step-by-step examples of Durbin-Watson tests, refer to these tutorials that explain how to perform the test using different statistical software:
 How to Perform a Durbin-Watson Test in R 
 How to Perform a Durbin-Watson Test in Python 
 How to Perform a Durbin-Watson Test in Excel 
<h2><span class="orange">Three Ways to Calculate Effect Size for a Chi-Square Test</span></h2>
In statistics, there are two commonly used Chi-Square tests:
<b> Chi-Square Test for Goodness of Fit </b>: Used to determine whether or not a categorical variable follows a hypothesized distribution.
<b> Chi-Square Test for Independence : </b>Used to determine whether or not there is a significant association between two categorical variables from a single population.
For both of these tests, we end up with a p-value that tells us whether or not we should reject the null hypothesis of the test. The p-value tells us whether or not the results of the test are significant, but it doesn’t tell us the  effect size  of the test.
There are three ways to measure effect size: Phi (φ), Cramer’s V (V), and odds ratio (OR).
In this post we explain how to calculate each of these effect sizes along with when it’s appropriate to use each one.
<h2>Phi (φ)</h2>
<h3>How to Calculate </h3>
Phi is calculated as φ = √(<em>X</em><sup>2</sup> / n)
where:
<em>X</em><sup>2</sup> is the Chi-Square test statistic
n = total number of observations
<h3>When to Use</h3>
It’s appropriate to calculate φ only when you’re working with a 2 x 2 contingency table (i.e. a table with exactly two rows and two columns).
<h3>How to Interpret</h3>
A value of φ  = 0.1 is considered to be a small effect, 0.3 a medium effect, and 0.5 a large effect.
<h2>Cramer’s V (V)</h2>
<h3>How to Calculate </h3>
Cramer’s V is calculated as V = √(<em>X</em><sup>2</sup> / n*df)
where:
<em>X</em><sup>2</sup> is the Chi-Square test statistic
n = total number of observations
df = (#rows-1) * (#columns-1)
<h3>When to Use</h3>
It’s appropriate to calculate V when you’re working with any table larger than a 2 x 2 contingency table.
<h3>How to Interpret</h3>
The following table shows how to interpret V based on the degrees of freedom:
<table><tbody>
<tr>
<th style="text-align: center;"><b>Degrees of freedom</b></th>
<th style="text-align: center;"><b>Small</b></th>
<th style="text-align: center;"><b>Medium</b></th>
<th style="text-align: center;"><b>Large</b></th>
</tr>
<tr>
<td style="text-align: center;"><b>1</b></td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.50</td>
</tr>
<tr>
<td style="text-align: center;"><b>2</b></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">0.35</td>
</tr>
<tr>
<td style="text-align: center;"><b>3</b></td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">0.17</td>
<td style="text-align: center;">0.29</td>
</tr>
<tr>
<td style="text-align: center;"><b>4</b></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.25</td>
</tr>
<tr>
<td style="text-align: center;"><b>5</b></td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">0.22</td>
</tr>
</tbody></table>
<h2>Odds Ratio (OR)</h2>
<h3>How to Calculate </h3>
Given the following 2 x2 table:
<table><tbody>
<tr>
<th>Effect Size</th>
<th># Successes</th>
<th># Failures</th>
</tr>
<tr>
<td><b>Treatment Group</b></td>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td><b>Control Group</b></td>
<td>C</td>
<td>D</td>
</tr>
</tbody></table>
The odds ratio would be calculated as:
Odds ratio = (AD) / (BC)
<h3>When to Use</h3>
It’s appropriate to calculate the odds ratio only when you’re working with a 2 x 2 contingency table. Typically the odds ratio is calculated when you’re interested in studying the odds of success in a treatment group relative to the odds of success in a control group.
<h3>How to Interpret</h3>
There is no specific value at which we deem an odds ratio be a small, medium, or large effect, but the  further away the odds ratio is from 1, the higher the likelihood that the treatment has an actual effect.
It’s best to use domain specific expertise to determine if a given odds ratio should be considered small, medium, or large.
<h2><span class="orange">Effect Size: What It Is and Why It Matters</span></h2>
<em>“Statistical significance is the least interesting thing about the results. You should describe the results in terms of measures of magnitude – not just, does a treatment affect people, but how much does it affect them.”</em> -Gene V. Glass
In statistics, we often use  p-values  to determine if there is a statistically significant difference between two groups.
For example, suppose we want to know if two different studying techniques lead to different test scores. So, we have one group of 20 students use one studying technique to prepare for a test while another group of 20 students uses a different studying technique. We then have each student take the same test. 
After running a two-sample t-test for a difference in means, we find that the p-value of the test is 0.001. If we use a 0.05 significance level, then this means there is a statistically significant difference between the mean test scores of the two groups. Thus, studying technique has an impact on test scores.
However, while the p-value tells us that studying technique has an impact on test scores, it doesn’t tell us the <em>size </em>of the impact. To understand this, we need to know <b>the effect size</b>.
<h2>What is Effect Size?</h2>
An<b> effect size</b> is a way to quantify the difference between two groups.
While a p-value can tell us whether or not there is a statistically significant difference between two groups, an effect size can tell us <em>how large </em>this difference actually is. In practice, effect sizes are much more interesting and useful to know than p-values.
There are three ways to measure effect size, depending on the type of analysis you’re doing:
<h3>1. Standardized Mean Difference</h3>
When you’re interested in studying the mean difference between two groups, the appropriate way to calculate the effect size is through a <b>standardized mean difference</b>. The most popular formula to use is known as Cohen’s <em>d</em>, which is calculated as:
Cohen’s <em>d </em>= (x<sub>1</sub> – x<sub>2</sub>) / s
where  x<sub>1</sub> and x<sub>2</sub> are the sample means of group 1 and group 2, respectively, and <em>s </em>is the standard deviation of the population from which the two groups were taken.
Using this formula, the effect size is easy to interpret:
A <em>d </em>of 1 indicates that the two group means differ by one standard deviation.
A <em>d </em>of 2 means that the group means differ by two standard deviations.
A <em>d</em> of 2.5 indicates that the two means differ by 2.5 standard deviations, and so on.
Another way to interpret the effect size is as follows: An effect size of 0.3 means the score of the average person in group <em>2 </em>is 0.3 standard deviations above the average person in group <em>1 </em>and thus exceeds the scores of 62% of those in group <em>1</em>.
The following table shows various effect sizes and their corresponding percentiles:
<table><tbody>
<tr>
<th><b>Effect Size</b></th>
<th><b>Percentage of Group <em>2</em> who would be below average person in Group <em>1</em></b></th>
</tr>
<tr>
<td>0.0</td>
<td>50%</td>
</tr>
<tr>
<td>0.2</td>
<td>58%</td>
</tr>
<tr>
<td>0.4</td>
<td>66%</td>
</tr>
<tr>
<td>0.6</td>
<td>73%</td>
</tr>
<tr>
<td>0.8</td>
<td>79%</td>
</tr>
<tr>
<td>1.0</td>
<td>84%</td>
</tr>
<tr>
<td>1.2</td>
<td>88%</td>
</tr>
<tr>
<td>1.4</td>
<td>92%</td>
</tr>
<tr>
<td>1.6</td>
<td>95%</td>
</tr>
<tr>
<td>1.8</td>
<td>96%</td>
</tr>
<tr>
<td>2.0</td>
<td>98%</td>
</tr>
<tr>
<td>2.5</td>
<td>99%</td>
</tr>
<tr>
<td>3.0</td>
<td>99.9%</td>
</tr>
</tbody></table>
The larger the effect size, the larger the difference between the average individual in each group.
In general, a <em>d </em>of 0.2 or smaller is considered to be a small effect size, a <em>d </em>of around 0.5 is considered to be a medium effect size, and a <em>d </em>of 0.8 or larger is considered to be a large effect size.
Thus, if the means of two groups don’t differ by at least 0.2 standard deviations, the difference is trivial, even if the p-value is statistically significant.
<h3>2. Correlation Coefficient</h3>
When you’re interested in studying the quantitative relationship between two variables, the most popular way to calculate the effect size is through the  Pearson Correlation Coefficient . This is a measure of the linear association between two variables <em>X </em>and <em>Y. </em>It has a value between -1 and 1 where:
-1 indicates a perfectly negative linear correlation between two variables
0 indicates no linear correlation between two variables
1 indicates a perfectly positive linear correlation between two variables
The formula to calculate the Pearson Correlation Coefficient is quite complex, but it can be found  here  for those who are interested.
The further away the correlation coefficient is from zero, the stronger the linear relationship between two variables. This can also be seen by creating a simple scatterplot of the values for variables <em>X </em>and <em>Y</em>. 
For example, the following scatterplot shows the values of two variables that have a correlation coefficient of <em>r = </em>0.94.
This value is far from zero, which indicates that there is a strong positive relationship between the two variables.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/effectsize1.jpg"331">
Conversely, the following scatterplot shows the values of two variables that have a correlation coefficient of <em>r = </em>0.03. This value is close to zero, which indicates that there is virtually no relationship between the two variables.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/effectsize2.jpg"327">
In general, the effect size is considered to be low if the value of the Pearson Correlation Coefficient <em>r </em>is around 0.1, medium if <em>r </em>is around 0.3, and large if <em>r </em>is 0.5 or greater.
<h3>3. Odds Ratio</h3>
When you’re interested in studying the odds of success in a treatment group relative to the odds of success in a control group, the most popular way to calculate the effect size is through the <b>odds ratio</b>.
For example, suppose we have the following table:
<table><tbody>
<tr>
<th>Effect Size</th>
<th># Successes</th>
<th># Failures</th>
</tr>
<tr>
<td><b>Treatment Group</b></td>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td><b>Control Group</b></td>
<td>C</td>
<td>D</td>
</tr>
</tbody></table>
The odds ratio would be calculated as:
Odds ratio = (AD) / (BC)
The further away the odds ratio is from 1, the higher the likelihood that the treatment has an actual effect.
<h2>The Advantages of Using Effect Sizes Over P-Values</h2>
Effect sizes have several advantages over p-values:
<b>1.</b> An effect size helps us get a better idea of <em>how large </em>the difference is between two groups or <em>how strong </em>the association is between two groups. A p-value can only tell us whether or not there <em>is </em>some significant difference or some significant association.
<b>2. </b>Unlike p-values, effect sizes can be used to quantitatively compare the results of different studies done in different settings. For this reason, effect sizes are often used in meta-analyses.
<b>3.</b> P-values can be affected by large sample sizes. The larger the sample size, the greater the statistical power of a hypothesis test, which enables it to detect even small effects. This can lead to low p-values, despite small effect sizes that may have no practical significance.
A simple example can make this clear: Suppose we want to know whether two studying techniques lead to different test scores. We have one group of 20 students use one studying technique while another group of 20 students uses a different studying technique. We then have each student take the same test. 
The mean score for group 1 is <b>90.65 </b>and the mean score for group 2 is <b>90.75</b>. The standard deviation for sample 1 is <b>2.77</b> and the standard deviation for sample 2 is <b>2.78</b>.
When we perform an independent two-sample t test, it turns out that the test statistic is <b>-0.113 </b>and the corresponding p-value is<b> 0.91</b>. The difference between the mean test scores is not statistically significant.
However, consider if the sample sizes of the two samples were both <b>200</b>, yet the means and the standard deviations remained the exact same.
In this case, an independent two-sample t test would reveal that the test statistic is <b>-1.97</b> and the corresponding p-value is just under <b>0.05</b>. The difference between the mean test scores is statistically significant.
The underlying reason that large sample sizes can lead to statistically significant conclusions is due to the formula used to calculate the test statistics <em>t</em>:
<b>test statistic <em>t</em></b>  = [ (x<sub>1</sub> – x<sub>2</sub>) – d ]  /  (√s<sup>2</sup><sub>1</sub> / n<sub>1</sub> + s<sup>2</sup><sub>2</sub> / n<sub>2</sub>)
Notice that when n<sub>1</sub> and n<sub>2</sub> are small, the entire denominator of the test statistic <em>t </em>is small. And when we divide by a small number, we end up with a large number. This means the test statistic <em>t </em>will be large and the corresponding p-value will be small, thus leading to statistically significant results.
<h3>What is Considered a Good Effect Size?</h3>
One question students often have is: <b><em>What is considered a good effect size?</em></b>
The short answer: An effect size can’t be “good” or “bad” since it simply measures the size of the difference between two groups or the strength of the association between two two groups.
However, we can use the following rules of thumb to quantify whether an effect size is small, medium or large:
<b>Cohen’s D:</b>
A <em>d </em>of 0.2 or smaller is considered to be a small effect size.
A <em>d </em>of 0.5 is considered to be a medium effect size.
A <em>d </em>of 0.8 or larger is considered to be a large effect size.
<b>Pearson Correlation Coefficient</b>
An absolute value of <em>r</em> around 0.1 is considered a low effect size.
An absolute value of <em>r</em> around 0.3 is considered a medium effect size.
An absolute value of <em>r</em> greater than .5 is considered to be a large effect size.
However, the definition of a “strong” correlation can vary from one field to the next. Refer to  this article  to gain a better understanding of what is considered a strong correlation in different industries.
<h2><span class="orange">How to Use the Elbow Method in R to Find Optimal Clusters</span></h2>
One of the most common clustering algorithms used in  machine learning  is known as <b>k-means clustering</b>.
K-means clustering is a technique in which we place each observation in a dataset into one of <em>K</em> clusters.
The end goal is to have <em>K </em>clusters in which the observations within each cluster are quite similar to each other while the observations in different clusters are quite different from each other.
When performing k-means clustering, the first step is to choose a value for <em>K</em> – the number of clusters we’d like to place the observations in.
One of the most common ways to choose a value for <em>K</em> is known as <b>the elbow method</b>, which involves creating a plot with the number of clusters on the x-axis and the total within sum of squares on the y-axis and then identifying where an “elbow” or bend appears in the plot.
The point on the x-axis where the “elbow” occurs tells us the optimal number of clusters to use in the k-means clustering algorithm.
The following example shows how to use the elbow method in R.
<h2>Example: Using the Elbow Method in R</h2>
For this example we’ll use the <b>USArrests </b>dataset built into R, which contains the number of arrests per 100,000 residents in each U.S. state in 1973 for Murder, Assault, and Rape along with the percentage of the population in each state living in urban areas, UrbanPop.
The following code shows how to load the dataset, remove rows with missing values, and scale each variable in the dataset to have a mean of 0 and standard deviation of 1:
<b>#load data
df &lt;- USArrests
#remove rows with missing values</b>
<b>df &lt;- na.omit(df)
#scale each variable to have a mean of 0 and sd of 1</b>
<b>df &lt;- scale(df)
#view first six rows of dataset
head(df)
               Murder   Assault   UrbanPop         Rape
Alabama    1.24256408 0.7828393 -0.5209066 -0.003416473
Alaska     0.50786248 1.1068225 -1.2117642  2.484202941
Arizona    0.07163341 1.4788032  0.9989801  1.042878388
Arkansas   0.23234938 0.2308680 -1.0735927 -0.184916602
California 0.27826823 1.2628144  1.7589234  2.067820292
Colorado   0.02571456 0.3988593  0.8608085  1.864967207
</b>
To find the optimal number of clusters to use in the k-means algorithm, we’ll use the <b>fviz_nbclust()</b> function from the <b>factoextra</b> package to create a plot of the number of clusters vs. the total within sum of squares:
<b>library(cluster)
library(factoextra)
#create plot of number of clusters vs total within sum of squares
fviz_nbclust(df, kmeans, method = "wss")</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/kmean1.png">
In this plot it appears that there is an “elbow” or bend at k = 4 clusters. This is the point where the total within sum of squares begins to level off.
This tells us that the optimal number of clusters to use in the k-means algorithm is 4.
<b>Note</b>: Although we could achieve a lower total within sum of squares by using more clusters, we would likely be  overfitting the training data  and thus the k-means algorithm wouldn’t perform as well on testing data.
We can proceed to use the <b>kmeans()</b> function from the <b>cluster</b> package to perform k-means clustering on the dataset using the optimal value for <em>k</em> of 4:
<b>#make this example reproducible
set.seed(1)
#perform k-means clustering with k = 4 clusters
km &lt;- kmeans(df, centers = 4, nstart = 25)
#view results
km
K-means clustering with 4 clusters of sizes 16, 13, 13, 8
Cluster means:
      Murder    Assault   UrbanPop        Rape
1 -0.4894375 -0.3826001  0.5758298 -0.26165379
2 -0.9615407 -1.1066010 -0.9301069 -0.96676331
3  0.6950701  1.0394414  0.7226370  1.27693964
4  1.4118898  0.8743346 -0.8145211  0.01927104
Clustering vector:
       Alabama         Alaska        Arizona       Arkansas     California       Colorado 
             4              3              3              4              3              3 
   Connecticut       Delaware        Florida        Georgia         Hawaii          Idaho 
             1              1              3              4              1              2 
      Illinois        Indiana           Iowa         Kansas       Kentucky      Louisiana 
             3              1              2              1              2              4 
         Maine       Maryland  Massachusetts       Michigan      Minnesota    Mississippi 
             2              3              1              3              2              4 
      Missouri        Montana       Nebraska         Nevada  New Hampshire     New Jersey 
             3              2              2              3              2              1 
    New Mexico       New York North Carolina   North Dakota           Ohio       Oklahoma 
             3              3              4              2              1              1 
        Oregon   Pennsylvania   Rhode Island South Carolina   South Dakota      Tennessee 
             1              1              1              4              2              4 
         Texas           Utah        Vermont       Virginia     Washington  West Virginia 
             3              1              2              1              1              2 
     Wisconsin        Wyoming 
             2              1 
Within cluster sum of squares by cluster:
[1] 16.212213 11.952463 19.922437  8.316061
 (between_SS / total_SS =  71.2 %)
Available components:
[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss" "betweenss"   
[7] "size"         "iter"         "ifault"         
</b>
From the results we can see that:
<b>16 </b>states were assigned to the first cluster
<b>13</b> states were assigned to the second cluster
<b>13</b> states were assigned to the third cluster
<b>8 </b>states were assigned to the fourth cluster
We can also append the cluster assignments of each state back to the original dataset:
<b>#add cluster assigment to original data
final_data &lt;- cbind(USArrests, cluster = km$cluster)
#view final data
head(final_data)
    MurderAssaultUrbanPop  Rape cluster
Alabama    13.223658  21.2 4
Alaska    10.026348  44.5 2
Arizona     8.129480  31.0 2
Arkansas     8.819050  19.5 4
California   9.027691  40.6 2
Colorado     7.920478  38.7 2
</b>
Each observation from the original data frame has been placed into one of four clusters.
<h2>Additional Resources</h2>
The following tutorials provide step-by-step examples of how to perform various clustering algorithms in R:
 K-Means Clustering in R: Step-by-Step Example 
 K-Medoids Clustering in R: Step-by-Step Example 
 Hierarchical Clustering in R: Step-by-Step Example 
<h2><span class="orange">How to Perform Element-Wise Multiplication in R</span></h2>
R is excellent at performing element-wise multiplication between two objects.
The following examples show how to perform element-wise multiplication between various objects in R.
<h3>Example 1: Multiply Two Vectors</h3>
The following code shows how to perform element-wise multiplication with two vectors:
<b>#create vectors
a &lt;- c(1, 3, 4, 5)
b &lt;- c(2, 2, 3, 3)
#perform element-wise multiplication
a*b
[1]  2  6 12 15</b>
Here is how the results were calculated:
1 * 2 = <b>2</b>
3 * 2 = <b>6</b>
4 * 3 = <b>12</b>
5 * 3 = <b>15</b>
<h3>Example 2: Multiply Data Frame & Vector</h3>
The following code shows how to perform element-wise multiplication with a data frame and a vector:
<b>#define data frame
df &lt;- data.frame(a=c(1, 3, 4, 5), b=c(2, 2, 3, 3))
#view data frame
df
  a b
1 1 2
2 3 2
3 4 3
4 5 3
#define vector
x &lt;- c(2, 5, 5, 8)
#multiply data frame by vector
df*x
   a  b
1  2  4
2 15 10
3 20 15
4 40 24
</b>
<h3>Example 3: Multiply Two Data Frames</h3>
The following code shows how to perform element-wise multiplication between two data frames:
<b>#define data frames
df1 &lt;- data.frame(a=c(1, 3, 4, 5),  b=c(2, 2, 3, 3))
df2 &lt;- data.frame(c=c(6, 2, 2, 2),  d=c(1, 7, 4, 9))
#multiply two data frames
df1*df2
   a  b
1  6  2
2  6 14
3  8 12
4 10 27
</b>
Note that the resulting data frame is the same size as the two data frames that we multiplied.
Also note that we will receive an error if we attempt to multiply two data frames of different sizes:
<b>#define data frames of unequal sizes
df1 &lt;- data.frame(a=c(1, 3, 4, 5),  b=c(2, 2, 3, 3))
df2 &lt;- data.frame(c=c(6, 2, 2),  d=c(1, 7, 4))
#attempt to multiply two data frames
df1*df2
Error in Ops.data.frame(df1, df2) : 
  ‘*’ only defined for equally-sized data frames</b>
<h2><span class="orange">Empirical Rule Calculator</span></h2>
The <b>Empirical Rule</b>, sometimes called the 68-95-99.7 rule, states that for a given dataset with a normal distribution:
<b>68%</b> of data values fall within one standard deviation of the mean.
<b>95%</b> of data values fall within two standard deviations of the mean.
<b>99.7%</b> of data values fall within three standard deviations of the mean.
To apply the empirical rule to a given dataset, simply enter the mean and standard deviation of the dataset in the boxes below, then click the “Calculate” button.
<label for="pop_mean"><b>Mean</b></label>
<input type="number" id="pop_mean" min="0" value="13.5">
<label for="pop_sd"><b>Standard deviation (σ)</b></label>
<input type="number" id="pop_sd" min="0" value="4">
<input type="button" id="button" onclick="calc()" value="Calculate">
<div>
<div>
<div>
<script>
function calc() {
    
//get input data
var pop_mean = document.getElementById('pop_mean').value*1;
var pop_sd = document.getElementById('pop_sd').value*1;
//output values
document.getElementById('one').innerHTML = "Approximately <b>68%</b> of data values lie between <b>" + (pop_mean-(pop_sd*1)).toFixed(3) + "</b> and <b>" + (pop_mean-(-pop_sd*1)).toFixed(3) + "</b>";
document.getElementById('two').innerHTML = "Approximately <b>95%</b> of data values lie between <b>" + (pop_mean-(pop_sd*2)).toFixed(3) + "</b> and <b>" + (pop_mean-(-pop_sd*2)).toFixed(3) + "</b>";
    document.getElementById('three').innerHTML = "Approximately <b>99.7%</b> of data values lie between <b>" + (pop_mean-(pop_sd*3)).toFixed(3) + "</b> and <b>" + (pop_mean-(-pop_sd*3)).toFixed(3) + "</b>";
  }
</script>
<h2><span class="orange">How to Apply the Empirical Rule in Excel</span></h2>
The <b>Empirical Rule</b>, sometimes called the 68-95-99.7 rule, states that for a given dataset with a normal distribution:
<b>68%</b> of data values fall within one standard deviation of the mean.
<b>95%</b> of data values fall within two standard deviations of the mean.
<b>99.7%</b> of data values fall within three standard deviations of the mean.
In this tutorial, we explain how to apply the Empirical Rule in Excel to a given dataset.
<h2>Applying the Empirical Rule in Excel</h2>
Suppose we have a normally-distributed dataset with a mean of <b>7</b> and a standard deviation of <b>2.2</b>. The following screenshot shows how to apply the Empirical Rule to this dataset in Excel to find which values 68% of the data falls between, which values 95% of the data falls between, and which values 99.7% of the data falls between:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/empiricalRuleExcel1.jpg">
From this output, we can see:
68% of the data falls between <b>4.8 </b>and <b>9.2</b>
95% of the data falls between <b>2.6 </b>and <b>11.4</b>
99.7% of the data falls between <b>0.4 </b>and <b>13.6</b>
The cells in columns <em>F </em>and <em>G </em>show the formulas that were used to find these values.
To apply the Empirical Rule to a different dataset, we simply need to change the mean and standard deviation in cells C2 and C3. For example, here is how to apply the Empirical Rule to a dataset with a mean of <b>40</b> and a standard deviation of <b>3.75</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/empiricalRuleExcel2.jpg"675">
From this output, we can see:
68% of the data falls between <b>36.25 </b>and <b>43.75</b>
95% of the data falls between <b>32.5 </b>and <b>47.5</b>
99.7% of the data falls between <b>28.75 </b>and <b>51.25</b>
And here is one more example of how to apply the Empirical Rule to a dataset with a mean of <b>100 </b>and a standard deviation of <b>5</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/empiricalRuleExcel3.jpg">
From this output, we can see:
68% of the data falls between <b>95 </b>and <b>105</b>
95% of the data falls between <b>90 </b>and <b>110</b>
99.7% of the data falls between <b>85 </b>and <b>115</b>
<h2>Finding What Percentage of Data Falls Between Certain Values</h2>
Another question you might have is: <em>What percentage of data falls between certain values?</em>
For example, suppose you have a normally-distributed dataset with a mean of 100, a standard deviation of 5, and you want to know what percentage of the data falls between the values <b>99 </b>and <b>105</b>.
In Excel, we can easily answer this question by using the function <b>= NORM.DIST()</b>, which takes the following arguments:
<b>NORM.DIST</b>(x, mean, standard_dev, cumulative)
where:
<em>x </em>is the value we’re interested in
<em>mean </em>is the mean of the distribution
<em>standard_dev </em>is the standard deviation of the distribution
<em>cumulative </em>takes a value of “TRUE” (returns the CDF) or “FALSE” (returns the PDF) – we’ll use “TRUE” to get the value of the cumulative distribution function.
The following screenshot shows how to use the <b>NORM.DIST()</b> function to find the percentage of the data that falls between the values <b>99 </b>and <b>105 </b>for a distribution that has a mean of 100 and a standard deviation of 5:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/01/empiricalRuleExcel4.jpg">
We see that <b>42.1% </b>of the data falls between the values 105 and 99 for this distribution.
<b>Helpful Tools:</b>
 Empirical Rule Calculator 
 Empirical Rule (Practice Problems) 
<h2><span class="orange">How to Apply the Empirical Rule in R</span></h2>
The <b>Empirical Rule</b>, sometimes called the 68-95-99.7 rule, states that for a given dataset with a normal distribution:
<b>68%</b> of data values fall within one standard deviation of the mean.
<b>95%</b> of data values fall within two standard deviations of the mean.
<b>99.7%</b> of data values fall within three standard deviations of the mean.
In this tutorial, we explain how to apply the Empirical Rule in R to a given dataset.
<h3>Applying the Empirical Rule in R</h3>
The <b>pnorm()</b> function in R returns the value of the cumulative density function of the normal distribution.
This function uses the following basic syntax:
<b>pnorm(q, mean, sd)</b>
where:
<b>q</b>: normally distributed random variable value
<b>mean</b>: mean of distribution
<b>sd</b>: standard deviation of distribution
We can use the following syntax to find the area under the normal distribution curve that lies in between various standard deviations:
<b>#find area under normal curve within 1 standard deviation of mean
pnorm(1) - pnorm(-1)
[1] 0.6826895
#find area under normal curve within 2 standard deviations of mean 
pnorm(2) - pnorm(-2)
[1] 0.9544997
#find area under normal curve within 3 standard deviations of mean 
pnorm(3) - pnorm(-3)
[1] 0.9973002
</b>
From the output we can confirm:
<b>68%</b> of data values fall within one standard deviation of the mean.
<b>95%</b> of data values fall within two standard deviations of the mean.
<b>99.7%</b> of data values fall within three standard deviations of the mean.
The following examples show how to use the Empirical Rule with different datasets in practice.
<h3>Example 1: Applying the Empirical Rule to a Dataset in R</h3>
Suppose we have a normally distributed dataset with a mean of <b>7</b> and a standard deviation of <b>2.2</b>.
We can use the following code to find which values contain 68%, 95%, and 99.7% of the data:
<b>#define mean and standard deviation values
mean=7
sd=2.2
#find which values contain 68% of data
mean-2.2; mean+2.2
[1] 4.8
[1] 9.2
#find which values contain 95% of data
mean-2*2.2; mean+2*2.2
[1] 2.6
[1] 11.4
#find which values contain 99.7% of data
mean-3*2.2; mean+3*2.2
[1] 0.4
[1] 13.6
</b>
From this output, we can see:
68% of the data falls between <b>4.8 </b>and <b>9.2</b>
95% of the data falls between <b>2.6 </b>and <b>11.4</b>
99.7% of the data falls between <b>0.4 </b>and <b>13.6</b>
<h3>Example 2: Finding What Percentage of Data Falls Between Certain Values</h3>
Imagine we have a normally distributed dataset with a mean of 100 and standard deviation of 5. 
Suppose we want to know what percentage of the data falls between the values <b>99</b> and <b>105</b> in this distribution.
We can use the <b>pnorm(</b>) function to find the answer:
<b>#find area under normal curve between 99 and 105
pnorm(105, mean=100, sd=5) - pnorm(99, mean=100, sd=5)
[1] 0.4206045
</b>
We see that <b>42.06% </b>of the data falls between the values 99 and 105 for this distribution.
<h2><span class="orange">Empirical Rule Practice Problems</span></h2>
The <b>Empirical Rule</b>, sometimes called the 68-95-99.7 rule, states that for a given dataset with a normal distribution:
<b>68%</b> of data values fall within one standard deviation of the mean.
<b>95%</b> of data values fall within two standard deviations of the mean.
<b>99.7%</b> of data values fall within three standard deviations of the mean.
Test your knowledge of the Empirical Rule using the practice problems below.
<hr id="hr_top">
The height of plants in a certain garden are normally distributed with a mean of 12.3 inches and a standard deviation of 4.1 inches.
<b>Use the Empirical Rule to estimate what percentage of plants are between 8.2 and 16.4 inches tall.</b>
<input type="number" id="answer" value=""> %
<input type="button" id="button_calc" onclick="check()" value="Check Answer">
<b></b>
<input type="button" id="button_calc" onclick="solution()" value="Show Solution">
<input type="button" id="button_calc" onclick="gen()" value="Generate New Question">
<script>
var globalThing= {}; // Globally scoped object
  
function check() {
    if(globalThing.q_selected=="between") {
        if(globalThing.sd_multiplier==1) {
        var solution = 68;
        }
        if(globalThing.sd_multiplier==2) {
        var solution = 95;
        }
        if(globalThing.sd_multiplier==3) {
        var solution = 99.7;
        }
    } //end between
    if(globalThing.q_selected=="less than") {
        if(globalThing.sd_multiplier==1) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 84;
            } else {
            var solution = 16;
            }
        }
        if(globalThing.sd_multiplier==2) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 97.5;
            } else {
            var solution = 2.5;
            }
        }
        if(globalThing.sd_multiplier==3) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 99.85;
            } else {
            var solution = 0.15;
            }
        }
    } //end less than
    if(globalThing.q_selected=="greater than") {
        if(globalThing.sd_multiplier==1) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 16;
            } else {
            var solution = 84;
            }
        }
        if(globalThing.sd_multiplier==2) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 2.5;
            } else {
            var solution = 97.5;
            }
        }
        if(globalThing.sd_multiplier==3) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 0.15;
            } else {
            var solution = 99.85;
            }
        }
    } //end greater than
//check if user-entered solution matches correct solution
var user_answer = document.getElementById('answer').value;
    if (user_answer == solution) {
    document.getElementById('output').innerHTML = "Correct!"
    } else {
    document.getElementById('output').innerHTML = "Not quite yet..."
    }
//toggle answer showing
var result_display = document.getElementById("words_output");
result_display.style.display = "block";
} //end massive check() function
function solution() {
    if(globalThing.q_selected=="between") {
        if(globalThing.sd_multiplier==1) {
        var solution = 68;
        document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 68% of data values fall within one standard deviation of the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located one standard deviation below the mean and " + globalThing.sd_above.toFixed(1) + " is located one standard deviation above the mean.
Thus, <b>68%</b> of plants are between " + globalThing.sd_below.toFixed(1) + " and " + globalThing.sd_above.toFixed(1) + " inches tall.";
        }
        if(globalThing.sd_multiplier==2) {
        var solution = 95;
        document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 95% of data values fall within two standard deviations of the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located two standard deviations below the mean and " + globalThing.sd_above.toFixed(1) + " is located two standard deviations above the mean.
Thus, <b>95%</b> of plants are between " + globalThing.sd_below.toFixed(1) + " and " + globalThing.sd_above.toFixed(1) + " inches tall.";
        }
        if(globalThing.sd_multiplier==3) {
        var solution = 99.7;
        document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 99.7% of data values fall within three standard deviations of the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located three standard deviations below the mean and " + globalThing.sd_above.toFixed(1) + " is located three standard deviations above the mean.
Thus, <b>99.7%</b> of plants are between " + globalThing.sd_below.toFixed(1) + " and " + globalThing.sd_above.toFixed(1) + " inches tall.";
        }
    } //end between
    if(globalThing.q_selected=="less than") {
        if(globalThing.sd_multiplier==1) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 84;
                    document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 68% of data values fall within one standard deviation of the mean. This means that 34% of values fall between the mean and one standard deviation above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located one standard deviation above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 34% = <b>84%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>84%</b> of plants are less than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 16;                              document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 68% of data values fall within one standard deviation of the mean. This means that 34% of values fall between the mean and one standard deviation below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located one standard deviation below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 34% = 84% of values fall above " + globalThing.sd_below.toFixed(1) + ". This means that 100% - 84% = <b>16%</b> of values fall below " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>16%</b> of plants are less than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
        if(globalThing.sd_multiplier==2) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 97.5;                           
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 95% of data values fall within two standard deviations of the mean. This means that 47.5% of values fall between the mean and two standard deviations above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located two standard deviations above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 47.5% = <b>97.5%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>97.5%</b> of plants are less than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 2.5;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 95% of data values fall within two standard deviations of the mean. This means that 47.5% of values fall between the mean and two standard deviations below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located two standard deviations below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 47.5% = 97.5% of values fall above " + globalThing.sd_below.toFixed(1) + ". This means that 100% - 97.5% = <b>2.5%</b> of values fall below " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>2.5%</b> of plants are less than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
        if(globalThing.sd_multiplier==3) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 99.85;                        
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 99.7% of data values fall within three standard deviations of the mean. This means that 49.85% of values fall between the mean and three standard deviations above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located three standard deviations above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 49.85% = <b>99.85%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>99.85%</b> of plants are less than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 0.15;                       
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 99.7% of data values fall within three standard deviations of the mean. This means that 49.85% of values fall between the mean and three standard deviations below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located three standard deviations below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 49.85% = 99.85% of values fall above " + globalThing.sd_below.toFixed(1) + ". This means that 100% - 99.85% = <b>0.15%</b> of values fall below " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>0.15%</b> of plants are less than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
    } //end less than
    if(globalThing.q_selected=="greater than") {
        if(globalThing.sd_multiplier==1) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 16;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 68% of data values fall within one standard deviation of the mean. This means that 34% of values fall between the mean and one standard deviation above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located one standard deviation above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 34% = <b>84%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ". This means that 100% - 84% = <b>16%</b> of values fall above " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>16%</b> of plants are greater than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 84;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 68% of data values fall within one standard deviation of the mean. This means that 34% of values fall between the mean and one standard deviation below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located one standard deviation below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 34% = <b>84%</b> of values fall above " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>84%</b> of plants are greater than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
        if(globalThing.sd_multiplier==2) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 2.5;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 95% of data values fall within two standard deviations of the mean. This means that 47.5% of values fall between the mean and two standard deviations above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located two standard deviations above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 47.5% = <b>97.5%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ". This means that 100% - 97.5% = <b>2.5%</b> of values fall above " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>2.5%</b> of plants are greater than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 97.5;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 95% of data values fall within two standard deviations of the mean. This means that 47.5% of values fall between the mean and two standard deviations below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located two standard deviations below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 47.5% = <b>97.5%</b> of values fall above " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>97.5%</b> of plants are greater than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
        if(globalThing.sd_multiplier==3) {
            if(globalThing.sd_selected==globalThing.sd_above) {
            var solution = 0.15;
          document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 99.7% of data values fall within three standard deviations of the mean. This means that 49.85% of values fall between the mean and three standard deviations above the mean.
In this example, " + globalThing.sd_above.toFixed(1) + " is located three standard deviations above the mean. Since we know that 50% of data values fall below the mean in a normal distribution, a total of 50% + 49.85% = <b>99.85%</b> of values fall below " + globalThing.sd_above.toFixed(1) + ". This means that 100% - 99.85% = <b>0.15%</b> of values fall above " + globalThing.sd_above.toFixed(1) + ".
Thus, <b>0.15%</b> of plants are greater than " + globalThing.sd_above.toFixed(1) + " inches tall.";
            } else {
            var solution = 99.85;
            document.getElementById('solution_words').innerHTML = "The Empirical Rule states that for a given dataset with a normal distribution, 99.7% of data values fall within three standard deviations of the mean. This means that 49.85% of values fall between the mean and three standard deviation below the mean.
In this example, " + globalThing.sd_below.toFixed(1) + " is located three standard deviations below the mean. Since we know that 50% of data values fall above the mean in a normal distribution, a total of 50% + 49.85% = <b>99.85%</b> of values fall above " + globalThing.sd_below.toFixed(1) + ".
Thus, <b>99.85%</b> of plants are greater than " + globalThing.sd_below.toFixed(1) + " inches tall.";
            }
        }
    } //end greater than
//toggle hide/show solution
  var solution_div = document.getElementById("solution_div");
  solution_div.style.display = "block";
} //end massive solution() function
function gen() {
var mean = Math.round(jStat.uniform.sample(20, 50)*10)/10;
var sd = Math.round(jStat.uniform.sample(2, 6)*10)/10;
var sd_options = [1, 2, 3];
globalThing.sd_multiplier = sd_options[Math.floor(Math.random()*sd_options .length)];
globalThing.sd_above = mean - (-globalThing.sd_multiplier*sd);
globalThing.sd_below = mean - (globalThing.sd_multiplier*sd);
sd_above_below = [globalThing.sd_above, globalThing.sd_below];
globalThing.sd_selected = sd_above_below[Math.floor(Math.random()*sd_above_below.length)];
var q_options = ["between", "less than", "greater than"];
globalThing.q_selected = q_options[Math.floor(Math.random()*q_options .length)];
if (globalThing.q_selected == "less than") {
document.getElementById('scenario').innerHTML = "less than " + globalThing.sd_selected.toFixed(1);
} else if (globalThing.q_selected == "greater than") {
document.getElementById('scenario').innerHTML = "greater than " + globalThing.sd_selected.toFixed(1);
} else {
document.getElementById('scenario').innerHTML = "between " + globalThing.sd_below.toFixed(1) + " and " + globalThing.sd_above.toFixed(1);
}
//fill in mean and sd in initial question
document.getElementById('mean').innerHTML = mean;
document.getElementById('sd').innerHTML = sd;
//toggle answer & solution to hide and clear input field
var result_display = document.getElementById("words_output");
result_display.style.display = "none";
var solution_div = document.getElementById("solution_div");
solution_div.style.display = "none";
document.getElementById('answer').value = "";
} //end massive gen() function
//generate initial question
gen();
</script>
<h2><span class="orange">How to Create an Empty Plot in R (3 Examples)</span></h2>
There are three common ways to create an empty plot in R:
<b>Method 1: Create Completely Empty Plot</b>
<b>plot.new()</b>
<b>Method 2: Create Empty Plot with Axes</b>
<b>plot(NULL, xlab="", ylab="", xaxt="n", yaxt="n",
     xlim=c(0, 10), ylim=c(0, 10))</b>
<b>Method 3: Create Empty Plot with Axes & Labels</b>
<b>plot(NULL, ylab="y label", xlab="x label", main="title",
     xlim=c(0, 10), ylim=c(0, 10))</b>
The following example shows how to use each method in practice.
<h3>Example 1: Create Completely Empty Plot</h3>
We can use the following code to create a completely empty plot in R:
<b>plot.new()
</b>
Here’s what the result looks like in the plotting window in RStudio: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/emptyplot1.jpg"594">
<h3>Example 2: Create Empty Plot with Axes</h3>
We can use the following code to create an empty plot with axes in R:
<b>plot(NULL, xlab="", ylab="", xaxt="n", yaxt="n",
     xlim=c(0, 10), ylim=c(0, 10))</b>
Here’s what the result looks like in the plotting window in RStudio:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/emptyplot2.jpg"622">
Note that the <b>xaxt</b> and <b>yaxt</b> arguments suppress the tick marks on the x-axis and y-axis, respectively. 
<h3>Example 3: Create Empty Plot with Axes & Labels</h3>
We can use the following code to create an empty plot with axes and labels in R:
<b>plot(NULL, ylab="y label", xlab="x label", main="title",
     xlim=c(0, 10), ylim=c(0, 10))</b>
Here’s what the result looks like in the plotting window in RStudio:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/04/emptyplot3.jpg"599">
<h2><span class="orange">Endogenous vs. Exogenous Variables: Definition & Examples</span></h2>
Two variables that can occur in regression models are:
<b>1. Endogenous variables:</b> Variables that are explained by other variables within a model.
<b>2. Exogenous variables:</b> Variables that are <em>not</em> explained by other variables within a model.
When using regression models, researchers are often interested in understanding the relationship between one or more explanatory variables and a  response variable .
And in general:
It’s possible to manipulate endogenous variables to produce some effect in the response variable.
It’s not possible to manipulate exogenous variables.
The following examples illustrate how to identify endogenous vs. exogenous variables in different regression models.
<h3>Example 1: Crop Yield</h3>
Suppose a farmer is interested in understanding the factors that affect total crop yield. He collects data and builds the following  regression model :
Crop Yield = B<sub>0</sub> + B<sub>1</sub>(Fertilizer) + B<sub>2</sub>(Type of Soil Used) + B<sub>3</sub>(Rainfall)
Here is how to identify each variable in the model:
Crop Yield: This variable is <b>endogenous</b> because it can be explained by fertilizer, type of soil used, and rainfall.
Fertilizer: This variable is <b>endogenous</b> because its effectiveness is influenced by the type of soil used.
Type of Soil Used: This variable is <b>endogenous</b> because it is influenced by the type of soil used.
Rainfall: This variable is <b>exogenous</b> because it is not influenced by the other variables in the model. In other words, the amount of fertilizer used or the type of soil used cannot effect the amount of rainfall in any way.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/endogenous1.png">
<h3>Example 2: Consumer Spending</h3>
Suppose an economist is interested in understanding the factors that affect consumer spending. She collects data and builds the following  regression model :
Consumer Spending = B<sub>0</sub> + B<sub>1</sub>(Income) + B<sub>2</sub>(Investment Returns) + B<sub>3</sub>(Government Tax Rates)
Here is how to identify each variable in the model:
Consumer Spending: This variable is <b>endogenous</b> because it can be explained by income, investment returns, and government spending.
Income: This variable is <b>endogenous</b> because it is affected by government tax rates.
Investment Returns: This variable is <b>endogenous</b> because it is influenced government tax rates.
Government tax rates: This variable is <b>exogenous</b> because it is not influenced by the other variables in the model. In other words, the amount that an individual earns in income or earns in investment returns cannot effect the tax rates set by the government in any way.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/03/endogenous2.png">
<h2><span class="orange">How to Manually Enter Raw Data in R</span></h2>
R is one of the most popular programming languages for working with data. But before we can work with data, we have to actually get data into R!
If you already have your data located in a CSV file or Excel file, you can follow the steps in these tutorials to import it into R:
 How to Import CSV Files into R 
 How to Import Excel Files into R 
However, sometimes you may want to manually enter  raw data  into R. This tutorial explains how to do so.
<h3>Enter a Vector</h3>
We can use the following syntax to enter a single vector of numeric values into R:
<b>#create vector of numeric values
numeric_values &lt;- c(1, 3, 5, 8, 9)
#display class of vector
class(numeric_values)
[1] "numeric"
#display vector of numeric values
numeric_values
[1] 1 3 5 8 9
#return second element in vector
numeric_values[4]
[1] 8
</b>
We can use the same syntax to enter a vector of character values:
<b>#create vector of character values
char_values &lt;- c("Bob", "Mike", "Tony", "Andy")
#display class of vector
class(char_values)
[1] "character"
</b>
<h3>Enter a Data Frame </h3>
We can use the following syntax to enter a data frame of a values in R:
<b>#create data frame
df &lt;- data.frame(team=c("A", "A", "B", "B", "C"), points=c(12, 15, 17, 24, 27), assists=c(4, 7, 7, 8, 12))
#display data frame
df
  team points assists
1    A     12       4
2    A     15       7
3    B     17       7
4    B     24       8
5    C     27      12
#display class of df
class(df)
[1] "data.frame"
#return value in fourth row and third column
df[4, 3]
[1] 8
</b>
<h3>Enter a Matrix</h3>
We can use the following syntax to enter a matrix of values in R:
<b>#create matrix with two columns and five rows
points=c(12, 15, 17, 24, 27)
assists=c(4, 7, 7, 8, 12)
#column bind the two vectors together to create a matrix
mat &lt;- cbind(points, assists)
#display matrix
mat
     points assists
[1,]     12       4
[2,]     15       7
[3,]     17       7
[4,]     24       8
[5,]     27      12
#display class of mat
class(mat)
[1] "matrix"
#return value in fourth row and second column
mat[4, 2]
assists 
      8
</b>
<em><b>Note:</b> A matrix requires each column to be the same type, unlike data frames.</em>
You can find more R tutorials  here .
<h2><span class="orange">Equal Frequency Binning in Python</span></h2>
In statistics, <b>binning </b>is the process of placing numerical values into <em>bins</em>.
The most common form of binning is known as <b>equal-width binning</b>, in which we divide a dataset into <em>k </em>bins of equal width.
A less commonly used form of binning is known as <b>equal-frequency binning</b>, in which we divide a dataset into <em>k </em>bins that all have an equal number of frequencies.
This tutorial explains how to perform equal frequency binning in python.
<h3>Equal Frequency Binning in Python</h3>
Suppose we have a dataset that contains 100 values:
<b>import numpy as np
import matplotlib.pyplot as plt
#create data
np.random.seed(1)
data = np.random.randn(100)
#view first 5 values
data[:5]
array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])
</b>
<b>Equal-Width Binning:</b>
If we create a histogram to display these values, Python will use equal-width binning by default:
<b>#create histogram with equal-width bins
n, bins, patches = plt.hist(data, edgecolor='black')
plt.show()
#display bin boundaries and frequency per bin 
bins, n
(array([-2.3015387 , -1.85282729, -1.40411588, -0.95540447, -0.50669306,
        -0.05798165,  0.39072977,  0.83944118,  1.28815259,  1.736864  ,
         2.18557541]),
 array([ 3.,  1.,  6., 17., 19., 20., 14., 12.,  5.,  3.]))
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/equalfreqbinningpython1.png">
Each bin has an equal width of approximately .4487, but each bin doesn’t contain an equal amount of observations. For example:
The first bin extends from -2.3015387 to -1.8528279 and contains 3 observations.
The second bin extends from -1.8528279 to -1.40411588 and contains 1 observation.
The third bin extends from -1.40411588 to -0.95540447 and contains 6 observations.
And so on.
<b>Equal-Frequency Binning:</b>
To create bins that contain an equal number of observations, we can use the following function:
<b>#define function to calculate equal-frequency bins 
def equalObs(x, nbin):
    nlen = len(x)
    return np.interp(np.linspace(0, nlen, nbin + 1),     np.arange(nlen),     np.sort(x))
#create histogram with equal-frequency bins 
n, bins, patches = plt.hist(data, equalObs(data, 10), edgecolor='black')
plt.show()
#display bin boundaries and frequency per bin 
bins, n
(array([-2.3015387 , -0.93576943, -0.67124613, -0.37528495, -0.20889423,
         0.07734007,  0.2344157 ,  0.51292982,  0.86540763,  1.19891788,
         2.18557541]),
 array([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.]))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/equalfreqbinningpython2.png">
Each bin doesn’t have an equal width, but each bin <i>does </i>contain an equal amount of observations. For example:
The first bin extends from -2.3015387 to -0.93576943  and contains 10 observations.
The second bin extends from -0.93576943 to -0.67124613 and contains 10 observations.
The third bin extends from -0.67124613 to -0.37528495 and contains 10 observations.
And so on.
We can see from the histogram that each bin is clearly not the same width, but each bin does contain the same amount of observations which is confirmed by the fact that each bin height is equal.
<h2><span class="orange">What is the Assumption of Equal Variance in Statistics?</span></h2>
Many statistical tests make the <b>assumption of equal variance</b>. If this assumption is violated, then the results of the tests become unreliable.
The most common statistical tests and procedures that make this assumption of equal variance include:
<b>1. ANOVA</b>
<b>2. t-tests</b>
<b>3. Linear Regression</b>
This tutorial explains the assumption made for each test, how to determine if this assumption is met, and what to do if it is violated.
<h3>Equal Variance Assumption in ANOVA</h3>
An <b>ANOVA</b> (“Analysis of Variance”) is used to determine whether or not there is a significant difference between the means of three or more independent groups.
Here’s an example of when we might use an ANOVA:
Suppose we recruit 90 people to participate in a weight-loss experiment. We randomly assign 30 people to use program A, B, or C for one month.
 
To see if the program has an impact on weight loss, we can perform a  one-way ANOVA .
An ANOVA assumes that each of the groups has equal variance. There are two ways to test if this assumption is met:
<b>1. Create boxplots.</b>
<h3><img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2019/12/boxplot.jpg"438"></h3>
Boxplots offer a visual way to check the assumption of equal variances.
The variance of weight loss in each group can be seen by the length of each box plot. The longer the box, the higher the variance. For example, we can see that the variance is a bit higher for participants in program C compared to both program A and program B.
<b>2. Conduct Bartlett’s Test.</b>
 Bartlett’s Test  tests the null hypothesis that the samples have equal variances vs. the alternative hypothesis that the samples do not have equal variances.
If the p-value of the test is less than some significance level (like 0.05), then we have evidence to say that the samples do not all have equal variances.
<b>What if the equal variance assumption is violated?</b>
In general, ANOVA’s are considered to be fairly robust against violations of the equal variances assumption as long as each group has the same sample size.
However, if the sample sizes are not the same and this assumption is severely violated, you could instead run a  Kruskal-Wallis Test , which is the non-parametric version of the one-way ANOVA.
<h3>Equal Variance Assumption in t-tests</h3>
A  two sample t-test  is used to test whether or not the means of two populations are equal.
The test makes the assumption that the variances are equal between the two groups. There are two ways to test if this assumption is met:
<b>1. Use the rule of thumb ratio.</b>
As a rule of thumb, if the ratio of the larger variance to the smaller variance is less than 4, then we can assume the variances are approximately equal and use the two sample t-test.
For example, suppose sample 1 has a variance of 24.5 and sample 2 has a variance of 15.2. The ratio of the larger sample variance to the smaller sample variance would be calculated as 24.5 / 15.2 = 1.61.
Since this ratio is less than 4, we could assume that the variances between the two groups are approximately equal.
<b>2. Perform an F-test.</b>
The <b>F-test</b> tests the null hypothesis that the samples have equal variances vs. the alternative hypothesis that the samples do not have equal variances.
If the p-value of the test is less than some significance level (like 0.05), then we have evidence to say that the samples do not all have equal variances.
<b>What if the equal variance assumption is violated?</b>
If this assumption is violated then we can perform  Welch’s t-test , which is a non-parametric version of the two sample t-test and does not make the assumption that the two samples have equal variances.
<h3>Equal Variance Assumption in Linear Regression</h3>
 Linear regression  is used to quantify the relationship between one or more predictor variables and a response variable.
Linear regression makes the assumption that the  residuals  have constant variance at every level of the predictor variable(s). This is known as <em>homoscedasticity</em>. When this is not the case, the residuals are said to suffer from  <em>heteroscedasticity</em>  and the results of the regression analysis become unreliable.
The most common way to determine if this assumption is met is to created a plot of residuals vs. fitted values. If the residuals in this plot seem to be scattered randomly around zero, then the assumption of homoscedasticity is likely met.
However, if there exists a systematic pattern in the residuals, such as the “cone” shape in the following plot then heteroscedasticity is a problem:
<img class="lazy" data-src="https://fourpillarfreedom.com/wp-content/uploads/2019/02/het2.jpg">
<b>What if the equal variance assumption is violated?</b>
If this assumption is violated, the most common way to deal with it is to transform the response variable using one of the three transformations:
<b>1. Log Transformation: </b>Transform the response variable from y to <b>log(y)</b>.
<b>2. Square Root Transformation: </b>Transform the response variable from y to <b>√y</b>.
<b>3. Cube Root Transformation: </b>Transform the response variable from y to <b>y<sup>1/3</sup></b>.
By performing these transformations, the problem of heteroscedasticity typically goes away.
Another way to fix heteroscedasticity is to use  weighted least squares regression . This type of regression assigns a weight to each data point based on the variance of its fitted value.
Essentially, this gives small weights to data points that have higher variances, which shrinks their squared residuals. When the proper weights are used, this can eliminate the problem of heteroscedasticity.
<h2><span class="orange">What is the Erlang Distribution?</span></h2>
The <b>Erlang distribution</b> is a  probability distribution  originally created by  A.K. Erlang  to model the number of telephone calls that an operator at a switching station may receive at once.
The distribution is used in telephone traffic engineering, queueing systems, mathematical biology, and other fields to model a variety of real-world phenomena.
<h3>Properties of the Erlang Distribution</h3>
The Erlang distribution has the following probability density function:
<b>f(x; k, μ) = x<sup>k-1</sup>e<sup>-x/μ</sup> / μ<sup>k</sup>(k-1)!</b>
where:
<b>k:</b> The shape parameter. This must be a positive integer.
<b>μ:</b> The scale parameter. This must be a positive real number.
It turns out that the Erlang distribution is a special case of the Gamma distribution when the shape parameter <em>k</em> is restricted to only positive real integers.
Note that the scale parameter is the reciprocal of the rate parameter, λ, i.e.  μ = 1/λ.
The Erlang distribution has the following properties:
<b>Mean:</b> k/λ
<b>Mode:</b> (k-1)/λ
<b>Variance:</b> k/λ<sup>2</sup>
<b>Skewness:</b> 2/√k
<b>Kurtosis:</b> 6/k
The Erlang distribution has the following relationships with other distributions:
When the shape parameter, k, is equal to 1 the Erlang distribution is equal to the  exponential distribution .
When the scale parameter, μ, is equal to 2 the Erlang distribution is equal to a Chi-Squared distribution with 2 degrees of freedom.
<h3>Visualizing the Erlang Distribution</h3>
The following plot shows the shape of the Erlang distribution when it takes on different parameters:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/erlang1-1.png">
It’s interesting to see just how much the shape of the distribution changes depending on the values used for the shape and scale parameters.
<b>Note:</b> You can find the R code used to generate the plot of Erlang distributions  here .
<h3>Use Cases</h3>
The Erlang distribution is used in a variety of real-world settings including:
<b>1. Call Centers</b>
The Erlang distribution is used to model the time in between incoming calls at a call center along with the expected number of calls.
This allows call centers to know what their staffing capacity should be during different times of the day so they can handle the incoming calls in a timely fashion without losing money by staffing too many employees during a given shift.
<b>2. Medical Settings</b>
The Erlang distribution is widely used to model cell cycle time distribution, which has a variety of different applications in medical settings.
<b>3. Retail Settings</b>
The Erlang distribution is used by retailers for modeling the frequency of interpurchase times by consumers.
This gives retailers and other businesses an idea of how often a given consumer is expected to purchase a product or service from them. This helps businesses with inventory control as well as staffing.
<h2><span class="orange">How to Add Error Bars to Charts in Excel</span></h2>
Often you may be interested in adding <b>error bars </b>to charts in Excel to capture uncertainty around measurements or calculated values. Fortunately this is easy to do using built-in Excel graphing functions.
This tutorial explains how to add error bars to both bar charts and line charts.
<h3>Error Bars in Bar Charts</h3>
Suppose we have the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel1.png">
To create a bar chart for this dataset, we can first highlight the data, then click on the <b>Insert </b>tab along the top ribbon. Within the <b>Charts </b>group, click on the first chart in the category titled <b>Insert column or bar chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel2.png">
This automatically produces the following bar chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel3.png">
To add error bars to each bar, click anywhere on the chart. Then click the Plus (+) sign that appears in the top right corner. Then click <b>Error Bars</b> > <b>More Options</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel4.png">
A new window will appear where you can choose to format the error bars with the following options:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel5.png">
The most common “Error Amount” to use is the <b>standard error</b>, which is calculated as:
<b>Standard error = s / √n</b>
where:
<b>s: </b>sample standard deviation
<b>n: </b>sample size
In this example, we could calculate the standard error by using the following formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel6.png">
The standard error turns out to be <b>1.78</b>. This is the width of the error bar that extends in both directions from the point estimates on the graph. For example, the value of the first bar in the chart is 4, thus it has an error bar that extends from:
Lower end: 4 – 178 = <b>2.22</b>
Upper end: 4 + 1.78 = <b>5.78</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel7.png">
<h3>Error Bars in Line Charts</h3>
Suppose we have the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel1.png">
To create a line chart for this dataset, we can first highlight the data, then click on the <b>Insert </b>tab along the top ribbon. Within the <b>Charts </b>group, click on the first chart in the category titled <b>Line chart</b>.  This will produce the following line chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel8.png">
To add error bars to each bar, click anywhere on the chart. Then click the Plus (+) sign that appears in the top right corner. Then click <b>Error Bars</b> > <b>More Options</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel9.png">
A new window will appear where you can choose to format the error bars with the following options:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel5.png">
You can choose to calculate the “Error Amount” using a fixed value, a percentage, a number of standard deviations, or the standard error. 
Once you select an error amount, the following error bars will be displayed on the line chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/errorbar_excel10.png">
<em>You can find more Excel tutorials  here .</em>
<h2><span class="orange">How to Add Error Bars to Charts in Google Sheets</span></h2>
Often you may be interested in adding <b>error bars</b> to charts in Google Sheets to capture uncertainty around measurements or calculated values.
Fortunately this is easy to do using built-in Google Sheets graphing functions.
The following step-by-step example shows how to add error bars to a column chart in Google Sheets.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the values for some data in Google Sheets:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets1.png">
<h3>Step 2: Create a Column Chart</h3>
Next, let’s insert a column chart. Highlight cells <b>A1:B6</b>, then click the <b>Insert</b> tab and click <b>Chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets2.png">
In the <b>Chart editor</b> window on the right side of the screen, click <b>Chart type</b> and then click <b>Column chart</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets3.png">
The following column chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets0.png">
<h3>Step 3: Insert Error Bars</h3>
To insert error bars, click the <b>Customize</b> tab on the Chart editor window. Scroll down and click <b>Series</b>, then check the box next to <b>Error bars</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets4.png">
By default, error bars that are 10% of the size of each column will be shown in the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets5.png">
<h3>Step 4: Customize Error Bars</h3>
There are three types of error bars you can use in column charts in Google Sheets:
Percent (default)
Constant
Standard Deviation
For example, we may choose to display a constant error bar with a length of 5 for each column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets6.png">
An error bar with a length of 5 would be added to each column in the chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorSheets7.png">
Feel free to choose one of the three types of error bars to display, depending on how you would like the chart to appear.
<h2><span class="orange">How to Add Error Bars to Charts in R (With Examples)</span></h2>
You can use the following basic syntax to add error bars to a bar plot in R:
<b>ggplot(df) +
    geom_bar(aes(x=x, y=y), stat='identity') +
    geom_errorbar(aes(x=x, ymin=y-sd, ymax=y+sd), width=0.4)
</b>
The following examples show how to use this function in practice.
<h3>Example 1: Add Error Bars Using Summary Data</h3>
Suppose we have the following data frame in R that shows the summary statistics for five categories:
<b>#create data frame
df &lt;- data.frame(category=c('A', 'B', 'C', 'D', 'E'), value=c(12, 17, 30, 22, 19), sd=c(4, 5, 7, 4, 2))
#view data frame
df
  category value sd
1        A    12  4
2        B    17  5
3        C    30  7
4        D    22  4
5        E    19  2
</b>
We can use the following code to create a bar plot with error bars to visualize this data:
<b>library(ggplot2)
#create bar plot with error bars
ggplot(df) +
    geom_bar(aes(x=category, y=value), stat='identity', fill='steelblue') +
    geom_errorbar(aes(x=category, ymin=value-sd, ymax=value+sd), width=0.4)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorbarR1.png">
Feel free to use the following arguments to modify the appearance of the error bars:
<b>width</b>: The width of the error bars
<b>size</b>: The thickness of the error bars
<b>color</b>: The color of the error bars
For example:
<b>library(ggplot2)
#create bar plot with custom error bars 
ggplot(df) +
    geom_bar(aes(x=category, y=value), stat='identity', fill='steelblue') +
    geom_errorbar(aes(x=category, ymin=value-sd, ymax=value+sd),  width=0.3, size=2.3, color='red')
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorbarR2.png">
<h3>Example 2: Add Error Bars Using Raw Data</h3>
Suppose we have the following data frame that shows the raw data for five different categories:
<b>#make this example reproducible
set.seed(0)
#create data frame
df &lt;- data.frame(category=rep(c('A', 'B', 'C', 'D', 'E'), each=10), value=runif(50, 10, 20))
#view first six rows of data frame
head(df)
  category    value
1        A 18.96697
2        A 12.65509
3        A 13.72124
4        A 15.72853
5        A 19.08208
6        A 12.01682
</b>
The following code shows how to summarize the data and then create a bar plot with error bars:
<b>library(dplyr)
library(ggplot2)
#summarize mean and sd for each category
df_summary &lt;- df %>%
  group_by(category) %>%
  summarize(mean=mean(value),
            sd=sd(value))
#view summary data
df_summary
# A tibble: 5 x 3
  category  mean    sd
       
1 A         16.4  2.80
2 B         14.9  2.99
3 C         14.6  3.25
4 D         15.2  2.48
5 E         15.8  2.41 
#create bar plot with error bars
ggplot(df_summary) +
    geom_bar(aes(x=category, y=mean), stat='identity', fill='steelblue') +
    geom_errorbar(aes(x=category, ymin=mean-sd, ymax=mean+sd), width=0.3, color='red')</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/errorbarR3.png">
<h2><span class="orange">How to Add Error Bars to Charts in Python</span></h2>
Often you may be interested in adding <b>error bars </b>to charts in Python to capture uncertainty around measurements or calculated values. Fortunately this is easy to do using the matplotlib library.
This tutorial explains how to add error bars to both bar charts and line charts in Python.
<h3>Error Bars in Bar Charts</h3>
Suppose we have the following dataset of 10 values in Python:
<b>import numpy as np
import matplotlib.pyplot as plt
#define dataset
data = [4, 6, 6, 8, 9, 14, 16, 16, 17, 20]</b>
To create a bar chart with error bars for this dataset, we can define the width of the error bars as the <b>standard error</b>, which is calculated a<b>
</b>
<b>Standard error = s / √n</b>
where:
<b>s: </b>sample standard deviation
<b>n: </b>sample size
The following code shows how to calculate the standard error for this example:
<b>#calculate standard error
std_error = np.std(data, ddof=1) / np.sqrt(len(data))
#view standard error 
std_error
1.78
</b>
Lastly, we can create the bar chart using error bars that have a width equal to the standard error:
<b>#define chart 
fig, ax = plt.subplots()
#create chart
ax.bar(x=np.arange(len(data)), #x-coordinates of bars
       height=data, #height of bars
       yerr=std_error, #error bar width
       capsize=4) #length of error bar caps</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/error_bar_python1.png">
The standard error turned out to be <b>1.78</b>. This is the width of the error bar that extends in both directions from the point estimates on the graph. For example, the value of the first bar in the chart is 4, thus it has an error bar that extends from:
Lower end: 4 – 178 = <b>2.22</b>
Upper end: 4 + 1.78 = <b>5.78</b>
Each error bar in the chart is the same width.
<h3>Error Bars in Line Charts</h3>
The following code shows how to create a line chart with error bars for the same dataset:
<b>import numpy as np
import matplotlib.pyplot as plt
#define data
data = [4, 6, 6, 8, 9, 14, 16, 16, 17, 20]
#define x and y coordinates
x = np.arange(len(data))
y = data
#create line chart with error bars
fig, ax = plt.subplots()
ax.errorbar(x, y,
            yerr=std_error,
            capsize=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/error_bar_python2.png">
Note that the argument <b>yerr </b>tells Python to create vertical error bars. We could instead use horizontal vertical bars by using the <b>xerr </b>argument:
<b>#create line chart with horizontal error bars
fig, ax = plt.subplots()
ax.errorbar(x, y,
            xerr=std_error,
            capsize=4)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/08/error_bar_python3.png">
<em>You can find more Python tutorials  here .</em>
<h2><span class="orange">How to Fix: error in do_one(nmeth) : na/nan/inf in foreign function call (arg 1)</span></h2>
One error you may encounter in R is:
<b>Error in do_one(nmeth) : NA/NaN/Inf in foreign function call (arg 1)
</b>
This error occurs when you attempt to perform  k-means clustering in R  but the data frame you’re using has one or more missing values.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R with a missing value in the second row:
<b>#create data frame
df &lt;- data.frame(var1=c(2, 4, 4, 6, 7, 8, 8, 9, 9, 12), var2=c(12, 14, 14, 8, 8, 15, 16, 9, 9, 11), var3=c(22, NA, 23, 24, 28, 23, 19, 16, 12, 15))
row.names(df) &lt;- LETTERS[1:10]
#view data frame
df
  var1 var2 var3
A    2   12   22
B    4   14   NA
C    4   14   23
D    6    8   24
E    7    8   28
F    8   15   23
G    8   16   19
H    9    9   16
I    9    9   12
J   12   11   15</b>
If we attempt to use the <b>kmeans()</b> function to perform k-means clustering on this data frame, we’ll receive an error:
<b>#attempt to perform k-means clustering with k = 3 clusters
km &lt;- kmeans(df, centers = 3)
Error in do_one(nmeth) : NA/NaN/Inf in foreign function call (arg 1)
</b>
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply use the  na.omit()  function to remove rows with missing values from the data frame:
<b>#remove rows with NA values
df &lt;- na.omit(df)
#perform k-means clustering with k = 3 clusters
km &lt;- kmeans(df, centers = 3)
#view results
km
K-means clustering with 3 clusters of sizes 4, 3, 2
Cluster means:
  var1      var2     var3
1  5.5 14.250000 21.75000
2 10.0  9.666667 14.33333
3  6.5  8.000000 26.00000
Clustering vector:
A C D E F G H I J 
1 1 3 3 1 1 2 2 2 
Within cluster sum of squares by cluster:
[1] 46.50000 17.33333  8.50000
 (between_SS / total_SS =  79.5 %)
Available components:
[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"  </b>
Notice that the k-means clustering algorithm runs successfully once we remove the rows with missing values from the data frame.
<b>Bonus:</b>  A complete step-by-step guide to k-means clustering in R 
<h2><span class="orange">How to Fix: Error in eval(predvars, data, env) : object ‘x’ not found</span></h2>
One error you may encounter in R is:
<b>Error in eval(predvars, data, env) : object 'x' not found 
</b>
This error occurs when you attempt to use a regression model in R to predict the response values of a new data frame, but the column names in the new data frame do not match the column names of the data frame that you used to fit the model.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we fit a simple linear regression model in R:
<b>#create data frame
data &lt;- data.frame(x=c(1, 2, 2, 3, 5, 6, 8, 9),   y=c(7, 8, 8, 6, 9, 8, 12, 14))
#fit linear regression model to data
model &lt;- lm(y ~ x, data=data)
#view summary of model
summary(model)
Call:
lm(formula = y ~ x, data = data)
Residuals:
    Min      1Q  Median      3Q     Max 
-2.1613 -0.7500  0.5000  0.9355  1.5161 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)   5.5161     0.9830   5.611  0.00137 **
x             0.7742     0.1858   4.167  0.00590 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 1.463 on 6 degrees of freedom
Multiple R-squared:  0.7432,Adjusted R-squared:  0.7004 
F-statistic: 17.37 on 1 and 6 DF,  p-value: 0.005896
</b>
Now suppose we attempt to use the <b>predict()</b> function to predict the response values for a new data frame:
<b>#define new data frame
new_data &lt;- data.frame(x1=c(4, 5, 7, 8, 9))
#attempt to predict y values for new data frame
predict(model, newdata=new_data)
Error in eval(predvars, data, env) : object 'x' not found
</b>
We receive an error because the data frame that we used when fitting the model had a predictor variable named <b>x</b>, but in the new data frame we named the predictor variable <b>x1</b>.
Since these names don’t match, we receive an error.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply make sure that the predictor variable in the new data frame has the same name.
So, we’ll be sure to name the predictor variable <b>x</b> in the new data frame:
<b>#define new data frame
new_data &lt;- data.frame(x=c(4, 5, 7, 8, 9)) 
</b>
Now we can use the <b>predict()</b> function to predict the response values for the new data frame:
<b>#predict y values for new data frame
predict(model, newdata=new_data)
        1         2         3         4         5 
 8.612903  9.387097 10.935484 11.709677 12.483871 
</b>
We’re able to successfully predict the y values for the new data frame without any errors since the column names matched. 
<h2><span class="orange">How to Fix: error in plot.new() : figure margins too large</span></h2>
One error you may encounter in R is:
<b>Error in plot.new() : figure margins too large
</b>
This error occurs when the plot panel in RStudio is too small for the margins of the plot that you’re attempting to create.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create the following plot in R:
<b>#attempt to create scatterplot
plot(1:30)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/error1.png">
We receive the following error:
<b>Error in plot.new() : figure margins too large 
</b>
We receive this error because the plot panel is extremely small (notice how small the panel is in the bottom left corner) and so the margins of the plot can’t be displayed in such a small panel.
<h3>Method #1: Fix the Error by Increasing the Size of the Plot Panel</h3>
The easiest way to fix this error is to increase the size of the plotting panel in RStudio:
<b>plot(1:30)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/error2.png">
Notice that we don’t receive an error because the plotting panel was large enough to display the margins of the plot.
<h3>Method #2: Fix the Error by Using the par() Function</h3>
By default, the  par()  function in R sets the margins of a plot as follows:
Bottom margin: <b>5.1</b>
Left margin: <b>4.1</b>
Top margin: <b>4.1</b>
Right margin: <b>2.1</b>
However, we can use the following syntax to make the margins smaller:
<b>#adjust plot margins
par(mar = c(1, 1, 1, 1))
#create scatterplot
plot(1:30)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/08/error3.png">
The plot is successfully displayed in the plotting panel in RStudio because we reduced the margins so much.
<h3>Method #3: Fix the Error by Shutting Down Current Plotting Device</h3>
If neither of the previous methods are able to fix the error, then you may need to use the following code to shut down the current plotting device:
<b>dev.off()</b>
In some cases, this may fix the error because it removes any plot settings that were used for previous plots and may be interfering with your current plot.
<h2><span class="orange">How to Fix: Error in plot.window(…) : need finite ‘xlim’ values</span></h2>
One error you may encounter when using R is:
<b>Error in plot.window(...) : need finite 'xlim' values
</b>
This error occurs when you attempt to create a plot in R and use either a character vector or a vector with only NA values on the x-axis.
The following examples show two different scenarios where this error may occur in practice.
<h3>Example 1: Error with Character Vector</h3>
Suppose attempt to create a scatterplot using the following code:
<b>#define data
x &lt;- c('A', 'B', 'C', 'D', 'E', 'F')
y &lt;- c(3, 6, 7, 8, 14, 19)
#attempt to create scatterplot
plot(x, y)
Error in plot.window(...) : need finite 'xlim' values
</b>
We receive an error because the vector that we used for the x-axis values is a character vector.
To fix this error, we simply need to supply a numeric vector to the x-axis:
<b>#define two numeric vectors
x &lt;- c(1, 2, 3, 4, 5, 6)
y &lt;- c(3, 6, 7, 8, 14, 19)
#create scatterplot
plot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/error11.png">
We’re able to create the scatterplot without any errors because we supplied a numeric vector for the x-axis.
<h3>Example 2: Error with Vector of NA Values</h3>
Suppose attempt to create a scatterplot using the following code:
<b>#define data
x &lt;- c(NA, NA, NA, NA, NA, NA)
y &lt;- c(3, 6, 7, 8, 14, 19)
#attempt to create scatterplot
plot(x, y)
Error in plot.window(...) : need finite 'xlim' values
</b>
We receive an error because the vector that we used for the x-axis values is a vector with only NA values.
To fix this error, we simply need to supply a numeric vector to the x-axis:
<b>#define two numeric vectors
x &lt;- c(1, 5, 9, 13, 19, 22)
y &lt;- c(3, 6, 7, 8, 14, 19)
#create scatterplot
plot(x, y)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/error12.png">
Once again we’re able to successfully create a scatterplot with no errors because we used a numeric vector for the x-axis.
<h2><span class="orange">How to Fix in R: could not find function “%>%”</span></h2>
One error you may encounter in R is:
<b>Error: could not find function "%>%"
</b>
This error often occurs when you attempt to use the “<b>%>%</b>” function in R without first loading the  dplyr  package.
To fix this error, you simply need to load the dplyr package first:
<b>library(dplyr)</b>
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we have the following data frame in R that displays the points scored by various basketball players on different teams:
<b>#create data frame
df &lt;- data.frame(team=c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'), points=c(6, 14, 15, 19, 22, 25, 39, 34))
#view data frame
df
  team points
1    A      6
2    A     14
3    A     15
4    A     19
5    B     22
6    B     25
7    B     39
8    B     34
</b>
Now suppose we attempt to use the “<b>%>%</b>” function to find the average points scored by players on each team:
<b>#find average points scored by players on each team
df %>%
  group_by(team) %>%
  summarize(avg_points = mean(points))
</b>
We receive an error because we never loaded the dplyr package.
<h3>How to Fix the Error</h3>
The way to fix this error is to simply load the dplyr package before using the “<b>%>%</b>” function:
<b>library(dplyr)
#find average points scored by players on each team
df %>%
  group_by(team) %>%
  summarize(avg_points = mean(points))
# A tibble: 2 x 2
  team  avg_points
        
1 A           13.5
2 B           30  
</b>
The output displays the average points scored by players on each team and we receive no error because we loaded the dplyr package before using the “<b>%>%</b>” function.
<h2><span class="orange">How to Fix in R: error in rbind(deparse.level, …) : numbers of columns of arguments do not match</span></h2>
One error you may encounter in R is:
<b>Error in rbind(deparse.level, ...) : 
  numbers of columns of arguments do not match 
</b>
This error occurs when you attempt to use the  rbind()  function in R to row-bind together two or more data frames that do not have the same number of columns.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we have the following two data frames in R:
<b>#create first data frame
df1 &lt;- data.frame(x=c(1, 4, 4, 5, 3),  y=c(4, 4, 2, 8, 10))
df1
  x  y
1 1  4
2 4  4
3 4  2
4 5  8
5 3 10
#create second data frame 
df2 &lt;- data.frame(x=c(2, 2, 2, 5, 7),  y=c(3, 6, 2, 0, 0),  z=c(2, 7, 7, 8, 15))
df2
  x y  z
1 2 3  2
2 2 6  7
3 2 2  7
4 5 0  8
5 7 0 15</b>
Now suppose we attempt to use <b>rbind</b> to row-bind these two data frames into one data frame:
<b>#attempt to row-bind the two data frames together
rbind(df1, df2)
Error in rbind(deparse.level, ...) : 
  numbers of columns of arguments do not match
</b>
We receive an error because the two data frames do not have the same number of columns.
<h3>How to Fix the Error</h3>
There are two ways to fix this problem:
<b>Method 1: Use rbind on Common Columns</b>
One way to fix this problem is to use the <b>intersect()</b> function to find the common column names between the data frames and then row-bind the data frames only on those columns:
<b>#find common column names
common &lt;- intersect(colnames(df1), colnames(df2))
#row-bind only on common column names
df3 &lt;- rbind(df1[common], df2[common])
#view result
df3
   x  y
1  1  4
2  4  4
3  4  2
4  5  8
5  3 10
6  2  3
7  2  6
8  2  2
9  5  0
10 7  0</b>
<b>Method 2: Use bind_rows() from dplyr</b>
Another way to fix this problem is to use the <b>bind_rows()</b> function from the  dplyr  package, which automatically fills in NA values for column names that do no match:
<b>library(dplyr)
#bind together the two data frames
df3 &lt;- bind_rows(df1, df2)
#view result
df3
   x  y  z
1  1  4 NA
2  4  4 NA
3  4  2 NA
4  5  8 NA
5  3 10 NA
6  2  3  2
7  2  6  7
8  2  2  7
9  5  0  8
10 7  0 15
</b>
Notice that NA values are filled in for the values from <b>df1</b> since column <b>z</b> didn’t exist in this data frame.
<h2><span class="orange">How to Fix: error in xy.coords(x, y, xlabel, ylabel, log) : ‘x’ and ‘y’ lengths differ</span></h2>
One common error you may encounter in R is:
<b>Error in xy.coords(x, y, xlabel, ylabel, log) : 
  'x' and 'y' lengths differ 
</b>
This error occurs when you attempt to create a plot of two variables but the variables don’t have the same length.
This tutorial shares exactly how to fix this error.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a scatterplot of the following two variables in R:
<b>#define x and y variables
x &lt;- c(2, 5, 5, 8)
y &lt;- c(22, 28, 32, 35, 40, 41)
#attempt to create scatterplot of x vs. y
plot(x, y)
Error in xy.coords(x, y, xlabel, ylabel, log) : 
  'x' and 'y' lengths differ
</b>
We receive an error because the length of x and y are not equal.
We can confirm this by printing the length of each variable:
<b>#print length of x
length(x)
[1] 4
#print length of y
length(y)
[1] 6
#check if length of x and y are equal
length(x) == length(y)
[1] FALSE
</b>
<h3>How to Fix the Error</h3>
The easiest way to fix this error is to simply make sure that both vectors have the same length:
<b>#define x and y variables to have same length
x &lt;- c(2, 5, 5, 8, 9, 12)
y &lt;- c(22, 28, 32, 35, 40, 41)
#confirm that x and y are the same length
length(x) == length(y)
[1] TRUE
create scatterplot of x vs. y
plot(x, y)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/length1.png">
If one vector happens to be shorter than the other, you could choose to plot only the values up to the length of the shorter vector.
For example, if vector x has 4 values and vector y has 6 values, we could create a scatterplot using only the first 4 values of each vector:
<b>#define x and y variables
x &lt;- c(2, 5, 5, 8)
y &lt;- c(22, 28, 32, 35, 40, 41)
#create scatterplot of first 4 pairwise values of x vs. y
plot(x, y[1:length(x)])
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/length2.png">
Notice that only the first four values of each vector are used to create the scatterplot.
<h2><span class="orange">How to Fix in R: error: `mapping` must be created by `aes()`</span></h2>
One error you may encounter when using R is:
<b>Error: `mapping` must be created by `aes()`
</b>
This error occurs when you attempt to use the <b>aes()</b> argument when creating a plot in ggplot2 and use it in the incorrect place or use it without the ‘mapping’ syntax.
The following example shows how to fix this error in practice.
<h3>How to Reproduce the Error</h3>
Suppose we attempt to create a boxplot using ggplot2:
<b>library(ggplot2)
#create data
df &lt;- data.frame(y=c(2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 16, 19, 28), x1=c(1, 2, 2, 3, 5, 6, 8, 8, 9, 9, 10, 11, 12, 15, 15), x2=c(8, 7, 7, 6, 6, 4, 3, 5, 4, 6, 5, 4, 3, 2, 2))
#attempt to create boxplot for 'x1' variable
ggplot() +
  geom_boxplot(df, aes(x=x1))
Error: `mapping` must be created by `aes()`
</b>
We receive an error because the <b>aes()</b> argument is used in the <b>geom_boxplot()</b> function without using the ‘mapping’ syntax.
<h3>How to Fix the Error</h3>
There are two ways to fix this error.
<b>Method 1: Use ‘mapping’ Syntax</b>
One way to fix the error is to specifically use the ‘mapping’ syntax in front of the <b>aes()</b> argument:
<b>library(ggplot2)
#create data
df &lt;- data.frame(y=c(2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 16, 19, 28), x1=c(1, 2, 2, 3, 5, 6, 8, 8, 9, 9, 10, 11, 12, 15, 15), x2=c(8, 7, 7, 6, 6, 4, 3, 5, 4, 6, 5, 4, 3, 2, 2))
#create boxplot for 'x1' variable
ggplot() +
  geom_boxplot(df, mapping=aes(x=x1))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/aes11.png">
Since we explicitly used the <b>mapping</b> syntax, we avoided any error.
<b>Method 2: Use ‘aes’ in ggplot Function</b>
Another way to fix this error is to use the <b>aes()</b> argument within the <b>ggplot()</b> function:
<b>library(ggplot2)
#create data
df &lt;- data.frame(y=c(2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 16, 19, 28), x1=c(1, 2, 2, 3, 5, 6, 8, 8, 9, 9, 10, 11, 12, 15, 15), x2=c(8, 7, 7, 6, 6, 4, 3, 5, 4, 6, 5, 4, 3, 2, 2))
#create boxplot for 'x1' variable
ggplot(df, aes(x=x1)) +
  geom_boxplot()
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/aes11.png">
We’re able to successfully create the boxplot and avoid any errors because we used the <b>aes()</b> argument within the <b>ggplot()</b> function.
<h2><span class="orange">What is Error Propagation? (Definition & Example)</span></h2>
<b>Error propagation</b> occurs when you measure some quantities <em>a</em>, <em>b</em>, <em>c</em>, … with uncertainties δ<em>a</em>, δ<em>b</em>, <em>δc</em> … and you then want to calculate some other quantity <em>Q</em> using the measurements of <em>a</em>, <em>b</em>, <em>c</em>, etc.
It turns out that the uncertainties δ<em>a</em>, δ<em>b</em>, <em>δc</em> will <b>propagate </b>(i.e. “extend to”) to the uncertainty of <em>Q.</em>
To calculate the uncertainty of <em>Q</em>, denoted δ<em>Q</em>, we can use the following formulas.
<b>Note:</b> For each of the formulas below, it’s assumed that the quantities <em>a</em>, <em>b</em>, <em>c</em>, etc. have errors that are <em>random</em> and <em>uncorrelated</em>.
<h3>Addition or Subtraction</h3>
If <em>Q</em> = a + b + … + c – (x + y + … + z)
Then δ<em>Q</em> = √(δa)<sup>2</sup> + (δb)<sup>2</sup> + … + (δc)<sup>2</sup> + (δx)<sup>2</sup> + (δy)<sup>2</sup> + … + (δz)<sup>2</sup>
<b>Example:</b> Suppose you measure the length of a person from the ground to their waist as 40 inches ± .18 inches. You then measure the length of a person from their waist to the top of their head as 30 inches ± .06 inches.
Suppose you then use these two measurements to calculate the total height of the person. The height would be calculated as 40 inches + 30 inches = <b>70</b> inches. The uncertainty in this estimate would be calculated as:
δ<em>Q</em> = √(δa)<sup>2</sup> + (δb)<sup>2</sup> + … + (δc)<sup>2</sup> + (δx)<sup>2</sup> + (δy)<sup>2</sup> + … + (δz)<sup>2</sup>
δ<em>Q</em> = √(.18)<sup>2</sup> + (.06)<sup>2</sup>
δ<em>Q</em> = <b>0.1897</b>
This gives us a final measurement of <b>70 ± 0.1897</b> inches.
<h3>Multiplication or Division</h3>
If <em>Q</em> = (ab…c) / (xy…z)
Then δ<em>Q</em>  = |Q| * √(δa/a)<sup>2</sup> + (δb/b)<sup>2</sup> + … + (δc/c)<sup>2</sup> + (δx/x)<sup>2</sup> + (δy/y)<sup>2</sup> + … + (δz/z)<sup>2</sup>
<b>Example: </b>Suppose you want to measure the ratio of the length of item <em>a</em> to item <em>b</em>. You measure the length of <em>a</em> to be 20 inches ± .34 inches and the length of <em>b</em> to be 15 inches ± .21 inches.
The ratio defined as <em>Q</em> = <em>a/b</em> would be calculated as 20/15 = <b>1.333</b>. The uncertainty in this estimate would be calculated as:
δ<em>Q</em>  = |Q| * √(δa/a)<sup>2</sup> + (δb/b)<sup>2</sup> + … + (δc/c)<sup>2</sup> + (δx/x)<sup>2</sup> + (δy/y)<sup>2</sup> + … + (δz/z)<sup>2</sup>
δ<em>Q</em>  = |1.333| * √(.34/20)<sup>2</sup> + (.21/15)<sup>2</sup>
δ<em>Q</em>  = <b>0.0294</b>
This gives us a final ratio of <b>1.333 ± 0.0294</b> inches.
<h3>Measured Quantity Times Exact Number</h3>
If <em>A</em> is known exactly and <em>Q</em> = <em>A</em>x
Then δ<em>Q</em>  = |A|δx
<b>Example:</b> Suppose you measure the diameter of a circle as 5 meters ± 0.3 meters. You then use this value to calculate the circumference of the circle <em>c = πd</em>.
The circumference would be calculated as <em>c = πd</em> = <em>π*5</em> = <b>15.708</b>. The uncertainty in this estimate would be calculated as:
δ<em>Q</em>  = |A|δx
δ<em>Q</em>  = |<em>π</em>| * 0.3
δ<em>Q</em>  = <b>0.942</b>
Thus, the circumference of the circle is <b>15.708 ± 0.942</b> meters.
<h3>Uncertainty in a Power</h3>
If <em>n</em> is an exact number and <em>Q</em> = <em>x<sup>n</sup></em>
Then δ<em>Q</em>  = |<em>Q</em>| * |<em>n</em>| * (δ<em>x/x</em>)
<b>Example:</b> Suppose you measure the side of a cube to be <em>s</em> = 2 inches <b>± </b>.02 inches. You then use this value to calculate the volumne of the cube <em>v</em> = <em>s</em><sup>3</sup>.
The volume would be calculated as <em>v</em> = <em>s</em><sup>3</sup> = 2<sup>3</sup> = <b>8 in.<sup>3</sup></b>. The uncertainty in this estimate would be calculated as:
δ<em>Q</em>  = |<em>Q</em>| * |<em>n</em>| * (δ<em>x/x</em>)
δ<em>Q</em>  = |8| * |3| *  (.02/2)
δ<em>Q</em>  = <b>0.24</b>
Thus, the volume of the cube is <b>8 ± .24 in.<sup>3</sup></b>.
<h3>General Formula for Error Propagation</h3>
If <em>Q</em> = <em>Q(x)</em> is any function of <em>x</em> then the general formula for error propagation can be defined as:
<b>δ<em>Q = |dQ</em>/<em>dX</em>|δx</b>
Note that you’ll rarely have to derive these formulas from scratch, but it can be good to know the general formula used to derive them.
<h2><span class="orange">How to Calculate Eta Squared in R</span></h2>
 Eta squared  is a measure of  effect size  that is commonly used in ANOVA models.
It measures the proportion of variance associated with each main effect and interaction effect in an ANOVA model and is calculated as follows:
<b>Eta squared = SS<sub>effect</sub> / SS<sub>total</sub></b>
where:
<b>SS<sub>effect</sub>:</b> The sum of squares of an effect for one variable.
<b>SS<sub>total</sub>:</b> The total sum of squares in the ANOVA model.
The value for Eta squared ranges from 0 to 1, where values closer to 1 indicate a higher proportion of variance that can be explained by a given variable in the model.
The following rules of thumb are used to interpret values for Eta squared:
<b>.01:</b> Small effect size
<b>.06:</b> Medium effect size
<b>.14 or higher:</b> Large effect size
This tutorial provides a step-by-step example of how to calculate Eta squared for variables in an ANOVA model in R.
<h2>Step 1: Create the Data</h2>
Suppose we want to determine if exercise intensity and gender impact weight loss.
To test this, we recruit 30 men and 30 women to participate in an experiment in which we randomly assign 10 of each to follow a program of either no exercise, light exercise, or intense exercise for one month.
The following code shows how to create a data frame to hold the data we’re working with:
<b>#make this example reproducible
set.seed(10)
#create data frame
data &lt;- data.frame(gender=rep(c("Male", "Female"), each = 30),   exercise=rep(c("None", "Light", "Intense"), each = 10, times=2),   weight_loss=c(runif(10, -3, 3), runif(10, 0, 5), runif(10, 5, 9),                 runif(10, -4, 2), runif(10, 0, 3), runif(10, 3, 8)))
#view first six rows of data frame
head(data)
#  gender exercise weight_loss
#1   Male     None  0.04486922
#2   Male     None -1.15938896
#3   Male     None -0.43855400
#4   Male     None  1.15861249
#5   Male     None -2.48918419
#6   Male     None -1.64738030
#see how many participants are in each group
table(data$gender, data$exercise)
#         Intense Light None
#  Female      10    10   10
#  Male        10    10   10</b>
<h2>Step 2: Fit the ANOVA Model</h2>
The following code shows how to fit a  two-way ANOVA  using exercise and gender as factors and weight loss as the  response variable :
<b>#fit the two-way ANOVA model
model &lt;- aov(weight_loss ~ gender + exercise, data = data)
#view the model output
summary(model)
            Df Sum Sq Mean Sq F value  Pr(>F)    
gender       1   15.8   15.80   9.916 0.00263 ** 
exercise     2  505.6  252.78 158.610 &lt; 2e-16 ***
Residuals   56   89.2    1.59       
</b>
<h2>Step 3: Calculate Eta Squared</h2>
We can calculate the effect size Eta squared for each variable in our model by using the  etaSquared()  function from the <b>lsr</b> package:
<b>#load lsr package
library(lsr)
#calculate Eta Squared
etaSquared(model)
            eta.sq eta.sq.part
gender   0.0258824   0.1504401
exercise 0.8279555   0.8499543
</b>
The Eta squared for gender and exercise are as follows:
Eta squared for gender: <b>0.0258824</b>
Eta squared for exercise: <b>0.8279555</b>
We would conclude that the effect size for exercise is very large while the effect size for gender is quite small.
These results match the p-values shown in the output of the ANOVA table. The p-value for exercise ( &lt;.000) is much smaller than the p-value for gender (.00263), which indicates that exercise is much more significant at predicting weight loss.
<h2>Additional Resources</h2>
The following tutorials explain how to fit various ANOVA models in R:
 How to Conduct a One-Way ANOVA in R 
 How to Conduct a Two-Way ANOVA in R 
 How to Conduct a Repeated Measures ANOVA in R 
<h2><span class="orange">What is Eta Squared? (Definition & Example)</span></h2>
<b>Eta squared</b> is a measure of  effect size  that is commonly used in ANOVA models.
It measures the proportion of variance associated with each main effect and interaction effect in an ANOVA model.
<h3>How to Calculate Eta Squared</h3>
The formula to calculate Eta squared is straightforward:
<b>Eta squared = SS<sub>effect</sub> / SS<sub>total</sub></b>
where:
<b>SS<sub>effect</sub>:</b> The sum of squares of an effect for one variable.
<b>SS<sub>total</sub>:</b> The total sum of squares in the ANOVA model.
The value for Eta squared ranges from 0 to 1, where values closer to 1 indicate a higher proportion of variance that can be explained by a given variable in the model.
The following rules of thumb are used to interpret values for Eta squared:
<b>.01:</b> Small effect size
<b>.06:</b> Medium effect size
<b>.14 or higher:</b> Large effect size
<h3>Example: Calculating Eta Squared</h3>
Suppose we want to determine if exercise intensity and gender impact weight loss.
To test this, we recruit 30 men and 30 women to participate in an experiment in which we randomly assign 10 of each to follow a program of either no exercise, light exercise, or intense exercise for one month.
The following table shows the results of a  two-way ANOVA  using exercise and gender as factors and weight loss as the  response variable :
<b>            Df Sum Sq Mean Sq F value p value    
gender       1   15.8   15.80   9.916 0.00263
exercise     2  505.6  252.78 158.610 &lt; 2e-16
Residuals   56   89.2    1.59  
</b>
We can calculate SS<sub>total</sub>, the total sum of squares, as follows: 15.8 + 505.6 + 89.2 = <b>610.6</b>.
We can then calculate Eta squared for gender and exercise as follows:
Eta squared for gender: 15.8 / 610.6 = <b>.02588</b>
Eta squared for exercise: 505.6 / 610.6 = <b>.828</b>
We would conclude that the effect size for exercise is very large while the effect size for gender is quite small.
These results match the p-values shown in the output of the ANOVA table. The p-value for exercise ( &lt;.000) is much smaller than the p-value for gender (.00263), which indicates that exercise is much more significant at predicting weight loss.
This example also illustrates why Eta squared is useful: Although gender is statistically significant (p = .00263), the effect size associated with it is actually quite small.
A  p-value  can only tell us whether or not there is some significant association between two variables, but a measure of effect size like Eta squared can tell us the strength of association between the variables.
<h2><span class="orange">How to Calculate Euclidean Distance in Excel</span></h2>
The <b>Euclidean distance</b> between two vectors, A and B, is calculated as:
<b>Euclidean distance = √Σ(A<sub>i</sub>-B<sub>i</sub>)<sup>2</sup></b>
where:
<b>Σ</b> is a Greek symbol that means “sum”
<b>A<sub>i</sub></b> is the i<sup>th</sup> value in vector A
<b>B<sub>i</sub></b>is the i<sup>th</sup> value in vector B
To calculate the Euclidean distance between two vectors in Excel, we can use the following function:
<b>=SQRT(SUMXMY2(RANGE1, RANGE2))
</b>
Here’s what the formula does in a nutshell:
<b>SUMXMY2</b> finds the sum of the squared differences in the corresponding elements of range 1 and range 2.
<b>SQRT</b> takes the square root of this sum of squared differences.
The end result if the Euclidean distance between the two ranges.
For example, suppose we have the following two vectors, A and B, in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/euclidExcel1.png">
We can use the following function to calculate the Euclidean distance between the two vectors: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/euclidExcel2.png">
The Euclidean distance between the two vectors turns out to be <b>12.40967</b>.
Note that this function will only include complete pairwise observations when calculating the Euclidean distance.
For example, the last two rows in column A would not be included in the calculation of the Euclidean distance between the following two vectors:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/12/euclidExcel3.png">
The Euclidean distance between the two vectors turns out to be <b>5.656854</b>. 
<h2><span class="orange">How to Calculate Euclidean Distance in R (With Examples)</span></h2>
The <b>Euclidean distance</b> between two vectors, A and B, is calculated as:
<b>Euclidean distance = √Σ(A<sub>i</sub>-B<sub>i</sub>)<sup>2</sup></b>
To calculate the Euclidean distance between two vectors in R, we can define the following function:
<b>euclidean &lt;- function(a, b) sqrt(sum((a - b)^2))
</b>
We can then use this function to find the Euclidean distance between any two vectors:
<b>#define two vectors
a &lt;- c(2, 6, 7, 7, 5, 13, 14, 17, 11, 8)
b &lt;- c(3, 5, 5, 3, 7, 12, 13, 19, 22, 7)
#calculate Euclidean distance between vectors
euclidean(a, b)
[1] 12.40967
</b>
The Euclidean distance between the two vectors turns out to be <b>12.40967</b>.
Note that we can also use this function to calculate the Euclidean distance between two columns of a data frame:
<b>#define data frame
df &lt;- data.frame(a=c(3, 4, 4, 6, 7, 14, 15), b=c(4, 8, 8, 9, 14, 13, 7), c=c(7, 7, 8, 5, 15, 11, 8), d=c(9, 6, 6, 7, 6, 15, 19))
#calculate Euclidean distance between columns <em>a </em>and <em>d</em>
euclidean(df$a, df$d)
[1] 7.937254
</b>
Note that this function will produce a warning message if the two vectors are not of equal length:
<b>#define two vectors of unequal length
a &lt;- c(2, 6, 7, 7, 5, 13, 14)
b &lt;- c(3, 5, 5, 3, 7, 12, 13, 19, 22, 7)
#attempt to calculate Euclidean distance between vectors
euclidean(a, b)
[1] 23.93742
Warning message:
In a - b : longer object length is not a multiple of shorter object length</b>
<em>You can refer to  this Wikipedia page  to learn more details about Euclidean distance.</em>
<h2><span class="orange">How to Calculate Euclidean Distance in Python (With Examples)</span></h2>
The <b>Euclidean distance</b> between two vectors, A and B, is calculated as:
<b>Euclidean distance = √Σ(A<sub>i</sub>-B<sub>i</sub>)<sup>2</sup></b>
To calculate the Euclidean distance between two vectors in Python, we can use the <b>numpy.linalg.norm</b> function:
<b>#import functions
import numpy as np
from numpy.linalg import norm
#define two vectors
a = np.array([2, 6, 7, 7, 5, 13, 14, 17, 11, 8])
b = np.array([3, 5, 5, 3, 7, 12, 13, 19, 22, 7])
#calculate Euclidean distance between the two vectors 
norm(a-b)
12.409673645990857</b>
The Euclidean distance between the two vectors turns out to be <b>12.40967</b>.
Note that this function will produce a warning message if the two vectors are not of equal length:
<b>#import functions
import numpy as np
from numpy.linalg import norm
#define two vectors
a = np.array([2, 6, 7, 7, 5, 13, 14])
b = np.array([3, 5, 5, 3, 7, 12, 13, 19, 22, 7])
#calculate Euclidean distance between the two vectors 
norm(a-b)
ValueError: operands could not be broadcast together with shapes (7,) (10,) 
</b>
Note that we can also use this function to calculate the Euclidean distance between two columns of a pandas DataFrame:
<b>#import functions
import pandas as pd 
import numpy as np
from numpy.linalg import norm
#define DataFrame with three columns
df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],   'assists': [5, 7, 7, 9, 12, 9, 9, 4],   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})
#calculate Euclidean distance between 'points' and 'assists' 
norm(df['points'] - df['assists'])
40.496913462633174
</b>
The Euclidean distance between the two columns turns out to be <b>40.49691</b>.
<h3>Notes</h3>
<b>1. </b>There are multiple ways to calculate Euclidean distance in Python, but as  this Stack Overflow thread explains , the method explained here turns out to be the fastest.
<b>2. </b>You can find the complete documentation for the <b>numpy.linalg.norm</b> function  here .
<b>3.</b> You can refer to  this Wikipedia page  to learn more details about Euclidean distance.
<h2><span class="orange">6 Real-Life Examples of the Normal Distribution</span></h2>
The  normal distribution  is the most commonly-used probability distribution in all of statistics.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/symmetric1.png">
It has the following properties:
Bell shaped
 Symmetrical 
 Unimodal  – it has one “peak”
Mean and median are equal; both are located at the center of the distribution
About 68% of data falls within one standard deviation of the mean
About 95% of data falls within two standard deviations of the mean
About 99.7% of data falls within three standard deviations of the mean
This tutorial shares 6 examples of real-world phenomena that actually follow the normal distribution.
<h3>Example 1: Birthweight of Babies</h3>
It’s well-documented that the birthweight of newborn babies is normally distributed with a mean of about 7.5 pounds.
The histogram of the birthweight of newborn babies in the U.S. displays a bell-shape that is typically of the normal distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal1-2.png">
<h3>Example 2: Height of Males</h3>
The distribution of the height of males in the U.S. is roughly normally distributed with a mean of 70 inches and a standard deviation of 3 inches.
A histogram of the height of all U.S. male reveals a bell shape:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/normalReal1.png">
<h3>Example 3: Shoe Sizes</h3>
The distribution of shoe sizes for males in the U.S. is roughly normally distributed with a mean of size 10 and a standard deviation of 1.
A histogram of the shoe sizes of all U.S. male reveals a bell shape with a single peak at size 10:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal3.png">
<h3>Example 4: ACT Scores</h3>
The distribution of ACT scores for high school students in the U.S. is normally distributed with a mean of 21 and a standard deviation of about 5.
A histogram of the ACT scores for all U.S. high school students illustrates this normal distribution:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/unimodal2.png">
<h3>Example 5: Average NFL Player Retirement Age</h3>
The distribution of retirement age for NFL players is normally distributed with a mean of 33 years old and a standard deviation of about 2 years.
A histogram of this distribution exhibits a classical bell shape:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/normalReal2.png">
<h3>Example 6: Blood Pressure</h3>
The distribution of diastolic blood pressure for men is normally distributed with a mean of about 80 and a standard deviation of 20.
A histogram of the distribution of blood pressures for all mean displays a normal distribution with a bell shape:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/02/normalReal3.png">
<h2><span class="orange">How to Graph Three Variables in Excel (With Example)</span></h2>
There are two common ways to create a graph with three variables in Excel:
<b>1. Create a Line Graph with Three Lines</b>
<b>2. Create a Bar Graph with Clustered Bars</b>
The following examples show how to create both of these graphs using the following dataset in Excel that shows the sales of three different products during various years:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/lines1.png">
<h2>Example 1: Create a Line Graph with Three Lines</h2>
We can use the following steps to plot each of the product sales as a line on the same graph:
Highlight the cells in the range <b>B1:D8</b>.
Click the <b>Insert</b> Tab along the top ribbon.
In the <b>Charts</b> group, click the first chart option in the section titled <b>Insert Line or Area Chart</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/linechart.jpg"588">
The following chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/lines2.png">
Each line represents the sales of one of the three products during each year.
<h2>Example 2: Create a Bar Graph with Clustered Bars</h2>
We can use the following steps to plot each of the product sales as a bar on the same graph:
Highlight the cells in the range <b>B1:D8</b>.
Click the <b>Insert</b> Tab along the top ribbon.
In the <b>Charts</b> group, click the first chart option in the section titled <b>Insert Column or Bar Chart</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/barchart.jpg"599">
The following chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/threevar1.jpg"668">
Each bar represents the sales of one of the three products during each year.
If you’d like to modify the x-axis to display the years, simply right click the x-axis and click <b>Select Data</b> from the dropdown.
In the new window that appears, click the <b>Edit</b> button under <b>Horizontal Axis Labels</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/threevar2.jpg"563">
Then choose <b>A2:A8</b> as the Axis label range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/threevar3.jpg"329">
Once you click <b>OK</b>, the x-axis labels will be updated to display the years:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/threevar4.jpg"532">
<h2>Additional Resources</h2>
The following tutorials explain how to create other common graphs in Excel:
 How to Create a Stem-and-Leaf Plot in Excel 
 How to Create a Dot Plot in Excel 
 How to Create Side-by-Side Boxplots in Excel 
 How to Create an Ogive Graph in Excel 
<h2><span class="orange">How to Add Average Line to Bar Chart in Excel</span></h2>
Occasionally you may want to add a line to a bar chart in Excel to represent the average value of the bars.
This tutorial provides a step-by-step example of how to create the following bar chart with an average line in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel7.jpg">
Let’s jump in!
<h3>Step 1: Enter the Data</h3>
First, let’s create the following dataset that shows the total sales of some item during each month in a year:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel1.jpg"425">
<h3>Step 2: Calculate the Average Value</h3>
Next, we’ll use the following formula to calculate the average sales per month:
<b>=AVERAGE($B$2:$B$13)
</b>
We can type this formula into cell <b>C2</b> and then copy and paste it to every remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel2.jpg"437">
<h3>Step 3: Create Bar Chart with Average Line</h3>
Next, highlight the cell range <b>A1:C13</b>, then click the <b>Insert</b> tab along the top ribbon, then click <b>Clustered Column</b> within the <b>Charts</b> group.
The following chart will be created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel3.jpg"659">
Next, right click anywhere on the chart and then click <b>Change Chart Type</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel4.jpg"539">
In the new window that appears, click <b>Combo</b> and then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel5.jpg"629">
The chart will be converted into a bar chart with an average line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel6.jpg"514">
The blue bars represent the sales each month and the orange line represents the average sales across all 12 months.
<h3>Step 4: Customize the Chart (Optional)</h3>
Feel free to add a title, customize the colors, customize the line style, and adjust the width of the bars and the average line to make the plot more aesthetically pleasing:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avglineexcel7.jpg">
<h2><span class="orange">How to Add Months to Date in Excel (With Examples)</span></h2>
You can use the <b>EDATE()</b> function in Excel to quickly add a certain number of months to a date.
This formula uses the following basic syntax:
<b>EDATE(start_date, months)</b>
where:
<b>start_date</b>: The starting date
<b>months</b>: The number of months to add to the starting date
For example, we can use the following syntax to add 10 months to the date in cell A1:
<b>=EDATE(A1, 10)
</b>
The following example shows how to use this function in practice.
<h2>Example: Add Months to Date in Excel</h2>
Suppose we have the following list of dates in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/add11.jpg"476">
We can type the following formula into cell <b>B2</b> to add three months to the date in cell <b>A2</b>:
<b>=EDATE(A2, 3)
</b>
We can then drag and fill this formula down to each remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/add12.jpg"452">
By default, Excel will display the dates in a numerical format.
To display the dates in a recognizable date format, highlight the cells in the range <b>B2:B11</b>, then click the <b>Number format</b> dropdown arrow and choose <b>Short Date</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/add13.jpg"669">
The dates will then be formatted correctly:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/add14.jpg">
Notice that each of the values in column B show the value of the date in column A plus three months.
Note that you can also use negative numbers to subtract months from a date.
For example, we could type the following formula into cell <b>B2</b> to subtract three months from the date in cell <b>A2</b>:
<b>=EDATE(A2, -3)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/add16.jpg">
Now each of the values in column B shows the value of the date in column A minus three months.
<b>Note</b>: You can find the complete documentation for the <b>EDATE()</b> function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Convert Days to Months in Excel 
 How to Calculate Average by Month in Excel 
 How to Calculate the Number of Months Between Dates in Excel 
<h2><span class="orange">How to Add & Subtract Hours from Time in Excel</span></h2>
You can use the following basic formulas to add and subtract hours from a time in Excel:
<b>Formula 1: Add Hours to Time</b>
<b>=A1+(3/24) </b>
This particular formula adds <b>3</b> hours to the time in cell <b>A1</b>.
<b>Formula 2: Subtract Hours from Time</b>
<b>=A1-(3/24) </b>
This particular formula subtracts <b>3</b> hours from the time in cell <b>A1</b>.
This formula works with times <em>and</em> datetimes in Excel.
<b>Note</b>: We must divide the number of hours by 24 because otherwise Excel will attempt to add or subtract 3 <em>days</em> instead of <em>hours</em>.
The following examples show how to use each formula in practice.
<h2>Example 1: Add & Subtract Hours from Time in Excel</h2>
The following screenshot shows how to add 3 hours to a column of time values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/time11.jpg">
The values in column B represent the values in column A with 3 hours added to them.
We can just as easily subtract 3 hours from each time value in column A as well:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/time12.jpg">
The values in column B represent the values in column A with 3 hours subtracted from them.
<h2>Example 2: Add & Subtract Hours from DateTime in Excel</h2>
The following screenshot shows how to add 3 hours to a column of datetime values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/time13.jpg">
The datetime values in column B represent the datetime values in column A with 3 hours added to them.
We can just as easily subtract 3 hours from each datetime value in column A as well:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/time14.jpg">
The datetime values in column B represent the datetime values in column A with 3 hours added to them.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Add & Subtract Weeks to Date in Excel 
 How to Convert Date to Month and Year Format in Excel 
 How to Calculate the Difference Between Two Dates in Excel 
<h2><span class="orange">How to Add & Subtract Weeks to Date in Excel</span></h2>
You can use the following basic formulas to add and subtract weeks from a date in Excel:
<b>Formula 1: Add Weeks to Date</b>
<b>=A1+7*(3) </b>
This particular formula adds <b>3</b> weeks to the date in cell <b>A1</b>.
<b>Formula 2: Subtract Weeks from Date</b>
<b>=A1-7*(1) </b>
This particular formula subtracts <b>1</b> week from the date in cell <b>A1</b>.
The following examples show how to use each formula in practice with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/add1.jpg"431">
<h2>Example 1: Add Weeks to Date in Excel</h2>
We can type the following formula into cell C2 to add 3 weeks to the date in cell A2:
<b>=A2+7*(3) </b>
We can then drag and fill this formula down to each remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/add3.jpg">
Column C now displays the date in column A with exactly 3 weeks added to it.
Feel free to change the <b>3</b> in the formula to any value you’d like to add a different number of weeks to the original date.
<h2>Example 2: Subtract Weeks from Date in Excel</h2>
We can type the following formula into cell C2 to subtract 1 week from the date in cell A2:
<b>=A2-7*(1) </b>
We can then drag and fill this formula down to each remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/add4.jpg"516">
Column C now displays the date in column A with 1 week subtracted from it.
Feel free to change the <b>1</b> in the formula to any value you’d like to subtract a different number of weeks from the original date.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Group Data by Week in Excel 
 How to Sum by Week in Excel 
<h2><span class="orange">Excel Advanced Filter: How to Use “Contains”</span></h2>
You can use the following syntax to filter for rows that contain specific text in an Excel <b>Advanced Filter</b>:
<b>*sometext*
</b>
The following examples show how to use this function in two different scenarios:
Filter for rows that contain one specific text
Filter for rows that contain one of multiple text
<h3>Example 1: Filter for Rows that Contain One Specific Text</h3>
Suppose we have the following dataset that shows the total sales of certain products in certain regions for a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/filtermultiple1.jpg"479">
Now suppose we’d like to filter for rows where the Region contains “<b>st</b>” in the name.
To do so, we can define a criteria range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext1.jpg"531">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext2.jpg"647">
We’ll choose <b>A1:C17</b> as the <b>list range</b> and <b>F1:F2</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext3.jpg"594">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where the Region contains the text “<b>st</b>“:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext4.jpg"565">
<h3>
<b>Example 2: Filter for Rows that Contain One of Multiple Text</b>
</h3>
Suppose we have the following dataset that shows the total sales of certain products in certain regions for a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/filtermultiple1.jpg"479">
Now suppose we’d like to filter for rows where the Region contains “<b>st</b>” or “<b>Nor</b>.”
To do so, we can define a criteria range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext5-1.jpg"559">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button.
We’ll choose <b>A1:C17</b> as the <b>list range</b> and <b>F1:G3</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext6.jpg"581">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where the Region contains “<b>st</b>” or “<b>Nor</b>“:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/containstext7.jpg"564">
<h2><span class="orange">Excel Advanced Filter: How to Use “Does Not Contain”</span></h2>
You can use the following syntax to filter for rows that do not contain specific text in an Excel <b>Advanced Filter</b>:
<b>&lt;>*sometext*
</b>
The following examples show how to use this function in two different scenarios:
Filter for rows that do not contain one specific text
Filter for rows that do not contain one of multiple text
<h3>Example 1: Filter for Rows that Do Not Contain One Specific Text</h3>
Suppose we have the following dataset that shows the total sales of certain products in certain regions for a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/filtermultiple1.jpg"479">
Now suppose we’d like to filter for rows where the Region does not contain “<b>East</b>.”
To do so, we can define a criteria range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not1.jpg"541">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not2.jpg"679">
We’ll choose <b>A1:C17</b> as the <b>list range</b> and <b>F1:F2</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not3.jpg"575">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where the Region does not contain “<b>East</b>“:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not4.jpg"541">
<h3>
<b>Example 2: Filter for Rows that Do Not Contain One of Multiple Text</b>
</h3>
Suppose we have the following dataset that shows the total sales of certain products in certain regions for a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/filtermultiple1.jpg"479">
Now suppose we’d like to filter for rows where the Region does not contain “<b>East</b>” or “<b>West</b>.”
To do so, we can define a criteria range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not5.jpg"550">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button.
We’ll choose <b>A1:C17</b> as the <b>list range</b> and <b>F1:G2</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not6.jpg"602">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where the Region does not contain “<b>East</b>” or “<b>West</b>“:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/not7.jpg"551">
<h2><span class="orange">Excel Advanced Filter: Display Rows with Non-Blank Values</span></h2>
You can use the following syntax to only display rows that are not blank in an Excel <b>Advanced Filter</b>:
<b>&lt;>
</b>
The following examples show how to use this syntax in two different scenarios:
Filter for rows that do not have blank values in one specific column
Filter for rows that do not have blank values in <em>any</em> column
<h3>Example 1: Filter for Rows that Do Not Have Blank Values in One Specific Column</h3>
Suppose we have the following dataset that shows information for various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank1.jpg"460">
Now suppose we’d like to filter for rows where the Team column is not blank.
To do so, we can define a criteria range in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank2.jpg"497">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank3.jpg"567">
We’ll choose <b>A1:C11</b> as the <b>list range</b> and <b>E1:E2</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank4.jpg"537">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where the Team column is not blank:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank5.jpg"461">
<h3>Example 2: Filter for Rows that Do Not Have Blank Values in Any Column</h3>
Suppose we have the following dataset that shows information for various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank6.jpg"463">
Now suppose we’d like to filter for rows where there is not a blank value in <em>any</em> column.
To do so, we can define a criteria range:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank7.jpg"527">
Next, we can click the <b>Data</b> tab and then click the <b>Advanced Filter</b> button.
We’ll choose <b>A1:C11</b> as the <b>list range</b> and <b>E1:G2</b> as the <b>criteria range</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank8.jpg"543">
Once we click <b>OK</b>, the dataset will be filtered to only show rows where there is no blank value in any column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/notblank9.jpg"534">
<h2><span class="orange">How to Apply a Percentage Increase or Decrease in Excel</span></h2>
You can use the following basic formulas to apply a percentage increase or percentage decrease to values in Excel:
<b>Method 1: Apply Percentage Increase</b>
<b>=A1*(1+B1)
</b>
<b>Method 2: Apply Percentage Decrease</b>
<b>=A1*(1-B1)
</b>
In both formulas, cell <b>A1</b> contains the original value and cell <b>B1</b> is the percentage that we’re increasing or decreasing the original value by.
The following examples show how to use each formula in practice.
<h3>Example 1: Apply Percentage Increase to Values</h3>
Suppose we have the following list of values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/multexcel1.jpg"486">
We can use the following formula in cell <b>C2</b> to apply a 25% increase to the value in cell <b>A2</b>:
<b>=A2*(1+B2)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/percentageExcel1.jpg">
Each value in column A has been increased by 25%.
For example:
<b>10</b> has been increased by 25% to <b>12.5</b>.
<b>15</b> has been increased by 25% to <b>18.75</b>.
<b>18</b> has been increased by 25% to <b>22.5</b>.
<b>20</b> has been increased by 25% to <b>25</b>.
And so on.
<h3>Example 2: Apply Percentage Decrease to Values</h3>
Once again suppose we have the following list of values in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/multexcel1.jpg"486">
We can use the following formula in cell <b>C2</b> to apply a 10% decrease to the value in cell <b>A2</b>:
<b>=A2*(1-B2)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/percentageExcel2.jpg">
Each value in column A has been decreased by 10%.
For example:
<b>10</b> has been decreased by 10% to <b>9</b>.
<b>15</b> has been decreased by 10% to <b>13.5</b>.
<b>18</b> has been decreased by 10% to <b>16.2</b>.
<b>20</b> has been decreased by 10% to <b>18</b>.
And so on.
<h2><span class="orange">How to AutoFill Dates in Excel (3 Examples)</span></h2>
Often you may want to autofill dates in Excel. Fortunately this is easy to do using the simple drag and fill feature built into Excel.
The following examples show how to autofill dates in Excel in practice.
<h3>Example 1: AutoFill Days in Excel</h3>
To autofill a list of days in Excel, simply type in one date to start:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill1.jpg"454">
Then hover over the bottom right-hand corner of the cell until a tiny “<b>+</b>” appears.
Then click and drag down to however many cells you’d like in the same column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill2.jpg"469">
The result is a list of consecutive days.
<h3>Example 2: AutoFill Weeks in Excel</h3>
To autofill a list of weeks in Excel, simply type in two dates that are exactly one week apart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill3.jpg"454">
Highlight cells <b>A2</b> and <b>A3</b>. Then hover over the bottom right-hand corner of cell <b>A3</b> until a tiny “<b>+</b>” appears.
Then click and drag down to however many cells you’d like in the same column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill4.jpg"459">
The result is a list of consecutive weeks.
<h3>Example 3: AutoFill Months in Excel</h3>
To autofill a list of months in Excel, simply type in two dates that are exactly one month apart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill5.jpg"447">
Highlight cells <b>A2</b> and <b>A3</b>. Then hover over the bottom right-hand corner of cell <b>A3</b> until a tiny “<b>+</b>” appears.
Then click and drag down to however many cells you’d like in the same column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/autofill6.jpg"463">
The result is a list of consecutive months.
<h2><span class="orange">Excel: How to Autofill Values from Another Sheet</span></h2>
The following step-by-step example shows how to autofill values from another sheet in Excel.
<h2>Step 1: Enter Data in First Sheet</h2>
First, let’s enter the following data into <b>Sheet1</b> in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/autosheet1.jpg"497">
<h2>Step 2: Autofill Data in Second Sheet</h2>
Now suppose we have another sheet titled <b>Sheet2</b> that contains the following data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/autosheet2.jpg"502">
Suppose we would like to autofill the values from the Points column in <b>Sheet1</b> into a Points column in <b>Sheet2</b>.
To do so, we can type the following formula in cell <b>C2</b> of <b>Sheet2</b>:
<b>=Sheet1!B2 </b>
This will automatically populate cell <b>C2</b> in <b>Sheet2</b> with the value from cell <b>B2</b> in <b>Sheet1</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/autosheet3.jpg"492">
To autofill the rest of the values in column C, hover over the bottom right-hand corner of cell <b>C2</b> until a tiny cross “+” appears. Then double click.
Each of the remaining cells in column C will be filled in:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/autosheet4.jpg"453">
Notice that all of the values from the Points column in <b>Sheet1</b> have been autofilled into <b>Sheet2</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to AutoFill Dates in Excel 
 How to Replace Blank Cells with Zero in Excel 
 How to Replace #N/A Values in Excel 
<h2><span class="orange">How to Calculate Average by Date in Excel</span></h2>
You can use the following formula to calculate the average value by date in an Excel spreadsheet:
<b>=AVERAGEIF(A1:A10, C1, B1:B10)
</b>
This particular formula calculates the average value in the cell range <b>B1:B10</b> only where the corresponding cells in the range <b>A1:A10</b> are equal to the date in cell <b>C1</b>.
The following example shows how to use this formula in practice.
<h3>Example: Calculate Average by Date in Excel</h3>
Suppose we have the following dataset that shows the sales of some product on various dates:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/averagedate1.jpg"496">
Now suppose we’d like to calculate the average sales value by date.
To generate a list of unique dates, we can use the following formula:
<b>=SORT(UNIQUE(A2:A15))</b>
We’ll type this formula into cell <b>D2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/averagedate2.jpg"483">
By default, Excel converts the date to the number of days since 1/1/1900.
To convert these numbers to a recognizable date format, simply highlight the cell range <b>D2:D6</b>, then click the format dropdown arrow and click <b>Short Date</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/averagedate3.jpg"598">
The dates will be converted to a recognizable date format:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/averagedate4.jpg"491">
Next, we can use the following formula to calculate the average sales by date:
<b>=AVERAGEIF($A$2:$A$15, D2, $B$2:$B$15)</b>
We’ll type this formula into cell <b>E2</b>, then copy and paste it into each remaining cell in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/averagedate5.jpg">
From the output we can see:
The average sales on 1/4/2022 is <b>5</b>.
The average sales on 1/7/2022 is <b>6.333</b>.
The average sales on 2/7/2022 is <b>6.333</b>.
And so on.
<h2><span class="orange">How to Calculate the Average by Group in Excel</span></h2>
The following step-by-step example shows how to calculate the average value by group in Excel.
<h2>Example: Calculate Average by Group in Excel</h2>
First, let’s enter the following dataset that shows the total points scored by various basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/test1.jpg"490">
Now suppose we’d like to find the average value of the points scored, grouped by team.
To do so, we can use the <b>UNIQUE()</b> function to first create a list of the unique teams.
We’ll type the following formula into cell <b>E2</b>:
<b>=UNIQUE(B2:B12)</b>
Once we press <b>Enter</b>, a list of unique team names will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/test2.jpg"495">
Next, we can use the <b>=AVERAGEIF()</b> function to find the average of points scored by players on each team:
<b>=AVERAGEIF($B$2:$B$12, E2, $C$2:$C$12)
</b>
We’ll type this formula into cell <b>F2</b> and copy and paste it down to each remaining cell in column F:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/averagegroup1.jpg">
Column E displays each of the unique teams and column F displays the average value of the points scored by each team.
We can verify these results are correct by manually calculating the average for one of the teams.
For example, the average points scored by players on the Spurs team would be:
Average points by Spurs players: (13.7 + 12.7 + 22.4) / 3 = <b>12.26667</b>.
This matches the value calculated using the formula.
<b>Note</b>: You can find the complete documentation for the <b>AVERAGEIF</b> formula in Excel  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate a Five Number Summary in Excel 
 How to Calculate the Mean and Standard Deviation in Excel 
 How to Calculate the Interquartile Range (IQR) in Excel 
<h2><span class="orange">How to Calculate Average by Month in Excel</span></h2>
Often you may want to calculate the average value grouped by month in Excel.
For example, suppose we have the following dataset and we’d like to calculate the average daily sales, grouped by month:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_sumbymonth1.jpg"504">
The following step-by-step example shows how to do so.
<h2>Step 1: Enter the Data</h2>
First, enter the data values into Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_sumbymonth1.jpg"504">
<h2>Step 2: Extract the Month from Dates</h2>
Next, we need to use the <b>=MONTH()</b> function to extract the month from each date.
In our example, we’ll type the following formula in cell <b>D2</b>:
<b>=MONTH(A2)
</b>
We’ll then drag and fill this formula down to every remaining cell in column D:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_sumbymonth2.jpg"478">
<h2>Step 3: Find the Unique Months</h2>
Next, we need to use the <b>=UNIQUE()</b> function to produce a list of unique months.
In our example, we’ll type the following formula in cell <b>F2</b>:
<b>=UNIQUE(D2:D10)
</b>
This will produce a list of unique months:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_sumbymonth3.jpg"512">
<h2>Step 4: Calculate the Average by Month</h2>
Next, we will use the <b>AVERAGEIF(range, criterion, average_range)</b> function to find the average of the daily sales values, grouped by month.
In our example, we’ll type the following formula in cell <b>G2</b>:
<b>=AVERAGEIF($D$2:$D$10, F2, $B$2:$B$10)
</b>
We’ll then drag and fill this formula down to the remaining cells in column G:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/avgmonth12.jpg">
This tells us:
The average daily sales value in January was <b>39</b>.
The average daily sales value in February was <b>25</b>.
The average daily sales value in March was <b>27.75</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Convert Date to Month and Year in Excel 
 How to Count by Month in Excel 
 How to Filter Dates by Month in Excel 
<h2><span class="orange">Excel: How to Calculate Average Excluding Outliers</span></h2>
There are two ways to calculate an average while excluding outliers in Excel:
<b>1. Calculate Average and Use TRIMMEAN to Exclude Outliers</b>
<b>2. Calculate Average and Use Interquartile Range to Exclude Outliers</b>
We will use the following dataset in Excel to illustrate how to use both methods:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/outlierExcel1.png">
<h3>Method 1: Calculate Average and Use TRIMMEAN to Exclude Outliers</h3>
The <b>TRIMMEAN</b> function in Excel can be used to calculate the average of a range of values while excluding a certain percentage of observations from the top and bottom of the dataset.
For example, we can use the following formula to calculate the average value in column A while excluding a total of 20% of observations (10% from the top and 10% from the bottom):
<b>=TRIMMEAN(A2:A16, 20%)
</b>
Since we have 15 values in our dataset 10% is 1.5, which is rounded down to 1. Thus, this formula will calculate the average of the values in the range while excluding the smallest value and the largest value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avgexclude1.jpg"451">
The average with outliers excluded turns out to be <b>58.30769</b>.
<h3>Method 2: Calculate Average and Use Interquartile Range to Exclude Outliers</h3>
The  interquartile range  (IQR) is the difference between the 75th percentile (Q3) and the 25th percentile (Q1) in a dataset. It measures the spread of the middle 50% of values.
We can define an observation to be an outlier if it is 1.5 times the interquartile range greater than the third quartile (Q3) or 1.5 times the interquartile range less than the first quartile (Q1).
We can use the following formula to calculate the interquartile range for our dataset in Excel:
<b>=QUARTILE(A2:A16,3)-QUARTILE(A2:A16,1)</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/outlierExcel2.png">
Next, we can use the following formula to use the IQR to identify outlier values and assign a “1” to any value that is an outlier in the dataset:
<b>=QUARTILE(A2:A16,3)-QUARTILE(A2:A16,1)</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2020/07/outlierExcel3.png">
We see that only one value – <b>164 </b>– turns out to be an outlier in this dataset.
Lastly, we can use the following formula to calculate the average of all values in the dataset that are not outliers:
<b>=AVERAGEIF(B2:B16, 0, A2:A16)
</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/avgexclude2.jpg">
The average with outliers excluded turns out to be <b>55.42857</b>.
<h2><span class="orange">How to Average Filtered Rows in Excel (With Example)</span></h2>
The easiest way to take the average of a filtered range in Excel is to use the following syntax:
<b>SUBTOTAL(101, A1:A10)
</b>
Note that the value 101 is a  shortcut  for taking the average of a filtered range of rows.
The following example shows how to use this function in practice.
<h3>Example: Sum Filtered Rows in Excel</h3>
Suppose we have the following dataset that shows the number of sales made during various days by a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/filtermonth1.jpg"480">
Next, let’s filter the data to only show the dates that are in January or April.
To do so, highlight the cell range <b>A1:B13</b>. Then click the <b>Data </b>tab along the top ribbon and click the <b>Filter</b> button.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/filtermonth2-1.jpg"542">
Then click the dropdown arrow next to <b>Date </b>and make sure that only the boxes next to January and April are checked, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter1.jpg"439">
The data will automatically be filtered to only show the rows where the dates are in January or April:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter2.jpg"450">
If we attempt to use the <b>AVERAGE()</b> function to find the average value in the Sales column, it will actually return the average of all of the original values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/averagefilter1.jpg"465">
Instead, we can use the <b>SUBTOTAL()</b> function:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/averagefilter2.jpg">
This function takes the average of only the visible rows.
We can manually verify this by taking the average of the visible rows:
Average of Sales in visible rows: (9+13+14+14+19) / 5 = <b>13.8</b>.
<h2><span class="orange">Excel: How to Calculate Average If Between Two Dates</span></h2>
You can use the following formula to calculate the average in Excel only for cells that fall between two specific dates:
<b>=AVERAGEIFS(B2:B11, A2:A11, "&lt;=1/15/2022", A2:A11, ">=1/5/2022")
</b>
This particular formula calculates the average value of cells in range <b>B2:B11</b> where the date in the range <b>A2:A11</b> is between 1/5/2022 and 1/15/2022.
The following example show  how to use this formula in practice.
<h3>Example: Calculate Average If Between Two Dates</h3>
Suppose we have the following dataset that shows the total sales made by some company on various dates:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagedates1.jpg"453">
We can use the following formula to calculate the average daily sales between 1/5/2022 and 1/15/2022:
<b>=AVERAGEIFS(B2:B11, A2:A11, "&lt;=1/15/2022", A2:A11, ">=1/5/2022")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagedates2.jpg"665">
The average daily sales between 1/5/2022 and 1/15/2022 is <b>7.2</b>.
We can manually verify that this is correct:
Average Daily Sales = (7 + 7 + 8 + 6 + 8) / 5 = <b>7.2</b>.
<b>Note</b>: You can find the complete documentation for the <b>AVERAGEIFS </b>function  here .
<h2><span class="orange">Excel: How to Calculate Average If Between Two Values</span></h2>
You can use the following formula to calculate the average of values in a range in Excel only for the values that fall between two specific values:
<b>=AVERAGEIFS(B:B,B:B,">=90",B:B,"&lt;=95")
</b>
This particular formula will only calculate the average for the values that fall between 90 and 95 in column B.
The following examples show how to use this formula in practice.
<h3>Example 1: Calculate Average If Between Two Values in Excel (Using One Range)</h3>
Suppose we have the following dataset that shows the exam scores received by 15 students: 
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagebetween2-1.jpg"492">
We can use the following formula to calculate the average exam score only for students who received a score between 90 and 95:
<b>=AVERAGEIFS(A:A,A:A,">=90",A:A,"&lt;=95")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagebetween5.jpg"557">
The average exam score only for students who received a score between 90 and 95 is <b>92.4</b>
We can manually verify that this is correct:
Average Exam Score = (90 + 92 + 92 + 93 + 95) / 5 = <b>92.4</b>.
<h3>Example 2: Calculate Average If Between Two Values in Excel (Using Multiple Ranges)</h3>
Suppose we have the following dataset that shows the height (in inches) and points scored by 15 basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagebetween3.jpg"458">
We can use the following formula to calculate the average exam points scored only for players who have a height between 70 and 75 inches:
<b>=AVERAGEIFS(B:B,A:A,">=70",A:A,"&lt;=75")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagebetween6.jpg"515">
The average points scored for players who are between 70 and 75 inches turns out to be <b>17.833</b>.
We can manually verify that this is correct:
Average Points Scored = (14 + 14 + 16 + 19 +20 + 24 / 6 = <b>17.833</b>.
<b>Note</b>: You can find the complete documentation for the <b>AVERAGEIFS </b>function  here .
<h2><span class="orange">Excel: How to Calculate Average If Cell Contains Number</span></h2>
You can use the following formula to calculate the average in Excel only for the cells that contain a number in a corresponding range:
<b>=SUMPRODUCT(--ISNUMBER(A2:A11), B2:B11) / COUNT(A2:A11)
</b>
This particular formula will calculate the average of the values in the range <b>B2:B11</b> only for the cells that contain a number in the range <b>A2:A11</b>.
The following example shows how to use this formula in practice.
<h2>Example: Calculate Average If Cell Contains Number</h2>
Suppose we have the following dataset in Excel that shows the number of sales made by employees at a company with certain ID’s:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/num1.jpg"436">
We can use the following formula to calculate the average sales made by only the employees who have a numeric value for ID:
<b>=SUMPRODUCT(--ISNUMBER(A2:A11), B2:B11) / COUNT(A2:A11)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/num2.jpg"672">
The average sales among employees with a numeric ID is <b>12</b>.
We can manually verify that this is correct by identifying which employees have numeric ID’s:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/num3.jpg"474">
The average sales made by these employees can be calculated as:
Average Sales = (19 + 4 + 8 +17) / 4 = <b>12</b>.
This matches the value calculated using our formula.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate Average If Between Two Values in Excel 
 How to Calculate a Cumulative Average in Excel 
 How to Find Weighted Moving Averages in Excel 
<h2><span class="orange">Excel: How to Calculate Average If Cell Contains Text</span></h2>
You can use the following formula to calculate the average in Excel only for the cells that contain a specific text:
<b>=AVERAGEIF(A1:A13,"*text*",B1:B13)
</b>
This particular formula will calculate the average of the values in the range <b>B1:B13</b> only for the cells that contain “text” in the range <b>A1:A13</b>.
<b>Note</b>: The asterisks are wildcard characters that tell Excel to ignore any text before or after a specific string.
The following example shows how to use this formula in practice.
<h2>Example: Calculate Average If Cell Contains Text</h2>
Suppose we have the following dataset that shows the points scored by 12 different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagecontains1.jpg"409">
We can use the following formula to calculate the average points scored by players on the “Mavs” team only:
<b>=AVERAGEIF(A2:A13,"*mavs*",B2:B13)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/averagecontains2.jpg"537">
The average points scored by players on the “Mavs” team is <b>25</b>.
We can manually verify that this is correct:
Average Points Scored = (31 + 23 + 21) / 3= <b>25</b>.
Note that this formula is case-insensitive.
That is, we could use “*MAVS*” or “*mavs*” or “*Mavs*” in the formula and Excel will return the same result.
<b>Note</b>: You can find the complete documentation for the <b>AVERAGEIF </b>function  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate Average If Between Two Values in Excel 
 How to Calculate a Cumulative Average in Excel 
 How to Find Weighted Moving Averages in Excel 
<h2><span class="orange">Excel: Calculate Average if Greater Than Zero</span></h2>
You can use the following formula to calculate the average in Excel only for values that are greater than zero:
<b>=AVERAGEIF(B2:B14, ">0", B2:B14)
</b>
This particular formula calculates the average value in the range <b>B2:B14</b> only for the cells that have a value greater than zero.
The following example shows how to use this formula in practice.
<h2>Example: Calculate Average if Greater than Zero in Excel</h2>
Suppose we have the following dataset in Excel that shows the total sales made by various employees at a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/av1.jpg"418">
If we simply used the <b>AVERAGE()</b> formula, we would find the average sales for all of the employees:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/av2.jpg"476">
The average sales per employee is <b>3.307</b>.
However, suppose we wanted to only calculate the average for employees who had greater than zero sales.
We could type the following formula into cell D2:
<b>=AVERAGEIF(B2:B14, ">0", B2:B14)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/av3.jpg">
The average sales for employees who had greater than zero sales was <b>4.3</b>.
This formula calculated the average by only using the values that were greater than zero.
We can confirm that this is correct by manually calculating the average of all values that are greater than zero:
Average of Values Greater than Zero: (10+4+4+3+9+2+1+1+4+5) / 10 = <b>4.3</b>.
This matches the value calculated by our formula.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 How to Calculate Average If Cell Contains Number in Excel 
 How to Use AVERAGEIF with Multiple Ranges in Excel 
 How to Calculate Average Excluding Outliers in Excel 
<h2><span class="orange">Excel: How to Average If Not Blank</span></h2>
You can use the following formulas in Excel to calculate the average value of a range if the value in a corresponding range is not blank:
<b>Formula 1: Average If Not Blank (One Column)</b>
<b>=AVERAGEIF(A:A, "&lt;>", B:B)
</b>
This formula calculates the average in column B only where the values in column A are not blank.
<b>Formula 2: Average If Not Blank (Multiple Columns)</b>
<b>=AVERAGEIFS(C:C, A:A, "&lt;>", B:B, "&lt;>")
</b>
This formula calculates the average in column C only where the values in column A <em>and</em> B are not blank.
The following examples show how to use each formula in practice.
<h3>Example 1: Average If Not Blank (One Column)</h3>
The following screenshot shows how to calculate the average of the values in the <b>Points</b> column only where the values in the <b>Team</b> column are not blank:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/averageifnot1.jpg">
The average of the values in the <b>Points</b> column for the rows where <b>Team</b> is not blank is <b>19.714</b>.
We can verify this is correct by manually calculating the average of the points for the teams that are not blank:
Average of points: (22 + 17 + 28 + 30 + 12 + 11 + 18) / 7 = <b>19.714</b>.
This matches the value that we calculated using the formula.
<h3>Example 2: Average If Not Blank (Multiple Columns)</h3>
The following screenshot shows how to calculate the average of the values in the <b>Points</b> column only where the values in the <b>Conference</b> <em>and</em> <b>Team</b> columns are not blank:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/averageifnot2.jpg"579">
The average of the values in the <b>Points</b> column for the rows where the <b>Conference</b> <em>and</em> <b>Team</b> columns are not blank is <b>18</b>.
We can verify this is correct by manually calculating the average of the points where the conference and team is not blank:
Average of points: (22 + 17 + 28 + 12 + 11) / 5 = <b>18</b>.
This matches the value that we calculated using the formula.
<h2><span class="orange">Excel: Calculate Average and Ignore Zero and Blank Cells</span></h2>
You can use the following formula to calculate the average in Excel while ignoring zeros and blank cells:
<b>=AVERAGEIF(B2:B14, "&lt;>0")
</b>
This particular formula calculates the average value in the range <b>B2:B14</b> and ignores cells that are equal to zero or blank.
<b>Note</b>: Excel ignores blank cells by default when calculating an average. 
Thus, we only need to specify in the formula that cells should not be equal ( “&lt;>0”) to zero as well.
The following example shows how to use this formula in practice.
<h2>Example: Calculate Average & Ignore Zero and Blank Cells in Excel</h2>
Suppose we have the following dataset in Excel that shows the total sales made by various employees at a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avv1.jpg"440">
If we simply used the <b>AVERAGE()</b> formula, we would find the average sales for all of the employees who had a non-blank value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avv2.jpg"470">
The average sales per employee who had a non-blank value is <b>3</b>.
However, suppose we wanted to only calculate the average for employees who had a sales value that was not blank and not equal to zero.
We could type the following formula into cell D2:
<b>=AVERAGEIF(B2:B14, "&lt;>0")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avv3.jpg">
The average sales for employees who had greater than zero sales was <b>4.125</b>.
This formula calculated the average by only using the values that were not blank and not equal to zero.
We can confirm that this is correct by manually calculating the average of all values that are not blank or equal to zero:
Average of Values Greater than Zero: (10+4+4+3+2+1+4+5) / 8 = <b>4.125</b>.
This matches the value calculated by our formula.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 How to Calculate Average If Cell Contains Number in Excel 
 How to Use AVERAGEIF with Multiple Ranges in Excel 
 How to Calculate Average Excluding Outliers in Excel 
<h2><span class="orange">How to Calculate Average Percentage in Excel (With Examples)</span></h2>
Often you may want to calculate an average percentage of some dataset. Fortunately this is easy to do using built-in functions in Excel.
This tutorial provides two examples of how to calculate an average percentage in different scenarios.
<h2>Example 1: Calculate Average Percentage with Percentages Only</h2>
Suppose we have the following list of percentages in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avgpercent1-1.jpg"485">
To calculate the average percentage, we can type the following formula into cell <b>B11</b>:
<b>=AVERAGE(B2:B9)</b>
Once we press <b>Enter</b>, the average percentage will be shown:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avgpercent2.jpg"447">
We can see that the average percentage is <b>81.94%</b>.
<h2>Example 2: Calculate Average Percentage with Counts & Percentages</h2>
Suppose we administer a survey to parents, students, and teachers at a certain school and ask them if they would be in favor of a new school rule.
The following dataset shows the number of people who responded to the survey in each of the three groups along with the percentage of individuals in each group who are in favor of the new rule:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avgpercent4.jpg"416">
We can use the following formula to calculate the average percentage of individuals who are in favor of the new rule across all three groups:
<b>=SUMPRODUCT(B2:B4, C2:C4)/SUM(B2:B4)
</b>
The following screenshot shows how to use this formula:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/avgpercent5.jpg">
We can see that <b>58.33%</b> of total individuals are in favor of the new rule.
We can verify that this is correct by manually calculating how many people were in favor of the rule from each group and then dividing by the total number of people:
% in Favor from Students = 400 * 30% = 120.
% in Favor from Parents = 300 * 90% = 270.
% in Favor from Teachers = 50 * 95% = 47.5.
% All Individuals in Favor = (120+270+47.5) / 750 = <b>0.5833</b>.
This matches the average percentage that we calculated using the <b>SUMPRODUCT</b> formula.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Find Percentage of Two Numbers in Excel 
 How to Calculate a Weighted Percentage in Excel 
 How to Calculate a Cumulative Percentage in Excel 
<h2><span class="orange">Excel: How to Use AVERAGEIF with Multiple Ranges</span></h2>
In Excel, it’s not possible to use the <b>AVERAGEIF()</b> function to calculate an average value using multiple ranges.
However, you can use the following formula as a workaround: 
<b>=(SUM(SUMIF(A2:A11,G2,B2:B11),SUMIF(D2:D11,G2,E2:E11))/SUM(COUNTIF(A2:A11,G2),COUNTIF(D2:D11,G2)))
</b>
This particular formula finds the average of the values in the ranges <b>B2:B11</b> and <b>E2:E11</b> where the corresponding values in the ranges <b>A2:A11</b> and <b>D2:D11</b> are equal to the value in cell <b>G2</b>.
The following example shows how to use this formula in practice.
<h2>Example: Using AVERAGEIF with Multiple Ranges in Excel</h2>
Suppose we have the following data in Excel that shows the sales of various fruits on different days:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/average1.jpg"453">
Now suppose we would like to calculate the average daily sales of <b>Mangos</b>.
We can use the following formula to do so: 
<b>=(SUM(SUMIF(A2:A11,G2,B2:B11),SUMIF(D2:D11,G2,E2:E11))/SUM(COUNTIF(A2:A11,G2),COUNTIF(D2:D11,G2)))
</b>
We’ll type this formula into cell <b>H2</b> and then press <b>Enter</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/average2.jpg">
We can see that the average daily sales of Mangos is <b>6.5</b>.
We can verify this is correct by manually taking the average of all sales values where the corresponding product is Mangos:
Average Mango Sales: (8 + 6 + 5 + 4 + 8 + 8) / 6 = <b>6.5</b>.
This matches the value that we calculated using our formula.
<b>Note</b>: In this example, we calculated an average using two cell ranges, but we can use similar syntax to include any number of cell ranges that we’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: How to Average If Not Blank 
 Excel: How to Calculate Average Excluding Outliers 
 Excel: How to Calculate the Average by Group 
<h2><span class="orange">Excel: How to Create a Bubble Chart with Labels</span></h2>
This tutorial provides a step-by-step example of how to create the following bubble chart with labels in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble8.jpg">
<h3>Step 1: Enter the Data</h3>
First, let’s enter the following data into Excel that shows various attributes for 10 different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble1.jpg"429">
<h3>Step 2: Create the Bubble Chart</h3>
Next, highlight the cells in the range <b>B2:D11</b>. Then click the <b>Insert</b> tab along the top ribbon and then click the <b>Bubble Chart</b> option within the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble2.jpg"614">
The following bubble chart will automatically be created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble3.jpg"587">
The x-axis displays the <b>points</b>, the y-axis displays the <b>assists</b>, and the size of each bubble represents the <b>rebounds</b>.
However, it’s tough to know which bubbles represent which players because there are no labels.
<h3>Step 3: Add Labels</h3>
To add labels to the bubble chart, click anywhere on the chart and then click the green plus “<b>+</b>” sign in the top right corner.
Then click the arrow next to <b>Data Labels</b> and then click <b>More Options</b> in the dropdown menu:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble4.jpg"544">
In the panel that appears on the right side of the screen, check the box next to <b>Value From Cells</b> within the<b> Label Options</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble5.jpg"302">
In the new window that appears, choose <b>A2:A11</b> as the cell range that contains our labels:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble6.jpg"450">
Then click <b>OK</b> and in the <b>Format Data Labels</b> panel on the right side of the screen, uncheck the box next to <b>Y Value</b> and choose <b>Center</b> as Label Position.
The following labels will automatically be added to the bubble chart:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble7.jpg"529">
<h3>Step 4: Customize the Bubble Chart</h3>
Lastly, feel free to click on individual elements of the chart to add a title, add axis labels, modify label font size, and remove gridlines:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/bubble8.jpg">
The final bubble chart is easy to read and we know exactly which bubbles represent which players.
<h2><span class="orange">Excel: How to Calculate the Difference Between Two Pivot Tables</span></h2>
The following example shows how to calculate the difference between two pivot tables in Excel.
<h3>Example: Calculate Difference Between Two Pivot Tables</h3>
Suppose we have the following two pivot tables that show the total sales and returns for different stores during two different years:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/diffpivot1.jpg"501">
Suppose we would like to calculate the difference in the <b>Sum of Sales</b> and <b>Sum of Returns</b> columns between the two pivot tables.
To calculate the difference in the <b>Sum of Sales</b> columns between the two pivot tables for just store <b>A</b>, we can type the following formula:
<b>=GETPIVOTDATA("Sum of Sales",$E$2,"Team","A")-GETPIVOTDATA("Sum of Sales",$E$10,"Team","A")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/diffpivot2.jpg">
Notice that this formula correctly calculates the difference between the <b>Sum of Sales</b> values between 2020 and 2019 for store A.
Difference = 38 – 16 = <b>22</b>.
We can change the values in the <b>GETPIVOTDATA</b> formula to calculate the difference between each corresponding value in the two pivot tables:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/diffpivot3.jpg"673">
<b>Note</b>: You can find the complete documentation for the <b>GETPIVOTDATA</b> function in Excel  here .
<h2><span class="orange">Excel: How to Calculate Years Between Two Dates</span></h2>
You can use the following formulas to calculate the number of years between two dates in Excel:
<b>Formula 1: Calculate Full Years Between Two Dates</b>
<b>=INT(YEARFRAC(A2,B2))
</b>
<b>Formula 2: Calculate Fractional Years Between Two Dates</b>
<b>YEARFRAC(A2,B2)
</b>
Both formulas assume that cell <b>A2</b> contains the start date and cell <b>B2</b> contains the end date.
The following examples show how to use each formula in practice.
<h2>Example 1: Calculate Full Years Between Two Dates</h2>
The following screenshot shows how to calculate the number of full years between a list of start and end dates in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/years1.jpg">
Here’s how to interpret the output:
There are <b>16</b> full years between 1/4/2005 and 1/1/2022.
There are <b>15</b> full years between 3/15/2007 and 3/15/2022.
There are <b>14</b> full years between 4/14/2008 and 4/18/2022.
And so on.
<h2>Example 2: Calculate Fractional Years Between Two Dates</h2>
The following screenshot shows how to calculate the number of fractional years between a list of start and end dates in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/years2.jpg">
Here’s how to interpret the output:
There are <b>16.992</b> years between 1/4/2005 and 1/1/2022.
There are <b>15</b> years between 3/15/2007 and 3/15/2022.
There are <b>14.011</b> years between 4/14/2008 and 4/18/2022.
And so on.
<b>Note</b>: You can find the complete documentation for the <b>YEARFRAC </b>function in Excel  here .
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Calculate the Number of Months Between Dates in Excel 
 How to Convert Date to Month and Year Format in Excel 
 How to Calculate Average by Month in Excel 
<h2><span class="orange">How to Change Axis Scales in Excel Plots (With Examples)</span></h2>
This tutorial provides a step-by-step example of how to change the x-axis and y-axis scales on plots in Excel.
<h3>Step 1: Enter the Data</h3>
First, let’s enter a simple dataset into Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale1.jpg"473">
<h3>Step 2: Create a Scatterplot</h3>
Next, highlight the cells in the range <b>A2:B16</b>. Then click the <b>Insert</b> tab along the top ribbon and then click the <b>Scatter</b> option within the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale2.jpg"463">
The following scatterplot will automatically be created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale3.jpg"639">
<h3>Step 3: Change the Axis Scales</h3>
By default, Excel will choose a scale for the x-axis and y-axis that ranges roughly from the minimum to maximum values in each column.
In this example, we can see that the <b>x-axis</b> ranges from <b>0 to 20</b> and the <b>y-axis</b> ranges from <b>0 to 30</b>.
To change the scale of the x-axis, simply right click on any of the values on the x-axis. In the dropdown menu that appears, click <b>Format Axis</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale4.jpg"395">
In the <b>Format Axis</b> panel that appears on the right side of the screen, change the values in the Minimum and Maximum boxes to change the scale of the x-axis.
For example, we could change the Maximum value of the x-axis to <b>50</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale5.jpg"305">
Once we press <b>Enter</b>, the x-axis scale will automatically be updated on the plot:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale6.jpg">
Notice that the x-axis now ranges from <b>0 to 50</b>.
The y-axis has remained unchanged.
Instead of changing the minimum and maximum bounds, we could also choose to use a logarithmic scale for the axis instead.
In the <b>Format Axis</b> panel, simply check the box next to <b>Logarithmic scale</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale7.jpg"286">
The x-axis will automatically be updated to use a logarithmic scale:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/scale8.jpg">
<b>Related:</b>  When Should You Use a Log Scale in Charts? 
Note that in these examples, we chose to change only the x-axis scale.
However, we can just as easily change the y-axis scale by right-clicking on any of the values on the y-axis and performing the same steps as above.
<h2><span class="orange">How to Filter a Chart in Excel (With Example)</span></h2>
Often you may want to filter a chart in Excel to only display a subset of the original data.
Fortunately this is easy to do using the <b>Chart Filters</b> function in Excel.
The following example shows how to use this function in practice.
<h2>Example: Filter a Chart in Excel</h2>
Suppose we have the following dataset in Excel that shows the sales of three different products during various years:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/06/lines1.png">
We can use the following steps to plot each of the product sales as a bar on the same graph:
Highlight the cells in the range <b>B1:D8</b>.
Click the <b>Insert</b> Tab along the top ribbon.
In the <b>Charts</b> group, click the first chart option in the section titled <b>Insert Column or Bar Chart</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/barchart.jpg"599">
The following chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/threevar1.jpg"668">
Each bar represents the sales of one of the three products during each year.
Now suppose we’d like to filter the chart to only show the sales of products A and B.
To do so, we can click anywhere on the chart, then click the <b>filter</b> icon that appears in the top right corner, then uncheck the box next to <b>Product C</b>, then click <b>Apply</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/filterchart1.jpg">
<b>Note</b>: It’s important that you click the <b>Apply</b> button, otherwise no filter will be applied.
The chart will automatically update to only show the sales for products A and B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/filterchart2.jpg"510">
You can also apply more than one filter.
For example, you could also uncheck the boxes next to the years 2015, 2016, and 2017 to filter by year as well:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/filterchart3.jpg"680">
Once you click <b>Apply</b>, the chart will automatically update to only show the sales for years 2018 through 2021:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/filterchart4.jpg"497">
Feel free to apply as many filters as you’d like to gain different insights into your dataset.
<h2>Additional Resources</h2>
The following tutorials explain how to create other common graphs in Excel:
 How to Create a Stem-and-Leaf Plot in Excel 
 How to Create a Dot Plot in Excel 
 How to Create Side-by-Side Boxplots in Excel 
 How to Create an Ogive Graph in Excel 
<h2><span class="orange">Excel: How to Create Chart & Ignore Blank Axis Labels</span></h2>
This tutorial provides a step-by-step example of how to create a chart in Excel and ignore blank axis labels.
<h2>Step 1: Enter Data with Some Blank Values</h2>
First, let’s enter the following dataset into Excel that contains some blank values for the axis labels:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/ignore1.jpg"387">
If we highlight this range of data and insert a bar chart, the x-axis will have several blank values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/ignore2.jpg"480">
<h2>Step 2: Modify the Data to Remove Blank Values</h2>
In this step, we’ll create a new dataset that removes all of the blank values from the original dataset.
First, type the following formula into cell D2:
<b>=IFERROR(INDEX($A$2:$A$9,AGGREGATE(15,3,ROW($A$2:$A$9)-ROW($A$1)/($A$2:$A$9&lt;>""),ROWS($A$2:A2))),"")
</b>
Then drag the formula down to the other cells in column D until you encounter a blank value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/ignore3.jpg"497">
Next, type the following formula into cell E2:
<b>=INDEX($B$2:$B$9,MATCH(D2,$A$2:$A$9,0))</b>
Then drag the formula down to the remaining cells in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/ignore4.jpg"547">
We have successfully created a new dataset that contains only the rows where the value in the original “Store” column is not blank.
<h2>Step 3: Create the Chart with No Blank Axis Labels</h2>
We can now highlight the cells in the range <b>D2:E6</b>, then click the <b>Insert</b> tab along the top ribbon, then click the icon called <b>Clustered Column</b> within the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/ignore5.jpg"676">
Notice that the x-axis of the chart contains no blank labels since we used the modified dataset to create this chart.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Add Labels to Scatterplot Points in Excel 
 How to Change Axis Scales in Excel Plots 
 How to Add a Vertical Line to Charts in Excel 
<h2><span class="orange">Excel: How to Create a Chart and Ignore Blank Cells</span></h2>
Often you may want to create a chart in Excel using a range of data and ignore any blank cells in the range.
Fortunately this is easy to do using the <b>Hidden and Empty Cells</b> feature in Excel.
The following example shows how to use this function in practice.
<h3>Example: Create Chart in Excel and Ignore Blank Cells</h3>
Suppose we have the following dataset that shows the sales of some product during each month in a year:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore11.jpg"406">
Now suppose we would like to create a line chart to visualize the sales during each month.
We can highlight the cells in the range <b>B2:B13</b>, then click the <b>Insert</b> tab along the top ribbon, then click the <b>Line</b> button within the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/linechart.jpg"590">
The following line chart will appear:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore12.jpg"597">
Notice that there are two gaps in the line chart where we have missing values for the months of May and August.
To fill in these gaps, right click anywhere on the chart and then click <b>Select Data</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore134.jpg"564">
In the new window that appears, click the <b>Hidden and Empty Cells</b> button in the bottom left corner:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore14.jpg"604">
In the new window that appears, check the button next to <b>Connect data points with line</b> and then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore15.jpg"325">
The gaps in the line chart will automatically be filled in:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/ignore16.jpg">
<h2><span class="orange">Excel: How to Check if Cell Contains Text from List</span></h2>
You can use the following formula in Excel to check if a cell contains text from a list:
<b>=IF(OR(COUNTIF(A1,"*"&$E$2:$E$8&"*")), "Yes", "No")
</b>
In this example, if cell <b>A1</b> contains any of the text values in the range <b>E2:E8</b> then it will return a <b>Yes</b>, otherwise it will return a <b>No</b>.
The following example shows how to use this formula in practice.
<h3>Example: Check if Cell Contains Text from List in Excel</h3>
Suppose we have the following dataset in Excel that shows the number of points scored by various basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/contains11.jpg"458">
There are three teams in the list from Texas: Mavs, Spurs, and Rockets.
Suppose we’d like to create a new column that tells us whether each team is from Texas or not.
First, we’ll create a list of the Texas teams in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/list1.jpg"456">
Then we’ll use the following formula to check if the value in the Team column contains any of the text values in column E:
<b>=IF(OR(COUNTIF(A2,"*"&$E$2:$E$4&"*")), "Yes", "No")</b>
We can type this formula into cell <b>C2</b> and then copy and paste it down to the remaining cells in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/list2.jpg"638">
Notice that any row that contains Mavs, Spurs, or Rockets receives a value of <b>Yes</b> while all other rows receive a value of <b>No</b>.
Also note that we could return values other than “Yes” and “No.”
For example, we could use the following formula to return “Texas” or “Not Texas” instead:
<b>=IF(OR(COUNTIF(A2,"*"&$E$2:$E$4&"*")), "Texas", "Not Texas")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/list3.jpg"678">
Notice that any row that contains Mavs, Spurs, or Rockets receives a value of <b>Texas </b>while all other rows receive a value of <b>Not Texas</b>.
<h2><span class="orange">Excel: How to Check if Range Contains Specific Value</span></h2>
You can use the following formulas to check if a range in Excel contains a specific value:
<b>Method 1: Check if Range Contains Value (Return TRUE or FALSE)</b>
<b>=COUNTIF(A1:A10,"this_value")>0</b>
<b>Method 2: Check if Range Contains Partial Value (Return TRUE or FALSE)</b>
<b>=COUNTIF(A1:A10,"*this_val*")>0</b>
<b>Method 3: Check if Range Contains Value (Return Custom Text)</b>
<b>=IF(COUNTIF(A1:A10,"this_value"),"Yes","No")
</b>
The following examples show how to use each formula in practice with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/rangecontains1.jpg"466">
<h3>Example 1: Check if Range Contains Value (Return TRUE or FALSE)</h3>
We can use the following formula to check if the range of team names contains the value “Mavericks”:
<b>=COUNTIF(A2:A15,"Mavericks")>0</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/rangecontains2.jpg"534">
The formula returns <b>FALSE</b> since the value “Mavericks” does not exist in the range <b>A2:A15</b>.
<h3>Example 2: Check if Range Contains Partial Value (Return TRUE or FALSE)</h3>
We can use the following formula to check if the range of team names contains the partial value “avs” in any cell:
<b>=COUNTIF(A2:A15,"*avs*")>0</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/rangecontains3.jpg"500">
The formula returns <b>TRUE </b>since the partial value “avs” occurs in at least one cell in the range <b>A2:A15</b>.
<h3>Example 3: Check if Range Contains Value (Return Custom Text)</h3>
We can use the following formula to check if the range of team names contains the value “Hornets” in any cell and return either “Yes” or “No” as a result:
<b>=IF(COUNTIF(A2:A15,"Hornets"),"Yes","No") </b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/rangecontains4.jpg"545">
The formula returns <b>No </b>since the value “Hornets” does not occur in any cell in the range <b>A2:A15</b>.
<h2><span class="orange">Excel: How to Compare Dates Without Time</span></h2>
Often you may want to compare two dates in Excel while ignoring the time values associated with the dates.
Fortunately you can use the <b>INT()</b> function in Excel to extract just the date from a datetime value, which allows you to easily compare dates while ignoring the time.
The following examples show how to use this <b>INT()</b> function in different scenarios.
<h3>Example 1: Compare Dates Without Time</h3>
Suppose we have the following list of datetime values in Excel that show when different people signed up for a 5K race along with the cutoff date for signing up:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/comparedatetime1.jpg"487">
We can type the following formula into cell B2 to compare the sign up date with the cutoff date:
<b>=IF(INT(A2)&lt;=$D$2, "Valid", "Not Valid")
</b>
We can then drag and fill this formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/comparedatetime2.jpg"563">
This formula compares only the date in column A with the cutoff date in cell D2.
If the date in column A is equal to or prior to the date in cell D2, the formula returns <b>Valid</b>.
Otherwise, the formula returns<b> Not Valid</b>.
<h3>Example 2: Compare and Count Dates Without Time</h3>
Once again suppose we have the following list of datetime values in Excel that show when different people signed up for a 5K race along with the cutoff date for signing up:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/comparedatetime1.jpg"487">
We can type the following formula into cell F2 to count the total number of sign up dates that are equal to or prior to the cutoff date:
<b>=SUMPRODUCT((INT(A2:A10)&lt;=D2)+0)
</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/comparedatetime3.jpg"580">
From the output we can see that <b>5</b> total dates in column A are equal to or prior to the cutoff date.
By using the <b>INT()</b> function, we were able to compare only the date portion of the datetime values in column A to the cutoff date.
<h2><span class="orange">Excel: How to Use a Concatenate If Formula</span></h2>
The following examples show how to use a <b>concatenate if</b> formula in Excel.
<h3>Example 1: Concatenate If (By Column)</h3>
Suppose we have the following data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/concatif1.jpg"471">
We can use the following formula to concatenate cells in column A and B only if the value in column B is equal to “Good”:
<b>=CONCAT(IF(B2="Good", A2:B2, ""))
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/concatif.jpg">
If the cell in column B is equal to “Good” then the value in column C is equal to the concatenation of the cells in column A and B.
Otherwise, this formula simply returns a blank value.
<h3>Example 2: Concatenate If (By Row)</h3>
Once again suppose we have the following data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/concatif1.jpg"471">
We can use the following formula to concatenate all of the cells in column A where the value in column B is equal to “Good”:
<b>=CONCAT(IF(B2:B7="Good", A2:A7, ""))
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/concatif2.jpg"556">
Notice that the value in cell <b>C2</b> is the result of concatenating every value in column A where the corresponding value in column B is equal to “Good.”
<b>Note</b>: You can find the complete documentation for the <b>CONCAT</b> function in Excel  here .
<h2><span class="orange">Excel: Apply Conditional Formatting Based on Date</span></h2>
To apply conditional formatting to cells in Excel based on date values, you can use the <b>New Rule</b> option under the <b>Conditional Formatting</b> dropdown menu within the <b>Home</b> tab.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based1.jpg"602">
You can then choose the option called <b>Use a formula to determine which cells to format</b> and type a custom formula in the box:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based2.jpg"554">
The following examples show how to use various formulas to highlight cells in the range <b>A2:A10</b> in Excel that contain the following date values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based3.jpg"514">
<h2>Example 1: Highlight Cells Based on Their Date Compared to Today</h2>
This article was written on 11/2/2022. Thus, we can use the following formula to highlight all cells in the range <b>A2:A10</b> that have a date before today:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based2.jpg"554">
Once we press <b>OK</b>, all cells that have a date before 11/2/2022 will be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based4.jpg"507">
Note that you can use the following formulas to highlight cells that are equal to or greater than today:
Highlight cells with a date equal to today: <b>=$A2 = TODAY()</b>
Highlight cells with a date after today: <b>=$A2 > TODAY()</b>
<h2>Example 2: Highlight Cells Based on Their Date Compared to Specific Date</h2>
We can use the following formula to highlight all cells in the range <b>A2:A10</b> that have a date before 6/30/2022:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based5.jpg"540">
Once we press <b>OK</b>, all cells that have a date before 6/30/2022 will be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based6.jpg"459">
<b>Note</b>: If your specific date is stored in a cell, such as cell D2, then you can instead use the following formula: <b>=$A2 &lt; D$2</b>.
<h2>Example 3: Highlight Cells Based on Date Range</h2>
We can use the following formula to highlight all cells in the range <b>A2:A10</b> that have a date between 4/25/2022 and 8/25/2022:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based7.jpg">
Once we press <b>OK</b>, all cells that have a date between this date range will be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/based8.jpg">
Notice that only the cells with a date between 4/25/2022 and 8/25/2022 are highlighted.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: Apply Conditional Formatting if Cell Contains Text 
 Excel: Apply Conditional Formatting with Multiple Conditions 
 Excel: Apply Conditional Formatting if Between Two Values 
<h2><span class="orange">Excel: Apply Conditional Formatting if Between Two Values</span></h2>
Often you may want to apply conditional formatting to cells whose values fall between two specific values in Excel.
The following example shows exactly how to do so.
<h3>Example: Conditional Formatting if Between Two Values</h3>
Suppose we have the following dataset that contains information about various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/multcondition1.jpg"469">
Suppose we would like to highlight each value in the points column where the value is between 10 and 20.
To do so, highlight the values in the range <b>B2:B14</b>, then click the <b>Conditional Formatting</b> icon on the <b>Home</b> tab, then click <b>Highlight Cells Rules</b>, then <b>Between</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditionalbetween.jpg"611">
In the new window that appears, choose 10 as the lower value and 20 as the upper value:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditionalbetween1.jpg"632">
One you click <b>OK</b>, the values in the points column that fall between 10 and 20 will automatically be formatted with a light red background and dark red text:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditionalbetween2.jpg"455">
Note that you can also choose a different format for the cells.
For example, you could choose to format the cells using a green background with dark green text:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditionalbetween3.jpg">
You can also choose <b>Custom Format</b> to specify a custom format style for the cells:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditionalbetween4.jpg"465">
This allows you to pick any combination of styles you’d like for the background color and text color.
<h2><span class="orange">Excel: How to Apply Conditional Formatting if Cell Contains Text</span></h2>
Often you may want to apply conditional formatting to cells that contain specific text in Excel.
The following example shows exactly how to do so.
<h3>Example: Conditional Formatting if Cell Contains Text</h3>
Suppose we have the following dataset that shows the names of various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/formatcontain1.jpg"468">
Suppose we would like to highlight each team name equal to “Mavs” in column A.
To do so, highlight the values in the range <b>A2:A14</b>, then click the <b>Conditional Formatting</b> icon on the <b>Home</b> tab, then click <b>New Rule</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional.jpg"523">
In the new window that appears, click <b>Use a formula to determine which cells to format</b>, then type in the following formula into the box:
<b>=SEARCH("Mavs", A2)
</b>
Then click the <b>Format</b> button and choose a color to use to fill in the cells that contain “Mavs” in the name. Then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional2-1.jpg">
Each team that contains “Mavs” in the name will automatically be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional2.jpg"473">
Note that you can also highlight cells that contain <b>partial text</b> by using the asterisk (*) wildcard with the <b>SEARCH</b> function.
For example, we could use the following formula to highlight all team names that contain the partial text “avs” in the name:
<b>=SEARCH("*avs*", A2)</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional3.jpg"676">
Once we click <b>OK</b>, each team that contains “avs” in the name will be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional4.jpg"475">
<h2><span class="orange">Excel: Apply Conditional Formatting with Multiple Conditions</span></h2>
Often you may want to apply conditional formatting to cells based on multiple conditions in Excel.
The following example shows exactly how to do so.
<h3>Example: Conditional Formatting with Multiple Conditions</h3>
Suppose we have the following dataset that contains information about various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/multcondition1.jpg"455">
Suppose we would like to highlight each value in the points column where the value is greater than 10 <em>and </em>less than 20.
To do so, highlight the values in the range <b>B2:B14</b>, then click the <b>Conditional Formatting</b> icon on the <b>Home</b> tab, then click <b>New Rule</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional.jpg"523">
In the new window that appears, click <b>Use a formula to determine which cells to format</b>, then type in the following formula into the box:
<b>=IF(AND(B2>10, B2&lt;20), TRUE, FALSE)
</b>
Then click the <b>Format</b> button and choose a fill color to use, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional5.jpg">
Each value in the points column that is greater than 10 <em>and</em> less than 20 will automatically be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional6.jpg"482">
<b>Note</b>: You can find the complete documentation for the <b>AND</b> function in Excel  here .
<h2><span class="orange">Excel: Apply Conditional Formatting if Two Cells Are Not Equal</span></h2>
Often you may want to apply conditional formatting to two cells in Excel if their values are not equal.
The following example shows exactly how to do so.
<h3>Example: Conditional Formatting if Two Cells Are Not Equal</h3>
Suppose we have the following lists in Excel that contain the names of 10 students each:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/ne0.jpg"412">
Suppose we would like to highlight the rows where the two names are not equal between the classes.
To do so, highlight the values in the range <b>A2:B11</b>, then click the <b>Conditional Formatting</b> icon on the <b>Home</b> tab, then click <b>New Rule</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/conditional.jpg"523">
In the new window that appears, click <b>Use a formula to determine which cells to format</b>, then type in the following formula into the box:
<b>=$A2 &lt;> $B2
</b>
Then click the <b>Format</b> button and choose a fill color to use, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/ne1-2.jpg"598">
Each row where the names are not equal will automatically be highlighted:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/ne2.jpg"472">
Note that this formula is <b>case-insensitive</b>. This means if we have “john” in one column and “John” in the other, the formula will assume these values are equal.
However, you can use the following formula to apply a <b>case-sensitive</b> search:
<b>=NOT(EXACT($A2,$B2))
</b>
This means if we have “john” in one column and “John” in the other, the formula will assume these values are <em>not</em> equal and will apply conditional formatting to them.
<h2><span class="orange">How to Connect Points in a Scatter Plot in Excel</span></h2>
Often you may want to connect the points in a scatter plot in Excel.
Fortunately this is easy to do and the following step-by-step example shows how to do so.
<h2>Step 1: Enter the Data</h2>
First, let’s enter the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/connect3.jpg"487">
<h2>Step 2: Create the Scatter Plot</h2>
Next, we will create a scatter plot to visualize the values in the dataset.
To do so, highlight the cells in the range <b>A2:B14</b>, then click the <b>Insert</b> tab along the top ribbon, then click the <b>Scatter</b> icon in the <b>Charts</b> group:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/04/scatterExcel.png">
The following scatter plot will automatically be created:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/connect4.jpg"528">
Notice that the points in the plot are not connected by default.
<h2>Step 3: Connect the Points in the Scatter Plot</h2>
To connect the points in the plot, double click on any individual point in the plot.
In the <b>Format Data Series</b> panel that appears on the right side of the screen, click the paint bucket icon, then click the <b>Line</b> group, then click <b>Solid Line</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/connect5.jpg"315">
The points in the plot will automatically be connected with a line:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/connect6.jpg">
Also note that within the <b>Format Data Series</b> panel, you can control the style of the line including:
Line color
Line width
Line dash type
Feel free to modify the appearance of the line to make it look however you’d like.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 How to Add Labels to Scatterplot Points in Excel 
 How to Add a Horizontal Line to a Scatterplot in Excel 
 How to Add a Regression Line to a Scatterplot in Excel 
<h2><span class="orange">How to Convert Categorical Data to Numeric in Excel</span></h2>
Often you may want to convert categorical data to numeric data in Excel to perform some specific type of analysis.
For example, suppose we ask 20 individuals to provide a categorical rating for some movie but we would actually like the categories to be converted to numerical values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_cat1.jpg"464">
The following step-by-step example shows how to do so.
<h3>Step 1: Enter the Data</h3>
First, enter the data values into Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_cat1.jpg"464">
<h3>Step 2: Use the IFS Function to Convert Categorical Values to Numeric Values</h3>
Next, we need to use the <b>=IFS()</b> function to convert the four categorical values of Great, Good, OK, Bad into numerical values of 4, 3, 2, 1.
In our example, we’ll type the following formula in cell <b>C2</b>:
<b>=IFS(B2="Great", 4, B2="Good", 3, B2="OK", 2, B2="Bad", 1)
</b>
The following screenshot shows how to use this function in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_cat2.jpg"612">
We can see that the first categorical value of <b>Great</b> has been converted to the numerical value of <b>4</b>.
<h3>Step 3: Drag the Formula Down to All Cells</h3>
Lastly, we’ll simply drag the formula in cell C2 down to every remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/excel_cat3.jpg"489">
From the output, we can see:
All <b>Great</b> ratings have been converted to a numerical value of <b>4</b>.
All <b>Good </b>ratings have been converted to a numerical value of <b>3</b>.
All <b>OK </b>ratings have been converted to a numerical value of <b>2</b>.
All <b>Bad </b>ratings have been converted to a numerical value of <b>1</b>.
We can now proceed to perform some numerical analysis on the data.
For example, we might decide to calculate the mean value in the <b>Numeric_Rating</b> column to get an idea of how the average individual rated the movie.
<h2><span class="orange">Excel: How to Convert Date to Month and Year Format</span></h2>
You can use one of the following formulas to convert a date to a month and year in Excel:
<b>Formula 1: Convert Date to Month and Full Year (e.g. 01/2022)</b>
<b>=TEXT(A1, "mm/yyyy")
</b>
<b>Formula 2: Convert Date to Month and Last Two Digits of Year (e.g. 01/22)</b>
<b>=TEXT(A1, "mm/yy")
</b>
<b>Formula 3: Convert Date to Abbreviated Month and Full Year (e.g. Jan. 2022)</b>
<b>=TEXT(A1, "mmm. yyyy")
</b>
<b>Formula 4: Convert Date to Full Month and Full Year (e.g. January 2022)</b>
<b>=TEXT(A1, "mmmm yyyy")</b>
Note that each formula assumes the date is in cell <b>A1</b>.
The following examples show how to use each formula in practice.
<h2>Example 1: Convert Date to Month and Full Year</h2>
We can use the following formula to convert a date to a month and full year:
<b>=TEXT(A2, "mm/yyyy") </b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/monthyear11.jpg">
Column B displays the month and full year for each date in column A.
<h2>Example 2: Convert Date to Month and Last Two Digits of Year</h2>
We can use the following formula to convert a date to a month and the last two digits of the year:
<b>=TEXT(A2, "mm/yy") </b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/monthyear12.jpg"505">
Column B displays the month and last two digits of the year for each date in column A.
<h2>Example 3: Convert Date to Abbreviated Month and Full Year</h2>
We can use the following formula to convert a date to an abbreviated month name and the full year:
<b>=TEXT(A2, "mmm. yyyy") </b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/monthyear13.jpg"509">
Column B displays the abbreviated month and full year for each date in column A.
<h2>Example 4: Convert Date to Full Month and Full Year</h2>
We can use the following formula to convert a date to a full month name and the full year:
<b>=TEXT(A2, "mmmm yyyy") </b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/06/monthyear14.jpg">
Column B displays the full month and full year for each date in column A.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Convert Date to Quarter and Year in Excel 
 How to Compare Dates Without Time in Excel 
 How to Filter Dates by Month in Excel 
<h2><span class="orange">How to Convert Date to Number in Excel (3 Examples)</span></h2>
This tutorial explains how to convert a date to a number in three different scenarios:
<b>1.</b> Convert One Date to Number
<b>2.</b> Convert Several Dates to Numbers
<b>3.</b> Convert Date to Number of Days Since Another Date
Let’s jump in!
<h3>Example 1: Convert One Date to Number</h3>
Suppose we would like to convert the date “2/10/2022” to a number in Excel.
We can use the <b>DATEVALUE</b> function in Excel to do so:
<b>=DATEVALUE("2/10/2022")
</b>
By default, this function calculates the number of days between a given date and <b>1/1/1900</b>.
The following screenshot shows how to use this function in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertNum1.jpg"468">
This tells us that there is a difference of <b>44,602</b> days between 2/10/2022 and 1/1/1900.
<h3>Example 2: Convert Several Dates to Numbers</h3>
Suppose we have the following list of dates in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertNum2.jpg"470">
To convert each of these dates to a number, we can highlight the range of cells that contain the dates, then click the <b>Number format</b> dropdown menu on the <b>Home</b> tab and choose <b>Number</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertNum3.jpg"670">
This will automatically convert each date to a number that represents the number of days between each date and <b>1/1/1900</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertNum4.jpg"514">
<h3>Example 3: Convert Date to Number of Days Since Another Date</h3>
We can use the following formula to convert a date to a number of days since another date:
<b>=DATEDIF(B2, A2, "d")
</b>
This particular formula calculates the number of days between the date in cell <b>B2</b> and the date in cell <b>A2</b>.
The following screenshot shows how to use the <b>DATEDIF</b> formula to calculate the number of days between the dates in column A and 1/1/2022:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertnum5.jpg"513">
Here’s how to interpret the values in column B:
There are <b>3</b> days between 1/1/2022 and 1/4/2022.
There are <b>8</b> days between 1/1/2022 and 1/9/2022.
There are <b>14</b> days between 1/1/2022 and 1/15/2022.
And so on.
<h2><span class="orange">Excel: How to Convert Date to Quarter and Year</span></h2>
You can use one of the following formulas to convert a date to a quarter and year in Excel:
<b>Formula 1: Convert Date to Quarter Only (e.g. Q1)</b>
<b>="Q" &INT((MONTH(A1)+2)/3)
</b>
<b>Formula 2: Convert Date to Quarter and Year (e.g. Q1-2022)</b>
<b>="Q" &INT((MONTH(A1)+2)/3) & "-" & YEAR(A1)
</b>
<b>Formula 3: Convert Date to Full Quarter Name and Year (e.g. Quarter 1 2022)</b>
<b>="Quarter " &INT((MONTH(A1)+2)/3) & " " & YEAR(A1)
</b>
Note that each formula assumes the date is in cell <b>A1</b>.
The following examples show how to use each formula in practice.
<h3>Example 1: Convert Date to Quarter Only </h3>
We can use the following formula to convert a date to a quarter only:
<b>="Q" &INT((MONTH(A2)+2)/3)</b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/quarter1.jpg"487">
The quarter for each date in column A is shown in column B.
<h3>Example 2: Convert Date to Quarter and Year</h3>
We can use the following formula to convert a date to a quarter and year:
<b>="Q" &INT((MONTH(A2)+2)/3) & "-" & YEAR(A2)</b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/quarter2.jpg">
The quarter and year for each date in column A is shown in column B.
<h3>Example 3: Convert Date to Full Quarter Name and Year</h3>
We can use the following formula to convert a date to a full quarter name and year:
<b>="Quarter " &INT((MONTH(A2)+2)/3) & " " & YEAR(A2)</b>
We can type this formula into cell B2 and drag the formula down to every remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/quarter3.jpg"623">
The quarter and year for each date in column A is shown in column B.
<h2><span class="orange">How to Convert Days to Months in Excel</span></h2>
You can use the following formula in Excel to convert days to months:
<b>=(B1-A1)/(365/12)
</b>
This formula calculates the number of months between cell <b>B1</b> (the end date) and cell <b>A1</b> (the start date).
The following example shows how to use this formula in practice.
<h3>Example: Convert Days to Months in Excel</h3>
Suppose we have the following list of start and end dates in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/daymonth1.jpg"464">
We could use the following formula to calculate the number of days between each start and end date:
<b>B2-A2</b>
We can type this formula into cell <b>C2</b> and then copy and paste it down to every remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/daymonth2.jpg"514">
Column C shows the difference (in days) between each start and end date.
However, we could instead use the following formula to calculate the difference between each start and end date in terms of months:
<b>=(B2-A2)/(365/12)</b>
We can type this formula into cell <b>C2</b> and then copy and paste it down to every remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/daymonth3.jpg"522">
Column C shows the number of months (including decimal places) between each start and end date.
For example:
There are <b>0.5589</b> months between 1/1/2020 and 1/18/2020.
There are <b>2.1041</b> months between 2/1/2020 and 4/5/2020.
There are <b>0.1644</b> months between 3/1/2020 and 3/6/2020.
And so on.
Note that you could instead use this formula to calculate the number of months between two dates if you’d like to assume that 30 days represents an average month:
<b>=(B2-A2)/30</b>
However, this is not as accurate as using (365/12) as the denominator in the formula.
<h2><span class="orange">Excel: Convert Decimal Time to Hours & Minutes</span></h2>
You can use the following formula to convert a decimal time to hours and minutes in Excel:
<b>=TEXT(B2/24, "h:mm")</b>
This will convert the decimal time in cell <b>B2</b> into hours and minutes.
For example, if the decimal time in cell <b>B2</b> is <b>2.5</b> then this formula will convert it to <b>2:30</b>.
The following example shows how to use this formula in practice.
<h2>Example: Convert Decimal Time to Hours & Minutes in Excel</h2>
Suppose we have the following dataset in Excel that shows the time (in decimal format) that it took for various athletes to finish some task:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/deci1.jpg"488">
To convert each decimal time to hours and minutes, we can type the following formula into cell <b>C2</b>:
<b>=TEXT(B2/24, "h:mm")</b>
We can then drag and fill this formula down to each remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/12/deci2.jpg">
Notice that each decimal time in column B has been converted to hours and minutes in column C.
For example:
<b>2.5</b> hours is equal to 2 hours and 30 minutes.
<b>3.05</b> hours is equal to 3 hours and 3 minutes.
<b>4.25</b> hours is equal to 4 hours and 15 minutes.
<b>5.5 </b>hours is equal to 5 hours and 30 minutes.
And so on.
<b>Note</b>: If you would also like to display seconds, you can use the following formula:
<b>=TEXT(B2/24, "h:mm:ss")</b>
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 Excel: How to Convert Time Duration to Minutes 
 Excel: Calculate Difference Between Two Times in Minutes 
 Excel: Calculate Difference Between Two Times in Hours 
<h2><span class="orange">Excel: How to Convert Minutes to Hours and Minutes</span></h2>
Often you may want to convert minutes to hours and minutes in Excel.
Fortunately this is easy to do and the following step-by-step example shows how to do so.
<h2>Step 1: Enter the Data</h2>
First, let’s enter the following dataset in Excel that shows the time (in minutes) that it took for various athletes to finish some task:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/minhours1.jpg"493">
<h2>Step 2: Divide Minutes by 1440</h2>
To display the minutes as hours and minutes, we must first divide each value in the minutes column by 1,440.
We’ll type the following formula into cell <b>C2</b>, then drag and fill the formula down to each remaining cell in column C:
<b>=B2/1440</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/minhours2.jpg"543">
<h2>Step 3: Format the Cells</h2>
Next, we need to format the cells so the values are shown in terms of hours and minutes.
To do so, highlight the cells in the range <b>C2:C11</b>, then click the <b>Number Format</b> dropdown menu, then click <b>More Number Formats</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/minhours3.jpg"649">
In the new window that appears, click <b>Custom</b> in the <b>Category</b> list, then type <b>[h]:mm</b> in the <b>Type</b> window, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/minhours4.jpg"558">
Once you click <b>OK</b>, the cells will automatically be formatted as hours and minutes:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/minhours5.jpg"501">
For example:
30 minutes is equal to <b>0 hours and 30 minutes</b>.
35 minutes is equal to <b>0 hours and 35 minutes</b>.
71 minutes is equal to <b>1 hour and 11 minutes</b>.
And so on.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 Excel: How to Convert Time Duration to Minutes 
 Excel: Calculate Difference Between Two Times in Minutes 
 Excel: Calculate Difference Between Two Times in Hours 
<h2><span class="orange">How to Convert a Pivot Table to a Table in Excel</span></h2>
The following step-by-step example shows how to convert an Excel pivot table to a data table.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the following sales data for three different stores:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortpivot1.jpg"475">
<h3>Step 2: Create the Pivot Table</h3>
To create a pivot table, click the <b>Insert</b> tab along the top ribbon and then click the <b>PivotTable</b> icon:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/gp0.jpg"521">
In the new window that appears, choose <b>A1:C16</b> as the range and choose to place the pivot table in cell <b>E1</b> of the existing worksheet:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortpivot2.jpg"665">
Once you click <b>OK</b>, a new <b>PivotTable Fields panel</b> will appear on the right side of the screen.
Drag the <b>Store</b> field to the <b>Rows</b> box, then drag the <b>Product </b>field to the <b>Columns</b> box, then drag the <b>Quantity</b> field to the <b>Values</b> box:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortpivot3.jpg"315">
The pivot table will automatically be populated with the following values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sortpivot4.jpg"471">
<h3>Step 3: Convert Pivot Table to Table</h3>
To convert this pivot table to an ordinary data table, simply select the entire pivot table (in this case, we select the range <b>E1:I6</b>) and press <b>Ctrl+C</b> to copy the data.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertdata1.jpg"633">
Then right click the cell where you’d like to paste the data (we’ll choose cell <b>E8</b>) and click the option titled <b>Paste Values</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertdata2.jpg"645">
The values from the pivot table will automatically be pasted as regular data values, starting in cell <b>E8</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/convertdata3.jpg"675">
Notice that this table doesn’t contain any of the fancy formatting or dropdown filters that were in the pivot table.
We’re simply left with a table of regular data values.
<h2><span class="orange">How to Convert Time into Decimals in Excel (With Examples)</span></h2>
You can use the following formulas to convert a time into a decimal value in Excel:
<b>1. Convert Time to Number of Hours:</b> Multiply original time by <b>24</b> (the number of hours in a day)
<b>2. Convert Time to Number of Minutes:</b> Multiply original time by <b>1440</b> (the number of minutes in a day)
<b>3. Convert Time to Number of Seconds:</b> Multiply original time by <b>86400</b> (the number of seconds in a day)
The following example shows how to use each of these formulas in practice.
<h3>Example: Convert Time into Decimals in Excel</h3>
Suppose we have the following list of times in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/timedecimal1.jpg"470">
We can use the following formulas to convert each time into a decimal that represents the total hours, minutes, and seconds:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/timedecimal2.jpg"471">
<b>Note</b>: Make sure that the Hours, Minutes, and Seconds columns are all formatted as either <b>General</b> or <b>Number</b> in order for the decimals to show up correctly.
Here’s how to interpret the output:
The time 2:30 is equal to <b>2.5</b> total hours.
The time 2:30 is equal to <b>150</b> total minutes.
The time 2:30 is equal to <b>9,000</b> total seconds.
And so on.
If you’d only like the integer values then you can wrap each formula in the <b>INT()</b> function:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/timedecimal3.jpg"490">
Here’s how to interpret the output:
The time 10:15:40 contains <b>10</b> whole hours.
The time 10:15:40 contains <b>615 </b>whole minutes.
The time 10:15:40 contains <b>36,940</b> whole seconds.
And so on.
<h2><span class="orange">Excel: How to Convert Time Duration to Minutes</span></h2>
You can use the following formula to convert a time duration to minutes in Excel:
<b>=VALUE(B2*24*60)
</b>
This particular formula converts the time duration in cell B2 to minutes.
For example, if the time is <b>10:14:22</b> then the formula will convert this to <b>614.37 </b>so that the time is represented as 614.37 minutes.
The following example shows how to use this formula in practice.
<h2>Example: Convert Time to Minutes in Excel</h2>
Suppose we have the following dataset in Excel that shows the number of hours, minutes, and seconds it took various athletes to finish a competition:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/dur1.jpg"426">
We can ensure that the values in the Duration column are formatted as durations by highlighting the range <b>B2:B11</b>, then clicking the <b>Number Format </b>dropdown, then clicking <b>More Number Formats</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/durat2.jpg"422">
We can then click the Category on the left called <b>Custom</b>, then choose <b>h:mm:ss</b>, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/durat3.jpg"562">
Next, we can use the following formula to convert the durations into minutes:
<b>=VALUE(B2*24*60)</b>
We will type this formula into cell <b>C2</b> and then click and drag the formula down to each remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/dur3.jpg">
The new <b>Minutes </b>column displays the time in the <b>Duration</b> column as minutes.
For example:
A duration of 10 hours, 14 minutes, and 22 seconds is converted to <b>614.3667 </b>minutes.
A duration of 26 hours, 14 minutes, and 22 seconds is converted to <b>1,547.367 </b>minutes.
A duration of 13 hours, 30 minutes, and 0 seconds is converted to <b>810 </b>minutes.
And so on.
<b>Note</b>: In this formula we multiply the time durations by 24 hours in a day and then by 60 minutes in an hour allows us to convert time durations to minutes.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 Excel: Calculate Difference Between Two Times in Hours 
 Excel: Calculate Difference Between Two Times in Minutes 
 Excel: How to Calculate Average Time 
<h2><span class="orange">Excel: How to Convert Time Duration to Seconds</span></h2>
You can use the following formula to convert a time duration to seconds in Excel:
<b>=VALUE(B2*24*3600)
</b>
This particular formula converts the time duration in cell B2 to seconds.
For example, if the time is <b>10:14:22</b> then the formula will convert this to <b>36862 </b>so that the time is represented as 36,862 seconds.
The following example shows how to use this formula in practice.
<h2>Example: Convert Time to Seconds in Excel</h2>
Suppose we have the following dataset in Excel that shows the number of hours, minutes, and seconds it took various athletes to finish a competition:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/dur1.jpg"426">
We can ensure that the values in the Duration column are formatted as durations by highlighting the range <b>B2:B11</b>, then clicking the <b>Number Format </b>dropdown, then clicking <b>More Number Formats</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/durat2.jpg"422">
We can then click the Category on the left called <b>Custom</b>, then choose <b>h:mm:ss</b>, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/durat3.jpg"562">
Next, we can use the following formula to convert the durations into seconds:
<b>=VALUE(B2*24*3600)</b>
We will type this formula into cell <b>C2</b> and then click and drag the formula down to each remaining cell in column C:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/dur2.jpg"484">
The new <b>Seconds </b>column displays the time in the <b>Duration</b> column as seconds.
For example:
A duration of 10 hours, 14 minutes, and 22 seconds is converted to <b>36,862 </b>seconds.
A duration of 26 hours, 14 minutes, and 22 seconds is converted to <b>94,462</b> seconds.
A duration of 13 hours, 30 minutes, and 0 seconds is converted to <b>48,600 </b>seconds.
And so on.
<b>Note</b>: In this formula we multiply the time durations by 24 hours in a day and then by 3,600 seconds in an hour allows us to convert time durations to seconds.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common operations in Excel:
 Excel: Calculate Difference Between Two Times in Hours 
 Excel: Calculate Difference Between Two Times in Minutes 
 Excel: How to Calculate Average Time 
<h2><span class="orange">Excel: How to Convert YYYYMMDD to Date Format</span></h2>
You can use the following formula to convert a date in <b>YYYYMMDD</b> format to a <b>DD/MM/YYYY</b> format in Excel:
<b>=DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))
</b>
This particular formula converts the date value in cell <b>A2</b> from a <b>YYYYMMDD</b> format to a <b>DD/MM/YYYY</b> format.
For example, this would convert a value of <b>20191030</b> to <b>10/30/2019</b>, which is an easier date format to read.
The following example shows how to use this formula in practice.
<h2>Example: Convert YYYYMMDD to Date Format in Excel</h2>
Suppose we have the following list of dates in Excel that are currently formatted as YYYYMMDD:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/yyyy1.jpg"486">
We can type the following formula into cell <b>B2</b> to convert the date value in cell <b>A2</b> to a more recognizable date format:
<b>=DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))</b>
We can then drag and fill this formula down to each remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/10/yyyy2.jpg"574">
Notice that each date value in column A has been converted to a date value with a <b>MM/DD/YYYY</b> format in column B.
<h2>Bonus: How This Formula Works</h2>
The <b>DATE</b> function in Excel uses the following basic syntax:
<b>=DATE(year, month, day)</b>
It then returns a date with a <b>MM/DD/YYYY</b> format.
Thus, if we type <b>DATE(2019, 10, 30)</b> then Excel will return <b>10/30/2019</b>.
Now consider when we use the following formula:
<b>=DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))</b>
This formula tells Excel to provide the following arguments to the <b>DATE</b> function:
The first 4 characters on the left of some string.
The middle 2 characters (starting from position 5) of some string.
The last 2 characters on the right of some string.
Thus, a date formatted as <b>YYYYMMDD</b> gets converted to:
<b>=DATE(YYYY, MM, DD)</b>
This produces a date value with a <b>MM/DD/YYYY</b> format.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: Calculate the Number of Months Between Dates 
 Excel: How to Calculate Sum by Date 
 Excel: How to Calculate Average by Date 
<h2><span class="orange">How to Count by Month in Excel</span></h2>
You can use the following formula to count the number of occurrences by month in an Excel spreadsheet:
<b>=SUMPRODUCT(1*(MONTH(A1:A10)=11))
</b>
This particular formula counts the number of dates in the range <b>A1:A10</b> that occur in the eleventh month (November) of the year.
The following example shows how to use this formula in practice.
<h3>Example: Count by Month in Excel</h3>
Suppose we have the following dataset that shows the sales of some product on various dates:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countmonth1.jpg"465">
Now suppose we’d like to count the number of dates by month.
To generate a list of unique month numbers, we can use the following formula:
<b>=SORT(UNIQUE(MONTH(A2:A15)))</b>
We’ll type this formula into cell <b>D2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countmonth2.jpg"511">
Next, we can use the following formula to count the number of dates by month:
<b>=SUMPRODUCT(1*(MONTH($A$2:$A$15)=D2))</b>
We’ll type this formula into cell <b>E2</b>, then copy and paste it into each remaining cell in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countmonth3.jpg"593">
From the output we can see:
Month 1 (January) occurred <b>4</b> times.
Month 2 (February) occurred <b>3</b> times.
Month 3 (March) occurred <b>1</b> time.
And so on.
<h2><span class="orange">How to Count by Year in Excel</span></h2>
You can use the following formula to count the number of occurrences by year in an Excel spreadsheet:
<b>=SUMPRODUCT(1*(YEAR(A1:A10)=2020))
</b>
This particular formula counts the number of dates in the range <b>A1:A10</b> that occur in the year 2020.
The following example shows how to use this formula in practice.
<h3>Example: Count by Year in Excel</h3>
Suppose we have the following dataset that shows the sales of some product on various dates:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countyear1.jpg"505">
Now suppose we’d like to count the number of dates by year.
To generate a list of unique years, we can use the following formula:
<b>=SORT(UNIQUE(YEAR(A2:A15)))</b>
We’ll type this formula into cell <b>D2</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countyear2.jpg"536">
Next, we can use the following formula to count the number of dates by year:
<b>=SUMPRODUCT(1*(YEAR($A$2:$A$15)=D2))</b>
We’ll type this formula into cell <b>E2</b>, then copy and paste it into each remaining cell in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countyear3.jpg">
From the output we can see:
The year 2018 occurred <b>2</b> times.
The year 2019 occurred <b>3</b> times.
The year 2020 occurred <b>2</b> times.
And so on.
<h2><span class="orange">How to Count Duplicates in Excel (With Examples)</span></h2>
Often you may want to count the number of duplicate values in a column in Excel.
Fortunately this is easy to do and the following examples demonstrate how.
<h3>Example 1: Count Duplicates for Each Value</h3>
We can use the following syntax to count the number of duplicates for each value in a column in Excel:
<b>=COUNTIF($A$2:$A$14, A2)
</b>
For example, the following screenshot shows how to use this formula to count the number of duplicates in a list of team names:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dup1.png">
From the output we can see:
The team name ‘Mavs’ occurs <b>2</b> times
The team name ‘Hawks’ occurs <b>3</b> times
The team name ‘Nets’ occurs <b>4</b> times
And so on.
<h3>Example 2: Count Non-Duplicate Values</h3>
We can use the following syntax to count the total number of non-duplicate values in a column:
<b>=SUMPRODUCT((A2:A14&lt;>"")/COUNTIF(A2:A14,A2:A14&""))
</b>
For example, the following screenshot shows how to use this formula to count the number of non-duplicates in a list of team names:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dup2.png">
From the output we can see that there are <b>6</b> unique team names.
<h3>Example 3: List Non-Duplicate Values</h3>
We can use the following syntax to list out all of the non-duplicate values in a column:
<b>=UNIQUE(A2:A14)</b>
The following screenshot shows how to use this formula to list out all of the unique team names in a column:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2021/10/dup3.png">
We can see that there are <b>6</b> unique team names and each of them are listed in column C.
<h2><span class="orange">How to Count Filtered Rows in Excel (With Example)</span></h2>
The easiest way to count the number of cells in a filtered range in Excel is to use the following syntax:
<b>SUBTOTAL(103, A1:A10)
</b>
Note that the value 103 is a  shortcut  for finding the count of a filtered range of rows.
The following example shows how to use this function in practice.
<h3>Example: Count Filtered Rows in Excel</h3>
Suppose we have the following dataset that shows the number of sales made during various days by a company:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/filtermonth1.jpg"447">
Next, let’s filter the data to only show the dates that are in January or April.
To do so, highlight the cell range <b>A1:B13</b>. Then click the <b>Data </b>tab along the top ribbon and click the <b>Filter</b> button.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/filtermonth2-1.jpg"542">
Then click the dropdown arrow next to <b>Date </b>and make sure that only the boxes next to January and April are checked, then click <b>OK</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter1.jpg"439">
The data will automatically be filtered to only show the rows where the dates are in January or April:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter2.jpg"450">
If we attempt to use the <b>COUNT()</b> function to count the number of values in the Date column, it will actually return the count of all of the original values:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter3.jpg"452">
Instead, we can use the <b>SUBTOTAL()</b> function:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter4.jpg"456">
This function only counts the visible rows.
From the output we can see that there are <b>5</b> days that fall in January or April.
Note that in this particular formula we used <b>103</b> in the subtotal function, but we could have also used <b>102</b>:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countfilter5.jpg">
Here’s the difference between the two:
<b>102</b> uses the <b>COUNT</b> function, which counts only cells containing numbers.
<b>103</b> uses the <b>COUNTA</b> function, which counts all cells that aren’t empty.
Feel free to use the value in your formula that makes sense for your data.
<h2><span class="orange">Excel: How to Count Cells Not Equal to Value</span></h2>
You can use the following formulas to count the number of cells in Excel not equal to some value:
<b>Method 1: Count Cells Not Equal to Value</b>
<b>=COUNTIF(A1:A100, "&lt;>value")
</b>
This formula counts the number of cells in the range <b>A1:A100</b> that are not equal to <b>value</b>.
<b>Method 2: Count Cells Not Equal to Several Values</b>
<b>=COUNTIFS(A1:A100, "&lt;>value1", A1:A100, "&lt;>value2", A1:A100, "&lt;>value3")
</b>
This formula counts the number of cells in the range <b>A1:A100</b> that are not equal to <b>value1</b> <em>or</em> <b>value2</b> <em>or</em> <b>value3</b>.
The following examples show how to use each method in practice.
<h3>Example 1: Count Cells Not Equal to Value</h3>
Suppose we have the following data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sumnot1.jpg"454">
We can use the following formula to count the number of cells in the <b>Team</b> column that are not equal to “A”:
<b>=COUNTIF(A2:A13, "&lt;>A")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countnot1.jpg">
This tells us that there are <b>10</b> cells in the <b>Team</b> column not equal to “A.”
<h3>Example 2: Count Cells Not Equal to Several Values</h3>
Once again suppose we have the following data in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/sumnot1.jpg"454">
We can use the following formula to count the number of cells in the <b>Team</b> column that are not equal to “A” <em>or</em> “B”:
<b>=COUNTIFS(A2:A13, "&lt;>A", A2:A13, "&lt;>B")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countnot2.jpg"556">
This tells us that there are <b>4 </b>cells in the <b>Team</b> column not equal to “A” <em>or</em> “B.”
<h2><span class="orange">How to Count Number of Occurrences in Excel</span></h2>
You can use the <b>=UNIQUE()</b> and <b>=COUNTIF()</b> functions to count the number of occurrences of different values in a column in Excel.
The following step-by-step example shows how to do so.
<h3>Step 1: Enter the Data</h3>
First, let’s enter the names for a list of basketball teams in column A:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/occurrences1.jpg"442">
<h3>Step 2: Find the Unique Values in the Column</h3>
Next, let’s use the <b>=UNIQUE()</b> function to create a list of every unique team name in column A:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/occurrences2.jpg"491">
This function creates an array of unique values by default.
<h3>Step 3: Count the Occurrence of Each Unique Value</h3>
Next, let’s use the following formula to count the number of occurrences of each unique team name:
<b>=COUNTIF($A$2:$A$15, D2)
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/occurrences3.jpg"526">
Note that we simply copy and pasted the formula in cell <b>E2</b> to each of the remaining cells in column E.
From the output we can see:
The team name ‘Hornets’ occurs <b>2</b> times in column A.
The team name ‘Mavs’ occurs <b>3</b> times in column A.
The team name ‘Spurs’ occurs <b>3</b> times in column A.
The team name ‘Rockets’ occurs <b>1</b> time in column A.
And so on.
<h2><span class="orange">How to Count Rows with Value in Excel (3 Examples)</span></h2>
You can use the following methods to count rows with a particular value in Excel:
<b>Method 1: Count Rows with Any Value</b>
<b>=COUNTIF(B2:B11, "&lt;>")</b>
<b>Method 2: Count Rows with No Value</b>
<b>=COUNTBLANK(B2:B11)</b>
<b>Method 3: Count Rows with Specific Value</b>
<b>=COUNTBLANK(B2:B11, "50")</b>
The following examples show how to use each method with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/count1.jpg"478">
<h2>Example 1: Count Rows with Any Value</h2>
We can use the following formula to count the number of rows with <em>any</em> value in column B:
<b>=COUNTIF(B2:B11, "&lt;>")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/count2.jpg"479">
We can see that there are <b>7</b> rows with any value in the Points column.
<h2>Example 2: Count Rows with No Value</h2>
We can use the following formula to count the number of rows with <i>no </i>value in column B:
<b>=COUNTBLANK(B2:B11)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/count3.jpg"483">
We can see that there are <b>3</b> rows with no value in the Points column.
<h2>Example 3: Count Rows with Specific Value</h2>
We can use the following formula to count the number of rows with a value of “8” in column B:
<b>=COUNTIF(B2:B11, "8")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/08/count4.jpg"471">
We can see that there are <b>3</b> rows with a value of “8” in the Points column.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Count Specific Words in Excel 
 How to Count Unique Values by Group in Excel 
 How to Use COUNTIF with Multiple Ranges in Excel 
<h2><span class="orange">How to Count Specific Words in Excel (With Examples)</span></h2>
You can use the following formulas to count the occurrence of specific words in Excel:
<b>Method 1: Count Occurrence of Specific Word in Cell</b>
<b>=(LEN(A2)-LEN(SUBSTITUTE(A2,"word","")))/LEN("word")
</b>
This particular formula counts how many times “word” occurs in cell <b>A2</b>.
<b>Method 2: Count Occurrence of Specific Word in Range</b>
<b>=SUMPRODUCT((LEN(A2:A8)-LEN(SUBSTITUTE(A2:A8,"word","")))/LEN("word"))
</b>
This particular formula counts how many times “word” occurs in the cell range <b>A2:A8</b>.
The following examples show how to use each formula in practice with the following column of text in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countspecific0.jpg"505">
<h2>Example 1: Count Occurrence of Specific Word in Cell</h2>
We can type the following formula into cell B2 to count how many times the word “Three” occurs in cell A2:
<b>=(LEN(A2)-LEN(SUBSTITUTE(A2,"Three","")))/LEN("Three")
</b>
We can then drag and fill this formula down to each remaining cell in column B:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countspecific1.jpg"565">
Column B shows how many times the word “Three” appeared in the corresponding cell in column A.
<b>Note</b>: This formula is case-sensitive. For example, the word “three” will not be counted.
<h2>Example 2: Count Occurrence of Specific Word in Range</h2>
We can type the following formula into cell B10 to count how many times the word “Three” occurs in the cell range A2:A8:
<b>=SUMPRODUCT((LEN(A2:A8)-LEN(SUBSTITUTE(A2:A8,"Three","")))/LEN("Three"))</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countspecific2.jpg"595">
We can see that the word “Three” occurs a total of <b>6</b> times in the cell range <b>A2:A8</b>.
To create a case-insensitive formula, we can use the <b>UPPER</b> function in Excel as follows:
<b>=SUMPRODUCT((LEN(A2:A8)-LEN(SUBSTITUTE(UPPER(A2:A8),UPPER("Three"),"")))/LEN("Three"))</b>
We can type this formula into cell B10 to count how many times “Three” (regardless of case) occurs in the cell range A2:A8.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countspecific3.jpg"652">
We can see that the word “Three” (regardless of case) occurs a total of <b>8</b> times in the cell range <b>A2:A8</b>.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: How to Count If Cells Contain Text 
 Excel: How to Use COUNTIF with Multiple Ranges 
 Excel: How to Count Unique Values Based on Multiple Criteria 
<h2><span class="orange">How to Count Unique Values by Group in Excel</span></h2>
You can use the following formula to count the number of unique values by group in Excel:
<b>=SUMPRODUCT(($A$2:$A$13=A2)/COUNTIFS($B$2:$B$13, $B$2:$B$13, $A$2:$A$13, $A$2:$A$13))
</b>
This formula assumes that the group names are in the range <b>A2:A13</b> and the values are in the range <b>B2:B13</b>.
The following example shows how to use this formula in practice.
<h2>Example: Count Unique Values by Group in Excel</h2>
Suppose we have the following dataset that shows the points scored by basketball players on various teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countunique1.jpg"469">
Now suppose we’d like to count the number of unique points values, grouped by team.
To do so, we can use the <b>=UNIQUE()</b> function to first create a list of the unique teams. We’ll type the following formula into cell D2:
<b>=UNIQUE(A2:A13)</b>
Once we press enter, a list of unique team names will be displayed:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countunique2.jpg"486">
Now we can type the following formula into cell E2 to count the number of unique points values for the Lakers:
<b>=SUMPRODUCT(($A$2:$A$13=D2)/COUNTIFS($B$2:$B$13, $B$2:$B$13, $A$2:$A$13, $A$2:$A$13))</b>
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countunique3.jpg"528">
We’ll then drag this formula down to the remaining cells in column E:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/07/countunique4.jpg"502">
That’s it!
Column D displays each of the unique teams and column E displays the count of unique points values for each team.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 Excel: How to Count If Cells Contain Text 
 Excel: How to Use COUNTIF with Multiple Ranges 
 Excel: How to Count Unique Values Based on Multiple Criteria 
<h2><span class="orange">Excel: How to Count Unique Values Based on Multiple Criteria</span></h2>
You can use the following basic formula in Excel to count unique values based on multiple criteria:
<b>=SUM(--(LEN(UNIQUE(FILTER(A:A,(Criteria1)*(Criteria2)*(Criteria3),"")))>0))</b>
This particular formula counts the number of unique values in column A based on three criteria being met.
The following example shows how to use this formula in practice.
<h3>Example: Count Unique Values Based on Multiple Criteria in Excel</h3>
Suppose we have the following dataset in Excel that shows the conference and points scored for various basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/uniquecriteria1.jpg"466">
Now suppose we’d like to count the number of unique player names who meet the following criteria:
The player is in the <b>West</b> conference.
The player has <b>greater than 20</b> points.
We can use the following formula to count the number of unique player names who meet this criteria:
<b>=SUM(--(LEN(UNIQUE(FILTER(A2:A14,(B2:B14="West")*(C2:C14>20),"")))>0))
</b>
We can type this formula into cell E2 of our spreadsheet:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/uniquecriteria2.jpg"668" data-wp-editing="1">
From the output we can see there are <b>3</b> unique player names that are in the West conference and have more than 20 points.
We can verify this is correct by manually identifying each player who meets both criteria:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/uniquecriteria3.jpg"483">
Out of the four players who meet both criteria, there are three unique player names:
Greg
Sean
Mike
Note that in this example we performed a count unique using two criteria, but we can use similar syntax to use as many criteria as we’d like.
<h2><span class="orange">Excel: How to Use COUNTA with Criteria</span></h2>
You can use the <b>COUNTA</b> function in Excel to count the number of cells in a range that are not empty.
However, sometimes may want to use the <b>COUNTA</b> function to count cells that are not empty <em>and</em> meet some additional criteria.
You can use the following basic syntax to do so:
<b>=COUNTA(B2:B12)-COUNTIF(B2:B12,"0")
</b>
This particular formula counts all cells in the range <b>B2:B12</b> that are not blank <em>and</em> are not equal to 0.
The following example shows how to use this syntax in practice.
<h2>Example: Using COUNTA with Criteria in Excel</h2>
Suppose we have the following dataset that shows the points scored by basketball players on various teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/cc1.jpg"413">
We can use the following <b>COUNTA</b> function with the <b>COUNTIF</b> function to count the number of cells in the Points column that are not empty <em>and</em> not equal to 0:
<b>=COUNTA(B2:B12)-COUNTIF(B2:B12,"0")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/11/cc2.jpg"568">
From the output we can see that there are 8 cells in the Points column that are not empty and not equal to zero.
Here’s what this formula actually did under the hood:
<b>COUNTA</b> counted <b>10</b> blank cells.
<b>COUNTIF</b> counted <b>2</b> cells equal to zero.
Thus, <b>COUNTA</b> – <b>COUNTIF</b> produced <b>10</b> – <b>2</b> = <b>8</b>.
Feel free to replace the value in the <b>COUNTIF</b> function to exclude whichever values you’d like from the <b>COUNTA</b> function.
<h2>Additional Resources</h2>
The following tutorials explain how to perform other common tasks in Excel:
 How to Count Filtered Rows in Excel 
 How to Count Duplicates in Excel 
 How to Count by Group in Excel 
<h2><span class="orange">Excel: How to Count If Cells Contain Text</span></h2>
You can use the following methods to count cells in Excel that contain specific text:
<b>Method 1: Count Cells that Contain One Specific Text</b>
<b>=COUNTIF(A2:A13, "*text*")
</b>
This formula will count the number of cells in the range <b>A2:A13</b> that contain “text” in the cell.
<b>Method 2: Count Cells that Contain One of Several Text</b>
<b>=SUM(COUNTIF(A2:A13,{"*text1","*text2*","*text3*"}))
</b>
This formula will count the number of cells in the range <b>A2:A13</b> that contain “text1”, “text2”, or “text3” in the cell.
The following examples show how to use each method in practice with the following dataset in Excel:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/contain111.jpg"392">
<h3>Example 1: Count Cells that Contain One Specific Text</h3>
We can use the following formula to count the values in the <b>Team </b>column that contain “avs” in the name:
<b>=COUNTIF(A2:A13, "*avs*")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/contain112.jpg"463">
We can see that a total of <b>4</b> cells in the <b>Team</b> column contain “avs” in the name.
<h3>Example 2: Count Cells that Contain One of Several Text</h3>
We can use the following formula to count the number of cells in the <b>Team</b> column that contain “avs”, “urs”, or “ockets” in the name:
<b>=SUM(COUNTIF(A2:A13,{"*avs","*urs*","*ockets*"}))</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/contain113.jpg"598">
We can see that a total of <b>7</b> cells in the <b>Team</b> column contain “avs”, “urs”, or “ockets” in the name.
<h2><span class="orange">Excel: How to Use COUNTIF From Another Sheet</span></h2>
You can use the following basic syntax to use a <b>COUNTIF</b> from another sheet in Excel:
<b>=COUNTIF(Sheet1!A1:B20, ">30")
</b>
The following examples show how to use this syntax in practice.
<h3>Example 1: COUNTIF From Another Sheet</h3>
Suppose we have the following sheet named <b>Sheet1</b> in Excel that contains some data about basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/co1.jpg"453">
Now suppose we’d like to switch to <b>Sheet2</b> and count the total players who have more than 30 points.
We can use the following syntax to do so:
<b>=COUNTIF(Sheet1!B2:B9, ">30")</b>
Here’s how to apply this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/co2.jpg">
We can see that <b>2</b> players have more than 30 points.
<h3>Example 2: COUNTIFS From Another Sheet</h3>
Suppose we have the following sheet that contains some data about basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/co3.jpg"476">
Now suppose we’d like to switch to <b>Sheet2</b> and count the total players who are on team A <em>and</em> have more than 30 points.
We can use a <b>COUNTIFS</b> function to do so since we’re using multiple criteria when counting:
<b>=COUNTIFS(Sheet1!A2:A9, "A", Sheet1!B2:B9, ">30")</b>
Here’s how to apply this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/01/co4.jpg"612">
We can see that <b>3</b> players belong to team A <em>and</em> have more than 30 points.
<h2><span class="orange">Excel: COUNTIF Greater Than But Less Than Some Number</span></h2>
You can use the following formula to count the number of cells in Excel that are greater than but less than some number:
<b>=COUNTIFS(B:B,">15",B:B,"&lt;25")
</b>
This particular formula counts the number of cells in column B where the value is greater than 15 but less than 25.
The following example shows how to use this formula in practice.
<h3>Example: COUNTIF Greater Than But Less Than</h3>
Suppose we have the following dataset in Excel that shows the number of points scored by basketball players on various teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/countif11.jpg"475">
We can use the following formula to count the number of cells in the column that have a value greater than 15 but less than 25:
<b>=COUNTIFS(B2:B11,">15",B2:B11,"&lt;25")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/countif12.jpg"544">
We can see that a total of <b>3</b> cells in the <b>Points </b>column have a value greater than 15 but less than 25.
We can verify this is correct by manually identifying each of these cells in the data:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/03/countif13.jpg"507">
<b>Note</b>: You can find the complete documentation for the <b>COUNTIFS</b> function in Excel  here .
<h2><span class="orange">Excel: COUNTIF Less Than Date</span></h2>
You can use the following formula to count the number of cells in Excel that are less than a particular date:
<b>=COUNTIF(A2:A11, "&lt;"&D2)
</b>
This particular formula counts the number of cells in column A where the date is less than the date in cell D2.
The following example shows how to use this formula in practice.
<h3>Example: COUNTIF Less Than Date in Excel</h3>
Suppose we have the following dataset in Excel that shows the number of sales made by a company on various days:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifless1.jpg"459">
Suppose we would like to count how many days are before 4/1/2022.
We can specify this date value in cell D2 and then type the following formula in cell E2:
<b>=COUNTIF(A2:A11, "&lt;"&D2)</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifless2.jpg">
We can see that there are a total of <b>6</b> days in column A that occur before 4/1/2022.
Note that if we change the date in cell D2, the value in cell E2 will automatically updated.
For example, suppose we change the date to 3/1/2022:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifless3.jpg"508">
We can see that there are a total of <b>4</b> days in column A that occur before 3/1/2022.
<h2><span class="orange">Excel: Use COUNTIF with Multiple Criteria in Same Column</span></h2>
You can use the following syntax to perform a COUNTIF function with multiple criteria in the same column in Excel:
<b>=SUMPRODUCT(COUNTIF(A2:A16,{"word1","word","word3"}))
</b>
This particular formula will return the count of cells in the range<b> A2:A16</b> where the value is equal to “word1”, “word2”, or “word3.”
The following example shows how to use this syntax in practice.
<h3>Example: Use COUNTIF with Multiple Criteria in Same Column</h3>
Suppose we have the following dataset in Excel that contains the names of various basketball teams:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsame1.jpg"401">
We can use the following formula to count the number of cells in the range A2:A16 that are equal to “Mavs”, “Celtics”, or “Spurs”:
<b>=SUMPRODUCT(COUNTIF(A2:A16,{"Mavs","Celtics","Spurs"}))</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsame2.jpg"653">
We can see that a total of 9 cells were equal to one of these three values.
We can manually count each of these 9 cells to verify that this is correct:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsame3.jpg"412">
There are indeed 9 cells that are equal to “Mavs”, “Celtics”, or “Spurs.”
<h2><span class="orange">Excel: How to Use COUNTIF with Multiple Ranges</span></h2>
The <b>COUNTIFS()</b> function in Excel can be used to count the number of rows in a spreadsheet that meet multiple criteria.
This function uses the following syntax:
<b>COUNTIFS(criteria_range1, criterion1, criteria_range2, criterion2, …)</b>
where:
<b>criteria_range1</b>: The first range of cells to look in.
<b>criterion1</b>: The criterion to look for in the first range of cells.
The following example shows how to use this function in practice.
<h2>Example: Using COUNTIFS in Excel</h2>
Suppose we have the following dataset that shows the team and points scored for seven different basketball players:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsexcel1.jpg"459">
We can use the following <b>COUNTIFS()</b> formula to count the number of players who play for the Lakers <em>and</em> who score 20 or more points per game:
<b>=COUNTIFS(B2:B8, "Lakers", C2:C8, ">20")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsexcel2.jpg"523">
The total number of players that meet these two criteria is <b>2</b>.
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/05/countifsexcel3.jpg">
Specifically we can see that player “D” and “E” meet these two criteria.
Note that in this example we only used the <b>COUNTIFS()</b> function with two cell ranges, but we can use this function with any number of cell ranges that we’d like.
<h2><span class="orange">COUNTIF vs. COUNTIFS in Excel: What’s the Difference?</span></h2>
In Excel, the <b>COUNTIF</b> and <b>COUNTIFS</b> functions both count the number of cells in a range that meet a certain condition, but they use slightly different behaviors:
The <b>COUNTIF</b> function counts the number of cells in a range that meet <b>one condition</b>.
The <b>COUNTIFS</b> function counts the number of cells in a range that meet <b>several conditions</b>.
The following examples show how to use each function in practice.
<h3>Example 1: Using COUNTIF</h3>
We can use the following <b>COUNTIF</b> formula to count the number of rows where the value in the range A2:A16 is equal to “Mavs”:
<b>=COUNTIF(A2:A16, "Mavs")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countifvs1.jpg"517">
We can see that a total of <b>5</b> cells in the range A2:A16 meet this criteria.
<h3>Example 2: Using COUNTIFS</h3>
We can use the following <b>COUNTIFS</b> formula to count the number of rows where the value in the range A2:A16 is equal to “Mavs” and the value in the range B2:B16 is equal to “Guard”:
<b>=COUNTIFS(A2:A16, "Mavs", B2:B16, "Guard")
</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countifvs2.jpg"601">
We can see that a total of <b>5</b> rows in the dataset contain “Mavs” in column A and “Guard” in column B.
Note that we can use as many conditions as we’d like within the <b>COUNTIFS</b> function.
For example, we can use the following formula to find the rows that meet three different conditions:
<b>=COUNTIFS(A2:A16, "Mavs", B2:B16, "Guard", C2:C16, ">20")</b>
The following screenshot shows how to use this formula in practice:
<img class="lazy" data-src="https://www.statology.org/wp-content/uploads/2022/02/countifvs3.jpg"655">
We can see that a total of <b>1</b> row in the dataset contains “Mavs” in column A, “Guard” in column B, and a value greater than 20 in column C.

<script src='https://williamkpchan.github.io/LibDocs/readbook.js'></script>
<script>
var lazyLoadInstance = new LazyLoad({
    elements_selector: ".lazy"
    // ... more custom settings?
});
</script>
