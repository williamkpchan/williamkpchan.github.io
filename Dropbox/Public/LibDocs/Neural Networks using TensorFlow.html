
<base target="_blank">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<style type="text/css">
body {
background-color: #000000;
 color: #109030;
 margin: 100;
}
a { text-decoration: none;
	color: #28B8B8;}
a:visited {	color: #389898;}
A:hover {	color: yellow;}
A:focus {	color: red;}
code { color: pink; background-color: #302030}
pre { color: gray; background-color: #001010}
#newtype { color: pink}
#redpink { color: #cc0099}
#redword { color: red}
#yellowword { color: yellow}
#greenword { color: lightgreen}
#limeword { color: #00ff00}
#orangeword { color: orange}
#cyanword { color: cyan}
#whiteword { color: white}
#grayword { color: gray}
#brownword { color: #ff8000}
#yellowgreen { color: #bfff00}
#palered { color: #ffcccc}
#blueword { color: dodgerblue}
#purpleword { color: darkorchid}
#goldword { color: GoldenRod}
#silverword { color: silver}
#blackword { color: black}
.left {
    position: absolute;
    left: 100px;
    color: GoldenRod;
    border: 1px solid GoldenRod;
    padding: 2px;
    font-size: 60%;
}
.bord {
    color: redpink;
    border: 1px solid GoldenRod;
    padding: 1px;
    font-size: 90%;
}
.highlight { 
    color: white;
    background-color: #002030
  }
</STYLE>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script>
$(document).ready(function(){
    $('.left').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
</head>
<body>
<FONT size=3>

<h1>An Introduction to Implementing Neural Networks using TensorFlow</h1>
<h2>Introduction</h2>
<h2>Table of Contents</h2>
<ul>
<li>When to apply neural nets?</li>
<li>General way to solve problems with Neural Networks</li>
<li>Understanding Image data and popular libraries to solve it</li>
<li>What is TensorFlow?</li>
<li>A typical &#8220;flow&#8221; of TensorFlow</li>
<li>Implementing MLP in TensorFlow</li>
<li>Limitations of TensorFlow</li>
<li>TensorFlow vs. other libraries</li>
<li>Where to go from here?</li>
</ul>
<p>&nbsp;</p>
<h2>When to apply Neural Networks ?</h2>
<p style="text-align: justify;">Neural Networks have been in the spotlight for quite some time now. For a more detailed explanation on neural network and deep learning <a href="https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/" target="_blank" rel="nofollow">read here</a>.

<ul>
<li style="text-align: justify;"><strong>Firstly, neural networks require clear and informative data (and mostly big data) to train.</strong> Try to imagine Neural Networks as a child. It first observes how its parent walks. Then it tries to walk on its own, and with its every step, the child learns how to perform a particular task. It may fall a few times, but after few unsuccessful attempts, it learns how to walk. If you don&#8217;t let it walk, it might not ever learn how to walk. The more exposure you can provide to the child, the better it is.</li>
<li style="text-align: justify;"><strong>It is prudent to use Neural Networks for complex problems such as image processing. </strong>Neural nets belong to a class of algorithms called representation learning algorithms. These algorithms break down complex problems into simpler form so that they become understandable (or &#8220;representable&#8221;). Think of it as chewing food before you gulp. This would be harder for traditional (non-representation learning) algorithms.</li>
<li style="text-align: justify;"><strong>When you have appropriate type of neural network to solve the problem. </strong>Each problem has its own twists. So the data decides the way you solve the problem. For example, if the problem is of sequence generation, recurrent neural networks are more suitable. Whereas, if it is image related problem, you would probably be better of taking convolutional neural networks for a change.</li>
<li style="text-align: justify;"><strong>Last but not the least,</strong> <strong>hardware</strong> <strong>requirements are essential for running a deep neural network model. </strong>Neural nets were &#8220;discovered&#8221; long ago, but they are shining in the recent years for the main reason that computational resources are better and more powerful. If you want to solve a real life problem with these networks, get ready to buy some high-end hardware!</li>
</ul>
<p>&nbsp;</p>
<h2>General way to solve problems with Neural Networks</h2>
<p style="text-align: justify;">
TO DO list of how to approach a Neural Network problem.</p>
<ul>
<li style="text-align: justify;">Check if it is a problem where Neural Network gives you uplift over traditional algorithms (refer to the checklist in the section above)</li>
<li style="text-align: justify;">Do a survey of which Neural Network architecture is most suitable for the required problem</li>
<li style="text-align: justify;">Define Neural Network architecture through which ever language / library you choose.</li>
<li style="text-align: justify;">Convert data to right format and divide it in batches</li>
<li style="text-align: justify;">Pre-process the data according to your needs</li>
<li style="text-align: justify;">Augment Data to increase size and make better trained models</li>
<li style="text-align: justify;">Feed batches to Neural Network</li>
<li style="text-align: justify;">Train and monitor changes in training and validation data sets</li>
<li style="text-align: justify;">Test your model, and save it for future use</li>
</ul>
<p>For this article, I will be focusing on image data. So let us understand that first before we delve into TensorFlow.</p>
<p>&nbsp;</p>
<h2>Understanding Image data and popular libraries to solve it</h2>
<p style="text-align: justify;">Images are mostly arranged as 3-D arrays, with the dimensions referring to height, width and color channel. For example, if you take a screenshot of your PC at this moment, it would be first convert into a 3-D array and then compress it  &#8216;.jpeg&#8217; or &#8216;.png&#8217; file formats.</p>
<p style="text-align: justify;">While these images are pretty easy to understand to a human, a computer has a hard time to understand them. This phenomenon is called &#8220;Semantic gap&#8221;. Our brain can look at the image and understand the complete picture in a few seconds. On the other hand, computer sees image as just an array of numbers. So the problem is how to we explain this image to the machine?</p>
<p style="text-align: justify;">In early days, people tried to break down the image into &#8220;understandable&#8221; format for the machine like a &#8220;template&#8221;. For example, a face always has a specific structure which is somewhat preserved in every human, such as the position of eyes, nose or the shape of our face. But this method would be tedious, because when the number of objects to recognise would increase, the &#8220;templates&#8221; would not hold.</p>
<p style="text-align: justify;">Fast forward to 2012, a deep neural network architecture won the ImageNet challenge, a prestigious challenge to recognise objects from natural scenes. It continued to reign its sovereignty in all the upcoming ImageNet challenges, thus proving the usefulness to solve image problems.</p>
<p style="text-align: justify;">So which library / language do people normally use to solve image recognition problems? One <a href="https://www.analyticsvidhya.com/blog/2016/08/deep-learning-path/" target="_blank" rel="nofollow">recent survey</a> I did that most of the popular deep learning libraries have interface for Python, followed by Lua, Java and Matlab. The most popular libraries, to name a few, are:</p>
<ul>
<li style="text-align: justify;"><a href="http://caffe.berkeleyvision.org/" target="_blank" rel="nofollow">Caffe</a></li>
<li><a href="http://deeplearning4j.org/" target="_blank" rel="nofollow">DeepLearning4j</a></li>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="nofollow">TensorFlow</a></li>
<li><a href="http://www.deeplearning.net/software/theano" target="_blank" rel="nofollow">Theano</a></li>
<li><a href="http://torch.ch/" target="_blank" rel="nofollow">Torch</a></li>
</ul>
<p>Now, that  you understand how an image is stored and which are the common libraries used, let us look at what TensorFlow has to offer.</p>
<p>&nbsp;</p>
<h2>What is TensorFlow?</h2>
<p>Lets start with the official definition,</p>
<blockquote>
<p style="text-align: justify;">&#8220;TensorFlow is an open source software library for numerical computation using dataflow graphs. Nodes in the graph represents mathematical operations, while graph edges represent multi-dimensional data arrays (aka tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.&#8221;</p>
</blockquote>
<p><img src="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/tensors_flowing.gif">
<img ="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/tensors_flowing-3.gif"></p>
<p style="text-align: justify;">If that sounds a bit scary &#8211; don&#8217;t worry. Here is my simple definition &#8211; look at TensorFlow as nothing but numpy with a twist. If you have worked on numpy before, understanding TensorFlow will be a piece of cake! A major difference between numpy and TensorFlow is that TensorFlow follows a lazy programming paradigm. It first builds a graph of all the operation to be done, and then when a &#8220;session&#8221; is called, it &#8220;runs&#8221; the graph. It&#8217;s built to be scalable, by changing internal data representation to tensors (aka multi-dimensional arrays). Building a computational graph can be considered as the main ingredient of TensorFlow. To know more about mathematical constitution of a computational graph, read <a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="nofollow">this article</a>.</p>
<p style="text-align: justify;">It&#8217;s easy to classify TensorFlow as a neural network library, but it&#8217;s not just that. Yes, it was designed to be a powerful neural network library. But it has the power to do much more than that. You can build other machine learning algorithms on it such as decision trees or k-Nearest Neighbors. You can literally do everything you normally would do in numpy! It&#8217;s aptly called &#8220;numpy on steroids&#8221;</p>
<p style="text-align: justify;">The advantages of using TensorFlow are:</p>
<ul>
<li style="text-align: justify;"><strong>It has an intuitive construct</strong>, because as the name suggests it has <em>&#8220;flow of tensors&#8221;. </em>You can easily visualize each and every part of the graph.</li>
<li style="text-align: justify;"><strong>Easily train on cpu/gpu for distributed computing</strong></li>
<li style="text-align: justify;"><strong>Platform flexibility</strong>. You can run the models wherever you want, whether it is on mobile, server or PC.</li>
</ul>
<p>&nbsp;</p>
<h2>A typical &#8220;flow&#8221; of TensorFlow</h2>
<p style="text-align: justify;">Every library has its own &#8220;implementation details&#8221;, i.e. a way to write which follows its coding paradigm. For example, when implementing scikit-learn, you first create object of the desired algorithm, then build a model on train and get predictions on test set, something like this:</p>
<pre><span class="n"># define hyperparamters of ML algorithm
clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">100.</span><span class="p">)
# train 
</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>X<span class="p">,</span> <span class="n">y</span><span class="p">)
# test 
</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></pre>
<p style="text-align: justify;">As I said earlier, TensorFlow follows a lazy approach. The usual workflow of running a program in TensorFlow is as follows:</p>
<ul>
<li style="text-align: justify;"><strong>Build a computational graph, </strong>this can be any mathematical operation TensorFlow supports.</li>
<li style="text-align: justify;"><strong>Initialize variables, </strong>to compile the variables defined previously<strong><br />
</strong></li>
<li style="text-align: justify;"><strong>Create session, </strong>this is where the magic starts!<strong><br />
</strong></li>
<li style="text-align: justify;"><strong>Run graph in session, </strong>the compiled graph is passed to the session, which starts its execution. <strong><br />
</strong></li>
<li style="text-align: justify;"><strong>Close session, </strong>shutdown the session.</li>
</ul>
<p>&nbsp;</p>
<p>Few terminologies used in TensoFlow;</p>
<ul>
<li>
<pre>placeholder: A way to feed data into the graphs</pre>
</li>
<li>
<pre>feed_dict: A dictionary to pass numeric values to computational graph</pre>
</li>
</ul>
<p>Lets write a small program to add two numbers!</p>
<pre># import tensorflow
import tensorflow as tf

# build computational graph
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int16</span><span class="p">)
</span>
<span class="n">addition</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)

# initialize variables
init = tf.initialize_all_variables()

# create session and run the graph
</span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:
    sess.run(init)</span>
    <span class="k">print</span> <span class="s">"Addition: </span><span class="si">%i</span><span class="s">"</span> <span class="o">%</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">addition</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="mi">3</span><span class="p">})

</span># close session
sess.close()</pre>
<p>&nbsp;</p>
<h2>Implementing Neural Network in TensorFlow</h2>
<p style="text-align: justify;">Let us remember what we learned about neural networks first.</p>
<p style="text-align: justify;">We could have used a different neural network architecture to solve this problem, but for the sake of simplicity, we settle on feed forward multilayer perceptron with an in depth implementation.</p>
<p style="text-align: justify;">So, a typical implementation of Neural Network would be as follows:</p>
<ul style="text-align: justify;">
<li>Define Neural Network architecture to be compiled</li>
<li>Transferring data to your models</li>
<li>Under the hood, the data is first divided into batches, so that it can be ingested. The batches are first preprocessed, augmented and then fed into Neural Network for training</li>
<li>The model then gets trained incrementally</li>
<li>Display the cost for a specific number of timesteps</li>
<li>After training save the model for future use</li>
<li>Test the model on a new data and check how it performs</li>
</ul>
<p>Here we solve our deep learning practice problem &#8211; <a href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/" target="_blank" rel="nofollow">Identify the Digits</a>.  Let&#8217;s for a moment take a look at our problem statement.</p>
<p style="text-align: justify;">Our problem is an image recognition, to identify digits from a given 28 x 28 image. We have a subset of images for training and the rest for testing our model. So first, download the train and test files. The dataset contains a zipped file of all the images in the dataset and both the train.csv and test.csv have the name of corresponding train and test images. Any additional features are not provided in the datasets, just the raw images are provided in &#8216;.png&#8217; format.</p>
<p style="text-align: justify;">As you know we will use TensorFlow to make a neural network model. So you should first install TensorFlow in your system. Refer the<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md" target="_blank" rel="nofollow"> official installation guide</a> for installation, as per your system specifications.</p>
<p style="text-align: justify;">We will follow the template as described above</p>
<ul>
<li>Let&#8217;s import all the required modules</li>
</ul>
<pre>%pylab inline

import os
import numpy as np
import pandas as pd
from scipy.misc import imread
from sklearn.metrics import accuracy_score
import tensorflow as tf</pre>
<ul>
<li>Let&#8217;s set a seed value, so that we can control our models randomness</li>
</ul>
<pre># To stop potential randomness
seed = 128
rng = np.random.RandomState(seed)</pre>
<ul>
<li>The first step is to set directory paths, for safekeeping!</li>
</ul>
<pre>root_dir = os.path.abspath('../..')
data_dir = os.path.join(root_dir, 'data')
sub_dir = os.path.join(root_dir, 'sub')

# check for existence
os.path.exists(root_dir)
os.path.exists(data_dir)
os.path.exists(sub_dir)</pre>
<ul>
<li>Now let us read our datasets. These are in .csv formats, and have a filename along with the appropriate labels</li>
</ul>
<pre>train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))
test = pd.read_csv(os.path.join(data_dir, 'Test.csv'))

sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))

train.head()</pre>
<table class="dataframe" border="1">
<thead>
<tr>
<th></th>
<th>filename</th>
<th>label</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>0.png</td>
<td>4</td>
</tr>
<tr>
<th>1</th>
<td>1.png</td>
<td>9</td>
</tr>
<tr>
<th>2</th>
<td>2.png</td>
<td>1</td>
</tr>
<tr>
<th>3</th>
<td>3.png</td>
<td>7</td>
</tr>
<tr>
<th>4</th>
<td>4.png</td>
<td>3</td>
</tr>
</tbody>
</table>
<ul>
<li>Let us see what our data looks like! We read our image and display it.</li>
</ul>
<pre>img_name = rng.choice(train.filename)
filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)

img = imread(filepath, flatten=True)

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()</pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3.png"><img ="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3.png" alt="3" width="353" height="351" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3.png 353w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3-150x150.png 150w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3-300x298.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3-83x83.png 83w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3-200x200.png 200w" sizes="(max-width: 353px) 100vw, 353px" /></a></p>
<p>The above image is represented as numpy array, as seen below</p>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one.png"><img ="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one-1024x353.png" alt="one" width="1024" height="353" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one-1024x353.png 1024w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one-300x103.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one-768x264.png 768w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one-850x293.png 850w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one.png 1115w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>&nbsp;</p>
<ul>
<li>For easier data manipulation, let&#8217;s store all our images as numpy arrays</li>
</ul>
<pre>temp = []
for img_name in train.filename:
    image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)
    img = imread(image_path, flatten=True)
    img = img.astype('float32')
    temp.append(img)
    
train_x = np.stack(temp)

temp = []
for img_name in test.filename:
    image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)
    img = imread(image_path, flatten=True)
    img = img.astype('float32')
    temp.append(img)
    
test_x = np.stack(temp)</pre>
<ul>
<li>As this is a typical ML problem, to test the proper functioning of our model we create a validation set. Let&#8217;s take a split size of 70:30 for train set vs validation set</li>
</ul>
<pre>split_size = int(train_x.shape[0]*0.7)

train_x, val_x = train_x[:split_size], train_x[split_size:]
train_y, val_y = train.label.ix[:split_size], train.label.ix[split_size:]</pre>
<ul>
<li>Now we define some helper functions, which we use later on, in our programs</li>
</ul>
<pre>def dense_to_one_hot(labels_dense, num_classes=10):
    """Convert class labels from scalars to one-hot vectors"""
    num_labels = labels_dense.shape[0]
    index_offset = numpy.arange(num_labels) * num_classes
    labels_one_hot = numpy.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
    
    return labels_one_hot

def preproc(unclean_batch_x):
    """Convert values to range 0-1"""
    temp_batch = unclean_batch_x / unclean_batch_x.max()
    
    return temp_batch

def batch_creator(batch_size, dataset_length, dataset_name):
    """Create batch with random samples and return appropriate format"""
    batch_mask = rng.choice(dataset_length, batch_size)
    
    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, 784)
    batch_x = preproc(batch_x)
    
    if dataset_name == 'train':
        batch_y = eval(dataset_name).ix[batch_mask, 'label'].values
        batch_y = dense_to_one_hot(batch_y)
        
    return batch_x, batch_y</pre>
<ul>
<li>Now comes the main part! Let us define our neural network architecture. We define a neural network with 3 layers;  input, hidden and output. The number of neurons in input and output are fixed, as the input is our 28 x 28 image and the output is a 10 x 1 vector representing the class. We take 500 neurons in the hidden layer. This number can vary according to your need. We also assign values to remaining variables. Read the <a href="https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/">article on fundamentals of neural network</a> to know more in depth of how it works.</li>
</ul>
<pre>### set all variables

# number of neurons in each layer
input_num_units = 28*28
hidden_num_units = 500
output_num_units = 10

# define placeholders
x = tf.placeholder(tf.float32, [None, input_num_units])
y = tf.placeholder(tf.float32, [None, output_num_units])

# set remaining variables
epochs = 5
batch_size = 128
learning_rate = 0.01

### define weights and biases of the neural network (refer <a href="https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/">this article</a> if you don't understand the terminologies)

weights = {
    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)),
    'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))
}

biases = {
    'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)),
    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))
}</pre>
<ul>
<li>Now create our neural networks computational graph</li>
</ul>
<pre>hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])
hidden_layer = tf.nn.relu(hidden_layer)

output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']</pre>
<ul>
<li>Also, we need to define cost of our neural network</li>
</ul>
<pre>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, y))</pre>
<ul>
<li>And set the optimizer, i.e. our backpropogation algorithm. Here we use <a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="nofollow">Adam</a>, which is an efficient variant of Gradient Descent algorithm. There are a number of other optimizers available in tensorflow (refer <a href="https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#optimizers" target="_blank" rel="nofollow">here</a>)</li>
</ul>
<pre>optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</pre>
<ul>
<li>After defining our neural network architecture, let&#8217;s initialize all the variables</li>
</ul>
<pre>init = tf.initialize_all_variables()</pre>
<ul>
<li>Now let us create a session, and run our neural network in the session. We also validate our models accuracy on validation set that we created</li>
</ul>
<pre>with tf.Session() as sess:
    # create initialized variables
    sess.run(init)
    
    ### for each epoch, do:
    ###   for each batch, do:
    ###     create pre-processed batch
    ###     run optimizer by feeding batch
    ###     find cost and reiterate to minimize
    
    for epoch in range(epochs):
        avg_cost = 0
        total_batch = int(train.shape[0]/batch_size)
        for i in range(total_batch):
            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')
            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})
            
            avg_cost += c / total_batch
            
        print "Epoch:", (epoch+1), "cost =", "{:.5f}".format(avg_cost)
    
    print "\nTraining complete!"
    
    
    # find predictions on val set
    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(pred_temp, "float"))
    print "Validation Accuracy:", accuracy.eval({x: val_x.reshape(-1, 784), y: dense_to_one_hot(val_y.values)})
    
    predict = tf.argmax(output_layer, 1)
    pred = predict.eval({x: test_x.reshape(-1, 784)})</pre>
<p>This will be the output of the above code</p>
<pre>Epoch: 1 cost = 8.93566
Epoch: 2 cost = 1.82103
Epoch: 3 cost = 0.98648
Epoch: 4 cost = 0.57141
Epoch: 5 cost = 0.44550

Training complete!
Validation Accuracy: 0.952823</pre>
<ul>
<li>To test our model with our own eyes, let&#8217;s visualize its predictions</li>
</ul>
<pre>img_name = rng.choice(test.filename)
filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)

img = imread(filepath, flatten=True)

test_index = int(img_name.split('.')[0]) - 49000

print "Prediction is: ", pred[test_index]

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()


</pre>
<pre>Prediction is:  8
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8.png"><img ="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8.png" alt="8" width="353" height="351" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8.png 353w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8-150x150.png 150w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8-300x298.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8-83x83.png 83w, https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8-200x200.png 200w" sizes="(max-width: 353px) 100vw, 353px" /></a></pre>
<ul>
<li>We see that our model performance is pretty good! Now let&#8217;s create a submission</li>
</ul>
<pre>sample_submission.filename = test.filename

 sample_submission.label = pred

sample_submission.to_csv(os.path.join(sub_dir, 'sub01.csv'), index=False)</pre>
<p>And done! We just created our own trained neural network!</p>
<p>&nbsp;</p>
<h2>Limitations of TensorFlow</h2>
<ul>
<li style="text-align: justify;">Even though TensorFlow is powerful, it&#8217;s still a low level library. For example, it can be considered as a machine level language. But for most of the purpose, you need modularity and high level interface such as keras</li>
<li style="text-align: justify;">It&#8217;s still in development, so much more awesomeness to come!</li>
<li style="text-align: justify;">It depends on your hardware specs, the more the merrier</li>
<li style="text-align: justify;">Still not an API for many languages.</li>
<li style="text-align: justify;">There are still many things yet to be included in TensorFlow, such as OpenCL support.</li>
</ul>
<p style="text-align: justify;">Most of the above mentioned are in the sights of TensorFlow developers. They have made a roadmap for specifying how the library should be developed in the future.</p>
<p>&nbsp;</p>
<h2>TensorFlow vs. Other Libraries</h2>
<p style="text-align: justify;">TensorFlow is built on similar principles as Theano and Torch of using mathematical computational graphs. But with the additional support of distributed computing, TensorFlow comes out to be better at solving complex problems. Also deployment of TensorFlow models is already supported which makes it easier to use for industrial purposes, giving a fight to commercial libraries such as Deeplearning4j, H2O and Turi. TensorFlow has APIs for Python, C++ and Matlab. There&#8217;s also a recent surge for support for other languages such as Ruby and R. So, TensorFlow is trying to have a universal language support.</p>
<p>&nbsp;</p>
<h2>Where to go from here?</h2>
<p style="text-align: justify;">So you saw how to build a simple neural network with TensorFlow. This code is meant for people to understand how to get started implementing TensorFlow, so take it with a pinch of salt. Remember that to solve more complex real life problems, you have to tweak the code a little bit.</p>
<p style="text-align: justify;">Many of the above functions can be abstracted to give a seamless end-to-end workflow. If you have worked with scikit-learn, you might know how a high level library abstracts &#8220;under the hood&#8221; implementations to give end-users a more easier interface. Although TensorFlow has most of the implementations already abstracted, high level libraries are emerging such as TF-slim and TFlearn.</p>
<p>&nbsp;</p>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="nofollow">TensorFlow official repository</a></li>
<li>Rajat Monga (TensorFlow technical lead) <a href="https://youtu.be/wmw8Bbb_eIE" target="_blank" rel="nofollow">&#8220;TensorFlow for everyone&#8221;</a> video</li>
<li><a href="https://github.com/jtoy/awesome-tensorflow/#github-projects">A curated list of dedicated resources </a></li>
</ul>