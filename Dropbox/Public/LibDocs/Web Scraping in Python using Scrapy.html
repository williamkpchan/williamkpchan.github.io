<base target="_blank">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" href="..\maincss.css">
<style>
body{margin-left:10%; margin-right:10%;}
</style>
</head>

<body>

<h1 itemprop="name" class="entry-title">Web Scraping in Python using Scrapy</h1>

<h2>Introduction</h2>

<h2>Table of Contents</h2>
<ol>
<li>Overview of Scrapy</li>
<li>Write your first Web Scraping code with Scrapy
<ol>
<li>Set up your system</li>
<li>Scraping Reddit: Fast Experimenting with Scrapy Shell</li>
<li>Writing Custom Scrapy Spiders</li>
</ol>
</li>
<li>Case Studies using Scrapy
<ol>
<li>Scraping an E-Commerce site</li>
<li>Scraping Techcrunch: Create your own RSS Feed Reader</li>
</ol>
</li>
</ol>
<p>&nbsp;</p>
<h2>1. Overview of Scrapy</h2>
<p>Scrapy is a Python framework for large scale web scraping. It gives you all the tools you need to efficiently <b><i>extract</i></b> data from websites, <b><i>process</i></b> them as you want, and store them in your preferred <b><i>structure </i></b>and format.</p>

<h2>2. Write your first Web Scraping code with Scrapy</h2>

<h3>2.1 Set up your system</h3>
<p>Scrapy supports both versions of Python 2 and 3. If you're using Anaconda, you can install the package from the conda-forge channel, which has up-to-date packages for Linux, Windows and OS X.</p>
<p>To install Scrapy using conda, run:</p>
<pre>conda install -c conda-forge scrapy</pre>
<p>Alternatively, if you're on Linux or Mac OSX, you can directly install scrapy by:</p>
<pre>pip install scrapy</pre>
<p><strong>Note: </strong>This article will follow <strong>Python 2</strong> with Scrapy.</p>
<p>&nbsp;</p>
<h3>2.2 Scraping Reddit: Fast Experimenting with Scrapy Shell</h3>
<p>Recently there was a season launch of a prominent TV series (GoTS7) and the social media was on fire, people all around were posting memes, theories, their reactions etc. I had just learnt scrapy and was wondering if it can be used to catch a glimpse of people's reactions?</p>
<p>&nbsp;</p>
<h4>Scrapy Shell</h4>
<p>I love the python shell, it helps me “try out” things before I can implement them in detail. Similarly, scrapy provides a shell of its own that you can use to experiment. To start the scrapy shell in your command line type:</p>
<pre>scrapy shell</pre>
<p>Woah! Scrapy wrote a bunch of stuff. For now, you don't need to worry about it. In order to get information from Reddit (about GoT) you will have to first run a <i>crawler </i>on it. A crawler is a program that browses web sites and downloads content. Sometimes crawlers are also referred as spiders.</p>
<p>&nbsp;</p>
<h4>About Reddit<b> </b></h4>
<p><a href="https://www.reddit.com/">Reddit</a> is a discussion forum website. It allows users to create “subreddits”  for a single topic of discussion. It supports all the features that conventional discussion portals have like creating a post, voting, replying to post, including images and links etc. Reddit also ranks the post based on their votes using a ranking algorithm of its own.</p>
<p>A crawler needs a starting point to start crawling(downloading) content from. Let's see, on googling “game of thrones Reddit” I found that Reddit has a sub-reddit exclusively for game of thrones at <a href="https://www.reddit.com/r/gameofthrones/">https://www.reddit.com/r/gameofthrones/</a> this will be the crawler's start URL.</p>
<p>To run the crawler in the shell type:</p>
<pre>fetch("<a href="https://www.reddit.com/r/gameofthrones/">https://www.reddit.com/r/gameofthrones/</a>")</pre>
<p><img class="aligncenter wp-image-37639 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160432/110.png" alt="" width="1137" height="330" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160432/110.png 1137w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160432/110-300x87.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160432/110-768x223.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160432/110-850x247.png 850w" sizes="(max-width: 1137px) 100vw, 1137px" /></p>
<p>When you crawl something with scrapy it returns a “response” object that contains the downloaded information. Let's see what the crawler has downloaded:</p>
<pre>view(response)</pre>
<p>This command will open the downloaded page in your default browser.</p>
<p><img class="aligncenter wp-image-37640 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160446/210.png" alt="" width="778" height="450" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160446/210.png 778w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160446/210-300x174.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160446/210-768x444.png 768w" sizes="(max-width: 778px) 100vw, 778px" /></p>
<p>Wow that looks exactly like the website, the crawler has successfully downloaded the entire web page.</p>
<p>Let's see how does the raw content looks like:</p>
<pre>print response.text</pre>
<p><img class="aligncenter wp-image-37641 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160500/39.png" alt="" width="1132" height="442" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160500/39.png 1132w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160500/39-300x117.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160500/39-768x300.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160500/39-850x332.png 850w" sizes="(max-width: 1132px) 100vw, 1132px" /></p>
<p>That's a lot of content but not all of it is relevant. Let's create list of things that need to be extracted :</p>
<ul>
<li>Title of each post</li>
<li>Number of votes it has</li>
<li>Number of comments</li>
<li>Time of post creation</li>
</ul>
<p>&nbsp;</p>
<h4>Extracting title of posts</h4>
<p>Scrapy provides ways to extract information from HTML based on css selectors like class, id etc. Let's find the css selector for title, right click on any post's title and select “Inspect” or “Inspect Element”:</p>
<p><img class="aligncenter wp-image-37642 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160518/46.png" alt="" width="1440" height="635" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160518/46.png 1440w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160518/46-300x132.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160518/46-768x339.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160518/46-850x375.png 850w" sizes="(max-width: 1440px) 100vw, 1440px" /></p>
<p>This will open the the developer tools in your browser:</p>
<p><img class="aligncenter wp-image-37643 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160534/52.png" alt="" width="1001" height="317" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160534/52.png 1001w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160534/52-300x95.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160534/52-768x243.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160534/52-850x269.png 850w" sizes="(max-width: 1001px) 100vw, 1001px" /></p>
<p>As it can be seen,  the css class “title” is applied to all &lt;p&gt; tags that have titles. This will helpful in filtering out titles from rest of the content in the response object:</p>
<pre>response.css(".title::text").extract()
<img class="aligncenter wp-image-37644 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160547/61.png" alt="" width="1137" height="414" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160547/61.png 1137w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160547/61-300x109.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160547/61-768x280.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160547/61-850x309.png 850w" sizes="(max-width: 1137px) 100vw, 1137px" /></pre>
<p>Here <b>response.css(..)</b> is a function that helps extract content based on css selector passed to it. The ‘.' is used with the title because it's a css . Also you need to use ::text to tell your scraper to extract only text content of the matching elements. This is done because scrapy directly returns the matching element along with the HTML code. Look at the following two examples:</p>
<p><img class="alignnone wp-image-37720 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24113134/Screen-Shot-2017-07-24-at-11.38.11.png" alt="" width="938" height="238" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24113134/Screen-Shot-2017-07-24-at-11.38.11.png 938w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24113134/Screen-Shot-2017-07-24-at-11.38.11-300x76.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24113134/Screen-Shot-2017-07-24-at-11.38.11-768x195.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24113134/Screen-Shot-2017-07-24-at-11.38.11-850x216.png 850w" sizes="(max-width: 938px) 100vw, 938px" /></p>
<p>Notice how &#8220;::text&#8221; helped us <strong>filter </strong>and extract only the text content.</p>
<p>&nbsp;</p>
<h4>Extracting Vote counts for each post</h4>
<p>Now this one is tricky, on inspecting, you get three scores:</p>
<p><img class="aligncenter wp-image-37645 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160600/72.png" alt="" width="516" height="99" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160600/72.png 516w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160600/72-300x58.png 300w" sizes="(max-width: 516px) 100vw, 516px" /></p>
<p>The “score” class is applied to all the three so it can't be used as a unique selector is required. On further inspection, it can be seen that the selector that uniquely matches the <strong>vote count</strong> that we need is the one that contains both &#8220;score&#8221; and &#8220;unvoted&#8221;.</p>
<p>When more than two selectors are required to identify an element, we use them both. Also since both are CSS classes we have to use &#8220;.&#8221; with their names. Let's try it out first by extracting the <strong>first element that matches</strong>:</p>
<pre>response.css(".score.unvoted").extract_first()</pre>
<p><img class="aligncenter wp-image-37646 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160609/81.png" alt="" width="1138" height="71" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160609/81.png 1138w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160609/81-300x19.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160609/81-768x48.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160609/81-850x53.png 850w" sizes="(max-width: 1138px) 100vw, 1138px" /></p>
<p><img class="aligncenter wp-image-37647 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160622/92.png" alt="" width="600" height="110" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160622/92.png 600w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160622/92-300x55.png 300w" sizes="(max-width: 600px) 100vw, 600px" /></p>
<p>See that the number of votes of the first post is correctly displayed. Note that on Reddit, the votes score is dynamic based on the number of upvotes and downvotes, so it'll be changing in real time. We will add &#8220;::text&#8221; to our selector so that we only get the vote value and not the complete vote element. To fetch all the votes:</p>
<pre>response.css(".score.unvoted::text").extract()</pre>
<p><strong>Note: </strong>Scrapy has two functions to extract the content <em><strong>extract()</strong> </em>and<em><strong> extract_first()</strong></em>.</p>
<p>&nbsp;</p>
<h4>Dealing with relative time stamps: extracting time of post creation</h4>
<p>On inspecting the post it is clear that the “time” element contains the time of the post.</p>
<p><img class="aligncenter wp-image-37648 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160632/102.png" alt="" width="1137" height="238" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160632/102.png 1137w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160632/102-300x63.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160632/102-768x161.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160632/102-850x178.png 850w" sizes="(max-width: 1137px) 100vw, 1137px" /></p>
<p><strong>There is a catch here though</strong>, this is only the <strong>relative time</strong>(16 hours ago etc.) of the post. This doesn't give any information about the date or time zone the time is in. In case we want to do some analytics, we won't be able to know by which date do we have to calculate &#8220;16 hours ago&#8221;. Let's inspect the time element a little more:</p>
<p><img class="aligncenter wp-image-37649 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160645/112.png" alt="" width="743" height="81" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160645/112.png 743w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160645/112-300x33.png 300w" sizes="(max-width: 743px) 100vw, 743px" /></p>
<p>The “title” attribute of time has both the date and the time in UTC. Let's extract this instead:</p>
<pre>response.css("time::attr(title)").extract()</pre>
<p><img class="aligncenter wp-image-37651 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160654/122.png" alt="" width="1139" height="163" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160654/122.png 1139w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160654/122-300x43.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160654/122-768x110.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160654/122-850x122.png 850w" sizes="(max-width: 1139px) 100vw, 1139px" /></p>
<p>The <b><i>.attr(attributename) </i></b>is used to get the value of the specified attribute of the matching element.</p>
<p>&nbsp;</p>
<h4> Extracting Number of comments:</h4>
<p>I leave this as a practice assignment for you. If you have any issues, you can post them here: <a href="https://discuss.analyticsvidhya.com/">https://discuss.analyticsvidhya.com/</a> and the community will help you out 🙂 .</p>
<p><b>So far:</b></p>
<ul>
<li><b><i>response &#8211; </i></b>An object that the scrapy crawler returns. This object contains all the information about the downloaded content.</li>
<li><b><i>response.css(..) &#8211; </i></b>Matches the element with the given CSS selectors.</li>
<li><b><i>extract_first(..) &#8211; </i></b>Extracts the “first” element that matches the given criteria.</li>
<li><b><i>extract(..) &#8211; </i></b>Extracts “all” the elements that match the given criteria.</li>
</ul>
<p>&nbsp;</p>
<p><b>Note: </b>CSS selectors are a very important concept as far as web scraping is considered, you can read more about it <a href="https://www.w3schools.com/cssref/css_selectors.asp">here</a> and how to <a href="https://doc.scrapy.org/en/latest/topics/selectors.html">use CSS selectors with scrapy</a>.</p>
<p>&nbsp;</p>
<h3>2.3 Writing Custom Spiders</h3>
<p>As mentioned above, a spider is a program that downloads content from web sites or a given URL. When extracting data on a larger scale, you would need to write custom spiders for different websites since there is no &#8220;one size fits all&#8221; approach in web scraping owing to diversity in website designs. You also would need to write code to convert the extracted data to a structured format and store it in a reusable format like CSV, JSON, excel etc. That's a lot of code to write, luckily <b><i>scrapy comes with most of these functionality built in</i></b>.</p>
<p>&nbsp;</p>
<h4>Creating a scrapy project</h4>
<p>Let's exit the scrapy shell first and create a new scrapy project:</p>
<pre>scrapy startproject ourfirstscraper www.reddit.com/r/gameofthrones/</pre>
<p>This will create a folder “ourfirstscraper” with the following structure:</p>
<p><img class="aligncenter size-full wp-image-37652" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160708/133.png" alt="" width="710" height="314" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160708/133.png 710w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160708/133-300x133.png 300w" sizes="(max-width: 710px) 100vw, 710px" /></p>
<p>For now, the two most important files are:</p>
<ul>
<li><b>settings.py &#8211; </b>This file contains the settings you set for your project, you'll be dealing a lot with it.</li>
<li><b>spiders/ &#8211; </b>This folder is where all your custom spiders will be stored. Every time you ask scrapy to run a spider, it will look for it in this folder.</li>
</ul>
<p>&nbsp;</p>
<h4>Creating a spider</h4>
<p>Let's change directory into our first scraper and create a basic spider “redditbot” :</p>
<pre>scrapy genspider redditbot <a href="http://www.reddit.com/r/gameofthrones/">www.reddit.com/r/gameofthrones/</a></pre>
<p>This will create a new spider “redditbot.py” in your <b>spiders/</b> folder with a basic template:</p>
<p><img class="aligncenter size-full wp-image-37653" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160719/142.png" alt="" width="920" height="288" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160719/142.png 920w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160719/142-300x94.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160719/142-768x240.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160719/142-850x266.png 850w" sizes="(max-width: 920px) 100vw, 920px" /></p>
<p>Few things to note here:</p>
<ul>
<li><b>name : </b>Name of the spider, in this case it is “redditbot”. Naming spiders properly becomes a huge relief when you have to maintain hundreds of spiders.</li>
<li><strong>allowed_domains</strong> : An optional list of strings containing domains that this spider is allowed to crawl. Requests for URLs not belonging to the domain names specified in this list won't be followed.</li>
<li><strong>parse(self, response) :</strong> This function is called whenever the crawler successfully crawls a URL. Remember the <i>response </i>object from earlier? This is the same response object that is passed to the parse(..).</li>
</ul>
<p>After every successful crawl the <b><i>parse(..)</i></b> method is called and so that's where you write your extraction logic. Let's add the earlier logic wrote earlier to extract titles, time, votes etc. in the parse function:</p>
<pre>def parse(self, response):
        #Extracting the content using css selectors
        titles = response.css('.title.may-blank::text').extract()
        votes = response.css('.score.unvoted::text').extract()
        times = response.css('time::attr(title)').extract()
        comments = response.css('.comments::text').extract()
       
        #Give the extracted content row wise
        for item in zip(titles,votes,times,comments):
            #create a dictionary to store the scraped info
            scraped_info = {
                'title' : item[0],
                'vote' : item[1],
                'created_at' : item[2],
                'comments' : item[3],
            }

            #yield or give the scraped info to scrapy
            yield scraped_info</pre>
<p>&nbsp;</p>
<p><b>Note: </b>Here <b><i>yield</i></b> <b><i>scraped_info</i></b> does all the magic. This line returns the scraped info(the dictionary of votes, titles, etc.) to scrapy which in turn processes it and stores it.</p>
<p>Save the file redditbot.py and head back to shell. Run the spider with the following command:</p>
<pre>scrapy crawl redditbot</pre>
<p>Scrapy would print a lot of stuff on the command line. Let's focus on the data.</p>
<p><img class="aligncenter size-full wp-image-37654" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160732/152.png" alt="" width="1432" height="251" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160732/152.png 1432w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160732/152-300x53.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160732/152-768x135.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160732/152-850x149.png 850w" sizes="(max-width: 1432px) 100vw, 1432px" /></p>
<p>Notice that all the data is downloaded and extracted in a dictionary like object that meticulously has the votes, title, created_at and comments.</p>
<p>&nbsp;</p>
<h4>Exporting scraped data as a csv<b> </b></h4>
<p>Getting all the data on the command line is nice but as a data scientist, it is preferable to have data in certain formats like CSV, Excel, JSON etc. that can be imported into programs. Scrapy provides this nifty little functionality where you can export the downloaded content in various formats. Many of the popular formats are already supported.</p>
<p>Open the <b>settings.py</b> file and add the following code to it:</p>
<pre>#Export as CSV Feed
FEED_FORMAT = "csv"
FEED_URI = "reddit.csv"</pre>
<p><img class="aligncenter size-full wp-image-37655" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160750/161.png" alt="" width="924" height="418" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160750/161.png 924w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160750/161-300x136.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160750/161-768x347.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160750/161-850x385.png 850w" sizes="(max-width: 924px) 100vw, 924px" /></p>
<p>And run the spider :</p>
<pre>scrapy crawl redditbot</pre>
<p>This will now export all scraped data in a file <b>reddit.csv</b>. Let's see how the CSV looks:</p>
<p><img class="aligncenter size-full wp-image-37656" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160805/172.png" alt="" width="735" height="471" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160805/172.png 735w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160805/172-300x192.png 300w" sizes="(max-width: 735px) 100vw, 735px" /></p>
<p>What happened here:</p>
<ul>
<li><b>FEED_FORMAT : </b>The format in which you want the data to be exported. Supported formats are: JSON, JSON lines, XML and CSV.</li>
<li><strong>FEED_URI :</strong> The location of the exported file.</li>
</ul>
<p>There are a plethora of forms that scrapy support for exporting feed if you want to dig deeper you can check <a href="https://doc.scrapy.org/en/latest/topics/feed-exports.html">here</a> and <a href="https://doc.scrapy.org/en/latest/topics/selectors.html#using-selectors">using css selectors in scrapy</a>.</p>
<p>Now that you have successfully created a system that crawls web content from a link, scrapes(extracts) selective data from it and saves it in an appropriate structured format let's take the game a notch higher and learn more about web scraping.</p>
<p>&nbsp;</p>
<h2>3. Case studies using Scrapy</h2>
<p>Let's now look at a few case studies to get more experience of scrapy as a tool and its various functionalities.</p>
<p>&nbsp;</p>
<h3>Scraping an E-Commerce site</h3>
<p>The advent of internet and smartphones has been an impetus to the e-commerce industry. With millions of customers and billions of dollars at stake, the market has started seeing the multitude of players. Which in turn has led to rise of e-commerce aggregator platforms which collect and show you the information regarding your products from across multiple portals? For example when planning to buy a smartphone and you would want to see the prices at different platforms at a single place. What does it take to build such an aggregator platform? Here's my small take on building an e-commerce site scraper.</p>
<p>As a test site, you will scrape <b>ShopClues </b>for <b>4G-Smartphones</b></p>
<p>Let's first generate a basic spider:</p>
<pre>scrapy genspider shopclues www.shopclues.com/mobiles-featured-store-4g-smartphone.html</pre>
<p>This is how the shop clues web page looks like:</p>
<p><img class="aligncenter size-full wp-image-37657" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160820/182.png" alt="" width="1440" height="900" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160820/182.png 1440w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160820/182-300x188.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160820/182-768x480.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160820/182-850x531.png 850w" sizes="(max-width: 1440px) 100vw, 1440px" /></p>
<p>The following information needs to be extracted from the page:</p>
<ul>
<li>Product Name</li>
<li>Product price</li>
<li>Product discount</li>
<li>Product image</li>
</ul>
<p>&nbsp;</p>
<h4>Extracting image URLs of the product</h4>
<p>On careful inspection, it can be seen that the attribute “data-img” of the &lt;img&gt; tag can be used to extract image URLs:</p>
<pre>response.css("img::attr(data-img)").extract()</pre>
<p><img class="aligncenter size-full wp-image-37658" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160835/192.png" alt="" width="1129" height="363" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160835/192.png 1129w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160835/192-300x96.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160835/192-768x247.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160835/192-850x273.png 850w" sizes="(max-width: 1129px) 100vw, 1129px" /></p>
<p>&nbsp;</p>
<h4>Extracting product name from &lt;img&gt; tags</h4>
<p>Notice that the “title” attribute of the &lt;img&gt; tag contains the product's full name:</p>
<p><img class="aligncenter size-full wp-image-37659" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160850/202.png" alt="" width="824" height="141" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160850/202.png 824w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160850/202-300x51.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160850/202-768x131.png 768w" sizes="(max-width: 824px) 100vw, 824px" /></p>
<pre>response.css("img::attr(title)").extract()</pre>
<p>Similarly, selectors for price(&#8220;.p_price&#8221;) and discount(&#8220;.prd_discount&#8221;).</p>
<p>&nbsp;</p>
<h4>How to download product images?</h4>
<p>Scrapy provides reusable <b>images pipelines</b> for downloading files attached to a particular item (for example, when you scrape products and also want to download their images locally).</p>
<p>The Images Pipeline has a few extra functions for processing images. It can:</p>
<ul>
<li>Convert all downloaded images to a common format (JPG) and mode (RGB)</li>
<li>Thumbnail generation</li>
<li>Check images width/height to make sure they meet a minimum constraint</li>
</ul>
<p>In order to use the <b>images pipeline </b> to download images, it needs to be <b>enabled</b> in the <b>settings.py</b> file. Add the following lines to the file :</p>
<pre>ITEM_PIPELINES = {
  'scrapy.pipelines.images.ImagesPipeline': 1
}
IMAGES_STORE = 'tmp/images/'</pre>
<p>you are basically telling scrapy to use the ‘Images Pipeline' and the location for the images should be in the folder ‘tmp/images/. The final spider would now be:</p>
<pre>import scrapy

class ShopcluesSpider(scrapy.Spider):
   #name of spider
   name = 'shopclues'

   #list of allowed domains
   allowed_domains = ['www.shopclues.com/mobiles-featured-store-4g-smartphone.html']
   #starting url
   start_urls = ['http://www.shopclues.com/mobiles-featured-store-4g-smartphone.html/']
   #location of csv file
   custom_settings = {
       'FEED_URI' : 'tmp/shopclues.csv'
   }


   def parse(self, response):
       #Extract product information
       titles = response.css('img::attr(title)').extract()
       images = response.css('img::attr(data-img)').extract()
       prices = response.css('.p_price::text').extract()
       discounts = response.css('.prd_discount::text').extract()


       for item in zip(titles,prices,images,discounts):
           scraped_info = {
               'title' : item[0],
               'price' : item[1],
               'image_urls' : [item[2])], #Set's the url for scrapy to download images
               'discount' : item[3]
           }

           yield scraped_info</pre>
<p>A few things to note here:</p>
<ul>
<li><b>custom_settings</b> : This is used to set settings of an individual spider. Remember that settings.py is for the whole project so here you tell scrapy that the output of this spider should be stored in a CSV  file &#8220;shopclues.csv&#8221; that is to be stored in the &#8220;tmp&#8221; folder.</li>
<li><b>scraped_info[“image_urls”]  : </b>This is the field that scrapy checks for the image's link. If you set this field with a list of URLs, , scrapy will automatically download and store those images for you.</li>
</ul>
<p>On running the spider the output can be read from &#8220;tmp/shopclues.csv&#8221;:</p>
<p><img class="aligncenter size-full wp-image-37660" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160902/211.png" alt="" width="1013" height="534" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160902/211.png 1013w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160902/211-300x158.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160902/211-768x405.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160902/211-850x448.png 850w" sizes="(max-width: 1013px) 100vw, 1013px" /></p>
<p>You also get the images downloaded. Check the folder “tmp/images/full” and you will see the images:</p>
<p><img class="aligncenter size-full wp-image-37661" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160917/222.png" alt="" width="1440" height="793" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160917/222.png 1440w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160917/222-300x165.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160917/222-768x423.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160917/222-850x468.png 850w" sizes="(max-width: 1440px) 100vw, 1440px" /></p>
<p>Also, notice that scrapy automatically adds the <b>download path of the image on your system</b> in the csv:</p>
<p><img class="aligncenter size-full wp-image-37662" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160930/232.png" alt="" width="1125" height="145" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160930/232.png 1125w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160930/232-300x39.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160930/232-768x99.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22160930/232-850x110.png 850w" sizes="(max-width: 1125px) 100vw, 1125px" /></p>
<p>There you have your own little e-commerce aggregator 🙂</p>
<p>If you want to dig in you can read more about scrapy's Images Pipeline <a href="https://doc.scrapy.org/en/latest/topics/media-pipeline.html#scrapy.pipelines.images">here</a></p>
<p>&nbsp;</p>
<h3>Scraping Techcrunch: Creating your own RSS Feed Reader</h3>
<p><img class="alignnone wp-image-37725 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24120050/Screen-Shot-2017-07-24-at-12.06.58.png" alt="" width="1440" height="681" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24120050/Screen-Shot-2017-07-24-at-12.06.58.png 1440w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24120050/Screen-Shot-2017-07-24-at-12.06.58-300x142.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24120050/Screen-Shot-2017-07-24-at-12.06.58-768x363.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/24120050/Screen-Shot-2017-07-24-at-12.06.58-850x402.png 850w" sizes="(max-width: 1440px) 100vw, 1440px" /></p>
<p>Techcrunch is one of my favourite blogs that I follow to stay abreast with news about startups and latest technology products. Just like many blogs nowadays TechCrunch gives its own <strong>RSS feed</strong> here : <a href="https://techcrunch.com/feed/">https://techcrunch.com/feed/</a> . One of scrapy's features is its ability to handle XML data with ease and in this part, you are going to extract data from Techcrunch's RSS feed.</p>
<p>Create a basic spider:</p>
<pre>Scrapy genspider techcrunch <a href="https://techcrunch.com/feed/">techcrunch.com/feed/</a></pre>
<p>Let's have a look at the XML, the marked portion is data of interest:</p>
<p><img class="aligncenter size-full wp-image-37663" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161110/242.png" alt="" width="1440" height="825" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161110/242.png 1440w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161110/242-300x172.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161110/242-768x440.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161110/242-850x487.png 850w" sizes="(max-width: 1440px) 100vw, 1440px" /></p>
<p>Here are some observations from the page:</p>
<ul>
<li>Each article is present between <b>&lt;item&gt;&lt;/item&gt; </b>tags and there are <b>20 </b>such items(articles).</li>
<li>The title of the post is in <b>&lt;title&gt;&lt;/title&gt; </b>tags.</li>
<li>Link to the article can be found in <b>&lt;link&gt; </b>tags.</li>
<li><b>&lt;pubDate&gt; </b>contains the date of publishing.</li>
<li>The author name is enclosed between funny looking <b>&lt;dc:creator&gt;</b> tags.</li>
</ul>
<p>&nbsp;</p>
<h4>Overview of XPath and XML</h4>
<p>XPath is a syntax that is used to define XML documents. It can be used to traverse through an XML document. Note that XPath's follows a hierarchy.</p>
<p>&nbsp;</p>
<h4>Extracting title of post</h4>
<p>Let's extract the title of the first post. Similar to <b><i>response.css(..) </i></b>, the function <b><i>response.xpath(..)</i></b> in scrapy to deal with XPath. The following code should do it:</p>
<pre>response.xpath("//item/title").extract_first()</pre>
<p>&nbsp;</p>
<p><b>Output</b> :</p>
<pre>u'&lt;title xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc
="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/
01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"&gt;Why the future of deep learning depends on finding good data&lt;/title&gt;'</pre>
<p>Wow! That's a lot of content, but only the text content of the title is of interest. Let's filter it out:</p>
<pre>response.xpath("//item/title/text()").extract_first()</pre>
<p><b>Output </b>:</p>
<pre>u'Why the future of deep learning depends on finding good data'</pre>
<p>This is much better. Notice that <b>text()</b> here is equivalent of <b>::text</b> from CSS selectors. Also look at the XPath <b>//item/title/text()<i> </i></b>here you are basically saying find the element “item” and extract the “text” content of its sub element “title”<i>.</i></p>
<p>Similarly, the xpaths for link, pubDate as :</p>
<ul>
<li>Link &#8211; //item/link/text()</li>
<li>Date of publishing &#8211; //item/pubDate/text()</li>
</ul>
<p>&nbsp;</p>
<h4>Extracting author name: Dealing with namespaces in XML</h4>
<p>Notice the <b>&lt;creator&gt; </b>tags:</p>
<p><img class="aligncenter size-full wp-image-37664" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161124/252.png" alt="" width="1020" height="190" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161124/252.png 1020w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161124/252-300x56.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161124/252-768x143.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161124/252-850x158.png 850w" sizes="(max-width: 1020px) 100vw, 1020px" /></p>
<p>The tag itself has some text “dc:” because of which it can't be extracted using XPath and the author name itself is crowded with “![CDATA..” irrelevant text. These are just <b>XML namespaces</b> and you don't want to have anything to do with them so we'll ask scrapy to remove the namespace:</p>
<pre>response.selector.remove_namespaces()</pre>
<p>Now when you try extracting the author name , it will work :</p>
<pre>response.xpath("//item/creator/text()").extract_first()</pre>
<p><b>Output</b> : u'Ophir Tanz,Cambron Carter'</p>
<p>The complete spider for TechCrunch would be:</p>
<pre>import scrapy

class TechcrunchSpider(scrapy.Spider):
    #name of the spider
    name = 'techcrunch'

    #list of allowed domains
    allowed_domains = ['techcrunch.com/feed/']

    #starting url for scraping
    start_urls = ['http://techcrunch.com/feed/']

    #setting the location of the output csv file
    custom_settings = {
        'FEED_URI' : 'tmp/techcrunch.csv'
    }

    def parse(self, response):
        #Remove XML namespaces
        response.selector.remove_namespaces()

        #Extract article information
        titles = response.xpath('//item/title/text()').extract()
        authors = response.xpath('//item/creator/text()').extract()
        dates = response.xpath('//item/pubDate/text()').extract()
        links = response.xpath('//item/link/text()').extract()

        for item in zip(titles,authors,dates,links):
            scraped_info = {
                'title' : item[0],
                'author' : item[1],
                'publish_date' : item[2],
                'link' : item[3]
            }

            yield scraped_info</pre>
<p>Let's run the spider:</p>
<pre>scrapy crawl techcrunch</pre>
<p><img class="aligncenter size-full wp-image-37665" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261.png" alt="" width="994" height="558" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261.png 994w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261-300x168.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261-768x431.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261-850x477.png 850w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/07/22161138/261-257x144.png 257w" sizes="(max-width: 994px) 100vw, 994px" /></p>
<p>And there you have your own RSS reader :)!</p>
<p>&nbsp;</p>
<h2>End Notes</h2>
<p>In this article, we have just scratched the surface of Scrapy's potential as a web scraping tool. Nevertheless, if you have experience with any other tools for scraping it would have been evident by now that in efficiency and practical application, Scrapy wins hands down.<b> </b>All the code used in this article is <a href="https://github.com/mohdsanadzakirizvi/web-scraping-magic-with-scrapy-and-python">available on github.</a> Also, check out some of the interesting projects built with Scrapy:</p>

</body>
</html>
