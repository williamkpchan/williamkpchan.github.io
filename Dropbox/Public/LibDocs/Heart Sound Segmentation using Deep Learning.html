<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">

<style>

a:hover,a:active{color:red}
table.w3-table-all{margin:20px 0}
.top {
 position:relative;
 background-color:black;
 height:68px;
 padding-top:20px;
 line-height:50px;
 overflow:hidden;
 z-index:2;
}
body {
 background-color: #000000;
 color: MediumSeaGreen;
 margin-left: 14%;
 margin-right: 14%;
 font-size: 24px;
}
a { text-decoration: none;
	color: #58D858;}
a:visited { color: #88C898;}
A:hover {	color: yellow;}
A:focus {	color: red;}
code { color: gray; background-color: #001010; font-size: 18px;}
pre { color: gray; background-color: #001010; font-size: 18px;}
h1, h2, h3, h4, h5, .goldword {
	color: gold;
}
table{
	width: 100%;
	font-size: 20px;
	border-collapse: collapse;
	border: 1px solid gray;
}
th{
	border: 1px solid gray;
	font-weight:bold;
	color: lightgreen;
}
td{
	padding:10px;
	border: 1px dotted dimgray;
}
tr>th:first-child{
	width:40%;
}
tr>td:first-child{
	color: lime;

}
img{
	margin-top:1%;
	margin-bottom:2%;
}
.topic{
    color: lime;
}
.goldsha {
    color: white;
    border: 1px solid gold;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -2px -2px 3px gold inset;
}
.redsha {
    color: gold;
    border: 1px solid red;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -2px -2px 3px red inset;
}
.whitesha {
    color: red;
    border: 1px solid white;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -3px -2px 3px white inset;
}
.orangesha {
    color: yellow;
    border: 1px solid orange;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -2px -2px 3px orange inset;
}
.yellowsha {
    color: lime;
    border: 1px solid yellow;
    padding: 2px;
    border-radius: 3px;
	box-shadow: 3px 3px 3px silver;
	display: inline-block;
}
.greensha {
    color: lightblue;
    border: 1px solid green;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -2px -2px 3px green inset;
}
.left {
    position: absolute;
    left: 100px;
    color: GoldenRod;
    border: 1px solid GoldenRod;
    padding: 2px;
    font-size: 60%;
}
.bord {
    color: redpink;
    border: 1px solid GoldenRod;
    padding: 1px;
    font-size: 90%;
}
.yellowbord {
    color: lime;
    border: 1px solid yellow;
    padding: 2px;
    border-radius: 3px;
	box-shadow: 3px 3px 3px silver;
}
.bluebord {
    color: white;
    border: 1px solid lightblue;
    padding: 2px;
    border-radius: 3px;
	box-shadow: -2px -2px 3px silver inset;
}
.highlight { 
    color: white;
    background-color: #002030
  }
hr {width: 50%;}
li{
	list-style-type: decimal;
}
#toc, #tang, #san, #pill {
	margin-left: 15%;
	margin-right: 15%;
	color: gold;
	padding: 1%;
	text-align: left;
	box-shadow: 5px 5px 15px silver;
	border-radius: 5px;
	border: 1px solid DarkSlateGray;
    font-size: 90%;
}
.mywords{
    color: Crimson;
}
.orangeword{
    color: orange;
}
.remarks {
	font-size: 22px;
	color: MediumSeaGreen;
}
</STYLE>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5/jquery.js"></script>
<script>
$(document).ready(function(){
    $('h1, h2, h3, h4, h5, .goldword, .topic').click(function(){
    parent.history.back();
    return false;
    });
});
</script>


</head><body>

<center><b>Heart Sound Segmentation using Deep Learning</b></center>
<div id="toc"><ul></ul></div>
<br>
<br>
<br>


<h2>Introduction</h2>
<p>The idea of doing a project on heart sound segmentation came from a recent breakthrough I heard over the internet. One of the influencers I follow &#8211; Andrew Ng published a research paper a while back &#8211; which essentially is a state-of-the-art method for detecting heart disease.</p>

<p>It was an intriguing idea for me, so I went through all the materials published on the subject to understand what was the original idea behind.</p>
<p>To keep the story short, the authors said that they used deep learning &#8211; a technique which has been in the news for a while now, for extracting the patterns that experts used to identify a diseased patient. This algorithm after training, became so good at the task that the authors claim to surpass even seasoned doctors. This idea influenced me that even I &#8211; albeit small &#8211; could have an impact on the substantial advancements that these researchers are having!</p>
<p>This article focuses on audio segmentation problem in ECG signals and how we leverage deep learning to solve the task. I will first discuss a bit about segmentation problem in general and then show you the ways that can be used to solve the problem. I will also discuss what &#8220;heart sound&#8221; is and then show you an implementation of heart sound segmentation.</p>
<p>So let&#8217;s get on with it!</p>
<p><strong>Note:</strong> This article assumes that you have a basic knowledge of audio data analysis. If you want to brush up the concepts &#8211; you can go through the article</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/">Getting Started with Audio Data Analysis using Deep Learning</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/">Fundamentals of Deep Learning</a></li>
</ul>
<p>&nbsp;</p>
<h2>Table of Contents</h2>
<ul>
<li>What is a Segmentation problem in general?</li>
<li>Supervised Segmentation approach</li>
<li>Understanding our problem &#8211; What do you mean by &#8220;Heart Sound&#8221;?</li>
<li>Implementation of Heart Sound Segmentation</li>
</ul>
<p>&nbsp;</p>
<h2>What is a Segmentation problem (in general)?</h2>
<p>Before we dive into heart sound segmentation, let us go back and understand what segmentation problem entails. Segmentation literally means dividing a particular object into parts (or segments) based on a defined set of characteristics. This object can be anything &#8211; ranging from concrete things like a frame of an image or an audio signal, to abstract objects like market or consumers.</p>
<p>You may ask, why would you segment objects? The answer is simple &#8211; if you break down an object, it becomes an easier task extract information from it. For example in Customer Management, working with averages never reveals actionable insights until broken down in segments. As mentioned in <a href="https://www.analyticsvidhya.com/blog/2013/08/importance-segmentation-create/">the article</a>, this is an example of customer segmentation of credit card usage on the basis of their age.</p>
<p><a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2013/08/customer-segmentation.jpg"><img class="aligncenter size-full wp-image-1097" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2013/08/customer-segmentation.jpg" sizes="(max-width: 995px) 100vw, 995px" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2013/08/customer-segmentation.jpg 995w, https://www.analyticsvidhya.com/wp-content/uploads/2013/08/customer-segmentation-300x230.jpg 300w" alt="customer segmentation" width="995" height="765" /></a></p>
<p>&nbsp;</p>
<h2>Supervised Segmentation approach</h2>
<p>Now that you know Segmentation as a problem, let us understand the approaches to solve a segmentation problem.</p>
<p>Segmentation, specially for audio data analysis, is an important pre-processing step. This is because you can segment a noisy and lengthy audio signal into short homogeneous segments, which are handy short sequences of audio used for further processing. Now to solve a segmentation problem, you can either do it directly using unsupervised methods or convert it into a supervised problem and then group it according to its class.</p>
<p>To explain this more intuitively, lets take an example of Image Segmentation task.</p>
<p>Suppose you have an image of a cat in a field as we can see below. What you want is to divide the image into chunks &#8211; so that one individual object can be separately identified from the other. You can do this in two ways</p>
<ul>
<li><strong>Approach 1:</strong> From each pixel of the image, find out the pixels which are close to each other and have an approximately similar color. You can cluster these pixels together to form a bigger picture of an object. In the example below, our cat is mostly greyish white. So it would be easier to find the pixels and segmenting the cat out of the image. This is an <strong>unsupervised approach</strong> to segmentation.</li>
<li><strong>Approach 2:</strong> Train a model by giving it explicit examples of the classes belonging to the image &#8211; specifically a cat, trees and sky. Then get the model predictions on which class is present where in the image. This is a <strong>supervised approach</strong> to segmentation.</li>
</ul>
<p><img class="aligncenter wp-image-39842 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30071313/segmentation1.png" alt="" width="634" height="513" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30071313/segmentation1.png 634w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30071313/segmentation1-300x243.png 300w" sizes="(max-width: 634px) 100vw, 634px" /></p>
<p>Although both the approaches has its pros and cons, the decision to start out with either of the approach will depend upon how hard it is to get training examples to go on with the supervised approach.</p>
<p>&nbsp;</p>
<h2>Understanding our problem &#8211; What do you mean by &#8220;Heart Sound&#8221;?</h2>
<p>Without wasting any time, let us jump on to what our actual problem is and try to solve it. Quoting the <a href="http://www.peterjbentley.com/heartchallenge/">challenge page</a> itself,</p>
<blockquote><p><span class="Normal">According to the World Health Organisation, cardiovascular diseases (CVDs) are the number one cause of death globally: more people die annually from CVDs than from any other cause. An estimated 17.1 million people died from CVDs in 2004, representing 29% of all global deaths. Of these deaths, an estimated 7.2 million were due to coronary heart disease. Any method which can help to detect signs of heart disease could therefore have a significant impact on world health. This challenge is to produce methods to do exactly that.</span></p></blockquote>
<p>The task in the challenge is to <span class="Normal">find a method that can locate sounds particular to a heart (aka lub &amp; dub, which are technically called S1 and S2) within audio data and then segment the audio files on the basis of these sounds. After segmenting the sounds, the challenge then asks us to produce a method that can classify heartbeat into normal and diseased categories. For the purpose of this article, we will take up only the first task of the challenge, i.e. to segment heart audio.<br />
</span></p>
<p>To give you a practical glimpse, this is how the heart sounds like</p>
<p><iframe width="500" height="375" src="https://www.youtube.com/embed/NeMJXMSkA7g?start=31&#038;feature=oembed" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe></p>
<p><span class="Normal">A normal heart sound has a clear “lub dub, lub dub” pattern, with the time from “lub” to “dub” shorter than the time from “dub” to the next “lub” (when the heart rate is less than 140 beats per minute)</span>. <span class="Normal">A temporal description of “lub” and “dub” locations over time in the following illustration:<br />
</span></p>
<pre><span class="Normal">lub……….dub……………. lub……….dub……………. lub……….dub……………. lub……….dub</span></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Implementation of Heart Sound Segmentation</h2>
<p>The very basic step you need to do whenever you start up on a problem is to understand the data and go through it record by record. Let us start with this:</p>
<p><strong>Note:</strong> you can download the required dataset from <a href="http://www.peterjbentley.com/heartchallenge/">this webpage</a>. Only download Dataset A of challenge 1 (<span class="Normal">Atraining_normal.zip</span> and Atraining_normal_seg.csv)</p>
<pre># import modules%pylab inline

import librosa
import numpy as np
import pandas as pd
from librosa import display</pre>
<pre># read csv filetemp = pd.read_csv('../misc/Atraining_normal_seg.csv')
temp.head()</pre>
<p><img class="aligncenter wp-image-39844 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30093712/try1.png" alt="" width="994" height="319" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30093712/try1.png 994w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30093712/try1-300x96.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30093712/try1-768x246.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30093712/try1-850x273.png 850w" sizes="(max-width: 994px) 100vw, 994px" /></p>
<ul>
<li>Let&#8217;s plot a sample heartbeat from out dataset</li>
</ul>
<pre># load sampledata, sampling_rate = librosa.load('../misc/Atraining_normal/201102081321.wav', sr=44100 )
display.waveplot(data, sr=sampling_rate)</pre>
<p><img class="aligncenter wp-image-39845 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30094009/try2.png" alt="" width="993" height="378" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30094009/try2.png 993w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30094009/try2-300x114.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30094009/try2-768x292.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30094009/try2-850x324.png 850w" sizes="(max-width: 993px) 100vw, 993px" /></p>
<p>We see that there are cycles of heartbeat, with a higher intensity sound followed by a lower intensity sound.</p>
<ul>
<li>For our problem, we would have to create training data from the raw files. The code below does this simply by going though all the raw files, and extracting a part of the audio along with its respective label</li>
</ul>
<pre># create training data
data_x = []
data_y = []
for j in range(temp.shape[0]):
   for i in range(1, temp.shape[1] - 1):
     try: 
       data, sampling_rate = librosa.load('../misc/Atraining_normal/'+ temp.iloc[j, 0].split('.')[0] +'.wav', sr=44100 )
       temp_data = data[int(temp.iloc[j, i]):int(temp.iloc[j, i+1])]
       temp_label = temp.iloc[:, i].name.split('.')[0]
 
       data_x.append(temp_data)
       data_y.append(temp_label)
     except:
       pass</pre>
<ul>
<li>When we create this data, a bit of pre-processing is required. First is to make all the the extracted samples of same shape, second is to normalize the data and third is to create appropriate X and Y for our deep learning model.</li>
</ul>
<pre># preprocessing from keras.preprocessing.sequence import pad_sequences

# step 1data_x = pad_sequences(data_x, maxlen=20000, dtype='float', padding='post', truncating='post', value=0.)

# step 2data_x = data_x / np.max(data_x)

# step 3
data_x = data_x[:,:,np.newaxis]
data_y = pd.Series(data_y)
data_y.value_counts()

data_y = data_y.map({'S1':0, 'S2':1}).values</pre>
<ul>
<li>Now let us build our deep learning model. We will build a CNN model, as CNN have proved to be state-of-the-art architecture for sequence understanding and classification</li>
</ul>
<p>from keras.layers import InputLayer, Conv1D, Dense, Flatten, MaxPool1D<br />
from keras.models import Sequential</p>
<p>model = Sequential()</p>
<p>model.add(InputLayer(input_shape=data_x.shape[1:]))</p>
<p>model.add(Conv1D(filters=50, kernel_size=10, activation=&#8217;relu&#8217;))<br />
model.add(MaxPool1D(strides=8))<br />
model.add(Conv1D(filters=50, kernel_size=10, activation=&#8217;relu&#8217;))<br />
model.add(MaxPool1D(strides=8))<br />
model.add(Flatten())<br />
model.add(Dense(units=1, activation=&#8217;softmax&#8217;))</p>
<p>model.compile(optimizer=&#8217;adam&#8217;, loss=&#8217;binary_crossentropy&#8217;, metrics=[&#8216;accuracy&#8217;])</p>
<p>Our model will have this type of architecture</p>
<p><img class="aligncenter wp-image-39846 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30095622/try3.png" alt="" width="992" height="442" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30095622/try3.png 992w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30095622/try3-300x134.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30095622/try3-768x342.png 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30095622/try3-850x379.png 850w" sizes="(max-width: 992px) 100vw, 992px" /></p>
<ul>
<li>The next step is to train your model on the transformed dataset</li>
</ul>
<pre># train modelmodel.fit(data_x, data_y, batch_size=32, epochs=1)</pre>
<p>We are restricting the training for only 1 epoch here. But you can increase this to make your model perform better.</p>
<p>And voila! You have a trained model which can be used to perform segmentation task. Now to get the durations where you should segment a heartbeat, just divide your raw test file into multiple parts and get the top prediction out of it. The model would give a prediction like this</p>
<p><img class="aligncenter wp-image-39847 size-full" src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30101339/try4.png" alt="" width="600" height="361" srcset="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30101339/try4.png 600w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/11/30101339/try4-300x181.png 300w" sizes="(max-width: 600px) 100vw, 600px" /></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>End Notes</h2>
<p>I hope this article gave you a glimpse of how advancements in audio analysis can help us creating amazing technologies that can change our lives. The possibilities it opens up for humans can be huge.</p>
<p>I have specially included an implementation of the technique so that you can use it to try it out locally. If you find the article helpful or have any suggestions, do let me know in the comments below!</p>
<br>
<br><br><br><br><br>
<script>
  $(function() {
    var toc = $('#toc>ul');

    function makeLi(text, href) {
      return $('<a href="' + href + '" target="_self">' + text + '</a><br>');
    }

    $('h2, h3').each(function(i) {
      var chapter = $(this), chapterNumber = i + 1;
      toc.append(
        makeLi(chapter.text(), '#chapter-' + chapterNumber)
      );
      chapter.attr('id', 'chapter-' + chapterNumber);
    });

  });
</script>
</body>
</html>
