<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" href="submaincss.css">
<style>
</style>

</head>
<body>

<a href="https://educationalresearchtechniques.com/"><h2>Research techniques and education</h2></a>
<h1>Smoothing Splines in R</h1>
<p>This post will provide information on smoothing splines. Smoothing splines are used in regression when we want to reduce the residual sum of squares by adding more flexibility to the regression line without allowing too much overfitting.<br />
In order to do this, we must tune the parameter called the smoothing spline. The smoothing spline is essentially a natural cubic spline with a knot at every unique value of x in the model. Having this many knots can lead to severe overfitting. This is corrected for by controlling the degrees of freedom through the parameter called lambda. You can manually set this value or select it through cross-validation.</p>
<p>We will now look at an example of the use of smoothing splines with the “Clothing” dataset from the “Ecdat” package. We want to predict “tsales” based on the use of innovation in the stores. Below is some initial code.</p>
<pre><code><span class="keyword">library ( Ecdat )</span></code></pre>
<pre><code><span>data ( Clothing )</span>
<span>str ( Clothing )</span></code></pre>
<pre><code>## 'data.frame':    400 obs. of  13 variables:
##  $ tsales : int  750000 1926395 1250000 694227 750000 400000 1300000 495340 1200000 495340 ...
##  $ sales  : num  4412 4281 4167 2670 15000 ...
##  $ margin : num  41 39 40 40 44 41 39 28 41 37 ...
##  $ nown   : num  1 2 1 1 2 ...
##  $ nfull  : num  1 2 2 1 1.96 ...
##  $ npart  : num  1 3 2.22 1.28 1.28 ...
##  $ naux   : num  1.54 1.54 1.41 1.37 1.37 ...
##  $ hoursw : int  76 192 114 100 104 72 161 80 158 87 ...
##  $ hourspw: num  16.8 22.5 17.2 21.5 15.7 ...
##  $ inv1   : num  17167 17167 292857 22207 22207 ...
##  $ inv2   : num  27177 27177 71571 15000 10000 ...
##  $ ssize  : int  170 450 300 260 50 90 400 100 450 75 ...
##  $ start  : num  41 39 40 40 44 41 39 28 41 37 ...</code></pre>
<p>We are going to create three models. Model one will have 70 degrees of freedom, model two will have 7, and model three will have the number of degrees of freedom are determined through cross-validation. Below is the code.</p>
<pre><code><span>fit1 &lt;- smooth.spline ( Clothing $ inv2,Clothing $ tsales,df = 57 )</span>
<span>fit2 &lt;- smooth.spline ( Clothing $ inv2,Clothing $ tsales,df = 7 )</span>
<span>fit3 &lt;- smooth.spline ( Clothing $ inv2,Clothing $ tsales,cv = T )</span></code></pre>
<pre><code>## Warning in smooth.spline(Clothing$inv2, Clothing$tsales, cv = T): cross-
## validation with non-unique 'x' values seems doubtful</code></pre>
<pre><code><span>( data.frame ( fit1 $ df,fit2 $ df,fit3 $ df ) )</span></code></pre>
<pre><code>##   fit1.df  fit2.df  fit3.df
## 1      57 7.000957 2.791762</code></pre>
<p>In the code above we used the “smooth.spline” function which comes with base r.Notice that we did not use the same coding syntax as the “lm” function calls for. The code above also indicates the degrees of freedom for each model.  You can see that for &#8220;fit3&#8221; the cross-validation determine that 2.79 was the most appropriate degrees of freedom. In addition, if you type in the following code.</p>
<pre><code><span>sapply ( data.frame ( fit1 $ x,fit2 $ x,fit3 $ x ),length )</span></code></pre>
<pre><code>## fit1.x fit2.x fit3.x 
##     73     73     73</code></pre>
<p>You will see that there are only 73 data points in each model. The “Clothing” dataset has 400 examples in it. The reason for this reduction is that the “smooth.spline” function only takes unique values from the original dataset. As such, though there are 400 examples in the dataset only 73 of them are unique.</p>
<p>Next, we plot our data and add regression lines</p>
<pre><code><span>plot ( Clothing $ inv2,Clothing $ tsales )</span>
<span>lines ( fit1,col = 'red',lwd = 3 )</span>
<span>lines ( fit2,col = 'green',lwd = 3 )</span>
<span>lines ( fit3,col = 'blue',lwd = 3 )</span>
<span>legend ( 'topright',lty = 1,col = c ( 'red','green','blue' ),c ( "df = 57",'df=7','df=CV 2.8' ) )</span></code></pre>
<p>

<img src="https://educationalresearchtechniques.files.wordpress.com/2017/11/115.png"></p>
<p>You can see that as the degrees of freedom increase so does the flexibility in the line. The advantage of smoothing splines is to have a more flexible way to assess the characteristics of a dataset.</p>

