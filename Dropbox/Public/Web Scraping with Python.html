<base target="_blank">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<style type="text/css">

body {
 font-size: 20px;
 margin: 10%;
 background-color: #000000;
 color: #109030;
}
a { text-decoration: none;
	color: #28B8B8;}
a:visited {	color: #389898;}
A:hover {	color: yellow;}
A:focus {	color: red;}
code { color: gray; background-color: #001800}
pre { color: gray; background-color: #001010}
#newtype { color: pink}
#redpink { color: #cc0099}
#redword { color: red}
#yellowword { color: yellow}
#greenword { color: lightgreen}
#limeword { color: #00ff00}
#orangeword { color: orange}
#cyanword { color: cyan}
#whiteword { color: white}
#grayword { color: gray}
#brownword { color: #ff8000}
#yellowgreen { color: #bfff00}
#palered { color: #ffcccc}
#blueword { color: dodgerblue}
#purpleword { color: darkorchid}
#goldword { color: GoldenRod}
#silverword { color: silver}
#blackword { color: black}
.left {
    position: absolute;
    left: 100px;
    color: GoldenRod;
    border: 1px solid GoldenRod;
    padding: 2px;
    font-size: 60%;
}
.aquacolor {
    color: Aqua;
}
.bord {
    color: redpink;
    border: 1px solid GoldenRod;
    padding: 1px;
    font-size: 90%;
}
.bordsub {
    color: #F07070;
    margin: 3px 90px 3px 90px;
    border: 1px solid darkcyan;
    padding: 1px;
    font-size: 90%;
}
.highlight { 
    color: white;
    background-color: #002030
  }
.redpink { color: .cc0099}
.redword { color: red}
.yellowword { color: yellow}
.greenword { color: lightgreen}
.limeword { color: .00ff00}
.orangeword { color: orange}
.cyanword { color: cyan}
.whiteword { color: white}
.grayword { color: gray}
.brownword { color: #ff8000}
.yellowgreen { color: #bfff00}
.palered { color: #ffcccc}
.blueword { color: dodgerblue}
.purpleword { color: darkorchid}
.goldword { color: GoldenRod}
.silverword { color: silver}
.blackword { color: black}

</STYLE>
<style type="text/css">
#content pre {
  border: 1px dashed #2f6fab;
  padding: 0.5em; background-color: #fafafa;
  overflow:auto;
}
#content pre ol { 
  margin: 0; padding: 0;
  margin-left: 2em; 
}
 
#content pre ol li {
  margin: 0; padding: 0;
  height: 1em;
}
 
/* used for testing...
#content pre ol li div {
  background-color: blue;
  line-height: 1em;
  border: 0; padding: 0;
}*/
</style><!-- Favicon Rotator -->

    <style type="text/css" media="screen">
          div.printfriendly a, div.printfriendly a:link, div.printfriendly a:hover, div.printfriendly a:visited {
            text-decoration: none;
            border: none;
          }
    </style>
</head>
<h1 class="entry-title">A Simple Intro to Web Scraping with Python</h1>
		<div class="entry-content">
		<div class="socialize-in-content socialize-in-content-right"><div class="socialize-in-button socialize-in-button-right"><a href="http://twitter.com/share" class="twitter-share-button" data-counturl="http://www.blog.pythonlibrary.org/2016/08/04/a-simple-intro-to-web-scraping-with-python/" data-url="http://bit.ly/2aT1ivD" data-text="A Simple Intro to Web Scraping with Python" data-count="vertical" data-via="mousevspython" ><!--Tweetter--></a></div><div class="socialize-in-button socialize-in-button-right"></div><div class="socialize-in-button socialize-in-button-right"><div class="g-plusone" data-size="small" data-href="http://www.blog.pythonlibrary.org/2016/08/04/a-simple-intro-to-web-scraping-with-python/"></div></div></div><div class="pf-content"><p>Web scraping is where a programmer will write an application to download web pages and parse out specific information from them. Usually when you are scraping data you will need to make your application navigate the website programmatically. In this chapter, we will learn how to download files from the internet and parse them if need be. We will also learn how to create a simple spider that we can use to crawl a website.</p>

<hr/>
<h3>Preparing to Scrape</h3>
<p>
<p>Before we can start scraping, we need to figure out what we want to do. We will be using my blog for this example. Our task will be to scrape the titles and links to the articles on the front page of this blog. You can use Python&#8217;s <strong>urllib2</strong> module to download the HTML that we need to parse or you can use the <strong>requests</strong> library. For this example, I&#8217;ll be using requests. </p>
<p>Most websites nowadays have pretty complex HTML. Fortunately most browsers provide tools to make figuring out where website elements are quite trivial. For example, if you open my blog in chrome, you can right click on any of the article titles and click the <strong>Inspect</strong> menu option (see below):</p>
<p><img src="http://www.blog.pythonlibrary.org/wp-content/uploads/2016/08/chp19_inspect_element.png" alt="chp19_inspect_element"></p>
<p>Once you&#8217;ve clicked that, you will see a sidebar appear that highlights the tag that contains the title. It looks like this:</p>
<p><img src="http://www.blog.pythonlibrary.org/wp-content/uploads/2016/08/chp19_inspect_window-1024x586.png"></p>
<p>The Mozilla Firefox browser has Developer tools that you can enable on a per page basis that includes an Inspector you can use in much the same way as we did in Chrome. Regardless which web browser you end up using, you will quickly see that the <strong>h1</strong> tag is the one we need to look for. Now that we know what we want to parse, we can learn how to do so!</p>
<hr/>
<h3>BeautifulSoup</h3>
<p>
<p>One of the most popular HTML parsers for Python is called <strong>BeautifulSoup</strong>. It&#8217;s been around for quite some time and is known for being able to handle malformed HTML well. To install it for Python 3, all you need to do is the following:</p>
<pre class="python">pip install beautifulsoup4</pre>
<p>If everything worked correctly, you should now have BeautifulSoup installed. When passing BeautifulSoup some HTML to parse, you can specify a tree builder. For this example we will use <strong>html.parser</strong>, because it is included with Python. If you&#8217;d like something faster, you can install lxml. </p>
<p>Let&#8217;s actually take a look at some code to see how this all works:</p>
<pre class="python"><span style="color: #ff7700;font-weight:bold;">import</span> requests
<span style="color: #ff7700;font-weight:bold;">from</span> bs4 <span style="color: #ff7700;font-weight:bold;">import</span> BeautifulSoup
&nbsp;
&nbsp;
url = <span style="color: #483d8b;">'http://www.blog.pythonlibrary.org/'</span>
&nbsp;
<span style="color: #ff7700;font-weight:bold;">def</span> get_articles<span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>:
    <span style="color: #483d8b;">&quot;&quot;</span><span style="color: #483d8b;">&quot;
    Get the articles from the front page of the blog
    &quot;</span><span style="color: #483d8b;">&quot;&quot;</span>
    req = requests.<span style="color: black;">get</span><span style="color: black;">&#40;</span>url<span style="color: black;">&#41;</span>
    html = req.<span style="color: black;">text</span>
    soup = BeautifulSoup<span style="color: black;">&#40;</span>html, <span style="color: #483d8b;">'html.parser'</span><span style="color: black;">&#41;</span>
    pages = soup.<span style="color: black;">findAll</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">'h1'</span><span style="color: black;">&#41;</span>
&nbsp;
    articles = <span style="color: black;">&#123;</span>i.<span style="color: black;">a</span><span style="color: black;">&#91;</span><span style="color: #483d8b;">'href'</span><span style="color: black;">&#93;</span>: i.<span style="color: black;">text</span>.<span style="color: black;">strip</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
                <span style="color: #ff7700;font-weight:bold;">for</span> i <span style="color: #ff7700;font-weight:bold;">in</span> pages <span style="color: #ff7700;font-weight:bold;">if</span> i.<span style="color: black;">a</span><span style="color: black;">&#125;</span>
    <span style="color: #ff7700;font-weight:bold;">for</span> article <span style="color: #ff7700;font-weight:bold;">in</span> articles:
        s = <span style="color: #483d8b;">'{title}: {url}'</span>.<span style="color: black;">format</span><span style="color: black;">&#40;</span>
            title=articles<span style="color: black;">&#91;</span>article<span style="color: black;">&#93;</span>,
            url=article<span style="color: black;">&#41;</span>
        <span style="color: #ff7700;font-weight:bold;">print</span><span style="color: black;">&#40;</span>s<span style="color: black;">&#41;</span>
&nbsp;
    <span style="color: #ff7700;font-weight:bold;">return</span> articles
&nbsp;
<span style="color: #ff7700;font-weight:bold;">if</span> __name__ == <span style="color: #483d8b;">'__main__'</span>:
    articles = get_articles<span style="color: black;">&#40;</span><span style="color: black;">&#41;</span></pre>
<p>Here we do out imports and set up what URL we are going to use. Then we create a function where the magic happens. We use the requests library to get the URL and then pull the HTML out as a string using the request object&#8217;s <strong>text</strong> property. Then we pass the HTML to BeautifulSoup which turns it into a nice object. After that, we ask BeautifulSoup to find all the instances of <strong>h1</strong> and then use a dictionary comprehension to extract the title and URL. We then print that information to stdout and return the dictionary.</p>
<p>Let&#8217;s try to scrape another website. This time we will look at Twitter and use my blog&#8217;s account: mousevspython. We will try to scrape what I have tweeted recently. You will need to follow the same steps as before by right-clicking on a tweet and inspecting it to figure out what we need to do. In this case, we need to look for the &#8216;li&#8217; tag and the js-stream-item class. Let&#8217;s take a look:</p>
<pre class="python"><span style="color: #ff7700;font-weight:bold;">import</span> requests
&nbsp;
<span style="color: #ff7700;font-weight:bold;">from</span> bs4 <span style="color: #ff7700;font-weight:bold;">import</span> BeautifulSoup
&nbsp;
url = <span style="color: #483d8b;">'https://twitter.com/mousevspython'</span>
req = requests.<span style="color: black;">get</span><span style="color: black;">&#40;</span>url<span style="color: black;">&#41;</span>
html = req.<span style="color: black;">text</span>
soup = BeautifulSoup<span style="color: black;">&#40;</span>html, <span style="color: #483d8b;">'html.parser'</span><span style="color: black;">&#41;</span>
tweets = soup.<span style="color: black;">findAll</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">'li'</span>, <span style="color: #483d8b;">'js-stream-item'</span><span style="color: black;">&#41;</span>
<span style="color: #ff7700;font-weight:bold;">for</span> item <span style="color: #ff7700;font-weight:bold;">in</span> <span style="color: #008000;">range</span><span style="color: black;">&#40;</span><span style="color: #008000;">len</span><span style="color: black;">&#40;</span>soup.<span style="color: black;">find_all</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">'p'</span>, <span style="color: #483d8b;">'TweetTextSize'</span><span style="color: black;">&#41;</span><span style="color: black;">&#41;</span><span style="color: black;">&#41;</span>:
    tweet_text = tweets<span style="color: black;">&#91;</span>item<span style="color: black;">&#93;</span>.<span style="color: black;">get_text</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
    <span style="color: #ff7700;font-weight:bold;">print</span><span style="color: black;">&#40;</span>tweet_text<span style="color: black;">&#41;</span>
    dt = tweets<span style="color: black;">&#91;</span>item<span style="color: black;">&#93;</span>.<span style="color: black;">find</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">'a'</span>, <span style="color: #483d8b;">'tweet-timestamp'</span><span style="color: black;">&#41;</span>
    <span style="color: #ff7700;font-weight:bold;">print</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">'This was tweeted on '</span> + dt<span style="color: black;">&#41;</span></pre>
<p>As before, we use BeautifulSoup&#8217;s <strong>findAll</strong> command to grab all the instances that match our search criteria. Then we also look for the paragraph tag (i.e. &#8216;p&#8217;) and the <strong>TweetTextSize</strong> class and loop over the results. You will note that we used <strong>find_all</strong> here. Just so we&#8217;re clear, findAll is an alias of find_all, so they do the exact same thing. Anyway, we loop over those results and grab the tweet text and the tweet timestamp and print them out. </p>
<p>You would think that there might be an easier way to do this sort of thing and there is. Some websites provide a developer API that you can use to access their website&#8217;s data. Twitter has a nice one that requires a consumer key and a secret. We will actually be looking at how to use that API and a couple of others in the next chapter.</p>
<p>Let&#8217;s move on and learn how to write a spider!</p>
<hr/>
<h3>Scrapy</h3>
<p>
<p>Scrapy is a framework that you can use for crawling websites and extracting (i.e. scraping) data. It can also be used to extract data via a website&#8217;s API or as a general purpose web crawler. To install Scrapy, all you need is pip:</p>
<pre class="python">pip install scrapy</pre>
<p>According to Scrapy&#8217;s documentation, you will also need lxml and OpenSSL installed. We are going to use Scrapy to do the same thing that we used BeautifulSoup for, which was scraping the title and link of the articles on my blog&#8217;s front page. To get started, all you need to do open up a terminal and change directories to the one that you want to store our project in. Then run the following command:</p>
<pre class="python">scrapy startproject blog_scraper</pre>
<p>This will create a directory named <strong>blog_scraper</strong> in the current directory which will contain the following items:</p>
<ul>
<li> Another nested blog_scraper folder </li>
<li>scrapy.cfg</li>
</ul>
<p>Inside of the second blog_scraper folder is where the good stuff is:</p>
<ul>
<li>A spiders folder</li>
<li>__init__.py</li>
<li>items.py</li>
<li>pipelines.py</li>
<li>settings.py</li>
</ul>
<p>We can go with the defaults for everything except <strong>items.py</strong>. So open up <strong>items.py</strong> in your favorite Python editor and add the following code:</p>
<pre class="python"><span style="color: #ff7700;font-weight:bold;">import</span> scrapy
&nbsp;
&nbsp;
<span style="color: #ff7700;font-weight:bold;">class</span> BlogScraperItem<span style="color: black;">&#40;</span>scrapy.<span style="color: black;">Item</span><span style="color: black;">&#41;</span>:
    title = scrapy.<span style="color: black;">Field</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
    link = scrapy.<span style="color: black;">Field</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span></pre>
<p>What we are doing here is creating a class that models what it is that we want to capture, which in this case is a series of titles and links. This is kind of like SQLAlchemy&#8217;s model system in which we would create a model of a database. In Scrapy, we create a model of the data we want to scrape. </p>
<p>Next we need to create a spider, so change directories into the <strong>spiders</strong> directory and create a Python file there. Let&#8217;s just call it <strong>blog.py</strong>. Put the following code inside of your newly created file:</p>
<pre class="python"><span style="color: #ff7700;font-weight:bold;">from</span> scrapy.<span style="color: black;">spider</span> <span style="color: #ff7700;font-weight:bold;">import</span> BaseSpider
<span style="color: #ff7700;font-weight:bold;">from</span> scrapy.<span style="color: black;">selector</span> <span style="color: #ff7700;font-weight:bold;">import</span> Selector
<span style="color: #ff7700;font-weight:bold;">from</span> ..<span style="color: black;">items</span> <span style="color: #ff7700;font-weight:bold;">import</span> BlogScraperItem
&nbsp;
&nbsp;
<span style="color: #ff7700;font-weight:bold;">class</span> MyBlogSpider<span style="color: black;">&#40;</span>BaseSpider<span style="color: black;">&#41;</span>:
    name = <span style="color: #483d8b;">'mouse'</span>
    start_urls = <span style="color: black;">&#91;</span><span style="color: #483d8b;">'http://blog.pythonlibrary.org'</span><span style="color: black;">&#93;</span>
&nbsp;
    <span style="color: #ff7700;font-weight:bold;">def</span> parse<span style="color: black;">&#40;</span><span style="color: #008000;">self</span>, response<span style="color: black;">&#41;</span>:
        selector = Selector<span style="color: black;">&#40;</span>response<span style="color: black;">&#41;</span>
        blog_titles = selector.<span style="color: black;">xpath</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">&quot;//h1[@class='entry-title']&quot;</span><span style="color: black;">&#41;</span>
        selections = <span style="color: black;">&#91;</span><span style="color: black;">&#93;</span>
&nbsp;
        <span style="color: #ff7700;font-weight:bold;">for</span> data <span style="color: #ff7700;font-weight:bold;">in</span> blog_titles:
            selection = BlogScraperItem<span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
            selection<span style="color: black;">&#91;</span><span style="color: #483d8b;">'title'</span><span style="color: black;">&#93;</span> = data.<span style="color: black;">xpath</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">&quot;a/text()&quot;</span><span style="color: black;">&#41;</span>.<span style="color: black;">extract</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
            selection<span style="color: black;">&#91;</span><span style="color: #483d8b;">'link'</span><span style="color: black;">&#93;</span> = data.<span style="color: black;">xpath</span><span style="color: black;">&#40;</span><span style="color: #483d8b;">&quot;a/@href&quot;</span><span style="color: black;">&#41;</span>.<span style="color: black;">extract</span><span style="color: black;">&#40;</span><span style="color: black;">&#41;</span>
            selections.<span style="color: black;">append</span><span style="color: black;">&#40;</span>selection<span style="color: black;">&#41;</span>
&nbsp;
        <span style="color: #ff7700;font-weight:bold;">return</span> selections</pre>
<p>Here we just import the <strong>BaseSpider</strong> class and a <strong>Selector</strong> class. We also import our <strong>BlogScraperItem</strong> class that we created earlier. Then we subclass BaseSpider and name our spider <strong>mouse</strong> since the name of my blog is The Mouse Vs the Python. We also give it a start URL. Note that this is a list which means that you could give this spider multiple start URLs. The most important piece is our <strong>parse</strong> function. It will take the responses it gets from the website and parse them. </p>
<p>Scrapy supports using CSS expressions or XPath for selecting certain parts of an HTML document. This basically tells Scrapy what it is that we want to scrape. XPath is a bit harder to read, but it&#8217;s also the most powerful, so we&#8217;ll be using it for this example. To grab the titles, we can use Google Chrome&#8217;s Inspector tool to figure out that the titles are located inside an <strong>h1</strong> tag with a class name of <strong>entry-title</strong>.</p>
<p>The selector returns an a <strong>SelectorList</strong> instance that we can iterate over. This allows us to continue to make xpath queries on each item in this special list, so we can extract the title text and the link. We also create a new instance of our BlogScraperItem and insert the title and link that we extracted into that new object. Finally we append our newly scraped data into a list which we return when we&#8217;re done.</p>
<p>To run this code, go back up to the top level folder which contained the nested blog_scraper folder and config file and run the following command:</p>
<pre class="python">scrapy crawl mouse</pre>
<p>You will notice that we are telling Scrapy to crawl using the <strong>mouse</strong> spider that we created. This command will cause a lot of output to be printed to your screen. Fortunately, Scrapy supports exporting the data into various formats such as CSV, JSON and XML. Let&#8217;s export the data we scraped using the CSV format:</p>
<pre class="python">scrapy crawl mouse -o articles.<span style="color: #dc143c;">csv</span> -t <span style="color: #dc143c;">csv</span></pre>
<p>You will still see a lot of output generated to stdout, but the title and link will be saved to disk in a file called <strong>articles.csv</strong>. </p>
<p>Most crawlers are set up to follow links and crawl the entire website or a series of websites. The crawler in this website wasn&#8217;t created that way, but that would be a fun enhancement that you can add on your own.</p>
<hr/>
<h3>Wrapping Up</h3>
<p>
<p>Scraping data from the internet is challenging and fun. Python has many libraries that can make this chore quite easy. We learned about how we can use BeautifulSoup to scrape data from a blog and from Twitter. Then we learned about one of the most popular libraries for creating a web crawler / scraper in Python: Scrapy. We barely scratched the surface of what these libraries can do, so you are encouraged to spend some time reading their respective documentation for further details.</p>
<hr/>
<h3>Related Reading</h3>
<p>
<ul>
<li>Idiot Inside &#8211; <a href="http://www.idiotinside.com/2016/05/23/get-android-app-download-count-google-play-store/" target="_blank">Get android app downloads count and rating from Google Play Store</a></li>
<li>The Scraping Hub &#8211; <a href="https://blog.scrapinghub.com/2016/05/25/data-extraction-with-scrapy-and-python-3/" target="_blank">Data Extraction with Scrapy and Python 3</a></li>
<li>Dan Nguyen &#8211; <a href="http://blog.danwin.com/examples-of-web-scraping-in-python-3-x-for-data-journalists/" target="_blank">Python 3 web-scraping examples with public data</a></li>
<li>First Web Scraper <a href="https://first-web-scraper.readthedocs.io/en/latest/" target="_blank">tutorial</a></li>
<li><a href="http://www.analyticsvidhya.com/blog/2015/10/beginner-guide-web-scraping-beautiful-soup-python/" target="_blank">Beginnerâ€™s guide to Web Scraping in Python (using BeautifulSoup)</a></li>
<li>Greg Reda &#8211; <a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/" target="_blank">Web Scraping 101 with Python</a></li>
<li>Miguel Grinberg &#8211; <a href="http://blog.miguelgrinberg.com/post/easy-web-scraping-with-python" target="_blank">Easy Web Scraping with Python</a></li>
<li>The Hitchhiker&#8217;s Guide to Python &#8211; <a href="http://docs.python-guide.org/en/latest/scenarios/scrape/" target="_blank">HTML Scraping</a></li>
<li>Real Python &#8211; <a href="https://realpython.com/blog/python/web-scraping-and-crawling-with-scrapy-and-mongodb/" target="_blank">Web Scraping and Crawling With Scrapy and MongoDB </a>
</ul>

</body>
</html>