<!doctype html>
<head lang="en-US">
<style type="text/css">

body {
 margin: 10%;
 background-color: #000000;
 font-size: 16px;
 color: #109030;
}
a { text-decoration: none;
	color: #28B8B8;}
a:visited {	color: #389898;}
A:hover {	color: yellow;}
A:focus {	color: red;}
code { color: pink; background-color: #302030}
pre { color: gray; background-color: #001010}
#newtype { color: pink}
#redpink { color: #cc0099}
#redword { color: red}
#yellowword { color: yellow}
#greenword { color: lightgreen}
#limeword { color: #00ff00}
#orangeword { color: orange}
#cyanword { color: cyan}
#whiteword { color: white}
#grayword { color: gray}
#brownword { color: #ff8000}
#yellowgreen { color: #bfff00}
#palered { color: #ffcccc}
#blueword { color: dodgerblue}
#purpleword { color: darkorchid}
#goldword { color: GoldenRod}
#silverword { color: silver}
#blackword { color: black}
.left {
    position: absolute;
    left: 100px;
    color: GoldenRod;
    border: 1px solid GoldenRod;
    padding: 2px;
    font-size: 60%;
}
.aquacolor {
    color: Aqua;
}
.bord {
    color: redpink;
    border: 1px solid GoldenRod;
    padding: 1px;
    font-size: 90%;
}
.bordsub {
    color: #F07070;
    margin: 3px 90px 3px 90px;
    border: 1px solid darkcyan;
    padding: 1px;
    font-size: 90%;
}
.highlight { 
    color: white;
    background-color: #002030
  }
.redpink { color: .cc0099}
.redword { color: red}
.yellowword { color: yellow}
.greenword { color: lightgreen}
.limeword { color: .00ff00}
.orangeword { color: orange}
.cyanword { color: cyan}
.whiteword { color: white}
.grayword { color: gray}
.brownword { color: #ff8000}
.yellowgreen { color: #bfff00}
.palered { color: #ffcccc}
.blueword { color: dodgerblue}
.purpleword { color: darkorchid}
.goldword { color: GoldenRod}
.silverword { color: silver}
.blackword { color: black}

</STYLE>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script>
$(document).ready(function(){
    $('.left').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
</head>
<body>

<div id="toc"></div>

<h2>Introduction</h2>
<p style="text-align: justify;">The need and importance of extracting data from the web is becoming increasingly loud and clear. Every few weeks, I find myself in a situation where we need to extract data from the web. For example, last week we were thinking of creating an index of hotness and sentiment about various data science courses available on the internet. This would not only require finding out new courses, but also scrape the web for their reviews and then summarizing them in a few metrics! This is one of the problems / products, whose efficacy depends more on web scrapping and information extraction (data collection) than the techniques used to summarize the data.</p>
<p>&nbsp;</p>
<h2>Ways to extract information from web</h2>
<p style="text-align: justify;">There are several ways to extract information from the web. Use of <a href="https://en.wikipedia.org/wiki/Application_programming_interface" target="_blank" rel="nofollow">API</a>s being probably the best way to extract data from a website. Almost all large websites like Twitter, Facebook, Google, Twitter, StackOverflow provide APIs to access their data in a more structured manner. <strong>If you can get what you need through an API, it is almost always preferred approach over web scrapping.</strong> This is because if you are getting access to structured data from the provider, why would you want to create an engine to extract the same information.</p>
<p style="text-align: justify;">Sadly, not all websites provide an API. Some do it because they do not want the readers to extract huge information in structured way, while others don&#8217;t provide APIs due to lack of technical knowledge. What do you do in these cases? Well, we need to scrape the website to fetch the information.</p>
<p style="text-align: justify;">There might be a few other ways like RSS feeds, but they are limited in their use and hence I am not including them in the discussion here.</p>

<p style="text-align: justify;">For those of you, who need a non-programming way to extract information out of web pages, you can also look at <a href="https://import.io/" target="_blank" rel="nofollow">import.io</a> . It provides a GUI driven interface to perform all basic web scraping operations. The hackers can continue to read this article!</p>
<p>&nbsp;</p>
<h2 style="text-align: justify;">Libraries required for web scraping</h2>
<p style="text-align: justify;">As we know, python is a open source programming language. You may find many libraries to perform one function. Hence, it is necessary to find the best to use library. I prefer <strong>BeautifulSoup</strong> (python library), since it is easy and intuitive to work on. Precisely, I&#8217;ll use two Python modules for scraping data:</p>
<ul style="text-align: justify;">
<li><strong>Urllib2</strong>: It is a Python module which can be used for fetching URLs. It defines functions and classes to help with URL actions (basic and digest authentication, redirections, cookies, etc). For more detail refer to the <a href="https://docs.python.org/2/library/urllib2.html" target="_blank" rel="nofollow">documentation page</a>.</li>
<li><strong>BeautifulSoup:</strong> It is an incredible tool for pulling out information from a webpage. You can use it to extract tables, lists, paragraph and you can also put filters to extract information from web pages. In this article, we will use latest version BeautifulSoup 4. You can look at the installation instruction in its <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="nofollow">documentation page</a>.</li>
</ul>
<p style="text-align: justify;">BeautifulSoup does not fetch the web page for us. That&#8217;s why, I use urllib2 in combination with the BeautifulSoup library.</p>
<p style="text-align: justify;">Python has several other options for HTML scraping in addition to BeatifulSoup. Here are some others:</p>
<ul style="text-align: justify;">
<li><a href="http://wwwsearch.sourceforge.net/mechanize/" rel="nofollow">mechanize</a></li>
<li><a href="http://arshaw.com/scrapemark/" rel="nofollow">scrapemark</a></li>
<li><a href="http://scrapy.org/" rel="nofollow">scrapy</a></li>
</ul>
<p>&nbsp;</p>
<h2>Scrapping a web Page using BeautifulSoup</h2>
<p style="text-align: justify;">Here, I am scraping data from a <a href="https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India" target="_blank" rel="nofollow">Wikipedia page</a>. Our final goal is to extract list of state, union territory capitals in India. And some basic detail like establishment, former capital and others form this <a href="https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India" target="_blank" rel="nofollow">wikipedia page</a>. Let&#8217;s learn with doing this project step wise step:</p>
<ol style="text-align: justify;">
<li><strong><strong>Import necessary libraries:<br />
</strong></strong></li>
</ol>
<pre>#import the library used to query a website
import urllib2</pre>
<pre>#specify the url
wiki = "https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India"</pre>
<pre>#Query the website and return the html to the variable 'page'
page = urllib2.urlopen(wiki)</pre>
<pre>#import the Beautiful soup functions to parse the data returned from the website
from bs4 import BeautifulSoup</pre>
<pre>#Parse the html in the 'page' variable, and store it in Beautiful Soup format
soup = BeautifulSoup(page)</pre>
<ol start="2">
<li><strong>Use function &#8220;prettify&#8221; to look at nested structure of HTML page<br />
</strong> <a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/FirstP.png"><img class="wp-image-20952 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/FirstP.png"></a>Above, you can see that structure of the HTML tags. This will help you to know about different available tags and how can you play with these to extract information.</li>
</ol>
<p>&nbsp;</p>
<ol start="3">
<li><strong>Work with HTML tags</strong></li>
</ol>
<ol type="a">
<li><strong>soup.&lt;tag&gt;: </strong>Return content between opening and closing tag including tag.
<pre>In[30]:soup.title
Out[30]:&lt;title&gt;List of state and union territory capitals in India - Wikipedia, the free encyclopedia&lt;/title&gt;</pre>
</li>
<li><strong>soup.&lt;tag&gt;.string: </strong>Return string within given tag
<pre class="prompt input_prompt">In [38]:<span class="cm-variable">soup</span>.<span class="cm-variable">title</span>.<span class="cm-variable">string</span>
Out[38]:u'List of state and union territory capitals in India - Wikipedia, the free encyclopedia'
</pre>
</li>
<li><strong>Find all the links within page’s &lt;a&gt; tags:: </strong> We know that, we can tag a link using tag &#8220;&lt;a&gt;&#8221;. So, we should go with option <strong>soup.a</strong> and it should return the links available in the web page. Let&#8217;s do it.
<pre class="prompt input_prompt">In [40]:<span class="cm-variable">soup</span>.<span class="cm-variable">a</span> 
Out[40]:&lt;a id="top"&gt;&lt;/a&gt;</pre>
<p>Above, you can see that, we have only one output. Now to extract all the links within &lt;a&gt;, we will use &#8220;<strong>find_all().<br />
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/All_Links.png"><img class="aligncenter wp-image-20953 " src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/All_Links-1024x268.png"></a></strong>Above, it is showing all links including titles, links and other information.  Now to show only links, we need to iterate over each a tag and then return the link using attribute &#8220;href&#8221; with <strong>get</strong>.<br />
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/All_Links2.png"><img class="aligncenter wp-image-20954 " src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/All_Links2.png"></a></li>
</ol>
<p>&nbsp;</p>
<ol start="4">
<li><strong>Find the right table: </strong>As we are seeking a table to extract information about state capitals, we should identify the right table first. Let&#8217;s write the command to extract information within all <strong>table</strong> tags.
<pre>all_tables=soup.find_all('table')
</pre>
<p>Now to identify the right table, we will use attribute &#8220;class&#8221; of table and use it to filter the right table. In chrome, you can check the class name by right click on the required table of web page &#8211;&gt; Inspect element &#8211;&gt; Copy the class name OR go through the output of above command find the class name of right table.</p>
<pre>right_table=soup.find('table', class_='wikitable sortable plainrowheaders')
right_table
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/righttable.png"><img class="aligncenter wp-image-20955 size-full" src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/righttable.png"></a>Above, we are able to identify right table.</pre>
</li>
<li><strong>Extract the information to DataFrame: </strong>Here, we need to iterate through each row (tr) and then assign each element of tr (td) to a variable and append it to a list. Let&#8217;s first look at the HTML structure of the table (I am not going to extract information for table heading &lt;th&gt;)<br />
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/Structure.png"><img class="aligncenter wp-image-20957 " src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/Structure.png"></a>Above, you can notice that second element of &lt;tr&gt; is within tag &lt;th&gt; not &lt;td&gt; so we need to take care for this. Now to access value of each element, we will use &#8220;find(text=True)&#8221; option with each element.  Let&#8217;s look at the code:</li>
</ol>
<pre>#Generate lists
A=[]
B=[]
C=[]
D=[]
E=[]
F=[]
G=[]
for row in right_table.findAll("tr"):
    cells = row.findAll('td')
    states=row.findAll('th') #To store second column data
    if len(cells)==6: #Only extract table body not heading
        A.append(cells[0].find(text=True))
        B.append(states[0].find(text=True))
        C.append(cells[1].find(text=True))
        D.append(cells[2].find(text=True))
        E.append(cells[3].find(text=True))
        F.append(cells[4].find(text=True))
        G.append(cells[5].find(text=True))</pre>
<pre>#import pandas to convert list to data frame
import pandas as pd
df=pd.DataFrame(A,columns=['Number'])
df['State/UT']=B
df['Admin_Capital']=C
df['Legislative_Capital']=D
df['Judiciary_Capital']=E
df['Year_Capital']=F
df['Former_Capital']=G
df
</pre>
<p style="text-align: justify;">Finally, we have data in dataframe:<br />
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/Output.png"><img class="aligncenter wp-image-20958 " src="https://www.analyticsvidhya.com/wp-content/uploads/2015/10/Output.png"></a><br />
Similarly, you can perform various other types of web scraping using &#8220;<strong>BeautifulSoup</strong>&#8220;. This will reduce your manual efforts to collect data from web pages. You can also look at the other attributes like .parent, .contents, .descendants and .next_sibling, .prev_sibling and various attributes to navigate using tag name. These will help you to scrap the web pages effectively.-</p>
<p>&nbsp;</p>
<h2>But, why can&#8217;t I just use Regular Expressions?</h2>
<p style="text-align: justify;">Now, if you know <a href="https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/" target="_blank">regular expressions</a>, you might be thinking that you can write code using regular expression which can do the same thing for you. I definitely had this question. In my experience with BeautifulSoup and Regular expressions to do same thing I found out:</p>
<ul>
<li style="text-align: justify;">Code written in BeautifulSoup is usually more robust than the one written using regular expressions. Codes written with regular expressions need to be altered with any changes in pages. Even BeautifulSoup needs that in some cases, it is just that BeautifulSoup is relatively better.</li>
<li style="text-align: justify;">Regular expressions are much faster than BeautifulSoup, usually by a factor of 100 in giving the same outcome.</li>
</ul>
<p style="text-align: justify;">So, it boils down to speed vs. robustness of the code and there is no universal winner here. If the information you are looking for can be extracted with simple regex statements, you should go ahead and use them. For almost any complex work, I usually recommend BeautifulSoup more than regex.</p>
<br>
<h2>Index</h2>
<div id="Idx"></div>

<script>
  $(function() {
    var toc = $('#toc');

    function makeLi(text, href) {
      return $('<a href="' + href + '" target="_self">' + text + '</a><br>');
    }

    $('h2').each(function(i) {
      var chapter = $(this), chapterNumber = i + 1;
      toc.append(
        makeLi(chapter.text(), '#chapter-' + chapterNumber)
      );
      chapter.attr('id', 'chapter-' + chapterNumber);
    });

  });
</script>
<script>
$(document).ready(function(){
    $('h2').click(function(){
    parent.history.back();
    return false;
    });
});
</script>
<script>
  $(function() {
    var toc = $('#Idx');

    function makeLi(text, href) {
      return $('<a href="' + href + '" target="_self">' + text + '</a><br>');
    }

    $('strong').each(function(i) {
      var chapter = $(this), chapterNumber = i + 1;
      toc.append(
        makeLi(chapter.text(), '#chapter-' + chapterNumber)
      );
      chapter.attr('id', 'chapter-' + chapterNumber);
    });

  });
</script>

</body>
</html>
