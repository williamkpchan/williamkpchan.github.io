<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><base target=_blank><style>body { margin: 10%; font-size: 24px; background-color: #000000; color: #109030;}a { text-decoration: none; color: #28B8B8;}a:visited { color: #389898;}A:hover { color: yellow;}A:focus { color: red;}code { color: pink; background-color: #001500}pre { color: gray; background-color: #001010}</style>
	<h1 itemprop="name" class="entry-title">A Complete Tutorial to Learn Data Science with Python from Scratch</h1>
	

<h2>Table of Contents</h2>
<ol>
<li>Python libraries and data structures
<ul>
<li>Python Data Structures</li>
<li>Python Iteration and Conditional Constructs</li>
<li>Python Libraries</li>
</ul>
</li>
<li>Exploratory analysis in Python using Pandas
<ul>
<li>Introduction to series and dataframes</li>
<li>Analytics Vidhya dataset- Loan Prediction Problem</li>
</ul>
</li>
<li>Data Munging in Python using Pandas</li>
<li>Building a Predictive Model in Python
<ul>
<li>Logistic Regression</li>
<li>Decision Tree</li>
<li>Random Forest</li>
</ul>
</li>
</ol>


<h2>2. Python libraries and Data Structures</h2>
<h3>Python Data Structures</h3>
<p>Following are some data structures, which are used in Python. You should be familiar with them in order to use them as appropriate.</p>
<ul>
<li style="text-align: justify;"><strong>Lists</strong> &#8211; Lists are one of the most versatile data structure in Python. A list can simply be defined by writing a list of comma separated values in square brackets. <span style="color: #000000;">Lists might contain items of different types, but usually the items all have the same type. Python lists are mutable and individual elements of a list can be changed.</span></li>
</ul>
<p style="padding-left: 30px;">Here is a quick example to define a list and then access it:</p>
<img class="aligncenter size-full wp-image-4944" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/python_lists.png"></p>
<ul>
<li style="text-align: justify;"><strong>Strings</strong> &#8211; Strings can simply be defined by use of single ( &#8216; ), double ( &#8221; ) or triple ( &#8221;&#8217; ) inverted commas. Strings enclosed in tripe quotes ( &#8221;&#8217; ) can span over multiple lines and are used frequently in docstrings (Python&#8217;s way of documenting functions). \ is used as an escape character. Please note that Python strings are immutable, so you can not change part of strings.</li>
</ul>
<img src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/python_strings.png" alt="python_strings"
<ul>
<li style="text-align: justify;"><strong>Tuples</strong> &#8211; <span style="color: #4b4b4b;">A tuple is represented by a number of values separated by commas. Tuples are immutable and the output is surrounded by parentheses so that nested tuples are processed correctly. Additionally, even though tuples are immutable, they can hold mutable data if needed.</span></li>
</ul>
<p style="padding-left: 30px; text-align: justify;">Since Tuples are immutable and can not change, they are faster in processing as compared to lists. Hence, if your list is unlikely to change, you should use tuples, instead of lists.</p>
<p style="padding-left: 30px;"><a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/Python_tuples.png"><img class="aligncenter size-full wp-image-4946" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/Python_tuples.png" alt="Python_tuples" width="868" height="449" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2014/07/Python_tuples.png 868w, https://www.analyticsvidhya.com/wp-content/uploads/2014/07/Python_tuples-300x155.png 300w" sizes="(max-width: 868px) 100vw, 868px" /></a></p>
<ul>
<li><strong>Dictionary &#8211; </strong>D<span style="color: #000000;">ictionary is an unordered set of </span><em style="color: #000000;">key: value</em><span style="color: #000000;"> pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: </span><tt class="docutils literal" style="color: #000000;"><span class="pre">{}</span></tt><span style="color: #000000;">.</span><strong><span style="color: #000000;"> </span></strong></li>
</ul>
<p style="padding-left: 30px;"><a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/Python_dictionary.png"><img class="aligncenter size-full wp-image-4949" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/07/Python_dictionary.png" alt="Python_dictionary" width="995" height="347" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2014/07/Python_dictionary.png 995w, https://www.analyticsvidhya.com/wp-content/uploads/2014/07/Python_dictionary-300x104.png 300w" sizes="(max-width: 995px) 100vw, 995px" /></a></p>
<h3>Python Iteration and Conditional Constructs</h3>
<p style="text-align: justify;">Like most languages, Python also has a FOR-loop which is the most widely used method for iteration. It has a simple syntax:</p>
<pre>for i in [Python Iterable]:
  expression(i)</pre>
<p style="text-align: justify;">Here &#8220;Python Iterable&#8221; can be a list, tuple or other advanced data structures which we will explore in later sections. Let&#8217;s take a look at a simple example, determining the factorial of a number.</p>
<pre>fact=1
for i in range(1,N+1):
  fact *= i</pre>
<p style="text-align: justify;">Coming to conditional statements, these are used to execute code fragments based on a condition. The most commonly used construct is if-else, with following syntax:</p>
<pre>if [condition]:
  __execution if true__
else:
  __execution if false__</pre>
<p>For instance, if we want to print whether the number N is even or odd:</p>
<pre>if N%2 == 0:
  print 'Even'
else:
  print 'Odd'</pre>
<p style="text-align: justify;">Now that you are familiar with Python fundamentals, let&#8217;s take a step further. What if you have to perform the following tasks:</p>
<ol>
<li>Multiply 2 matrices</li>
<li>Find the root of a quadratic equation</li>
<li>Plot bar charts and histograms</li>
<li>Make statistical models</li>
<li>Access web-pages</li>
</ol>
<p style="text-align: justify;">If you try to write code from scratch, its going to be a nightmare and you won&#8217;t stay on Python for more than 2 days! But lets not worry about that. Thankfully, there are many libraries with predefined which we can directly import into our code and make our life easy.</p>
<p>For example, consider the factorial example we just saw. We can do that in a single step as:</p>
<pre>math.factorial(N)</pre>
<p>Off-course we need to import the math library for that. Lets explore the various libraries next.</p>
<p>&nbsp;</p>
<h3>Python Libraries</h3>
<p style="text-align: justify;">Lets take one step ahead in our journey to learn Python by getting acquainted with some useful libraries. The first step is obviously to learn to import them into our environment. There are several ways of doing so in Python:</p>
<div id='stb-container-9465' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-9465' class='stb-grey_box stb-box' >
<pre><strong>import</strong> math <strong>as</strong> m</pre>
<pre><strong>from</strong> math <strong>import</strong> *</pre>
</div></div>
<p style="text-align: justify;">In the first manner, we have defined an alias m to library math. We can now use various functions from math library (e.g. factorial) by referencing it using the alias m.factorial().</p>
<p style="text-align: justify;">In the second manner, you have imported the entire name space in math i.e. you can directly use factorial() without referring to math.</p>
<div id='stb-container-3901' class='stb-container-css stb-section-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src=''></aside><div id='stb-box-3901' class='stb-section_box stb-box' > <span style="color: #ffffff;"><strong>Tip: Google recommends that you use first style of importing libraries, as you will know where the functions have come from.</strong></span> </div></div>
<p>Following are a list of libraries, you will need for any scientific computations and data analysis:</p>
<ul>
<li style="text-align: justify;"><strong>NumPy</strong> stands for Numerical Python. The most powerful feature of NumPy is n-dimensional array. This library also contains basic linear algebra functions, Fourier transforms,  advanced random number capabilities and tools for integration with other low level languages like Fortran, C and C++</li>
<li style="text-align: justify;"><strong>SciPy</strong> stands for Scientific Python. SciPy is built on NumPy. It is one of the most useful library for variety of high level science and engineering modules like discrete Fourier transform, Linear Algebra, Optimization and Sparse matrices.</li>
<li style="text-align: justify;"><strong>Matplotlib</strong> for plotting vast variety of graphs, starting from histograms to line plots to heat plots.. You can use Pylab feature in ipython notebook (ipython notebook &#8211;pylab = inline) to use these plotting features inline. If you ignore the inline option, then pylab converts ipython environment to an environment, very similar to Matlab. You can also use Latex commands to add math to your plot.</li>
<li style="text-align: justify;"><strong>Pandas</strong> for structured data operations and manipulations. It is extensively used for data munging and preparation. Pandas were added relatively recently to Python and have been instrumental in boosting Python&#8217;s usage in data scientist community.</li>
<li style="text-align: justify;"><strong>Scikit Learn</strong> for machine learning. Built on NumPy, SciPy and matplotlib, this library contains a lot of effiecient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction.</li>
<li style="text-align: justify;"><strong>Statsmodels</strong> for statistical modeling. <span style="color: #404040;">Statsmodels is a Python module that allows users to explore data, estimate statistical models, and perform statistical tests. An extensive list of descriptive statistics, statistical tests, plotting functions, and result statistics are available for different types of data and each estimator.</span></li>
<li style="text-align: justify;"><strong>Seaborn</strong> for statistical data visualization. Seaborn is a library for making attractive and informative statistical graphics in Python. It is based on matplotlib. Seaborn aims to make visualization a central part of exploring and understanding data.</li>
<li style="text-align: justify;"><strong>Bokeh</strong> for creating interactive plots, dashboards and data applications on modern web-browsers. It empowers the user to generate elegant and concise graphics in the style of D3.js. Moreover, it has the capability of high-performance interactivity over very large or streaming datasets.</li>
<li style="text-align: justify;"><strong>Blaze</strong> for extending the capability of Numpy and Pandas to distributed and streaming datasets. It can be used to access data from a multitude of sources including Bcolz, MongoDB, SQLAlchemy, Apache Spark, PyTables, etc. Together with Bokeh, Blaze can act as a very powerful tool for creating effective visualizations and dashboards on huge chunks of data.</li>
<li style="text-align: justify;"><strong>Scrapy</strong> for web crawling. It is a very useful framework for getting specific patterns of data. It has the capability to start at a website home url and then dig through web-pages within the website to gather information.</li>
<li style="text-align: justify;"><strong>SymPy</strong> for symbolic computation. It has wide-ranging capabilities from basic symbolic arithmetic to calculus, algebra, discrete mathematics and quantum physics. Another useful feature is the capability of formatting the result of the computations as LaTeX code.</li>
<li style="text-align: justify;"><strong>Requests</strong> for accessing the web. It works similar to the the standard python library urllib2 but is much easier to code. You will find subtle differences with urllib2 but for beginners, Requests might be more convenient.</li>
</ul>
<p><strong>Additional libraries, you might need:</strong></p>
<ul>
<li><strong>os</strong> for Operating system and file operations</li>
<li><strong>networkx</strong> and <strong>igraph</strong> for graph based data manipulations</li>
<li><strong>regular expressions</strong> for finding patterns in text data</li>
<li><strong>BeautifulSoup</strong> for scrapping web. It is inferior to Scrapy as it will extract information from just a single webpage in a run.</li>
</ul>
<p style="text-align: justify;">Now that we are familiar with Python fundamentals and additional libraries, lets take a deep dive into problem solving through Python. Yes I mean making a predictive model! In the process, we use some powerful libraries and also come across the next level of data structures. We will take you through the 3 key phases:</p>
<ol>
<li>Data Exploration &#8211; finding out more about the data we have</li>
<li>Data Munging &#8211; cleaning the data and playing with it to make it better suit statistical modeling</li>
<li>Predictive Modeling &#8211; running the actual algorithms and having fun 🙂</li>
</ol>
<p>&nbsp;</p>
<h2>3. Exploratory analysis in Python using Pandas</h2>
<p style="text-align: justify;">In order to explore our data further, let me introduce you to another animal (as if Python was not enough!) &#8211; Pandas</p>
<div id="attachment_5487" style="width: 300px" class="wp-caption aligncenter"><a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/08/pandas.jpg"><img class="wp-image-5487 size-medium" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/08/pandas-300x200.jpg" alt="pandas" width="300" height="200" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2014/08/pandas-300x200.jpg 300w, https://www.analyticsvidhya.com/wp-content/uploads/2014/08/pandas-1024x682.jpg 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a><p class="wp-caption-text">Image Source: Wikipedia</p></div>
<p style="text-align: justify;">Pandas is one of the most useful data analysis library in Python (I know these names sounds weird, but hang on!). They have been instrumental in increasing the use of Python in data science community. We will now use Pandas to read a data set from an Analytics Vidhya competition, perform exploratory analysis and build our first basic categorization algorithm for solving this problem.</p>
<p>Before loading the data, lets understand the 2 key data structures in Pandas &#8211; Series and DataFrames</p>
<p>&nbsp;</p>
<h3>Introduction to Series and Dataframes</h3>
<p style="text-align: justify;">Series can be understood as a 1 dimensional labelled / indexed array. You can access individual elements of this series through these labels.</p>
<p style="text-align: justify;">A dataframe is similar to Excel workbook &#8211; you have column names referring to columns and you have rows, which can be accessed with use of row numbers. The essential difference being that column names and row numbers are known as column and row index, in case of dataframes.</p>
<p style="text-align: justify;">Series and dataframes form the core data model for Pandas in Python. The data sets are first read into these dataframes and then various operations (e.g. group by, aggregation etc.) can be applied very easily to its columns.</p>
<p>More: <a href="http://pandas.pydata.org/pandas-docs/stable/10min.html" target="_blank">10 Minutes to Pandas</a></p>
<p>&nbsp;</p>
<h3>Practice data set &#8211; Loan Prediction Problem</h3>
<p>You can download the dataset from <a href="http://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii" target="_blank" rel="nofollow">here</a>. Here is the description of variables:</p>
<div id='stb-container-2526' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2526' class='stb-grey_box stb-box' >
<pre style="color: #7b7c75;">VARIABLE DESCRIPTIONS:
Variable	          Description
Loan_ID	                  Unique Loan ID
Gender	                  Male/ Female
Married	                  Applicant married (Y/N)
Dependents	          Number of dependents
Education	          Applicant Education (Graduate/ Under Graduate)
Self_Employed	          Self employed (Y/N)
ApplicantIncome	          Applicant income
CoapplicantIncome	  Coapplicant income
LoanAmount	          Loan amount in thousands
Loan_Amount_Term	  Term of loan in months
Credit_History	          credit history meets guidelines
Property_Area	          Urban/ Semi Urban/ Rural
Loan_Status	          Loan approved (Y/N)
</div></div>
</pre>
<p>&nbsp;</p>
<h3>Let&#8217;s begin with exploration</h3>
<p style="text-align: justify;">To begin, start iPython interface in Inline Pylab mode by typing following on your terminal / windows command prompt:</p>
<pre><div id='stb-container-1346' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-1346' class='stb-grey_box stb-box' >ipython notebook --pylab=inline</div></div></pre>
<p style="text-align: justify;">This opens up iPython notebook in pylab environment, which has a few useful libraries already imported. Also, you will be able to plot your data inline, which makes this a really good environment for interactive data analysis. You can check whether the environment has loaded correctly, by typing the following command (and getting the output as seen in the figure below):</p>
<pre><div id='stb-container-4261' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-4261' class='stb-grey_box stb-box' >plot(arange(5))</div></div></pre>
<p style="text-align: left;"><a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/08/ipython_pylab_check.png"><img class="aligncenter size-full wp-image-5507" src="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/08/ipython_pylab_check.png" alt="ipython_pylab_check" width="375" height="253" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2014/08/ipython_pylab_check.png 375w, https://www.analyticsvidhya.com/wp-content/uploads/2014/08/ipython_pylab_check-300x202.png 300w" sizes="(max-width: 375px) 100vw, 375px" /></a></p>
<p style="text-align: left;">I am currently working in Linux, and have stored the dataset in the following location:</p>
<p style="text-align: center;"> /home/kunal/Downloads/Loan_Prediction/train.csv</p>
<p>&nbsp;</p>
<h3>Importing libraries and the data set:</h3>
<p>Following are the libraries we will use during this tutorial:</p>
<ul>
<li>numpy</li>
<li>matplotlib</li>
<li>pandas</li>
</ul>
<p style="text-align: justify;">Please note that you do not need to import matplotlib and numpy because of Pylab environment. I have still kept them in the code, in case you use the code in a different environment.</p>
<p style="text-align: justify;">After importing the library, you read the dataset using function read_csv(). This is how the code looks like till this stage:</p>
<pre><div id='stb-container-4877' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-4877' class='stb-grey_box stb-box' >import pandas as pd
import numpy as np
import matplotlib as plt

df = pd.read_csv("/home/kunal/Downloads/Loan_Prediction/train.csv") #Reading the dataset in a dataframe using Pandas
</div></div></pre>
<p>&nbsp;</p>
<h3>Quick Data Exploration</h3>
<p>Once you have read the dataset, you can have a look at few top rows by using the function head()</p>
<pre><div id='stb-container-8257' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-8257' class='stb-grey_box stb-box' >df.head(10)</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head.png"><img class="wp-image-22446 size-large aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head-1024x390.png" alt="" width="1024" height="390" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head-1024x390.png 1024w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head-300x114.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head-850x324.png 850w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/1.-head.png 1230w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>This should print 10 rows. Alternately, you can also look at more rows by printing the dataset.</p>
<p>Next, you can look at summary of numerical fields by using describe() function</p>
<pre><div id='stb-container-9544' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-9544' class='stb-grey_box stb-box' >df.describe()</div></div></pre>
<p style="text-align: justify;"><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/2.-describe.png"><img class="alignnone wp-image-22448 size-full" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/2.-describe.png" alt="" width="810" height="332" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/2.-describe.png 810w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/2.-describe-300x123.png 300w" sizes="(max-width: 810px) 100vw, 810px" /></a></p>
<p style="text-align: justify;">describe() function would provide count, mean, standard deviation (std), min, quartiles and max in its output (Read <a title="Using statistics: How to understand population distributions?" href="https://www.analyticsvidhya.com/blog/2014/07/statistics/" target="_blank">this article</a> to refresh basic statistics to understand population distribution)</p>
<p style="text-align: justify;">Here are a few inferences, you can draw by looking at the output of describe() function:</p>
<ol style="color: #000000; text-align: justify;">
<li>LoanAmount has (614 – 592) 22 missing values.</li>
<li>Loan_Amount_Term has (614 – 600) 14 missing values.</li>
<li>Credit_History has (614 – 564) 50 missing values.</li>
<li>We can also look that about 84% applicants have a credit_history. How? The mean of Credit_History field is 0.84 (Remember, Credit_History has value 1 for those who have a credit history and 0 otherwise)</li>
<li>The ApplicantIncome distribution seems to be in line with expectation. Same with CoapplicantIncome</li>
</ol>
<p style="text-align: justify;">Please note that we can get an idea of a possible skew in the data by comparing the mean to the median, i.e. the 50% figure.</p>
<p style="text-align: justify;">For the non-numerical values (e.g. Property_Area, Credit_History etc.), we can look at frequency distribution to understand whether they make sense or not. The frequency table can be printed by following command:</p>
<pre><div id='stb-container-3262' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-3262' class='stb-grey_box stb-box' >df['Property_Area'].value_counts()</div></div></pre>
<p>Similarly, we can look at unique values of port of credit history. Note that dfname[&#8216;column_name&#8217;] is a basic indexing technique to acess a particular column of the dataframe. It can be a list of columns as well. For more information, refer to the &#8220;10 Minutes to Pandas&#8221; resource shared above.</p>
<p>&nbsp;</p>
<h3>Distribution analysis</h3>
<p style="text-align: justify;">Now that we are familiar with basic data characteristics, let us study distribution of various variables. Let us start with numeric variables &#8211; namely ApplicantIncome and LoanAmount</p>
<p style="text-align: justify;">Lets start by plotting the histogram of ApplicantIncome using the following commands:</p>
<pre><div id='stb-container-3400' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-3400' class='stb-grey_box stb-box' >df['ApplicantIncome'].hist(bins=50)
</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_6_1.png"><img class="wp-image-22452 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_6_1.png" alt="" width="388" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_6_1.png 388w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_6_1-300x198.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_6_1-258x169.png 258w" sizes="(max-width: 388px) 100vw, 388px" /></a></p>
<p>Here we observe that there are few extreme values. This is also the reason why 50 bins are required to depict the distribution clearly.</p>
<p>Next, we look at box plots to understand the distributions. Box plot for fare can be plotted by:</p>
<pre><div id='stb-container-8106' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-8106' class='stb-grey_box stb-box' >df.boxplot(column='ApplicantIncome')
</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_7_1.png"><img class="wp-image-22453 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_7_1.png" alt="" width="385" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_7_1.png 385w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_7_1-300x199.png 300w" sizes="(max-width: 385px) 100vw, 385px" /></a></p>
<p>This confirms the presence of a lot of outliers/extreme values. This can be attributed to the income disparity in the society. Part of this can be driven by the fact that we are looking at people with different education levels. Let us segregate them by Education:</p>
<pre><div id='stb-container-2189' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2189' class='stb-grey_box stb-box' >df.boxplot(column='ApplicantIncome', by = 'Education')</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_9_1.png"><img class="wp-image-22454 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_9_1.png" alt="" width="395" height="282" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_9_1.png 395w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_9_1-300x214.png 300w" sizes="(max-width: 395px) 100vw, 395px" /></a></p>
<p style="text-align: justify;">We can see that there is no substantial different between the mean income of graduate and non-graduates. But there are a higher number of graduates with very high incomes, which are appearing to be the outliers.</p>
<p>Now, Let&#8217;s look at the histogram and boxplot of LoanAmount using the following command:</p>
<pre><div id='stb-container-6502' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-6502' class='stb-grey_box stb-box' >df['LoanAmount'].hist(bins=50)</div></div></pre>
<pre><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_13_1.png"><img class="size-full wp-image-22455 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_13_1.png" alt="output_13_1" width="375" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_13_1.png 375w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_13_1-300x205.png 300w" sizes="(max-width: 375px) 100vw, 375px" /></a>
 <div id='stb-container-3518' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-3518' class='stb-grey_box stb-box' >df.boxplot(column='LoanAmount')</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_14_1.png"><img class="size-full wp-image-22456 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_14_1.png" alt="output_14_1" width="372" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_14_1.png 372w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_14_1-300x206.png 300w" sizes="(max-width: 372px) 100vw, 372px" /></a></p>
<p style="text-align: justify;">Again, there are some extreme values. Clearly, both ApplicantIncome and LoanAmount require some amount of data munging. LoanAmount has missing and well as extreme values values, while ApplicantIncome has a few extreme values, which demand deeper understanding. We will take this up in coming sections.</p>
<p>&nbsp;</p>
<h3>Categorical variable analysis</h3>
<p style="text-align: justify;">Now that we understand distributions for ApplicantIncome and LoanIncome, let us understand categorical variables in more details. We will use Excel style pivot table and cross-tabulation. For instance, let us look at the chances of getting a loan based on credit history. This can be achieved in MS Excel using a pivot table as:</p>
<p style="text-align: justify;"><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/10.-pivot_table3.png"><img class="wp-image-22534 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/10.-pivot_table3.png" alt="" width="608" height="318" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/10.-pivot_table3.png 608w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/10.-pivot_table3-300x157.png 300w" sizes="(max-width: 608px) 100vw, 608px" /></a></p>
<p style="text-align: justify;">Note: here loan status has been coded as 1 for Yes and 0 for No. So the mean represents the probability of getting loan.</p>
<p style="text-align: justify;">Now we will look at the steps required to generate a similar insight using Python. Please refer to <a href="https://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/">this article</a> for getting a hang of the different data manipulation techniques in Pandas.</p>
<pre><div id='stb-container-9024' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-9024' class='stb-grey_box stb-box' >temp1 = df['Credit_History'].value_counts(ascending=True)
temp2 = df.pivot_table(values='Loan_Status',index=['Credit_History'],aggfunc=lambda x: x.map({'Y':1,'N':0}).mean())
print 'Frequency Table for Credit History:' 
print temp1

print '\nProbility of getting loan for each Credit History class:' 
print temp2</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/11.-pivot_python.png"><img class="size-full wp-image-22535 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/11.-pivot_python.png" alt="11. pivot_python" width="444" height="176" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/11.-pivot_python.png 444w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/11.-pivot_python-300x119.png 300w" sizes="(max-width: 444px) 100vw, 444px" /></a></p>
<p style="text-align: justify;">Now we can observe that we get a similar pivot_table like the MS Excel one. This can be plotted as a bar chart using the &#8220;matplotlib&#8221; library with following code:</p>
<pre><div id='stb-container-2306' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2306' class='stb-grey_box stb-box' >import matplotlib.pyplot as plt
fig = plt.figure(figsize=(8,4))
ax1 = fig.add_subplot(121)
ax1.set_xlabel('Credit_History')
ax1.set_ylabel('Count of Applicants')
ax1.set_title("Applicants by Credit_History")
temp1.plot(kind='bar')

ax2 = fig.add_subplot(122)
temp2.plot(kind = 'bar')
ax2.set_xlabel('Credit_History')
ax2.set_ylabel('Probability of getting loan')
ax2.set_title("Probability of getting loan by credit history")
</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_16_1.png"><img class="wp-image-22458 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_16_1.png" alt="" width="526" height="288" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_16_1.png 526w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_16_1-300x164.png 300w" sizes="(max-width: 526px) 100vw, 526px" /></a></p>
<p style="text-align: justify;">This shows that the chances of getting a loan are eight-fold if the applicant has a valid credit history. You can plot similar graphs by Married, Self-Employed, Property_Area, etc.</p>
<p>Alternately, these two plots can also be visualized by combining them in a stacked chart::</p>
<pre><div id='stb-container-3412' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-3412' class='stb-grey_box stb-box' >temp3 = pd.crosstab(df['Credit_History'], df['Loan_Status'])
temp3.plot(kind='bar', stacked=True, color=['red','blue'], grid=False)</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_17_1.png"><img class="wp-image-22459 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_17_1.png" alt="" width="372" height="278" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_17_1.png 372w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_17_1-300x224.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_17_1-83x63.png 83w" sizes="(max-width: 372px) 100vw, 372px" /></a></p>
<p>You can also add gender into the mix (similar to the pivot table in Excel):</p>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_18_1.png"><img class="wp-image-22460 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_18_1.png" alt="" width="372" height="329" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_18_1.png 372w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/output_18_1-300x265.png 300w" sizes="(max-width: 372px) 100vw, 372px" /></a></p>
<p style="text-align: justify;">If you have not realized already, we have just created two basic classification algorithms here, one based on credit history, while other on 2 categorical variables (including gender). You can quickly code this to create your first submission on AV Datahacks.</p>
<p style="text-align: justify;">We just saw how we can do exploratory analysis in Python using Pandas. I hope your love for pandas (the animal) would have increased by now &#8211; given the amount of help, the library can provide you in analyzing datasets.</p>
<p style="text-align: justify;">Next let&#8217;s explore ApplicantIncome and LoanStatus variables further, <a title="Data Munging in Python (using Pandas) – Baby steps in Python" href="https://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/" target="_blank">perform data munging</a> and create a dataset for applying various modeling techniques. I would strongly urge that you take another dataset and problem and go through an independent example before reading further.</p>
<p>&nbsp;</p>
<h2>4. Data Munging in Python : Using Pandas</h2>
<p style="text-align: justify;">For those, who have been following, here are your must wear shoes to start running.<a href="https://www.analyticsvidhya.com/blog/wp-content/uploads/2014/09/Orange-Shoes.jpg"><br />
</a></p>
<h3>Data munging &#8211; recap of the need</h3>
<p style="text-align: justify;">While our exploration of the data, we found a few problems in the data set, which needs to be solved before the data is ready for a good model. This exercise is typically referred as &#8220;Data Munging&#8221;. Here are the problems, we are already aware of:</p>
<ol style="text-align: justify;">
<li>There are missing values in some variables. We should estimate those values wisely depending on the amount of missing values and the expected importance of variables.</li>
<li>While looking at the distributions, we saw that ApplicantIncome and LoanAmount seemed to contain extreme values at either end. Though they might make intuitive sense, but should be treated appropriately.</li>
</ol>
<p style="text-align: justify;">In addition to these problems with numerical fields, we should also look at the non-numerical fields i.e. Gender, Property_Area, Married, Education and Dependents to see, if they contain any useful information.</p>
<p style="text-align: justify;">If you are new to Pandas, I would recommend reading <a href="https://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/" target="_blank">this article</a> before moving on. It details some useful techniques of data manipulation.</p>
<p>&nbsp;</p>
<h3>Check missing values in the dataset</h3>
<p style="text-align: justify;">Let us look at missing values in all the variables because most of the models don&#8217;t work with missing data and even if they do, imputing them helps more often than not. So, let us check the number of nulls / NaNs in the dataset</p>
<pre><div id='stb-container-2844' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2844' class='stb-grey_box stb-box' > df.apply(lambda x: sum(x.isnull()),axis=0) </div></div></pre>
<p style="text-align: justify;">This command should tell us the number of missing values in each column as isnull() returns 1, if the value is null.</p>
<p style="text-align: justify;"><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/4.-missing.png"><img class="size-full wp-image-22461 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/4.-missing.png" alt="4. missing" width="465" height="304" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/4.-missing.png 465w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/4.-missing-300x196.png 300w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/4.-missing-258x169.png 258w" sizes="(max-width: 465px) 100vw, 465px" /></a></p>
<p style="text-align: justify;">Though the missing values are not very high in number, but many variables have them and each one of these should be estimated and added in the data. Get a detailed view on different imputation techniques through <a href="https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/">this article</a>.</p>
<p style="text-align: justify;">Note: Remember that missing values may not always be NaNs. For instance, if the Loan_Amount_Term is 0, does it makes sense or would you consider that missing? I suppose your answer is missing and you&#8217;re right. So we should check for values which are unpractical.</p>
<p>&nbsp;</p>
<h3>How to fill missing values in LoanAmount?</h3>
<p style="text-align: justify;">There are numerous ways to fill the missing values of loan amount &#8211; the simplest being replacement by mean, which can be done by following code:</p>
<pre><div id='stb-container-7423' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-7423' class='stb-grey_box stb-box' > df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)</div></div></pre>
<p style="text-align: justify;">The other extreme could be to build a supervised learning model to predict loan amount on the basis of other variables and then use age along with other variables to predict survival.</p>
<p style="text-align: justify;">Since, the purpose now is to bring out the steps in data munging, I&#8217;ll rather take an approach, which lies some where in between these 2 extremes. A key hypothesis is that the whether a person is educated or self-employed can combine to give a good estimate of loan amount.</p>
<p style="text-align: justify;">First, let&#8217;s look at the boxplot to see if a trend exists:</p>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/5.-loan-amount-boxplot.png"><img class="wp-image-22463 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/5.-loan-amount-boxplot.png" alt="" width="383" height="350" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/5.-loan-amount-boxplot.png 383w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/5.-loan-amount-boxplot-300x274.png 300w" sizes="(max-width: 383px) 100vw, 383px" /></a></p>
<p style="text-align: justify;">Thus we see some variations in the median of loan amount for each group and this can be used to impute the values. But first, we have to ensure that each of Self_Employed and Education variables should not have a missing values.</p>
<p style="text-align: justify;">As we say earlier, Self_Employed has some missing values. Let&#8217;s look at the frequency table:</p>
<p style="text-align: justify;"><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/6.-self-emp.png"><img class="size-full wp-image-22464 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/6.-self-emp.png" alt="6. self emp" width="389" height="104" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/6.-self-emp.png 389w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/6.-self-emp-300x80.png 300w" sizes="(max-width: 389px) 100vw, 389px" /></a></p>
<p style="text-align: justify;">Since ~86% values are &#8220;No&#8221;, it is safe to impute the missing values as &#8220;No&#8221; as there is a high probability of success. This can be done using the following code:</p>
<pre><div id='stb-container-2187' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2187' class='stb-grey_box stb-box' > df['Self_Employed'].fillna('No',inplace=True)</div></div></pre>
<p style="text-align: justify;">Now, we will create a Pivot table, which provides us median values for all the groups of unique values of Self_Employed and Education features. Next, we define a function, which returns the values of these cells and apply it to fill the missing values of loan amount:</p>
<pre><div id='stb-container-2079' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2079' class='stb-grey_box stb-box' > 
<span style="color: #222222;">table = df.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=np.median)
# Define function to return value of this pivot_table
def fage(x):
 return table.loc[x['Self_Employed'],x['Education']]
# Replace missing values
df['LoanAmount'].fillna(df[df['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)
</span></div></div></pre>
<p style="text-align: justify;">This should provide you a good way to impute missing values of loan amount.</p>
<p>&nbsp;</p>
<h3><strong>How to treat for extreme values in distribution of LoanAmount and ApplicantIncome?</strong></h3>
<p style="text-align: justify;">Let&#8217;s analyze LoanAmount first. Since the extreme values are practically possible, i.e. some people might apply for high value loans due to specific needs. So instead of treating them as outliers, let&#8217;s try a log transformation to nullify their effect:</p>
<pre><div id='stb-container-8063' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-8063' class='stb-grey_box stb-box' > df['LoanAmount_log'] = np.log(df['LoanAmount'])
df['LoanAmount_log'].hist(bins=20)</div></div></pre>
<p>Looking at the histogram again:<br />
<a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/7.-loan-log.png"><img class="size-full wp-image-22466 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/7.-loan-log.png" alt="7. loan log" width="375" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/7.-loan-log.png 375w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/7.-loan-log-300x205.png 300w" sizes="(max-width: 375px) 100vw, 375px" /></a></p>
<p>Now the distribution looks much closer to normal and effect of extreme values has been significantly subsided.</p>
<p style="text-align: justify;">Coming to ApplicantIncome. One intuition can be that some applicants have lower income but strong support Co-applicants. So it might be a good idea to combine both incomes as total income and take a log transformation of the same.</p>
<pre><div id='stb-container-1260' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-1260' class='stb-grey_box stb-box' >df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']
df['TotalIncome_log'] = np.log(df['TotalIncome'])
df['LoanAmount_log'].hist(bins=20) </div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/8.-total-income-log.png"><img class="size-full wp-image-22467 aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/8.-total-income-log.png" alt="8. total income log" width="375" height="256" srcset="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/8.-total-income-log.png 375w, https://www.analyticsvidhya.com/wp-content/uploads/2016/01/8.-total-income-log-300x205.png 300w" sizes="(max-width: 375px) 100vw, 375px" /></a></p>
<p style="text-align: justify;">Now we see that the distribution is much better than before. I will leave it upto you to impute the missing values for Gender, Married, Dependents, Loan_Amount_Term, Credit_History. Also, I encourage you to think about possible additional information which can be derived from the data. For example, creating a column for LoanAmount/TotalIncome might make sense as it gives an idea of how well the applicant is suited to pay back his loan.</p>
<p>Next, we will look at making predictive models.</p>
<p>&nbsp;</p>
<h2>5. Building a Predictive Model in Python</h2>
<p style="text-align: justify;">After, we have made the data useful for modeling, let&#8217;s now look at the python code to create a predictive model on our data set. Skicit-Learn (sklearn) is the most commonly used library in Python for this purpose and we will follow the trail. I encourage you to get a refresher on sklearn through <a href="https://www.analyticsvidhya.com/blog/2015/01/scikit-learn-python-machine-learning-tool/" target="_blank">this article</a>.</p>
<p style="text-align: justify;">Since, sklearn requires all inputs to be numeric, we should convert all our categorical variables into numeric by encoding the categories. This can be done using the following code:</p>
<pre><div id='stb-container-3609' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-3609' class='stb-grey_box stb-box' > from sklearn.preprocessing import LabelEncoder
var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']
le = LabelEncoder()
for i in var_mod:
    df[i] = le.fit_transform(df[i])
df.dtypes </div></div></pre>
<p style="text-align: justify;">Next, we will import the required modules. Then we will define a generic classification function, which takes a model as input and determines the Accuracy and Cross-Validation scores. Since this is an introductory article, I will not go into the details of coding. Please refer to <a href="https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/" target="_blank">this article</a> for getting details of the algorithms with R and Python codes. Also, it&#8217;ll be good to get a refresher on cross-validation through <a href="https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/" target="_blank">this article</a>, as it is a very important measure of power performance.</p>
<pre> <div id='stb-container-5657' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-5657' class='stb-grey_box stb-box' >#Import models from scikit learn module:
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import KFold   #For K-fold cross validation
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn import metrics

#Generic function for making a classification model and accessing performance:
def classification_model(model, data, predictors, outcome):
  #Fit the model:
  model.fit(data[predictors],data[outcome])
  
  #Make predictions on training set:
  predictions = model.predict(data[predictors])
  
  #Print accuracy
  accuracy = metrics.accuracy_score(predictions,data[outcome])
  print "Accuracy : %s" % "{0:.3%}".format(accuracy)

  #Perform k-fold cross-validation with 5 folds
  kf = KFold(data.shape[0], n_folds=5)
  error = []
  for train, test in kf:
    # Filter training data
    train_predictors = (data[predictors].iloc[train,:])
    
    # The target we're using to train the algorithm.
    train_target = data[outcome].iloc[train]
    
    # Training the algorithm using the predictors and target.
    model.fit(train_predictors, train_target)
    
    #Record error from each cross-validation run
    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))
 
  print "Cross-Validation Score : %s" % "{0:.3%}".format(np.mean(error))

  #Fit the model again so that it can be refered outside the function:
  model.fit(data[predictors],data[outcome]) </div></div></pre>
<p>&nbsp;</p>
<h3 id="Logistic-Regression:">Logistic Regression</h3>
<p style="text-align: justify;">Let&#8217;s make our first Logistic Regression model. One way would be to take all the variables into the model but this might result in overfitting (don&#8217;t worry if you&#8217;re unaware of this terminology yet). In simple words, taking all variables might result in the model understanding complex relations specific to the data and will not generalize well. Read more about <a href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" target="_blank">Logistic Regression</a>.</p>
<p>We can easily make some intuitive hypothesis to set the ball rolling. The chances of getting a loan will be higher for:</p>
<ol>
<li>Applicants having a credit history (remember we observed this in exploration?)</li>
<li>Applicants with higher applicant and co-applicant incomes</li>
<li>Applicants with higher education level</li>
<li>Properties in urban areas with high growth perspectives</li>
</ol>
<p>So let&#8217;s make our first model with &#8216;Credit_History&#8217;.</p>
<pre><div id='stb-container-1809' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-1809' class='stb-grey_box stb-box' >outcome_var = 'Loan_Status'
model = LogisticRegression()
predictor_var = ['Credit_History']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 80.945% Cross-Validation Score : 80.946%</p>
<pre><div id='stb-container-8833' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-8833' class='stb-grey_box stb-box' >#We can try different combination of variables:
predictor_var = ['Credit_History','Education','Married','Self_Employed','Property_Area']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 80.945% Cross-Validation Score : 80.946%</p>
<p>Generally we expect the accuracy to increase on adding variables. But this is a more challenging case. The accuracy and cross-validation score are not getting impacted by less important variables. Credit_History is dominating the mode. We have two options now:</p>
<ol>
<li>Feature Engineering: dereive new information and try to predict those. I will leave this to your creativity.</li>
<li>Better modeling techniques. Let&#8217;s explore this next.</li>
</ol>
<p>&nbsp;</p>
<h3 id="Decision-Tree:">Decision Tree</h3>
<p>Decision tree is another method for making a predictive model. It is known to provide higher accuracy than logistic regression model. Read more about <a href="https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/" target="_blank">Decision Trees</a>.</p>
<pre><div id='stb-container-6468' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-6468' class='stb-grey_box stb-box' >model = DecisionTreeClassifier()
predictor_var = ['Credit_History','Gender','Married','Education']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 81.930% Cross-Validation Score : 76.656%</p>
<p>Here the model based on categorical variables is unable to have an impact because Credit History is dominating over them. Let&#8217;s try a few numerical variables:</p>
<pre><div id='stb-container-2347' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-2347' class='stb-grey_box stb-box' >#We can try different combination of variables:
predictor_var = ['Credit_History','Loan_Amount_Term','LoanAmount_log']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 92.345% Cross-Validation Score : 71.009%</p>
<p style="text-align: justify;">Here we observed that although the accuracy went up on adding variables, the cross-validation error went down. This is the result of model over-fitting the data. Let&#8217;s try an even more sophisticated algorithm and see if it helps:</p>
<p>&nbsp;</p>
<h3 id="Random-Forest:">Random Forest</h3>
<p style="text-align: justify;">Random forest is another algorithm for solving the classification problem. Read more about <a href="https://www.analyticsvidhya.com/blog/2015/09/random-forest-algorithm-multiple-challenges/" target="_blank">Random Forest</a>.</p>
<p style="text-align: justify;">An advantage with Random Forest is that we can make it work with all the features and it returns a feature importance matrix which can be used to select features.</p>
<pre><div id='stb-container-1658' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-1658' class='stb-grey_box stb-box' >model = RandomForestClassifier(n_estimators=100)
predictor_var = ['Gender', 'Married', 'Dependents', 'Education',
       'Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',
        'LoanAmount_log','TotalIncome_log']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 100.000% Cross-Validation Score : 78.179%</p>
<p>Here we see that the accuracy is 100% for the training set. This is the ultimate case of overfitting and can be resolved in two ways:</p>
<ol>
<li>Reducing the number of predictors</li>
<li>Tuning the model parameters</li>
</ol>
<p>Let&#8217;s try both of these. First we see the feature importance matrix from which we&#8217;ll take the most important features.</p>
<pre><div id='stb-container-4073' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-4073' class='stb-grey_box stb-box' >#Create a series with feature importances:
featimp = pd.Series(model.feature_importances_, index=predictor_var).sort_values(ascending=False)
print featimp</div></div></pre>
<p><a href="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/9.-rf-feat-imp.png"><img class="wp-image-22476 size-full aligncenter" src="https://www.analyticsvidhya.com/wp-content/uploads/2016/01/9.-rf-feat-imp.png" alt="" width="251" height="205" /></a></p>
<p>Let&#8217;s use the top 5 variables for creating a model. Also, we will modify the parameters of random forest model a little bit:</p>
<pre><div id='stb-container-4232' class='stb-container-css stb-grey-container stb-image-none stb-ltr stb-corners stb-side-none'><aside class='stb-icon'><img src='https://www.analyticsvidhya.com/blog/wp-content/plugins/wp-special-textboxes/images/gears-b.png'></aside><div id='stb-box-4232' class='stb-grey_box stb-box' >model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)
predictor_var = ['TotalIncome_log','LoanAmount_log','Credit_History','Dependents','Property_Area']
classification_model(model, df,predictor_var,outcome_var)</div></div></pre>
<p>Accuracy : 82.899% Cross-Validation Score : 81.461%</p>
<p style="text-align: justify;">Notice that although accuracy reduced, but the cross-validation score is improving showing that the model is generalizing well. Remember that random forest models are not exactly repeatable. Different runs will result in slight variations because of randomization. But the output should stay in the ballpark.</p>
<p style="text-align: justify;">You would have noticed that even after some basic parameter tuning on random forest, we have reached a cross-validation accuracy only slightly better than the original logistic regression model. This exercise gives us some very interesting and unique learning:</p>
<ol>
<li>Using a more sophisticated model does not guarantee better results.</li>
<li>Avoid using complex modeling techniques as a black box without understanding the underlying concepts. Doing so would increase the tendency of overfitting thus making your models less interpretable</li>
<li><a href="https://www.analyticsvidhya.com/blog/2015/03/feature-engineering-variable-transformation-creation/" target="_blank">Feature Engineering</a> is the key to success. Everyone can use an Xgboost models but the real art and creativity lies in enhancing your features to better suit the model.</li>
</ol>
<p>So are you ready to take on the challenge? Start your data science journey with <a href="http://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction" target="_blank">Loan Prediction Problem</a>.</p>
<p>&nbsp;</p>
