
<base target="_blank">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">


<style type="text/css">
a {	text-decoration: none;}
A:hover {	color: yellow;}
A:focus {	color: red;}
#newtype { color: pink}
#redpink { color: #cc0099}
#redword { color: red}
#yellowword { color: yellow}
#greenword { color: green}
#orangeword { color: orange}
#whiteword { color: white}
#grayword { color: gray}
#brownword { color: #ff8000}
#yellowgreen { color: #bfff00}
#palered { color: #ffcccc}
#goldword { color: GoldenRod}

.highlight { 
    color: gray;
    background-color: #002030
  }
</STYLE>

</head>
<body bgcolor="#000000" text="#109030" leftmargin="10" topmargin="10" marginwidth="100" link="#08C8A8" vlink="#389898" alink="#28B8B8">
<FONT size=3>

<h1>Guide for Beginners to Learn SparkR</h1>
<h2>Introduction</h2>
<p style="text-align: justify;">Lately, I&#8217;ve been reading the book <em>Data Scientist at Work</em> to draw some inspiration from successful data scientists. Among other things, I found that most of the data scientists have emphasized upon the evolution of Spark and its incredible extent of computational power.</p>
<p style="text-align: justify;">This piqued my interest to know more about Spark. Since then, I&#8217;ve done an extensive research on this topic to come across every possible bit of information I could find.</p>
<p style="text-align: justify;">Fortunately, Spark has extensive packages for different programming languages. I think, being an R user, my inherent inclination to SparkR is justified.</p>
<p style="text-align: justify;">After I finished with the research, I realized there is no structured learning path available on SparkR. I even connected with folks who are keen to learn SparkR, but none came across such structured learning path. Have you faced the same difficulty ? If yes, here&#8217;s your answer.</p>
<p style="text-align: justify;">This inspired me to create this step by step learning path. I&#8217;ve listed the best resources available on SparkR. If you manage to complete the 7 steps thoroughly, you are expected to acquire intermediate level of adeptness on Spark. However, your journey from intermediate to expert level would require hours of practice. You knew that, right ? Let&#8217;s begin!</p>

<h2>Step 1: What is Spark? Why do we need it?</h2>
<p style="text-align: justify;"><span style="font-weight: 400;">Spark is an <a href="http://spark.apache.org/" target="_blank" rel="nofollow">Apache project</a> promoted as “lightning fast cluster computing”. It&#8217;s astonishing computing speed makes it 100x faster than hadoop  and 10x faster than Mapreduce in memory. For large data processing, Spark has become first choice of every data scientist or engineer today.</span></p>
<p style="text-align: justify;"><span style="font-weight: 400;">You see Amazon, eBay, Yahoo, Facebook, everyone is using Spark for data processing on insanely large data sets. Apache Spark has one of the fastest growing big data community with more than 750 contributors from 200+ companies worldwide. According to the 2015 Data Science Salary Survey by O’Reilly, presence of Apache Spark skills added $11,000 extra to the median salary.</span></p>
<p><span style="font-weight: 400;">To explore the amazing world of Spark in detail, you can refer this </span><a href="https://www.toptal.com/spark/introduction-to-apache-spark" target="_blank" rel="nofollow"><span style="font-weight: 400;">article</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">You can also watch this video to learn more about the value that Spark has added to the business world:</span></p>
<p><iframe width="500" height="281" src="https://www.youtube.com/embed/mL5dQ_1gkiA?feature=oembed&amp;width=500&amp;height=750" frameborder="0" allowfullscreen></iframe></p>
<p><span style="font-weight: 400;">However, if you more of a <em>person who read stuffs</em>, you can skip the video and check this recommended </span><a href="http://blog.cloudera.com/blog/2014/03/why-apache-spark-is-a-crossover-hit-for-data-scientists/" target="_blank"><span style="font-weight: 400;">blog</span></a><span style="font-weight: 400;">.</span></p>
<p>Interesting Read: <a href="https://databricks.com/blog/2014/11/05/spark-officially-sets-a-new-record-in-large-scale-sorting.html" target="_blank" rel="nofollow">Apache officially sets a new record in large scale sorting</a></p>
<p>&nbsp;</p>
<h2>Step 2: What is Spark R?</h2>
<p>Being an R user, let&#8217;s channelize our focus on SparkR.</p>
<p style="text-align: justify;"><span style="font-weight: 400;">R is one of the most widely used programming languages in data science. With its simple syntax and ability to run complex algorithms, it is probably the first choice of language for beginners. </span></p>
<p style="text-align: justify;">But, R suffers from a problem. That is, its data processing capacity is limited to memory on a single node. This limits the amount of data you can process with R. Now, you know why does R runs out of memory when you attempt to work on large data sets. To overcome this memory problem, we can use SparkR.</p>
<p style="text-align: justify;">Along with R, Apache Spark provides APIs for various languages such as Python, Scala, Java, SQL and many more. These APIs act as a bridge in connecting these tools with Spark.</p>
<p><span style="font-weight: 400;">For a detailed view of SparkR, this is a must watch video:</span></p>
<p><iframe width="500" height="281" src="https://www.youtube.com/embed/5o-9ozwQgMw?feature=oembed&amp;width=500&amp;height=750" frameborder="0" allowfullscreen></iframe></p>
<p style="text-align: justify;"><strong>Note:</strong> SparkR has a limitation. Currently, it only support linear predictive models. Therefore, if you were excited to run boosting algorithm on SparkR, you might have to wait until the next version is rolled out.</p>
<p>&nbsp;</p>
<h2>Step 3 : Setting up your Machine</h2>
<p style="text-align: justify;"><span style="font-weight: 400;">If you are still reading, I presume that this new technology has sparked a curiosity in you and that you would be determined to complete this journey. So, lets move on with setting up the machine:</span></p>
<p><span style="font-weight: 400;">To install SparkR, firstly, we need to install Spark in our systems, since it runs at the backend.</span></p>
<p><span style="font-weight: 400;">Following resources will help you in installation on your respective OS:</span></p>
<ol>
<li style="font-weight: 400;"><a href="https://hernandezpaul.wordpress.com/2016/01/24/apache-spark-installation-on-windows-10/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Windows</span></a></li>
<li style="font-weight: 400;"><a href="http://blog.prabeeshk.com/blog/2014/10/31/install-apache-spark-on-ubuntu-14-dot-04/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Ubuntu</span></a></li>
<li style="font-weight: 400;"><a href="http://genomegeek.blogspot.in/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Mac OS</span></a></li>
</ol>
<p style="text-align: justify;"><span style="font-weight: 400;">After you&#8217;ve successfully installed,  it just takes few extra steps to initiate SparkR , once you are done with Spark installation. Following resources will help you to initiate SparkR locally:</span></p>
<ol>
<li style="font-weight: 400;"><a href="http://blog.danielemaasit.com/2015/07/26/installing-and-starting-sparkr-locally-on-windows-8-1-and-rstudio/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Windows</span></a></li>
<li style="font-weight: 400;"><a href="http://www.r-bloggers.com/sparkr-with-rstudio-in-ubuntu-12-04/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Ubuntu</span></a></li>
<li style="font-weight: 400;"><a href="http://opiateforthemass.es/articles/six-lines-to-install-and-start-sparkr-on-mac-os-x-yosemite/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Mac OS</span></a></li>
</ol>
<p>&nbsp;</p>
<h2>Step 4 : Getting the Basics Right</h2>
<p style="text-align: justify;"><span style="font-weight: 400;"><strong>Start with R:</strong> Though I assume that you would be knowing R if you are interested to work with Big Data. However, if R is not your domain, this </span><a href="https://www.datacamp.com/courses/intermediate-r" target="_blank"><span style="font-weight: 400;">course</span></a><span style="font-weight: 400;"> by data camp will help you to get started with R.</span></p>
<p><strong>Exercise:</strong> Install a package <a href="http://swirlstats.com/" target="_blank" rel="nofollow">swirl in R</a> and do the complete set of exercises.</p>
<p style="text-align: justify;"><span style="font-weight: 400;"><strong>Database handling with SQL:</strong> SQL is widely used in SparkR in order to implement functions easily using simple commands. This helps in reducing the code lines you have to write. Also, increases the speed of operations. If you are not familiar with SQL, you should do this <a href="https://www.codecademy.com/learn/learn-sql" target="_blank">course</a></span><span style="font-weight: 400;"> by codecademy.</span></p>
<p><strong>Exercise: </strong> <a href="http://www.w3resource.com/sql-exercises/sql-retrieve-from-table.php" target="_blank" rel="nofollow">Practice 1</a> and <a href="http://www.w3resource.com/sql-exercises/sql-boolean-operators.php" target="_blank" rel="nofollow">Practice 2</a></p>
<p>&nbsp;</p>
<h2>Step 5 : Data Exploration with SparkR and SQL</h2>
<p style="text-align: justify;">Once your basics are at place, it&#8217;s time to learn to work with SparkR &amp; SQL.</p>
<p style="text-align: justify;"><span style="font-weight: 400;">SparkR enables us to use a number of data exploration operations using a combination of R and SQL simultaneously. </span><span style="font-weight: 400;">The most common ones being <code>select</code>, <code>collect</code>, <code>group_By</code>, <code>summarize</code>, <code>subset</code> and <code>arrange</code>. </span><span style="font-weight: 400;">You can learn these operations with </span><a href="https://www.codementor.io/spark/tutorial/spark-r-data-frame-operations-sql" target="_blank"><span style="font-weight: 400;">this article</span></a><span style="font-weight: 400;">.</span></p>
<p><strong>Exercise: </strong>Do this exercise by <a href="http://ampcamp.berkeley.edu/5/exercises/sparkr.html" target="_blank" rel="nofollow">AmpBerkley</a></p>
<p style="text-align: justify;"><span style="font-weight: 400;">Dataset used in above exercise: </span><a href="http://d12yw77jruda6f.cloudfront.net/training-downloads.zip" target="_blank" rel="nofollow"><span style="font-weight: 400;">Download</span></a></p>
<p>&nbsp;</p>
<h2>Step 6 : Building Predictive Models (Linear) on SparkR</h2>
<p style="text-align: justify;">As mentioned above, SparkR only supports linear modeling algorithms such as <code>Regression</code>. However, it&#8217;s just a matter of time until we are facing this constraint. I am expecting them to soon roll out an updated version which would support non-linear models as well.</p>
<p style="text-align: justify;"><span style="font-weight: 400;">SparkR implements linear modeling using the function <code>glm</code>. On the other hand, a</span><span style="font-weight: 400;">t present, Spark has a machine learning library known as <code>MLlib</code> (for more info on MLlib, </span><a href="http://spark.apache.org/mllib/" target="_blank"><span style="font-weight: 400;">click here</span></a><span style="font-weight: 400;">), which supports non-linear modeling. </span></p>
<p><span style="font-weight: 400;"><strong>Learn and Practice:</strong> To build your first <em>linear regression model</em> on SparkR, follow this <a href="https://www.codementor.io/spark/tutorial/linear-models-apache-spark-1-5-uses-present-limitations" target="_blank" rel="nofollow">link.</a> To build a <em>logistic regression model</em>, follow this <a href="http://rpubs.com/tcosta/sparkr-glm" target="_blank" rel="nofollow">link</a>.</span></p>
<p>&nbsp;</p>
<h2>Step 7 : Integrating SparkR with Hive for Faster Computation</h2>
<p>SparkR works even faster with Apache Hive for database management.</p>
<p style="text-align: justify;"><b>Apache Hive</b><span style="font-weight: 400;"> is a data warehouse infrastructure built on top of Hadoop for providing data summarization, query, and analysis. Integrating Hive with SparkR would help running queries even faster and more efficiently.</span></p>
<p style="text-align: justify;"><span style="font-weight: 400;">If you want to step into bigdata, the use of hive would really be a great advantage for efficient data processing. You can i</span><span style="font-weight: 400;">nstall Hive by following the links given for respective OS:</span></p>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;">For </span><a href="https://www.javacodegeeks.com/2012/10/apache-hive-on-windows-in-6-easy-steps.html" target="_blank" rel="nofollow"><span style="font-weight: 400;">Windows</span></a></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">For </span><a href="http://blog.aegissofttech.com/blog/post/learn-apache-hive-installation-on-ubuntu-linux" target="_blank" rel="nofollow"><span style="font-weight: 400;">Ubuntu</span></a></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">For </span><a href="https://amodernstory.com/2015/03/29/installing-hive-on-mac/" target="_blank" rel="nofollow"><span style="font-weight: 400;">Mac OS</span></a></li>
</ol>
<p style="text-align: justify;">After you&#8217;ve installed R successfully, you can start integrating Hive with SparkR using the steps<span style="font-weight: 400;"> demonstrated in this </span><a href="https://www.youtube.com/watch?v=qwCaIxv2hXY" target="_blank" rel="nofollow"><span style="font-weight: 400;">video</span></a><span style="font-weight: 400;">. Alternatively, i</span><span style="font-weight: 400;">f you are more comfortable in reading, this video is also available in text format on this </span><span style="font-weight: 400;"><a href="http://www.godatafy.com/tech-blog/sparkr-installation/#more-456" target="_blank" rel="nofollow">blog</a>.</span></p>
<p style="text-align: justify;"><span style="font-weight: 400;">For a quick overview on SparkR, you can also follow its official </span><a href="https://spark.apache.org/docs/latest/sparkr.html" target="_blank" rel="nofollow"><span style="font-weight: 400;">documentation</span></a><span style="font-weight: 400;">.</span></p>
<p>&nbsp;</p>
<h2>End Notes</h2>
<p style="text-align: justify;"><span style="font-weight: 400;">I hope that I have made the learning path clear enough to accelerate your journey into data science using SparkR. </span></p>
<p style="text-align: justify;"><span style="font-weight: 400;">SparkR is often being seen as an intermediate step to switch into Big Data using R. I learned SparkR because I used to find immense difficulty in working on large data sets in R. SparkR provided me a convenient and cost free way to continue with my learning. </span></p>
<p style="text-align: justify;">In addition, for a R user, SparkR can also provide headstart to someone who wishes to transition into big data industry. It&#8217;s is much powerful than I have explored yet.</p>
<p style="text-align: justify;"><span style="font-weight: 400;">Did you find this article helpful ? Have you worked on SparkR ? Do share your suggestions / experience in the comments section below.</span></p>
