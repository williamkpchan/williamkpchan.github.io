<base target="_blank">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<style type="text/css">

body {
background-color: #000000;
 color: #109030;
 margin:10%;
}
a { text-decoration: none;
	color: #28B8B8;}
a:visited {	color: #389898;}
A:hover {	color: yellow;}
A:focus {	color: red;}
code { color: pink; background-color: #302030}
pre { color: gray; background-color: #001010}
#newtype { color: pink}
#redpink { color: #cc0099}
#redword { color: red}
#yellowword { color: yellow}
#greenword { color: lightgreen}
#limeword { color: #00ff00}
#orangeword { color: orange}
#cyanword { color: cyan}
#whiteword { color: white}
#grayword { color: gray}
#brownword { color: #ff8000}
#yellowgreen { color: #bfff00}
#palered { color: #ffcccc}
#blueword { color: dodgerblue}
#purpleword { color: darkorchid}
#goldword { color: GoldenRod}
#silverword { color: silver}
#blackword { color: black}
.left {
    position: absolute;
    left: 100px;
    color: GoldenRod;
    border: 1px solid GoldenRod;
    padding: 2px;
    font-size: 60%;
}
.bord {
    color: redpink;
    border: 1px solid GoldenRod;
    padding: 1px;
    font-size: 90%;
}
.highlight { 
    color: white;
    background-color: #002030
  }
</STYLE>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script>
$(document).ready(function(){
    $('.left').click(function(){
    parent.history.back();
    return false;
    });
});
</script>


</head>
<body>
<FONT size=3>

<h1>The 10 Algorithms Machine Learning Engineers Need to Know
</h1>

<p name="0101" id="0101" class="graf graf--p graf-after--h3">It is no doubt that the sub-field of machine learning / artificial intelligence has increasingly gained more popularity in the past couple of years. As Big Data is the hottest trend in the tech industry at the moment, machine learning is incredibly powerful to make predictions or calculated suggestions based on large amounts of data. Some of the most common examples of machine learning are Netflix’s algorithms to make movie suggestions based on movies you have watched in the past or Amazon’s algorithms that recommend books based on books you have bought before.
</p>
<p name="3a50" id="3a50" class="graf graf--p graf-after--p">So if you want to learn more about machine learning, how do you start? For me, my first introduction is when I took an Artificial Intelligence class when I was studying abroad in Copenhagen. My lecturer is a full-time Applied Math and CS professor at the Technical University of Denmark, in which his research areas are logic and artificial, focusing primarily on the use of logic to model human-like planning, reasoning and problem solving. The class was a mix of discussion of theory/core concepts and hands-on problem solving. The textbook that we used is one of the AI classics: 
<a href="https://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597" data-href="https://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597" class="markup--anchor markup--p-anchor" target="_blank">Peter Norvig’s 
<em class="markup--em markup--p-em">Artificial Intelligence — A Modern Approach
</em>
</a>, in which we covered major topics including intelligent agents, problem-solving by searching, adversarial search, probability theory, multi-agent systems, social AI, philosophy/ethics/future of AI. At the end of the class, in a team of 3, we implemented simple search-based agents solving transportation tasks in a virtual environment as a programming project.
</p>
<p name="1bce" id="1bce" class="graf graf--p graf-after--p">I have learned a tremendous amount of knowledge thanks to that class, and decided to keep learning about this specialized topic. In the last few weeks, I have been multiple tech talks in San Francisco on deep learning, neural networks, data architecture — and a Machine Learning conference with a lot of well-known professionals in the field. Most importantly, I enrolled in 
<strong class="markup--strong markup--p-strong">Udacity’s 
</strong>
<a href="https://www.udacity.com/course/intro-to-machine-learning--ud120" data-href="https://www.udacity.com/course/intro-to-machine-learning--ud120" class="markup--anchor markup--p-anchor" target="_blank">
<strong class="markup--strong markup--p-strong">
<em class="markup--em markup--p-em">Intro to Machine Learning
</em>
</strong>
</a>
<em class="markup--em markup--p-em"> 
</em>online course in the beginning of June and has just finished it a few days ago. In this post, I want to share some of the most common machine learning algorithms that I learned from the course.
</p>
<p class="highlight">Machine learning algorithms can be divided into 3 broad categories — supervised learning, unsupervised learning, and reinforcement learning. 
</p>Supervised learning
</strong> is useful in cases where a property (
<em class="markup--em markup--p-em">label
</em>) is available for a certain dataset (
<em class="markup--em markup--p-em">training set
</em>), but is missing and needs to be predicted for other instances. 
<strong class="markup--strong markup--p-strong">Unsupervised learning
</strong> is useful in cases where the challenge is to discover implicit relationships in a given 
<em class="markup--em markup--p-em">unlabeled 
</em>dataset (items are not pre-assigned). 
<strong class="markup--strong markup--p-strong">Reinforcement learning
</strong> falls between these 2 extremes — there is some form of feedback available for each predictive step or action, but no precise label or error message. Since this is an intro class, I didn’t learn about reinforcement learning, but I hope that 10 algorithms on supervised and unsupervised learning will be enough to keep you interested.
</p>
<h3 name="df84" id="df84" class="graf graf--h3 graf-after--p">
<strong class="markup--strong markup--h3-strong">Supervised Learning
</strong>
</h3>
<p name="79cd" id="79cd" class="graf graf--p graf-after--h3">
<strong class="markup--strong markup--p-strong">1.
</strong> 
<strong class="markup--strong markup--p-strong">Decision Trees: 
</strong>A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance-event outcomes, resource costs, and utility. Take a look at the image to get a sense of how it looks like.
</p>

<figcaption class="imageCaption">Decision Tree
</figcaption>
<p>From a business decision point of view, a decision tree is the minimum number of yes/no questions that one has to ask, to assess the probability of making a correct decision, most of the time. As a method, it allows you to approach the problem in a structured and systematic way to arrive at a logical conclusion.
</p>
<p name="8a16" id="8a16" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">2.
</strong> 
<strong class="markup--strong markup--p-strong">Naïve Bayes Classification: 
</strong>Naïve Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes’ theorem with strong (naïve) independence assumptions between the features. The featured image is the equation — with P(A|B) is posterior probability, P(B|A) is likelihood, P(A) is class prior probability, and P(B) is predictor prior probability.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*IBFIDn5MR6e9Yk1qslVoGA.jpeg">
<figcaption class="imageCaption">Naive Bayes Classification
</figcaption>
<p>Some of real world examples are:
</p>
<p name="de3c" id="de3c" class="graf graf--p graf-after--p">· To mark an email as spam or not spam
</p>
<p name="d170" id="d170" class="graf graf--p graf-after--p">· Classify a news article about technology, politics, or sports
</p>
<p name="eac3" id="eac3" class="graf graf--p graf-after--p">· Check a piece of text expressing positive emotions, or negative emotions?
</p>
<p name="d29f" id="d29f" class="graf graf--p graf-after--p">· Used for face recognition software.
</p>
<p name="b1e6" id="b1e6" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">3.
</strong> 
<strong class="markup--strong markup--p-strong">Ordinary Least Squares Regression: 
</strong>If you know statistics, you probably have heard of linear regression before. Least squares is a method for performing linear regression. You can think of linear regression as the task of fitting a straight line through a set of points. There are multiple possible strategies to do this, and “ordinary least squares” strategy go like this — You can draw a line, and then for each of the data points, measure the vertical distance between the point and the line, and add these up; the fitted line would be the one where this sum of distances is as small as possible.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/1000/1*Sy_6ipmBh_21KD0_dds1HQ.png">

</p>
</p>
<figcaption class="imageCaption">Ordinary Least Squares Regression
</figcaption>
<p>Linear refers the kind of model you are using to fit the data, while least squares refers to the kind of error metric you are minimizing over.
</p>
<p name="1b1c" id="1b1c" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">4.
</strong> 
<strong class="markup--strong markup--p-strong">Logistic Regression: 
</strong>Logistic regression is a powerful statistical way of modeling a binomial outcome with one or more explanatory variables. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*nsphNzg5aAtTWbI4jwKItw.png">

</p>
</p>
<figcaption class="imageCaption">Logistic Regression
</figcaption>
<p>In general, regressions can be used in real-world applications such as:
</p>
<p name="4d06" id="4d06" class="graf graf--p graf-after--p">· Credit Scoring
</p>
<p name="fab5" id="fab5" class="graf graf--p graf-after--p">· Measuring the success rates of marketing campaigns
</p>
<p name="5c9f" id="5c9f" class="graf graf--p graf-after--p">· Predicting the revenues of a certain product
</p>
<p name="303e" id="303e" class="graf graf--p graf-after--p">· Is there going to be an earthquake on a particular day?
</p>
<p name="ee0b" id="ee0b" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">5.
</strong> 
<strong class="markup--strong markup--p-strong">Support Vector Machines: 
</strong>SVM is binary classification algorithm. Given a set of points of 2 types in N dimensional place, SVM generates a (N — 1) dimensional hyperlane to separate those points into 2 groups. Say you have some points of 2 types in a paper which are linearly separable. SVM will find a straight line which separates those points into 2 types and situated as far as possible from all those points.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*3MU2_8mbRM2qhNz0tecvUg.png">

</p>
</p>
<figcaption class="imageCaption">Support Vector Machine
</figcaption>
<p>In terms of scale, some of the biggest problems that have been solved using SVMs (with suitably modified implementations) are display advertising, human splice site recognition, image-based gender detection, large-scale image classification…
</p>
<p name="95d3" id="95d3" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">6.
</strong> 
<strong class="markup--strong markup--p-strong">Ensemble Methods: 
</strong>Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a weighted vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, bagging, and boosting.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*BKzn0JPoIJhob5g0j5xj5A.png">

</p>
</p>
<figcaption class="imageCaption">Ensemble Learning Algorithms
</figcaption>
<p>So how do ensemble methods work and why are they superior to individual models?
</p>
<p name="1090" id="1090" class="graf graf--p graf-after--p">· 
<strong class="markup--strong markup--p-strong">They average out biases
</strong>: If you average a bunch of democratic-leaning polls and republican-leaning polls together, you will get an average something that isn’t leaning either way.
</p>
<p name="65b0" id="65b0" class="graf graf--p graf-after--p">· 
<strong class="markup--strong markup--p-strong">They reduce the variance
</strong>: The aggregate opinion of a bunch of models is less noisy than the single opinion of one of the models. In finance, this is called diversification — a mixed portfolio of many stocks will be much less variable than just one of the stocks alone. This is why your models will be better with more data points rather than fewer.
</p>
<p name="1204" id="1204" class="graf graf--p graf-after--p">· 
<strong class="markup--strong markup--p-strong">They are unlikely to over-fit: 
</strong>If you have individual models that didn’t over-fit, and you are combining the predictions from each model in a simple way (average, weighted average, logistic regression), then there’s no room for over-fitting.
</p>
<h3 name="4817" id="4817" class="graf graf--h3 graf-after--p">
<strong class="markup--strong markup--h3-strong">Unsupervised Learning
</strong>
</h3>
<p name="b21c" id="b21c" class="graf graf--p graf-after--h3">
<strong class="markup--strong markup--p-strong">7.
</strong> 
<strong class="markup--strong markup--p-strong">Clustering Algorithms: 
</strong>Clustering is the task of grouping a set of objects such that objects in the same group (
<em class="markup--em markup--p-em">cluster
</em>) are more similar to each other than to those in other groups.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*a58qZWbN7aAxFUTPeRiRTQ.png">

</p>
</p>
<figcaption class="imageCaption">Clustering Algorithms
</figcaption>
<p>Every clustering algorithm is different, and here are a couple of them:
</p>
<p name="8420" id="8420" class="graf graf--p graf-after--p">· Centroid-based algorithms
</p>
<p name="9784" id="9784" class="graf graf--p graf-after--p">· Connectivity-based algorithms
</p>
<p name="22aa" id="22aa" class="graf graf--p graf-after--p">· Density-based algorithms
</p>
<p name="29c8" id="29c8" class="graf graf--p graf-after--p">· Probabilistic
</p>
<p name="9b0a" id="9b0a" class="graf graf--p graf-after--p">· Dimensionality Reduction
</p>
<p name="1cb6" id="1cb6" class="graf graf--p graf-after--p">· Neural networks / Deep Learning
</p>
<p name="6ee6" id="6ee6" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">8.
</strong> 
<strong class="markup--strong markup--p-strong">Principal Component Analysis: 
</strong>PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.
</p>
<p>

<img src="https://cdn-images-1.medium.com/max/750/1*WRKdN-NYF0mMumhfOXVa2Q.png">

</p>
</p>
<figcaption class="imageCaption">Principal Component Analysis
</figcaption>
<p>Some of the applications of PCA include compression, simplifying data for easier learning, visualization. Notice that domain knowledge is very important while choosing whether to go forward with PCA or not. It is not suitable in cases where data is noisy (all the components of PCA have quite a high variance).
</p>
<p name="c17f" id="c17f" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">9.
</strong> 
<strong class="markup--strong markup--p-strong">Singular Value Decomposition: 
</strong>In linear algebra, SVD is a factorization of a real complex matrix. For a given 
<em class="markup--em markup--p-em">m * n 
</em>matrix M, there exists a decomposition such that M = UΣV, where U and V are unitary matrices and Σ is a diagonal matrix.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/750/1*KHPKX-04JO3utClrxopJ0w.png">

</p>
</p>
<figcaption class="imageCaption">Singular Value Decomposition
</figcaption>
<p>PCA is actually a simple application of SVD. In computer vision, the 1st face recognition algorithms used PCA and SVD in order to represent faces as a linear combination of “eigenfaces”, do dimensionality reduction, and then match faces to identities via simple methods; although modern methods are much more sophisticated, many still depend on similar techniques.
</p>
<p name="82da" id="82da" class="graf graf--p graf-after--p">
<strong class="markup--strong markup--p-strong">10.
</strong> 
<strong class="markup--strong markup--p-strong">Independent Component Analysis: 
</strong>ICA is a statistical technique for revealing hidden factors that underlie sets of random variables, measurements, or signals. ICA defines a generative model for the observed multivariate data, which is typically given as a large database of samples. In the model, the data variables are assumed to be linear mixtures of some unknown latent variables, and the mixing system is also unknown. The latent variables are assumed non-gaussian and mutually independent, and they are called independent components of the observed data.
</p>
<p>
<img src="https://cdn-images-1.medium.com/max/1000/1*RBN-qGYgTFlsxzfORsqoEg.png">

</p>
</p>
<figcaption class="imageCaption">Independent Component Analysis
</figcaption>
<p>ICA is related to PCA, but it is a much more powerful technique that is capable of finding the underlying factors of sources when these classic methods fail completely. Its applications include digital images, document databases, economic indicators and psychometric measurements.
</p>
<p name="edf1" id="edf1" class="graf graf--p graf-after--p graf--last">Now go forth and wield your understanding of algorithms to create machine learning applications that make better experiences for people everywhere.
</p>
</p>
</p>
</section>
</main>